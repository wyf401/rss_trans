<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 16 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>MERaLiON-TextLLM：中文、印尼语、马来语和新加坡式英语大型语言模型的跨语言理解</title>
      <link>https://arxiv.org/abs/2501.08335</link>
      <description><![CDATA[arXiv:2501.08335v1 公告类型：新
摘要：多语言大型语言模型 (MLLM) 在各种语言中都表现出令人印象深刻的能力。然而，不同语系之间的功效可能有很大差异，尤其是对于那些语言资源有限的语系。本报告介绍了 MERaLiON-TextLLM，这是一系列开源语言模型，专门用于提高对中文、印尼语、马来语和新加坡式英语的理解和生成。最初发布的模型建立在 Llama-3-8B-Base 上，并通过精心设计的持续预训练和权重合并过程进行改进。我们的方法在这些语言的基准测试中实现了性能改进，超过了官方 Llama-3 模型的能力。我们提供模型检查点作为资源，以支持跨语言语言理解的进一步研究和开发。]]></description>
      <guid>https://arxiv.org/abs/2501.08335</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于自由文本数据精选标记和评级的大型语言模型集合</title>
      <link>https://arxiv.org/abs/2501.08413</link>
      <description><![CDATA[arXiv:2501.08413v1 公告类型：新
摘要：心理学研究通常会收集自由文本响应，这提供了定量措施可能无法捕捉到的丰富定性见解。由多名训练有素的人工编码员在自由文本数据中标记精选的研究兴趣主题通常需要大量劳动力和时间。尽管大型语言模型 (LLM) 在语言处理方面表现出色，但依赖于闭源 LLM 的 LLM 辅助标记技术不能直接应用于自由文本数据，除非明确同意外部使用。
在本研究中，我们提出了一个组装本地可部署 LLM 的框架，以在隐私约束下增强自由文本数据中预定主题的标记。类似于多个人工评分者的注释，该框架利用了各种开源 LLM 的异质性。集成方法寻求 LLM 之间的一致性和不一致性之间的平衡，由相关性评分方法指导，该方法利用主题描述和 LLM 推理之间的嵌入距离。我们使用来自饮食失调相关论坛的可公开访问的 Reddit 数据和饮食失调患者的自由文本回复（均辅以人工注释）对集成方法进行了评估。
我们发现：（1）相同大小的 LLM 之间的标记性能存在异质性，一些 LLM 表现出低灵敏度但高精度，而另一些则表现出高灵敏度但低精度。（2）与单个 LLM 相比，LLM 集成在预测人工注释方面实现了最高的精度和最佳的精度-灵敏度权衡。（3）LLM 之间的相关性得分显示出比二分标记更大的一致性，表明相关性评分方法有效地缓解了 LLM 标记的异质性。]]></description>
      <guid>https://arxiv.org/abs/2501.08413</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言和文本到图像模型中的宗教偏见状况：分析、检测和消除偏见策略</title>
      <link>https://arxiv.org/abs/2501.08441</link>
      <description><![CDATA[arXiv:2501.08441v1 公告类型：新
摘要：注意：本文包括与宗教偏见相关的潜在冒犯性内容的示例，仅用于学术目的。语言模型的广泛采用凸显了对其固有偏见进行批判性审查的必要性，尤其是关于宗教的偏见。本研究系统地研究了语言模型和文本到图像生成模型中的宗教偏见，分析了开源和闭源系统。我们构建了大约 400 个独特的、自然发生的提示，以探测语言模型在不同任务中的宗教偏见，包括掩码填充、提示完成和图像生成。我们的实验揭示了与某些宗教不成比例的潜在刻板印象和偏见的令人担忧的实例。此外，我们还探索了跨领域偏见，研究了宗教偏见如何与性别、年龄和国籍等人口统计因素相交叉。本研究通过使用旨在减轻已识别偏见的纠正提示，进一步评估了有针对性的去偏见技术的有效性。我们的研究结果表明，语言模型在文本和图像生成任务中仍然表现出明显的偏见，这凸显了开发更公平的语言模型以实现全球可接受性的迫切需要。]]></description>
      <guid>https://arxiv.org/abs/2501.08441</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Jochre 3 和意第绪语 OCR 语料库</title>
      <link>https://arxiv.org/abs/2501.08442</link>
      <description><![CDATA[arXiv:2501.08442v1 公告类型：新
摘要：我们描述了一个公开的意第绪语 OCR 语料库的构建，并描述和评估了开源 OCR 工具套件 Jochre 3，包括用于语料库注释的 Alto 编辑器、用于 Alto OCR 层生成的 OCR 软件以及可定制的 OCR 搜索引擎。意第绪语 OCR 语料库的当前版本包含 658 页、186K 个标记和 840K 个字形。Jochre 3 OCR 工具使用各种微调的 YOLOv8 模型进行自上而下的页面布局分析，并使用自定义 CNN 网络进行字形识别。它在我们的测试语料库上获得了 1.5% 的 CER，远远超过所有其他现有的意第绪语公共模型。我们利用 Jochre 3 OCR 分析了完整的 6.6 亿个 Yiddish Book Center 单词，并且可以通过 Yiddish Book Center OCR 搜索引擎搜索新的 OCR。]]></description>
      <guid>https://arxiv.org/abs/2501.08442</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于文本分类的大型语言模型：案例研究和综合回顾</title>
      <link>https://arxiv.org/abs/2501.08457</link>
      <description><![CDATA[arXiv:2501.08457v1 公告类型：新
摘要：释放大型语言模型 (LLM) 在数据分类中的潜力代表了自然语言处理领域一个有希望的前沿。在这项工作中，我们在两种不同的分类场景中评估了不同 LLM 与最先进的深度学习和机器学习模型的性能：i) 根据在线发布的职位评论对员工的工作地点进行分类（多类分类），以及 2) 将新闻文章分类为假的或真假（二元分类）。我们的分析涵盖了各种语言模型，这些模型在大小、量化和架构上有所不同。我们探索了替代提示技术的影响，并根据加权 F1 分数评估模型。此外，我们研究了每个语言模型的性能（F1 分数）和时间（推理响应时间）之间的权衡，以更细致地理解每个模型的实际适用性。我们的工作揭示了基于提示策略的模型响应的显著差异。我们发现 LLM（尤其是 Llama3 和 GPT-4）在复杂的分类任务（例如多类分类）中的表现优于传统方法，但推理时间会更长。相比之下，在更简单的二元分类任务中，更简单的 ML 模型可以提供更好的性能与时间权衡。]]></description>
      <guid>https://arxiv.org/abs/2501.08457</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>低资源任务的选择性注意力合并：儿童 ASR 案例研究</title>
      <link>https://arxiv.org/abs/2501.08468</link>
      <description><![CDATA[arXiv:2501.08468v1 公告类型：新
摘要：虽然语音基础模型 (SFM) 在各种语音任务中表现出色，但它们在儿童自动语音识别 (ASR) 等低资源任务中的表现受到有限的预训练数据的限制。为了解决这个问题，我们探索了不同的模型合并技术，以利用在更大、更多样化的语音语料库上训练的模型的知识。本文还介绍了选择性注意 (SA) 合并，这是一种新方法，它可以选择性地合并来自注意力矩阵的任务向量，以增强 SFM 在低资源任务上的性能。在 MyST 数据库上的实验表明，相对词错误率显著降低高达 14%，优于现有的模型合并和数据增强技术。通过将数据增强技术与 SA Merge 相结合，我们在 MyST 数据库上为 Whisper-small 模型实现了 8.69 的最新 WER，凸显了 SA Merge 在改进低资源 ASR 方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.08468</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>剧院舞台作为实验室：现场表演的实时喜剧法学硕士系统回顾</title>
      <link>https://arxiv.org/abs/2501.08474</link>
      <description><![CDATA[arXiv:2501.08474v1 公告类型：新
摘要：在这篇立场文件中，我们回顾了近年来涉及计算幽默生成系统的学术和艺术作品的折衷历史，并特别关注现场表演。我们认为，人工智能喜剧应该在现场条件下、在共享物理或在线空间的观众面前以及在实时约束下进行评估。我们进一步指出，即兴喜剧是部署和评估计算幽默系统的完美基础。使用成功的人工智能融合节目的例子，我们证明现场表演为计算幽默生成提出了三组挑战：1) 关于机器人化身、拟人化和人机竞争的问题，2) 关于喜剧时机和观众互动性质的问题，以及 3) 关于人类对看似荒谬的人工智能生成的幽默的解释的问题。我们认为这些问题会影响评估计算幽默的方法的选择，因为任何这样的方法都需要解决现场观众和表演空间的限制。这些询问也强调了人类喜剧演员与人工智能工具的不同类型的合作关系。]]></description>
      <guid>https://arxiv.org/abs/2501.08474</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>量化数据对齐对下游模型性能的重要性</title>
      <link>https://arxiv.org/abs/2501.08496</link>
      <description><![CDATA[arXiv:2501.08496v1 公告类型：新
摘要：与传统上强调数据集大小相反，我们探索了数据对齐（数据质量的一个经常被忽视的方面）在训练大型语言模型 (LLM) 中的作用。为此，我们使用基于 Task2Vec 的对齐系数（两个数据集之间相似性的定量度量）来量化训练数据和评估数据之间的对齐对下游性能的影响。具体来说，我们针对两种设置进行了受控的 \textit{interventional} 实验：1. 各种预训练 (pt) 与评估数据集之间对齐系数增加的影响，以及 2. 领域特定微调 (ft) 与领域特定评估之间对齐系数增加的影响。我们探索的特定领域任务是自动形式化——用于形式验证的自然语言和代码之间的机器翻译任务。在这两种情况下，我们都发现模型训练和评估数据的对齐系数与模型在相应下游任务上的损失/困惑之间存在强烈且可预测的负相关性。这些发现表明需要重新评估 LLM 训练方法，证明了数据对齐与数据量相比的相关性，尤其是在自动形式化等专门的下游任务中。]]></description>
      <guid>https://arxiv.org/abs/2501.08496</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>让 Whisper 适应地区方言：增强英国弱势群体的公共服务</title>
      <link>https://arxiv.org/abs/2501.08502</link>
      <description><![CDATA[arXiv:2501.08502v1 公告类型：新 
摘要：我们在公共服务领域收集新数据，以评估最先进的自动语音识别 (ASR) 模型捕捉英国 (UK) 地区口音差异的能力，特别关注来自苏格兰的两种具有不同方言的口音。这项研究解决了现实世界中的问题，即有偏见的 ASR 模型可能导致公共服务中的沟通不畅，使具有地区口音的个人处于不利地位，特别是那些弱势群体。我们首先在基线数据集和我们的数据上检查 Whisper large-v3 模型的开箱即用性能。然后，我们探讨了微调 Whisper 对英国两个地区性能的影响，并通过手动检查模型错误来研究现有模型评估技术对我们实际应用的有效性。我们观察到，与基线数据相比，Whisper 模型在我们的测试数据集上的字错误率 (WER) 更高，并且对给定数据进行微调可以提高具有相同域和口音的测试数据集的性能。微调后的模型在应用于训练区域之外的测试数据时似乎也表现出更好的性能，这表明微调后的模型可能可以在英国部分地区内转移。我们对模型输出的手动分析揭示了使用 WER 作为评估指标并进行微调以适应区域方言的优缺点。]]></description>
      <guid>https://arxiv.org/abs/2501.08502</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Doc-Guided Sent2Sent++：具有 Doc-Guided 内存的 Sent2Sent++ 代理，用于文档级机器翻译</title>
      <link>https://arxiv.org/abs/2501.08523</link>
      <description><![CDATA[arXiv:2501.08523v1 公告类型：新
摘要：人工智能领域见证了自然语言处理的重大进步，这主要归功于大型语言模型 (LLM) 的功能。这些模型构成了旨在解决长上下文依赖关系的代理的骨干，特别是在文档级机器翻译 (DocMT) 中。DocMT 提出了独特的挑战，质量、一致性和流畅度是评估的关键指标。现有方法（例如 Doc2Doc 和 Doc2Sent）要么省略句子，要么损害流畅度。本文介绍了 Doc-Guided Sent2Sent++，这是一种采用增量句子级强制解码策略 \textbf{以确保每个句子都得到翻译，同时提高相邻句子的流畅度} 的代理。我们的代理利用 Doc-Guided Memory，只关注摘要及其翻译，我们发现这是一种保持一致性的有效方法。通过对多种语言和领域的广泛测试，我们证明了 Sent2Sent++ 在质量、一致性和流畅性方面优于其他方法。结果表明，我们的方法在 s-COMET、d-COMET、LTCR-$1_f$ 和文档级困惑度 (d-ppl) 等指标上取得了显著的改进。本文的贡献包括对当前 DocMT 研究的详细分析、Sent2Sent++ 解码方法的介绍、Doc-Guided Memory 机制以及跨语言和领域的有效性验证。]]></description>
      <guid>https://arxiv.org/abs/2501.08523</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>复杂性控制促进 Transformer 中基于推理的组合泛化</title>
      <link>https://arxiv.org/abs/2501.08537</link>
      <description><![CDATA[arXiv:2501.08537v1 公告类型：新
摘要：Transformers 在各种任务中都表现出了令人印象深刻的能力，但它们在组合问题上的表现仍然是一个争论的主题。在这项研究中，我们研究了 Transformers 在组合任务中行为背后的内部机制。我们发现复杂性控制策略显著影响模型是学习概括分布外的原始级规则（基于推理的解决方案）还是仅依赖于记忆映射（基于记忆的解决方案）。通过将掩蔽策略应用于模型的信息电路并采用多种复杂性指标，我们揭示了与不同解决方案类型相关的不同内部工作机制。进一步的分析表明，基于推理的解决方案表现出较低的复杂性偏差，这与研究充分的神经元凝聚现象一致。这种较低的复杂性偏差被认为是使这些解决方案能够学习推理规则的关键因素。我们在多个现实世界数据集中验证了这些结论，包括图像生成和自然语言处理任务，证实了我们的研究结果的广泛适用性。]]></description>
      <guid>https://arxiv.org/abs/2501.08537</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语义建模的知识提示链</title>
      <link>https://arxiv.org/abs/2501.08540</link>
      <description><![CDATA[arXiv:2501.08540v1 公告类型：新
摘要：为结构化数据（例如 CSV、JSON 和 XML 文件）构建语义的任务在知识表示领域中非常重要。尽管我们在互联网上拥有大量结构化数据，但将它们映射到领域本体以为其构建语义仍然非常具有挑战性，因为它需要构建模型来理解和学习图结构知识。否则，这项任务将需要人类的努力和成本。在本文中，我们提出了一种新颖的自动语义建模框架：知识提示链。它可以序列化图结构知识并将其正确地注入到提示链架构中的 LLM 中。通过这种知识注入和提示链，我们框架中的模型可以学习图的结构信息和潜在空间，并按照链的指令自然地生成语义标签和语义图。根据实验结果，尽管使用的结构化输入数据减少，但我们的方法仍比现有的领先技术取得了更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.08540</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>信息熵不变性：增强注意力机制中的长度外推</title>
      <link>https://arxiv.org/abs/2501.08570</link>
      <description><![CDATA[arXiv:2501.08570v1 公告类型：新
摘要：提高大型语言模型 (LLM) 的长度外推能力仍然是自然语言处理中的一个关键挑战。最近的许多努力都集中在修改缩放的点积注意机制上，并且经常在没有严格的理论依据的情况下引入缩放温度。为了填补这一空白，我们引入了一种基于信息熵不变性的新方法。我们提出了两种新的缩放温度来增强长度外推。首先，一种无需训练的方法 InfoScale 专为点积注意而设计，并通过确保信息熵保持一致来在长度外推期间保持对原始标记的关注。其次，我们从理论上分析了缩放 (CosScale) 对余弦注意的影响。实验数据表明，将 InfoScale 和 CosScale 结合起来可以在上下文窗口扩展到训练长度的 64 倍的 GAU-{\alpha} 模型上实现最先进的性能，并且优于现有的七种方法。我们的分析表明，显著增加 CosScale 可以近似于窗口注意力，并强调注意力分数稀释是处理长距离上下文的关键挑战。代码和数据可在 https://github.com/HT-NEKO/InfoScale 上找到。]]></description>
      <guid>https://arxiv.org/abs/2501.08570</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>什么限制了基于法学硕士 (LLM) 的人体模拟：法学硕士 (LLM) 还是我们的设计？</title>
      <link>https://arxiv.org/abs/2501.08579</link>
      <description><![CDATA[arXiv:2501.08579v1 公告类型：新
摘要：我们认为，推进基于 LLM 的人体模拟需要解决 LLM 固有的局限性和模拟框架设计挑战。最近的研究表明，基于 LLM 的人体模拟与现实世界的观察之间存在显著差距，凸显了这些双重挑战。为了解决这些差距，我们对 LLM 的局限性和我们的设计问题进行了全面分析，并针对这两个方面提出了有针对性的解决方案。此外，我们探索了同时解决这两个挑战的未来方向，特别是在数据收集、LLM 生成和评估方面。为了支持该领域的进一步研究，我们提供了基于 LLM 的人体模拟资源的精选集合。\footnote{https://github.com/Persdre/llm-human-simulation}]]></description>
      <guid>https://arxiv.org/abs/2501.08579</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LoRS：稀疏大型语言模型的高效低秩自适应</title>
      <link>https://arxiv.org/abs/2501.08582</link>
      <description><![CDATA[arXiv:2501.08582v1 公告类型：新
摘要：现有的低秩自适应 (LoRA) 方法在稀疏大型语言模型 (LLM) 上面临挑战，因为无法保持稀疏性。最近的研究引入了通过用额外的掩码机制增强 LoRA 技术来保持稀疏性的方法。尽管取得了这些成功，但这些方法面临着内存和计算开销增加的问题，这影响了 LoRA 方法的效率。为了解决这一限制，我们引入了 LoRS，这是一种创新方法，旨在在微调稀疏 LLM 时实现内存和计算效率。为了减轻与保持稀疏性相关的大量内存和计算需求，我们的方法结合了权重重新计算和计算图重新排列的策略。此外，我们还通过更好的适配器初始化来提高 LoRS 的有效性。这些创新导致微调阶段的内存和计算消耗显着减少，同时实现了优于现有 LoRA 方法的性能水平。]]></description>
      <guid>https://arxiv.org/abs/2501.08582</guid>
      <pubDate>Thu, 16 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>