<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 09 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>社会情感反应生成：基于 LLM 的对话系统的人工评估协议</title>
      <link>https://arxiv.org/abs/2412.04492</link>
      <description><![CDATA[arXiv:2412.04492v1 公告类型：新
摘要：对话系统现在能够产生令人印象深刻且通常相关的响应。然而，我们无法看到或控制最先进的大型语言模型 (LLM) 背后的社会情感策略，这在它们的透明度方面存在问题，因此对关键应用的可信度也存在问题。另一个问题是，当前的自动化指标无法正确评估生成的响应的质量，超出数据集的基本事实。在本文中，我们提出了一种神经架构，其中包括在响应生成之前规划社会情感策略的中间步骤。我们将开源基线 LLM 的性能与这些相同模型的输出进行比较，这些模型增强了我们的规划模块。我们还对比了从自动指标获得的输出和人工注释者提供的评估结果。我们描述了一种新颖的评估协议，其中包括粗粒度一致性评估，以及对各种社交和情感标准的响应的更细粒度注释。我们的研究表明，预测一系列预期策略标签并使用该序列生成响应比直接端到端生成方案产生更好的结果。它还强调了当前生成内容评估指标的分歧和局限性。注释平台的代码和注释数据已公开，以供评估未来的模型。]]></description>
      <guid>https://arxiv.org/abs/2412.04492</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MAG-V：用于合成数据生成和验证的多智能体框架</title>
      <link>https://arxiv.org/abs/2412.04494</link>
      <description><![CDATA[arXiv:2412.04494v1 公告类型：新 
摘要：使用与环境交互的函数或工具扩展大型语言模型 (LLM) 的功能导致了代理范式的出现。在行业中，由于领域数据的稀缺、专有客户数据的法律保留、业务需求的快速变化以及新助手原型的需要，训练 LLM 并不总是可行的。代理通过依赖底层 LLM 的零样本推理能力并利用工具探索和推理客户数据并响应用户请求，为上述问题提供了一个优雅的解决方案。然而，这里有两个问题：(I) 获取大规模客户查询进行代理测试非常耗时，(II) 高度依赖代理响应用户查询所遵循的工具调用序列（或轨迹）可能会导致意外或不正确的行为。为了解决这个问题，我们提出了 MAG-V，这是一个多代理框架，首先生成一个模拟客户查询的问题数据集；第二，从响应中逆向设计替代问题以进行轨迹验证。初步结果表明，我们的合成数据可以提高代理在实际客户查询方面的表现。此外，我们的轨迹验证方法受到远程监督的启发，并使用传统的机器学习 (ML) 模型，其准确率比 GPT-4o 评判基线高出 11%，并且与 GPT-4 评判员在我们构建的数据集上的表现相匹配。总的来说，我们的方法是朝着将不同的任务代理统一到一个有凝聚力的框架中以实现一致目标迈出的一步。]]></description>
      <guid>https://arxiv.org/abs/2412.04494</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型为人文学科研究中的低资源语言带来的机遇与挑战</title>
      <link>https://arxiv.org/abs/2412.04497</link>
      <description><![CDATA[arXiv:2412.04497v1 公告类型：新
摘要：低资源语言是人类历史的宝贵宝库，体现了文化进化和智力多样性。尽管这些语言意义重大，但它们面临着严峻的挑战，包括数据稀缺和技术限制，这阻碍了对它们的全面研究和保存。大型语言模型 (LLM) 的最新进展为应对这些挑战提供了变革性的机会，使语言、历史和文化研究的创新方法成为可能。本研究系统地评估了 LLM 在低资源语言研究中的应用，涵盖了语言变异、历史文献、文化表达和文学分析。通过分析技术框架、当前方法和道德考虑，本文确定了数据可访问性、模型适应性和文化敏感性等关键挑战。鉴于低资源语言固有的文化、历史和语言丰富性，这项工作强调跨学科合作和定制模型的开发是推动该领域研究的有希望的途径。通过强调人工智能与人文学科相结合以保护和研究人类语言和文化遗产的潜力，这项研究促进了全球维护思想多样性的努力。]]></description>
      <guid>https://arxiv.org/abs/2412.04497</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>政治与民主中的大型语言模型：综合调查</title>
      <link>https://arxiv.org/abs/2412.04498</link>
      <description><![CDATA[arXiv:2412.04498v1 公告类型：新
摘要：生成式人工智能的进步，特别是大型语言模型 (LLM)，对政治和民主产生了重大影响，在政策制定、政治交流、分析和治理等各个领域都有潜力。本文调查了 LLM 在政治领域的近期和潜在应用，研究了它们的前景和相关挑战。本文探讨了 LLM 在立法进程、政治交流和政治分析中的应用方式。此外，我们还研究了 LLM 在外交和国家安全背景、经济和社会建模以及法律应用中的潜力。虽然 LLM 提供了提高政治进程效率、包容性和决策能力的机会，但它们也带来了与偏见、透明度和问责制相关的挑战。本文强调了负责任的发展、道德考虑和治理框架的必要性，以确保 LLM 融入政治符合民主价值观并促进更加公正和公平的社会。]]></description>
      <guid>https://arxiv.org/abs/2412.04498</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型及其局限性简介</title>
      <link>https://arxiv.org/abs/2412.04503</link>
      <description><![CDATA[arXiv:2412.04503v1 公告类型：新
摘要：本文提供了大型语言模型 (LLM) 的入门知识，并确定了它们的优势、局限性、应用和研究方向。它旨在为学术界和工业界那些有兴趣了解关键 LLM 概念和技术的人提供帮助，并在日常任务和更复杂的场景中利用这些知识，这些技术可以增强当前的实践和流程。]]></description>
      <guid>https://arxiv.org/abs/2412.04503</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多箱批处理可提高 LLM 推理吞吐量</title>
      <link>https://arxiv.org/abs/2412.04504</link>
      <description><![CDATA[arXiv:2412.04504v1 公告类型：新
摘要：随着大型语言模型 (LLM) 因其多样化功能而越来越受欢迎，提高其推理系统的效率变得越来越重要。批处理 LLM 请求是调度服务器（例如 GPU）上的推理作业的关键步骤，使系统能够通过允许并行处理多个请求来最大化吞吐量。但是，请求通常具有不同的生成长度，导致资源利用不足，因为硬件必须等待批次中运行时间最长的请求完成后才能转到下一个批次。我们从排队论的角度形式化了这个问题，并旨在设计一种吞吐量最优的控制策略。我们提出了多箱批处理，这是一种简单而有效的方法，可以通过将具有相似（预测）执行时间的请求分组到预定的箱中来证明可以提高 LLM 推理吞吐量。通过理论分析和实验的结合，包括现实世界的 LLM 推理场景，我们证明了与标准批处理方法相比显着的吞吐量提升。]]></description>
      <guid>https://arxiv.org/abs/2412.04504</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用 BERT 实现语义一致性：预训练语义表征模型在社会科学研究中的应用</title>
      <link>https://arxiv.org/abs/2412.04505</link>
      <description><![CDATA[arXiv:2412.04505v1 公告类型：新
摘要：在社会科学研究和文本分析任务中，实现不同时间跨度的一致词语解释至关重要，因为稳定的语义表示是研究和任务正确性的基础，可增强对社会政治和文化分析的理解。Word2Vec 等传统模型已经提供了对长期语义变化的重要见解，但通常难以在短期上下文中捕捉到稳定的含义，这可能归因于训练数据不平衡导致的嵌入波动。最近的进展，特别是 BERT（来自 Transformers 的双向编码器表示），其预训练性质和 Transformer 编码器架构提供了可提高语义一致性的上下文嵌入，使其成为短期分析的有前途的工具。本研究实证比较了 Word2Vec 和 BERT 在与社会科学研究相关的文本分析任务中随时间保持稳定词义的表现。我们使用《人民日报》 20 年（2004-2023 年）的文章，评估了每个模型在不同时间范围内的语义稳定性。结果表明，BERT 在保持语义稳定性方面始终优于 Word2Vec，在上下文嵌入中提供了更高的稳定性。然而，该研究也承认，由于 BERT 固有的稳定性，它在捕捉较长时期内逐渐发生的语义变化方面存在局限性。研究结果表明，虽然 BERT 有利于社会科学中的短期语义分析，但研究人员应该考虑在长期研究中采用互补方法，以充分捕捉语义漂移。这项研究强调了根据社会科学分析的特定时间背景选择合适的词嵌入模型的重要性。]]></description>
      <guid>https://arxiv.org/abs/2412.04505</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Arctic-Embed 2.0：毫不妥协的多语言检索</title>
      <link>https://arxiv.org/abs/2412.04506</link>
      <description><![CDATA[arXiv:2412.04506v1 公告类型：新
摘要：本文介绍了 Arctic-Embed 2.0 的训练方法，这是一组开源文本嵌入模型，旨在实现准确、高效的多语言检索。虽然之前的作品遭受了英语检索质量下降的影响，但 Arctic-Embed 2.0 在多语言和纯英语基准上提供了具有竞争力的检索质量，并支持 Matryoshka 表示学习 (MRL) 以实现高效的嵌入存储，与其他方法相比，压缩质量下降幅度明显较小。我们详细介绍了设计和实施，并提出了模型开发过程中出现的几个重要的开放性研究问题。我们进行了探索这些研究问题的实验，并进行了广泛的讨论，旨在促进该领域的进一步讨论。]]></description>
      <guid>https://arxiv.org/abs/2412.04506</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实用元认知提示可提高法学硕士在讽刺检测方面的表现</title>
      <link>https://arxiv.org/abs/2412.04509</link>
      <description><![CDATA[arXiv:2412.04509v1 公告类型：新
摘要：由于措辞的细微差别和上下文依赖性，讽刺检测是情绪分析中的一项重大挑战。我们引入了语用元认知提示 (PMP) 来提高大型语言模型 (LLM) 在讽刺检测中的表现，它利用语用学和反思的原理帮助 LLM 解释隐含的含义、考虑上下文线索并反思差异以识别讽刺。使用最先进的 LLM，例如 LLaMA-3-8B、GPT-4o 和 Claude 3.5 Sonnet，PMP 在 MUStARD 和 SemEval2018 上的 GPT-4o 上实现了最先进的性能。这项研究表明，将实用推理和元认知策略融入提示中可显著提高法学硕士检测讽刺的能力，为未来的情绪分析研究提供了一个有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2412.04509</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推动大型语言模型用于临床时间关系提取</title>
      <link>https://arxiv.org/abs/2412.04512</link>
      <description><![CDATA[arXiv:2412.04512v1 公告类型：新
摘要：目标：本文旨在提示大型语言模型 (LLM) 在少样本和全监督设置中进行临床时间关系提取 (CTRE)。材料和方法：本研究使用四个 LLM：基于编码器的 GatorTron-Base (345M)/Large (8.9B)；基于解码器的 LLaMA3-8B/MeLLaMA-13B。我们开发了完整 (FFT) 和参数高效 (PEFT) 微调策略，并在 2012 i2b2 CTRE 任务上评估了这些策略。我们探索了 GatorTron-Base 的四种微调策略：(1) 标准微调，(2) 使用未冻结的 LLM 进行硬提示，(3) 使用冻结的 LLM 进行软提示，以及 (4) 使用冻结的 LLM 进行低秩自适应 (LoRA)。对于 GatorTron-Large，我们评估了两种利用量化技术的 PEFT 策略——软提示和带有冻结 LLM 的 LoRA。此外，LLaMA3-8B 和 MeLLaMA-13B 采用了两种 PEFT 策略：将带有量化的 LoRA 策略 (QLoRA) 应用于使用指令调整和标准微调的冻结 LLM。结果：在完全监督的设置下，带有未冻结 GatorTron-Base 的硬提示获得了最高的 F1 分数 (89.54%)，比 SOTA 模型 (85.70%) 高出 3.74%。此外，适用于 GatorTron-Large 的两种 QLoRA 变体和 GatorTron-Base 的标准微调分别比 SOTA 模型高出 2.36%、1.88% 和 0.25%。在这种设置下，具有冻结参数的基于解码器的模型优于基于编码器的模型；然而，在少样本场景中，趋势发生了逆转。讨论和结论：本研究提出了新方法，显著提高了 CTRE 性能，使依赖 CTRE 系统的下游任务受益。研究结果强调了根据任务要求和数据可用性选择合适模型和微调策略的重要性。未来的工作将探索更大的模型和更广泛的 CTRE 应用。]]></description>
      <guid>https://arxiv.org/abs/2412.04512</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>理解思维链推理中的隐藏计算</title>
      <link>https://arxiv.org/abs/2412.04537</link>
      <description><![CDATA[arXiv:2412.04537v1 公告类型：新
摘要：思路链 (CoT) 提示显著增强了大型语言模型的推理能力。然而，最近的研究表明，即使用填充（隐藏）字符（例如“...”）替换 CoT，模型仍然可以执行复杂的推理任务，这留下了模型如何在内部处理和表示推理步骤的问题。在本文中，我们研究了在使用填充 CoT 序列训练的 Transformer 模型中解码这些隐藏字符的方法。通过使用 logit lens 方法分析分层表示并检查 token 排名，我们证明了隐藏字符可以在不损失性能的情况下恢复。我们的研究结果为 Transformer 模型的内部机制提供了见解，并为提高语言模型推理的可解释性和透明度开辟了途径。]]></description>
      <guid>https://arxiv.org/abs/2412.04537</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>给我一些难题：临床 QA 的合成数据生成</title>
      <link>https://arxiv.org/abs/2412.04573</link>
      <description><![CDATA[arXiv:2412.04573v1 公告类型：新
摘要：临床问答 (QA) 系统使医生能够快速从电子健康记录 (EHR) 中访问患者信息。但是，训练这些系统需要大量带注释的数据，由于所需的专业知识和与临床数据相关的隐私问题，这些数据受到限制。本文探讨了在零样本设置中使用大型语言模型 (LLM) 生成临床 QA 数据。我们发现，幼稚的提示通常会导致简单的问题，而这些问题不能反映临床场景的复杂性。为了解决这个问题，我们提出了两种提示策略：1) 指示模型生成与输入上下文不重叠的问题，2) 使用预定义的模式总结输入记录以支持问题生成。在两个临床 QA 数据集上进行的实验表明，我们的方法生成了更具挑战性的问题，与基线相比显着提高了微调性能。我们比较了合成数据和黄金数据，发现它们的训练效果之间存在差距，这是由合成生成的答案的质量造成的。]]></description>
      <guid>https://arxiv.org/abs/2412.04573</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>展现而非诉说：利用法学硕士 (LLM) 揭示隐性人物刻画</title>
      <link>https://arxiv.org/abs/2412.04576</link>
      <description><![CDATA[arXiv:2412.04576v1 公告类型：新
摘要：分析小说中人物形象的工具对于作家和文学学者开发和解读引人入胜的故事很有价值。现有的工具，例如用于分析虚构人物的可视化工具，主要依赖于人物属性的明确文本指标。然而，人物形象往往是隐性的，通过动作和行为而不是明确的陈述来揭示。我们通过利用大型语言模型 (LLM) 来揭示隐含的人物形象来解决这一差距。我们首先为这项任务生成一个数据集，该数据集具有比现有叙事文本语料库（如 TinyStories 和 WritingPrompts）更大的跨主题相似性、词汇多样性和叙事长度。然后我们介绍 LIIPA（用于推断人物分析的隐性描绘的 LLM），这是一个提示 LLM 揭示人物形象的框架。LIIPA 可以配置为使用各种类型的中间计算（人物属性单词列表、思路链）来推断虚构人物在源文本中的形象。我们发现 LIIPA 的表现优于现有方法，并且由于能够利用完整的叙事背景，因此在增加人物数量（描绘的独特人物数量）时更加稳健。最后，我们研究了人物刻画估计对人物人口统计的敏感性，确定了 LIIPA 框架中方法之间的公平性-准确性权衡——这是算法公平性文献中常见的现象。尽管存在这种权衡，但所有 LIIPA 变体在公平性和准确性方面均始终优于非 LLM 基线。我们的工作展示了使用 LLM 分析复杂人物以及更好地理解隐性刻画偏见如何体现在叙事文本中的潜在好处。]]></description>
      <guid>https://arxiv.org/abs/2412.04576</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有精细条件的概率论问题的表述</title>
      <link>https://arxiv.org/abs/2412.04602</link>
      <description><![CDATA[arXiv:2412.04602v1 公告类型：新
摘要：概率论问题被证明是学生面临的最具挑战性的问题之一。在这里，我们制定并讨论了概率论中的四个相关问题，这些问题对于母语不是英语的一到四年级本科生来说很难。这些例子强调了在开始解决问题之前准确理解问题的条件和要求是多么重要。我们详细讨论了这些问题的解决方案，用数值估计对其进行了补充，并将问题中的条件与 Python 编程语言中的逻辑语句联系起来。我们还测试了两个广泛使用的聊天机器人（GPT-4o 和 Claude 3.5 Sonnet），检查了它们对这些问题的回答。]]></description>
      <guid>https://arxiv.org/abs/2412.04602</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM-Align：利用大型语言模型进行知识图谱中的实体对齐</title>
      <link>https://arxiv.org/abs/2412.04690</link>
      <description><![CDATA[arXiv:2412.04690v1 公告类型：新 
摘要：实体对齐（EA）旨在识别和匹配不同知识图谱（KG）中的相应实体，在知识融合和集成中起着至关重要的作用。基于嵌入的实体对齐（EA）最近引起了广泛关注，导致许多创新方法的出现。最初，这些方法集中于基于关系三元组定义的知识图谱（KG）的结构特征学习实体嵌入。后续方法将实体的名称和属性作为补充信息进行集成，以改进用于 EA 的嵌入。然而，现有的方法缺乏对实体属性和关系的深度语义理解。在本文中，我们提出了一种基于大型语言模型（LLM）的实体对齐方法 LLM-Align，它探索大型语言模型的指令跟踪和零样本能力来推断实体的对齐。 LLM-Align 使用启发式方法选择实体的重要属性和关系，然后将选定的实体三元组输入到 LLM 以推断对齐结果。为了保证对齐结果的质量，我们设计了一种多轮投票机制来缓解 LLM 中出现的幻觉和位置偏差问题。在三个 EA 数据集上进行的实验表明，与现有的 EA 方法相比，我们的方法实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.04690</guid>
      <pubDate>Mon, 09 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>