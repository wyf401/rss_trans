<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 31 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>GaLore$+$：使用 Cross-Head Projection 提升 LLM 的低秩适应性</title>
      <link>https://arxiv.org/abs/2412.19820</link>
      <description><![CDATA[arXiv:2412.19820v1 公告类型：新
摘要：最近的低秩训练方法，例如 GaLore，已显着减少了优化大型语言模型 (LLM) 所需的内存。然而，这些方法通常会受到耗时的低秩投影估计的影响。特别是，GaLore 中的奇异值分解 (SVD) 会消耗超过 80% 的总训练时间。为了解决这个问题，我们提出了 GaLore$+$，它使用跨头低秩投影来减少估计多头注意力低秩投影的大量时间消耗。此外，我们采用随机子空间迭代来实现快速 SVD。为了进一步提高性能，我们提出了稀疏编码残差来减少由优化器一阶和二阶矩和权重更新上的低秩近似引起的误差。我们在算术推理和自然语言生成数据集上评估了 GaLore$+$。我们的实验表明，与 vanilla GaLore 相比，GaLore$+$ 具有更优异的性能，同时实现了大约 $4\times$ 倍的微调速度。]]></description>
      <guid>https://arxiv.org/abs/2412.19820</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估细粒度摘要：使用 LLM 自动评估</title>
      <link>https://arxiv.org/abs/2412.19906</link>
      <description><![CDATA[arXiv:2412.19906v1 公告类型：新
摘要：由于信息的指数级增长和对高效信息消费的需求，摘要任务变得至关重要。准确客观地评估摘要提出了重大挑战，特别是在处理内容丰富的长篇非结构化文本时。现有方法，如 ROUGE（Lin，2004）和嵌入相似性，通常得出的分数与人类判断的相关性较低，并且直观上也难以理解，因此很难衡量摘要的真实质量。LLM 可以模仿人类给出主观评价，但主观分数很难解释和证明。它们可以通过改变模型和提示的语气轻松操纵。在本文中，我们介绍了一种新颖的评估方法和工具，旨在应对这些挑战，为摘要输出提供更全面、准确和可解释的评估。我们的方法 (SumAutoEval) 提出并评估了不同粒度级别的指标，对完整性、正确性、对齐和可读性等 4 个关键维度给出了客观分数。我们通过实证证明，SumAutoEval 能够通过更好的人为相关性增强对输出质量的理解。]]></description>
      <guid>https://arxiv.org/abs/2412.19906</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HADES：用于大型语言模型中高效推测的硬件加速解码</title>
      <link>https://arxiv.org/abs/2412.19925</link>
      <description><![CDATA[arXiv:2412.19925v1 公告类型：新
摘要：大型语言模型 (LLM) 通过理解和生成类似人类的文本彻底改变了自然语言处理。然而，对更复杂的 LLM 的需求日益增加，由于其规模和复杂性，带来了巨大的计算挑战。本文介绍了硬件加速解码 (HADES)，这是一种提高 LLM 性能和能效的新方法。我们解决了具有硬件级推测解码支持的 LLM 加速器的设计，这是现有文献中以前未探讨过的概念。我们的工作展示了推测解码如何显著提高 LLM 操作的效率，为这些模型更先进和更实际的应用铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2412.19925</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>正确与正确：法学硕士 (LLM) 可以做出艰难的选择吗？</title>
      <link>https://arxiv.org/abs/2412.19926</link>
      <description><![CDATA[arXiv:2412.19926v1 公告类型：新
摘要：道德困境描述了在涉及相互冲突的道德价值观的两个“正确”选项之间的选择。我们对 LLM 如何应对道德困境进行了全面的评估。具体来说，我们调查了 LLM 的 (1) 理解道德困境的敏感性、(2) 道德价值选择的一致性、(3) 对后果的考虑，以及 (4) 使其反应与提示中明确或隐含指定的道德价值偏好保持一致的能力。从领先的道德框架中汲取灵感，我们构建了一个数据集，其中包含 1,730 个涉及四对相互冲突的价值观的道德困境。我们评估了来自六个家族的 20 位知名 LLM。我们的实验表明：(1) LLM 在主要价值观对之间表现出明显的偏好，并且优先考虑真相而不是忠诚、社区而不是个人、长期考虑而不是短期考虑。(2) 较大的 LLM 倾向于支持义务论观点，即使指定了负面后果，他们也会保持其行动选择。 (3) 明确的指导方针比情境中的例子更能有效地指导法学硕士的道德选择。最后，我们的实验凸显了法学硕士在理解不同形式的道德困境方面的局限性。]]></description>
      <guid>https://arxiv.org/abs/2412.19926</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估社交媒体平台上网络欺凌检测的文本分类方法</title>
      <link>https://arxiv.org/abs/2412.19928</link>
      <description><![CDATA[arXiv:2412.19928v1 公告类型：新
摘要：网络欺凌对受害者的心理产生负面影响，严重加剧了社区的心理健康问题。这是社交媒体平台上普遍存在的问题，需要有效的实时检测和监控系统来识别有害信息。然而，当前的网络欺凌检测系统面临着与性能、数据集质量、时间效率和计算成本相关的挑战。本研究旨在通过调整和评估网络欺凌检测领域中现有的文本分类技术进行比较研究。该研究专门评估了这些技术在识别社交媒体平台上的网络欺凌实例方面的有效性和性能。它专注于利用和评估大型语言模型，包括 BERT、RoBERTa、XLNet、DistilBERT 和 GPT-2.0，以确定它们是否适用于该领域。结果表明，BERT 在性能、时间效率和计算资源之间取得了平衡：准确率为 95%，精确率为 95%，召回率为 95%，F1 得分为 95%，错误率为 5%，推理时间为 0.053 秒，RAM 使用率为 35.28 MB，CPU/GPU 使用率为 0.4%，能耗为 0.000263 kWh。研究结果表明，生成式 AI 模型虽然功能强大，但在测试基准上的表现并不总是优于微调模型。然而，通过针对特定数据集和任务对现有模型进行战略性调整和微调，仍然可以实现最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.19928</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>弥合语境差距：通过语境摘录增强长篇社交对话的理解力</title>
      <link>https://arxiv.org/abs/2412.19966</link>
      <description><![CDATA[arXiv:2412.19966v1 公告类型：新
摘要：我们专注于提高小组录音对话的理解力，这些对话是将人们聚集在一起的媒介，并提供分享有关重要社会问题的个人故事和经历的空间。解析和传达这些对话信息的一种方法是在后续对话中分享突出显示的摘录。这可以帮助促进对相关问题的集体理解，通过向其他可能不熟悉并因此无法理解这些经历的人群强调观点和经验。然后出现的主要挑战是，从一次对话中摘录并在另一个环境中分享的摘录可能缺少关键背景或先前在原始对话中引入的关键元素。当对话变得更长、主题和共享体验更丰富时，这个问题会加剧。为了解决这个问题，我们探索了大型语言模型 (LLM) 如何通过提供社会相关背景来丰富这些摘录。我们提出了有效的语境化方法，以提高理解力、可读性和同理心。通过主观和客观评估，我们发现理解力有显著提高。虽然 LLM 可以提供有价值的背景，但它们很难捕捉到关键的社会方面。我们发布了人工注释的突出摘录 (HSE) 数据集以支持未来的工作。此外，我们还展示了语境丰富的摘录如何提供更有针对性和更全面的对话摘要。]]></description>
      <guid>https://arxiv.org/abs/2412.19966</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OneKE：基于 Docker 架构引导的 LLM 代理知识提取系统</title>
      <link>https://arxiv.org/abs/2412.20005</link>
      <description><![CDATA[arXiv:2412.20005v1 公告类型：新
摘要：我们介绍了 OneKE，一个基于 Docker 的模式引导知识提取系统，它可以从 Web 和原始 PDF 书籍中提取知识，并支持各种领域（科学、新闻等）。具体来说，我们设计了具有多个代理和一个配置知识库的 OneKE。不同的代理执行各自的角色，从而支持各种提取场景。配置知识库有助于模式配置、错误案例调试和更正，从而进一步提高性能。基准数据集上的经验评估证明了 OneKE 的有效性，而案例研究进一步阐明了它对跨多个领域的各种任务的适应性，突出了其广泛应用的潜力。我们已经在 https://github.com/zjunlp/OneKE 上开源了代码，并在 http://oneke.openkg.cn/demo.mp4 上发布了视频。]]></description>
      <guid>https://arxiv.org/abs/2412.20005</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>STAYKATE：结合代表性抽样和基于检索的方法的混合上下文示例选择——科学领域的案例研究</title>
      <link>https://arxiv.org/abs/2412.20043</link>
      <description><![CDATA[arXiv:2412.20043v1 公告类型：新
摘要：大型语言模型 (LLM) 展示了在上下文中学习的能力，为科学信息提取提供了一种潜在的解决方案，而科学信息提取通常面临着诸如训练数据不足和注释过程成本高昂等挑战。鉴于上下文示例的选择会显著影响性能，设计一种适当的方法来对有效示例进行采样至关重要。在本文中，我们提出了 STAYKATE，这是一种静态-动态混合选择方法，它将主动学习的代表性采样原理与流行的基于检索的方法相结合。三个领域特定数据集的结果表明，STAYKATE 优于传统的监督方法和现有的选择方法。对于其他方法构成挑战的实体类型，性能的提升尤为明显。]]></description>
      <guid>https://arxiv.org/abs/2412.20043</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>“我的生活很悲惨，每天要签名500次”：揭露谦虚自夸、伪装自夸的人</title>
      <link>https://arxiv.org/abs/2412.20057</link>
      <description><![CDATA[arXiv:2412.20057v1 公告类型：新
摘要：谦虚自夸是一种现象，即个人以谦虚或抱怨为幌子进行自我宣传。例如，像“呃，我不敢相信我被提拔为整个团队的领导。压力太大了！”这样的陈述，在假装抱怨的同时巧妙地强调了一项成就。检测谦虚自夸对于机器更好地理解人类语言的细微差别非常重要，尤其是在情绪分析和意图识别等任务中。然而，计算语言学中还没有研究过这个话题。我们首次引入了自动检测文本中谦虚自夸的任务。我们通过提出谦虚自夸的 4 元组定义来形式化该任务，并评估机器学习、深度学习和大型语言模型 (LLM) 在这个任务上的表现，比较它们与人类的表现。我们还创建并发布了一个名为 HB24 的数据集，其中包含使用 GPT-4o 生成的 3,340 个谦虚自夸。我们的实验表明，检测谦虚自夸并非易事，即使对于人类来说也是如此。我们最好的模型实现了 0.88 的 F1 分数。这项工作为进一步探索这种微妙的语言现象及其融入更广泛的自然语言理解系统奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2412.20057</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有限资源语言环境中使用大型语言模型进行列表重排序的比较分析</title>
      <link>https://arxiv.org/abs/2412.20061</link>
      <description><![CDATA[arXiv:2412.20061v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种 NLP 任务（包括文本排名）中都表现出显著的有效性。本研究评估了大型语言模型 (LLM) 在资源有限的非洲语言列表重新排名中的表现。我们在跨语言环境中比较了专有模型 RankGPT3.5、Rank4o-mini、RankGPTo1-mini 和 RankClaude-sonnet。结果表明，这些 LLM 在大多数评估指标中都明显优于传统基线方法（如 BM25-DT），尤其是在 nDCG@10 和 MRR@100 中。这些发现凸显了 LLM 在增强资源匮乏语言的重新排名任务方面的潜力，并提供了具有成本效益的解决方案的见解。]]></description>
      <guid>https://arxiv.org/abs/2412.20061</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用 LLM 从混合长文档中提取信息：框架和数据集</title>
      <link>https://arxiv.org/abs/2412.20072</link>
      <description><![CDATA[arXiv:2412.20072v1 公告类型：新
摘要：大型语言模型（LLM）在文本理解和表格推理任务中表现出色。然而，它们理解和分析包含文本和表格数据的混合文本的能力仍未被探索。混合文本通常以混合长文档（HLD）的形式出现，远远超出了LLM的标记限制。因此，我们应用自动信息提取框架（AIE）使LLM能够处理HLD，并进行实验以分析从HLD中提取信息的四个重要方面。给出了以下发现：1）选择和总结HLD有用部分的有效方法。2）简单的表格序列化方法足以让LLM理解表格。3）朴素的AIE在许多复杂场景中具有适应性。4）有用的提示工程可以增强HLD上的LLM。为了解决 HLD 中数据集稀缺的问题并支持未来的工作，我们还提出了财务报告数值提取 (FINE) 数据集。数据集和代码在附件中公开提供。]]></description>
      <guid>https://arxiv.org/abs/2412.20072</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>M-MAD：用于细粒度机器翻译评估的多维多智能体辩论框架</title>
      <link>https://arxiv.org/abs/2412.20127</link>
      <description><![CDATA[arXiv:2412.20127v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展催生了 LLM-as-a-judge 范式，展示了它们提供类似人类判断的潜力。然而，在机器翻译 (MT) 评估领域，当前的 LLM-as-a-judge 方法缺乏学习自动指标。在本文中，我们提出了多维多智能体辩论 (M-MAD)，这是一个基于 LLM 的系统多智能体框架，用于高级 LLM-as-a-judge MT 评估。我们的研究结果表明，M-MAD 通过 (1) 将启发式 MQM 标准解耦为不同的评估维度以进行细粒度评估；(2) 采用多智能体辩论来利用 LLM 的协作推理能力；(3) 将特定维度的结果综合到最终评估判断中，以确保结果稳健可靠，从而取得了重大进展。综合实验表明，M-MAD 不仅优于所有现有的 LLM-as-a-judge 方法，而且即使在使用 GPT-4o mini 等次优模型时，也能与最先进的基于参考的自动度量相媲美。详细的消融和分析凸显了我们框架设计的优越性，为 LLM-as-a-judge 范式提供了全新的视角。我们的代码和数据可在 https://github.com/SU-JIAYUAN/M-MAD 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2412.20127</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>复杂表格问答中在线规划的高效多智能体协作与工具使用</title>
      <link>https://arxiv.org/abs/2412.20145</link>
      <description><![CDATA[arXiv:2412.20145v1 公告类型：新
摘要：复杂表格问答 (TQA) 旨在回答需要复杂推理的问题，例如多步骤或多类别推理，以表格形式表示的数据。以前的方法通过利用闭源大型语言模型 (LLM) 或微调的开放权重 LLM 表现出显着的性能。然而，微调 LLM 需要高质量的训练数据，而这些数据的获取成本很高，并且使用闭源 LLM 会带来可访问性挑战并导致可重复性问题。在本文中，我们提出了使用工具的多智能体协作 (MACT)，这是一个既不需要闭源模型也不需要微调的框架。在 MACT 中，规划代理和编码代理也利用工具协作回答问题。我们对四个 TQA 基准进行的实验表明，MACT 在四个基准中的三个上都优于以前的 SoTA 系统，并且在两个基准上，它的表现与更大、更昂贵的闭源模型 GPT-4 相当，即使只使用开放权重模型而没有任何微调。我们进行了广泛的分析，以证明 MACT 在 TQA 中的多智能体协作的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.20145</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>建立丰富的数据集以增强波斯语问答系统</title>
      <link>https://arxiv.org/abs/2412.20212</link>
      <description><![CDATA[arXiv:2412.20212v1 公告类型：新
摘要：问答系统为问题提供简短、精确和具体的答案。到目前为止，已经为英语开发了许多强大的问答系统，而一些资源较少的语言，如波斯语，则只有少量的标准数据集。在本研究中，为波斯语提供了一个全面的开放域数据集。这个数据集被称为 NextQuAD，有 7,515 个上下文，包括 23,918 个问题和答案。然后，使用两个预训练的语言模型（包括 ParsBERT 和 XLM-RoBERTa），将基于 BERT 的问答模型应用于该数据集。这两个模型的结果已使用平均 logits 进行集成。在开发集上的评估显示精确匹配 (EM) 为 0.95，Fl_score 为 0.97。此外，为了将 NextQuAD 与其他波斯语数据集进行比较，我们在 NextQuAD 上训练的模型在另外两个数据集 PersianQA 和 ParSQuAD 上进行了评估。比较结果表明，所提出的模型在 PersianQA 和 ParSQuAD-manual 中分别将 EM 提高了 0.39 和 0.14，而在 ParSQuAD-automatic 中 EM 略有下降，为 0.007。]]></description>
      <guid>https://arxiv.org/abs/2412.20212</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解码情绪：自述抑郁症患者的言语感知模式</title>
      <link>https://arxiv.org/abs/2412.20213</link>
      <description><![CDATA[arXiv:2412.20213v1 公告类型：新
摘要：本研究考察了印度人群中自我报告的抑郁症与情感言语感知之间的关系。PANAS 和 PHQ-9 分别用于评估当前情绪和抑郁。参与者的情绪反应以效价和唤醒量表的形式记录下来，以反映连续呈现的情感语音音频。除了描述中性情绪的音频文件外，抑郁症组和非抑郁症组在任何情绪刺激方面均无显著差异。抑郁症组的 PANAS 分数明显高于非抑郁症组，这表明预先倾向的情绪对当前情绪状态有影响。与先前的研究结果相反，本研究并未观察到抑郁症组的积极情绪反应减少。然而，结果表明，在所有情绪感知测量中，对描绘悲伤和愤怒的言语刺激的情绪反应是一致的。]]></description>
      <guid>https://arxiv.org/abs/2412.20213</guid>
      <pubDate>Tue, 31 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>