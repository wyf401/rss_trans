<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 21 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>大型语言模型存在偏见，因为它们是大型语言模型</title>
      <link>https://arxiv.org/abs/2406.13138</link>
      <description><![CDATA[arXiv:2406.13138v1 公告类型：新
摘要：本文的主要目标是引发关于偏见与大型语言模型基本属性之间关系的深思熟虑的讨论。我们通过试图让读者相信有害偏见是任何大型语言模型设计不可避免的结果来实现这一点，因为 LLM 目前就是如此。如果这是真的，这表明，如果不认真重新考虑由 LLM 驱动的人工智能，回到其设计背后的基本假设，就无法妥善解决有害偏见的问题。]]></description>
      <guid>https://arxiv.org/abs/2406.13138</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>DialSim：用于评估对话代理的长期对话理解的实时模拟器</title>
      <link>https://arxiv.org/abs/2406.13144</link>
      <description><![CDATA[arXiv:2406.13144v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展显著增强了对话代理的能力，使其适用于各个领域（例如教育）。尽管取得了进展，但对代理的评估往往忽略了现实世界对话的复杂性，例如实时交互、多方对话和扩展的上下文依赖性。为了弥补这一差距，我们引入了实时对话模拟器 DialSim。在这个模拟器中，代理被分配了热门电视节目中角色的角色，要求它使用过去的对话信息回答自发问题并区分已知和未知信息。DialSim 的主要功能包括评估代理在合理时间限制内响应的能力、处理长期多方对话以及管理对抗设置（例如交换角色名称）以挑战代理对预训练知识的依赖。我们利用这个模拟器评估了最新的对话代理并分析了它们的局限性。我们的实验突出了这些代理的优点和缺点，为未来对话式人工智能领域的改进提供了宝贵的见解。DialSim 可在 https://github.com/jiho283/Simulator 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.13144</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>当部分大于总和时：单个 LLM 组件的表现可以胜过完整模型</title>
      <link>https://arxiv.org/abs/2406.13131</link>
      <description><![CDATA[arXiv:2406.13131v1 公告类型：新
摘要：本文通过将大型语言模型的输出分解为注意力头和 MLP（组件）的个体贡献来研究上下文学习 (ICL)。我们观察到一些奇怪的组件：表现良好的组件，即使模型表现不佳，它们在分类任务上也能单独表现良好；表现不佳的组件，表现比偶然性差得多；标签偏差的组件总是预测相同的标签。我们发现，即使全模型准确度差异很大，组件准确度在不同的演示集和提示模板的扰动之间也是高度相关的。根据我们的发现，我们提出了组件重新加权，它学习从一些标记示例中线性重新缩放组件激活。给定 24 个标记示例，我们的方法在 Llama-2-7B 上的 8 个任务中比 24 次 ICL 平均提高了 6.0% 的准确度点。总的来说，本文丰富了我们对 ICL 的理解，并通过检查模型内部提供了实用的改进方法。]]></description>
      <guid>https://arxiv.org/abs/2406.13131</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:55 GMT</pubDate>
    </item>
    <item>
      <title>PathoLM：通过基因组基础模型从 DNA 序列识别致病性</title>
      <link>https://arxiv.org/abs/2406.13133</link>
      <description><![CDATA[arXiv:2406.13133v1 公告类型：新
摘要：病原体鉴定是诊断、治疗和预防疾病的关键，对于控制感染和保障公共健康至关重要。传统的基于比对的方法虽然被广泛使用，但计算量大且依赖于广泛的参考数据库，由于其灵敏度和特异性低，通常无法检测到新病原体。同样，传统的机器学习技术虽然很有前景，但需要大量带注释的数据集和广泛的特征工程，并且容易过度拟合。为了应对这些挑战，我们推出了 PathoLM，这是一种针对细菌和病毒序列致病性识别而优化的尖端病原体语言模型。利用核苷酸转换器等预训练 DNA 模型的优势，PathoLM 需要最少的数据进行微调，从而增强病原体检测能力。它有效地捕捉了更广泛的基因组背景，显着提高了对新型和不同病原体的识别。我们开发了一个全面的数据集，其中包含大约 30 种病毒和细菌，包括 ESKAPEE 病原体、七种对抗生素具有耐药性的致命细菌菌株。此外，我们还整理了一个专门以 ESKAPEE 组为中心的物种分类数据集。在比较评估中，PathoLM 的表现明显优于 DciPatho 等现有模型，展示了强大的零样本和少量样本能力。此外，我们扩展了 PathoLM-Sp 用于 ESKAPEE 物种分类，尽管任务很复杂，但它与其他先进的深度学习方法相比表现出色。]]></description>
      <guid>https://arxiv.org/abs/2406.13133</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:55 GMT</pubDate>
    </item>
    <item>
      <title>长上下文语言模型可以包含检索、RAG、SQL 等吗？</title>
      <link>https://arxiv.org/abs/2406.13121</link>
      <description><![CDATA[arXiv:2406.13121v1 公告类型：新
摘要：长上下文语言模型 (LCLM) 有可能彻底改变我们传统上依赖外部工具（如检索系统或数据库）完成任务的方法。利用 LCLM 本地摄取和处理整个信息语料库的能力可以带来许多优势。它通过消除对工具专业知识的需求来增强用户友好性，提供强大的端到端建模以最大限度地减少复杂管道中的级联错误，并允许在整个系统中应用复杂的提示技术。为了评估这种范式转变，我们引入了 LOFT，这是现实世界任务的基准，需要多达数百万个标记的上下文，旨在评估 LCLM 在上下文检索和推理方面的表现。我们的研究结果表明，尽管从未明确训练过这些任务，但 LCLM 具有令人惊讶的能力，可以与最先进的检索和 RAG 系统相媲美。然而，LCLM 在 SQL 类任务所需的组合推理等领域仍面临挑战。值得注意的是，提示策略对性能有显著影响，这强调了随着上下文长度的增加，需要继续进行研究。总体而言，LOFT 为 LCLM 提供了一个严格的测试场地，展示了它们在模型能力扩展时取代现有范式和应对新任务的潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.13121</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>学习通过事实一致性模型生成带引文的答案</title>
      <link>https://arxiv.org/abs/2406.13124</link>
      <description><![CDATA[arXiv:2406.13124v1 公告类型：新
摘要：大型语言模型 (LLM) 经常产生幻觉，从而影响其在关键任务情况下的可靠性。解决此问题的一种方法是在生成内容的同时提供相关来源的引用，从而增强生成的可验证性。然而，在答案中准确引用段落仍然是一个巨大的挑战。本文提出了一种利用事实一致性模型 (FCM) 的弱监督微调方法。我们的方法在生成带有引文的文本和使用 FCM 过滤的引文数据进行监督微调之间交替进行。重点学习被整合到目标中，指导微调过程以强调事实单位标记，以 FCM 为衡量标准。使用各种指令调整的 LLM 在 ALCE 少量引用基准上的结果显示，与上下文学习、普通监督微调和最先进的方法相比，其性能更优异，平均分别提高了 $34.1$、$15.5$ 和 $10.5$ 个引用 F$_1$ 点。此外，在域转移设置中，我们表明获得的引用生成能力可以稳健地转移到看不见的数据集。值得注意的是，我们的引用改进有助于在基线中实现最低的事实错误率。]]></description>
      <guid>https://arxiv.org/abs/2406.13124</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>电影叙事的多语言概要：故事理解的数据集</title>
      <link>https://arxiv.org/abs/2406.13092</link>
      <description><![CDATA[arXiv:2406.13092v1 公告类型：新
摘要：故事视频文本对齐是计算故事理解中的一项核心任务，旨在将视频片段与其描述中的相应句子对齐。然而，由于人工注释的视频文本对应关系稀缺以及好莱坞电影主要集中在英文旁白上，该任务的进展受到阻碍。为了解决这些问题，本文构建了一个大规模多语言视频故事数据集，名为电影叙事多语言概要 (M-SYMON)，包含来自 7 种语言的 13,166 个电影摘要视频，以及 101.5 小时视频的细粒度视频文本对应关系的人工注释。在来自 SyMoN 的人工注释数据上进行的训练在剪辑准确率和句子 IoU 得分上分别比 SOTA 方法高出 15.7 和 16.2 个百分点，证明了注释的有效性。作为未来研究的基准，我们创建了 6 种具有不同多语言训练策略的基线方法，比较了它们在语言内和跨语言设置中的表现，体现了多语言视频文本对齐的挑战。]]></description>
      <guid>https://arxiv.org/abs/2406.13092</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:53 GMT</pubDate>
    </item>
    <item>
      <title>探索和基准测试大型语言模型的规划能力</title>
      <link>https://arxiv.org/abs/2406.13094</link>
      <description><![CDATA[arXiv:2406.13094v1 公告类型：新
摘要：我们寻求提升大型语言模型 (LLM) 的规划能力，主要研究四个方向。首先，我们构建了一个全面的基准套件，涵盖经典规划领域和自然语言场景。该套件包括生成不同难度级别的实例的算法，可以对 LLM 性能进行严格而系统的评估。其次，我们研究使用上下文学习 (ICL) 来增强 LLM 规划，探索增加上下文长度和提高规划性能之间的直接关系。第三，我们展示了微调 LLM 对最佳规划路径的积极影响，以及结合模型驱动搜索程序的有效性。最后，我们研究了所提出的方法在分布外场景中的表现，评估了推广到新的和看不见的规划挑战的能力。]]></description>
      <guid>https://arxiv.org/abs/2406.13094</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:53 GMT</pubDate>
    </item>
    <item>
      <title>多阶段平衡蒸馏：解决序列级知识蒸馏中的长尾挑战</title>
      <link>https://arxiv.org/abs/2406.13114</link>
      <description><![CDATA[arXiv:2406.13114v1 公告类型：新
摘要：大型语言模型 (LLM) 显著推进了各种自然语言处理任务，但部署它们仍然需要大量计算。知识蒸馏 (KD) 是一种很有前途的解决方案，它能够将功能从较大的教师 LLM 转移到更紧凑的学生模型。特别是，序列级 KD 可以提炼基于原理的推理过程，而不仅仅是最终结果，在提高学生的推理能力方面显示出巨大的潜力。然而，当前的方法在长尾数据分布下难以进行序列级 KD，对稀疏表示域的泛化产生不利影响。我们引入了多阶段平衡蒸馏 (BalDistill) 框架，它在固定的计算预算内迭代平衡训练数据。通过动态选择代表性头域示例并合成尾域示例，BalDistill 在各种长尾数据集中实现了最先进的性能，提高了蒸馏模型的效率和功效。]]></description>
      <guid>https://arxiv.org/abs/2406.13114</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:53 GMT</pubDate>
    </item>
    <item>
      <title>三思而后行：双角度评估检索增强生成</title>
      <link>https://arxiv.org/abs/2406.13050</link>
      <description><![CDATA[arXiv:2406.13050v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 具有令人印象深刻的功能，但它们经常面临诸如时间错位和产生幻觉内容等挑战。使用检索机制增强 LLM 以从外部来源获取相关信息提供了一种有希望的解决方案。受谚语“三思而后行”的启发，我们提出了一个双角度评估的检索增强生成框架 \textit{Think-then-Act}。与以前不加区分地重写查询或不顾必要地执行检索，或在决定额外检索之前生成临时响应（这会增加模型生成成本）的方法不同，我们的框架采用了一个两阶段过程：(i) 评估输入查询的清晰度和完整性以确定是否需要重写；(ii) 评估模型回答查询的能力并决定是否需要额外检索。在五个数据集上的实验结果表明，\textit{Think-then-Act} 框架显著提高了性能。与现有基线相比，我们的框架在准确性和效率方面有显著提高，并且在英语和非英语环境中均表现良好。消融研究验证了最佳模型置信度阈值，凸显了我们的方法的资源优化优势。]]></description>
      <guid>https://arxiv.org/abs/2406.13050</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 Rusty-DAWG 评估语言模型的 $n$-Gram 新颖性</title>
      <link>https://arxiv.org/abs/2406.13069</link>
      <description><![CDATA[arXiv:2406.13069v1 公告类型：新
摘要：语言模型 (LM) 生成的文本相对于其训练语料库有多新颖？在这项工作中，我们研究了现代 LM 从其训练数据中生成 $n$-gram 的程度，评估了 (i) LM 分配给完成训练 $n$-gram 的概率和 (ii) $n$-novelty，即 LM 生成的 $n$-gram 中未出现在训练数据中的比例（对于任意大的 $n$）。为了能够在恒定时间内对语料库进行任意长度的 $n$-gram 搜索，我们开发了 Rusty-DAWG，这是一种受基因组数据索引启发的新型搜索工具。我们将 LM 生成的文本的新颖性与人类书写的文本进行比较，并探讨影响生成新颖性的因素，重点关注 Pythia 模型。我们发现，当 n &gt; 4 时，LM 生成的文本不如人类书写的文本新颖，但当 n 较小时，LM 生成的文本新颖性更强。较大的 LM 和更受约束的解码策略都会降低新颖性。最后，我们表明，如果 n-gram 在训练数据中出现的频率较低，则 LM 可以以较低的损失完成 n-gram。总体而言，我们的结果揭示了影响 LM 生成文本新颖性的因素，我们发布了 Rusty-DAWG 以促进进一步的预训练数据研究。]]></description>
      <guid>https://arxiv.org/abs/2406.13069</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:52 GMT</pubDate>
    </item>
    <item>
      <title>CCA 在多视图文本数据中生成潜在状态/变量的适用性</title>
      <link>https://arxiv.org/abs/2406.12997</link>
      <description><![CDATA[arXiv:2406.12997v1 公告类型：新
摘要：典型相关分析 (CCA) 用于学习低维实向量（称为潜在变量）的概率解释已在各个领域得到广泛利用。这项研究更进一步，展示了 CCA 在发现潜在状态方面的潜力，该状态可在双视图设置下捕获文本数据中的上下文信息。本研究中讨论的 CCA 解释利用了文本数据的多视图性质，即文档中的连续句子或二元对话中的轮流，并且具有强大的理论基础。此外，本研究提出了一个使用 CCA 执行自动简答评分 (ASAG) 任务的模型。实证分析证实，所提出的模型可提供具有竞争力的结果，甚至可以击败各种复杂的监督技术。该模型简单、线性且适应性强，应作为基线使用，尤其是在标记训练数据稀缺或不存在的情况下。]]></description>
      <guid>https://arxiv.org/abs/2406.12997</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:51 GMT</pubDate>
    </item>
    <item>
      <title>通过集成提示检测错误 (DEEP)：用于检测事实错误的端到端 LLM 框架</title>
      <link>https://arxiv.org/abs/2406.13009</link>
      <description><![CDATA[arXiv:2406.13009v1 公告类型：新
摘要：准确的文本摘要是大型语言模型执行的最常见和最重要的任务之一，其中人工审查整个文档的成本可能很高，但摘要中的错误成本可能更高。我们提出了通过集成提示检测错误 (DEEP) - 一种用于检测文本摘要中事实错误的端到端大型语言模型框架。我们的框架使用一组不同的 LLM 提示来识别事实不一致，将它们的输出视为二进制特征，然后将其输入到集成模型中。然后，我们校准集成模型以产生经验准确的概率，即文本在事实上是一致的或没有幻觉。我们证明，如果不优化评估数据集子集上的阈值，用于检测摘要中事实错误的先前模型的表现会明显更差。我们的框架在 AggreFact-XSUM FTSOTA、TofuEval Summary-Level 和 HaluEval Summarization 基准上实现了最先进的 (SOTA) 平衡准确率，可检测 Transformer 生成的文本摘要中的事实错误。它无需对语言模型进行任何微调，也无需依赖实际环境中不可用的阈值技术即可实现此目的。]]></description>
      <guid>https://arxiv.org/abs/2406.13009</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:51 GMT</pubDate>
    </item>
    <item>
      <title>D2O：用于大型语言模型高效生成推理的动态判别操作</title>
      <link>https://arxiv.org/abs/2406.13035</link>
      <description><![CDATA[arXiv:2406.13035v1 公告类型：新 
摘要：大型语言模型 (LLM) 中的高效推理受到键值 (KV) 缓存不断增长的内存需求的阻碍，尤其是对于较长的序列。传统的 KV 缓存驱逐策略根据注意力分数对不太重要的 KV 对进行优先排序，这通常会降低生成质量，导致上下文丢失或幻觉等问题。为了解决这个问题，我们引入了动态判别操作 (D2O)，这是一种新方法，它利用两级判别策略来优化 KV 缓存大小而无需微调，同时保留基本上下文。最初，通过观察浅层和深层之间注意力权重的不同密度，我们利用这种洞察力来确定哪些层应该避免过度驱逐以最大限度地减少信息丢失。随后，对于每层的驱逐策略，D2O 创新性地加入了补偿机制，该机制维持相似度阈值以重新区分先前丢弃的 token 的重要性，确定是否应将其召回并与类似 token 合并。我们的方法不仅实现了显着的内存节省并将推理吞吐量提高了 3 倍以上，而且还保持了高质量的长文本生成。在各种基准测试和 LLM 架构上进行的大量实验表明，D2O 在受限的 KV 缓存预算下显着提高了性能。]]></description>
      <guid>https://arxiv.org/abs/2406.13035</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:51 GMT</pubDate>
    </item>
    <item>
      <title>SHIELD：LLM 文本生成中版权合规性的评估和辩护策略</title>
      <link>https://arxiv.org/abs/2406.12975</link>
      <description><![CDATA[arXiv:2406.12975v1 公告类型：新
摘要：大型语言模型 (LLM) 已经改变了机器学习，但由于其可能生成侵犯版权的文本而引发了重大的法律担忧，导致了几起备受瞩目的诉讼。法律环境正在努力跟上这些快速发展的步伐，关于生成的文本是否会抄袭受版权保护的材料的争论仍在继续。当前的 LLM 可能会侵犯版权或过度限制非版权文本，从而带来以下挑战：(i) 需要一个全面的评估基准来从多个方面评估版权合规性；(ii) 评估对绕过保护措施攻击的稳健性；(iii) 开发针对受版权保护文本生成的有效防御措施。为了应对这些挑战，我们引入了一个精选数据集来评估方法、测试攻击策略并提出轻量级、实时的防御措施，以防止生成受版权保护的文本，确保 LLM 的安全合法使用。我们的实验表明，当前的 LLM 经常输出受版权保护的文本，而越狱攻击可以显著增加受版权保护的输出量。我们提出的防御机制通过有效拒绝恶意请求，显著减少了 LLM 生成的受版权保护的文本量。代码可在 https://github.com/xz-liu/SHIELD 上公开获取]]></description>
      <guid>https://arxiv.org/abs/2406.12975</guid>
      <pubDate>Fri, 21 Jun 2024 06:19:50 GMT</pubDate>
    </item>
    </channel>
</rss>