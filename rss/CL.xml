<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 30 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用深度学习技术对乌尔都语文本进行文档级情感分析</title>
      <link>https://arxiv.org/abs/2501.17175</link>
      <description><![CDATA[arXiv:2501.17175v1 公告类型：新 
摘要：文档级乌尔都语情绪分析 (SA) 是一项具有挑战性的自然语言处理 (NLP) 任务，因为它处理资源匮乏的语言中的大型文档。在大型文档中，有大量的单词表现出不同的观点。深度学习 (DL) 模型由复杂的神经网络架构组成，这些架构能够学习数据的不同特征来对各种情绪进行分类。除了音频、图像和视频分类之外，DL 算法现在广泛用于基于文本的分类问题。为了探索乌尔都语 SA 的强大 DL 技术，我们应用了五种不同的 DL 架构，即双向长短期记忆 (BiLSTM)、卷积神经网络 (CNN)、具有双向长短期记忆的卷积神经网络 (CNN-BiLSTM)、来自 Transformer 的双向编码器表示 (BERT)。在本文中，我们提出了一种将 BiLSTM 与单层多滤波器卷积神经网络 (BiLSTM-SLMFCNN) 相结合的 DL 混合模型。通过使用适用于文档级别 (SA) 的预训练乌尔都语词嵌入，将所提出的和基线技术应用于乌尔都语客户支持数据集和 IMDB 乌尔都语电影评论数据集。对这些技术的结果进行了评估，我们提出的模型优于乌尔都语 SA 的所有其他 DL 技术。BiLSTM-SLMFCNN 的表现优于基线 DL 模型，在小型、中型和大型 IMDB 乌尔都语电影评论数据集和乌尔都语客户支持数据集上分别实现了 83{\%}、79{\%}、83{\%} 和 94{\%} 的准确率。]]></description>
      <guid>https://arxiv.org/abs/2501.17175</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>调整 LLM Judges 超参数</title>
      <link>https://arxiv.org/abs/2501.17178</link>
      <description><![CDATA[arXiv:2501.17178v1 公告类型：新
摘要：评估大型语言模型 (LLM) 通常需要昂贵的人工注释。为了解决这个问题，提出了基于 LLM 的评判者，它比较两个 LLM 的输出，从而可以在没有人工干预的情况下对模型进行排名。虽然已经提出了几种方法，但不同论文之间存在许多混杂因素。例如，模型、提示和其他超参数通常同时更改，使得苹果与苹果的比较具有挑战性。在本文中，我们建议系统地分析和调整 LLM 评判者的超参数。为了减轻评估评判者的高成本，我们建议利用多目标多保真度，这可以找到以准确性换取成本的评判者，并显着降低搜索成本。我们的方法识别的评判者不仅在准确性和成本效率方面优于现有基准，而且还利用开放权重模型，确保更高的可访问性和可重复性。]]></description>
      <guid>https://arxiv.org/abs/2501.17178</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过价值强化提供情感支持的对话系统</title>
      <link>https://arxiv.org/abs/2501.17182</link>
      <description><![CDATA[arXiv:2501.17182v1 公告类型：新
摘要：情感支持对话系统旨在减轻求助者的痛苦并帮助他们克服挑战。虽然人类价值观$\unicode{x2013}$塑造个人优先事项的核心信念$\unicode{x2013}$在当代心理治疗中越来越受到重视，因为它们在促进内部转变和长期情感健康方面发挥着作用，但它们与情感支持系统的整合仍未得到充分探索。为了弥补这一差距，我们提出了一种价值驱动的方法来训练情感支持对话系统，旨在强化求助者的积极价值观。我们的模型通过利用 Reddit 的在线支持对话，学会识别每次需要强化哪些价值观以及如何强化。该模型在情感支持能力方面表现出色，超越了各种基线。值得注意的是，它更有效地探索和引出了求助者的价值观。治疗师的专家评估突出了我们模型的两个主要优势：它能够验证用户的挑战，并能有效地强调他们处境的积极方面。这两者都是价值强化的关键要素。我们的工作验证了价值强化对情感支持系统的有效性，并为未来的研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2501.17182</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于航空航天制造专业知识的法学硕士评估：自动生成和多模型问答</title>
      <link>https://arxiv.org/abs/2501.17183</link>
      <description><![CDATA[arXiv:2501.17183v1 Announce Type: new 
摘要：航空航天制造对技术参数的精度要求极高。GPT-4 和 QWen 等大型语言模型 (LLM) 在自然语言处理中的出色表现引发了业界对其在工艺设计、材料选择和工具信息检索等任务中的应用兴趣。然而，LLM 容易在专业领域产生“幻觉”，产生不准确或虚假的信息，对航空航天产品质量和飞行安全构成重大风险。本文介绍了一套针对航空航天制造领域 LLM 量身定制的评估指标，旨在通过分析其在回答基于专业知识的问题方面的表现来评估其准确性。首先，通过对经典航空航天制造教科书和指南的深入文本分析来提取关键信息。随后，利用 LLM 生成技术，我们精心构造了难度各异、有多个正确答案的多项选择题。随后，采用不同的LLM模型回答这些问题，并记录其准确率。实验结果表明，LLM在航空航天专业知识方面的能力亟待提高。本研究为LLM在航空航天制造业的应用提供了理论基础和实践指导，填补了该领域的一个关键空白。]]></description>
      <guid>https://arxiv.org/abs/2501.17183</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>翻译任务中的不确定性可视化：法学硕士绩效和信心指标评估</title>
      <link>https://arxiv.org/abs/2501.17187</link>
      <description><![CDATA[arXiv:2501.17187v1 公告类型：新
摘要：大型语言模型 (LLM) 越来越多地用于机器翻译，但它们的预测通常表现出不确定性，从而阻碍了可解释性和用户信任。有效地可视化这些不确定性可以增强 LLM 输出的可用性，特别是在翻译准确性至关重要的情况下。本文解决了两个主要目标：(1) 为用户提供对模型置信度的 token 级洞察；(2) 开发基于 Web 的可视化工具来量化和表示翻译不确定性。为了实现这些目标，我们将 T5 模型与 WMT19 数据集结合用于翻译任务，并使用 BLEU、METEOR 和 ROUGE 等既定指标评估翻译质量。我们引入了三个新的不确定性量化 (UQ) 指标：(1) token 概率的几何平均值、(2) token 概率的算术平均值和 (3) token 分布峰度的算术平均值。这些指标为评估翻译性能提供了一个简单而有效的框架。我们的分析揭示了传统评估指标与 UQ 指标之间的线性关系，证明了我们方法的有效性。此外，我们还开发了一种基于 Web 的交互式可视化工具，使用颜色渐变来表示标记置信度。此工具让用户清晰直观地了解翻译质量，同时提供有关模型性能的宝贵见解。总体而言，我们表明我们的 UQ 指标和可视化工具既稳健又可解释，为评估和访问机器翻译系统提供了实用工具。]]></description>
      <guid>https://arxiv.org/abs/2501.17187</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用分类模型和比较分析对医学问答大型语言模型进行微调的综合研究</title>
      <link>https://arxiv.org/abs/2501.17190</link>
      <description><![CDATA[arXiv:2501.17190v1 公告类型：新
摘要：本文概述了专门用于回答医学问题的大型语言模型 (LLM) 的开发和微调。我们主要提高提供可靠医学查询答案的准确性和效率。在我们的方法中，我们有两个阶段，预测收到的医学问题的特定标签，然后为该标签提供预定义的答案。根据其能力检查和评估了 RoBERTa 和 BERT 等各种模型。这些模型使用从 Healthline.com 抓取的 6,800 个样本的数据集进行训练，并附加了合成数据。为了进行评估，我们使用 5 倍交叉验证进行了比较研究。为了评估性能，我们使用了准确度、精确度、召回率和 F1 分数等指标，并记录了训练时间。使用 5 倍交叉验证评估模型的性能。 LoRA Roberta-large 模型的准确率达到 78.47%，精确率达到 72.91%，召回率达到 76.95%，F1 得分达到 73.56%。Roberta-base 模型表现出色，准确率达到 99.87%，精确率达到 99.81%，召回率达到 99.86%，F1 得分达到 99.82%。Bert Uncased 模型表现出色，准确率达到 95.85%，精确率达到 94.42%，召回率达到 95.58%，F1 得分达到 94.72%。最后，Bert Large Uncased 模型取得了最高性能，准确率、精确率、召回率和 F1 得分均为 100%。所获得的结果有助于表明模型在对医疗问题进行分类和生成准确答案方面的能力，有助于制定更好的健康相关 AI 解决方案。]]></description>
      <guid>https://arxiv.org/abs/2501.17190</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于观点总结的方面感知分解</title>
      <link>https://arxiv.org/abs/2501.17191</link>
      <description><![CDATA[arXiv:2501.17191v1 公告类型：新
摘要：观点总结在从大规模在线评论中获取有意义的见解方面起着关键作用。为了使这个过程更易于解释和扎实，我们提出了一种由评论方面指导的模块化方法，将方面识别、观点整合和元评论综合的任务分开，从而提高透明度和易于检查。我们在代表科学研究、商业和产品领域的数据集上进行了广泛的实验。结果表明，与强大的基线模型相比，我们的方法可以生成更有根据的总结，这已通过自动和人工评估得到验证。此外，我们的模块化方法结合了基于评论方面的推理，比知识无关的分解提示产生了更具信息量的中间输出。这些中间输出还可以有效地支持人类从大量评论中总结意见。]]></description>
      <guid>https://arxiv.org/abs/2501.17191</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能辅助德国就业合同审查：基准数据集</title>
      <link>https://arxiv.org/abs/2501.17194</link>
      <description><![CDATA[arXiv:2501.17194v1 公告类型：新
摘要：雇佣合同用于在世界各地商定雇主和雇员之间的工作条件。理解和审查合同中无效或不公平条款需要对法律制度和术语有广泛的了解。自然语言处理 (NLP) 的最新进展有望协助进行这些审查。然而，由于专家注释数据集的稀缺，将 NLP 技术应用于法律文本尤其困难。为了解决这个问题，并作为我们使用 NLP 协助律师进行合同审查的起点，我们发布了一个匿名和注释的基准数据集，用于审查德国雇佣合同条款的合法性和公平性，以及基线模型评估。]]></description>
      <guid>https://arxiv.org/abs/2501.17194</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Atlas Selene Mini：通用评估模型</title>
      <link>https://arxiv.org/abs/2501.17195</link>
      <description><![CDATA[arXiv:2501.17195v1 公告类型：新
摘要：我们介绍了 Atla Selene Mini，这是一种最先进的小型语言模型评判器 (SLMJ)。Selene Mini 是一种通用评估器，在 11 个分布外基准测试中的整体表现优于最好的 SLMJ 和 GPT-4o-mini，涵盖绝对评分、分类和成对偏好任务。它是 RewardBench 上得分最高的 8B 生成模型，超越了 GPT-4o 和专业评委等强大基线。为了实现这一目标，我们开发了一种原则性的数据管理策略，该策略通过综合生成的评论来增强公共数据集，并通过过滤和数据集消融确保高质量。我们在组合直接偏好优化 (DPO) 和监督微调 (SFT) 损失上训练我们的模型，并生成一个在现实世界场景中表现出色的高度可提示的评估器。 Selene Mini 在金融和医疗行业数据集上与人类专家评估的零样本一致性显著提高。它对提示格式的变化也具有很强的鲁棒性。初步结果表明，Selene Mini 是实时、社区驱动的 Judge Arena 中排名最高的评估器。我们在 HuggingFace (https://hf.co/AtlaAI/Selene-1-Mini-Llama-3.1-8B) 和 Ollama 上发布了模型权重，以鼓励社区广泛采用。]]></description>
      <guid>https://arxiv.org/abs/2501.17195</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用心理测量方法提高 LLM 排行榜</title>
      <link>https://arxiv.org/abs/2501.17200</link>
      <description><![CDATA[arXiv:2501.17200v1 公告类型：新
摘要：大型语言模型 (LLM) 的快速发展使得创建基准来评估其性能成为必要。这些基准类似于人类测试和调查，因为它们由旨在测量这些系统认知行为中出现的属性的问题集组成。然而，与社会科学中研究的明确特征和能力不同，这些基准所衡量的属性通常更模糊且定义不太严格。最突出的基准通常被分组到排行榜中以方便使用，汇总性能指标并实现模型之间的比较。不幸的是，这些排行榜通常依赖于简单的聚合方法，例如取基准的平均分数。在本文中，我们展示了应用当代心理测量方法（最初是为人类测试和调查开发的）来提高大型语言模型在排行榜上的排名的优势。以 Hugging Face 排行榜的数据为例，我们将传统的朴素排名方法的结果与心理测量排名进行了比较。研究结果强调了采用心理测量技术对 LLM 绩效进行更稳健和更有意义的评估的好处。]]></description>
      <guid>https://arxiv.org/abs/2501.17200</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NUS-Emo 在 SemEval-2024 任务 3：对话中多模态情绪原因分析的指令调整法学硕士</title>
      <link>https://arxiv.org/abs/2501.17261</link>
      <description><![CDATA[arXiv:2501.17261v1 公告类型：新
摘要：本文介绍了我们为 SemEval-2024 任务 3 开发的系统的架构：对话中的多模态情绪原因分析。我们的项目针对子任务 2 的挑战，致力于多模态情绪原因对提取与情绪类别 (MECPE-Cat)，并构建了一个针对此任务独特挑战的双组件系统。我们将任务分为两个子任务：对话中的情绪识别 (ERC) 和情绪原因对提取 (ECPE)。为了解决这些子任务，我们利用大型语言模型 (LLM) 的能力，这些模型在各种自然语言处理任务和领域中始终表现出最先进的性能。最重要的是，我们为 LLM 设计了一种情绪原因感知指令调整方法，以增强对情绪及其相应因果原理的感知。我们的方法使我们能够熟练地应对 MECPE-Cat 的复杂性，在任务中取得了 34.71% 的加权平均 F1 分数，并在排行榜上名列第二。重现我们实验的代码和元数据均已公开。]]></description>
      <guid>https://arxiv.org/abs/2501.17261</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>为旧事物注入新活力：质量评估辅助约束解码用于自动后期编辑</title>
      <link>https://arxiv.org/abs/2501.17265</link>
      <description><![CDATA[arXiv:2501.17265v1 公告类型：新
摘要：自动后期编辑 (APE) 系统经常会遇到过度校正的问题，即对翻译进行不必要的修改，这违背了最少编辑的原则。在本文中，我们提出了一种新技术，通过在解码过程中结合单词级质量评估 (QE) 信息来减轻过度校正。此方法与架构无关，使其适用于任何 APE 系统，无论底层模型或训练方法如何。我们对英语-德语、英语-印地语和英语-马拉地语语言对的实验表明，所提出的方法比其相应的基线 APE 系统有显着的改进，TER 增益分别为 $0.65$、$1.86$ 和 $1.44$ 点。这些结果强调了 QE 和 APE 任务之间的互补关系，并强调了集成 QE 信息以减少 APE 系统中的过度校正的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.17265</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大规模知识图谱问答服务的综合评价</title>
      <link>https://arxiv.org/abs/2501.17270</link>
      <description><![CDATA[arXiv:2501.17270v1 公告类型：新
摘要：知识图谱问答系统 (KGQA) 根据知识图谱中的数据回答事实性问题。KGQA 系统很复杂，因为系统必须理解寻求知识的自然语言查询中的关系和实体，并将它们映射到针对 KG 的结构化查询以回答它们。在本文中，我们介绍了 Chronos，这是一个针对行业规模的 KGQA 的综合评估框架。它旨在全面评估这样一个多组件系统，重点关注 (1) 端到端和组件级指标、(2) 可扩展到不同的数据集和 (3) 在发布之前衡量系统性能的可扩展方法。在本文中，我们讨论了在行业规模上评估 KGQA 系统所面临的独特挑战，回顾了 Chronos 的设计以及它如何应对这些挑战。我们将展示它如何为数据驱动的决策提供基础，并讨论使用它来衡量和改进现实世界的 KGQA 系统的挑战。]]></description>
      <guid>https://arxiv.org/abs/2501.17270</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>量身定制的真相：通过个性化和伪造的统计数据优化 LLM 说服力</title>
      <link>https://arxiv.org/abs/2501.17273</link>
      <description><![CDATA[arXiv:2501.17273v1 公告类型：新 
摘要：大型语言模型 (LLM) 正变得越来越有说服力，展示了通过利用个人数据在与人类的对话中个性化论点的能力。这可能会对虚假信息活动的规模和有效性产生严重影响。我们研究了 LLM 在辩论环境中的说服力，方法是让人类（n=33）参与 LLM 生成的旨在改变人类观点的论点。我们通过测量人类在辩论前后对辩论假设的认同程度并分析意见变化的幅度以及 LLM 方向更新的可能性来量化 LLM 的效果。我们比较了既定说服策略的说服力，包括根据用户人口统计和个性形成的个性化论点、诉诸虚构的统计数据以及同时利用个性化论点和虚构统计数据的混合策略。我们发现人类和 GPT-4o-mini 生成的静态论点具有相当的说服力。然而，在互动辩论环境中利用混合策略时，LLM 的表现优于静态的人工撰写的论据。这种方法有 $\mathbf{51\%}$ 的机会说服参与者修改他们的初始立场，而静态的人工撰写的论据则为 $\mathbf{32\%}$。我们的结果凸显了 LLM 具有令人担忧的潜力，可以实现廉价且有说服力的大规模虚假宣传活动。]]></description>
      <guid>https://arxiv.org/abs/2501.17273</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过以幻觉为中心的偏好优化缓解大型语言模型中的幻觉翻译</title>
      <link>https://arxiv.org/abs/2501.17295</link>
      <description><![CDATA[arXiv:2501.17295v1 公告类型：新
摘要：机器翻译 (MT) 正在经历范式转变，基于微调大型语言模型 (LLM) 的系统与专门为翻译任务训练的传统编码器-解码器模型的竞争力越来越强。然而，基于 LLM 的系统产生幻觉的风险更高，这会严重损害用户的信任和安全。大多数关于幻觉缓解的先前研究都集中在传统的 MT 模型上，解决方案涉及事后缓解——检测幻觉翻译并重新翻译。虽然有效，但这种方法在部署生产中的额外工具时增加了复杂性，也增加了延迟。为了解决这些限制，我们提出了一种在模型训练阶段从本质上学习缓解幻觉的方法。具体来说，我们引入了一个数据创建框架来生成以幻觉为中心的偏好数据集。在这些偏好数据集上微调 LLM 可将五种语言对中的幻觉率平均降低 96%，同时保持整体翻译质量。在零样本设置中，我们的方法可将三种未见过的目标语言中的幻觉率平均降低 89%。]]></description>
      <guid>https://arxiv.org/abs/2501.17295</guid>
      <pubDate>Thu, 30 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>