<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Thu, 06 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>ExpertGenQA：专业领域的开放式质量检查生成</title>
      <link>https://arxiv.org/abs/2503.02948</link>
      <description><![CDATA[ARXIV：2503.02948V1公告类型：新 
摘要：为专门的技术领域生成高质量的问题 - 答案对仍然具有挑战性，现有方法在利用专家示例和实现主题多样性之间面临着权衡。我们提出了ExpertGenQA，该协议将几乎没有的学习与结构化主题和样式分类结合在一起，以生成全面的域特异性质量质量质量质量对。使用美国联邦铁路管理文件作为测试床，我们证明了ExpertgenQA在维持$ 94.4 \％$主题覆盖范围的同时，实现了两倍的基线方法。通过系统的评估，我们表明当前基于LLM的法官和奖励模型对肤浅的写作风格而不是内容质量表现出很大的偏见。我们使用Bloom的分类法分析表明，与基于模板的方法相比，专家Genqa更好地保留了专家编写问题的认知复杂性分布。当用于训练检索模型时，我们生成的查询将TOP-1的准确性提高了$ 13.02 \％$，而不是基线性能，这表明了它们在技术领域中下游应用的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.02948</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Infinisst：与大语言模型同时翻译无限的语音</title>
      <link>https://arxiv.org/abs/2503.02969</link>
      <description><![CDATA[ARXIV：2503.02969V1公告类型：新 
摘要：由于需要有效处理历史语音上下文和过去的翻译，因此无界流语音的同时翻译仍然是一个具有挑战性的问题，因此可以平衡质量和延迟（包括计算开销）。大多数先前的作品都采用预分段的语音，从而限制了其现实世界的适用性。在本文中，我们提出了一种新颖的方法，该方法将SST提出为多转化的对话任务，从而实现了无限语音的无缝翻译。我们在训练过程中构建了从必须使用的必需轨迹的翻译轨迹和稳健的细分，并制定了键值（KV）缓存管理策略，以促进有效的推理。对必需结构，en-de和en-ZH的实验表明，与基准相比，Infinisst在保持相同的翻译质量的同时，将计算感知潜伏期降低了0.5至1秒。消融研究进一步验证了我们的数据构建和缓存管理策略的贡献。我们在https://github.com/leililab/infinisst上发布代码]]></description>
      <guid>https://arxiv.org/abs/2503.02969</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型中的多语言相对从句依恋歧义分辨率</title>
      <link>https://arxiv.org/abs/2503.02971</link>
      <description><![CDATA[ARXIV：2503.02971V1公告类型：新 
摘要：本研究研究了大型语言模型（LLM）如何解决相对条款（RC）的依恋歧义，并将其表现与人类句子处理进行比较。着眼于两个语言因素，即RC的长度和复杂的确定词短语（DPS）的句法位置，我们评估LLM在语言的复杂性中是否可以实现类似人类的解释。在这项研究中，我们用多种语言评估了几种LLM，包括克劳德，双子座和骆驼：英语，西班牙语，法语，德语，日语和韩语。尽管这些模型在印欧语（英语，西班牙语，法语和德语）中表现良好，但它们遇到了亚洲语言（日语和韩语）的困难，通常违约将英语翻译不正确。这些发现强调了LLMS对语言歧义的处理的可变性，并强调了对模型改进的需求，尤其是对于非欧洲语言。这项研究为LLM设计的未来增强提供了信息，以提高各种语言环境中的准确性和类似人类的处理。]]></description>
      <guid>https://arxiv.org/abs/2503.02971</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Lingoly-too：通过语言型和拼字化混淆的推理解开记忆</title>
      <link>https://arxiv.org/abs/2503.02972</link>
      <description><![CDATA[ARXIV：2503.02972V2公告类型：新 
摘要：评估大语言模型（LLM）的推理能力（LLMS）容易因评估基准的数据暴露而高估。我们介绍了一个框架，用于产生语言推理问题，以减少记忆在模型绩效估算中的影响，并将此框架应用于开发Lingoly-Too，这是语言推理的挑战性基准。通过开发拼字模板，我们动态混淆了真实语言的写作系统，以产生大量的问题。这些变化保留了每个解决方案所需的推理步骤，同时降低了模型培训数据中出现的特定问题实例的可能性。我们的实验表明，包括Claud 3.7十四行诗，O1-Preview和DeepSeek R1在内的边境模型与先进的推理作斗争。我们的分析还表明，LLM在同一问题的排列中表现出明显的准确性差异，并且平均而言，在其原始拼字法中出现的问题上表现更好。我们的发现突出了LLM中响应产生的不透明性质，并提供了证据表明先前的数据暴露有助于过度估计前沿模型的推理能力。]]></description>
      <guid>https://arxiv.org/abs/2503.02972</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有效地引导LLM通过建立自信方向遵循偏好</title>
      <link>https://arxiv.org/abs/2503.02989</link>
      <description><![CDATA[ARXIV：2503.02989V1公告类型：新 
摘要：拥有与人类偏好保持一致的LLM对于满足个人需求至关重要，例如保持写作风格或产生特定的感兴趣主题。当前的大多数对齐方法都依赖于微调或提示，这可能是昂贵或难以控制的。通过构建特定的转向说明来修改模型输出的模型转向算法通常易于实现和优化。但是，它们的功能通常仅限于将模型转向两个方向之一（即双向转向），并且没有理论上的理解来保证其性能。在这项工作中，我们提出了一个理论框架，以了解和量化模型转向方法。受框架的启发，我们提出了一种自信的方向转向方法（confst），该方法通过在推理时修改其激活来引导LLMS。更具体地说，Conflst构建了一个自信方向，该方向与用户的喜好紧密相符，然后将此方向添加到LLMS的激活中，以有效地引导模型输出。我们的方法比流行的双向模型转向方法提供了三个关键优势：1）功能更强大，因为可以同时将多个用户的偏好（即两个以上）用户的喜好对准； 2）实现很容易，因为无需确定将转向向量添加到哪个层； 3）不需要明确的用户指令。我们在GPT-2 XL（1.5B），Mistral（7b）和Gemma-It（9B）模型上验证了我们的方法，以需要将LLM在各种主题和样式上转移的输出，从而实现优于竞争方法的卓越性能。]]></description>
      <guid>https://arxiv.org/abs/2503.02989</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Bangla文档的零射击多标签分类：大解码器VS。经典编码器</title>
      <link>https://arxiv.org/abs/2503.02993</link>
      <description><![CDATA[ARXIV：2503.02993V1公告类型：新 
摘要：孟加拉国是一种超过3亿本名母语的人所说的语言，并被排名全球第六种口语，由于其复杂的形态学特征和有限的资源，在自然语言处理（NLP）中提出了独特的挑战（NLP）。尽管最近基于大型解码器的模型（LLM），例如GPT，Llama和DeepSeek，在许多NLP任务中都表现出了出色的性能，但它们在孟加拉的有效性仍未得到探索。在本文中，我们建立了第一个基准测试，将基于解码器的LLM与基于经典编码器的模型进行了零击的多标签分类（零摄像-MLC）任务。我们对32种最先进模型的评估表明，现有的所谓强大编码器和解码器仍在努力实现Bangla Zero-Sho-Shot-MLC任务的高精度，这表明需要为Bangla NLP进行更多的研究和资源。]]></description>
      <guid>https://arxiv.org/abs/2503.02993</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在社交媒体上发布之前，我会得到仇恨言论，以预测滥用的答复</title>
      <link>https://arxiv.org/abs/2503.03005</link>
      <description><![CDATA[ARXIV：2503.03005V1公告类型：新 
摘要：尽管研究越来越多地在社交媒体上应对进攻性语言，但这项研究主要是反应性的，确定社交媒体上已经发布的内容是否滥用。预测方法存在差距，我们在研究中通过预测发布后会收到的滥用回复的数量来解决。 We formulate the problem from the perspective of a social media user asking: ``if I post a certain message on social media, is it possible to predict the volume of abusive replies it might receive?&#39;&#39; We look at four types of features, namely text, text metadata, tweet metadata, and account features, which also help us understand the extent to which the user or the content helps predict the number of abusive replies.反过来，这有助于我们开发一个模型，以支持社交媒体用户找到发布内容的最佳方法。我们的目标之一也是确定推文将获得的滥用回复量的程度是由推文的内容或用户的标识发布的。我们的研究发现，可以建立一个模型，该模型通过开发从消息的内容中得出的全面功能来竞争性能。此外，我们的研究表明，从用户的身份获得的功能不会影响模型性能，因此表明尤其是帖子的内容会触发滥用的答复，而不是用户是谁。]]></description>
      <guid>https://arxiv.org/abs/2503.03005</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种训练所有这些的模型：层次结构的自我介绍以增强早期层嵌入</title>
      <link>https://arxiv.org/abs/2503.03008</link>
      <description><![CDATA[ARXIV：2503.03008V1公告类型：新 
摘要：部署语言模型通常需要处理模型大小与性能权衡，以满足下游延迟限制，同时保留模型的实用性。通常使用模型蒸馏来减少模型大小，同时保持可接受的性能。但是，由于蒸馏涉及多个训练步骤，因此蒸馏效率可能不佳。在这项工作中，我们介绍了ModularStarenCoder，这是一种带有1B参数的模块化多EXIT编码器，可用于代码检索范围内的多个任务。 ModullStarenCoder经过一种新型的自我验证机制的培训，该机制可显着改善较低的表示形式，从而允许使用模型的不同部分，同时仍然在绩效方面保持良好的权衡。我们的体系结构着重于通过系统地捕获多个表示级别的句法和语义结构来增强文本对编码和代码对代码搜索。特定的编码层作为出口头的靶向，使较高的层可以在训练过程中引导较早的层。这种自我验证效应改善了中间表示，以无额外的培训成本增加了检索召回。除了多次EXIT方案外，我们的方法还集成了存储库级的上下文损失，该损失最大程度地利用了训练上下文窗口，从而进一步增强了学习的表示形式。我们还发布了一个通过代码翻译构建的新数据集，无缝扩展传统的文本对代码基准，并在不同的编程语言上使用代码对代码对。实验结果突出了通过多exit监督自我验证的好处。]]></description>
      <guid>https://arxiv.org/abs/2503.03008</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>保险箱：LLMS中稀疏的自动编码器基于稀疏的自动编码器框架，可缓解LLMS</title>
      <link>https://arxiv.org/abs/2503.03032</link>
      <description><![CDATA[ARXIV：2503.03032V1公告类型：新 
摘要：尽管大语言模型（LLM）的最新性能，但这些模型经常遭受幻觉的影响，这可能会破坏其在关键应用中的性能。在这项工作中，我们提出了一种安全的方法，一种新的方法，用于通过利用稀疏的自动编码器（SAE）来检测和减轻幻觉。尽管已经独立探索了幻觉检测技术和SAE，但它们在综合系统中的协同应用，尤其是对于幻觉感知的查询富集，尚未得到充分研究。为了验证安全的有效性，我们将其评估在两个模型上，该模型在三个不同的跨域数据集中有可用的SAE，旨在评估幻觉问题。经验结果表明，安全可以始终提高查询产生的准确性，并减轻所有数据集的幻觉，从而实现高达29.45％的准确性提高。]]></description>
      <guid>https://arxiv.org/abs/2503.03032</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>鼠尾草：通过扩大国家行动的转向和炼油对话生成</title>
      <link>https://arxiv.org/abs/2503.03040</link>
      <description><![CDATA[ARXIV：2503.03040V1公告类型：新 
摘要：大型语言模型的最新进展表现出了以任务为导向的应用程序令人印象深刻的能力，但是建立了可以进行自然，战略对话的情感智能聊天机器人仍然是一个挑战。我们提出了一种名为Sage的新方法，该方法使用潜在变量来控制对话生成中的长途行为。我们方法的核心是国家行动链（SAC），它通过引入封装情绪状态和对话转弯之间的情绪状态和对话策略的潜在变量来增强标准语言模型。在推断期间，这些变量是在每个响应之前生成的，从而在维持自然相互作用模式的同时，可以对对话进展进行粗粒的控制。我们还介绍了一个自我完善的管道，该管道利用对话树搜索，基于LLM的奖励建模以及有针对性的微调来优化对话轨迹。我们的实验结果表明，使用这种方法训练的模型表明，情绪智力指标的性能提高，同时保持LLM基准测试的强大功能。我们潜在变量的离散性质促进了基于搜索的策略，并为对话系统的增强学习的未来应用奠定了基础，在该系统中可以在州一级进行学习，而不是代币层面。]]></description>
      <guid>https://arxiv.org/abs/2503.03040</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>QE4PE：人类后编辑的单词级质量估计</title>
      <link>https://arxiv.org/abs/2503.03044</link>
      <description><![CDATA[ARXIV：2503.03044V1公告类型：新 
摘要：单词级质量估计（QE）检测到机器翻译中的错误跨度，可以指导和促进人类的后编辑。尽管已经对单词级量化量化宽松系统的准确性进行了广泛的评估，但它们的可用性和下游对人类后编辑的速度，质量和编辑选择的影响仍在研究中。我们的QE4PE研究调查了单词级量化宽松对机器翻译（MT）编辑的影响，在涉及两个翻译方向的42个专业后编辑的现实环境中。我们比较了四个错误跨度的突出显示模式，包括监督和基于不确定性的单词量量量宽量表方法，用于识别最先进的神经MT模型输出中的潜在错误。通过行为日志来估算编辑后的工作和生产力，而质量改进是通过单词和细分级的人类注释来评估的。我们发现，域，语言和编辑的速度是确定亮点有效性的关键因素，在人造和自动化的量化宽松之间存在适度的差异，突显了专业工作流程中准确性与可用性之间的差距。]]></description>
      <guid>https://arxiv.org/abs/2503.03044</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>半监督的内在学习学习：基线研究</title>
      <link>https://arxiv.org/abs/2503.03062</link>
      <description><![CDATA[ARXIV：2503.03062V1公告类型：新 
摘要：在数据选择中的大多数现有工作（ICL）的重点是从地面真理注释中构建演示，而对选择可靠的自我生成的注释的关注有限。在这项工作中，我们提出了一个三步半监督的ICL框架：注释生成，演示选择和半监督推理。我们的基线Naive-semiicl提示选择ICL提示的高信任自我生成的演示，在16个数据集中，平均比16次射击基线的表现平均高9.94％。我们进一步介绍了ITERPSD，这是一种注释方法，可以迭代地完善伪示例，在分类任务中获得多达6.8％的额外收益。最后，我们揭示了半监督ICL的缩放定律，其中模型以1,000多次示威来实现最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2503.03062</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>改善LLM-AS-A-A-a-a-a-Gudge推论与判断分配</title>
      <link>https://arxiv.org/abs/2503.03064</link>
      <description><![CDATA[ARXIV：2503.03064V1公告类型：新 
摘要：使用语言模型可缩减对文本质量的人类偏好（LLM-AS-A-Gudge）已成为适用于许多任务的标准实践。通常仅从法官的文本输出中提取判断，通常是贪婪的解码。但是，LLM法官自然会在判断令牌上提供分布，邀请推理方法广度以提取细粒度的偏好。我们发现，在所有评估设置（即尖，成对，成对和listwise）中，以判断分布的平均值始终优于采用模式（即贪婪解码）的表现。我们进一步探讨了从判断分布中得出偏好的新方法，并发现融合风险规定的方法通常会改善绩效。最后，我们分析了LLM-AS-A-A-Gudge与Thebough（COT）提示配对，表明COT可能会崩溃判断分布的传播，通常会损害绩效。我们的发现表明，利用分配输出可以改善llm-as-a-a-a-a-a gudge，而不是单独使用文本接口。]]></description>
      <guid>https://arxiv.org/abs/2503.03064</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Muco-kgc：多文本知识知识图完成</title>
      <link>https://arxiv.org/abs/2503.03091</link>
      <description><![CDATA[ARXIV：2503.03091V1公告类型：新 
摘要：知识图完成（KGC）试图预测知识图（KGS）中缺少的实体（例如头部或尾巴）或通常包含不完整数据的关系。传统的基于嵌入的方法，例如Transe和Complext，具有改进的尾巴实体预测，但在测试过程中努力概括为看不见的实体。基于文本的模型通过利用其他语义上下文来减轻此问题；但是，它们对负三重态采样的依赖引入了高计算开销，语义上不一致和数据不平衡。最近的方法，例如KG-BERT，表现出希望，但在很大程度上取决于实体描述，这些描述通常在公斤中不可用。至关重要的是，现有方法忽略了与实体和关系相关的kg中有价值的结构信息。为了应对这些挑战，我们提出了多文本感知知识图的完成（MUCO-KGC），该模型利用图表内链接的实体和关系的上下文信息来预测尾部实体。 Muco-kgc消除了对实体描述和负三重抽样的需求，在增强性能的同时大大降低了计算复杂性。我们在标准数据集上进行的实验，包括FB15K-237，WN18RR，Codex-S和Codex-M，证明了Muco-KGC在三个数据集上的最先进方法表明。值得注意的是，Muco-kgc在WN18RR上改善了MRR，而Codex-S和Codex-M数据集则分别为$ 1.63 \％$，$ 3.77 \％$ $和$ 20.15 \％$ $ $ $，表明其对KGC任务的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.03091</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>监测解码：通过评估一代响应的事实来缓解幻觉</title>
      <link>https://arxiv.org/abs/2503.03106</link>
      <description><![CDATA[ARXIV：2503.03106V1公告类型：新 
摘要：尽管大型语言模型在各种任务中都表现出了出色的表现，但它们仍然容易受到幻觉的影响 - 产生了合理但实际上不正确的内容。现有的减轻这种风险的方法通常依赖于对多个全长世代进行取样，这引入了显着的响应潜伏期，并且当模型始终以高信心产生幻觉输出时，变得无效。为了解决这些局限性，我们引入了监视解码（MD），这是一个动态监视生成过程并有选择地采用进程干预措施的新型框架，重点是修改负责幻觉的至关重要的令牌。我们没有等到完成多个全长世代的完成，而是使用监视器功能在生成过程中识别易幻觉的令牌，并通过基于树的解码策略进一步完善这些令牌。这种方法可确保在维持效率的同时，在生成的产出中提高了事实的准确性和连贯性。实验结果表明，MD在有效性和效率方面始终优于基于自符的方法，从而达到更高的事实准确性，同时显着降低了计算开销。]]></description>
      <guid>https://arxiv.org/abs/2503.03106</guid>
      <pubDate>Thu, 06 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>