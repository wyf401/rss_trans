<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 30 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>LLAVADI：多模态大型语言模型提炼的关键</title>
      <link>https://arxiv.org/abs/2407.19409</link>
      <description><![CDATA[arXiv:2407.19409v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 的近期激增展示了它们通过将视觉理解集成到大型语言模型中实现广义智能的巨大潜力。然而，MLLM 的庞大模型大小导致了大量内存和计算需求，阻碍了它们的广泛部署。在这项工作中，我们并没有提出一种新的高效模型结构，也没有从头开始训练小规模 MLLM。相反，我们专注于通过知识蒸馏训练小规模 MLLM 的重要事项，这是从多模态蒸馏角度来看的第一步。我们广泛的研究涉及知识蒸馏过程中的训练策略、模型选择和蒸馏算法。这些结果表明，在师生框架中，token 和 logit 对齐的联合对齐起着关键作用。此外，我们从这项研究中得出了一系列有趣的观察结果。通过评估不同的基准和适当的策略，即使是 2.7B 的小规模模型也可以与具有 7B 或 13B 参数的大型模型相媲美。我们的代码和模型将公开供进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2407.19409</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:38 GMT</pubDate>
    </item>
    <item>
      <title>语言模型是否存在语言习得的关键期？</title>
      <link>https://arxiv.org/abs/2407.19325</link>
      <description><![CDATA[arXiv:2407.19325v1 公告类型：新
摘要：人类似乎有一个语言习得的关键期 (CP)：第二语言 (L2) 习得在幼儿期后变得更加困难，并且在此时期之后（但在此之前）停止接触第一语言 (L1) 通常不会导致 L1 能力的显着下降。目前尚不清楚这些 CP 效应是由先天决定的大脑成熟度还是由经验自然引起的神经连接稳定所致。在本研究中，我们使用语言模型 (LM) 来测试这些现象在多大程度上是人类所特有的，还是更广泛的语言学习者所共有的。我们通过在各种实验条件下对语言对训练 LM 来改变接触年龄，并发现 LM 缺乏与先天成熟阶段的任何直接类似物，在 L1 和 L2 上进行顺序训练时不会显示 CP 效应。我们的研究结果与“CP 效应是统计学习者学习的必然结果”的说法相矛盾，它们与 CP 效应的内在机制相一致。我们表明，我们可以通过在训练过程中引入正则化器来对 CP 进行逆向工程，以模拟可塑性的成熟下降。总而言之，我们的结果表明，仅靠 L1 学习可能不足以诱导 CP，需要进行额外的工程设计，以使语言模型在认知上更合理。]]></description>
      <guid>https://arxiv.org/abs/2407.19325</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:37 GMT</pubDate>
    </item>
    <item>
      <title>推理时间选择性去偏</title>
      <link>https://arxiv.org/abs/2407.19345</link>
      <description><![CDATA[arXiv:2407.19345v1 公告类型：新
摘要：我们提出了选择性去偏——一种推理时安全机制，旨在提高模型在预测性能和公平性方面的整体质量，以应对无法重新训练模型的情况。该方法的灵感来自选择性预测，其中一些被认为质量较低的预测在推理时被丢弃。在我们的方法中，我们识别出可能有偏差的模型预测，而不是丢弃它们，而是使用 LEACE——一种后处理去偏方法对它们进行去偏。为了选择有问题的预测，我们提出了一种基于 KL 散度的偏差量化方法，该方法比标准 UQ 方法取得了更好的效果。对文本分类数据集的实验表明，选择性去偏有助于缩小后处理方法与训练和预处理去偏技术之间的性能差距。]]></description>
      <guid>https://arxiv.org/abs/2407.19345</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:37 GMT</pubDate>
    </item>
    <item>
      <title>亚洲语言的分词：中文、韩语和日语</title>
      <link>https://arxiv.org/abs/2407.19400</link>
      <description><![CDATA[arXiv:2407.19400v1 公告类型：新
摘要：我们详细概述了亚洲语言（特别是中文、韩语和日语）的各种分词方法。对于每种语言，处理分词的方法都不同。我们还分析了每种方法的某些优缺点。此外，该领域还有未来的工作空间。]]></description>
      <guid>https://arxiv.org/abs/2407.19400</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:37 GMT</pubDate>
    </item>
    <item>
      <title>理解法学硕士中的记忆：动态、影响因素和含义</title>
      <link>https://arxiv.org/abs/2407.19262</link>
      <description><![CDATA[arXiv:2407.19262v1 公告类型：新
摘要：了解大型语言模型 (LLM) 是否以及在多大程度上记忆了训练数据，对于其输出的可靠性和训练数据的隐私性具有重要意义。为了清晰地测量和区分记忆与其他现象（例如上下文学习），我们创建了一个基于反复将 LLM 暴露于随机字符串的实验框架。我们的框架使我们能够更好地理解动态，即模型在反复暴露于随机字符串时的行为。使用我们的框架，我们做出了几个惊人的观察：（a）我们发现模型系列（Pythia、Phi 和 Llama2）的动态阶段是一致的，（b）我们确定了使某些字符串比其他字符串更容易记忆的因素，以及（c）我们确定了局部前缀和全局上下文在记忆中的作用。我们还表明，连续接触不同的随机字符串对记忆有显著的影响。我们的研究结果常常令人惊讶，对法学硕士 (LLM) 的研究和使用具有重要的后续影响。]]></description>
      <guid>https://arxiv.org/abs/2407.19262</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:36 GMT</pubDate>
    </item>
    <item>
      <title>数据限制下 LLM 的 LoRA 适配器对临床 NLP 分类的影响</title>
      <link>https://arxiv.org/abs/2407.19299</link>
      <description><![CDATA[arXiv:2407.19299v1 公告类型：新
摘要：由于领域差距和数据可用性有限，对用于临床自然语言处理 (NLP) 的大型语言模型 (LLM) 进行微调面临重大挑战。本研究调查了各种适配器技术（相当于低秩自适应 (LoRA)）在资源受限的医院环境中对 LLM 进行微调的有效性。我们尝试了四种结构 - 适配器、轻量级、TinyAttention 和门控残差网络 (GRN) - 作为临床笔记分类的最终层。我们对生物医学预训练模型进行了微调，包括 CamemBERT-bio、AliBERT 和 DrBERT，以及两个基于 Transformer 的模型。我们广泛的实验结果表明，i) 采用适配器结构不会对微调生物医学预训练的 LLM 产生显着的改进，ii) 从头开始​​训练的更简单的基于 Transformer 的模型在资源受限的情况下表现更好。在适配器结构中，GRN 在准确率、精确度、召回率和 F1 得分 0.88 方面表现出色。此外，LLM 的总训练时间超过 1000 小时，而基于更简单的 Transformer 的模型则不到 6 小时，这突显出 LLM 更适合具有大量计算资源和更大数据集的环境。因此，这项研究表明，基于 Transformer 的更简单的模型可以从头开始有效地进行训练，为数据可用性有限的低资源环境中的临床 NLP 任务提供了可行的解决方案。通过将 GRN 确定为最有效的适配器结构，我们提供了一种实用的方法来增强临床记录分类，而无需大量计算资源。]]></description>
      <guid>https://arxiv.org/abs/2407.19299</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:36 GMT</pubDate>
    </item>
    <item>
      <title>IBMEA：探索多模态实体对齐的变分信息瓶颈</title>
      <link>https://arxiv.org/abs/2407.19302</link>
      <description><![CDATA[arXiv:2407.19302v1 公告类型：新
摘要：多模态实体对齐（MMEA）旨在识别多模态知识图谱（MMKG）之间的等效实体，其中实体可以与相关图像相关联。大多数现有研究严重依赖自动学习的融合模块来集成多模态信息，很少明确抑制 MMEA 的冗余信息。为此，我们探索了多模态实体对齐（IBMEA）的变分信息瓶颈，它在生成实体表示时强调与对齐相关的信息并抑制与对齐无关的信息。具体而言，我们设计了多模态变分编码器来生成特定于模态的实体表示作为概率分布。然后，我们提出了四个特定于模态的信息瓶颈正则化器，限制了细化特定于模态的实体表示中的误导线索。最后，我们提出了一种模态混合信息对比正则化器来整合所有改进的模态特定表示，增强 MMKG 之间的实体相似性以实现 MMEA。我们在两个跨 KG 和三个双语 MMEA 数据集上进行了广泛的实验。实验结果表明，我们的模型始终优于以前的最先进方法，并且在低资源和高噪声数据场景中也表现出良好且稳健的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.19302</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:36 GMT</pubDate>
    </item>
    <item>
      <title>有害操纵的图像在多模态错误信息检测中很重要</title>
      <link>https://arxiv.org/abs/2407.19192</link>
      <description><![CDATA[arXiv:2407.19192v1 公告类型：新
摘要：如今，虚假信息在各种社交媒体平台上广泛传播，对社会造成了极其负面的影响。为了解决这个问题，自动识别虚假信息，尤其是包含多模态内容的虚假信息，引起了学术界和工业界越来越多的关注，并引发了一个活跃的研究课题，即多模态虚假信息检测（MMD）。通常，现有的 MMD 方法会捕获多种模态之间的语义相关性和不一致性，但忽略了多模态内容中的一些潜在线索。最近的研究表明，文章中图像的操纵痕迹是检测虚假信息的重要线索。同时，我们发现操纵背后的潜在意图，例如有害和无害，在 MMD 中也很重要。因此，在这项工作中，我们建议通过学习指示图像是否被操纵的操纵特征以及关于操纵的有害和无害意图的意图特征来检测虚假信息。不幸的是，使这些特征具有区分性的操纵和意图标签尚不清楚。为了解决这个问题，我们提出了两个弱监督信号作为替代方案，即在图像操纵检测中引入额外的数据集，并将两个分类任务制定为正向和未标记的学习问题。基于这些想法，我们提出了一种新颖的 MMD 方法，即 MMD 中的有害操纵图像问题 (HAMI-M3D)。在三个基准数据集上进行的大量实验可以证明 HAMI-M3D 可以持续提高任何 MMD 基线的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.19192</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么会产生虚假信息？通过整合意图特征来检测虚假信息</title>
      <link>https://arxiv.org/abs/2407.19196</link>
      <description><![CDATA[arXiv:2407.19196v1 公告类型：新
摘要：各种社交媒体平台，例如Twitter和Reddit，使人们能够更高效，更便捷地传播大量信息。然而，它们不可避免地充斥着错误信息，对我们日常生活的各个方面造成损害。为了减少负面影响，及时识别错误信息，即错误信息检测（MD），已成为一个受到广泛关注的活跃研究课题。作为一种复杂现象，文章的真实性受到多方面的影响。在本文中，我们受到错误信息和真实信息之间意图对立的启发。据此，我们提出推理文章的意图并形成相应的意图特征以促进文章特征的真实性鉴别。为此，我们参考现有的心理学理论为错误信息和真实信息构建了一组意图的层次结构，并将其应用于推理文章的意图，通过使用编码器-解码器结构逐步生成二进制答案。我们形成相应的意图特征并将其与 token 特征相结合，以实现更具判别性的文章特征，用于 MD。基于这些想法，我们提出了一种新颖的 MD 方法，即通过整合意图特征检测错误信息 (DM-INTER)。为了评估 DM-INTER 的性能，我们在基准 MD 数据集上进行了广泛的实验。实验结果验证了 DM-INTER 可以优于现有的基线 MD 方法。]]></description>
      <guid>https://arxiv.org/abs/2407.19196</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:35 GMT</pubDate>
    </item>
    <item>
      <title>代表利益相关者：法学硕士时代的 NLP 模型可解释性趋势</title>
      <link>https://arxiv.org/abs/2407.19200</link>
      <description><![CDATA[arXiv:2407.19200v1 公告类型：新
摘要：NLP 系统的最新进展，尤其是 LLM 的引入，已导致各个领域的广泛用户广泛采用这些系统，影响决策、就业市场、社会和科学研究。这种使用量的激增导致 NLP 模型可解释性和分析研究的激增，并伴随着大量技术调查。然而，这些调查往往忽视了解释利益相关者的需求和观点。在本文中，我们讨论了三个基本问题：我们为什么需要可解释性，我们在解释什么，以及如何解释？通过探索这些问题，我们研究了现有的可解释性范式、它们的属性及其与不同利益相关者的相关性。我们通过分析过去十年多个研究领域的趋势，进一步探索这些范式的实际意义。为此，我们检索了数千篇论文并使用 LLM 来描述它们。我们的分析揭示了 NLP 开发人员和非开发人员用户之间以及研究领域之间存在的显著差异，凸显了利益相关者的多样化需求。例如，在 NLP 领域之外，很少使用内部模型组件的解释。我们希望本文能够为未来符合各利益相关者目标和要求的方法的设计、开发和应用提供参考。]]></description>
      <guid>https://arxiv.org/abs/2407.19200</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:35 GMT</pubDate>
    </item>
    <item>
      <title>OfficeBench：跨办公自动化多个应用程序的基准语言代理</title>
      <link>https://arxiv.org/abs/2407.19056</link>
      <description><![CDATA[arXiv:2407.19056v1 公告类型：新
摘要：办公自动化通过自动完成工作流程中的日常任务，显著提高了人类的生产力。除了之前许多文档 AI 文献中研究的基本信息提取之外，办公自动化研究还应扩展到更现实的办公任务，这些任务需要整合办公系统中的各种信息源，并通过一系列决策过程产生输出。我们介绍了 OfficeBench，这是首批用于评估当前 LLM 代理在现实办公工作流程中处理办公任务的能力的办公自动化基准之一。OfficeBench 要求 LLM 代理根据工作流程的上下文需求，执行可行的长期规划，及时熟练地在应用程序之间切换，并准确地在大型组合动作空间内执行其操作。将我们定制的评估方法应用于每个任务，我们发现 GPT-4 Omni 的最高通过率为 47.00%，在处理办公任务方面表现出色。然而，这仍然远远低于现实世界办公工作流程所要求的人类表现和准确性标准。我们进一步观察到，大多数问题都与操作冗余和幻觉以及在多个应用程序之间切换的限制有关，这可能为开发有效的办公自动化代理框架提供宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2407.19056</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:34 GMT</pubDate>
    </item>
    <item>
      <title>用于分子逆向设计的多样本情境学习</title>
      <link>https://arxiv.org/abs/2407.19089</link>
      <description><![CDATA[arXiv:2407.19089v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种生成和判别化学设计任务的少样本上下文学习 (ICL) 中表现出色。LLM 新扩展的上下文窗口可以进一步提高 ICL 的分子逆向设计和先导优化能力。为了充分利用这些能力，我们开发了一种新的半监督学习方法，克服了多样本 ICL 缺乏实验数据的问题。我们的方法包括迭代包含具有高预测性能的 LLM 生成的分子以及实验数据。我们进一步将我们的方法集成到多模态 LLM 中，允许使用文本指令交互式修改生成的分子结构。正如我们所展示的，新方法大大改进了现有的分子设计 ICL 方法，同时方便科学家使用。]]></description>
      <guid>https://arxiv.org/abs/2407.19089</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:34 GMT</pubDate>
    </item>
    <item>
      <title>解决跨主题评估中作者身份验证的主题泄漏问题</title>
      <link>https://arxiv.org/abs/2407.19164</link>
      <description><![CDATA[arXiv:2407.19164v1 公告类型：新
摘要：作者验证 (AV) 旨在确定一对文本是否具有相同的作者。我们解决了评估 AV 模型对主题变化的鲁棒性的挑战。传统评估假设训练和测试数据之间的主题重叠最小。然而，我们认为测试数据中仍然可能存在主题泄漏，导致模型性能误导和排名不稳定。为了解决这个问题，我们提出了一种称为异质性知情主题采样 (HITS) 的评估方法，它创建一个具有异质分布主题集的较小数据集。我们的实验结果表明，HITS 采样的数据集在随机种子和评估分割中产生更稳定的模型排名。我们的贡献包括：1. 主题泄漏的原因和影响分析。 2. HITS 在减少主题泄漏影响方面的演示，以及 3. 稳健作者验证基准 (RAVEN) 允许主题快捷测试揭示 AV 模型对特定主题特征的依赖。]]></description>
      <guid>https://arxiv.org/abs/2407.19164</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:34 GMT</pubDate>
    </item>
    <item>
      <title>FarSSiBERT：一种基于 Transformer 的新型波斯语社交网络非正式文本语义相似度测量模型</title>
      <link>https://arxiv.org/abs/2407.19173</link>
      <description><![CDATA[arXiv:2407.19173v1 公告类型：新
摘要：NLP 的一项基本任务是确定两个文本之间的相似性并评估它们的相似程度。以前针对波斯语的方法准确率较低，无法有效理解文本的结构和含义。此外，这些方法主要侧重于正式文本，但在文本处理的实际应用中，需要能够处理口语文本的稳健方法。这需要基于上下文而不是仅仅考虑单词频率的算法来考虑单词的结构和重要性。由于波斯语缺乏适合此任务的数据集，因此开发此类算法并构建波斯语文本数据集非常重要。本文介绍了一种新的基于 Transformer 的模型，用于测量来自社交网络的波斯语非正式短文本之间的语义相似性。此外，为此目的构建了一个名为 FarSSiM 的波斯语数据集，使用来自社交网络的真实数据并由语言专家团队手动注释和验证。所提出的模型涉及使用 BERT 架构从头开始训练大型语言模型。该模型称为 FarSSiBERT，已在来自社交网络的大约 1.04 亿篇波斯语非正式短文本上进行了预训练，使其成为波斯语中独一无二的模型。此外，还提供了一种新颖的专门的非正式语言标记器，它不仅可以很好地对正式文本进行标记，还可以准确识别其他波斯语标记器无法识别的标记。事实证明，我们提出的模型在 Pearson 和 Spearman 系数标准中优于 ParsBERT、laBSE 和多语言 BERT。此外，预训练的大型语言模型在口语文本的其他 NLP 任务中以及作为鲜为人知的非正式词汇的标记器方面具有巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.19173</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:34 GMT</pubDate>
    </item>
    <item>
      <title>利用少量元提示优化硬提示</title>
      <link>https://arxiv.org/abs/2407.18920</link>
      <description><![CDATA[arXiv:2407.18920v1 公告类型：新
摘要：提示是一种灵活且适应性强的向大型语言模型 (LLM) 提供指令的方式。上下文提示包括文档或对话形式的上下文以及对 LLM 的自然语言指令，通常会限制 LLM 在遵守指令的同时将事实限制在给定上下文中。屏蔽上下文，它充当提示的模板。在本文中，我们提出了一种迭代方法，使用 LLM 从现有的一组提示模板中生成更好的模板，而无需向 LLM 透露上下文。探索了使用 LLM 本身优化提示的多种方法，以检查少量样本采样方法对迭代传播的影响，同时保持语言风格和语法对提示模板的优化，使用最佳表现方法可获得 103.87% 的改进。多个上下文任务的结果比较表明 LLM 能够在学习复制语言风格的同时保持语法。此外，还展示了不同的提示模板生成方法对输出的影响。]]></description>
      <guid>https://arxiv.org/abs/2407.18920</guid>
      <pubDate>Wed, 31 Jul 2024 03:15:33 GMT</pubDate>
    </item>
    </channel>
</rss>