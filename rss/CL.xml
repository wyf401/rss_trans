<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 04 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>将通用人工智能应用于专业医疗人工智能的前景及其挑战</title>
      <link>https://arxiv.org/abs/2411.00024</link>
      <description><![CDATA[arXiv:2411.00024v1 公告类型：新 
摘要：大型语言模型 (LLM) 与医疗应用的集成引起了整个医疗行业的广泛兴趣，从药物发现和开发到临床决策支持、协助远程医疗、医疗设备和医疗保险应用。这篇观点论文旨在讨论构建由 LLM 驱动的医疗 AI 应用程序的内部工作原理，并介绍一个全面的开发框架。我们回顾现有文献并概述在专门的医疗环境中应用 LLM 的独特挑战。此外，我们引入了一个三步框架来组织医学 LLM 研究活动：1) 建模：将复杂的医疗工作流程分解为可管理的步骤，以开发特定于医疗的模型；2) 优化：通过精心设计的提示优化模型性能并集成外部知识和工具，3) 系统工程：将复杂任务分解为子任务并利用人类专业知识来构建医疗 AI 应用程序。此外，我们还提供了详细的用例手册，其中描述了各种由 LLM 支持的医疗 AI 应用程序，例如优化临床试验设计、增强临床决策支持和推进医学影像分析。最后，我们讨论了使用 LLM 构建医疗 AI 应用程序的各种挑战和注意事项，例如处理幻觉问题、数据所有权和合规性、隐私、知识产权注意事项、计算成本、可持续性问题和负责任的 AI 要求。]]></description>
      <guid>https://arxiv.org/abs/2411.00024</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的个性化：一项调查</title>
      <link>https://arxiv.org/abs/2411.00027</link>
      <description><![CDATA[arXiv:2411.00027v1 公告类型：新
摘要：大型语言模型 (LLM) 的个性化最近变得越来越重要，应用范围广泛。尽管个性化 LLM 非常重要且最近取得了进展，但大多数现有的关于个性化 LLM 的研究要么完全集中在 (a) 个性化文本生成，要么 (b) 利用 LLM 进行个性化相关的下游应用，例如推荐系统。在这项工作中，我们首次通过引入个性化 LLM 使用的分类法并总结主要差异和挑战来弥合这两个独立主要方向之间的差距。我们提供了个性化 LLM 基础的形式化，巩固和扩展了 LLM 个性化的概念，定义和讨论了个性化、使用和个性化 LLM 需求的新方面。然后，我们通过提出个性化粒度、个性化技术、数据集、评估方法和个性化 LLM 应用的系统分类法，将这些不同领域和使用场景中的文献统一起来。最后，我们强调了尚待解决的挑战和重要未解决的问题。通过使用建议的分类法统一和调查最近的研究，我们旨在为现有文献和 LLM 个性化的不同方面提供清晰的指南，从而增强研究人员和从业人员的能力。]]></description>
      <guid>https://arxiv.org/abs/2411.00027</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>协同 LLM 代理和知识图谱进行 LBSN 中的社会经济预测</title>
      <link>https://arxiv.org/abs/2411.00028</link>
      <description><![CDATA[arXiv:2411.00028v1 公告类型：新
摘要：基于位置的社交网络 (LBSN) 的快速发展导致了社会的重大变化，导致使用 LBSN 数据进行社会经济预测（例如区域人口和商业活动估计）的研究很受欢迎。现有研究设计了各种图来建模异构 LBSN 数据，并进一步将图表示学习方法应用于社会经济预测。然而，这些方法严重依赖启发式思想和专业知识从各种数据中提取与任务相关的知识，这可能不是特定任务的最佳选择。此外，它们往往忽视不同指标之间的内在关系，从而限制了预测准确性。受大型语言模型 (LLM) 在常识推理、嵌入和多智能体协作方面的卓越能力的启发，在这项工作中，我们将 LLM 智能体和知识图谱协同起来进行社会经济预测。我们首先构建一个基于位置的知识图 (LBKG) 来集成多源 LBSN 数据。然后，我们利用 LLM 代理的推理能力来识别 LBKG 中与每种社会经济预测任务相关的元路径，并设计一个语义引导的注意模块来与元路径进行知识融合。此外，我们引入了一种跨任务通信机制，通过在 LLM 代理和 KG 级别实现跨任务知识共享来进一步提高性能。一方面，不同任务的 LLM 代理协作以生成更多样化和全面的元路径。另一方面，来自不同任务的嵌入被自适应地合并以实现更好的社会经济预测。在两个数据集上的实验证明了 LLM 和 KG 之间协同设计的有效性，为跨社会经济预测任务的信息共享提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2411.00028</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>保留预训练的表示空间：论前缀调整对大型多模态模型的有效性</title>
      <link>https://arxiv.org/abs/2411.00029</link>
      <description><![CDATA[arXiv:2411.00029v1 公告类型：新
摘要：最近，我们观察到大型多模态模型 (LMM) 正在彻底改变机器与世界互动的方式，为各种多模态应用开启新的可能性。为了使 LMM 适应下游任务，仅训练附加前缀标记或模块的参数高效微调 (PEFT) 已变得流行。然而，关于 PEFT 在 LMM 中的工作原理的分析很少。在本文中，我们深入研究了每种调整策略的优缺点，将重点从通常与这些方法相关的效率转移开。我们首先发现模型参数调整方法（例如 LoRA 和适配器）会扭曲在预训练期间学习的特征表示空间并限制预训练知识的充分利用。我们还证明，尽管前缀调整在下游任务上的性能较低，但它在保留表示空间方面表现出色。这些发现表明，一种简单的两步 PEFT 策略（称为前缀调整 PEFT (PT-PEFT)）结合了两者的优点，该策略依次执行前缀调整，然后执行 PEFT（即适配器、LoRA）。实验结果表明，与原始 PEFT 方法相比，PT-PEFT 不仅提高了图像字幕和视觉问答的性能，而且还有助于保留四个预训练模型的表示空间。]]></description>
      <guid>https://arxiv.org/abs/2411.00029</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WikiNER-fr-gold：黄金标准 NER 语料库</title>
      <link>https://arxiv.org/abs/2411.00030</link>
      <description><![CDATA[arXiv:2411.00030v1 公告类型：新
摘要：我们在本文中讨论了 WikiNER 语料库（一种多语言命名实体识别语料库）的质量，并提供了它的合并版本。WikiNER 的注释是以半监督的方式生成的，即事后没有进行任何人工验证。这种语料库被称为银标准。在本文中，我们提出了 WikiNER-fr-gold，它是 WikiNER 法语部分的修订版。我们的语料库由随机抽样的 20% 的原始法语子语料库（26,818 个句子，700k 个标记）组成。我们首先总结每个类别中包含的实体类型，以定义注释指南，然后我们继续修改语料库。最后，我们对 WikiNER-fr 语料库中观察到的错误和不一致性进行了分析，并讨论了未来的潜在工作方向。]]></description>
      <guid>https://arxiv.org/abs/2411.00030</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们的聊天机器人在撒谎吗？评估基于法学硕士的荷兰语支持聊天机器人的正确性</title>
      <link>https://arxiv.org/abs/2411.00034</link>
      <description><![CDATA[arXiv:2411.00034v1 公告类型：新
摘要：公司使用实时聊天和聊天机器人为客户提供支持，以赢得他们的忠诚度。AFAS 是一家荷兰公司，旨在利用大型语言模型 (LLM) 提供的机会，以极少甚至没有来自客户支持团队的输入来回答客户查询。增加了其复杂性，不清楚什么使响应正确，而且在荷兰语中也是如此。此外，由于可用于训练的数据很少，挑战在于确定大型语言模型生成的答案是否正确并即时执行。
这项研究是第一个根据 AFAS 支持团队的决策方式来定义响应的正确性的研究。它利用自然语言生成和自动答案评分系统的文献来自动化客户支持团队的决策。我们调查了需要二元响应的问题（例如，是否可以手动调整税率？）或指令（例如，我如何手动调整税率？）以测试我们的自动化方法与支持评级的接近程度。我们的方法可以在 55% 的情况下识别出错误消息。这项工作表明，自动评估我们的聊天机器人何时撒谎是可行的。]]></description>
      <guid>https://arxiv.org/abs/2411.00034</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>主题对话相关性 (TCR) 数据集和基准</title>
      <link>https://arxiv.org/abs/2411.00038</link>
      <description><![CDATA[arXiv:2411.00038v1 公告类型：新
摘要：工作场所会议对于组织协作至关重要，但很大一部分会议被评为无效。为了通过了解对话是否围绕主题来帮助提高会议效率，我们创建了一个全面的主题对话相关性 (TCR) 数据集，涵盖各种领域和会议风格。TCR 数据集包括 1,500 次独特的会议、2200 万字的记录和超过 15,000 个会议主题，这些主题来自新收集的语音中断会议 (SIM) 数据和现有的公共数据集。除了文本数据外，我们还开源脚本来生成合成会议或从 TCR 数据集创建增强会议以增强数据多样性。对于每个数据源，使用 GPT-4 创建基准来评估模型在理解转录主题相关性方面的准确性。]]></description>
      <guid>https://arxiv.org/abs/2411.00038</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>线性链变换：扩展优化动力学以微调大型语言模型</title>
      <link>https://arxiv.org/abs/2411.00039</link>
      <description><![CDATA[arXiv:2411.00039v1 公告类型：新
摘要：微调大型语言模型 (LLM) 已成为将预训练模型适应特定下游任务的关键。在本文中，我们提出了线性链变换 (LinChain)，这是一种在微调过程中引入一系列线性变换以丰富优化动态的新方法。通过将多个线性变换纳入参数更新过程，LinChain 扩展了更新的有效秩并增强了模型学习复杂任务特定表示的能力。我们证明，通过在训练期间提供更灵活的优化路径，该方法显著提高了 LLM 微调相对于最先进方法的性能，同时保持了结果模型的推理效率。我们在各种基准任务上的实验表明，LinChain 可以实现更好的泛化、更少的可学习参数和更好的任务适应性，使其成为 LLM 微调的有力策略。]]></description>
      <guid>https://arxiv.org/abs/2411.00039</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NeuroSym-BioCAT：利用神经符号方法进行生物医学学术文献分类和问答</title>
      <link>https://arxiv.org/abs/2411.00041</link>
      <description><![CDATA[arXiv:2411.00041v1 公告类型：新
摘要：生物医学学术文献摘要的数量不断增长，对有效检索准确和相关信息提出了越来越大的挑战。为了解决这个问题，我们引入了一种新方法，将优化的主题建模框架 OVB-LDA 与 BI-POP CMA-ES 优化技术相结合，以增强学术文献摘要分类。除此之外，我们还采用了经过微调的精简 MiniLM 模型，该模型针对特定领域的数据进行了微调，以实现高精度答案提取。我们的方法在三种配置中进行评估：学术文献摘要检索、黄金标准学术文献摘要和黄金标准片段，其表现始终优于 RYGH 和生物答案查找器等成熟方法。值得注意的是，我们证明仅从学术文献摘要中提取答案就可以获得高精度，这强调了摘要对于许多生物医学查询的充分性。尽管 MiniLM 体积小巧，但其性能却极具竞争力，挑战了只有大型、资源密集型模型才能处理如此复杂任务的普遍观念。我们的结果已在各种问题类型和评估批次中得到验证，凸显了我们的方法在现实世界生物医学应用中的稳健性和适应性。虽然我们的方法很有前景，但我们发现在处理复杂的列表类型问题和评估指标不一致方面存在挑战。未来的工作将侧重于使用更广泛的领域特定数据集来完善主题模型，进一步优化 MiniLM 并利用大型语言模型 (LLM) 来提高生物医学问答的准确性和效率。]]></description>
      <guid>https://arxiv.org/abs/2411.00041</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>问题分类可以帮助大型语言模型解决数学问题</title>
      <link>https://arxiv.org/abs/2411.00042</link>
      <description><![CDATA[arXiv:2411.00042v1 公告类型：新
摘要：在本文中，我们探讨了如何优化大型语言模型的使用，以快速准确地解决数学问题。特别是，我们展示了使用将问题分类为不同类别以促进解决问题的有效性。此外，我们通过创建准确的数据集来优化将问题分类为类别。我们相信，我们的解决问题的技术通过帮助减轻 LLM 中的幻觉而起作用，这是释放他们解决数学问题的能力的关键。]]></description>
      <guid>https://arxiv.org/abs/2411.00042</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MIMIC-IV-Ext-PE：使用大型语言模型预测 MIMIC-IV 数据集中的肺栓塞表型</title>
      <link>https://arxiv.org/abs/2411.00044</link>
      <description><![CDATA[arXiv:2411.00044v1 公告类型：新
摘要：肺栓塞 (PE) 是可预防的住院死亡的主要原因。诊断、风险分层和预防方面的进步可以改善结果。很少有大型公开可用的数据集包含用于研究的 PE 标签。使用 MIMIC-IV 数据库，我们提取了所有可用的计算机断层肺血管造影 (CTPA) 扫描放射学报告，两名医生手动将结果标记为 PE 阳性（急性 PE）或 PE 阴性。然后，我们应用了之前微调的 Bio_ClinicalBERT 转换器语言模型 VTE-BERT 来自动提取标签。我们通过测量 VTE-BERT 与人工裁决的性能来验证其可靠性。我们还将 VTE-BERT 的性能与诊断代码进行了比较。我们发现，对于急诊室和/或住院期间出具 CTPA 放射学报告的所有 19,942 名患者，VTE-BERT 的灵敏度为 92.4%，阳性预测值 (PPV) 为 87.8%。相比之下，对于出院诊断代码为 11,990 名住院患者的子集，诊断代码的灵敏度为 95.4%，PPV 为 83.8%。我们成功地在公开数据集中为 CTPA 添加了近 20,000 个标签，并证明了半监督语言模型在加速血液学研究方面的外部有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.00044</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于心理测量学的新型方法，用于开发大型语言模型的专业能力基准</title>
      <link>https://arxiv.org/abs/2411.00045</link>
      <description><![CDATA[arXiv:2411.00045v1 公告类型：新
摘要：大型语言模型 (LLM) 时代不仅提出了如何训练模型的问题，还提出了如何评估模型的问题。尽管现有的基准众多，但人们往往没有足够重视创建以有效和可靠的方式测试 LLM 的评估。为了应对这一挑战，我们采用了以证据为中心的设计 (ECD) 方法，并提出了一种基于严格心理测量原则的基准开发的综合方法。在本文中，我们首次尝试通过在教育学和教育领域创建一个新的基准来说明这种方法，强调现有基准开发方法的局限性并考虑到 LLM 的发展。我们得出结论，需要一种新的基准测试方法来匹配教育环境中日益复杂的人工智能应用。我们构建了一个由布鲁姆分类法指导的新基准，并由一组接受过测试开发培训的教育专家联盟严格设计。因此，当前的基准为 LLM 而非人类参与者提供了一种学术上稳健且实用的评估工具。通过对俄语 GPT 模型进行实证测试，它评估了不同任务复杂性中的模型性能，揭示了当前 LLM 能力中的关键差距。我们的结果表明，虽然生成式 AI 工具对教育具有重大前景——可能支持个性化辅导、实时反馈和多语言学习等任务——但它们作为自主教师助手的可靠性目前仍然相当有限，特别是在需要更深入认知参与的任务中。]]></description>
      <guid>https://arxiv.org/abs/2411.00045</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CurateGPT：一种灵活的语言模型辅助生物管理工具</title>
      <link>https://arxiv.org/abs/2411.00046</link>
      <description><![CDATA[arXiv:2411.00046v1 公告类型：新
摘要：有效的数据驱动的生物医学发现需要数据管理：这是一个耗时的过程，需要查找、组织、提炼、集成、解释、注释和验证各种信息，使其成为适合数据库和知识库的结构化形式。准确高效地管理这些数字资产对于确保它们公平、可信和可持续至关重要。不幸的是，专家策展人面临着巨大的时间和资源限制。每天发布的新信息的速度之快超出了他们的策展能力。以指令调整的大型语言模型 (LLM) 为代表的生成式人工智能为协助人类驱动的策展开辟了新的可能性。代理的设计理念将生成式人工智能的新兴能力与更精确的方法相结合。代理可以帮助策展人执行推理、搜索本体和跨外部来源集成知识的任务，否则所有这些工作都需要大量的手动工作。我们的 LLM 驱动注释工具 CurateGPT 将生成式 AI 的强大功能与值得信赖的知识库和文献来源融合在一起。CurateGPT 简化了策展流程，增强了常见工作流程中的协作和效率。与直接与 LLM 交互相比，CurateGPT 的代理可以访问 LLM 训练数据以外的信息，并提供支持每个声明的数据的直接链接。这有助于策展人、研究人员和工程师扩大策展工作，以跟上不断增长的科学数据量。]]></description>
      <guid>https://arxiv.org/abs/2411.00046</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>循序渐进：通过扩大词汇量自信地学习</title>
      <link>https://arxiv.org/abs/2411.00049</link>
      <description><![CDATA[arXiv:2411.00049v1 公告类型：新
摘要：在本文中，我们提出了一种创新的迭代规则学习方法，该方法专门针对（但不限于）基于文本的数据而设计。我们的方法侧重于逐步扩大每次迭代中使用的词汇量，从而显着减少内存消耗。此外，我们引入了置信度值作为生成规则可靠性的指标。通过利用置信度值，我们的方法可确保仅保留最强大和最值得信赖的规则，从而提高规则学习过程的整体质量。我们通过对各种文本和非文本数据集进行大量实验证明了我们方法的有效性，其中包括保险行业非常感兴趣的用例，展示了其在现实世界中的应用潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.00049</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模型越大，结果越好？使用基于 BERT 的知识提炼简化 ADHD 相关问题的严重程度分类</title>
      <link>https://arxiv.org/abs/2411.00052</link>
      <description><![CDATA[arXiv:2411.00052v1 公告类型：新
摘要：这项工作重点关注知识蒸馏方法在为自然语言处理应用生成轻量级但功能强大的基于 BERT 的模型方面的效率。在创建模型后，我们将生成的模型 LastBERT 应用于现实世界的任务，该任务从社交媒体文本数据中对注意力缺陷多动障碍 (ADHD) 相关问题的严重程度进行分类。参考 LastBERT（一种定制的学生 BERT 模型），我们将模型参数从 1.1 亿 BERT 基数显着降低到 2900 万，从而使模型缩小了约 73.64%。在 GLUE 基准测试中，包括释义识别、情感分析和文本分类，尽管有所减少，但学生模型在许多任务中仍保持了强劲的表现。该模型还用于现实世界的 ADHD 数据集，准确率和 F1 得分为 85%。与 DistilBERT (66M) 和 ClinicalBERT (110M) 相比，LastBERT 表现出了相当的性能，DistilBERT 略胜一筹，为 87%，而 ClinicalBERT 在相同指标上达到 86%。这些发现凸显了 LastBERT 模型能够正确分类 ADHD 严重程度，因此它为心理健康专业人士提供了一个有用的工具来评估和理解用户在社交网络平台上制作的材料。这项研究强调了知识提炼的可能性，以产生适合在资源有限条件下使用的有效模型，从而促进 NLP 和心理健康诊断。此外，模型大小显着减小而性能没有明显损失，这强调了训练和部署所需的计算资源更少，从而促进了更大的适用性。特别是使用 Google Colab 等现成的计算工具。这项研究展示了高级 NLP 方法在实用世界应用中的可访问性和实用性。]]></description>
      <guid>https://arxiv.org/abs/2411.00052</guid>
      <pubDate>Mon, 04 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>