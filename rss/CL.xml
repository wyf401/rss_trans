<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 29 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>大型模型中的参数有效微调：方法论综述</title>
      <link>https://arxiv.org/abs/2410.19878</link>
      <description><![CDATA[arXiv:2410.19878v1 公告类型：新 
摘要：正如通过缩放原始预测所预测的那样，大型模型在许多领域取得了突破性的进展，特别是在自然语言生成任务中，它们已经接近甚至超越了人类的水平。然而，其参数规模空前庞大，带来了巨大的计算和存储成本。这些大型模型需要大量的计算资源和 GPU 内存才能运行。在将大型模型适配到特定的下游任务时，其庞大的参数规模对在计算能力和 GPU 内存有限的硬件平台上进行微调提出了重大挑战。为了解决这个问题，参数高效微调 (PEFT) 通过高效调整大型预训练模型的参数以适应各种下游任务提供了一种实用的解决方案。具体而言，PEFT 调整预训练大型模型的参数以适应特定任务或领域，最大限度地减少额外参数的引入和所需的计算资源。本综述主要介绍了PEFT的初步知识，各种PEFT算法的核心思想和原理，PEFT的应用以及未来潜在的研究方向。通过阅读本综述，我们相信感兴趣的人可以快速掌握PEFT方法论，从而加速其发展和创新。]]></description>
      <guid>https://arxiv.org/abs/2410.19878</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过词频分析进行批判性圣经研究：揭示文本作者</title>
      <link>https://arxiv.org/abs/2410.19883</link>
      <description><![CDATA[arXiv:2410.19883v1 公告类型：新
摘要：圣经是几个世纪以来广泛而复杂的口头书写传播过程的产物，它模糊了早期修订的轮廓。关于确定现有层次以及确定圣经文本的创作日期和历史背景的争论非常激烈。传统的手工方法通过严谨的文本批评，采用语言、文体、圣经内部和历史标准来解决作者身份挑战。尽管计算机辅助分析最近取得了进展，但圣经文本中仍有许多模式需要发现。在本研究中，我们通过对单词频率进行统计分析来解决圣经文本的作者身份问题，这种方法对可能许多单词中少数单词的频率偏差特别敏感。我们的目标是区分圣经前九本书中众多章节中的三位不同作者。具体来说，我们将根据圣经注释考虑而标记的 50 个章节分为三个语料库（D、DtrH 和 P）。我们的方法没有事先假设作者身份，而是利用词频的细微差别来区分这三个语料库并识别与作者相关的语言属性。我们的分析表明，前两位作者（D 和 DtrH）与 P 的关系更为密切，这一事实与专家的评估一致。此外，通过评估每个章节与参考语料库的相似性，我们在确定作者身份方面获得了很高的准确性。这项研究通过提供可解释的、具有统计意义的证据，表明圣经作者具有不同的语言特征，并且可以识别这些差异，为圣经文本的作者身份提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2410.19883</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>集成经过微调的语言模型进行文本分类</title>
      <link>https://arxiv.org/abs/2410.19889</link>
      <description><![CDATA[arXiv:2410.19889v1 公告类型：新
摘要：微调是不同社区中广泛使用的一种常见做法，用于将预训练模型适应特定任务。文本分类是这些任务之一，有许多预训练模型可用。另一方面，神经网络集成通常用于提高性能并提供可靠的不确定性估计。然而，将预训练模型集成用于文本分类并不是一个研究得很好的方法。在本文中，我们提供了一个元数据集，其中包含来自六个数据集上的五个大型微调模型的预测，并报告了这些预测的不同集成策略的结果。我们的结果揭示了集成如何提高微调文本分类器的性能并激励未来在这些任务中采用集成。]]></description>
      <guid>https://arxiv.org/abs/2410.19889</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用持续学习改进多模态大型语言模型</title>
      <link>https://arxiv.org/abs/2410.19925</link>
      <description><![CDATA[arXiv:2410.19925v1 公告类型：新
摘要：生成式大型语言模型 (LLM) 表现出令人印象深刻的功能，可以通过将预训练的视觉模型集成到原始 LLM 中以创建多模态 LLM (MLLM) 来进一步增强其功能。然而，与原始 LLM 相比，这种集成通常会显著降低自然语言理解和生成任务的性能。本研究使用 LLaVA MLLM 调查了这个问题，将集成视为一个持续学习问题。我们评估了五种持续学习方法来减轻遗忘，并确定了一种增强视觉理解同时最大限度地减少语言性能损失的技术。我们的方法与 LLaVA 配方相比，将语言性能下降降低了 15\%，同时保持了较高的多模态准确度。我们还通过对一系列视觉语言任务的持续学习证明了我们方法的稳健性，有效地保留了语言技能，同时获得了新的多模态能力。]]></description>
      <guid>https://arxiv.org/abs/2410.19925</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>离散自监督语音表示能捕捉音调区别吗？</title>
      <link>https://arxiv.org/abs/2410.19935</link>
      <description><![CDATA[arXiv:2410.19935v1 公告类型：新
摘要：从自监督学习 (SSL) 基础模型获得的语音离散表示被广泛使用，尤其是在下游任务数据有限的情况下，例如资源匮乏的语言。通常，将语音离散化为符号序列是通过对 SSL 模型中的潜在符号进行无监督聚类来实现的。我们的研究评估了使用 k 均值找到的离散符号是否足以捕捉两种示例语言普通话和约鲁巴语中的音调。我们将潜在向量与从 HuBERT 基础、MandarinHuBERT 或 XLS-R 获得的离散符号进行比较，以进行元音和音调分类。我们发现使用离散符号会导致音调信息大量丢失，即使对于语言专门的 SSL 模型也是如此。我们建议离散化需要具有任务感知能力，特别是对于音调相关的下游任务。]]></description>
      <guid>https://arxiv.org/abs/2410.19935</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>逐层探索：揭示指令调整大型语言模型中多任务学习的发生位置</title>
      <link>https://arxiv.org/abs/2410.20008</link>
      <description><![CDATA[arXiv:2410.20008v1 公告类型：新
摘要：在各种任务上对预训练的大型语言模型 (LLM) 进行微调已成为构建可解决各种自然语言处理 (NLP) 任务的模型的常用方法。但是，这些模型在哪里以及在多大程度上保留特定于任务的知识仍未得到充分探索。本研究调查了预训练的 LLM 中编码的任务特定信息以及指令调整对其在 60 多个 NLP 任务中的表示的影响。我们使用一组矩阵分析工具来检查预训练和指令调整的 LLM 存储任务特定信息的方式之间的差异。我们的研究结果表明，虽然某些任务已经在预训练的 LLM 中编码，但其他任务极大地受益于指令调整。此外，我们还确定了模型从高级通用表示过渡到更面向任务的表示的层。这一发现扩展了我们对 LLM 控制机制的理解，并有助于未来在参数高效迁移学习和多任务学习领域的研究。]]></description>
      <guid>https://arxiv.org/abs/2410.20008</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>小型语言模型综述</title>
      <link>https://arxiv.org/abs/2410.20011</link>
      <description><![CDATA[arXiv:2410.20011v1 公告类型：新
摘要：小型语言模型 (SLM) 因其效率和性能而变得越来越重要，它们能够以最少的计算资源执行各种语言任务，使其成为各种设置的理想选择，包括设备上、移动设备、边缘设备等。在本文中，我们对 SLM 进行了全面的调查，重点介绍了它们的架构、训练技术和模型压缩技术。我们提出了一种新颖的分类法来对用于优化 SLM 的方法进行分类，包括模型压缩、修剪和量化技术。我们总结了可用于对 SLM 进行基准测试的基准数据集以及常用的评估指标。此外，我们还强调了尚待解决的关键开放挑战。我们的调查旨在为有兴趣开发和部署小型但高效的语言模型的研究人员和从业者提供宝贵的资源。]]></description>
      <guid>https://arxiv.org/abs/2410.20011</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 易受垂直对齐文本操纵的影响</title>
      <link>https://arxiv.org/abs/2410.20016</link>
      <description><![CDATA[arXiv:2410.20016v1 公告类型：新
摘要：文本分类涉及对给定文本进行分类，例如确定其情绪或识别有害内容。随着大型语言模型 (LLM) 的进步，这些模型在执行文本分类任务方面变得非常有效。然而，它们仍然显示出对文本格式变化的脆弱性。最近的研究表明，修改输入格式（例如垂直对齐基于编码器的模型的单词）会大大降低文本分类任务的准确性。虽然这些输入很容易被人类理解，但它们可能会严重误导模型，在涉及有害或敏感信息的实际场景中存在绕过检测的潜在风险。随着 LLM 的应用不断扩大，一个关键问题出现了：基于解码器的 LLM 是否表现出与垂直格式的文本输入类似的脆弱性？在本文中，我们研究了垂直文本输入对多个文本分类数据集中各种 LLM 性能的影响，并分析了其根本原因。我们的发现如下：(i) 垂直文本输入会显著降低 LLM 在文本分类任务中的准确性。 (ii) 思路链 (CoT) 推理无助于 LLM 识别垂直输入或减轻其脆弱性，但经过仔细分析的少量学习可以。 (iii) 我们通过分析标记化和注意力矩阵中的固有问题来探索脆弱性的根本原因。]]></description>
      <guid>https://arxiv.org/abs/2410.20016</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过引导偏差和影响函数对抽象文本摘要模型进行攻击</title>
      <link>https://arxiv.org/abs/2410.20019</link>
      <description><![CDATA[arXiv:2410.20019v1 公告类型：新
摘要：大型语言模型为文本理解和生成带来了新的机会。然而，它们容易受到对抗性扰动和数据中毒攻击，特别是在文本分类和翻译等任务中。然而，抽象文本摘要模型的对抗性鲁棒性仍然没有得到充分探索。在这项工作中，我们揭示了一种新方法，即利用摘要模型中固有的引导偏差来执行对抗性扰动。此外，我们引入了一种影响函数的创新应用，以执行数据中毒，从而损害模型的完整性。这种方法不仅显示了模型行为在产生期望结果方面的偏差，而且还显示了新的行为变化，即受到攻击的模型倾向于生成提取摘要而不是抽象摘要。]]></description>
      <guid>https://arxiv.org/abs/2410.20019</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>仔细思考并再次检查！元生成解锁低资源跨语言摘要的 LLM</title>
      <link>https://arxiv.org/abs/2410.20021</link>
      <description><![CDATA[arXiv:2410.20021v1 公告类型：新
摘要：跨语言摘要 (CLS) 旨在为不同目标语言的源文本生成摘要。目前，指令调整的大型语言模型 (LLM) 在各种英语任务中表现出色。然而，与英语、中文或西班牙语等语言不同，对于那些使用或数据有限的相对低资源语言，最近的研究表明，即使在少样本设置下，LLM 在 CLS 任务上的表现仍然不令人满意。这就提出了一个问题：LLM 是否能够处理低资源语言的跨语言摘要任务？为了解决这个问题，我们通过我们的四步零样本方法充分探索大型语言模型在低资源语言跨语言摘要任务上的潜力：总结、改进、翻译和细化 (SITR) 以及相应设计的提示。我们在两个著名的跨语言摘要数据集上使用多个 LLM 测试了我们提出的方法，这些数据集包含各种资源较少的目标语言。结果表明：i) 使用我们的零样本 SITR 方法时，GPT-3.5 和 GPT-4 显著且持续地优于其他基线。ii) 通过采用我们提出的方法，我们释放了 LLM 的潜力，使它们能够有效地处理资源相对较少的语言的跨语言摘要任务。]]></description>
      <guid>https://arxiv.org/abs/2410.20021</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>仅解码器的 Transformer 中的动态层选择</title>
      <link>https://arxiv.org/abs/2410.20022</link>
      <description><![CDATA[arXiv:2410.20022v1 公告类型：新
摘要：大型语言模型 (LLM) 的庞大规模促使人们寻求优化推理。一种有效的方法是动态推理，它使架构适应手头的样本以降低总体计算成本。我们通过实证研究了两种常见的自然语言生成 (NLG) 动态推理方法：层跳过和提前退出。我们发现，与提前退出相比，预训练的仅解码器模型对通过层跳过进行的层删除具有更高的鲁棒性。我们证明了使用隐藏状态信息来调整每个标记基础上的计算以进行层跳过的难度。最后，我们表明，通过构建 oracle 控制器，基于每个序列的动态计算分配有望显着提高效率。值得注意的是，我们发现存在一种分配，它平均仅使用 23.3% 的层即可实现与完整模型相同的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.20022</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越微调：缓解数据分析大型语言模型中幻觉的有效策略</title>
      <link>https://arxiv.org/abs/2410.20024</link>
      <description><![CDATA[arXiv:2410.20024v1 公告类型：新
摘要：大型语言模型 (LLM) 在自然语言处理中变得越来越重要，可通过自然语言查询实现高级数据分析。然而，这些模型通常会产生“幻觉”——不准确或虚假的信息——这可能会破坏它们在关键数据驱动决策中的可靠性。解决幻觉的挑战对于提高 LLM 在处理自然语言查询时的准确性和可信度至关重要。这项研究的重点是减轻 LLM 中的幻觉，特别是在数据分析的背景下。我们介绍并评估了四种有针对性的策略：结构化输出生成、严格规则执行、系统提示增强和语义层集成。我们的研究结果表明，这些方法比传统的微调方法更有效地减少幻觉，为在数据分析的自然语言查询中部署 LLM 提供了更可靠的框架。这项研究证明了这些策略提高 LLM 驱动数据查询准确性的潜力，确保在数据驱动环境中获得更可靠的结果。]]></description>
      <guid>https://arxiv.org/abs/2410.20024</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 GPT-4 检测土木工程中的建筑缺陷</title>
      <link>https://arxiv.org/abs/2410.20036</link>
      <description><![CDATA[arXiv:2410.20036v1 公告类型：新
摘要：人工智能 (AI) 在土木工程中的应用为提高设计质量和安全性提供了一种变革性方法。本文探讨了先进的 LLM GPT4 Turbo 视觉模型在设​​计阶段检测建筑缺陷的潜力，特别侧重于识别缺失的门窗。该研究通过精度、召回率和 F1 分数等指标评估模型的性能，证明了与人工验证的数据相比，AI 在准确检测缺陷方面的有效性。此外，该研究还探索了 AI 更广泛的功能，包括识别承重问题、材料弱点以及确保符合建筑规范。研究结果强调了 AI 如何显着提高设计准确性、减少昂贵的修订并支持可持续实践，最终通过确保更安全、更高效和美观优化的结构彻底改变土木工程领域。]]></description>
      <guid>https://arxiv.org/abs/2410.20036</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RARe：使用上下文示例进行检索增强检索</title>
      <link>https://arxiv.org/abs/2410.20088</link>
      <description><![CDATA[arXiv:2410.20088v1 公告类型：新
摘要：我们研究了在仅解码器语言模型 (LLM) 中广泛使用的上下文示例是否可以提高嵌入模型在检索任务中的性能。与 LLM 不同，在推理时将上下文示例（查询-文档对）简单地添加到目标查询之前并不能立即发挥作用。我们引入了一种简单的方法，使检索器能够使用上下文示例。我们的方法 RARe 使用上下文示例对预训练模型进行微调，其查询在语义上与目标查询相似。这可以应用于适应各种基础架构（即仅解码器语言模型、检索器模型），并在各种开放域检索数据集（BeIR、RAR-b）中持续实现高达 +2.72% nDCG 的性能提升。具体而言，我们发现与使用没有上下文示例的查询的模型相比，RARe 表现出更强的域外泛化能力，类似于 LLM 中的上下文学习。我们进一步分析了上下文示例增强的设计选择，并为该领域的未来工作奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2410.20088</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混合深度学习用于法律文本分析：预测印度尼西亚法院判决中的刑罚期限</title>
      <link>https://arxiv.org/abs/2410.20104</link>
      <description><![CDATA[arXiv:2410.20104v1 公告类型：新
摘要：公众对法律程序的了解有限，以及印度尼西亚法院系统的判决不一致，导致法官普遍不满，压力增加。本研究通过开发基于深度学习的法院判决长度预测系统来解决这些问题。我们的混合模型结合了 CNN 和 BiLSTM 与注意机制，实现了 0.5893 的 R 平方得分，有效地捕捉了法律文本中的局部模式和长期依赖关系。虽然文档摘要被证明是无效的，但仅使用前 30% 最常见的标记可以提高预测性能，这表明关注核心法律术语可以平衡信息保留和计算效率。我们还实施了修改后的文本规范化过程，解决了拼写错误和错误合并的单词等常见错误，这显著提高了模型的性能。这些发现对于自动化法律文件处理具有重要意义，有助于专业人士和公众理解法院判决。通过利用先进的 NLP 技术，这项研究有助于提高印度尼西亚法律体系的透明度和可及性，为更加一致和易理解的法律决策铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2410.20104</guid>
      <pubDate>Tue, 29 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>