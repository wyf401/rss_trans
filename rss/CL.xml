<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 14 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于生物医学实体和关系提取的广义知识增强框架</title>
      <link>https://arxiv.org/abs/2408.06618</link>
      <description><![CDATA[arXiv:2408.06618v1 公告类型：新
摘要：近年来，为生物医学实体和关系提取开发的框架越来越多。这项研究旨在解决生物医学出版物的加速增长和生物医学文本的复杂性，这些文本主要为领域专家撰写。为了应对这些挑战，我们开发了一个新颖的框架，该框架利用外部知识构建独立于任务且可重复使用的背景知识图，用于生物医学实体和关系提取。我们模型的设计灵感来自人类如何学习特定领域的主题。特别是，人类通常首先获取有关某个领域的最基本和最常见的知识来构建基础知识，然后以此为基础扩展到各种专门主题。我们的框架采用这种常识共享机制来构建一个通用的神经网络知识图，该图可以有效地学习转移到不同领域的特定生物医学文本。实验评估表明，我们的模型配备了这种通用的、可交叉转移的知识库，达到了具有竞争力的性能基准，包括用于结合相互作用检测的 BioRelEx 和用于药物不良反应识别的 ADE。]]></description>
      <guid>https://arxiv.org/abs/2408.06618</guid>
      <pubDate>Wed, 14 Aug 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>IFShip：通过领域知识增强指令调整实现可解释细粒度船舶分类的大型视觉语言模型</title>
      <link>https://arxiv.org/abs/2408.06631</link>
      <description><![CDATA[arXiv:2408.06631v1 公告类型：新
摘要：端到端解释是目前遥感细粒度船舶分类 (RS-FGSC) 任务的主流范式。然而，它的推理过程是不可解释的，导致它作为黑箱模型受到批评。为了解决这个问题，我们提出了一个名为 IFShip 的大型视觉语言模型 (LVLM)，用于可解释的细粒度船舶分类。与传统方法不同，IFShip 通过用自然语言准确地传达 FGSC 的推理过程，在可解释性方面表现出色。具体来说，我们首先设计了一个领域知识增强的思维链 (COT) 提示生成机制。该机制用于半自动构建一个名为 TITANIC-FGS 的任务特定指令跟踪数据集，它模拟类似人类的逻辑决策。然后，我们使用针对 TITANIC-FGS 数据集调整的任务指令来训练 IFShip 模型。基于 IFShip，我们开发了一个 FGSC 可视化聊天机器人，将 FGSC 问题重新定义为分步推理任务，并以自然语言传达推理过程。实验结果表明，所提出的方法在分类可解释性和准确性方面都超越了最先进的 FGSC 算法。此外，与 LLaVA 和 MiniGPT-4 等 LVLM 相比，我们的方法在 FGSC 任务中表现出卓越的专业性。当人眼可以识别细粒度的船舶类型时，它可以提供准确的推理链，而当人眼无法识别时，它可以提供可解释的解释。]]></description>
      <guid>https://arxiv.org/abs/2408.06631</guid>
      <pubDate>Wed, 14 Aug 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型、智能机器和知识获取的视角</title>
      <link>https://arxiv.org/abs/2408.06598</link>
      <description><![CDATA[arXiv:2408.06598v1 公告类型：新 
摘要：大型语言模型 (LLM) 以其生成合成“知识”的卓越能力而闻名，例如文本文档、音乐、图像等。然而，LLM 与人类理解抽象概念和推理的能力之间存在巨大差距。我们在人类知识获取和图灵测试的更大哲学背景下讨论这些问题。此外，我们通过分析 GPT-4 对从科学和数学到常识推理等问题的回答来说明 LLM 的局限性。这些例子表明，GPT-4 通常可以模仿人类的推理，即使它缺乏理解。然而，LLM 响应是从对所有可用数据进行训练的大型 LLM 模型合成的。相比之下，人类的理解基于少数抽象概念。基于这种区别，我们讨论了 LLM 对人类知识和教育获取的影响。]]></description>
      <guid>https://arxiv.org/abs/2408.06598</guid>
      <pubDate>Wed, 14 Aug 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>通过结构感知生成提取生物医学事件</title>
      <link>https://arxiv.org/abs/2408.06583</link>
      <description><![CDATA[arXiv:2408.06583v1 公告类型：新
摘要：生物医学事件提取 (BEE) 是一项关键任务，涉及对生物医学文本数据中细粒度实体之间的复杂关系进行建模。然而，大多数现有的 BEE 模型依赖于忽略数据中的标签语义和参数依赖结构的分类方法。为了解决这些限制，我们提出了 GenBEE，这是一种增强了结构感知前缀的生成模型，用于生物医学事件提取。GenBEE 构建事件提示，利用从大型语言模型 (LLM) 中提取的知识，从而结合标签语义和参数依赖关系。此外，GenBEE 引入了一个结构前缀学习模块，该模块使用结构提示生成结构感知前缀，通过结构特征丰富了生成过程。在三个基准数据集上进行的大量实验证明了 GenBEE 的有效性，并且它在 MLEE 和 GE11 数据集上实现了最先进的性能。此外，我们的分析表明，结构前缀有效地弥合了结构提示和生成模型的表示空间之间的差距，从而更好地整合事件结构信息。]]></description>
      <guid>https://arxiv.org/abs/2408.06583</guid>
      <pubDate>Wed, 14 Aug 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>CTISum：网络威胁情报汇总的新基准数据集</title>
      <link>https://arxiv.org/abs/2408.06576</link>
      <description><![CDATA[arXiv:2408.06576v1 公告类型：新
摘要：网络威胁情报 (CTI) 摘要任务要求系统从原始情报数据中生成简洁准确的亮点，这在为决策者提供关键信息以快速检测和应对网络安全领域的网络威胁方面发挥着重要作用。然而，由于缺乏可用的数据集，用于总结 CTI 报告（包括事实、分析见解、攻击过程等）的有效技术在很大程度上尚未得到探索。为此，我们提出了 CTISum，这是 CTI 摘要任务的新基准。考虑到攻击过程的重要性，提出了一种新的攻击过程摘要细粒度子任务，使防御者能够评估风险、识别安全漏洞、漏洞等。具体来说，我们首先设计一个多阶段注释管道来收集和注释 CTI 数据，然后使用一组提取和抽象摘要方法对 CTISum 进行基准测试。实验结果表明，当前最先进的模型在应用于 CTISum 时表现出局限性，强调了自动生成 CTI 报告的简洁摘要仍然是一个悬而未决的研究挑战。]]></description>
      <guid>https://arxiv.org/abs/2408.06576</guid>
      <pubDate>Wed, 14 Aug 2024 06:19:59 GMT</pubDate>
    </item>
    <item>
      <title>OpenEP：开放式未来事件预测</title>
      <link>https://arxiv.org/abs/2408.06578</link>
      <description><![CDATA[arXiv:2408.06578v1 公告类型：新 
摘要：未来事件预测（FEP）是世界上一项长期存在且至关重要的任务，因为了解事件的演变可以实现早期风险识别、明智决策和战略规划。现有工作通常将事件预测视为分类任务，并将未来事件的结果限制在固定范围内，例如是/否问题、候选集和分类法，难以涵盖未来事件的所有可能结果。在本文中，我们介绍了 OpenEP（一种开放式未来事件预测任务），它可以生成与现实场景相一致的灵活多样的预测。这主要体现在两个方面：首先，预测问题多种多样，涵盖事件发展的不同阶段和观点；其次，结果灵活，不受范围或格式的限制。为了方便对该任务的研究，我们构建了开放式未来事件预测数据集 OpenEPBench。对于问题构建，我们从地点、时间、事件发展、事件结果、事件影响、事件响应和其他七个角度提出问题，以便深入分析和理解事件的全面演变。对于结果构建，我们收集包含结果的自由格式文本作为基本事实，以提供语义完整且细节丰富的结果。此外，我们提出了 StkFEP，这是一个利益相关者增强的未来事件预测框架，它结合了开放式设置的事件特征。我们的方法提取事件中涉及的利益相关者来扩展问题以收集各种信息。我们还收集与问题相关且相似的历史事件，以揭示潜在的演变模式。实验结果表明，准确预测开放式设置中的未来事件对于现有的 LLM 来说具有挑战性。]]></description>
      <guid>https://arxiv.org/abs/2408.06578</guid>
      <pubDate>Wed, 14 Aug 2024 06:19:59 GMT</pubDate>
    </item>
    <item>
      <title>公平的多模式法学硕士的社会偏见消除</title>
      <link>https://arxiv.org/abs/2408.06569</link>
      <description><![CDATA[arXiv:2408.06569v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 取得了长足进步，提供了强大的视觉语言理解能力。然而，这些模型往往从训练数据集中继承了严重的社会偏见，导致基于种族和性别等属性的不公平预测。本文通过以下方式解决了 MLLM 中的社会偏见问题：i) 引入一个全面的具有多种社会概念的反事实数据集 (CMSC)，与现有数据集相比，它提供了更多样化和更广泛的训练集。ii) 提出一种反刻板印象去偏见策略 (ASD)。我们的方法通过重新审视 MLLM 训练过程、重新调整自回归损失函数和改进数据采样方法来抵消偏见。通过对各种 MLLM 进行大量实验，我们的 CMSC 数据集和 ASD 方法在保持模型原有性能的同时，显著减少了社会偏见。]]></description>
      <guid>https://arxiv.org/abs/2408.06569</guid>
      <pubDate>Wed, 14 Aug 2024 06:19:58 GMT</pubDate>
    </item>
    <item>
      <title>SparkRA：基于 Spark 大语言模型的检索增强知识服务系统</title>
      <link>https://arxiv.org/abs/2408.06574</link>
      <description><![CDATA[arXiv:2408.06574v1 公告类型：新
摘要：大型语言模型（LLM）在各种语言任务中都取得了显著的成就。为了提高LLM在科学文献服务中的表现，我们在科大讯飞Spark LLM的基础上，通过对科学文献进行预训练和监督微调，开发了科学文献LLM（SciLit-LLM）。此外，我们基于SciLit-LLM提出了一个知识服务系统Spark Research Assistant（SparkRA）。SparkRA可以在线访问，提供三大主要功能：文献调查、论文阅读和学术写作。截至2024年7月30日，SparkRA已拥有超过5万名注册用户，总使用次数超过130万次。]]></description>
      <guid>https://arxiv.org/abs/2408.06574</guid>
      <pubDate>Wed, 14 Aug 2024 06:19:58 GMT</pubDate>
    </item>
    <item>
      <title>AquilaMoE：通过扩展和扩展策略高效训练 MoE 模型</title>
      <link>https://arxiv.org/abs/2408.06567</link>
      <description><![CDATA[arXiv:2408.06567v1 公告类型：新
摘要：近年来，随着大型语言模型在各个领域的快速应用，这些模型的规模逐渐增大，其预训练所需的资源也呈指数级增长。从头开始训练 LLM 将耗费大量的计算资源，而从较小的模型向上扩展是一种更有效的方法，因此引起了广泛关注。在本文中，我们提出了 AquilaMoE，这是一种尖端的双语 8*16B 混合专家 (MoE) 语言模型，该模型有 8 位专家，每位专家有 160 亿个参数，并使用一种名为 EfficientScale 的创新训练方法开发。该方法通过两阶段过程优化性能，同时最小化数据要求。第一阶段称为 Scale-Up，使用预先训练的小模型中的权重初始化较大的模型，从而能够以更少的数据进行大量的知识转移和持续的预训练。第二阶段 Scale-Out 使用预训练的密集模型初始化 MoE 专家，进一步增强知识迁移和性能。在 1.8B 和 7B 模型上进行了广泛的验证实验，比较了各种初始化方案，实现了在持续预训练期间保持和减少损失的模型。利用最优方案，我们成功训练了 16B 模型，随后又训练了 8*16B AquilaMoE 模型，性能和训练效率均有显著提升。]]></description>
      <guid>https://arxiv.org/abs/2408.06567</guid>
      <pubDate>Wed, 14 Aug 2024 06:19:57 GMT</pubDate>
    </item>
    <item>
      <title>使用法学硕士进行战略链规划：将心理治疗对话的生成与动机访谈中的策略相结合</title>
      <link>https://arxiv.org/abs/2408.06527</link>
      <description><![CDATA[arXiv:2408.06527v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展已显示出在生成心理治疗对话方面的前景，尤其是在动机访谈 (MI) 中。然而，如何运用策略（一组动机访谈 (MI) 技能）来生成具有可解释性的治疗性对话尚未得到充分探索。我们提出了一种称为策略感知对话生成的方法，该方法使用策略链 (CoS) 规划，首先将 MI 策略预测为推理，并利用这些策略来指导后续的对话生成。它通过将生成的 MI 对话与治疗策略相结合，为心理治疗中的可控制和可解释生成带来了潜力。进行了包括自动和人工评估在内的大量实验，以验证 MI 策略的有效性。我们的研究结果证明了 LLM 在产生战略一致的对话方面的潜力，并为心理治疗环境中的实际应用提供了方向。]]></description>
      <guid>https://arxiv.org/abs/2408.06527</guid>
      <pubDate>Wed, 14 Aug 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>介绍 NewsPaLM MBR 和 QE 数据集：LLM 生成的高质量并行数据优于传统的 Web 爬取数据</title>
      <link>https://arxiv.org/abs/2408.06537</link>
      <description><![CDATA[arXiv:2408.06537v1 公告类型：新
摘要：神经机器翻译 (NMT) 的最新研究表明，对高质量机器生成数据的训练可以胜过对人类生成数据的训练。这项工作伴随着首次发布的 LLM 生成、MBR 解码和 QE 重新排序的数据集，其中包含句子级和多句子示例。我们进行了大量实验来证明我们的数据集的质量，包括其对 NMT 模型性能的下游影响。我们发现，从头开始对我们的（机器生成的）数据集进行训练的效果优于对（网络爬取的）WMT&#39;23 训练数据集（大 300 倍）进行训练，并且也优于对 WMT&#39;23 训练数据集的顶级质量子集进行训练。我们还发现，通过微调生成此数据集的 LLM 进行自我蒸馏的效果优于 LLM 强大的少量样本基线。这些发现证实了我们数据集的质量，并证明了高质量机器生成数据在提高 NMT 模型性能方面的价值。]]></description>
      <guid>https://arxiv.org/abs/2408.06537</guid>
      <pubDate>Wed, 14 Aug 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>喜欢黄色就意味着开校车吗？语言模型中的语义泄漏</title>
      <link>https://arxiv.org/abs/2408.06518</link>
      <description><![CDATA[arXiv:2408.06518v1 公告类型：新
摘要：尽管语言模型被广泛采用，但其偏见和意外行为仍然鲜为人知。在本文中，我们识别并描述了一种从未讨论过的现象，我们称之为语义泄漏，即模型以意想不到的方式将提示中的不相关信息泄漏到生成中。我们提出了一种评估设置来检测人工和自动的语义泄漏，策划了一个用于诊断这种行为的多样化测试套件，并测量了 13 个旗舰模型中的显着语义泄漏。我们还表明，模型在英语以外的语言中以及在不同的环境和生成场景中都表现出语义泄漏。这一发现凸显了语言模型中影响其生成模式和行为的另一种偏见。]]></description>
      <guid>https://arxiv.org/abs/2408.06518</guid>
      <pubDate>Wed, 14 Aug 2024 06:19:55 GMT</pubDate>
    </item>
    <item>
      <title>TOGGL：使用交错标记转录重叠语音</title>
      <link>https://arxiv.org/abs/2408.06474</link>
      <description><![CDATA[arXiv:2408.06474v1 公告类型：新
摘要：转录多个重叠说话者的语音通常需要将音频分离成多个流并独立识别每个流。最近的工作联合分离和转录，但需要为每个说话者提供单独的解码组件。我们提出了 TOGGL 模型来同时转录多个说话者的语音。TOGGL 模型使用特殊的输出标记将语音归因于每个说话者，仅使用一个解码器。我们的方法可以推广到两个说话者之外，即使只在两个说话者的数据上进行训练也是如此。与对话语音数据集上的竞争方法相比，我们展示了卓越的性能。我们的方法还提高了单扬声器音频的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.06474</guid>
      <pubDate>Wed, 14 Aug 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行跨语言会话语音摘要</title>
      <link>https://arxiv.org/abs/2408.06484</link>
      <description><![CDATA[arXiv:2408.06484v1 公告类型：新
摘要：跨语言对话语音摘要是一个重要问题，但资源匮乏。虽然许多语言都有转录本，但翻译的对话语音很少，而且包含摘要的数据集也不存在。我们在现有的 Fisher 和 Callhome 西班牙语-英语语音翻译语料库的基础上，为翻译补充了摘要。摘要是使用 GPT-4 从参考翻译中生成的，并被视为基本事实。任务是在存在转录和翻译错误的情况下生成类似的摘要。我们使用开源语音识别和机器翻译模型构建了一个基于基线级联的系统。我们测试了一系列 LLM 进行摘要，并分析了转录和翻译错误的影响。针对此任务调整 Mistral-7B 模型的性能明显优于现成的模型，并且与 GPT-4 的性能相匹配。]]></description>
      <guid>https://arxiv.org/abs/2408.06484</guid>
      <pubDate>Wed, 14 Aug 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>评估表格中实体歧义消除的语言模型</title>
      <link>https://arxiv.org/abs/2408.06423</link>
      <description><![CDATA[arXiv:2408.06423v1 公告类型：新摘要：表格是重要的信息容器，但理解其含义可能具有挑战性。事实上，最近人们一直关注语义表解释（STI），即涉及对表格数据进行语义注释以消除其含义歧义的任务。多年来，人们对基于深度学习的数据驱动方法的兴趣激增，这些方法越来越多地与基于启发式的方法相结合。在过去一段时间里，大型语言模型（LLM）的出现导致了表格注释新方法的出现。人们对这个以多重挑战为特征的研究领域的兴趣导致了采用不同技术的方法的激增。然而，这些方法并没有在共同的基础上得到一致的评估，使得评估和比较变得困难。这项工作提出了对四种最先进的（SOTA）方法的广泛评估——Alligator（以前称为 s-elBat）、Dagobah、TURL 和 TableLlama；前两种属于启发式算法，其他分别是仅编码器和仅解码器的 LLM。主要目标是衡量这些方法解决实体消歧任务的能力，最终目的是在该领域开辟新的研究路径。]]></description>
      <guid>https://arxiv.org/abs/2408.06423</guid>
      <pubDate>Wed, 14 Aug 2024 06:19:53 GMT</pubDate>
    </item>
    </channel>
</rss>