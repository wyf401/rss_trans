<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 19 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>优化性能：紧凑模型如何通过微调达到或超越 GPT 的分类能力</title>
      <link>https://arxiv.org/abs/2409.11408</link>
      <description><![CDATA[arXiv:2409.11408v1 公告类型：新
摘要：在本文中，我们证明，非生成式小型模型（例如 FinBERT 和 FinDRoBERTa）在经过微调后，在金融新闻情绪分析的零样本学习环境中可以胜过 GPT-3.5 和 GPT-4 模型。这些经过微调的模型在根据彭博社提供的每日金融新闻摘要确定市场情绪的任务上表现出与 GPT-3.5 相当的结果。为了微调和比较这些模型，我们创建了一个新颖的数据库，该数据库为每条新闻分配一个市场分数，而没有人类的解释偏见，系统地识别所提及的公司并分析它们的股票是上涨、下跌还是保持中性。此外，本文表明，孔多塞陪审团定理的假设不成立，这表明微调的小模型并不独立于微调的 GPT 模型，表明行为相似。最后，经过微调的模型在 HuggingFace 上公开发布，为进一步研究金融情绪分析和文本分类提供资源。]]></description>
      <guid>https://arxiv.org/abs/2409.11408</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型丰富人口统计数据数据集：名字意味着什么？</title>
      <link>https://arxiv.org/abs/2409.11491</link>
      <description><![CDATA[arXiv:2409.11491v1 公告类型：新
摘要：利用姓名中的性别、种族和年龄等人口统计信息丰富数据集是医疗保健、公共政策和社会科学等领域的一项关键任务。此类人口统计洞察可以更精确、更有效地与目标人群互动。尽管之前曾尝试采用隐马尔可夫模型和循环神经网络根据姓名预测人口统计数据，但仍然存在重大限制：缺乏大规模、精心策划、无偏见、公开可用的数据集，以及缺乏跨数据集稳健的方法。这种稀缺性阻碍了传统监督学习方法的发展。在本文中，我们证明了大型语言模型 (LLM) 的零样本能力可以与在专门数据上训练的定制模型一样好，甚至更好。我们将这些 LLM 应用于各种数据集，包括香港持牌金融专业人士的真实、未标记数据集，并批判性地评估这些模型中固有的人口统计偏差。我们的工作不仅推动了人口统计学丰富化的最新进展，而且为未来减轻法学硕士偏见的研究开辟了道路。]]></description>
      <guid>https://arxiv.org/abs/2409.11491</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于多文档的多轮合成对话生成</title>
      <link>https://arxiv.org/abs/2409.11500</link>
      <description><![CDATA[arXiv:2409.11500v1 公告类型：新
摘要：我们介绍了一种基于多文档的多轮合成对话生成技术，该技术结合了三个主要思想。首先，我们使用分类驱动的用户查询来控制整体对话流，这些查询是通过思维链 (CoT) 提示生成的。其次，我们通过模仿现实世界中检索器的使用来支持基于多文档的对话的生成，以便在对话中的每个用户回合后更新基础文档。第三，我们应用 LLM-as-a-Judge 来过滤掉带有错误答案的查询。人工对合成对话数据的评估表明，数据是多样的、连贯的，并且大部分包含正确的答案。对可回答查询的人工和自动评估都表明，在四个公开可用的多轮文档基准测试集上，对合成对话进行微调的模型始终优于对现有人工生成的训练数据进行微调的模型。]]></description>
      <guid>https://arxiv.org/abs/2409.11500</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言模型中的平等语言表征：一切始于标记器</title>
      <link>https://arxiv.org/abs/2409.11501</link>
      <description><![CDATA[arXiv:2409.11501v1 公告类型：新
摘要：标记器充当人类语言和语言模型潜在空间之间的桥梁，影响语言在这些模型中的表示方式。由于以英语为中心的大型语言模型 (LLM) 非常流行，人们正在努力将其应用于其他语言。然而，我们证明，从标记化的角度来看，并非所有标记器都能为复杂的脚本语言（如泰米尔语、僧伽罗语和印地语）提供公平的表示，这主要是由于预标记方法的选择。我们进一步表明，在实现这些复杂脚本语言的平等表示方面，预标记比标记算法本身发挥着更为关键的作用。为了解决这个问题，我们通过结合字素对字节对编码 (BPE) 算法进行了改进，我们称之为字素对编码 (GPE)。我们的实验表明，基于字素的字符提取优于复杂脚本的字节级标记器。我们通过对泰米尔语、僧伽罗语和印地语的实验验证了这种方法。]]></description>
      <guid>https://arxiv.org/abs/2409.11501</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语音翻译的思路链提示</title>
      <link>https://arxiv.org/abs/2409.11538</link>
      <description><![CDATA[arXiv:2409.11538v1 公告类型：新
摘要：大型语言模型 (LLM) 在语言理解和生成方面取得了显著的进步。在基于文本的 LLM 成功的基础上，最近的研究已经调整了这些模型以使用语音嵌入进行提示，从而产生了在自动语音识别 (ASR) 和自动语音翻译 (AST) 中表现出色性能的 Speech-LLM 模型。在这项工作中，我们提出了一种新方法，利用 ASR 转录作为基于编码器-解码器文本 LLM 构建的 Speech-LLM 中的 AST 提示。Speech-LLM 模型由语音编码器和编码器-解码器结构 Megatron-T5 组成。通过首先解码语音以生成 ASR 转录，然后使用这些转录以及编码语音进行提示，我们以类似思路链 (CoT) 提示的两步过程指导语音翻译。低秩自适应 (LoRA) 用于 T5 LLM 进行模型自适应，并且表现出优于完整模型微调的性能。实验结果表明，提出的 CoT 提示显著提高了 AST 性能，与单独的语音提示相比，在 6 个 En-&gt;X 或 X-&gt;En AST 任务中平均提高了 2.4 个 BLEU 点。此外，与预测 ASR 和 AST 转录连接序列的相关 CoT 预测方法相比，我们的方法平均提高了 2 个 BLEU 点。]]></description>
      <guid>https://arxiv.org/abs/2409.11538</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>小型语言模型在短篇创意写作方面的表现可以超越人类：一项将 SLM 与人类和 LLM 进行比较的研究</title>
      <link>https://arxiv.org/abs/2409.11547</link>
      <description><![CDATA[arXiv:2409.11547v1 公告类型：新
摘要：在本文中，我们评估了经过微调的小型语言模型 (SLM) BART Large 的创意小说写作能力，并将其性能与人类和两个大型语言模型 (LLM)：GPT-3.5 和 GPT-4o 进行比较。我们的评估包括两个实验：(i) 人工评估，读者评估 SLM 生成的故事与人类撰写的故事；(ii) 定性语言分析，比较不同模型生成的故事的文本特征。在第一个实验中，我们要求 68 名参与者从语法、相关性、创造力和吸引力等维度对模型和人类生成的短篇小说进行评分。BART Large 在创造力以外的大多数方面都优于人类作家，总分为 2.11，而人类撰写的文本为 1.85，提高了 14%。在第二个实验中，定性分析显示，虽然 GPT-4o 表现出近乎完美的内部和外部连贯性，但它倾向于产生更可预测的叙述，只有 3% 的故事被视为新颖。相比之下，BART 的故事中有 15% 被认为是新颖的，这表明尽管模型规模较小，但创造力程度更高。这项研究提供了定量和定性的见解，说明模型大小和微调如何影响创意写作任务中的创造力、流畅性和连贯性之间的平衡。]]></description>
      <guid>https://arxiv.org/abs/2409.11547</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在语言、语音和视觉任务中使用人类反馈进行偏好调整：一项调查</title>
      <link>https://arxiv.org/abs/2409.11564</link>
      <description><![CDATA[arXiv:2409.11564v1 公告类型：新
摘要：偏好调整是将深度生成模型与人类偏好对齐的关键过程。本调查全面概述了偏好调整和人类反馈整合方面的最新进展。本文分为三个主要部分：1）介绍和准备工作：介绍强化学习框架、偏好调整任务、模型和跨各种模态的数据集：语言、语音和视觉，以及不同的策略方法，2）深入研究每种偏好调整方法：详细分析偏好调整中使用的方法，3）应用、讨论和未来方向：探索偏好调整在下游任务中的应用，包括不同模态的评估方法，以及对未来研究方向的展望。我们的目标是介绍偏好调整和模型对齐方面的最新方法，增强研究人员和从业者对该领域的理解。我们希望鼓励该领域的进一步参与和创新。]]></description>
      <guid>https://arxiv.org/abs/2409.11564</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HEARTS：可解释、可持续且强大的文本刻板印象检测整体框架</title>
      <link>https://arxiv.org/abs/2409.11579</link>
      <description><![CDATA[arXiv:2409.11579v1 公告类型：新
摘要：刻板印象是对社会群体的普遍假设，即使是使用情境学习的最先进的法学硕士也难以准确识别它们。由于刻板印象的主观性，即构成刻板印象的因素会因文化、社会和个人观点的不同而有很大差异，因此强大的可解释性至关重要。可解释的模型确保这些细微的判断能够被人类用户理解和验证，从而促进信任和责任感。我们通过引入 HEARTS（可解释、可持续和强大的文本刻板印象检测整体框架）来应对这些挑战，该框架可提高模型性能、最大限度地减少碳足迹并提供透明、可解释的解释。我们建立了扩展多粒度刻板印象数据集 (EMGSD)，包含六个群体的 57,201 个标记文本，包括代表性不足的人口统计数据，如 LGBTQ+ 和地区刻板印象。消融研究证实，在 EMGSD 上微调的 BERT 模型优于在单个组件上训练的模型。然后，我们使用 SHAP 分析经过微调的碳效率高的 ALBERT-V2 模型，以生成 token 级重要性值，确保与人类理解保持一致，并通过比较 SHAP 和 LIME 输出来计算可解释性置信度分数。最后，应用 HEARTS 评估 12 个 LLM 输出中的刻板偏见，发现模型系列中的偏见随着时间的推移逐渐减少。]]></description>
      <guid>https://arxiv.org/abs/2409.11579</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ProSLM：一种用于可解释领域特定知识问答的 Prolog 协同语言模型</title>
      <link>https://arxiv.org/abs/2409.11589</link>
      <description><![CDATA[arXiv:2409.11589v1 公告类型：新
摘要：神经符号方法可以通过合并可解释的符号表示来增加不透明神经系统的鲁棒性。然而，以前的方法没有使用形式逻辑将查询情境化并验证大型语言模型 (LLM) 的输出。我们提出了一种新颖的神经符号框架 \systemname{}，以提高 LLM 在问答任务中的鲁棒性和可靠性。我们为 \systemname{} 提供了一个领域特定的知识库、一个逻辑推理系统以及与现有 LLM 的集成。该框架有两种功能 (1) 上下文收集：为给定查询生成可解释和相关的上下文，以及 (2) 验证：根据知识库 (KB) 确认和验证陈述的事实准确性。我们的工作开辟了神经符号生成 AI 文本验证和用户个性化的新领域。]]></description>
      <guid>https://arxiv.org/abs/2409.11589</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>“女性比男性更了解文化？”：人物角色对法学硕士中文化规范解读的影响</title>
      <link>https://arxiv.org/abs/2409.11636</link>
      <description><![CDATA[arXiv:2409.11636v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的部署不断扩大，对个性化 LLM 的需求也日益增加。个性化和指导这些模型输出的一种方法是分配一个角色——一个描述 LLM 预期行为的角色（例如，男人、女人、工程师）。本研究调查了 LLM 对社会规范的理解是否因分配的角色而异。理想情况下，无论角色如何，对社会规范的看法都应该保持一致，因为社会规范的可接受性应该由规范起源的地区决定，而不是由性别、体型或种族等个人特征决定。规范在其文化背景下是普遍的。在我们的研究中，我们在四个不同的 LLM 中测试了来自 12 个社会人口类别（例如年龄、性别、美貌）的 36 个不同角色。我们发现，LLM 对文化规范的解读会因所使用的角色而异，并且规范解读也会因社会人口类别而异（例如，外表组中的胖人和瘦人），其中具有更受社会欢迎的角色（例如，瘦人）的 LLM 比具有不太受社会欢迎的角色（例如，胖人）的 LLM 更准确地解读社会规范。我们还讨论了不同类型的社会偏见如何影响我们观察到的结果。]]></description>
      <guid>https://arxiv.org/abs/2409.11636</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BanStereoSet：用于测量孟加拉语法学硕士课程中刻板社会偏见的数据集</title>
      <link>https://arxiv.org/abs/2409.11638</link>
      <description><![CDATA[arXiv:2409.11638v1 公告类型：新
摘要：本研究介绍了 BanStereoSet，这是一个旨在评估孟加拉语多语言法学硕士中的刻板社会偏见的数据集。为了将偏见研究的重点扩展到以英语为中心的数据集之外，我们对 StereoSet、IndiBias 和 Kamruzzaman 等人的数据集的内容进行了本地化，制作了一种专门用于捕捉孟加拉语社区中普遍存在的偏见的资源。我们的 BanStereoSet 数据集包含 1,194 个句子，涵盖 9 个偏见类别：种族、职业、性别、年龄歧视、美貌、职业美貌、地区、种姓和宗教。该数据集不仅是衡量多语言法学硕士偏见的重要工具，而且还有助于探索不同社会类别中的刻板偏见，有可能指导在孟加拉语环境中开发更公平的语言技术。我们使用该数据集对几种语言模型的分析表明存在明显的偏见，这进一步证明了需要适合文化和语言的数据集来开发更公平的语言技术。]]></description>
      <guid>https://arxiv.org/abs/2409.11638</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RUIE：基于检索的大型语言模型统一信息提取</title>
      <link>https://arxiv.org/abs/2409.11673</link>
      <description><![CDATA[arXiv:2409.11673v1 公告类型：新
摘要：统一信息提取 (UIE) 旨在使用单一模型或框架完成所有信息提取任务。虽然以前的工作主要集中在使用构建的数据集对大型语言模型 (LLM) 进行指令调整，但这些方法需要大量的计算资源，并且难以推广到看不见的任务。为了解决这些限制，我们提出了 RUIE（基于检索的统一信息提取），这是一个利用上下文学习实现快速泛化同时降低计算成本的框架。RUIE 的关键挑战是选择最有益的演示，以便 LLM 有效地处理各种 IE 任务。为了实现这一点，我们整合了 LLM 对排名候选演示的偏好，并设计了一个关键字增强奖励模型来捕捉查询和演示之间的细粒度关系。然后，我们通过对比学习和知识提炼为 UIE 训练一个双编码器检索器。据我们所知，RUIE 是第一个可训练的 UIE 检索框架。在 8 个保留数据集上的实验结果证明了 RUIE 在推广到未见任务方面的有效性，与指令调整方法和其他检索器相比，平均 F1 分数分别提高了 19.22 和 3.13。进一步的分析证实了 RUIE 对不同大小的 LLM 的适应性及其关键组件的重要性。]]></description>
      <guid>https://arxiv.org/abs/2409.11673</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用分层细节聚焦网络增强复杂公式识别</title>
      <link>https://arxiv.org/abs/2409.11677</link>
      <description><![CDATA[arXiv:2409.11677v1 公告类型：新
摘要：分层和复杂的数学表达式识别 (MER) 具有挑战性，因为公式可能有多种解释，使解析和评估都变得复杂。在本文中，我们介绍了分层细节聚焦识别数据集 (HDR)，这是第一个专门为解决这些问题而设计的数据集。它由一个大规模训练集 HDR-100M 组成，通过一亿个训练实例提供了前所未有的规模和多样性。测试集 HDR-Test 包括对复杂分层公式的多种解释，用于全面的模型性能评估。此外，复杂公式的解析通常会受到细粒度细节错误的影响。为了解决这个问题，我们提出了分层细节聚焦识别网络 (HDNet)，这是一个创新框架，它包含一个分层子公式模块，专注于公式细节的精确处理，从而显着提高 MER 性能。实验结果表明，HDNet 在各种数据集上的表现均优于现有的 MER 模型。]]></description>
      <guid>https://arxiv.org/abs/2409.11677</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用 LLM 进行 API 交互：分类和合成数据生成的框架</title>
      <link>https://arxiv.org/abs/2409.11703</link>
      <description><![CDATA[arXiv:2409.11703v1 公告类型：新
摘要：随着大型语言模型 (LLM) 在自然语言处理领域的进步，人们越来越有兴趣利用它们的功能来简化软件交互。在本文中，我们提出了一种集成 LLM 的新系统，用于将自然语言输入分类为相应的 API 调用，并自动创建针对特定 API 函数的样本数据集。通过对自然语言命令进行分类，我们的系统允许用户通过简单的输入来调用复杂的软件功能，从而提高交互效率并降低软件使用的门槛。我们的数据集生成方法还可以对不同 LLM 在分类 API 调用方面进行高效、系统的评估，为开发人员或企业主提供了一个实用的工具来评估 LLM 是否适合定制 API 管理。我们使用为各种 API 函数生成的样本数据集对几个著名的 LLM 进行了实验。结果表明，GPT-4 实现了 0.996 的高分类准确率，而 LLaMA-3-8B 的表现要差得多，为 0.759。这些发现凸显了 LLM 改变 API 管理的潜力，并验证了我们的系统在指导跨不同应用程序的模型测试和选择方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.11703</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从列表到表情符号：格式偏差如何影响模型对齐</title>
      <link>https://arxiv.org/abs/2409.11704</link>
      <description><![CDATA[arXiv:2409.11704v1 公告类型：新
摘要：在本文中，我们研究了从人类反馈 (RLHF) 中强化学习的格式偏差。我们观察到许多广泛使用的偏好模型，包括人类评估者、GPT-4 和 RewardBench 基准上的顶级模型，都对特定格式模式表现出强烈的偏见，例如列表、链接、粗体文本和表情符号。此外，大型语言模型 (LLM) 可以利用这些偏见在 AlpacaEval 和 LMSYS Chatbot Arena 等流行基准上获得更高的排名。一个值得注意的例子是冗长偏见，当前的偏好模型倾向于看起来更全面的较长响应，即使它们的质量等于或低于较短的竞争响应。然而，除了冗长之外的格式偏见在文献中仍然很少得到充分探索。在这项工作中，我们将偏好学习中的偏见研究扩展到普遍认可的长度偏见之外，对更广泛的格式偏见进行了全面的分析。此外，我们还表明，只需少量有偏差的数据（少于 1%），我们就可以向奖励模型注入显著的偏差。此外，这些格式偏差也很容易被下游对齐算法（如最佳 n 采样和在线迭代 DPO）利用，因为操纵格式通常比提高响应质量更容易。我们的研究结果强调，无论是在设计对齐算法还是在评估模型时，都需要解开格式和内容之间的联系。]]></description>
      <guid>https://arxiv.org/abs/2409.11704</guid>
      <pubDate>Thu, 19 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>