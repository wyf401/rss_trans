<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 26 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>DEXTER：使用 LLM 进行开放域复杂问答的基准</title>
      <link>https://arxiv.org/abs/2406.17158</link>
      <description><![CDATA[arXiv:2406.17158v1 公告类型：新
摘要：开放域复杂问答 (QA) 是一项艰巨的任务，在证据检索和推理方面面临挑战。此类问题的复杂性可能源于问题的组成、混合证据或问题的歧义性。虽然经典 QA 任务的检索性能已得到充分探索，但它们在异构复杂检索任务（尤其是在开放域环境中）中的能力以及对下游 QA 性能的影响相对尚未得到探索。为了解决这个问题，在这项工作中，我们提出了一个由各种复杂 QA 任务组成的基准，并提供了一个工具包来评估开放域环境中最先进的预训练密集和稀疏检索模型。我们观察到，与其他预训练的密集检索模型相比，后期交互模型和令人惊讶的词汇模型（如 BM25）表现良好。此外，由于基于上下文的推理对于解决复杂的 QA 任务至关重要，我们还评估了 LLM 的推理能力以及检索性能对其推理能力的影响。通过实验，我们观察到在复杂 QA 的检索方面还有很大的进步，以改善下游 QA 性能。我们的软件和相关数据可以在 https://github.com/VenkteshV/DEXTER 上访问]]></description>
      <guid>https://arxiv.org/abs/2406.17158</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:54 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行释义和聚合，以最大限度地减少意图分类错误</title>
      <link>https://arxiv.org/abs/2406.17163</link>
      <description><![CDATA[arXiv:2406.17163v1 公告类型：新
摘要：大型语言模型 (LLM) 在自然语言生成方面取得了显著的成功，但人们对其在分类等决策任务中的适用性关注较少。我们表明，像 LLaMa 这样的 LLM 可以在大型多类分类任务上实现高性能，但仍然会产生分类错误，更糟糕的是，会生成超出词汇量的类标签。为了解决这些关键问题，我们引入了释义和聚合 (PAG)-LLM 方法，其中 LLM 生成输入查询的多个释义（并行查询），对原始查询和每个释义执行多类分类，最后根据它们的置信度得分聚合所有分类标签。我们在两个大型多类分类数据集上评估了 PAG-LLM：CLINC 和 Banking，结果显示错误减少了 22.7% 和 15.1%。我们表明 PAG-LLM 对于 LLM 不确定的困难示例特别有效，并减少了关键的错误分类和幻觉标签生成错误]]></description>
      <guid>https://arxiv.org/abs/2406.17163</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:54 GMT</pubDate>
    </item>
    <item>
      <title>Multi-LogiEval：评估大型语言模型的多步逻辑推理能力</title>
      <link>https://arxiv.org/abs/2406.17169</link>
      <description><![CDATA[arXiv:2406.17169v1 公告类型：新
摘要：随着大型语言模型 (LLM) 在自然语言理解任务中继续表现出色，迫切需要衡量它们进行类似人类的多步逻辑推理的能力。现有的逻辑推理评估基准通常主要关注具有有限推理规则的简单单步或多步推理。此外，缺乏用于评估非单调推理的数据集代表了一个关键的差距，因为它与类似人类的推理更接近。为了解决这些限制，我们提出了 Multi-LogiEval，这是一个全面的评估数据集，涵盖具有各种推理规则和深度的多步逻辑推理。Multi-LogiEval 涵盖三种逻辑类型——命题、一阶和非单调——由 30 多个推理规则和 60 多个具有不同深度的组合组成。利用此数据集，我们采用零样本思维链对一系列 LLM 进行了评估，包括 GPT-4、ChatGPT、Gemini-Pro、Yi、Orca 和 Mistral。实验结果表明，随着推理步骤/深度的增加，LLM 的性能显著下降（深度 1 时的平均准确率约为 68%，深度 5 时的平均准确率约为 43%）。我们进一步对 LLM 生成的推理链进行了彻底调查，发现了几个重要发现。我们相信 Multi-LogiEval 有助于未来评估和增强 LLM 逻辑推理能力的研究。数据可在 https://github.com/Mihir3009/Multi-LogiEval 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.17169</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:54 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型假设人们比实际更理性</title>
      <link>https://arxiv.org/abs/2406.17055</link>
      <description><![CDATA[arXiv:2406.17055v1 公告类型：新
摘要：为了让人工智能系统与人类进行有效沟通，它们必须了解我们如何做出决策。然而，人们的决策并不总是理性的，因此大型语言模型 (LLM) 中人类决策的隐式内部模型必须考虑到这一点。先前的经验证据似乎表明这些隐式模型是准确的——LLM 提供了人类行为的可信代理，其行为方式与我们预期的人类在日常互动中的行为方式相同。然而，通过将 LLM 行为和预测与大量人类决策数据集进行比较，我们发现事实并非如此：在模拟和预测人们的选择时，一套前沿的 LLM（GPT-4o 和 4-Turbo、Llama-3-8B 和 70B、Claude 3 Opus）假设人们比我们实际更理性。具体来说，这些模型偏离了人类行为，更接近理性选择的经典模型——期望值理论。有趣的是，人们在解释他人的行为时也倾向于假设他人是理性的。因此，当我们使用另一个心理数据集比较法学硕士和人们从他人的决策中得出的推论时，我们发现这些推论高度相关。因此，法学硕士的隐性决策模型似乎与人类对其他人会理性行事的期望相一致，而不是与人们的实际行为相一致。]]></description>
      <guid>https://arxiv.org/abs/2406.17055</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:53 GMT</pubDate>
    </item>
    <item>
      <title>注意力指导：通过提示来增强中间注意力</title>
      <link>https://arxiv.org/abs/2406.17095</link>
      <description><![CDATA[arXiv:2406.17095v1 公告类型：新
摘要：大型语言模型的上下文窗口已扩展到 128k 个标记或更多。然而，由于缺乏注意力，语言模型仍然受到位置偏差的影响，并且难以访问和使用上下文的中间部分。我们研究了 LLM 的相对位置意识以及通过提示缓解不成比例的注意力的可行性。我们用 $\texttt{注意力指令}$ 增强了原始任务指令，指导语言模型将更多注意力分配给选定的上下文片段。我们对基于位置和基于索引的指令的多文档问答任务进行了全面的调查。我们发现语言模型不具有上下文的相对位置意识。然而，它们展示了使用匹配索引将注意力调整到特定片段的能力。我们的分析有助于更深入地理解 LLM 中的立场偏见，并提供一种通过指导来减轻这种偏见的途径，从而使 LLM 能够在 RAG 应用程序中查找和利用从检索到的文档中的相关信息。]]></description>
      <guid>https://arxiv.org/abs/2406.17095</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:53 GMT</pubDate>
    </item>
    <item>
      <title>安全分类器的自动对抗发现</title>
      <link>https://arxiv.org/abs/2406.17104</link>
      <description><![CDATA[arXiv:2406.17104v1 公告类型：新
摘要：安全分类器对于减轻社交媒体和聊天机器人等在线论坛上的毒性至关重要。尽管如此，它们仍然容易受到新兴的、往往是无数的对抗性攻击。然而，传统的自动对抗数据生成方法往往会产生不是多样化的攻击，而是以前观察到的危害类型的变体。我们将安全分类器的自动对抗发现任务形式化——沿着以前看不见的危害维度寻找新的攻击，从而暴露分类器中的新弱点。我们沿着两个关键轴来衡量这项任务的进展 (1) 对抗成功：攻击是否欺骗了分类器？和 (2) 维度多样性：攻击是否代表了以前看不见的危害类型？我们对 CivilComments 毒性任务中现有攻击生成方法的评估揭示了它们的局限性：词语扰动攻击无法欺骗分类器，而基于提示的 LLM 攻击具有更多的对抗成功率，但缺乏维度多样性。即使是我们表现最好的基于提示的方法也只有 5% 的时间在攻击的未知危害维度上发现新的成功攻击。自动发现攻击的新有害维度至关重要，我们新任务的未来研究空间很大。]]></description>
      <guid>https://arxiv.org/abs/2406.17104</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:53 GMT</pubDate>
    </item>
    <item>
      <title>基于提示的 LLM 与微调的 LLM 实现因果图验证</title>
      <link>https://arxiv.org/abs/2406.16899</link>
      <description><![CDATA[arXiv:2406.16899v1 公告类型：新
摘要：这项工作旨在应用自然语言处理 (NLP) 技术使用文本源自动验证因果图。因果图通常来自无监督的因果发现方法，需要人类专家的手动评估。NLP 技术，即大型语言模型 (LLM)，例如 BERT 和 ChatGPT，可以用于通过基于文本上下文预测是否可以在节点对之间观察到因果关系来验证生成的因果图。在这项工作中，我们比较了两种类型的 NLP 模型的性能：(1) 针对因果关系分类任务进行微调的预训练语言模型和 (2) 基于提示的 LLM。与之前的研究相比，基于提示的 LLM 在一系列不同的任务上表现相对较好，但在生物医学和开放领域数据集上的初步实验表明，经过微调的模型远远优于基于提示的 LLM，F1 分数提高了 20.5 分。我们在我们的存储库中分享了代码和预处理数据集。]]></description>
      <guid>https://arxiv.org/abs/2406.16899</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:52 GMT</pubDate>
    </item>
    <item>
      <title>分析 Trojan BERT 模型上的多头注意力</title>
      <link>https://arxiv.org/abs/2406.16925</link>
      <description><![CDATA[arXiv:2406.16925v1 公告类型：新
摘要：该项目研究了 Transformer 模型中多头注意力的行为，特别关注了情绪分析背景下良性和特洛伊木马模型之间的差异。特洛伊木马攻击会导致模型在干净的输入上表现正常，但在呈现包含预定义触发器的输入时会出现错误分类。我们描述了特洛伊木马和良性模型中的注意力头功能，识别特定的“特洛伊木马”头并分析其行为。]]></description>
      <guid>https://arxiv.org/abs/2406.16925</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:52 GMT</pubDate>
    </item>
    <item>
      <title>基于法学硕士的人工智能聊天机器人全面调查</title>
      <link>https://arxiv.org/abs/2406.16937</link>
      <description><![CDATA[arXiv:2406.16937v1 公告类型：新
摘要：过去几十年见证了数据的激增，为数据饥渴的基于学习的人工智能技术奠定了基础。对话代理，通常称为人工智能聊天机器人，严重依赖此类数据来训练大型语言模型 (LLM) 并响应用户提示生成新内容 (知识)。随着 OpenAI 的 ChatGPT 的出现，基于 LLM 的聊天机器人在人工智能社区树立了新的标准。本文全面介绍了基于 LLM 的聊天机器人在各个领域的发展和部署。我们首先总结了基础聊天机器人的发展，然后总结了 LLM 的发展，然后概述了目前正在使用的基于 LLM 的聊天机器人和处于开发阶段的聊天机器人。我们将人工智能聊天机器人视为产生新知识的工具，探索它们在各个行业的多种应用。然后，我们讨论了尚未解决的挑战，并考虑了用于训练 LLM 的数据以及对所生成知识的滥用如何导致若干问题。最后，我们探讨了未来前景，以增强其在众多应用中的效率和可靠性。通过解决关键里程碑和基于 LLM 的聊天机器人的当前背景，我们的调查邀请读者深入研究这一领域，思考他们的下一代将如何重塑对话式人工智能。]]></description>
      <guid>https://arxiv.org/abs/2406.16937</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:52 GMT</pubDate>
    </item>
    <item>
      <title>modelLing：用于测试语言模型中的语言推理的新型数据集</title>
      <link>https://arxiv.org/abs/2406.17038</link>
      <description><![CDATA[arXiv:2406.17038v1 公告类型：新
摘要：我们引入了 modelLing，这是语言学奥林匹克式谜题的新基准，用于测试 AI 系统中的少样本推理。解决这些谜题需要从少量示例中推断语言语法结构的各个方面。此类谜题为语言模型提供了天然的试验台，因为它们需要组合泛化和少样本归纳推理。modeling 仅由专门为这项工作编写的新谜题组成，不存在出现在现有 AI 系统的训练数据中的风险：这改善了数据泄露的风险，而数据泄露是许多先前推理评估的潜在混杂因素。在我们的基准上评估了几个大型开源语言模型和 GPT，我们观察到不可忽略的准确性，展示了少样本的突发推理能力，而这不能仅仅归因于浅层记忆。然而，不完善的模型性能表明建模可用于衡量语言推理的进一步进展。]]></description>
      <guid>https://arxiv.org/abs/2406.17038</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:52 GMT</pubDate>
    </item>
    <item>
      <title>使用密集检索进行多语言实体链接</title>
      <link>https://arxiv.org/abs/2406.16892</link>
      <description><![CDATA[arXiv:2406.16892v1 公告类型：新
摘要：实体链接 (EL) 是将文本提及连接到相应实体的计算过程。与自然语言处理的许多领域一样，EL 领域从深度学习中受益匪浅，从而显著提高了性能。然而，目前的方法训练成本高昂，并且依赖于不同的数据源，使其可重复性变得复杂。在本文中，我们开发了多个快速训练的系统，证明了无需大型 GPU 集群即可实现竞争性实体链接。此外，我们在公开可用的数据集上进行训练，确保可重复性和可访问性。我们的模型针对 9 种语言进行了评估，准确概述了它们的优势。此外，我们还对双编码器训练超参数（EL 中的一种流行方法）进行了详细分析，以指导他们的明智选择。总的来说，我们的工作表明，即使在资源有限的情况下，也可以构建基于神经网络的竞争性 EL 系统，以多种语言运行，从而使 EL 更加平易近人。]]></description>
      <guid>https://arxiv.org/abs/2406.16892</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:51 GMT</pubDate>
    </item>
    <item>
      <title>一项关于 NLP 中 Transformer 的调查，重点关注效率</title>
      <link>https://arxiv.org/abs/2406.16893</link>
      <description><![CDATA[arXiv:2406.16893v1 公告类型：新
摘要：具有注意机制的 Transformer 和相关预训练模型的出现彻底改变了自然语言处理 (NLP) 领域。然而，由于架构高度复杂，此类模型资源密集。这限制了它们在资源受限环境中的应用。在选择合适的 NLP 模型时，在选择准确性还是效率之间以及反之亦然之间存在重大权衡。本文对 NLP 及其应用的发展进行了评论，重点强调了它们的准确性和效率。在此之后，对在模型开发的各个阶段提高基于 Transformer 的模型效率的研究贡献以及硬件考虑进行了调查。本次调查的目的是确定当前的 NLP 技术如何为可持续社会做出贡献，并为未来的研究奠定基础。]]></description>
      <guid>https://arxiv.org/abs/2406.16893</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:51 GMT</pubDate>
    </item>
    <item>
      <title>InstructPatentGPT：训练专利语言模型，使其遵循人工反馈的指令</title>
      <link>https://arxiv.org/abs/2406.16897</link>
      <description><![CDATA[arXiv:2406.16897v1 公告类型：新
摘要：在本研究中，专利起诉被概念化为从人类反馈中进行强化学习的系统。该系统的目标是增加语言模型生成更有可能被授予的专利权利要求的可能性。为了展示语言模型的可控性，该系统从授予的专利和授予前申请中学习，并提供不同的奖励。“授予”和“授予前”的状态被视为隐含的人类反馈。此外，针对专利撰写，本研究中的实验展示了该模型通过调整权利要求长度和包含限制性术语来缩小权利要求范围的能力。作为概念证明，实验仅关注权利要求，训练数据来自专门为人工智能量身定制的专利数据集。尽管专利审查中可用的人工反馈有限，生成的专利文本的质量也需要改进，但根据人工反馈进行 3 阶段强化学习的实验表明，生成语言模型能够反映专利审查中的人工反馈或意图。为了提高语言模型的可用性，本研究的实施采用了现代技术，可在单个消费级 GPU 上执行。随着专利审查中越来越多的人工反馈在专利局或公共领域得到更广泛的应用，已证明的概念验证降低了硬件要求，未来将证明其价值。]]></description>
      <guid>https://arxiv.org/abs/2406.16897</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:51 GMT</pubDate>
    </item>
    <item>
      <title>TextAge：用于年龄分类的精选多样化文本数据集</title>
      <link>https://arxiv.org/abs/2406.16890</link>
      <description><![CDATA[arXiv:2406.16890v1 公告类型：新
摘要：与年龄相关的语言模式在理解语言差异和制定适合年龄的沟通策略方面起着至关重要的作用。然而，缺乏全面和多样化的数据集阻碍了该领域研究的进展。为了解决这个问题，我们提出了 TextAge，这是一个精选的文本数据集，它将句子映射到制作者的年龄和年龄组，以及未成年人（13 岁以下）标签。TextAge 涵盖广泛的年龄范围，包括来自各种来源的口头和书面数据，例如 CHILDES、Meta、Poki Poems-by-kids、JUSThink 和电视节目“幸存者”。数据集经过广泛的清理和预处理，以确保数据质量和一致性。我们通过两个应用展示了 TextAge 的实用性：未成年人检测和世代分类。对于未成年人检测，我们训练了朴素贝叶斯分类器、经过微调的 RoBERTa 和 XLNet 模型，以区分未成年人和青年及以上成年人的语言模式。对于代际分类，这些模型将语言模式分为不同的年龄组（儿童、青少年、二十几岁等）。这些模型擅长对“儿童”组进行分类，但对年龄较大的群体，尤其是“五十多岁”、“六十多岁”和“七十多岁”的群体，则表现不佳，这可能是由于数据样本有限且语言差异不太明显。TextAge 为研究与年龄相关的语言模式和开发年龄敏感的语言模型提供了宝贵的资源。数据集的多样化组成和分类任务的良好结果凸显了其在各种应用中的潜力，例如内容审核、定向广告和适合年龄的沟通。未来的工作旨在进一步扩展数据集并探索先进的建模技术，以提高对年龄较大群体的表现。]]></description>
      <guid>https://arxiv.org/abs/2406.16890</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:50 GMT</pubDate>
    </item>
    <item>
      <title>使用生物学相关问题对大型语言模型的推理能力和可访问性进行调查</title>
      <link>https://arxiv.org/abs/2406.16891</link>
      <description><![CDATA[arXiv:2406.16891v1 公告类型：新
摘要：这篇研究论文讨论了过去十年在生物医学和大型语言模型方面取得的进展。为了了解这些进步是如何齐头并进的，本文还讨论了自然语言处理技术和工具与生物医学的整合。最后，本文的目标是通过引入针对前两个语言模型的新问题和提示列表来扩展去年（2023 年）进行的一项调查。通过这项调查，本文试图量化 LLM 推理能力的提高以及普通用户在多大程度上感受到这些改进。此外，本文还试图通过促使 LLM 深入回答开放式问题来扩展对生物文献检索的研究。]]></description>
      <guid>https://arxiv.org/abs/2406.16891</guid>
      <pubDate>Thu, 27 Jun 2024 03:15:50 GMT</pubDate>
    </item>
    </channel>
</rss>