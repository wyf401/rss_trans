<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 27 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>语言表征有利于零样本跨领域认知诊断</title>
      <link>https://arxiv.org/abs/2501.13943</link>
      <description><![CDATA[arXiv:2501.13943v1 公告类型：新
摘要：认知诊断旨在根据学生的历史反应日志推断他们的掌握水平。然而，现有的依赖于 ID 嵌入的认知诊断模型 (CDM) 通常必须在特定领域训练特定模型。这种限制可能会阻碍它们在各种目标领域的直接实际应用，例如不同的科目（例如数学、英语和物理）或不同的教育平台（例如 ASSISTments、Junyi Academy 和 Khan Academy）。为了解决这个问题，本文提出了语言表示偏爱的零样本跨领域认知诊断 (LRCD)。具体来说，LRCD 首先分析学生、练习和概念在不同领域的行为模式，然后使用文本描述来描述学生、练习和概念的概况。通过最近的高级文本嵌入模块，这些概况可以转换为统一语言空间中的向量。此外，为了解决语言空间和认知诊断空间之间的差异，我们在 LRCD 中提出了语言认知映射器来学习从前者到后者的映射。然后，这些配置文件可以轻松高效地与现有的 CDM 集成和训练。大量实验表明，在真实世界数据集上训练 LRCD 可以在不同目标域上实现值得称赞的零样本性能，在某些情况下，它甚至可以实现与在目标域上的完整响应数据上训练的一些经典 CDM 相媲美的性能。值得注意的是，我们惊讶地发现 LRCD 还可以提供对不同学科（如人文和科学）和来源（如小学和中学教育）之间差异的有趣见解。]]></description>
      <guid>https://arxiv.org/abs/2501.13943</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Fanar：以阿拉伯语为中心的多模态生成 AI 平台</title>
      <link>https://arxiv.org/abs/2501.13944</link>
      <description><![CDATA[arXiv:2501.13944v1 公告类型：新
摘要：我们介绍了 Fanar，这是一个以阿拉伯语为中心的多模态生成 AI 系统平台，支持语言、语音和图像生成任务。Fanar 的核心是 Fanar Star 和 Fanar Prime，这两个功能强大的阿拉伯语大型语言模型 (LLM) 在同类模型的成熟基准中名列前茅。Fanar Star 是一个 7B（十亿）参数模型，从头开始训练近 1 万亿个干净且去重的阿拉伯语、英语和代码标记。Fanar Prime 是一个 9B 参数模型，在相同的 1 万亿个标记集上持续训练 Gemma-2 9B 基础模型。这两个模型同时部署，旨在通过定制的编排器透明地解决不同类型的提示。 Fanar 平台还提供许多其他功能，包括用于处理宗教提示的定制伊斯兰检索增强生成 (RAG) 系统、用于总结预训练数据截止日期后发生的当前或近期事件信息的 Recency RAG。该平台提供额外的认知功能，包括支持多种阿拉伯方言的内部双语语音识别、经过微调以更好地反映区域特征的语音和图像生成。最后，Fanar 提供归因服务，可用于验证基于事实的生成内容的真实性。
Fanar 的设计、开发和实施完全由哈马德·本·哈利法大学的卡塔尔计算研究所 (QCRI) 进行，并由卡塔尔通信和信息技术部赞助，以支持自主 AI 技术开发。]]></description>
      <guid>https://arxiv.org/abs/2501.13944</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>社交 AI 代理中的自我解释</title>
      <link>https://arxiv.org/abs/2501.13945</link>
      <description><![CDATA[arXiv:2501.13945v1 公告类型：新
摘要：社交 AI 代理与社区成员互动，从而改变社区的行为。例如，在在线学习中，AI 社交助手可以连接学习者，从而增强社交互动。这些社交 AI 助手也需要解释自己，以增强透明度和与学习者的信任。我们提出了一种自我解释方法，该方法使用对 AI 社交助手的自我模型进行自省。自我模型被视为一个功能模型，该模型指定代理的方法如何使用知识来完成其任务。生成自我解释的过程使用思想链来反思自我模型，并使用 ChatGPT 来提供有关其功能的解释。我们评估 AI 社交助手的自我解释的完整性和正确性。我们还报告了它在现场课堂上的部署情况。]]></description>
      <guid>https://arxiv.org/abs/2501.13945</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Agentic AI 基于自然语言的框架缓解幻觉</title>
      <link>https://arxiv.org/abs/2501.13946</link>
      <description><![CDATA[arXiv:2501.13946v1 公告类型：新
摘要：幻觉仍然是当前生成式 AI 模型面临的重大挑战，它破坏了人们对 AI 系统及其可靠性的信任。本研究调查了如何协调多个专门的人工智能代理来帮助缓解这种幻觉，重点是利用自然语言处理 (NLP) 促进无缝代理交互的系统。为了实现这一点，我们设计了一个管道，将三百多个专门设计用于诱发幻觉的提示引入前端代理。然后，第二级和第三级代理系统地审查和完善输出，每个代理都采用不同的大型语言模型和量身定制的策略来检测未经证实的声明、纳入明确的免责声明和澄清推测内容。此外，我们引入了一组专门用于评估幻觉评分水平的新关键绩效指标 (KPI)。专门的第四级 AI 代理用于评估这些 KPI，提供详细的评估并确保准确量化幻觉相关行为的变化。这项研究的核心部分是使用 OVON（开放语音网络）框架，该框架依赖于通用的基于 NLP 的接口在代理之间传输上下文信息。通过结构化的 JSON 消息，每个代理传达其对幻觉可能性的评估以及可疑内容背后的原因，从而使后续阶段能够在不丢失上下文的情况下完善文本。结果表明，使用能够通过基于 NLP 的代理框架相互交互的多个专门代理可以在缓解幻觉方面取得有希望的结果，最终增强人工智能社区内的信任。]]></description>
      <guid>https://arxiv.org/abs/2501.13946</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型与基于知识的方法相结合的综合调查</title>
      <link>https://arxiv.org/abs/2501.13947</link>
      <description><![CDATA[arXiv:2501.13947v1 公告类型：新
摘要：人工智能的快速发展为该领域带来了实质性的进步。一个有希望的方向是将大型语言模型 (LLM) 与结构化知识系统相结合。这种方法旨在通过将 LLM 的生成语言理解与结构化系统的精确知识表示相结合来增强 AI 能力。本调查探讨了 LLM 与知识库之间的协同作用，重点关注现实世界的应用并解决相关的技术、操作和道德挑战。通过全面的文献综述，该研究确定了关键问题并评估了现有的解决方案。本文强调了将生成 AI 与知识库相结合的好处，包括改进数据情境化、提高模型准确性和更好地利用知识资源。研究结果详细概述了当前的研究状况，确定了关键差距并提出了可行的建议。这些见解有助于推进人工智能技术并支持其在各个领域的实际部署。]]></description>
      <guid>https://arxiv.org/abs/2501.13947</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 对好莱坞电影对话进行纵向滥用和情感分析</title>
      <link>https://arxiv.org/abs/2501.13948</link>
      <description><![CDATA[arXiv:2501.13948v1 公告类型：新
摘要：在过去的几十年里，人们越来越担心好莱坞电影中辱骂和暴力内容的普遍性。本研究使用大型语言模型 (LLM) 探索 1950 年至 2024 年好莱坞奥斯卡和大片电影对话的纵向辱骂和情感分析。通过使用微调的 LLM，我们分析了分为四种类型的一千多部电影的字幕，以研究过去七十年情感和辱骂内容的趋势和变化。我们的研究结果揭示了电影对话的显著时间变化，反映了更广泛的社会和文化影响。总体而言，电影中的情感倾向是多种多样的，对辱骂内容的检测也表现出明显的波动。结果显示，近几十年来辱骂内容逐渐增加，反映了社会规范和监管政策的变化。惊悚片等类型仍然呈现出更高的辱骂内容频率，强调了暴力和冲突的持续叙事作用。与此同时，大部分电影中仍充斥着幽默、乐观等积极情绪。此外，过去二十年，电影对白中的辱骂性内容逐渐增多，奥斯卡提名电影取代了十大卖座大片。]]></description>
      <guid>https://arxiv.org/abs/2501.13948</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI o1 能在眼科领域很好地推理吗？一项涉及 6,990 个问题的头对头评估研究</title>
      <link>https://arxiv.org/abs/2501.13949</link>
      <description><![CDATA[arXiv:2501.13949v1 公告类型：新
摘要：问题：与其他大型语言模型相比，OpenAI o1 在解决眼科特定问题方面的表现和推理能力如何？
结果：本研究使用来自 MedMCQA 的 6,990 个眼科问题评估了 OpenAI o1 和五个 LLM。O1 的准确率（0.88）和宏 F1 分数最高，但在基于文本生成指标的推理能力方面排名第三。在各个子主题中，o1 在“晶状体”和“青光眼”中排名第一，但在“角膜和外部疾病”、“玻璃体和视网膜”和“眼整形和眼眶疾病”中仅次于 GPT-4o。子组分析表明，o1 在具有较长基本事实解释的查询上表现更好。
含义：O1 的推理增强功能可能无法完全扩展到眼科，强调需要针对特定​​领域进行改进，以优化眼科等专业领域的表现。]]></description>
      <guid>https://arxiv.org/abs/2501.13949</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于长期心理健康评估的分层多专家框架</title>
      <link>https://arxiv.org/abs/2501.13951</link>
      <description><![CDATA[arXiv:2501.13951v1 公告类型：新
摘要：长篇心理健康评估对大型语言模型 (LLM) 提出了独特的挑战，大型语言模型在处理扩展的、特定领域的上下文时经常表现出幻觉或不一致的推理。我们引入了堆叠多模型推理 (SMMR)，这是一个分层框架，利用多个 LLM 和专门的小型模型作为同等的“专家”。早期层隔离短小、离散的子任务，而后期层通过更高级的长上下文模型集成和细化这些部分输出。我们在 DAIC-WOZ 抑郁症筛查数据集和 48 个精选的精神病诊断案例研究中评估了 SMMR，结果显示，在准确性、F1 分数和 PHQ-8 错误减少方面，与单模型基线相比有持续的改进。通过利用不同的“第二意见”，SMMR 可以减轻幻觉、捕捉细微的临床细微差别并提高高风险心理健康评估的可靠性。我们的研究结果强调了多专家框架对于更值得信赖的人工智能驱动筛选的价值。]]></description>
      <guid>https://arxiv.org/abs/2501.13951</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士中的双重用途困境：增强道德能力是否会降低效用？</title>
      <link>https://arxiv.org/abs/2501.13952</link>
      <description><![CDATA[arXiv:2501.13952v1 公告类型：新
摘要：近年来，人们在各个领域都做出了广泛的努力来增强大型语言模型 (LLM)，同时也越来越关注它们的伦理影响。然而，一个关键的挑战仍然被人们忽视：LLM 必须在拒绝有害的安全请求和容纳合法的实用请求之间取得平衡。本文提出了一种基于直接偏好优化 (DPO) 的对齐框架，该框架通过解决这种道德效用权衡来实现更好的整体性能，并使用化学领域应用作为概念验证。我们的对齐管道从 GPT 辅助的三阶段数据生成方案开始，其中我们创建了 LibraChemQA，这是一个包含 31.6k 个三元组实例的化学问答数据集。通过在数据生成过程中加入创新的平衡种子，我们的框架系统地考虑了合法和非法请求。该框架还引入了一种改写机制，用于有效的数据增强，从而增强了模型的化学理解能力。我们进一步开发了一种新颖的混合评估方案，由 LLM 评委对安全性和实用性进行精确评估。实验结果表明，我们的模型在兼顾安全性和实用性的情况下，整体性能得到了显著提升 - 我们最终的模型 LibraChem 在我们发布的基准测试中分别以 13.44%、7.16% 和 7.10% 的优势超越了包括 Claude-3、GPT-4o 和 LLaMA-3 在内的领先 LLM。]]></description>
      <guid>https://arxiv.org/abs/2501.13952</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MLLM 基准的冗余原则</title>
      <link>https://arxiv.org/abs/2501.13953</link>
      <description><![CDATA[arXiv:2501.13953v1 公告类型：新
摘要：随着多模态大型语言模型 (MLLM) 的快速迭代和该领域需求的不断变化，每年产生的基准数量已激增至数百个。快速增长不可避免地导致基准之间存在大量冗余。因此，退一步并批判性地评估当前的冗余状态并提出构建有效 MLLM 基准的有针对性的原则至关重要。在本文中，我们从三个关键角度关注冗余：1）基准能力维度的冗余，2）测试问题数量的冗余，以及 3）特定领域内的跨基准冗余。通过对 20 多个基准测试中数百个 MLLM 的性能进行全面分析，我们旨在定量衡量现有 MLLM 评估中的冗余程度，提供有价值的见解来指导 MLLM 基准测试的未来发展，并提出改进和有效解决冗余问题的策略。]]></description>
      <guid>https://arxiv.org/abs/2501.13953</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Chat3GPP：3GPP 文档的开源检索增强生成框架</title>
      <link>https://arxiv.org/abs/2501.13954</link>
      <description><![CDATA[arXiv:2501.13954v1 公告类型：新
摘要：第三代合作伙伴计划 (3GPP) 文件是全球电信的关键标准，同时由于其内容庞大、复杂且更新频繁，给电信领域的工程师和研究人员带来了重大挑战。大型语言模型 (LLM) 在自然语言处理任务中表现出色，但其通用性限制了它们在电信等特定领域的有效性。为了解决这个问题，我们提出了 Chat3GPP，这是一个针对 3GPP 规范量身定制的开源检索增强生成 (RAG) 框架。通过结合分块策略、混合检索和高效索引方法，Chat3GPP 可以高效地检索相关信息并生成对用户查询的准确响应，而无需进行特定领域的微调，它既灵活又可扩展，为适应 3GPP 以外的其他技术标准提供了巨大的潜力。我们在两个电信专用数据集上评估了 Chat3GPP，并证明了其与现有方法相比的卓越性能，展示了其在协议生成和代码自动化等下游任务中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.13954</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于角色的引导式 AI 调查：我们能否使用 LLM 大规模复制个人移动偏好？</title>
      <link>https://arxiv.org/abs/2501.13955</link>
      <description><![CDATA[arXiv:2501.13955v1 公告类型：新
摘要：本研究探讨了大型语言模型 (LLM) 生成人工调查的潜力，重点关注德国的个人流动偏好。通过利用 LLM 创建合成数据，我们旨在解决传统调查方法的局限性，例如成本高、效率低和可扩展性挑战。介绍了一种结合“人物角色”——人口统计和行为属性的组合——的新方法，并将其与其他五种合成调查方法进行了比较，这些方法在使用真实世界数据和方法复杂性方面有所不同。MiD 2017 数据集是德国的一项综合流动性调查，可作为评估合成数据与真实世界模式一致性的基准。结果表明，LLM 可以有效捕捉人口统计属性和偏好之间的复杂依赖关系，同时提供探索假设情景的灵活性。这种方法为交通规划和社会科学研究提供了宝贵的机会，实现了可扩展、经济高效和隐私保护的数据生成。]]></description>
      <guid>https://arxiv.org/abs/2501.13955</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Zep：用于代理内存的时间知识图谱架构</title>
      <link>https://arxiv.org/abs/2501.13956</link>
      <description><![CDATA[arXiv:2501.13956v1 公告类型：新
摘要：我们介绍了 Zep，这是一种用于 AI 代理的新型内存层服务，它在深度内存检索 (DMR) 基准测试中的表现优于当前最先进的系统 MemGPT。此外，Zep 在比 DMR 更全面、更具挑战性的评估中表现出色，更好地反映了现实世界的企业用例。虽然现有的基于大型语言模型 (LLM) 的代理的检索增强生成 (RAG) 框架仅限于静态文档检索，但企业应用程序需要从各种来源（包括正在进行的对话和业务数据）动态集成知识。Zep 通过其核心组件 Graphiti 解决了这一根本限制——这是一种时间感知知识图谱引擎，可动态合成非结构化对话数据和结构化业务数据，同时保持历史关系。在 MemGPT 团队建立为其主要评估指标的 DMR 基准测试中，Zep 表现出色（94.8% vs 93.4%）。除了 DMR，Zep 的功能还通过更具挑战性的 LongMemEval 基准得到进一步验证，该基准通过复杂的时间推理任务更好地反映了企业用例。在这次评估中，Zep 取得了显著的成果，准确率提高了 18.5%，同时与基线实现相比，响应延迟减少了 90%。这些结果在跨会话信息合成和长期上下文维护等企业关键任务中尤为明显，证明了 Zep 在实际应用中部署的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.13956</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对生成式人工智能进行基准测试，以对客观结构化临床考试 (OSCE) 中的医学生面试进行评分</title>
      <link>https://arxiv.org/abs/2501.13957</link>
      <description><![CDATA[arXiv:2501.13957v1 公告类型：新
摘要：简介。客观结构化临床考试 (OSCE) 被广泛用于评估医学生的沟通技巧，但对基于面试的评估进行评分非常耗时，并且可能受到人为偏见的影响。本研究探讨了大型语言模型 (LLM) 使用主面试评分量表 (MIRS) 自动化 OSCE 评估的潜力。
方法。我们比较了四种最先进的 LLM (GPT-4o、Claude 3.5、Llama 3.1 和 Gemini 1.5 Pro) 在零样本、思路链 (CoT)、少量样本和多步骤提示条件下评估 MIRS 所有 28 个项目中的 OSCE 成绩单的性能。这些模型针对 10 个 OSCE 案例的数据集进行了基准测试，其中有 174 个专家共识分数可用。使用三个准确度指标（精确、偏差一、阈值）来衡量模型性能。
结果。对所有 MIRS 项目和 OSCE 案例进行平均，LLM 的准确度较低（0.27 到 0.44），偏差准确度（0.67 到 0.87）和阈值准确度（0.75 到 0.88）为中等到高。零温度参数确保了较高的评分者内信度（GPT-4o 的 \alpha = 0.98）。CoT、少量样本和多步骤技术在针对特定评估项目进行定制时被证明是有价值的。在 MIRS 项目中的表现是一致的，与接触阶段和通信领域无关。
结论。我们证明了人工智能辅助 OSCE 评估的可行性，并提供了跨多种提示技术的多个 LLM 的基准测试。我们的工作为 LLM 提供了基线绩效评估，为未来临床沟通技巧自动评估的研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2501.13957</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>定制大型语言模型的图形检索增强生成综述</title>
      <link>https://arxiv.org/abs/2501.13958</link>
      <description><![CDATA[arXiv:2501.13958v1 公告类型：新
摘要：大型语言模型 (LLM) 在广泛的任务中表现出卓越的能力，但由于需要深厚的专业知识，它们在专业领域的应用仍然具有挑战性。检索增强生成 (RAG) 已成为一种有前途的解决方案，通过无缝集成外部知识库，可以在推理过程中实时访问特定领域的专业知识，为专业领域定制 LLM。尽管具有潜力，但基于平面文本检索的传统 RAG 系统面临三个关键挑战：(i) 专业背景下的复杂查询理解，(ii) 跨分布式源的知识集成困难，以及 (iii) 大规模系统效率瓶颈。本调查对基于图的检索增强生成 (GraphRAG) 进行了系统分析，这是一种彻底改变特定领域 LLM 应用的新范式。 GraphRAG 通过三项关键创新解决了传统 RAG 的局限性：（i）图形结构知识表示，明确捕获实体关系和域层次结构，（ii）高效的基于图形的检索技术，能够通过多跳推理能力实现保留上下文的知识检索，以及（iii）结构感知知识集成算法，利用检索到的知识准确、合乎逻辑地生成 LLM。在本次调查中，我们系统地分析了 GraphRAG 的技术基础，并研究了各个专业领域的当前实现情况，确定了关键的技术挑战和有前景的研究方向。社区在 \textcolor{blue}{\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}} 中收集了 GraphRAG 的所有相关资源，包括研究论文、开源数据和项目。]]></description>
      <guid>https://arxiv.org/abs/2501.13958</guid>
      <pubDate>Mon, 27 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>