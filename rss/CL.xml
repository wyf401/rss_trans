<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 11 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>法学硕士对法律问题的答案不稳定</title>
      <link>https://arxiv.org/abs/2502.05196</link>
      <description><![CDATA[arXiv:2502.05196v1 公告类型：新
摘要：如果 LLM 在多次被问到相同的问题时得出相同的结论，则它是稳定的。我们发现，像 gpt-4o、claude-3.5 和 gemini-1.5 这样的领先 LLM 在提供棘手的法律问题的答案时是不稳定的，即使通过将温度设置为 0 使其尽可能确定。我们策划并发布了一个包含 500 个法律问题的新数据集，这些问题是从涉及两方的真实案件中提炼出来的，包括事实、相互竞争的法律论点以及哪一方应该获胜的问题。当提供完全相同的问题时，我们观察到 LLM 有时会说一方应该赢，而有时又说另一方应该赢。这种不稳定性对依赖这些 LLM 的法律 AI 产品、法律程序和律师的数量不断增加产生了影响。]]></description>
      <guid>https://arxiv.org/abs/2502.05196</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用异构词汇的无损推测解码算法加速 LLM 推理</title>
      <link>https://arxiv.org/abs/2502.05202</link>
      <description><![CDATA[arXiv:2502.05202v1 公告类型：新
摘要：加速大型语言模型 (LLM) 的推理是生成式 AI 面临的一个关键挑战。推测解码 (SD) 方法通过使用单个目标前向传递生成多个标记，从而显著提高效率。然而，现有的 SD 方法要求起草者和目标模型共享相同的词汇表，从而限制了可能的起草者的数量，通常需要从头开始训练起草者。我们提出了三种新的 SD 方法，以消除这种共享词汇表的限制。这三种方法都保留了目标分布（即它们是无损的），并且可以与现成的模型一起使用，而无需额外的训练或修改。从经验上看，在总结、编程和长上下文任务中，我们的算法比标准自回归解码实现了显着的加速。通过使任何现成的模型都可以用作起草者并且不需要重新训练，这项工作大大拓宽了 SD 框架在实践中的适用性。]]></description>
      <guid>https://arxiv.org/abs/2502.05202</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>向语言模型提供高效的知识：一种新颖的集成编码器-解码器架构</title>
      <link>https://arxiv.org/abs/2502.05233</link>
      <description><![CDATA[arXiv:2502.05233v1 公告类型：新
摘要：本文介绍了一种新方法，通过在统一框架内集成检索和生成过程，在预测过程中有效地向语言模型 (LLM) 提供知识。虽然检索增强生成 (RAG) 模型解决了 LLM 训练数据和知识限制方面的差距，但它受到标记限制和对检索系统准确性的依赖的阻碍。我们提出的架构结合了上下文向量 (ICV) 来克服这些挑战。ICV 通过使用 LLM 的潜在嵌入来重塑上下文学习，以创建一个捕获基本任务信息的向量。然后使用该向量来转移 LLM 的潜在状态，从而无需在提示中添加演示示例即可增强生成过程。ICV 将信息直接集成到模型中，使其能够更有效地处理这些信息。我们广泛的实验评估表明，ICV 在问答、信息检索和其他任务中的表现优于标准的上下文学习和微调。这种方法减轻了当前 RAG 模型的局限性，并为处理广泛而多样化的数据集提供了更强大的解决方案。尽管只利用了一小部分参数，但我们的 ICV 增强模型在性能上与 LLaMA-3、Gemma 和 Phi-3 等模型相比具有竞争力，大大降低了计算成本和内存需求。与微调相比，ICV 缩短了提示长度，易于控制，突破了标记限制，并且计算效率更高。]]></description>
      <guid>https://arxiv.org/abs/2502.05233</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强知识图谱构建：重点评估幻觉、遗漏和图相似性指标</title>
      <link>https://arxiv.org/abs/2502.05239</link>
      <description><![CDATA[arXiv:2502.05239v1 公告类型：新
摘要：大型语言模型的最新进展已显示出从非结构化文本自动构建知识图谱的巨大潜力。本文以我们之前的工作 [16] 为基础，该工作使用精度、召回率、F1 分数、三重匹配和图匹配等指标评估了各种模型，并介绍了一种改进的方法来解决幻觉和遗漏的关键问题。我们提出了一个增强的评估框架，结合了 BERTScore 的图相似性，为图匹配设置了 95% 的实际阈值。我们的实验重点关注 Mistral 模型，在零样本和少样本设置中比较了其原始版本和微调版本。我们使用来自 KELM-sub 训练数据集的示例进一步扩展了我们的实验，说明微调模型显着提高了知识图谱构建的准确性，同时减少了精确的幻觉和遗漏。然而，我们的研究结果还表明，微调模型在 KELM-sub 数据集的泛化任务中表现较差。这项研究强调了综合评估指标对于推动从文本数据构建知识图谱的最新进展的重要性。]]></description>
      <guid>https://arxiv.org/abs/2502.05239</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SEER：大型语言模型表征的自解释性增强</title>
      <link>https://arxiv.org/abs/2502.05242</link>
      <description><![CDATA[arXiv:2502.05242v1 公告类型：新
摘要：解释大型语言模型 (LLM) 的隐藏表示是理解 LLM 底层推理逻辑和提高其在应用场景中的可靠性的一个视角。然而，以前的方法引入了外部“黑盒”模块来解释“黑盒”LLM，增加了潜在的不确定性并且无法提供忠实的解释。在本文中，我们提出了一种自解释方法 SEER，通过聚合相同的概念并解开表示空间中的不同概念来增强 LLM 的可解释性。通过这种方式，SEER 与 LLM 的输出同步提供表示所承载的忠实解释。此外，我们展示了 SEER 在可信度相关任务（例如安全风险分类和解毒任务）上的应用，其中自解释的 LLM 在可解释性和性能方面实现了持续的改进。更重要的是，我们通过最优传输理论从理论上分析了SEER对LLM泛化能力的提升。]]></description>
      <guid>https://arxiv.org/abs/2502.05242</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估大型语言模型中的性格特征：来自心理问卷的见解</title>
      <link>https://arxiv.org/abs/2502.05248</link>
      <description><![CDATA[arXiv:2502.05248v1 公告类型：新
摘要：心理评估工具长期以来一直帮助人类理解行为模式。虽然大型语言模型 (LLM) 可以生成与人类相当的内容，但我们会探索它们是否表现出个性特征。为此，这项工作将心理工具应用于不同场景中的 LLM 以生成个性档案。使用已建立的基于特征的问卷（例如大五量表）并解决训练数据污染的可能性，我们检查了 LLM 在五个核心人格维度上的维度变异性和主导性：开放性、尽责性、外向性、亲和性和神经质。我们的研究结果表明，即使在同一模型系列中，LLM 也表现出独特的主导特征、不同的特征和不同的个性档案。]]></description>
      <guid>https://arxiv.org/abs/2502.05248</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GSM-Infinite：您的 LLM 在无限增加的上下文长度和推理复杂性下如何表现？</title>
      <link>https://arxiv.org/abs/2502.05252</link>
      <description><![CDATA[arXiv:2502.05252v1 公告类型：新
摘要：长上下文大型语言模型 (LLM) 最近在信息检索和长文档问答中表现出色。然而，为了解决最具挑战性的智力问题，LLM 必须在长而复杂的上下文（例如前沿数学研究）中有效地推理。研究 LLM 如何处理日益增加的推理复杂性和上下文长度至关重要，但现有的基准缺乏定量评估的坚实基础。受 GSM-8K 问题抽象为计算图以及通过添加不必要的节点和边来引入噪声的能力的启发，我们开发了一个小学数学问题生成器，能够在细粒度控制下生成具有无限难度和上下文长度的算术问题。使用我们新合成的 GSM-Infinite 基准，我们全面评估了现有的 LLM。我们发现，随着复杂度的增加，推理性能会持续呈 S 型下降，同时推理扩展趋势也呈系统性：推理计算呈指数级增长只能带来线性性能提升。这些发现凸显了当前长上下文 LLM 的根本局限性以及扩展推理能力的关键挑战。我们的 GSM-Infinite 基准测试为系统地研究和推进长上下文和复杂上下文中的 LLM 推理提供了可扩展且可控的测试平台。]]></description>
      <guid>https://arxiv.org/abs/2502.05252</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士可以自学如何更好地预测未来</title>
      <link>https://arxiv.org/abs/2502.05253</link>
      <description><![CDATA[arXiv:2502.05253v1 公告类型：新
摘要：我们提出了一个结果驱动的微调框架，该框架可增强大型语言模型 (LLM) 的预测能力，而无需依赖人工策划的推理样本。我们的方法利用模型自我游戏来生成多对不同的推理轨迹和概率预测，以解决在模型知识截止日期之后解决的一系列不同问题。然后，我们根据这些推理轨迹与实际结果的距离对这些推理轨迹进行排序，然后通过直接偏好优化 (DPO) 对模型进行微调。在单独的测试集上，我们的方法将 Phi-4 14B 和 DeepSeek-R1 14B 的预测准确率提高了 7--10\%，超过基础模型和具有随机标签的 DPO 微调控制模型，使它们的预测能力与 GPT-4o 等更大的前沿模型相当。]]></description>
      <guid>https://arxiv.org/abs/2502.05253</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 能否对小型 LLM 的危害进行排名？我们还没有做到</title>
      <link>https://arxiv.org/abs/2502.05291</link>
      <description><![CDATA[arXiv:2502.05291v1 公告类型：新
摘要：大型语言模型 (LLM) 已经无处不在，因此了解其风险和局限性非常重要。较小的 LLM 可以部署在计算资源受限的地方，例如边缘设备，但它们产生有害输出的倾向不同。减轻 LLM 危害通常取决于注释 LLM 输出的危害性，而从人类那里收集这些信息的成本很高。这项工作研究了两个问题：较小的 LLM 在生成有害内容方面排名如何？较大的 LLM 对危害性的注释有多好？我们提示三个小型 LLM 引出各种类型的有害内容，例如歧视性语言、攻击性内容、侵犯隐私或负面影响，并收集其输出的人工排名。然后，我们评估了三个最先进的大型 LLM 注释这些响应的危害性的能力。我们发现较小的模型在危害性方面有所不同。我们还发现大型 LLM 与人类的一致性较低到中等。这些发现强调了进一步研究 LLM 中的危害减轻的必要性。]]></description>
      <guid>https://arxiv.org/abs/2502.05291</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>开发平衡合成数据以纠正阿拉伯语语法错误：一种基于错误标记模型和合成数据生成模型的方法</title>
      <link>https://arxiv.org/abs/2502.05312</link>
      <description><![CDATA[arXiv:2502.05312v1 公告类型：新 
摘要：合成数据生成被广泛认为是提高神经语法错误纠正 (GEC) 系统质量的一种方法。然而，目前的方法往往缺乏多样性或过于简单，无法生成人类所犯的各种语法错误，尤其是对于阿拉伯语等资源匮乏的语言。在本文中，我们将开发错误标记模型和合成数据生成模型，以创建一个大型阿拉伯语合成数据集，用于语法错误纠正。在错误标记模型中，使用 DeBERTav3 模型将正确的句子分为多种错误类型。阿拉伯语错误类型注释工具 (ARETA) 用于指导错误标记模型中的多标签分类任务，其中每个句子被分为 26 个错误标签。合成数据生成模型是一种基于反向翻译的模型，它通过在正确句子之前附加错误标签来生成不正确的句子，这些句子是使用 ARAT5 模型从错误标记模型生成的。在 QALB-14 和 QALB-15 测试集中，错误标记模型的 F1 达到 94.42%，这是识别干净句子中的错误标记的最新成果。通过语法错误纠正中的句法数据训练，我们在 QALB-14 测试集中取得了新的 F1 得分最新成果：79.36%。我们使用合成数据生成模型生成了 30,219,310 个合成句子对。]]></description>
      <guid>https://arxiv.org/abs/2502.05312</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>精细化的法学硕士是通过书籍追踪社会偏见的“时间胶囊”</title>
      <link>https://arxiv.org/abs/2502.05331</link>
      <description><![CDATA[arXiv:2502.05331v1 公告类型：新
摘要：书籍虽然往往富含文化见解，但也可以反映其时代的社会偏见——大型语言模型 (LLM) 可能会在训练过程中学习和延续这些偏见。我们引入了一种使用微调 LLM 来追踪和量化这些偏见的新方法。我们开发了 BookPAGE，这是一个包含 70 年（1950-2019 年）593 本小说书籍的语料库，用于追踪偏见的演变。通过对每个十年的书籍进行微调并使用有针对性的提示，我们研究了与性别、性取向、种族和宗教相关的偏见的变化。我们的研究结果表明，针对特定十年的书籍进行训练的 LLM 表现出反映其时代的偏见，既有渐进的趋势，也有显着的变化。例如，模型响应显示，从 1950 年代到 2010 年代，女性担任领导角色的描述逐渐增加（从 8% 增加到 22%），并在 1990 年代显著上升（从 4% 增加到 12%），这可能与第三波女权主义相一致。从 1980 年代到 2000 年代，同性关系的提及显着增加（从 0% 增加到 10%），反映了 LGBTQ+ 的日益增长。令人担忧的是，对伊斯兰教的负面描述在 2000 年代急剧上升（26% 增加到 38%），这可能反映了 9/11 之后的情绪。重要的是，我们证明这些偏见主要源于书籍的内容，而不是模型的架构或初始训练。我们的研究通过结合人工智能、文学研究和社会科学研究，为社会偏见趋势提供了一个新的视角。]]></description>
      <guid>https://arxiv.org/abs/2502.05331</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中用于上下文推理的概率子空间流形</title>
      <link>https://arxiv.org/abs/2502.05346</link>
      <description><![CDATA[arXiv:2502.05346v1 公告类型：新
摘要：将标记嵌入表示​​为学习流形上的概率分布可以实现更灵活的上下文推理，减少表示刚性，同时增强语义粒度。比较评估表明，概率嵌入可以改善邻域一致性并减少冗余，确保标记关系在微调迭代中保持更结构上的连贯性。概率子空间与注意力机制的集成有助于实现更具自适应性的上下文权重，使模型能够捕获传统嵌入中原本会被掩盖的潜在依赖关系。实验结果强调了对对抗性修改的增强的鲁棒性，即使在基于扰动的评估场景下，概率嵌入也能保持上下文完整性。性能评估表明，概率表示在特定领域的应用中具有更大的适应性，从而减轻了跨语言领域转换时进行大量再训练的需要。计算权衡保持在操作上可行的范围内，推理延迟的边际增加与增强的表示稳定性和上下文表达能力的优势相平衡。编码结构化不确定性的能力在生成建模任务中提供了优势，特别是在保持扩展序列的一致性需要能够处理模糊或上下文相关语言结构的表示框架的情况下。]]></description>
      <guid>https://arxiv.org/abs/2502.05346</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>韵律在口头问答中的作用</title>
      <link>https://arxiv.org/abs/2502.05389</link>
      <description><![CDATA[arXiv:2502.05389v1 公告类型：新
摘要：迄今为止，口语理解研究通常侧重于文本视角。大多数数据集都来自文本，随后合成为语音，并且大多数模型通常依赖于语音的自动转录。这不利于韵律——语音信号携带的除单词本身的语音之外的附加信息，并且很难仅从文本中恢复。在这项工作中，我们研究了韵律在口语问答中的作用。通过在由自然语音组成的 SLUE-SQA-5 数据集上分离韵律和词汇信息，我们证明仅靠韵律信息训练的模型可以通过利用韵律线索表现得相当好。但是，我们发现当词汇信息可用时，模型往往主要依赖于它。我们的研究结果表明，虽然韵律线索提供了有价值的补充信息，但需要更有效的整合方法来确保韵律与词汇特征一起发挥更大的作用。]]></description>
      <guid>https://arxiv.org/abs/2502.05389</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从情境学习中学习任务表征</title>
      <link>https://arxiv.org/abs/2502.05390</link>
      <description><![CDATA[arXiv:2502.05390v1 公告类型：新
摘要：大型语言模型 (LLM) 在上下文学习 (ICL) 方面表现出色，其中模型通过基于示例的提示适应新任务而无需更新参数。然而，理解任务如何在内部编码和泛化仍然是一个挑战。为了解决文献中的一些经验和技术差距，我们引入了一种自动化公式，用于将 ICL 提示中的任务信息编码为 Transformer 架构中注意力头的函数。这种方法将单个任务向量计算为注意力头的加权和，权重通过梯度下降因果优化。我们的研究结果表明，现有方法无法有效地推广到文本以外的模态。作为回应，我们还设计了一个基准来评估任务向量是否可以在功能回归任务中保持任务保真度。所提出的方法成功地从上下文演示中提取了特定于任务的信息，并在文本和回归任务中表现出色，证明了其在模态中的通用性。此外，消融研究表明，我们方法的有效性源于将最后隐藏状态的分布与表现最佳的上下文学习模型的分布保持一致。]]></description>
      <guid>https://arxiv.org/abs/2502.05390</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中的分层词汇流形投影：一种新的多尺度语义表示机制</title>
      <link>https://arxiv.org/abs/2502.05395</link>
      <description><![CDATA[arXiv:2502.05395v1 公告类型：新
摘要：将结构化分层嵌入集成到基于转换器的架构中引入了一种精细的词汇表示方法，确保在不影响计算效率的情况下保留多尺度语义关系。将标记映射到结构化流形上的投影机制提供了改进的词汇对齐，增强了单词表示在不同语言任务中的适应性。结构化编码框架确保分层嵌入在不同的抽象级别上保持一致性，从而允许在局部句法特征和全局语义结构之间实现稳定的转换。实验评估表明，分层嵌入始终优于传统的标记表示，在提高语言基准的准确性的同时保持较低的计算开销。跨多个领域的比较分析突出了分层嵌入保持上下文一致性的能力，特别是在结构化词汇对齐至关重要的专业语言应用中。统计评估进一步表明，分层嵌入在扰动条件下表现出增强的鲁棒性，确保语言结构在对抗性文本修改中保持稳定。分层投影与 Transformer 注意机制的集成可以改善上下文适应性，确保根据不同的语言分布动态调整标记表示。嵌入的精细分层组织在词汇建模中提供了更大的可解释性，有助于增强跨各种文本处理任务的泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2502.05395</guid>
      <pubDate>Tue, 11 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>