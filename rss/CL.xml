<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 29 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于图神经网络的文本分类优化算法</title>
      <link>https://arxiv.org/abs/2408.15257</link>
      <description><![CDATA[arXiv:2408.15257v1 Announce Type: new 
摘要：在自然语言处理领域，文本分类作为一项基础任务，具有重要的研究价值和应用前景。传统的文本分类方法通常依赖于词袋模型或TF-IDF等特征表示，这些方法忽略了单词之间的语义联系，难以掌握文本的深层结构细节。最近，GNN因其能够有效处理非欧几里得数据而被证明是文本分类任务的宝贵资产。然而，现有的基于GNN的文本分类方法仍然面临着图结构构建复杂、模型训练成本高等挑战。本文介绍了一种利用图神经网络的文本分类优化算法。通过引入自适应的图构建策略和高效的图卷积操作，有效提高了文本分类的准确率和效率。实验结果表明，所提出的方法在多个公共数据集上超越了传统方法和现有的GNN模型，凸显了其在文本分类任务中的优越性能和可行性。]]></description>
      <guid>https://arxiv.org/abs/2408.15257</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多任务微调和生成对抗学习以改进辅助分类</title>
      <link>https://arxiv.org/abs/2408.15265</link>
      <description><![CDATA[arXiv:2408.15265v1 公告类型：新
摘要：在本研究中，我们实现了一种新颖的 BERT 架构，用于对三个下游任务进行多任务微调：情绪分类、释义检测和语义文本相似性预测。我们的模型多任务 BERT 结合了层共享和三重架构、自定义句子对标记化、损失配对和梯度手术。此类优化在测试数据上产生了 0.516 的情绪分类准确率、0.886 的释义检测准确率和 0.864 的语义文本相似性相关性。我们还将生成对抗学习应用于 BERT，构建了一个条件生成器模型，该模型从潜在空间映射以在 $\mathbb{R}^{768}$ 中创建假嵌入。这些假嵌入与真实的 BERT 嵌入连接起来，并传递到鉴别器模型中进行辅助分类。使用这个我们称之为 AC-GAN-BERT 的框架，我们进行半监督敏感性分析，以研究增加未标记训练数据量对 AC-GAN-BERT 测试准确率的影响。总体而言，除了实现高性能多任务分类系统之外，我们的创新之处在于应用对抗性学习来构建模仿 BERT 的生成器。我们发现条件生成器成功生成了丰富的嵌入，并与类标签具有明显的空间相关性，从而避免了模式崩溃。我们的研究结果验证了 GAN-BERT 方法，并指出了生成器辅助知识提炼的未来方向。]]></description>
      <guid>https://arxiv.org/abs/2408.15265</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 COMET 的陷阱和前景</title>
      <link>https://arxiv.org/abs/2408.15366</link>
      <description><![CDATA[arXiv:2408.15366v1 公告类型：新
摘要：自推出以来，COMET 指标在机器翻译界开辟了一条道路，因为它与人类对翻译质量的判断具有很强的相关性。它的成功源于它是一种经过修改的预训练多语言模型，经过微调以进行质量评估。然而，作为一种机器学习模型，它也引发了一系列可能并不广为人知的新陷阱。我们从三个方面调查了这些意外行为：1）技术：过时的软件版本和计算精度；2）数据：测试时的空内容、语言不匹配和翻译语以及训练中的分布和领域偏差；3）使用和报告：文献中的多参考支持和模型引用。所有这些问题都意味着 COMET 分数在论文甚至技术设置之间是不可比的，我们提出了解决每个问题的观点。此外，我们发布了 SacreCOMET 包，它可以为软件和模型配置生成签名以及适当的引用。这项工作的目标是帮助社区更加合理地使用 COMET 指标。]]></description>
      <guid>https://arxiv.org/abs/2408.15366</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DualKanbaFormer：柯尔莫哥洛夫-阿诺德网络和状态空间模型 DualKanbaFormer：柯尔莫哥洛夫-阿诺德网络和状态空间模型 Transformer 用于基于多模态方面的情绪分析</title>
      <link>https://arxiv.org/abs/2408.15379</link>
      <description><![CDATA[arXiv:2408.15379v1 公告类型：新
摘要：多模态基于方面的情绪分析 (MABSA) 通过将文本与图像等其他数据类型相结合来增强情绪检测。然而，尽管设置了重要的基准，但注意力机制在有效建模文本中方面和观点目标之间的长距离依赖关系方面表现出局限性。它们在捕获视觉表示的全局上下文依赖关系方面也面临挑战。为此，我们提出了 Kolmogorov-Arnold 网络 (KAN) 和选择性状态空间模型 (Mamba) 转换器 (DualKanbaFormer)，这是一种解决上述问题的新颖架构。我们利用 Mamba 的强大功能来捕获全局上下文依赖关系，利用多头注意力 (MHA) 来捕获局部上下文依赖关系，并利用 KAN 来捕获文本表示（文本 KanbaFormer）和视觉表示（视觉 KanbaFormer）的非线性建模模式。此外，我们通过门控融合层将文本 KanbaFormer 和视觉 KanbaFomer 融合，以捕捉模态间动态。根据大量实验结果，我们的模型在两个公共数据集上的表现优于一些最先进的 (SOTA) 研究。]]></description>
      <guid>https://arxiv.org/abs/2408.15379</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当今法学硕士研究中的敬畏、规律和缺陷</title>
      <link>https://arxiv.org/abs/2408.15409</link>
      <description><![CDATA[arXiv:2408.15409v2 公告类型：新
摘要：我们对当代大型语言模型 (LLM) 研究背后的科学方法进行了严格的审查。为此，我们根据被认为是良好研究的典型标准（例如，统计测试的存在和可重复性）评估了 2,000 多项研究工作，并将其与处于争议中心的论点进行交叉验证（例如，关于突发行为的声明、使用 LLM 作为评估者）。我们发现了多种趋势，例如关于突发行为和道德免责声明的声明减少；尽管社区对其可用性缺乏共识，但 LLM 作为评估者的数量有所增加；以及 LLM 推理能力的声明有所增加，通常不利用人工评估。本文强调需要对该领域进行更多的审查和严格要求，以达到负责任的科学方法的基本原则，即合乎道德、可重复、系统和接受批评。]]></description>
      <guid>https://arxiv.org/abs/2408.15409</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>下一个标记预测的隐式几何：从语言稀疏模式到模型表示</title>
      <link>https://arxiv.org/abs/2408.15417</link>
      <description><![CDATA[arXiv:2408.15417v1 公告类型：新
摘要：大型文本语料库上的下一个标记预测 (NTP) 已成为训练大型语言模型的首选范例。然而，NTP 如何影响语言模式到结果模型表示的几何属性的映射仍不清楚。我们将大型语言模型的训练定义为稀疏概率标签向量上的软标签分类，再加上允许无限制生成上下文嵌入的分析近似。这种方法将 NTP 训练与 logit 域中的秩约束、核范数正则化优化联系起来，为分析单词和上下文嵌入的几何形状提供了一个框架。在大型嵌入空间中，我们发现 NTP 隐式地倾向于学习具有稀疏加低秩结构的 logit。虽然稀疏分量捕获了上下文-单词对的共现频率，但随着训练的进行而占据主导地位的正交低秩分量仅取决于共现矩阵的稀疏模式。因此，当投影到适当的子空间时，紧随同一组下一个标记的上下文的表示会崩溃，我们将这种现象称为子空间崩溃。我们在合成和小规模真实语言数据集上验证了我们的发现。最后，我们概述了潜在的研究方向，旨在加深对 NTP 对语言模式和规律学习的影响的理解。]]></description>
      <guid>https://arxiv.org/abs/2408.15417</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Legilimens：大型语言模型服务的实用统一内容审核</title>
      <link>https://arxiv.org/abs/2408.15488</link>
      <description><![CDATA[arXiv:2408.15488v1 公告类型：新
摘要：鉴于大型语言模型 (LLM) 生成的不安全内容对社会的影响，确保 LLM 服务符合安全标准是 LLM 服务提供商的关键关注点。常见的内容审核方法受到有效性和效率困境的限制，其中简单模型很脆弱，而复杂模型则消耗过多的计算资源。在本文中，我们首次揭示了通过从面向聊天的 LLM 中提取概念特征可以实现有效和高效的内容审核，尽管它们最初是针对对话而不是内容审核进行微调的。我们为 LLM 服务提出了一个实用且统一的内容审核框架，名为 Legilimens，它兼具有效性和效率。我们基于红队模型的数据增强增强了 Legilimens 对最先进越狱的鲁棒性。此外，我们还开发了一个框架来从理论上分析 Legilimens 与其他方法相比的成本效益。我们对五个主机 LLM、十七个数据集和九种越狱方法进行了广泛的实验，以验证 Legilimens 对抗普通和自适应对手的有效性、效率和稳健性。将 Legilimens 与商业和学术基线进行比较，证明了 Legilimens 的卓越性能。此外，我们确认 Legilimens 可以应用于少样本场景并扩展到多标签分类任务。]]></description>
      <guid>https://arxiv.org/abs/2408.15488</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过指令感知上下文压缩增强和加速大型语言模型</title>
      <link>https://arxiv.org/abs/2408.15491</link>
      <description><![CDATA[arXiv:2408.15491v1 公告类型：新
摘要：大型语言模型 (LLM) 因其在各种任务中的出色表现而受到广泛关注。然而，为了缓解幻觉问题，LLM 通常结合检索增强管道，为其提供丰富的外部知识和上下文。然而，挑战源于从检索器检索到的不准确和粗粒度的上下文。向 LLM 提供不相关的上下文会导致响应较差、推理延迟增加和成本增加。本文介绍了一种称为指令感知上下文压缩的方法，它可以过滤掉信息量较少的内容，从而加速和增强 LLM 的使用。实验结果表明，指令感知上下文压缩显着降低了内存消耗并最大限度地减少了生成延迟，同时保持了与使用完整上下文相当的性能水平。具体来说，我们实现了上下文相关成本的降低 50%，推理内存使用量减少了 5%，推理速度提高了 2.2 倍，而 Rouge-1 中仅下降了 0.047。这些结果表明我们的方法在效率和性能之间取得了有效的平衡。]]></description>
      <guid>https://arxiv.org/abs/2408.15491</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ReMamba：为 Mamba 提供有效的长序列建模</title>
      <link>https://arxiv.org/abs/2408.15496</link>
      <description><![CDATA[arXiv:2408.15496v2 公告类型：新
摘要：虽然 Mamba 架构在短上下文自然语言处理 (NLP) 任务上表现出卓越的推理效率和竞争性能，但经验证据表明，与基于 Transformer 的模型相比，其理解长上下文的能力有限。在本研究中，我们研究了 Mamba 模型的长上下文效率问题，并提出了 ReMamba，它增强了 Mamba 理解长上下文的能力。ReMamba 在两阶段重新转发过程中结合了选择性压缩和自适应技术，将额外的推理成本开销降至最低。在 LongBench 和 L-Eval 基准上的实验结果证明了 ReMamba 的有效性，分别比基线提高了 3.2 和 1.6 个百分点，并且达到了几乎与相同大小的 Transformer 模型相当的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.15496</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Dolphin：长上下文作为节能设备语言模型的新模式</title>
      <link>https://arxiv.org/abs/2408.15518</link>
      <description><![CDATA[arXiv:2408.15518v1 公告类型：新
摘要：本文介绍了 Dolphin，一种用于语言模型中节能处理长上下文的新型解码器-解码器架构。我们的方法解决了设备上模型固有的大量能耗和延迟挑战。Dolphin 采用紧凑的 0.5B 参数解码器将大量上下文信息提炼到内存嵌入中，大大减少了主要 7B 参数解码器模型的输入长度。受视觉语言模型的启发，我们重新利用图像嵌入投影仪来编码长文本上下文，有效地将扩展上下文视为一种独特的模态。这种创新方法能够处理更长的上下文，而无需与扩展输入序列相关的典型计算开销。实证评估表明，与传统的全长上下文处理方法相比，能源效率提高了 10 倍，延迟减少了 5 倍，且响应质量没有降低。我们的工作有助于为设备应用程序开发更具可持续性和可扩展性的语言模型，满足资源受限环境中对节能和响应式 AI 技术的关键需求，同时保持理解长上下文的准确性。这项研究对更广泛的自然语言处理领域具有重要意义，特别是在资源受限环境下的高效模型设计领域。通过在边缘设备上启用更复杂的 AI 功能，Dolphin 为计算资源极为宝贵的广泛应用中的高级语言处理铺平了道路。Dolphin 模型可在 https://huggingface.co/NexaAIDev/Dolphin 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2408.15518</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LRP4RAG：通过分层相关性传播检测检索增强生成中的幻觉</title>
      <link>https://arxiv.org/abs/2408.15533</link>
      <description><![CDATA[arXiv:2408.15533v2 公告类型：新
摘要：检索增强生成 (RAG) 已成为缓解大型语言模型 (LLM) 中幻觉的主要技术。然而，不完整的知识提取和不充分的理解仍然会误导 LLM 产生不相关甚至矛盾的反应，这意味着幻觉在 RAG 中持续存在。在本文中，我们提出了 LRP4RAG，一种基于分层相关性传播 (LRP) 算法的用于检测 RAG 中幻觉的方法。具体而言，我们首先利用 LRP 计算 RAG 生成器的输入和输出之间的相关性。然后我们对相关性矩阵进行进一步的提取和重采样。处理后的相关性数据被输入到多个分类器中以确定输出是否包含幻觉。据我们所知，这是 LRP 首次用于检测 RAG 幻觉，大量实验表明 LRP4RAG 的表现优于现有基线。]]></description>
      <guid>https://arxiv.org/abs/2408.15533</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跨语言交流中警告错误聊天翻译的调查</title>
      <link>https://arxiv.org/abs/2408.15543</link>
      <description><![CDATA[arXiv:2408.15543v1 公告类型：新
摘要：聊天的复杂性对机器翻译模型提出了重大挑战。认识到需要一个精确的评估指标来解决聊天翻译问题，本研究引入了聊天翻译的多维质量指标 (MQM-Chat)。通过使用 MQM-Chat 对五个模型进行的实验，我们观察到所有模型都产生了某些基本错误，而每个模型都有不同的缺点，例如遗漏、过度纠正模棱两可的源内容和流行语问题，导致风格化信息的丢失。我们的研究结果强调了 MQM-Chat 在评估聊天翻译方面的有效性，强调了风格化内容和对话一致性对未来研究的重要性。]]></description>
      <guid>https://arxiv.org/abs/2408.15543</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WildFeedback：将 LLM 与现场用户交互和反馈相结合</title>
      <link>https://arxiv.org/abs/2408.15549</link>
      <description><![CDATA[arXiv:2408.15549v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的不断发展，将这些模型与人类偏好进行对齐已成为一项关键挑战。传统的对齐方法依赖于人类或 LLM 注释的数据集，其局限性在于其资源密集型性质、固有的主观性以及放大模型偏差的反馈循环风险。为了克服这些限制，我们引入了 WildFeedback，这是一个新颖的框架，它利用实时、现场的用户交互来创建更准确反映真实人类价值观的偏好数据集。WildFeedback 通过三个步骤运行：反馈信号识别、偏好数据构建和用户指导评估。我们将这个框架应用于大量用户-LLM 对话语料库，从而产生了一个反映真实用户偏好的丰富偏好数据集。该数据集通过识别和分类自然对话中的反馈信号来捕捉用户偏好的细微差别，从而能够构建更具代表性和上下文敏感的对齐数据。我们进行了大量的实验，结果表明，在 WildFeedback 上进行微调的 LLM 能够显著提高与用户偏好的一致性，传统基准和我们提出的用户指导评估都证明了这一点。通过整合来自实际用户的实时反馈，WildFeedback 解决了困扰现有方法的可扩展性、主观性和偏见挑战，标志着朝着开发更能响应用户多样化和不断变化的需求的 LLM 迈出了重要一步。总之，WildFeedback 提供了一种强大、可扩展的解决方案，使 LLM 与真正的人类价值观保持一致，为以用户为中心的语言模型的开发和评估树立了新标准。]]></description>
      <guid>https://arxiv.org/abs/2408.15549</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过特征采样和部分对齐蒸馏来增强无损推测解码</title>
      <link>https://arxiv.org/abs/2408.15562</link>
      <description><![CDATA[arXiv:2408.15562v1 公告类型：新 
摘要：无损推测解码通过使用轻量级草稿模型生成树形候选，然后由目标 LLM 并行验证，从而加速目标大型语言模型 (LLM) 推理。目前，有效的方法利用草稿模型中的特征级而非标记级自回归来促进更直接的预测和增强的知识提炼。在本文中，我们重新评估这些方法并提出 FSPAD（无损推测解码的特征采样和部分对齐提炼），它在现有框架中引入了两个简单有效的组件来促进无损推测解码。首先，FSPAD 利用标记嵌入在高维空间中对目标 LLM 的特征进行采样，然后将它们输入到草稿模型中，因为特征固有的不确定性阻止草稿模型获得目标 LLM 的特定标记输出。其次，FSPAD 引入了部分对齐蒸馏来削弱草稿模型中特征与 logit 之间的联系，旨在减少训练过程中特征对齐与 logit 置信度之间的冲突。我们的实验包括对 Vicuna 和 LLaMA3-Instruct 系列中最大和最小模型的贪婪和非贪婪解码，以及多轮对话、翻译、摘要、问答、数学推理和检索增强生成中的任务。结果表明，FSPAD 在上述所有任务和目标 LLM 中的表现均优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2408.15562</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SIaM：大型语言模型的自我改进代码辅助数学推理</title>
      <link>https://arxiv.org/abs/2408.15565</link>
      <description><![CDATA[arXiv:2408.15565v1 公告类型：新
摘要：通过编码教授大型语言模型 (LLM) 解决数学问题是一种日益流行的趋势。现有研究主要侧重于促使强大的闭源模型生成种子训练数据，然后进行域内数据增强，从而使 LLM 具备相当大的代码辅助数学推理能力。然而，持续使用来自少数数据集（如 GSM8K）的增强数据训练这些模型可能会损害它们的泛化能力，并将其有效性限制在狭窄的问题类型范围内。相反，通过利用大规模、专家编写的多样化数学问答对来改进此类 LLM 的潜力仍未得到探索。为了利用这些资源并应对代码响应评估等独特挑战，我们提出了一种新颖的范式，该范式使用基于代码的批评模型来指导包括问题代码数据构建、质量控制和补充评估在内的步骤。我们还探索了使用自生成指令/偏好数据的不同对齐算法，以促进持续改进。在英语和中文的领域内（高达+5.7%）和领域外（+4.4%）基准上进行的实验证明了所提出范式的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.15565</guid>
      <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>