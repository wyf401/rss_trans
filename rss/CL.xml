<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 13 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用混合大型语言模型进行零样本机器生成文本检测</title>
      <link>https://arxiv.org/abs/2409.07615</link>
      <description><![CDATA[arXiv:2409.07615v1 公告类型：新
摘要：经过大规模训练并具有强大文本生成能力的大型语言模型 (LLM) 的传播大大增加了生成式 AI 技术所带来的威胁，因为它降低了生成有害、有毒、伪造或伪造内容的成本。作为回应，已经提出了各种提案来自动区分人工生成的文本和人类编写的文本，通常将问题定义为分类问题。大多数方法都通过精心挑选的检测器 LLM 评估输入文档，假设低困惑度分数可靠地表示机器制作的内容。由于使用单个检测器会导致性能脆弱，我们改为考虑多个检测器并得出一种新的、理论上有依据的方法来结合它们各自的优势。我们使用各种生成器 LLM 的实验表明，我们的方法有效地提高了检测的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2409.07615</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SimulBench：使用创造性模拟任务评估语言模型</title>
      <link>https://arxiv.org/abs/2409.07641</link>
      <description><![CDATA[arXiv:2409.07641v1 公告类型：新 
摘要：我们引入了 SimulBench，这是一个基准测试，旨在评估大型语言模型 (LLM) 在各种创造性模拟场景中的表现，例如充当 Linux 终端或与用户一起玩文字游戏。虽然这些模拟任务是衡量 LLM 一般智能的有效指标，但它们很少被纳入现有基准测试中。一个主要的挑战是开发一个评估框架来公平地测试不同的 LLM，同时保留用户和 AI 之间模拟任务的多轮交互性质。为了解决这个问题，我们建议使用固定的 LLM 作为用户代理，首先与 LLM 交互，以收集不同任务下的对话。然后，提取具有挑战性的对话脚本来评估不同的目标 LLM。为了便于对 \DataName{} 进行自动评估，GPT-4 被用作评估者，负责审查目标 LLM 在给定多轮对话脚本的情况下生成的最终响应的质量。我们的综合实验表明，这些模拟任务以其独特的性质继续带来重大挑战，并显示出专有模型与最先进的开放式 LLM 之间的差距。例如，GPT-4-turbo 在 18.55% 的案例中胜过 LLaMA-3-70b-Chat。]]></description>
      <guid>https://arxiv.org/abs/2409.07641</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于话语重写的无监督对话主题分割模型</title>
      <link>https://arxiv.org/abs/2409.07672</link>
      <description><![CDATA[arXiv:2409.07672v1 公告类型：新
摘要：对话主题分割在各类对话建模任务中起着至关重要的作用。最先进的无监督DTS方法通过邻近话语匹配和伪分割从对话数据中学习主题感知的话语表征，以进一步挖掘未标记对话关系中的有用线索。然而，在多轮对话中，话语通常具有共指或遗漏，导致直接使用这些话语进行表征学习可能会对邻近话语匹配任务中的语义相似度计算产生负面影响。为了充分利用对话关系中的有用线索，本研究提出了一种新颖的无监督对话主题分割方法，该方法将话语重写（UR）技术与无监督学习算法相结合，通过重写对话以恢复共指和遗漏的单词，从而有效地利用未标记对话中的有用线索。与现有的无监督模型相比，所提出的话语重写主题分割模型 (UR-DTS) 显著提高了主题分割的准确性。主要发现是，在 DialSeg711 上，绝对错误分数和 WD 方面的表现提高了约 6%，绝对错误分数达到 11.42%，WD 达到 12.97%。在 Doc2Dial 上，绝对错误分数和 WD 分别提高了约 3% 和 2%，导致 SOTA 在绝对错误分数方面达到 35.17%，在 WD 方面达到 38.49%。这表明该模型在捕捉对话主题的细微差别以及利用无标记对话的实用性和挑战方面非常有效。]]></description>
      <guid>https://arxiv.org/abs/2409.07672</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法律人工智能解决方案实验：以司法公正问答为例</title>
      <link>https://arxiv.org/abs/2409.07713</link>
      <description><![CDATA[arXiv:2409.07713v1 公告类型：新
摘要：生成式 AI 模型（例如 GPT 和 Llama 系列）在帮助普通人回答法律问题方面具有巨大潜力。然而，之前很少有研究关注在普通人背景下对这些模型进行数据采购、推理和评估。为此，我们提出了一个以人为本的法律 NLP 流程，涵盖数据采购、推理和评估。我们推出并发布了一个数据集 LegalQA，其中包含从劳动法到刑法的真实而具体的法律问题、法律专家撰写的相应答案以及每个答案的引文。我们为该数据集开发了一个自动评估协议，然后表明，尽管数据量少了 9 个数量级，但仅从训练集中的 850 个引文进行的检索增强生成就可以匹敌或超越全互联网检索。最后，我们提出了落后于闭源模型的开源工作的未来方向。]]></description>
      <guid>https://arxiv.org/abs/2409.07713</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Ruri：日语通用文本嵌入</title>
      <link>https://arxiv.org/abs/2409.07737</link>
      <description><![CDATA[arXiv:2409.07737v1 公告类型：新
摘要：我们报告了 Ruri 系列日语通用文本嵌入模型的开发情况。虽然近年来，英语和多语言环境中通用文本嵌入模型的开发一直很活跃，但日语模型开发仍然不足。主要原因是缺乏数据集和缺乏必要的专业知识。在本报告中，我们详细介绍了 Ruri 的开发过程。具体来说，我们讨论了使用 LLM 生成的合成数据集训练嵌入模型、构建用于数据集过滤和知识提炼的重新排序器，以及对生成的通用文本嵌入模型的性能评估。]]></description>
      <guid>https://arxiv.org/abs/2409.07737</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>支持在线讨论：将人工智能融入 Adhocracy+ 参与平台，以增强审议</title>
      <link>https://arxiv.org/abs/2409.07780</link>
      <description><![CDATA[arXiv:2409.07780v1 公告类型：新
摘要：在线空间允许人们讨论重要问题并做出联合决策，无论他们身在何处或处于哪个时区。然而，如果没有适当的支持和周到的设计，这些讨论在交换意见时往往缺乏结构和礼貌。人工智能 (AI) 为支持大规模在线参与过程的参与者和组织者提供了机会。在本文中，我们介绍了大型开源参与平台 adhocracy+ 的扩展，它提供了两个由 AI 支持的额外辩论模块，以提高讨论质量和参与者互动。]]></description>
      <guid>https://arxiv.org/abs/2409.07780</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过减少嵌入变异性实现稳定的语言模型预训练</title>
      <link>https://arxiv.org/abs/2409.07787</link>
      <description><![CDATA[arXiv:2409.07787v1 公告类型：新
摘要：稳定的预训练对于实现性能更好的语言模型至关重要。但是，由于计算成本高昂，通过计算每一步的梯度方差来跟踪预训练稳定性是不切实际的。我们探索了 Token Embedding Variability (TEV) 作为评估具有预层规范化的语言模型中预训练稳定性的简单有效代理，因为较浅的层更容易出现梯度爆炸（第 2.2 节）。此外，我们提出了多头低秩注意 (MLRA) 作为一种架构，通过限制输出嵌入方差的指数增长来缓解这种不稳定性，从而防止梯度爆炸（第 3.2 节）。使用 MLRA 的 GPT-2 的实证结果表明，稳定性提高，困惑度降低，尤其是在更深的模型中。]]></description>
      <guid>https://arxiv.org/abs/2409.07787</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的中文语音识别全文纠错</title>
      <link>https://arxiv.org/abs/2409.07790</link>
      <description><![CDATA[arXiv:2409.07790v1 公告类型：新
摘要：大型语言模型 (LLM) 已显示出在自动语音识别 (ASR) 中纠错的巨大潜力。然而，大多数研究都集中在短时语音记录中的话语上，这是监督式 ASR 训练的主要语音数据形式。本文研究了 LLM 对 ASR 系统从较长的语音记录（例如播客、新闻广播和会议的记录）生成的全文纠错的有效性。首先，我们开发了一个用于全文纠错的中文数据集，名为 ChFT，利用涉及文本到语音合成、ASR 和纠错对提取器的管道。该数据集使我们能够跨上下文纠正错误，包括全文和片段，并解决更广泛的错误类型，例如标点符号恢复和逆文本规范化，从而使纠正过程更加全面。其次，我们使用一组不同的提示和目标格式在构建的数据集上对预训练的 LLM 进行微调，并评估其在全文纠错方面的表现。具体来说，我们根据全文和片段设计提示，考虑各种输出格式，例如直接纠正的文本和基于 JSON 的纠错对。通过各种测试设置，包括同质、最新和硬测试集，我们发现微调后的 LLM 在具有不同提示的全文设置中表现良好，每个提示都有自己的优点和缺点。这为进一步的研究奠定了良好的基础。数据集可在网站上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.07790</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可控的合成临床记录生成与隐私保障</title>
      <link>https://arxiv.org/abs/2409.07809</link>
      <description><![CDATA[arXiv:2409.07809v1 公告类型：新
摘要：在机器学习领域，特定领域的注释数据是训练有效模型的宝贵资源。然而，在医学领域，这些数据通常包括个人健康信息 (PHI)，引发了严重的隐私问题。围绕 PHI 的严格规定限制了医疗数据集的可用性和共享，这对旨在开发高级机器学习模型的研究人员和从业者构成了重大挑战。在本文中，我们介绍了一种“克隆”包含 PHI 的数据集的新方法。我们的方法确保克隆的数据集保留原始数据的基本特征和实用性，而不会损害患者的隐私。通过利用差异隐私技术和新颖的微调任务，我们的方法可以生成不含可识别信息的数据集，同时保留模型训练所需的统计属性。我们进行效用测试以评估在克隆数据集上训练的机器学习模型的性能。结果表明，我们克隆的数据集不仅符合隐私标准，而且与在传统匿名数据集上训练的数据集相比，模型性能也得到了提升。这项工作为在机器学习中合乎道德且有效地利用敏感医疗数据提供了可行的解决方案，促进了医学研究的进步和稳健预测模型的开发。]]></description>
      <guid>https://arxiv.org/abs/2409.07809</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在语言模型的指导下从知识图谱中学习规则</title>
      <link>https://arxiv.org/abs/2409.07869</link>
      <description><![CDATA[arXiv:2409.07869v1 公告类型：新
摘要：信息提取方面的进步使得大型知识图谱（例如 Yago、Wikidata 或 Google KG）的自动构建成为可能，这些图谱广泛应用于语义搜索或数据分析等许多应用中。然而，由于它们是半自动构建的，KG 往往是不完整的。规则学习方法涉及从 KG 中提取频繁模式并将其转化为规则，可用于预测可能缺失的事实。此过程中的一个关键步骤是规则排名。规则排名对于高度不完整或有偏见的 KG（例如，KG 主要存储有关名人的事实）尤其具有挑战性，因为在这种情况下，有偏见的规则可能最适合数据并根据规则置信度等标准统计指标排在首位。为了解决这个问题，先前的研究提出不仅依靠原始 KG 而且还依靠 KG 嵌入模型预测的事实对规则进行排名。与此同时，随着语言模型（LM）的兴起，一些研究声称 LM 可以作为 KG 补全的替代手段。在本文中，我们的目标是验证 LM 的利用在多大程度上有助于提高规则学习系统的质量。]]></description>
      <guid>https://arxiv.org/abs/2409.07869</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于语料库的台湾普通话会话单音节词音高轮廓调查</title>
      <link>https://arxiv.org/abs/2409.07891</link>
      <description><![CDATA[arXiv:2409.07891v1 公告类型：新
摘要：在普通话中，单音节词在单独或仔细讲话时产生的声调轮廓以四种词汇声调为特征：高平调（T1）、上调（T2）、下调（T3）和下调（T4）。然而，在自发语音中，由于音节内共同发音和音节间与相邻音调的共同发音，单音节词的实际声调实现可能与这些规范声调有显著偏差。此外，Chuang 等人（2024）最近报道，具有 T2-T4 声调模式的双音节普通话词的声调轮廓由其含义共同决定。继他们的研究之后，我们基于语料库，对单音节词的音高轮廓在自然对话普通话中的实现方式进行了研究，一方面关注上下文预测因素的影响，另一方面关注词义如何共同决定音高轮廓。我们分析了自发台湾普通话语料库中 63 种不同词类的 3824 个标记的 F0 轮廓，使用广义加性（混合）模型将给定的观察到的音高轮廓分解为一组分量音高轮廓。我们发现声调上下文会大大改变单词的规范声调。一旦控制了声调上下文的影响，T2 和 T3 就会变成低平音，而 T1 则是高音，T4 则是高到中降调。在标准描述中，中性声调 (T0) 是基于前一个声调实现的，它本身就是一个低音调，其他预测因子会像标准声调 T1、T2、T3 和 T4 一样对其进行修改。我们还表明，单词，尤其是词义，共同决定了单词的 F0 轮廓。使用随机森林对变量重要性的分析进一步证实了声调上下文的显著影响和词义的影响。]]></description>
      <guid>https://arxiv.org/abs/2409.07891</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CLC-UKET 数据集：英国就业法庭的案件结果预测基准</title>
      <link>https://arxiv.org/abs/2409.08098</link>
      <description><![CDATA[arXiv:2409.08098v1 公告类型：新
摘要：本文通过制定预测英国就业法庭 (UKET) 案件结果的基准，探讨了技术创新与司法公正之间的交集。为了应对大量人工注释的挑战，该研究采用大型语言模型 (LLM) 进行自动注释，从而创建了 CLC-UKET 数据集。该数据集包含大约 19,000 个 UKET 案件及其元数据。全面的法律注释涵盖事实、索赔、先例参考、法定参考、案件结果、理由和管辖权法规。借助 CLC-UKET 数据，我们检查了 UKET 中的多类案件结果预测任务。收集人工预测以建立模型比较的性能参考。基线模型的经验结果表明，微调的 Transformer 模型在 UKET 预测任务上的表现优于零样本和少样本 LLM。通过将与任务相关的信息集成到少样本示例中，可以增强零样本 LLM 的性能。我们希望 CLC-UKET 数据集以及人工注释和实证结果可以成为与就业相关的争议解决的宝贵基准。]]></description>
      <guid>https://arxiv.org/abs/2409.08098</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Faetar 基准：资源极其匮乏的语言中的语音识别</title>
      <link>https://arxiv.org/abs/2409.08103</link>
      <description><![CDATA[arXiv:2409.08103v1 公告类型：新
摘要：我们推出了 Faetar 自动语音识别基准，这是一个基准语料库，旨在突破当前低资源语音识别方法的极限。Faetar 是一种主要在意大利使用的 Franco-Proven\c{c}al 变体，没有标准正字法，除了基准中包含的内容之外几乎没有现有的文本或语音资源，并且与其他形式的 Franco-Proven\c{c}al 有很大不同。该语料库来自现场录音，其中大部分都是嘈杂的，只有 5 小时有匹配的转录，并且强制对齐的质量参差不齐。该语料库包含另外 20 小时未标记的语音。我们报告了最先进的多语言语音基础模型的基线结果，最佳音素错误率为 30.4%，使用管道继续使用未标记集对基础模型进行预训练。]]></description>
      <guid>https://arxiv.org/abs/2409.08103</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WhisperNER：统一开放命名实体和语音识别</title>
      <link>https://arxiv.org/abs/2409.08107</link>
      <description><![CDATA[arXiv:2409.08107v1 公告类型：新
摘要：将命名实体识别 (NER) 与自动语音识别 (ASR) 相结合可以显著提高转录准确性和信息量。在本文中，我们介绍了 WhisperNER，这是一种允许联合语音转录和实体识别的新型模型。WhisperNER 支持开放式 NER，能够在推理时识别多样化和不断发展的实体。基于开放式 NER 研究的最新进展，我们使用合成语音样本扩充了一个大型合成数据集。这使我们能够在具有各种 NER 标签的大量示例上训练 WhisperNER。在训练期间，该模型会使用 NER 标签提示并进行优化以输出转录的话语以及相应的标记实体。为了评估 WhisperNER，我们为常用的 NER 基准生成合成语音，并使用开放 NER 标签注释现有的 ASR 数据集。我们的实验表明，WhisperNER 在域外开放类型 NER 和监督微调方面都优于自然基线。]]></description>
      <guid>https://arxiv.org/abs/2409.08107</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM-POTUS 分数：使用大型语言模型分析总统辩论的框架</title>
      <link>https://arxiv.org/abs/2409.08147</link>
      <description><![CDATA[arXiv:2409.08147v1 公告类型：新
摘要：大型语言模型在自然语言处理方面表现出了卓越的能力，但它们在政治话语分析中的应用仍未得到充分探索。本文介绍了一种使用 LLM 评估总统辩论表现的新方法，解决了客观评估辩论结果的长期挑战。我们提出了一个框架，分析候选人的“政策、角色和观点”（3P）以及它们如何与四个主要受众群体的“利益、意识形态和身份”（3I）产生共鸣：选民、企业、捐助者和政客。我们的方法采用大型语言模型来生成 LLM-POTUS 分数，这是一种基于 3P 和 3I 之间一致性的辩论表现的定量衡量标准。我们应用该框架分析了最近美国总统辩论的记录，展示了它能够对候选人的表现进行细致入微、多维度的评估。我们的研究结果揭示了不同辩论策略的有效性及其对不同受众群体的影响。这项研究不仅为政治分析提供了一种新工具，还探讨了在复杂的社会背景下使用法学硕士作为公正法官的潜力和局限性。此外，该框架为个人公民提供了一种独立的工具来评估总统辩论的表现，这增强了民主参与度并减少了对可能有偏见的媒体解释和机构影响的依赖，从而加强了知情公民参与的基础。]]></description>
      <guid>https://arxiv.org/abs/2409.08147</guid>
      <pubDate>Fri, 13 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>