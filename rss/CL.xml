<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 04 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用大型语言模型来增强癌症临床试验教育材料</title>
      <link>https://arxiv.org/abs/2412.01955</link>
      <description><![CDATA[arXiv:2412.01955v1 公告类型：新 
摘要：由于缺乏面向参与者的信息和教育资源，癌症临床试验在招募和参与方面经常面临挑战。本研究调查了大型语言模型 (LLM)，特别是 GPT4，在从临床试验知情同意书中生成患者友好的教育内容方面的潜力。使用来自 ClinicalTrials.gov 的数据，我们采用零样本学习来创建试验摘要，采用一样本学习来开发多项选择题，并通过患者调查和众包注释评估其有效性。结果表明，GPT4 生成的摘要既可读又全面，可以提高患者对临床试验的理解和兴趣。多项选择题表现出很高的准确性和与众包注释者的一致性。对于这两种资源类型，都发现了需要持续人工监督的幻觉。研究结果表明，LLM 具有“开箱即用”的潜力，只需极少的针对特定试验的工程即可支持临床试验教育材料的生成，但仍需要在人机交互的环境下实施，以避免错误信息风险。]]></description>
      <guid>https://arxiv.org/abs/2412.01955</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实时多语言手语处理</title>
      <link>https://arxiv.org/abs/2412.01991</link>
      <description><![CDATA[arXiv:2412.01991v1 公告类型：新
摘要：手语处理 (SLP) 是一个由自然语言处理 (NLP) 和计算机视觉组成的跨学科领域。它专注于手语的计算理解、翻译和生成。传统方法通常受到使用基于注释的系统的限制，这些系统既是语言特定的，又不足以捕捉手语的多维性质。这些限制阻碍了能够有效处理手语的技术的发展。
本论文旨在通过提出一个可以弥合现有技术差距的简单范例来彻底改变 SLP 领域。我们建议使用通用手语转录符号系统 SignWiring 作为手语的视觉手势模式和基于文本的语言表示之间的中介链接。
我们为 SLP 社区贡献基础库和资源，从而为更深入地探索手语翻译和制作任务奠定基础。这些任务包括将手语从视频翻译成口语文本，反之亦然。通过实证评估，我们确定了转录方法的有效性，以此作为实现更快、更有针对性的研究的关键，从而实现跨多种语言的更自然、更准确的翻译。
我们基于转录的范式的通用性也为 SLP 中的实时、多语言应用铺平了道路，从而为语言技术提供了一种更具包容性和可访问性的方法。这是朝着普遍可访问性迈出的重要一步，使人工智能驱动的语言技术能够更广泛地覆盖聋人和听力障碍者群体。]]></description>
      <guid>https://arxiv.org/abs/2412.01991</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>英语、泰米尔语和僧伽罗语的多向并行命名实体注释语料库</title>
      <link>https://arxiv.org/abs/2412.02056</link>
      <description><![CDATA[arXiv:2412.02056v1 公告类型：新
摘要：本文介绍了一个多向并行英语-泰米尔语-僧伽罗语语料库，该语料库带有命名实体 (NE) 注释，其中僧伽罗语和泰米尔语是资源匮乏的语言。使用预先训练的多语言语言模型 (mLM)，我们在此数据集上为僧伽罗语和泰米尔语建立了新的基准命名实体识别 (NER) 结果。我们还对不同类型的 mLM 的 NER 功能进行了详细调查。最后，我们展示了我们的 NER 系统在资源匮乏的神经机器翻译 (NMT) 任务中的实用性。我们的数据集已公开发布：https://github.com/suralk/multiNER。]]></description>
      <guid>https://arxiv.org/abs/2412.02056</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BN-AuthProf：对社交媒体文本中孟加拉语作者分析的机器学习进行基准测试</title>
      <link>https://arxiv.org/abs/2412.02058</link>
      <description><![CDATA[arXiv:2412.02058v1 公告类型：新
摘要：随着社交媒体平台的广泛使用，作者分析（即对文本进行分析以发现作者的性别和年龄等属性）已变得至关重要。本文重点介绍孟加拉语的作者分析，旨在根据匿名作者在社交媒体上的写作风格提取有关他们的宝贵见解。主要目标是介绍和测试机器学习方法在新创建的孟加拉语作者分析数据集 BN-AuthProf 上的性能。该数据集包含来自 300 位作者的 30,131 条社交媒体帖子，按年龄和性别标记。作者的身份和敏感信息被匿名化以确保隐私。采用了各种经典的机器学习和深度学习技术来评估数据集。对于性别分类，使用支持向量机 (SVM) 实现的最佳准确率为 80%，而多项式朴素贝叶斯 (MNB) 分类器实现了 0.756 的最佳 F1 分数。对于年龄分类，MNB 的最高准确率达到 91%，F1 得分为 0.905。这项研究凸显了机器学习在孟加拉语作者分析中的性别和年龄分类的有效性，其实际意义涵盖营销、安全、法医语言学、教育和刑事调查，同时考虑到隐私和偏见。]]></description>
      <guid>https://arxiv.org/abs/2412.02058</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>让我们逐个变量思考：大型语言模型支持临时概率推理</title>
      <link>https://arxiv.org/abs/2412.02081</link>
      <description><![CDATA[arXiv:2412.02081v1 公告类型：新
摘要：智能的一个标志是能够使用“常识”充实未指定的情况。我们建议从大型语言模型 (LLM) 中提取常识，以可以输入概率推理的形式。我们的调查重点是 $\textit{猜测}$ 问题，例如“新泽西州纽瓦克的 Airbnb 房源多少钱？” 在没有数据访问的情况下制定合理的答案需要利用和整合关于 $\texttt{价格}$ 和 $\texttt{位置}$ 可能与其他变量（例如 $\texttt{房产类型}$）相关的一些常识。我们的框架通过合成一个 $\textit{临时}$ 概率模型来回答这样的问题。首先，我们提示 LLM 提出一组与问题相关的随机变量，然后对它们的联合分布进行矩约束。然后，我们在对数线性族内优化联合分布 $p$，以最大化整体约束满足度。我们的实验表明，可以成功提示 LLM 提出合理的变量，虽然提出的数值约束可能存在噪声，但联合优化它们的满足度可以协调它们。当对来自三个真实世界表格数据集的概率问题进行评估时，我们发现我们的框架在与数据集分布的总变异距离方面的表现与直接提示基线相当，并且同样对噪声具有鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2412.02081</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提高多语言神经机器翻译中仅解码器架构的语言传输能力</title>
      <link>https://arxiv.org/abs/2412.02101</link>
      <description><![CDATA[arXiv:2412.02101v1 公告类型：新
摘要：现有的多语言神经机器翻译 (MNMT) 方法主要侧重于改进具有编码器-解码器架构的模型以翻译多种语言。然而，由于解码器架构在仅在并行数据上训练时性能不佳，因此在 MNMT 中较少被探索。在这项工作中，我们将解码器架构的问题归因于其缺乏语言传输能力。具体而言，解码器架构在用目标语言特征编码源标记方面不足。我们建议将解码过程分为两个阶段，以便在第一阶段明确排除目标标记，以隐式提升跨语言的传输能力。此外，我们对翻译指令施加了对比学习，从而提高了零样本翻译的性能。我们在 TED-19 和 OPUS-100 数据集上进行了实验，同时考虑了从头开始训练和微调场景。实验结果表明，与编码器-解码器架构相比，我们的方法不仅在监督翻译中表现出色，而且在零样本翻译中实现了高达 3.39 BLEU、6.99 chrF++、3.22 BERTScore 和 4.81 COMET 的提升。]]></description>
      <guid>https://arxiv.org/abs/2412.02101</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>可解释和可阐释的多模态大型语言模型：综合调查</title>
      <link>https://arxiv.org/abs/2412.02104</link>
      <description><![CDATA[arXiv:2412.02104v1 公告类型：新
摘要：人工智能 (AI) 的快速发展彻底改变了许多领域，大型语言模型 (LLM) 和计算机视觉 (CV) 系统分别推动了自然语言理解和视觉处理的进步。这些技术的融合催化了多模态 AI 的兴起，实现了涵盖文本、视觉、音频和视频模态的更丰富的跨模态理解。特别是多模态大型语言模型 (MLLM) 已经成为一个强大的框架，在图像文本生成、视觉问答和跨模态检索等任务中展示了令人印象深刻的功能。尽管取得了这些进步，但 MLLM 的复杂性和规模给可解释性和可解释性带来了重大挑战，而可解释性和可解释性对于在高风险应用中建立透明度、可信度和可靠性至关重要。本文对 MLLM 的可解释性和可解释性进行了全面调查，提出了一个新颖的框架，将现有研究分为三个角度：（I）数据、（II）模型、（III）训练和推理。我们系统地分析了从 token 级到嵌入级表示的可解释性，评估了与架构分析和设计相关的方法，并探索了增强透明度的训练和推理策略。通过比较各种方法，我们确定了它们的优势和局限性，并提出了未来的研究方向，以解决多模态可解释性中尚未解决的挑战。这项调查为提高 MLLM 的可解释性和透明度提供了基础资源，指导研究人员和从业者开发更负责任和更强大的多模态 AI 系统。]]></description>
      <guid>https://arxiv.org/abs/2412.02104</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WordNet 与人类直觉之间的语义关系知识不一致</title>
      <link>https://arxiv.org/abs/2412.02138</link>
      <description><![CDATA[arXiv:2412.02138v1 公告类型：新
摘要：WordNet 提供了一个由专家创建的精心构建的语义关系库。但是，还有另一个关于语义关系的信息来源，即语言使用者的直觉。我们首次系统地研究了这两个来源的一致程度。调查不一致的情况可以正确使用 WordNet 并促进其改进。我们的分析使用模板来引出人类参与者的反应，揭示了 WordNet 和人类直觉之间语义关系知识的普遍不一致。进一步的分析发现同义词和分类关系（上位词和下位词）之间存在系统性的不匹配模式，同时 WordNet 路径长度不能作为人类关于上位词或下位词关系的直觉的可靠指标。]]></description>
      <guid>https://arxiv.org/abs/2412.02138</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型和反射增量机制进行比较文献摘要</title>
      <link>https://arxiv.org/abs/2412.02149</link>
      <description><![CDATA[arXiv:2412.02149v1 公告类型：新摘要：在本文中，我们介绍了 ChatCite，这是一种利用大型语言模型 (LLM) 生成比较文献摘要的新方法。总结研究论文并重点关注研究之间的关键比较的能力是学术研究中的一项基本任务。现有的摘要模型虽然可以有效地生成简洁的摘要，但无法提供深入的比较见解。ChatCite 通过结合多步骤推理机制来解决这一限制，该机制从论文中提取关键要素，逐步构建比较摘要，并通过反射记忆过程细化输出。我们在自定义数据集 CompLit-LongContext 上评估 ChatCite，该数据集包含 1000 篇带有注释的比较摘要的研究论文。实验结果表明，ChatCite 在各种自动评估指标（例如 ROUGE 和新提出的 G-Score）上的表现优于几种基线方法，包括 GPT-4、BART、T5 和 CoT。人工评估进一步证实，与这些基线模型相比，ChatCite 生成的摘要更加连贯、有见地且流​​畅。我们的方法在自动文献综述生成方面取得了重大进展，为研究人员提供了一种高效比较和综合科学研究的强大工具。]]></description>
      <guid>https://arxiv.org/abs/2412.02149</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BANER：用于少样本命名实体识别的边界感知 LLM</title>
      <link>https://arxiv.org/abs/2412.02228</link>
      <description><![CDATA[arXiv:2412.02228v1 公告类型：新
摘要：尽管两阶段原型网络在少样本命名实体识别 (NER) 方面取得了成功，但跨度检测阶段的过度/不足检测错误跨度和类型分类阶段的未对齐实体原型等挑战仍然存在。此外，LLM 已被证明不是有效的少样本信息提取器。在本文中，我们提出了一种称为边界感知 LLM 的少样本命名实体识别方法来解决这些问题。我们引入了一种边界感知对比学习策略，以增强 LLM 感知广义实体跨度的实体边界的能力。此外，我们利用 LoRAHub 将目标域的信息与源域对齐，从而增强自适应跨域分类能力。在各种基准测试中进行的大量实验表明，我们的框架优于以前的方法，验证了它的有效性。特别是，所提出的策略在一系列 LLM 架构中都表现出了有效性。代码和数据发布于https://github.com/UESTC-GQJ/BANER。]]></description>
      <guid>https://arxiv.org/abs/2412.02228</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>压缩 KV 缓存以进行具有层间注意相似性的长上下文 LLM 推理</title>
      <link>https://arxiv.org/abs/2412.02252</link>
      <description><![CDATA[arXiv:2412.02252v1 公告类型：新
摘要：大型语言模型 (LLM)（例如 GPT 和 LLaMA 系列）中上下文窗口大小的增加提高了它们处理复杂长文本任务的能力，但代价是推理效率，特别是在内存和计算复杂性方面。现有方法（包括选择性标记保留和基于窗口的注意）提高了效率，但存在丢弃未来文本生成所需的重要标记的风险。在本文中，我们提出了一种方法，通过减少不太重要的标记的内存和计算负载而不是丢弃它们来提高 LLM 效率而不会丢失标记。我们解决了两个挑战：1）调查上下文中重要标记的分布，发现最近的标记比上下文中的远距离标记更重要，2）通过跨层共享注意力分数来优化远距离标记的资源。实验表明，我们的方法在不影响性能的情况下节省了 $35\%$ KV 缓存。]]></description>
      <guid>https://arxiv.org/abs/2412.02252</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MediaSpin：通过对新闻标题的细粒度分析探索媒体偏见</title>
      <link>https://arxiv.org/abs/2412.02271</link>
      <description><![CDATA[arXiv:2412.02271v1 公告类型：新
摘要：在本文中，我们介绍了 MediaSpin 数据集，旨在帮助开发能够检测新闻标题中存在的不同形式媒体偏见的模型，该模型是通过人工监督和验证的大型语言模型 (LLM) 媒体偏见标签开发的。该语料库包含 78,910 对新闻标题和注释，并解释了分配的 13 种不同类型的媒体偏见类别。我们证明了我们的数据集在新闻编辑中自动检测偏见的实用性。]]></description>
      <guid>https://arxiv.org/abs/2412.02271</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于方面的情感分析大型语言模型的综合评估</title>
      <link>https://arxiv.org/abs/2412.02279</link>
      <description><![CDATA[arXiv:2412.02279v1 公告类型：新
摘要：最近，大型语言模型（LLM）在自然语言处理领域引起了越来越多的关注，它以强大的推理和生成能力彻底改变了许多下游任务。例如，上下文学习（ICL）引入了一种无需微调的范式，允许开箱即用的LLM通过类比学习执行下游任务而无需任何微调。此外，在存在大量训练数据的微调依赖范式中，参数高效微调（PEFT）作为一种经济有效的方法，使LLM能够实现与完全微调相当的出色性能。
然而，LLM采用的这些迷人技术尚未在ABSA领域得到充分利用。以前的研究仅使用随机选择的输入输出对作为ICL中的演示来探究ABSA中的LLM，导致评估不完整且肤浅。在本文中，我们对 ABSA 领域的 LLM 进行了全面评估，涉及 13 个数据集、8 个 ABSA 子任务和 6 个 LLM。具体来说，我们设计了一个统一的任务公式来统一“多个范式中多个 ABSA 子任务的多个 LLM”。对于依赖微调的范式，我们使用基于指令的多任务学习有效地微调 LLM。对于无微调范式，我们提出了 3 种演示选择策略来刺激 LLM 的少样本能力。我们大量的实验表明，与微调依赖范式中的微调小语言模型 (SLM) 相比，LLM 实现了新的最佳性能。更重要的是，在 SLM 无效的无微调范式中，具有 ICL 的 LLM 仍然展现出令人印象深刻的潜力，甚至可以在某些 ABSA 子任务上与微调的 SLM 相媲美。]]></description>
      <guid>https://arxiv.org/abs/2412.02279</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关注中国少数民族语言模型的鲁棒性！藏文音节级文本对抗攻击</title>
      <link>https://arxiv.org/abs/2412.02323</link>
      <description><![CDATA[arXiv:2412.02323v1 Announce Type: new 
摘要：文本对抗攻击是指攻击者通过精心设计，对原始文本添加不可察觉的扰动，从而使NLP（自然语言处理）模型产生错误判断的一种攻击方法，该方法也用于评估NLP模型的鲁棒性。目前该领域的研究大多集中在英文上，对中文也有一定研究，但据我们所知，针对中国少数民族语言的研究很少。文本对抗攻击是中国少数民族语言信息处理面临的新挑战。针对这种情况，我们提出了一种基于音节余弦距离和评分机制的藏文音节级黑盒文本对抗攻击TSAttacker。然后，我们对由两个PLM（预训练语言模型）微调生成的六个模型进行TSAttacker，用于三个下游任务。实验结果表明，TSAttacker是有效的，能够生成高质量的对抗样本，此外，所涉及模型的鲁棒性仍有很大提升空间。]]></description>
      <guid>https://arxiv.org/abs/2412.02323</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于掩码语言模型的多粒度藏文文本对抗攻击方法</title>
      <link>https://arxiv.org/abs/2412.02343</link>
      <description><![CDATA[arXiv:2412.02343v1 Announce Type: new 
摘要：在社交媒体中，神经网络模型已被应用于仇恨言论检测、情感分析等，但神经网络模型容易受到对抗性攻击。例如，在文本分类任务中，攻击者精心地对原始文本引入几乎不改变原始语义的扰动，以诱使模型做出不同的预测。通过研究文本对抗性攻击方法，可以评估并提高语言模型的鲁棒性。目前，该领域的研究大多集中在英语上，对汉语也有一定研究，但针对中国少数民族语言的研究很少。随着人工智能技术的快速发展和中国少数民族语言模型的出现，文本对抗性攻击成为中国少数民族语言信息处理的新挑战。针对这种情况，我们提出了一种基于掩码语言模型的多粒度藏文文本对抗性攻击方法TSTricker。我们利用掩码语言模型生成候选替代音节或单词，采用评分机制确定替代顺序，然后对若干经过微调的受害者模型实施攻击方法。实验结果表明，TSTricker 使分类模型的准确率降低了 28.70% 以上，并使分类模型改变了 90.60% 以上样本的预测，攻击效果明显高于基线方法。]]></description>
      <guid>https://arxiv.org/abs/2412.02343</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>