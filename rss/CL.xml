<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 25 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于文本分类的自调节无数据知识融合</title>
      <link>https://arxiv.org/abs/2406.15476</link>
      <description><![CDATA[arXiv:2406.15476v1 公告类型：新
摘要：最近，各种模型库中预训练的文本模型越来越多。这些模型可以针对特定任务进行微调或在大型数据集上进行训练，从而大大降低了从头开始训练新模型的成本。但是，由于隐私、安全或知识产权问题，这些数据集可能无法公开访问。在本文中，我们的目标是开发一个轻量级的学生网络，该网络可以从多个教师模型中学习，而无需访问其原始训练数据。因此，我们研究了无数据知识融合 (DFKA)，这是一项知识转移任务，它将来自多个预训练教师模型的见解结合起来，并有效地将它们转移到紧凑的学生网络中。为了实现这一目标，我们提出了 STRATANET，这是一个建模框架，包括：(a) 一个可控数据生成器，可生成针对每位教师量身定制的文本数据；(b) 一个融合模块，可实施自我调节策略，使用来自教师不同层次的置信度估计来有选择地整合他们的知识并培养出多才多艺的学生。我们在三个具有不同标签或领域的基准文本分类数据集上评估了我们的方法。从经验上讲，我们证明使用我们的 STRATANET 学习的学生模型在数据驱动和无数据约束下明显优于几个基线。]]></description>
      <guid>https://arxiv.org/abs/2406.15476</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:18 GMT</pubDate>
    </item>
    <item>
      <title>CrisisSense-LLM：灾害信息学中多标签社交媒体文本分类的指令微调大型语言模型</title>
      <link>https://arxiv.org/abs/2406.15477</link>
      <description><![CDATA[arXiv:2406.15477v1 公告类型：新
摘要：在危机/灾难信息学领域，社交媒体越来越多地被用于提高态势感知，为响应和救援工作提供信息。高效准确的文本分类工具一直是危机信息学研究的重点领域。然而，当前的方法大多依赖于单标签文本分类模型，无法捕捉到嵌入在动态和多方面的灾难相关社交媒体数据中的不同见解。本研究通过针对灾难相关推文的多标签分类的指令微调来增强预训练的大型语言模型 (LLM)，从而引入了一种灾难文本分类的新方法。我们的方法包括从与灾难相关的推文中创建一个全面的指令数据集，然后将其用于微调开源 LLM，从而将其嵌入特定于灾难的知识。这种经过微调的模型可以同时对灾难相关信息的多个方面进行分类，例如事件类型、信息量和人员援助的参与程度，从而显著提高社交媒体数据在灾难中态势感知的效用。结果表明，这种方法增强了社交媒体帖子中关键信息的分类，从而有助于在紧急情况下更有效地部署态势感知。这项研究为更先进、适应性更强、更强大的灾难管理工具铺平了道路，利用 LLM 的功能来改善灾难场景中的实时态势感知和响应策略。]]></description>
      <guid>https://arxiv.org/abs/2406.15477</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:18 GMT</pubDate>
    </item>
    <item>
      <title>用于解决文本蕴涵问题的双曲句子表示</title>
      <link>https://arxiv.org/abs/2406.15472</link>
      <description><![CDATA[arXiv:2406.15472v1 公告类型：新
摘要：双曲空间已被证明适合对具有层次性质的数据进行建模。因此，我们使用庞加莱球来嵌入句子，目的是证明双曲空间如何用于解决文本蕴涵问题。为此，除了用于评估文本蕴涵的标准数据集外，我们还开发了两个额外的数据集。我们根据各种背景的基线进行评估，包括 LSTM、顺序嵌入和欧几里得平均，这是将句子表示到欧几里得空间的自然对应物。对于蕴涵任务的二元分类版本，我们在 SICK 数据集上的表现始终优于基线，在 SNLI 数据集上仅次于顺序嵌入。]]></description>
      <guid>https://arxiv.org/abs/2406.15472</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:17 GMT</pubDate>
    </item>
    <item>
      <title>CP 与 NLP 的交织：不合理约束句子的生成</title>
      <link>https://arxiv.org/abs/2406.15473</link>
      <description><![CDATA[arXiv:2406.15473v1 公告类型：新
摘要：受限文本生成仍然是一项具有挑战性的任务，特别是在处理硬约束时。传统的自然语言处理 (NLP) 方法优先生成有意义且连贯的输出。此外，当前最先进的方法通常缺乏表达能力和约束满足能力，无法有效地处理此类任务。本文提出了约束优先框架来解决这个问题。该框架将受限文本生成问题视为离散组合优化问题。它通过约束编程方法解决，该方法结合了语言属性（例如，n-gram 或语言级别）和其他更经典的约束（例如，字符、音节或单词的数量）。最终，策展阶段允许使用大型语言模型根据困惑度选择最佳生成的句子。通过解决一个新的更繁琐的受限文本生成问题：标志性的 RADNER 句子问题，证明了这种方法的有效性。这个问题旨在生成符合视觉和临床研究中使用定义的一组非常严格的规则的句子。得益于我们基于 CP 的方法，许多新的强约束句子已成功自动生成。这凸显了我们的方法在处理不合理约束的文本生成场景方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.15473</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:17 GMT</pubDate>
    </item>
    <item>
      <title>通过文本的时间表征进行精神障碍分类</title>
      <link>https://arxiv.org/abs/2406.15470</link>
      <description><![CDATA[arXiv:2406.15470v1 公告类型：新
摘要：精神障碍是全球性挑战，合格精神卫生专业人员的短缺加剧了这一挑战。由于顺序文本数据的复杂性和语言模型的上下文长度有限，当前法学硕士从社交媒体帖子中预测精神障碍具有挑战性。当前基于语言模型的方法将单个数据实例拆分为多个块，以补偿有限的上下文大小。然后将预测模型单独应用于每个块，并选择得票最多的输出作为最终预测。这会导致帖子间依赖关系和重要的时变信息的丢失，从而导致性能不佳。我们提出了一个新颖的框架，首先将按时间顺序排列的大量社交媒体帖子压缩成一系列数字。然后，我们使用这种时变表示进行精神障碍分类。我们通过在三种不同的精神状况下超越当前的 SOTA 来展示我们框架的泛化能力：抑郁、自残和厌食症，F1 分数绝对提高了 5%。我们研究了当前数据实例在语言模型的上下文长度范围内的情况，并提出了实证结果，强调了文本数据的时间属性的重要性。此外，我们利用提出的框架进行跨领域研究，探索不同疾病之间的共性以及跨领域数据使用的可能性。]]></description>
      <guid>https://arxiv.org/abs/2406.15470</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:16 GMT</pubDate>
    </item>
    <item>
      <title>使用小模型改进大模型：降低成本、提高性能</title>
      <link>https://arxiv.org/abs/2406.15471</link>
      <description><![CDATA[arXiv:2406.15471v1 公告类型：新
摘要：预训练大型模型（PLM），例如 ChatGPT，在各种任务中都表现出色。然而，PLM 的大量计算要求使大多数产品团队不愿运行或微调它们。在这种情况下，要利用 PLM 的卓越性能，必须依赖昂贵的 API，从而加剧了经济负担。尽管小模型的整体性能较差，但在特定分布中，它们可以实现相当甚至更好的结果。因此，一些输入可以由小模型专门处理。另一方面，某些任务可以分解为多个子任务，其中一些子任务无需强大的功能即可完成。在这种情况下，小模型可以处理简单的子任务，让大模型专注于具有挑战性的子任务，从而提高性能。我们提出了数据分流（DS）作为小模型和大模型协作的通用范例。 DS$^+$ 不仅大幅降低了查询大型模型的成本，而且有效提高了大型模型的性能。例如，ChatGPT 在亚马逊产品情绪分析中实现了 $94.43\%$ 的准确率，而 DS$^+$ 实现了 $95.64\%$ 的准确率，而成本已降至仅 $31.18\%$。此外，实验还证明，与微调相比，所提出的基于协作的范式可以更好地将特定任务知识注入 PLM。]]></description>
      <guid>https://arxiv.org/abs/2406.15471</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:16 GMT</pubDate>
    </item>
    <item>
      <title>RadEx：基于大型语言模型的放射学报告结构化信息提取框架</title>
      <link>https://arxiv.org/abs/2406.15465</link>
      <description><![CDATA[arXiv:2406.15465v1 公告类型：新
摘要：每年全球有超过 30 亿次放射检查和计算机断层扫描，产生的放射学报告大多是非结构化的，包含自由文本。尽管结构化报告具有潜在的好处，但其采用受到既定流程、资源限制和潜在信息丢失等因素的限制。然而，结构化信息对于各种用例都是必要的，包括自动分析、临床试验匹配和健康结果预测。本研究介绍了 RadEx，这是一个端到端框架，由 15 个软件组件和 10 个工件组成，用于开发从放射学报告中自动提取信息的系统。它涵盖了从注释训练数据到提取信息的完整过程，提供了一致的通用信息模型并为模型开发设定了界限。具体而言，RadEx 允许临床医生定义临床领域（例如乳房 X 线照相术）的相关信息并创建报告模板。该框架支持生成模型和仅编码器模型，并且将信息提取与模板填充分离可以实现独立的模型改进。根据 RadEx 框架开发信息提取系统有利于实施和维护，因为组件易于交换，而标准化工件确保组件之间的互操作性。]]></description>
      <guid>https://arxiv.org/abs/2406.15465</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:15 GMT</pubDate>
    </item>
    <item>
      <title>推理还是简单的下一个标记预测？压力测试大型语言模型的基准</title>
      <link>https://arxiv.org/abs/2406.15468</link>
      <description><![CDATA[arXiv:2406.15468v1 公告类型：新
摘要：我们提出了 MMLU-SR，这是一种新颖的数据集，旨在通过用修改后的术语挑战大型语言模型 (LLM) 在问答任务中的表现来衡量大型语言模型 (LLM) 的真实理解能力。我们推断，当关键术语被适当定义的替代术语替换时，真正理解概念的代理仍然可以对其进行评估，并试图将这种理解与单纯的文本替换区分开来。在我们的研究中，我们修改了标准化测试问题，用虚拟词及其定义替换关键术语。关键术语可以出现在问题、答案或问题和答案的上下文中。
尽管最近流行的 LLM 在 MMLU 排行榜上取得了高分，但我们发现在这种替换之后模型性能大幅下降，表明理解能力较差。这个新的基准为测试真正的模型理解提供了一个严格的基准，并对更广泛的科学界提出了挑战。]]></description>
      <guid>https://arxiv.org/abs/2406.15468</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:15 GMT</pubDate>
    </item>
    <item>
      <title>ExU：用于研究多语言虚假信息叙述并了解其传播的人工智能模型</title>
      <link>https://arxiv.org/abs/2406.15443</link>
      <description><![CDATA[arXiv:2406.15443v1 公告类型：新
摘要：解决在线虚假信息需要分析跨语言的叙述，以帮助事实核查人员和记者筛选大量数据。ExU 项目专注于开发基于人工智能的多语言虚假信息分析模型，解决谣言立场分类和索赔检索任务。我们描述了 ExU 项目提案，并总结了有关支持事实核查的工具设计的用户需求调查结果。]]></description>
      <guid>https://arxiv.org/abs/2406.15443</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:14 GMT</pubDate>
    </item>
    <item>
      <title>调查法学硕士 (LLM) 对数学应用题的稳健性</title>
      <link>https://arxiv.org/abs/2406.15444</link>
      <description><![CDATA[arXiv:2406.15444v1 公告类型：新
摘要：大型语言模型 (LLM) 擅长各种任务，包括解决数学应用题 (MWP)，但在解决包含无关信息的现实问题时却举步维艰。为了解决这个问题，我们提出了一个提示框架，通过添加不相关的变量来生成 MWP 的对抗变体。我们引入了一个数据集 ProbleMATHIC，其中包含对抗和非对抗 MWP。我们的实验表明，LLM 容易受到数值噪声的干扰，导致对抗 MWP 的平均相对性能下降约 26%。为了缓解这种情况，我们对来自我们数据集的对抗样本的 LLM（Llama-2、Mistral）进行了微调。对抗训练实例的微调可将对抗 MWP 的性能提高约 8%，表明对噪声的鲁棒性增强，并且能够更好地识别相关数据以进行推理。最后，为了评估我们的提示框架的通用性，我们引入了 GSM-8K-Adv，这是 GSM-8K 基准的对抗变体。面对对抗信息时，LLM 仍然举步维艰，性能下降高达约 6%。]]></description>
      <guid>https://arxiv.org/abs/2406.15444</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:14 GMT</pubDate>
    </item>
    <item>
      <title>探索 LLM 多代理用于 ICD 编码</title>
      <link>https://arxiv.org/abs/2406.15363</link>
      <description><![CDATA[arXiv:2406.15363v1 公告类型：新
摘要：大型语言模型 (LLM) 已展示出令人印象深刻的多样化能力，可使各个领域受益，例如无需特定领域训练即可从临床文本中提取零样本和少量信息。然而，对于 ICD 编码任务，由于 ICD 代码的高维和偏斜分布，它们通常会产生关键细节的幻觉并产生高召回率但低精度的结果。现有的基于 LLM 的方法无法解释参与编码的人类代理（例如患者、医生和编码员）之间复杂而动态的交互，并且它们缺乏可解释性和可靠性。在本文中，我们提出了一种用于 ICD 编码的新型多代理方法，它通过五个代理模拟现实世界的编码过程：患者代理、医生代理、编码员代理、审阅者代理和调整者代理。每个代理都有特定的功能并使用基于 LLM 的模型来执行它。我们在 MIMIC-III 数据集上评估了我们的方法，并表明与零样本思维链 (CoT) 提示和 CoT 自洽相比，我们提出的多智能体编码框架显著提高了常见和罕见代码的性能。消融研究证实了所提出的智能体角色的有效性。在编码准确性、罕见代码准确性和可解释性方面，我们的方法也与需要预训练或微调的最先进的 ICD 编码方法相匹配。]]></description>
      <guid>https://arxiv.org/abs/2406.15363</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:13 GMT</pubDate>
    </item>
    <item>
      <title>量子语言处理：最先进的技术</title>
      <link>https://arxiv.org/abs/2406.15370</link>
      <description><![CDATA[arXiv:2406.15370v1 公告类型：新
摘要：本文回顾了自然语言处理 (NLP) 的量子计算研究工作。他们的目标是提高当前模型的性能，并更好地表示几种语言现象，例如歧义和长距离依赖性。介绍了几种方法，包括符号图解方法和混合神经网络。这些工作表明实验研究已经可行，并为新模型的概念及其评估开辟了研究视角。]]></description>
      <guid>https://arxiv.org/abs/2406.15370</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:13 GMT</pubDate>
    </item>
    <item>
      <title>构建多语言视觉文本数据集，揭示视觉语言模型的视觉多语言能力</title>
      <link>https://arxiv.org/abs/2406.15359</link>
      <description><![CDATA[arXiv:2406.15359v1 公告类型：新
摘要：大型语言模型 (LLM) 引起了人们对视觉语言模型 (VLM) 的兴趣，该模型将图像-文本对作为输入进行处理。已经提出了研究 VLM 视觉理解能力的研究，但此类研究仍处于初步阶段，因为现有数据集无法全面评估 VLM 在多种语言中的细粒度视觉语言能力。为了进一步探索 GPT-4V \cite{openai2023GPT4} 等 VLM 的优势，我们开发了新的数据集，用于对 VLM 进行系统和定性分析。我们的贡献有四个方面：1）我们引入了九个视觉和语言 (VL) 任务（包括对象识别、图像文本匹配等），并通过使用包含 \textit{问题} 的模板并提示 GPT4-V 生成 \textit{答案} 和 \textit{理由}，构建了四种语言的多语言视觉文本数据集：英语、日语、斯瓦希里语和乌尔都语；2）引入了一个名为 \textit{不相关} 的新 VL 任务；3）引入了理由以使人类理解 VLM 推理过程；4）采用人工评估来衡量所提出的数据集对 VL 任务的适用性。我们表明，VLM 可以在我们的数据集上进行微调。我们的工作是首次在斯瓦希里语和乌尔都语中进行此类分析。此外，它在 VL 分析中引入了 \textit{理由}，这在评估中发挥了至关重要的作用。]]></description>
      <guid>https://arxiv.org/abs/2406.15359</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:12 GMT</pubDate>
    </item>
    <item>
      <title>不同的视角、不同的模型：推特上抑郁症检测的跨文化评估</title>
      <link>https://arxiv.org/abs/2406.15362</link>
      <description><![CDATA[arXiv:2406.15362v1 公告类型：新
摘要：社交媒体数据已用于检测患有精神障碍（例如抑郁症）的用户。尽管跨文化代表性具有全球意义，并且可能对模型性能产生影响，但公开可用的数据集通常缺乏与此方面相关的关键元数据。在这项工作中，我们评估了基准数据集的泛化能力，以在跨文化 Twitter 数据上构建 AI 模型。我们收集了来自七个国家的抑郁用户的自定义地理位置 Twitter 数据集作为测试数据集。我们的结果表明，抑郁症检测模型并不能在全球范围内推广。与全球北方相比，这些模型对全球南方用户的表现更差。与 Logistic 回归相比，预训练语言模型实现了最佳泛化，但在抑郁和非西方用户方面仍显示出显着的性能差距。我们量化了我们的发现并提供了一些可行的建议来缓解这个问题。]]></description>
      <guid>https://arxiv.org/abs/2406.15362</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:12 GMT</pubDate>
    </item>
    <item>
      <title>为低资源语言引入音节标记化：以斯瓦希里语为例</title>
      <link>https://arxiv.org/abs/2406.15358</link>
      <description><![CDATA[arXiv:2406.15358v1 公告类型：新
摘要：在多语言 NLP 中，人们进行了许多尝试，以确保预训练语言模型（例如 mBERT 或 GPT2）变得更好并适用于资源匮乏的语言。为了使预训练语言模型 (PLM) 实现多语言性，我们需要创建能够捕捉任何语言语言特征的词嵌入的技术。标记化就是这样一种技术，因为它允许根据字符或子词拆分单词，从而创建最能代表语言结构的词嵌入。创建这样的词嵌入对于将 PLM 应用于模型未经过训练的其他语言至关重要，从而实现多语言 NLP。但是，大多数 PLM 使用通用的标记化方法，例如 BPE、wordpiece 或 unigram，这些方法可能不适合特定语言。我们假设基于输入文本中音节的标记化（我们称之为音节标记化）应该有助于开发音节感知语言模型。音节感知语言模型使得将 PLM 应用于富含音节的语言（例如斯瓦希里语）成为可能。先前的研究引入了子词标记化。我们的工作扩展了此类努力。值得注意的是，我们提出了一个音节标记器，并采用以实验为中心的方法来验证基于斯瓦希里语的所提出的标记器。我们使用 GPT2 进行了文本生成实验，以评估音节标记器的有效性。我们的结果表明，所提出的音节标记器生成的音节嵌入可以有效地表示斯瓦希里语。]]></description>
      <guid>https://arxiv.org/abs/2406.15358</guid>
      <pubDate>Tue, 25 Jun 2024 06:19:11 GMT</pubDate>
    </item>
    </channel>
</rss>