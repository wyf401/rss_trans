<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 23 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>TRREACLE：通过上下文感知法学硕士和提示选择进行节俭推理</title>
      <link>https://arxiv.org/abs/2404.13082</link>
      <description><![CDATA[arXiv:2404.13082v1 公告类型：新
摘要：最近自然语言处理领域的成功导致了多个提供商大型语言模型（LLM）的激增。每个 LLM 课程都有不同的推理准确性、货币成本和延迟，其准确性进一步取决于问题的确切措辞（即具体提示）。与此同时，用户在回答所有问题时通常会受到金钱预算和延迟的限制，并且他们不知道为每个问题选择哪些法学硕士才能满足其准确性和长期预算要求。为了驾驭这个丰富的设计空间，我们提出了 TREACLE（通过上下文感知 LLM 和提示选择进行节俭推理），这是一种强化学习策略，可以联合选择模型和提示方案，同时尊重用户的货币成本和延迟限制。 TRREACLE 使用问题上下文，包括问题文本嵌入（反映查询的类型或难度）和响应历史记录（反映先前响应的一致性）来做出明智的决策。我们对具有各种 LLM 和提示的标准推理数据集（GSM8K、CSQA 和 LLC）进行的评估表明，与基线相比，TREACLE 可以节省高达 85% 的成本，同时保持高精度。重要的是，它使用户能够优雅地权衡准确性和成本。]]></description>
      <guid>https://arxiv.org/abs/2404.13082</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:03 GMT</pubDate>
    </item>
    <item>
      <title>用于情感分析的关系图卷积网络</title>
      <link>https://arxiv.org/abs/2404.13079</link>
      <description><![CDATA[arXiv:2404.13079v1 公告类型：新
摘要：随着在线平台上文本数据的增长，情感分析对于从用户生成的内容中提取见解变得至关重要。虽然传统方法和深度学习模型已显示出希望，但它们通常无法捕获实体之间的复杂关系。在本文中，我们建议利用关系图卷积网络（RGCN）进行情感分析，它通过捕获图中节点表示的数据点之间的依赖关系来提供可解释性和灵活性。我们通过使用预先训练的语言模型（例如 BERT 和 RoBERTa 以及 RGCN 架构）对来自 Amazon 和 Digikala 数据集的产品评论进行评估，证明了我们方法的有效性。我们的实验强调了 RGCN 在捕获情感分析任务的关系信息方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.13079</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:02 GMT</pubDate>
    </item>
    <item>
      <title>SuRe：使用候选答案对法学硕士的开放域质量检查进行检索总结</title>
      <link>https://arxiv.org/abs/2404.13081</link>
      <description><![CDATA[arXiv:2404.13081v1 公告类型：新
摘要：大型语言模型（LLM）在各种自然语言处理任务中取得了显着的进步，包括问答（QA）任务。虽然将新信息与相关段落的检索相结合是提高法学硕士质量保证的一种有前途的方法，但现有方法通常需要额外的微调，这对于最近的法学硕士来说是不可行的。通过提示增强检索到的段落有可能解决这一限制，但这一方向的探索有限。为此，我们设计了一个简单而有效的框架，以基于汇总检索（SuRe）的法学硕士增强开放域质量保证（ODQA）。 SuRe 帮助法学硕士预测给定问题的更准确答案，这些答案得到了总结性检索的充分支持，可以将其视为从检索到的段落中提取的明确基本原理。具体来说，SuRe 首先为每个多个候选答案构建检索到的段落的摘要。然后，SuRe 通过评估生成的摘要的有效性和排名来确认候选集中最合理的答案。各种 ODQA 基准的实验结果证明了 SuRe 的优越性，与标准提示方法相比，精确匹配 (EM) 提高了 4.6%，F1 分数提高了 4.0%。 SuRe 还可以与广泛的检索方法和法学硕士集成。最后，SuRe 生成的摘要显示出额外的优势，可以衡量检索到的段落的重要性，并作为模型和人类更喜欢的理由。]]></description>
      <guid>https://arxiv.org/abs/2404.13081</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:02 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士评估者认可并偏爱他们自己的一代人</title>
      <link>https://arxiv.org/abs/2404.13076</link>
      <description><![CDATA[arXiv:2404.13076v1 公告类型：新
摘要：事实证明，使用大语言模型（LLM）进行自我评估不仅在基准测试方面很有价值，而且在奖励建模、宪法人工智能和自我完善等方法方面也很有价值。但由于同一个法学硕士同时充当评估者和被评估者，因此引入了新的偏见。其中一种偏见是自我偏好，法学硕士评估者对自己的输出评分高于其他人的输出，而人类注释者则认为它们具有相同的质量。但是，当法学硕士给这些文本更高的分数时，他们是否真的认识到自己的输出，或者这只是巧合？在本文中，我们研究了自我认知能力是否有助于自我偏好。我们发现，像 GPT-4 和 Llama 2 这样的 LLM 开箱即用，在区分自己与其他 LLM 和人类方面具有非凡的准确性。通过微调法学硕士，我们发现自我识别能力与自我偏好偏差强度之间存在线性相关性；通过对照实验，我们表明因果解释可以抵抗简单的混杂因素。我们更广泛地讨论自我识别如何干扰公正的评估和人工智能安全。]]></description>
      <guid>https://arxiv.org/abs/2404.13076</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:01 GMT</pubDate>
    </item>
    <item>
      <title>通过语义搜索和微调提高基于大型语言模型的营销分析副驾驶的能力</title>
      <link>https://arxiv.org/abs/2404.13077</link>
      <description><![CDATA[arXiv:2404.13077v1 公告类型：新
摘要：人工智能（AI）被广泛部署来解决与营销归因和预算优化相关的问题。然而，人工智能模型可能非常复杂，如果没有广泛的实施团队，就很难理解模型的工作原理和见解。原则上，可以部署最近开发的大型语言模型 (LLM)（例如 GPT-4）来提供营销见解，从而减少做出关键决策所需的时间和精力。在实践中，要可靠地使用此类模型需要克服巨大的挑战。我们专注于特定领域的问答、数据检索所需的 SQL 生成以及表格分析，并展示如何应用语义搜索、提示工程和微调的组合来显着提高法学硕士执行这些任务的能力准确。我们比较了专有模型（如 GPT-4）和开源模型（如 Llama-2-70b）以及各种嵌入方法。这些模型在特定于营销组合建模和归因的示例用例上进行了测试。]]></description>
      <guid>https://arxiv.org/abs/2404.13077</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:01 GMT</pubDate>
    </item>
    <item>
      <title>利用基于 BERT 的模型增强跨学科研究：通过 SciBERT-CNN 和主题建模的方法</title>
      <link>https://arxiv.org/abs/2404.13078</link>
      <description><![CDATA[arXiv:2404.13078v1 公告类型：新
摘要：研究人员必须通过定期审查学术文献来了解其领域的最新动态，由于每天发表数千篇论文，这项任务变得更加复杂。传统的多标签文本分类方法常常忽略语义关系，无法解决固有的类别不平衡问题。本文介绍了一种使用 SciBERT 模型和 CNN 对 Elsevier OA CC-BY 语料库中的学术摘要进行系统分类的新颖方法。我们使用多段输入策略，通过 SciBERT 处理通过 BERT 主题建模获得的摘要、正文、标题和关键词。在这里，[CLS] 标记嵌入捕获每个片段的上下文表示，并通过 CNN 连接和处理。 CNN 使用卷积和池化来增强特征提取并降低维度，从而优化分类数据。此外，我们结合基于标签频率的类别权重来解决类别不平衡问题，显着提高分类 F1 分数并增强文本分类系统和文献综述效率。]]></description>
      <guid>https://arxiv.org/abs/2404.13078</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:01 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型建模情感和道德</title>
      <link>https://arxiv.org/abs/2404.13071</link>
      <description><![CDATA[arXiv:2404.13071v1 公告类型：新
摘要：本文探讨了将类人情感和伦理考虑整合到大型语言模型（LLM）中。我们首先对八种基本的人类情感进行建模，以对立的形式呈现，并利用合作法学硕士来重新解释和表达不同强度的这些情感。我们的重点延伸到在法学硕士中嵌入潜在的道德维度，以带有人类反馈的新型自我监督学习算法（SSHF）为指导。这种方法使法学硕士能够对道德准则进行自我评估和调整，从而增强他们生成不仅在情感上引起共鸣而且在道德上一致的内容的能力。本文介绍的方法和案例研究说明了法学硕士超越单纯的文本和图像生成的潜力，涉足同理心互动和原则性决策领域，从而在情感意识和道德意识人工智能系统的发展中树立了新的先例。]]></description>
      <guid>https://arxiv.org/abs/2404.13071</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中可组合概括的语义解析：一项调查</title>
      <link>https://arxiv.org/abs/2404.13074</link>
      <description><![CDATA[arXiv:2404.13074v1 公告类型：新
摘要：组合泛化是模型从仅看到的基元中泛化到复杂的、以前未见过的实体组合类型的能力。这种类型的泛化与面向任务的对话、文本到 SQL 解析和信息检索等应用程序的语义解析社区特别相关，因为它们可能具有无限的复杂性。尽管大型语言模型（LLM）在广泛的 NLP 任务中取得了成功，但解锁完美的组合泛化仍然是最后几个未解决的前沿领域之一。在过去的几年里，人们对探索语义解析任务的法学硕士的组合泛化能力的局限性、改进方法和评估指标的研究兴趣激增。在这项工作中，我们提出了一项文献调查，旨在综合分析、方法和评估方案的最新进展，为该领域的从业者和研究人员提供一个起点。]]></description>
      <guid>https://arxiv.org/abs/2404.13074</guid>
      <pubDate>Tue, 23 Apr 2024 06:19:00 GMT</pubDate>
    </item>
    <item>
      <title>实现高效的简历理解：多粒度、多模式预训练方法</title>
      <link>https://arxiv.org/abs/2404.13067</link>
      <description><![CDATA[arXiv:2404.13067v1 公告类型：新
摘要： 在当今在线招聘广泛普及的时代，简历理解已被广泛认为是一项基本而关键的任务，其目的是自动从简历文档中提取结构化信息。与传统的基于规则的方法相比，利用最近提出的预训练文档理解模型可以大大提高简历理解的有效性。然而，目前的方法忽略了简历中呈现的结构化信息内的层次关系，并且难以以有效的方式解析简历。为此，在本文中，我们提出了一种新颖的模型，即 ERU，以实现高效的简历理解。具体来说，我们首先引入一个布局感知的多模式融合变压器，用于使用集成的文本、视觉和布局信息对简历中的片段进行编码。然后，我们设计了三个自监督任务，通过大量未标记的简历来预训练该模块。接下来，我们使用多粒度序列标记任务对模型进行微调，以从简历中提取结构化信息。最后，对真实世界数据集的大量实验清楚地证明了 ERU 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.13067</guid>
      <pubDate>Tue, 23 Apr 2024 06:18:59 GMT</pubDate>
    </item>
    <item>
      <title>伏尼契手稿中抄写意图的微妙迹象</title>
      <link>https://arxiv.org/abs/2404.13069</link>
      <description><![CDATA[arXiv:2404.13069v1 公告类型：新
摘要：本研究通过寻找隐藏在“伏尼契”文字被忽视的特征中的微妙抄写意图迹象，探索神秘的伏尼契手稿。研究结果表明，段落内标记的分布根据位置的不同而显着不同，这些位置不仅由脚本固有的元素（例如段落和行边界）定义，而且还由外在元素（即植物的手绘插图）定义。]]></description>
      <guid>https://arxiv.org/abs/2404.13069</guid>
      <pubDate>Tue, 23 Apr 2024 06:18:59 GMT</pubDate>
    </item>
    <item>
      <title>来自反事实任务的证据支持大型语言模型中的紧急类比推理</title>
      <link>https://arxiv.org/abs/2404.13070</link>
      <description><![CDATA[arXiv:2404.13070v1 公告类型：新
摘要：我们最近报告的证据表明，大型语言模型能够以零样本的方式解决各种基于文本的类比问题，这表明类比推理能力的出现。最近的两篇评论对这些结果提出了质疑，引用了所谓“反事实”任务的证据，在这些任务中，字母表的标准序列被任意排列，以减少与语言模型训练数据中可能存在的材料的相似性。在这里，我们回应这些批评，澄清对我们原始工作中使用的测试材料的一些误解，并提供证据表明语言模型也能够泛化到这些新的反事实任务变体。]]></description>
      <guid>https://arxiv.org/abs/2404.13070</guid>
      <pubDate>Tue, 23 Apr 2024 06:18:59 GMT</pubDate>
    </item>
    <item>
      <title>Intellecta Cognitiva：用于推进学术知识和机器推理的综合数据集</title>
      <link>https://arxiv.org/abs/2404.13065</link>
      <description><![CDATA[arXiv:2404.13065v1 公告类型：新
摘要：Intellecta 数据集作为一种创新的综合数据集出现，旨在增强当代语言模型的认知处理能力。 Intellecta 由 115.3 亿个代币组成，整合了 80.1 亿个合成数据代币和 35.2 亿个丰富教科书数据代币，旨在促进高级推理和全面的教育叙事生成。利用 Mixtral-8x7B-Instruct-v0.1 模型，该数据集有助于生成复杂的思维过程和详细的教科书式解释，从而使语言模型能够参与批判性思维和深刻的教育话语。这个混合数据集证明了合成数据在突破人工智能边界方面的潜力，提供的存储库不仅庞大且多样化，而且经过完善以符合道德标准和智力严谨性。]]></description>
      <guid>https://arxiv.org/abs/2404.13065</guid>
      <pubDate>Tue, 23 Apr 2024 06:18:58 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型作为模拟患者进行临床教育</title>
      <link>https://arxiv.org/abs/2404.13066</link>
      <description><![CDATA[arXiv:2404.13066v1 公告类型：新
摘要：模拟患者（SP）为学生实践提供真实场景，在临床医学教育中发挥着至关重要的作用。然而，培训和雇用合格 SP 的成本高昂，加上他们在持续描绘真实患者时面临的繁重工作量和潜在风险，限制了学生接受此类临床培训。因此，基于计算机程序的模拟患者的集成近年来已成为一种有价值的教育工具。随着大型语言模型（LLM）的快速发展，其在对话式人工智能和角色扮演方面的卓越能力已得到证明，使其成为实施虚拟模拟患者（VSP）的可行选择。在本文中，我们提出了一个名为 CureFun 的集成模型不可知框架，它利用了法学硕士在临床医学教育中的潜力。该框架促进学生和模拟患者之间的自然对话，评估他们的对话，并提供提高学生临床探究技能的建议。通过综合评估，与其他基于LLM的聊天机器人相比，我们的方法展示了更真实、更专业的SP场景对话流程，从而证明了其模拟患者的熟练程度。此外，利用CureFun的评估能力，我们对几位医学法学硕士进行了评估，并从其诊断能力的角度讨论了使用法学硕士作为虚拟医生的可能性和局限性。]]></description>
      <guid>https://arxiv.org/abs/2404.13066</guid>
      <pubDate>Tue, 23 Apr 2024 06:18:58 GMT</pubDate>
    </item>
    <item>
      <title>FlowMind：使用法学硕士自动生成工作流程</title>
      <link>https://arxiv.org/abs/2404.13050</link>
      <description><![CDATA[arXiv:2404.13050v1 公告类型：新
摘要：快速发展的机器人流程自动化（RPA）领域在自动化重复流程方面取得了重大进展，但在需要用户要求的自发或不可预测任务的场景中，其有效性会降低。本文介绍了一种新颖的方法 FlowMind，利用大型语言模型 (LLM)（例如生成预训练变换器 (GPT)）的功能来解决此限制并创建自动工作流生成系统。在 FlowMind 中，我们提出了一个通用的讲座提示方案，有助于通过可靠的应用程序编程接口 (API) 奠定 LLM 推理的基础。这样，FlowMind 不仅可以缓解法学硕士中常见的幻觉问题，还可以消除法学硕士与专有数据或代码之间的直接交互，从而确保信息的完整性和机密性 - 这是金融服务的基石。 FlowMind 通过呈现自动生成的工作流程的高级描述来进一步简化用户交互，使用户能够有效地检查和提供反馈。我们还引入了 NCEN-QA，这是一个新的金融数据集，用于对 N-CEN 基金报告中的问答任务进行基准测试。我们使用 NCEN-QA 对照 FlowMind 的基线和消融变体来评估 FlowMind 生成的工作流程的性能。我们展示了 FlowMind 的成功、拟议讲座方案中每个组件的重要性以及 FlowMind 中用户交互和反馈的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.13050</guid>
      <pubDate>Tue, 23 Apr 2024 06:18:57 GMT</pubDate>
    </item>
    <item>
      <title>“嘿..！这种药让我恶心”：使用机器学习技术对用户生成的药物评论进行情感分析</title>
      <link>https://arxiv.org/abs/2404.13057</link>
      <description><![CDATA[arXiv:2404.13057v1 公告类型：新
摘要：情感分析在医疗保健领域变得越来越重要，特别是在生物医学和制药领域。公众产生的关于有效性、副作用和药物不良反应的数据是不同机构和药品生产商了解人们的担忧和反应的金矿。尽管获取毒品相关问题的数据集存在挑战，但对该主题的情绪分析将对该领域带来重大好处。该项目提出了一个药物评论分类系统，将用户对特定药物的评论分为不同的类别，例如正面、负面和中立。此方法使用从包含药物评论的公开来源（例如 drug.com）收集的数据集。对采集到的数据进行人工标注并人工验证，确保标注正确。使用 BERT、SciBERT 和 BioBERT 等三种预训练语言模型来获得嵌入，随后将其用作不同机器学习分类器（例如决策树、支持向量机、随机森林和深度学习算法）的特征例如循环神经网络。这些分类器的性能通过精度、召回率和 f1 分数进行量化，结果表明所提出的方法可用于分析人们对不同药物的情绪。]]></description>
      <guid>https://arxiv.org/abs/2404.13057</guid>
      <pubDate>Tue, 23 Apr 2024 06:18:57 GMT</pubDate>
    </item>
    </channel>
</rss>