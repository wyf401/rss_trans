<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Wed, 17 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>高效知识路径推理：知识图谱指导领域问答大语言模型</title>
      <link>https://arxiv.org/abs/2404.10384</link>
      <description><![CDATA[arXiv:2404.10384v1 公告类型：新
摘要：大型语言模型（LLM），例如 GPT3.5、GPT4 和 LLAMA2，在许多任务上表现出奇的好，并且优于人类专家。然而，在许多特定领域的评估中，这些法学硕士常常因相关语料库的训练不足而出现幻觉问题。此外，对大型模型进行微调可能会面临LLM不开源或高质量领域指令构建困难等问题。因此，知识图谱等结构化知识数据库可以更好地为法学硕士提供领域背景知识，充分利用法学硕士的推理和分析能力。在之前的一些工作中，通过问题检索子图时，会多次调用LLM来确定当前三元组是否适合包含在子图中。特别是对于需要多跳推理路径的问题，频繁调用LLM会消耗大量的算力。而且，在选择推理路径时，LLM每一步都会被调用一次，如果其中一个步骤选择错误，就会导致后续步骤的错误累积。本文基于LLM集成并优化了一个从KG中选择推理路径的管道，可以减少对LLM的依赖。此外，我们提出了一种基于思想链（CoT）和页面排名的简单有效的子图检索方法，它可以返回最有可能包含答案的路径。我们在三个数据集上进行实验：GenMedGPT-5k [14]、WebQuestions [2] 和 CMCQA [21]。最后，RoK 可以证明，使用更少的 LLM 调用就可以实现与之前的 SOTA 模型相同的结果。]]></description>
      <guid>https://arxiv.org/abs/2404.10384</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:14 GMT</pubDate>
    </item>
    <item>
      <title>通过学习过去的经验增强大型语言模型的置信度表达</title>
      <link>https://arxiv.org/abs/2404.10315</link>
      <description><![CDATA[arXiv:2404.10315v1 公告类型：新
摘要：大型语言模型（LLM）在各种下游任务中表现出了卓越的性能，但它们可能会以自信的语气生成不准确或虚假的信息。可能的解决方案之一是增强LLM置信度表达能力，其中表达的置信度可以与生成答案正确的真实概率很好地保持一致。然而，利用法学硕士的内在能力或答案输出对数的信号在准确捕获法学硕士的响应不确定性方面具有挑战性。因此，从认知诊断学中汲取灵感，我们提出了一种从过去的经验中学习（LePe）的方法来增强信心表达的能力。具体来说，我们首先明确三个关键问题：（1）如何抓住LLM的内在信心？ （2）如何教LLM表达自信？ （3）如何评价LLM的置信度表达？然后我们在 LePe 中设计了三个阶段来处理这些问题。此外，为了在构建训练数据时准确捕捉法学硕士的置信度，我们设计了一个完整的流程，包括问题准备和答案抽样。我们还使用 Llama 系列法学硕士进行实验，以验证我们提出的方法在四个数据集上的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.10315</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:13 GMT</pubDate>
    </item>
    <item>
      <title>自我探索避坑：细粒度奖励提升语言模型推理能力</title>
      <link>https://arxiv.org/abs/2404.10346</link>
      <description><![CDATA[arXiv:2404.10346v1 公告类型：新
摘要：大量推理训练（即 CoT Fine-tuning）对于提高大型语言模型（LLM）的推理能力是有效的。然而，获取人类撰写的基本原理或从专有模型中增强基本原理成本高昂且不可扩展。在本文中，我们研究了法学硕士能否自我提高推理能力的问题。为此，我们提出自我探索，LLM的任务是探索原理中的第一个错误步骤（即第一个坑），并将这些信号作为细粒度的奖励来进一步改进。在 GSM8K 和 MATH 测试集上，与监督微调 (SFT) 相比，Self-Explore 在三个 LLM 中平均提高了 11.57% 和 2.89%。我们的代码可在 https://github.com/hbin0701/Self-Explore 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.10346</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:13 GMT</pubDate>
    </item>
    <item>
      <title>通过神经符号目标总结和文本单元文本生成对低资源健康指导对话进行建模</title>
      <link>https://arxiv.org/abs/2404.10268</link>
      <description><![CDATA[arXiv:2404.10268v1 公告类型：新
摘要：健康指导帮助患者实现个性化和生活方式相关的目标，有效管理慢性病并缓解心理健康问题。由于其高度个性化和劳动密集型的性质，它对于社会经济地位较低的人群特别有利，但成本高昂。在本文中，我们提出了一种神经符号目标总结器来支持健康教练跟踪目标，以及一种文本单元文本对话生成模型，该模型可以与患者交谈并帮助他们创建和实现身体活动的具体目标。我们的模型优于以前最先进的模型，同时消除了对预定义模式和相应注释的需要。我们还提出了一个新的健康指导数据集，扩展了之前的工作，并提出了一个指标来根据数据难度来衡量患者反应的非常规性，从而在部署期间促进潜在的教练警报。]]></description>
      <guid>https://arxiv.org/abs/2404.10268</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:12 GMT</pubDate>
    </item>
    <item>
      <title>时态文档历史的未来语言建模</title>
      <link>https://arxiv.org/abs/2404.10297</link>
      <description><![CDATA[arXiv:2404.10297v1 公告类型：新
摘要：预测未来在人类活动的许多方面都引起了极大的兴趣。企业对未来趋势感兴趣，交易者对未来股价感兴趣，公司对未来技术突破高度感兴趣。虽然有许多自动化系统可以预测未来的数字数据，例如天气、股票价格和产品需求，但自动预测文本数据的工作相对较少。人类对文本数据预测感兴趣，因为它是我们消费的自然格式，并且专家通常以文本格式进行预测（Christensen 等人，2004 年；Tetlock 和 Gardner，2015 年；Frick，2015 年）。然而，在机器学习或自然语言处理社区中，这一普遍问题的形式化相对较少。为了解决这一差距，我们引入了未来语言建模的任务：基于文本的时间历史对未来文本进行概率建模。据我们所知，我们的工作是第一个以这种方式形式化预测未来任务的工作。我们表明，确实有可能构建未来的语言模型，以改进强大的非时间语言模型基线，从而为解决这一重要且广泛适用的问题打开了大门。]]></description>
      <guid>https://arxiv.org/abs/2404.10297</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:12 GMT</pubDate>
    </item>
    <item>
      <title>平衡专业性和多功能性：用于监督微调大型语言模型的从粗到细的框架</title>
      <link>https://arxiv.org/abs/2404.10306</link>
      <description><![CDATA[arXiv:2404.10306v1 公告类型：新
摘要：对齐的大型语言模型（LLM）展示了卓越的多功能性，能够处理各种现实世界的任务。同时，一致的法学硕士也有望表现出专业性，在特定应用中表现出色。然而，使用额外数据进行微调是获得专业性的常见做法，通常会导致先前获得的多功能性发生灾难性遗忘（CF），从而阻碍模型在不同任务中的性能。为了应对这一挑战，我们提出了 CoFiTune，一个从粗到细的框架，试图在专业性和多功能性之间取得平衡。在粗粒度层面，利用经验树搜索算法来查明和更新对专业至关重要的特定模块，同时保持其他参数冻结；在细粒度层面，软屏蔽机制规范了 LLM 的更新，在不损害专业性的情况下缓解 CF 问题。在对专业性和多功能性的总体评估中，CoFiTune 在不同的任务和模型规模上始终优于基线方法。与全参数 SFT 相比，CoFiTune 在 13B 模型上带来了约 14% 的多功能性改进和边际专业损失。最后，基于进一步的分析，我们对法学硕士中的信息转发过程提供了推测性的见解，这有助于解释所提出方法的有效性。该代码可在 https://github.com/rattlesnakey/CoFiTune 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.10306</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:12 GMT</pubDate>
    </item>
    <item>
      <title>CULTURE-GEN：通过自然语言提示揭示语言模型中的全球文化感知</title>
      <link>https://arxiv.org/abs/2404.10199</link>
      <description><![CDATA[arXiv:2404.10199v1 公告类型：新
摘要：随着大语言模型（LLM）的使用在全球范围内激增，对他们来说，拥有足够的知识和对不同的全球文化的公平代表性至关重要。在这项工作中，我们通过文化条件代，揭示了 110 个国家和地区的 3 个 SOTA 模型对 8 个文化相关主题的文化认知，并通过法学硕士从这些代中提取与每种文化相关的符号。我们发现，受文化制约的一代由语言“标记”组成，这些标记将边缘化文化与默认文化区分开来。我们还发现，法学硕士在文化符号方面的多样性程度参差不齐，并且来自不同地理区域的文化在法学硕士的文化不可知一代中有着不同的存在。我们的研究结果促进了法学硕士全球文化认知知识和公平性的进一步研究。代码和数据可以在：https://github.com/huihanlhh/Culture-Gen/]]></description>
      <guid>https://arxiv.org/abs/2404.10199</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:11 GMT</pubDate>
    </item>
    <item>
      <title>具有大型语言模型的生成文本隐写术</title>
      <link>https://arxiv.org/abs/2404.10229</link>
      <description><![CDATA[arXiv:2404.10229v1 公告类型：新
摘要：大型语言模型（LLM）的最新进展模糊了人类和机器之间高质量文本生成的界限，这有利于生成文本隐写术。然而，当前先进的隐写映射并不适合法学硕士，因为大多数用户仅限于访问法学硕士的黑盒 API 或用户界面，从而无法访问训练词汇及其采样概率。在本文中，我们探索了一种基于大型语言模型用户界面的黑盒生成文本隐写方法，称为LLM-Stega。 LLM-Stega 的主要目标是通过使用 LLM 的用户界面来进行 Alice（发送者）和 Bob（接收者）之间的安全隐蔽通信。具体来说，我们首先构建一个关键字集并设计一个新的加密隐写映射来嵌入秘密消息。此外，为了保证秘密消息的准确提取和生成的隐写文本的丰富语义，提出了一种基于拒绝采样的优化机制。综合实验表明，所提出的 LLM-Stega 优于当前最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2404.10229</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:11 GMT</pubDate>
    </item>
    <item>
      <title>通过采用法学硕士循环策略来发现社交媒体消息传递中的潜在争论</title>
      <link>https://arxiv.org/abs/2404.10259</link>
      <description><![CDATA[arXiv:2404.10259v1 公告类型：新
摘要：社交媒体的广泛使用导致舆论分析自动化方法的流行。监督方法擅长文本分类，但由于焦点的不断转移，社交媒体讨论的动态性质对这些技术提出了持续的挑战。另一方面，从公共话语中提取主题的传统无监督方法（例如主题建模）通常会揭示可能无法捕捉特定细微差别的总体模式。因此，社交媒体话语研究的很大一部分仍然依赖于劳动密集型的手动编码技术和人机交互方法，这既耗时又昂贵。在这项工作中，我们研究发现与特定主题相关的论点的问题。我们提出了一种通用的 LLM 在环策略，该策略利用大型语言模型 (LLM) 的高级功能从社交媒体消息中提取潜在的论点。为了展示我们的方法，我们将我们的框架应用于有争议的主题。我们使用两个公开可用的数据集：(1) 包含 25 个主题的 14k 个 Facebook 广告的气候活动数据集；(2) 包含 14 个主题的 9k 个 Facebook 广告的 COVID-19 疫苗活动数据集。此外，我们还根据现实世界事件分析人口目标定位和消息传递的适应性。]]></description>
      <guid>https://arxiv.org/abs/2404.10259</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:11 GMT</pubDate>
    </item>
    <item>
      <title>Deferred NAM：通过 DeferredContext 编码实现非流 ASR 的低延迟 Top-K 上下文注入</title>
      <link>https://arxiv.org/abs/2404.10180</link>
      <description><![CDATA[arXiv:2404.10180v1 公告类型：新
摘要：上下文偏差使语音识别器能够转录说话者上下文中的重要短语，例如联系人姓名，即使它们在训练数据中很少或不存在。基于注意力的偏置是一种领先的方法，它允许识别器和偏置系统进行完整的端到端协同训练，并且不需要单独的推理时间组件。此类偏置器通常由上下文编码器组成；其次是上下文过滤器，它缩小了要应用的上下文范围，从而缩短了每步的推理时间；最后，通过交叉注意力进行上下文应用。尽管在优化每帧性能方面已经投入了大量工作，但上下文编码器至少同样重要：在上下文编码结束之前无法开始识别。在这里，我们展示了轻量级短语选择过程可以在上下文编码之前移动，从而实现高达 16.1 倍的加速，并使偏差能够扩展到 20K 短语，最大预解码延迟低于 33ms。通过添加短语级和单词级交叉熵损失，我们的技术在没有损失和轻量级短语选择过程的情况下，相对于基线还实现了高达 37.5% 的相对 WER 降低。]]></description>
      <guid>https://arxiv.org/abs/2404.10180</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:10 GMT</pubDate>
    </item>
    <item>
      <title>RAG 模型的忠实度如何？量化 RAG 和 LLM 内部先验之间的拉锯战</title>
      <link>https://arxiv.org/abs/2404.10198</link>
      <description><![CDATA[arXiv:2404.10198v1 公告类型：新
摘要：检索增强生成（RAG）通常用于修复幻觉并为大型语言模型（LLM）提供最新知识。然而，如果法学硕士单独错误地回答了一个问题，提供正确的检索内容是否总能修复错误？相反，如果检索到的内容不正确，LLM 是否知道忽略错误信息，或者是否重述错误？为了回答这些问题，我们系统地分析了法学硕士的内部知识（即其先验知识）与在他们不同意时检索到的信息之间的拉锯战。我们在有或没有参考文档的数据集上测试 GPT-4 和其他法学硕士的问答能力。正如预期的那样，提供正确的检索信息可以修复大多数模型错误（准确率 94%）。然而，当参考文件受到越来越多的错误值的干扰时，当其内部先验较弱时，法学硕士更有可能背诵不正确的、经过修改的信息，但当其先验较强时，法学硕士会更有抵抗力。类似地，我们还发现，修改后的信息与模型先验的偏差越大，模型就越不可能选择它。这些结果凸显了模型的先验知识与参考文档中提供的信息之间潜在的紧张关系。]]></description>
      <guid>https://arxiv.org/abs/2404.10198</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:10 GMT</pubDate>
    </item>
    <item>
      <title>语言模型级联：代币级别的不确定性及其他</title>
      <link>https://arxiv.org/abs/2404.10136</link>
      <description><![CDATA[arXiv:2404.10136v1 公告类型：新
摘要：语言模型 (LM) 的最新进展显着提高了复杂 NLP 任务的质量，但代价是推理成本增加。级联提供了一种简单的策略来实现更有利的成本质量权衡：在这里，为大多数“简单”实例调用一个小模型，而一些“困难”实例则推迟到大型模型。虽然对于分类任务来说，支持级联的原理已经得到了充分的研究——基于预测的类不确定性的延迟在理论上和实践上都受到青睐——但对于生成式 LM 任务却缺乏类似的理解。在这项工作中，我们启动了对 LM 级联延迟规则的系统研究。我们首先检查预测类别不确定性到生成 LM 任务的自然延伸，即预测序列不确定性。我们表明，该度量存在长度偏差问题，根据长度过度强调或低估输出。这是因为 LM 产生一系列不确定性值，每个输出令牌都有一个不确定性值；此外，输出标记的数量在不同示例中是可变的。为了缓解这个问题，我们建议利用生成 LM 中隐含的更丰富的代币级不确定性信息。我们认为，朴素预测的序列不确定性对应于这些不确定性的简单聚合。相比之下，通过使用 FLAN-T5 模型对一系列自然语言基准进行实验，我们表明，通过学习的事后延迟规则合并令牌级别的不确定性可以显着优于这种简单的聚合策略。我们进一步表明，合并较小模型的嵌入和较大模型的中间层可以进一步提高整体成本质量权衡。]]></description>
      <guid>https://arxiv.org/abs/2404.10136</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:09 GMT</pubDate>
    </item>
    <item>
      <title>TabSQLify：通过表分解增强法学硕士的推理能力</title>
      <link>https://arxiv.org/abs/2404.10150</link>
      <description><![CDATA[arXiv:2404.10150v1 公告类型：新
摘要：表格推理是一项具有挑战性的任务，需要理解自然语言问题和结构化表格数据。大型语言模型 (LLM) 在自然语言理解和生成方面表现出了令人印象深刻的能力，但由于输入长度有限，它们经常难以处理大型表。在本文中，我们提出了 TabSQLify，这是一种新颖的方法，它利用文本到 SQL 生成将表分解为更小的相关子表，在执行推理任务之前仅包含用于回答问题或验证语句的基本信息。在我们对四个具有挑战性的数据集的综合评估中，与依赖完整表格作为输入的主流方法相比，我们的方法表现出可比或优越的性能。此外，我们的方法可以显着减少输入上下文长度，使其对于大规模表推理应用程序更具可扩展性和效率。我们的方法在 WikiTQ 基准测试中表现非常出色，准确率达到 64.7%。此外，在 TabFact 基准测试中，它实现了 79.5% 的高精度。这些结果超过了 gpt-3.5-turbo (chatgpt) 上其他基于 LLM 的基线模型。 TabSQLify 可以减小表大小，从而显着减轻 LLM 在处理大型表时的计算负载，而不会影响性能。]]></description>
      <guid>https://arxiv.org/abs/2404.10150</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:09 GMT</pubDate>
    </item>
    <item>
      <title>关于基于文本的强化学习的微调语言模型的效果</title>
      <link>https://arxiv.org/abs/2404.10174</link>
      <description><![CDATA[arXiv:2404.10174v1 公告类型：新
摘要：基于文本的强化学习涉及代理使用观察到的文本和自然语言中可接受的动作与虚构环境进行交互以完成任务。之前的研究表明，即使完全没有语义理解或其他语言能力，代理也可以在基于文本的交互环境中取得成功。这些智能体在玩此类游戏中的成功表明语义理解对于该任务可能并不重要。这就提出了一个重要问题，即 LM 在指导智能体通过游戏状态方面的好处。在这项工作中，我们展示了丰富的语义理解可以实现基于文本的 RL 智能体的高效训练。此外，我们将语义退化的发生描述为基于文本的强化学习（TBRL）中语言模型的不适当微调的结果。具体来说，我们描述了 LM 中单词语义表示的转变，以及它如何影响代理在语义上与训练游戏相似的任务中的表现。我们相信这些结果可能有助于开发更好的策略来微调基于文本的 RL 场景中的代理。]]></description>
      <guid>https://arxiv.org/abs/2404.10174</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:09 GMT</pubDate>
    </item>
    <item>
      <title>PRODIS - 用于研究波兰语可预测性效果的语音数据库和基于音素的语言模型</title>
      <link>https://arxiv.org/abs/2404.10112</link>
      <description><![CDATA[arXiv:2404.10112v1 公告类型：新
摘要：我们提出了波兰语的语音数据库和音素级语言模型。该数据库和模型旨在分析韵律和话语因素及其对与可预测性效果相互作用的声学参数的影响。该数据库也是第一个大型、公开的波兰语音语料库，具有出色的音质，可用于多说话人语音技术系统的语音分析和训练。数据库中的语音在管道中进行处理，实现了 90% 的自动化程度。它包含最先进的免费工具，可以扩展数据库或适应其他语言。]]></description>
      <guid>https://arxiv.org/abs/2404.10112</guid>
      <pubDate>Wed, 17 Apr 2024 06:19:08 GMT</pubDate>
    </item>
    </channel>
</rss>