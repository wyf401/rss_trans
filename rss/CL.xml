<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 23 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>SouLLMate：一款利用自适应 LLM、快速工程和 RAG 技术增强多样化心理健康支持的应用程序</title>
      <link>https://arxiv.org/abs/2410.16322</link>
      <description><![CDATA[arXiv:2410.16322v1 公告类型：新 
摘要：心理健康问题严重影响个人的日常生活，但即使有可用的在线资源，许多人也得不到他们需要的帮助。本研究旨在通过尖端人工智能技术提供多样化、可访问、无污名、个性化和实时的心理健康支持。它做出了以下贡献：（1）对最近的心理健康支持方法进行广泛调查，以确定普遍的功能和未满足的需求。（2）介绍SouLLMate，这是一个自适应的LLM驱动系统，集成了LLM技术、链、检索增强生成（RAG）、提示工程和领域知识。该系统提供风险检测和主动指导对话等高级功能，并利用RAG进行个性化个人资料上传和对话信息提取。（3）通过专业注释的访谈数据和现实生活中的自杀倾向数据开发用于初步评估和风险检测的新型评估方法。 （4）提出关键指标总结（KIS）、主动提问策略（PQS）和堆叠式多模型推理（SMMR）方法，通过上下文敏感的响应调整、语义连贯性评估和语言模型中长上下文推理的准确性提高模型性能和可用性。这项研究有助于推进心理健康支持技术，有可能提高全球心理健康护理的可及性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.16322</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>该候选人是 [MASK]。使用 LLM 的推荐信和就业市场结果</title>
      <link>https://arxiv.org/abs/2410.16325</link>
      <description><![CDATA[arXiv:2410.16325v1 公告类型：新
摘要：我实施了一种基于提示的学习策略，从机密推荐信中提取情绪指标和其他特征。我表明，推荐信的内容清楚地反映在经济学学术就业市场中求职者的表现中。相比之下，应用传统的“词袋”方法产生的情绪指标虽然与我的基于法学硕士的指标呈正相关，但不能预测就业市场的结果。使用随机森林，我表明信件质量和长度都可以预测就业市场的成功。顾问撰写的信件似乎与其他推荐人撰写的信件一样重要。]]></description>
      <guid>https://arxiv.org/abs/2410.16325</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KatzBot：革命性的学术聊天机器人，增强沟通</title>
      <link>https://arxiv.org/abs/2410.16385</link>
      <description><![CDATA[arXiv:2410.16385v1 公告类型：新
摘要：大学内部的有效沟通对于满足学生、校友和外部利益相关者的多样化信息需求至关重要。然而，现有的聊天机器人系统往往无法提供准确的、特定于上下文的响应，导致用户体验不佳。在本文中，我们介绍了 KatzBot，这是一款创新的聊天机器人，由 KatzGPT 提供支持，KatzGPT 是一种针对特定领域学术数据进行微调的自定义大型语言模型 (LLM)。KatzGPT 在两个特定于大学的数据集上进行训练：6,280 个句子完成对和 7,330 个问答对。KatzBot 的表现优于现有的开源 LLM，实现了更高的准确性和领域相关性。KatzBot 提供了用户友好的界面，显着提高了实际应用中的用户满意度。源代码可在 \url{https://github.com/AiAI-99/katzbot} 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2410.16385</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于法学硕士的复合人工智能系统优化：一项调查</title>
      <link>https://arxiv.org/abs/2410.16392</link>
      <description><![CDATA[arXiv:2410.16392v1 公告类型：新 
摘要：在复合 AI 系统中，LLM 调用、检索器、代码解释器或工具等组件是相互连接的。系统的行为主要由指令或工具定义等参数驱动。最近的进展使得使用 LLM 可以对这些参数进行端到端优化。值得注意的是，利用 LLM 作为优化器特别有效，因为它避免了梯度计算并且可以生成复杂的代码和指令。本文概述了基于 LLM 的复合 AI 系统优化的原理和新兴趋势。它涵盖了复合 AI 系统的原型、基于 LLM 的端到端优化方法以及对未来方向和更广泛影响的见解。重要的是，这项调查使用程序分析中的概念来提供 LLM 优化器如何优化复合 AI 系统的统一视图。论文的详尽列表请参阅https://github.com/linyuhongg/LLM-based-Optimization-of-Compound-AI-Systems。]]></description>
      <guid>https://arxiv.org/abs/2410.16392</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VipAct：通过专门的 VLM 代理协作和工具使用增强视觉感知</title>
      <link>https://arxiv.org/abs/2410.16400</link>
      <description><![CDATA[arXiv:2410.16400v1 公告类型：新
摘要：虽然视觉语言模型 (VLM) 在结合文本和视觉信息的各种任务中表现出色，但它们在需要详细像素级分析的细粒度视觉感知任务中仍然举步维艰。有效地从 VLM 中引出对如此复杂的视觉元素的全面推理仍然是一个悬而未决的挑战。在本文中，我们介绍了 VipAct，这是一个代理框架，它通过集成多代理协作和视觉专家模型来增强 VLM，从而实现更精确的视觉理解和全面推理。VipAct 由一个协调器代理组成，它管理任务需求分析、规划和协调，以及处理特定任务（如图像字幕和提供高精度感知信息的视觉专家模型）的专用代理。这种多代理方法允许 VLM 通过协同规划、推理和工具使用来更好地执行细粒度的视觉感知任务。我们在具有多种视觉感知任务的基准上对 VipAct 进行了评估，实验结果表明，与所有任务中最先进的基线相比，VipAct 的性能有了显著的提升。此外，全面的消融研究揭示了多智能体协作在引出更详细的 System-2 推理方面的关键作用，并强调了图像输入对任务规划的重要性。此外，我们的错误分析确定了 VLM 在视觉感知方面的固有局限性模式，为未来的潜在改进提供了见解。VipAct 提供了一个灵活且可扩展的框架，为各种实际应用中更先进的视觉感知系统铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.16400</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用学习到的实时评论特征增强多模态情感分析</title>
      <link>https://arxiv.org/abs/2410.16407</link>
      <description><![CDATA[arXiv:2410.16407v1 公告类型：新
摘要：实时评论，也称为 Danmaku，是与视频内容同步的用户生成消息。这些评论直接叠加在流媒体视频上，实时捕捉观众的情绪和反应。虽然之前的工作已经在情感分析中利用了实时评论，但由于不同视频平台上的实时评论相对稀少，其使用受到限制。为了解决这个问题，我们首先构建了情感分析实时评论 (LCAffect) 数据集，其中包含涵盖不同类型的英文和中文视频的实时评论，这些视频会引发广泛的情感。然后，使用该数据集，我们使用对比学习来训练视频编码器以生成合成的实时评论特征，以增强多模态情感内容分析。通过对英文和中文的各种情感分析任务（情绪、情感识别和讽刺检测）进行全面实验，我们证明这些合成的实时评论特征比最先进的方法显著提高了性能。]]></description>
      <guid>https://arxiv.org/abs/2410.16407</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用白盒语言模型提高神经元级可解释性</title>
      <link>https://arxiv.org/abs/2410.16443</link>
      <description><![CDATA[arXiv:2410.16443v1 公告类型：新
摘要：可以通过分析 GPT-2 等自回归语言模型中的神经元的激活模式来解释它们。最近的研究表明，诸如字典学习（一种事后稀疏编码）之类的技术可以增强这种神经元级的可解释性。在我们的研究中，我们的目标是通过将稀疏编码直接嵌入模型架构中而不是事后应用，从根本上提高神经网络的可解释性。在我们的研究中，我们引入了一种名为 Coding RAte TransformEr (CRATE) 的白盒变压器式架构，该架构专门设计用于捕获数据分布中的稀疏、低维结构。我们的综合实验展示了各种评估指标中神经元级可解释性的显着改进（相对改进高达 103%）。详细的调查证实，无论模型大小如何，这种增强的可解释性在不同层之间都是稳定的，突显了 CRATE 在增强神经网络可解释性方面的强大性能。进一步分析表明，CRATE 的可解释性增强源于其增强了对相关标记进行一致且有区别地激活的能力。这些发现为创建在神经元级解释方面表现优异的白盒基础模型指明了一个有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2410.16443</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>苏苏盒子或小猪存钱罐：评估加纳和美国之间的文化常识</title>
      <link>https://arxiv.org/abs/2410.16451</link>
      <description><![CDATA[arXiv:2410.16451v1 公告类型：新
摘要：最近的研究强调了常识知识的文化偶然性。我们引入了 AMAMMER${\epsilon}$，这是一组 525 个多项选择题的测试集，旨在评估英语法学硕士相对于加纳和美国文化背景的常识知识。为了创建 AMAMMER${\epsilon}$，我们从现有的常识数据集中选择了一组多项选择题 (MCQ)，并通过涉及加纳和美国参与者调查的多阶段过程重写它们。在三轮调查中，来自两个池的参与者被要求 (1) 写出正确和错误的答案选项，(2) 按照 5 点李克特量表对单个答案选项进行评分，以及 (3) 在最后的验证步骤中从新构建的 MCQ 项目中选择最佳答案选项。通过让参与者参与多个阶段，我们的程序确保参与者的观点在测试项目的创建和验证中都得到体现，从而在每个池中实现高度一致。我们在 AMAMMER${\epsilon}$ 上评估了几个现成的英语法学硕士。一致地，模型更喜欢与美国注释者而非加纳注释者的偏好相符的答案选择。此外，当测试项目指定文化背景（加纳或美国）时，模型表现出一定的适应能力，但在美国背景下的表现始终优于加纳。由于大量资源投入到英语法学硕士的推进中，我们的研究结果强调需要具有文化适应性的模型和评估来满足世界各地不同英语人群的需求。]]></description>
      <guid>https://arxiv.org/abs/2410.16451</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>你的法学硕士真的能忘记吗？一种恢复未学知识的简单方法</title>
      <link>https://arxiv.org/abs/2410.16454</link>
      <description><![CDATA[arXiv:2410.16454v1 公告类型：新
摘要：大型语言模型 (LLM) 在生成文本方面表现出非凡的能力，得益于对大量文本语料库的广泛训练。然而，LLM 也可能从其训练数据的多样性和敏感性中获得不良行为，这些训练数据可能包括受版权保护的内容和私人内容。机器反学习已被引入作为一种可行的解决方案，可以消除此类问题内容的影响，而无需昂贵且耗时的再训练。此过程旨在从 LLM 中删除特定知识，同时尽可能多地保留模型效用。尽管当前的反学习方法很有效，但很少有人关注现有的 LLM 反学习方法是否真正实现了遗忘或仅仅隐藏了知识，而当前的反学习基准无法检测到这些知识。本文表明，将量化应用于经过反学习的模型可以恢复“被遗忘”的信息。为了彻底评估这一现象，我们使用跨多个精度级别的各种量化技术进行了全面的实验。我们发现，对于具有效用约束的反学习方法，反学习模型平均可以完全精确地保留 21% 的预期遗忘知识，在 4 位量化后，该数字显著增加到 83%。根据我们的实证研究结果，我们对观察到的现象提供了理论解释，并提出了一种量化稳健的反学习策略来缓解这一复杂问题……]]></description>
      <guid>https://arxiv.org/abs/2410.16454</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>走向世界 (TTG)：迈向语言驱动的保障旅行计划</title>
      <link>https://arxiv.org/abs/2410.16456</link>
      <description><![CDATA[arXiv:2410.16456v1 公告类型：新
摘要：旅行规划是一项具有挑战性且耗时的任务，旨在找到一条满足航班、住宿、景点和其他旅行安排等多个相互依赖约束的行程。在本文中，我们提出了 To the Globe (TTG)，这是一个实时演示系统，它接收用户的自然语言请求，通过微调的大型语言模型将其转换为符号形式，并使用混合整数线性规划求解器生成最佳旅行行程。整个系统需要大约 5 秒钟才能以保证的行程回复用户请求。为了训练 TTG，我们开发了一个合成数据管道，该管道基于真实世界数据集的统计数据，以符号形式生成用户请求、航班和酒店信息（无需人工注释），并微调 LLM 以将 NL 用户请求转换为其符号形式，然后将其发送给符号求解器以计算最佳行程。我们的 NL-符号翻译在反向翻译指标中实现了约 91% 的精确匹配（即，生成的自然语言的估计符号形式是否与事实相符），其返回的行程与事实用户请求的最佳成本相比具有 0.979 的比率。在用户评估中，TTG 在生成的行程上始终获得 35-40% 的高净推荐值 (NPS)。]]></description>
      <guid>https://arxiv.org/abs/2410.16456</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中多语言习语和明喻的比较研究</title>
      <link>https://arxiv.org/abs/2410.16461</link>
      <description><![CDATA[arXiv:2410.16461v1 公告类型：新
摘要：本研究填补了文献中关于 LLM 在多种语言中解释不同类型的比喻性语言方面的比较性能的空白。通过使用两个多语言数据集对明喻和习语解释的 LLM 进行评估，我们探索了各种提示工程策略的有效性，包括思路链、小样本和英语翻译提示。我们还通过构建两个新的评估集将这些数据集的语言扩展到波斯语。我们的全面评估涉及闭源（GPT-3.5、GPT-4o mini、Gemini 1.5）和开源模型（Llama 3.1、Qwen2），突出了不同语言和比喻类型的性能存在显著差异。我们的研究结果表明，虽然提示工程方法通常是有效的，但它们的成功因比喻类型、语言和模型而异。我们还观察到，开源模型在明喻中尤其难以处理资源匮乏的语言。此外，许多语言的习语解释已接近饱和，需要更具挑战性的评估。]]></description>
      <guid>https://arxiv.org/abs/2410.16461</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越浏览：基于 API 的 Web 代理</title>
      <link>https://arxiv.org/abs/2410.16464</link>
      <description><![CDATA[arXiv:2410.16464v1 公告类型：新
摘要：Web 浏览器是互联网的门户，人类的大部分活动都在这里进行。因此，在通过 Web 浏览与互联网交互的 AI 代理方面已经进行了大量研究。但是，还有另一个专门为机器与在线内容交互而设计的接口：应用程序编程接口 (API)。在本文中，我们提出一个问题——如果我们将传统上由浏览代理处理的任务交给 AI 代理，并让其访问 API，会怎么样？为此，我们提出了两种代理：(1) API 调用代理，它试图仅通过 API 执行在线任务，类似于传统的编码代理；(2) 混合代理，它可以通过 Web 浏览和 API 与在线数据交互。在 WebArena（一种广泛使用且现实的 Web 导航任务基准）上的实验中，我们发现基于 API 的代理优于 Web 浏览代理。混合代理在各个任务上的表现几乎一致优于其他代理，与单纯的网页浏览相比，其绝对性能提升超过 20.0%，成功率达到 35.8%，在与任务无关的代理中达到 SOTA 性能。这些结果有力地表明，当 API 可用时，它们可以成为一种有吸引力的替代方案，而不必仅仅依赖网页浏览。]]></description>
      <guid>https://arxiv.org/abs/2410.16464</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DocEdit-v2：通过多模式 LLM 基础编辑文档结构</title>
      <link>https://arxiv.org/abs/2410.16472</link>
      <description><![CDATA[arXiv:2410.16472v1 公告类型：新
摘要：文档结构编辑涉及根据用户的请求操作文档图像中的本地化文本、视觉和布局组件。过去的研究表明，在文档图像中多模态地确定用户请求并识别准确的结构组件及其相关属性仍然是这项任务的关键挑战。为了解决这些问题，我们引入了 DocEdit-v2，这是一个通过利用大型多模态模型 (LMM) 执行端到端文档编辑的新框架。它由三个新组件组成：(1) Doc2Command，它同时定位编辑感兴趣区域 (RoI) 并将用户编辑请求消除歧义为编辑命令；(2) 基于 LLM 的命令重构提示将最初用于专用软件的编辑命令定制为适合通用 LMM 的编辑指令。 （3）此外，DocEdit-v2 通过 GPT-4V 和 Gemini 等大型多模态模型处理这些输出，以解析文档布局、在接地感兴趣区域 (RoI) 上执行编辑并生成编辑后的文档图像。在 DocEdit 数据集上进行的大量实验表明，DocEdit-v2 在编辑命令生成（2-33%）、RoI 边界框检测（12-31%）和整体文档编辑（1-12\%）任务上的表现明显优于强基线。]]></description>
      <guid>https://arxiv.org/abs/2410.16472</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于语法错误纠正的多头序列标注模型</title>
      <link>https://arxiv.org/abs/2410.16473</link>
      <description><![CDATA[arXiv:2410.16473v1 公告类型：新
摘要：为了解决语法错误纠正 (GEC) 问题，需要在源序列和目标序列之间进行映射，其中两者仅在少数跨度上有所不同。因此，注意力已转移到非自回归或序列标记模型。其中，GEC 已从 Seq2Seq 简化为使用从大型编辑空间中选择的编辑命令标记输入标记。由于类别数量众多且可用数据集有限，当前的序列标记方法仍然存在一些问题，仅通过专注于一项任务来处理广泛的语法错误。为此，我们进一步简化了 GEC，将其分为七个相关的子任务：插入、删除、合并、替换、转换、检测和纠正，其中纠正是我们的主要关注点。每个子任务都有一个专门的分类头。提出了新颖的多头多任务学习模型，以有效利用训练数据并利用来自相关任务训练信号的信息。为了缓解可用训练样本数量有限的问题，使用了一种新的去噪自动编码器来生成新的合成数据集以用于预训练。此外，提出了一种新的字符级变换来增强序列编辑功能并提高模型的词汇覆盖率。我们的单一/集成模型在 BEA-19（测试）和 CoNLL-14（测试）上分别实现了 74.4/77.0 和 68.6/69.1 的 F0.5。此外，在 JFLEG 测试集上进行评估，单一和集成模型的 GLEU 得分分别为 61.6 和 61.7。它大多以相当大的优势优于最近发表的最先进的结果。]]></description>
      <guid>https://arxiv.org/abs/2410.16473</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BIG5-CHAT：通过基于人性化数据进行训练，塑造法学硕士个性</title>
      <link>https://arxiv.org/abs/2410.16491</link>
      <description><![CDATA[arXiv:2410.16491v1 公告类型：新
摘要：在这项工作中，我们解决了将现实的人类性格特征嵌入 LLM 的挑战。以前的方法主要侧重于基于提示的方法，这些方法描述与所需性格特征相关的行为，存在现实性和有效性问题。为了解决这些限制，我们引入了 BIG5-CHAT，这是一个包含 100,000 个对话的大型数据集，旨在为人类如何在文本中表达自己的个性建立模型。利用这个数据集，我们探索监督微调和直接偏好优化作为基于训练的方法，以使 LLM 更自然地与人类性格模式保持一致。我们的方法在 BFI 和 IPIP-NEO 等人格评估方面的表现优于提示，特征相关性与人类数据更接近。此外，我们的实验表明，经过训练表现出更高的尽责性、更高的亲和性、更低的外向性和更低的神经质的模型在推理任务上表现出更好的表现，这与这些特征如何影响人类认知表现的心理学发现相一致。据我们所知，这项研究是第一项全面的研究，展示了基于培训的方法如何通过学习真实的人类行为来塑造法学硕士的个性。]]></description>
      <guid>https://arxiv.org/abs/2410.16491</guid>
      <pubDate>Wed, 23 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>