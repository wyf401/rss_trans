<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 24 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>以知识为中心的检索增强生成基准框架与实证研究</title>
      <link>https://arxiv.org/abs/2409.13694</link>
      <description><![CDATA[arXiv:2409.13694v1 公告类型：新
摘要：检索增强生成 (RAG) 通过集成检索机制来增强生成模型，从而使这些模型能够访问和利用外部知识源。尽管 RAG 具有诸多优势，但它仍面临重大挑战，尤其是在有效处理现实世界的查询和减轻幻觉方面。KDD Cup 2024 CRAG 竞赛通过将网页和模拟 API 作为知识源，将这些问题带到了最前沿，增加了在大型语言模型 (LLM) 处理信息之前解析 HTML 的复杂性。在本文中，我们提出了一种旨在应对这些挑战的新型 RAG 基准。我们的工作提供了一套全面的实验结果，为 RAG 的研究提供了宝贵的见解。我们彻底检查了整个 RAG 过程，包括知识源选择、检索、组织和推理。我们研究的主要发现包括使用代理自动选择知识源的影响以及噪声块对 RAG 推理的影响。此外，我们还进行了详细的实验，以分析各种超参数对 RAG 性能的影响。为了支持进一步的研究，我们已公开提供我们的结果、相关代码和 CRAG 数据集的解析版本\footnote{https://github.com/USTCAGI/RAG-X}，为 RAG 方法的进步做出了贡献，并为该领域的未来工作奠定了坚实的基础。]]></description>
      <guid>https://arxiv.org/abs/2409.13694</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>你只使用反应性注意力切片进行长上下文检索</title>
      <link>https://arxiv.org/abs/2409.13695</link>
      <description><![CDATA[arXiv:2409.13695v1 公告类型：新
摘要：支持大型语言模型 (LLM) 的更长上下文是推进 LLM 的一个有前途的方向。由于训练更长上下文窗口的模型在计算上很昂贵，因此已经使用了许多替代解决方案，例如检索增强生成 (RAG)。然而，大多数现有的 RAG 方法采用基于嵌入的检索，这在长上下文中存在不足。
为了应对这些挑战，我们提出了一种基于注意力的检索技术，即 You Only Use Reactive Attention 切片 (YOURA)。YOURA 利用一种称为反应分数的新型检索启发式方法对输入上下文中每个句子与查询句子的相关性进行排序。直观地说，我们测量每个标记的注意力分数如何“反应”查询并贪婪地检索最具反应性的句子。在内部，YOURA 为整个输入上下文生成一个标记索引向量（称为反应向量）。为了将每个句子映射到标记索引向量，我们提出了一种与嵌入无关的句子产量 (EASY)，这是一种尽力而为的标记摆动算法。
我们在六个 LongBench QA 数据集上的三个开源预训练 LLM 模型上评估了我们的检索技术。我们的技术在处理长上下文查询时实现了高达 30% 的 vLLM 推理吞吐量改进，其质量得分与简单但有效的截断中间方法几乎相同。]]></description>
      <guid>https://arxiv.org/abs/2409.13695</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>快速烘焙</title>
      <link>https://arxiv.org/abs/2409.13697</link>
      <description><![CDATA[arXiv:2409.13697v1 公告类型：新
摘要：改变 LLM 行为的两种主要方法是提示和权重更新（例如，微调）。提示 LLM 简单有效，用自然语言明确指定所需的更改，而权重更新提供更具表现力和持久的行为变化，通过对大型数据集进行训练隐式指定。我们提出了一种将提示“烘焙”到 LLM 权重中的技术。提示烘焙将提示 $u$ 和初始权重 $\theta$ 转换为一组新的权重 $\theta_u$，使得新的“烘焙”LLM 的行为与原始提示的 LLM 一样。从数学上讲，我们最小化 $P_\theta(\cdot | u)$ 和 $P_{\theta_u}(\cdot)$ 之间的 KL 散度，其中 $P$ 是 LLM 在标记序列上的概率分布。在我们所有的实验中，我们发现提示可以很容易地融入权重更新中。烘焙思路链提示可提高 GSM8K、ASDiv、MBPP、ARC-Easy、ARC-Challenge 和 CommonsenseQA 基准的零样本性能。烘焙新闻标题可直接更新 LLM 的知识。烘焙说明和角色可缓解长序列中的“提示遗忘”。此外，提前停止烘焙会产生“半生不熟”的模型，不断扩大提示强度。烘焙模型保留了对进一步提示和烘焙的敏感性，包括使用烘焙提示进行重新提示。令人惊讶的是，重新提示的模型在指令遵循以及数学推理和编码基准方面获得了进一步的性能提升。将重新提示和重新烘焙发挥到极致会产生一种我们称之为“提示追求”的迭代自我改进形式，指令遵循的初步结果显示出显着的性能提升。最后，我们讨论了对人工智能安全、持续模型更新、增强基于 LLM 的代理的实时学习能力以及生成更稳定的人工智能角色的影响。]]></description>
      <guid>https://arxiv.org/abs/2409.13697</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于帧级标准的轻量级传感器</title>
      <link>https://arxiv.org/abs/2409.13698</link>
      <description><![CDATA[arXiv:2409.13698v1 Announce Type: new 
摘要：基于序列级准则训练的转换器模型由于需要生成较大的概率矩阵，需要占用较大的内存。我们提出了一种基于帧级准则的轻量级转换器模型，利用CTC强制对齐算法的结果确定每帧的标签，然后将编码器输出与解码器输出的相应时刻的输出进行合并，而不是像转换器那样将编码器输出的每个元素与解码器输出的每个元素相加，这样可以大大减少内存和计算量。针对标签空白过多导致分类不平衡的问题，我们将空白和非空白概率解耦，并将空白分类器的梯度截断到主网络，使轻量级转换器能够达到与转换器相近的效果，并且利用更丰富的信息来预测空白概率，从而达到优于转换器的效果。]]></description>
      <guid>https://arxiv.org/abs/2409.13698</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CA-BERT：利用情境感知增强多轮聊天交互</title>
      <link>https://arxiv.org/abs/2409.13701</link>
      <description><![CDATA[arXiv:2409.13701v1 公告类型：新
摘要：自动聊天系统中的有效沟通取决于理解和响应上下文的能力。传统模型通常难以确定何时需要额外的上下文来生成适当的响应。本文介绍了上下文感知 BERT (CA-BERT)，这是一种基于 Transformer 的模型，专门针对这一挑战进行了微调。CA-BERT 创新地应用深度学习技术来辨别多轮聊天交互中的上下文必要性，从而提高了响应的相关性和准确性。
我们描述了 CA-BERT 的开发，它采用了 BERT 的强大架构，并采用了一种新颖的训练方案，该方案专注于专门的聊天对话数据集。该模型根据其对上下文必要性进行分类的能力进行评估，在准确性和效率方面表现出优于基线 BERT 模型的性能。此外，CA-BERT 的实施展示了训练时间和资源使用量的显着减少，使其适用于实时应用。
结果表明，CA-BERT 可通过提供对上下文的细致理解来有效增强聊天机器人的功能，从而改善自动化系统中的用户体验和交互质量。这项研究不仅推动了聊天应用中的 NLP 领域，还为未来对上下文敏感的 AI 发展的研究提供了一个框架。]]></description>
      <guid>https://arxiv.org/abs/2409.13701</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>塑造濒危语言和资源匮乏语言的未来——我们在法学硕士时代的角色：ECIR 2024 主题演讲</title>
      <link>https://arxiv.org/abs/2409.13702</link>
      <description><![CDATA[arXiv:2409.13702v1 公告类型：新
摘要：塞维利亚的伊西多尔有句名言：“语言造就了一个民族，而不是相反”，强调了语言在文化和社会认同形成中发挥的深远作用。今天，在列出的 7100 多种语言中，有相当一部分濒临灭绝。自 20 世纪 70 年代以来，语言学家、信息搜索者和爱好者帮助开发了数字资源和自动化工具，以支持包括濒危语言在内的多种语言。大型语言模型 (LLM) 技术的出现既有希望，也有危险。它们为内容和资源的翻译和生成提供了前所未有的可能性，而内容和资源是语言保护和振兴的关键要素。它们还带来了同质化、文化过度简单化和本已脆弱的语言进一步边缘化的威胁。本文基于此次演讲，提出了一次开创性的旅程，探索技术与传统之间的潜在路径和伙伴关系，特别关注奥克语。奥克语是一种来自法国南部、西班牙部分地区和意大利的语言，在中世纪发挥了重要的文化和经济作用。根据联合国教科文组织的说法，它现在濒临灭绝。这次演讲批判性地研究了人类的专业知识和人工智能如何共同努力，为保护构成我们全球特别是欧洲遗产基础的语言多样性带来希望，同时解决使用这些强大技术所带来的一些道德和实际挑战。本文基于我在第 46 届欧洲信息检索会议 (ECIR 2024) 上的主题演讲。作为阅读本文的替代方法，可以在线观看视频演讲。1 日期：2024 年 3 月 26 日。]]></description>
      <guid>https://arxiv.org/abs/2409.13702</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型从高层腐败计划中提取实体</title>
      <link>https://arxiv.org/abs/2409.13704</link>
      <description><![CDATA[arXiv:2409.13704v1 公告类型：新
摘要：近年来，金融犯罪的兴起引起了人们对这一话题的日益关注，许多人、组织和政府越来越多地试图打击它。尽管人们对这一领域的兴趣日益增加，但缺乏可用于训练和评估试图解决这些问题的作品的专门数据集。本文提出了一种新的微基准数据集，用于识别新闻文章中的个人和组织及其多篇文章的算法和模型，并提出了一种有助于创建它的方法。还报告了使用该数据集使用各种低十亿参数大型语言模型 (LLM) 在金融犯罪相关文章中识别个人和组织的实验努力。对于这些实验，报告了标准指标（准确度、精确度、召回率、F1 分数），并测试了包含提示工程最佳实践的各种提示变体。此外，针对实体提及歧义问题，提出了一种简单而有效的基于 LLM 的消歧方法，确保评估与现实相符。最后，将所提出的方法与广泛使用的最先进的开源基线进行了比较，显示了所提出方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2409.13704</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过公平意识集成消除文本安全分类器的偏见</title>
      <link>https://arxiv.org/abs/2409.13705</link>
      <description><![CDATA[arXiv:2409.13705v1 公告类型：新摘要：大型语言模型 (LLM) 的使用越来越多，需要高性能护栏来确保 LLM 输入和输出的安全。当这些保护措施在不平衡的数据上进行训练时，它们可以学习社会偏见。我们提出了一种轻量级的后处理方法来减轻闭源文本安全分类器中的反事实公平性。我们的方法包括构建一个集成，它不仅优于输入分类器并对其进行策略调整，而且还充当去偏正则化器。我们引入了两个与阈值无关的指标来评估模型的反事实公平性，并展示了如何将这些指标与公平数据重新加权 (FDW) 相结合有助于减轻偏见。我们创建了一个扩展的 Open AI 数据集和一个基于用户提示的新模板化 LLM 生成的数据集，这两个数据集在身份组之间都是反事实平衡的，并涵盖了四个关键的安全领域；我们将努力公开发布这些数据集。我们的结果表明，我们的方法提高了反事实公平性，同时对模型性能的影响最小。]]></description>
      <guid>https://arxiv.org/abs/2409.13705</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>去殖民化数据系统：使用粤拼或拼音作为中文姓名的音调表示，以进行数据链接</title>
      <link>https://arxiv.org/abs/2409.13706</link>
      <description><![CDATA[arXiv:2409.13706v1 公告类型：新
摘要：数据链接越来越多地用于健康研究和政策制定，并依赖于它来了解健康不平等。然而，链接数据的有用性取决于底层数据的质量，而不同的链接率可能会导致链接数据的选择偏差。一种有选择地损害数据质量的机制是姓名罗马化。将不同书写系统的文本转换为拉丁文字或罗马化，长期以来一直是在基于字符的书写系统（如中文、越南语和其他语言，如斯瓦希里语）中表示姓名的标准过程。中文字符的罗马化不标准，部分原因是无法保留正确的姓名顺序，缺乏对声调语言的正确语音表示，导致中国移民的链接率较低。本篇评论文章旨在提出，使用包含声调信息的粤语（Jyutping）或普通话（拼音）标准化罗马化系统可以提高具有中文姓名的个人的链接率和准确性。我们使用了从公开来源抓取的 771 个中文和英文姓名，并比较了粤语、拼音和香港政府罗马化系统（HKG-romanisation）在表示中文姓名方面的效用。我们证明，与 HKG-romanisation 系统相比，粤语和拼音的错误率都更低。我们认为，收集和保存人们原始书写系统的姓名在道德和社会上都是有意义的。这可能有助于开发特定语言的预处理和链接范例，从而产生更具包容性的研究数据，更好地代表目标人群。]]></description>
      <guid>https://arxiv.org/abs/2409.13706</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向安全的多语言前沿人工智能</title>
      <link>https://arxiv.org/abs/2409.13708</link>
      <description><![CDATA[arXiv:2409.13708v1 公告类型：新 
摘要：语言包容性的法学硕士（无论使用哪种语言都能保持良好的性能）对于在世界范围内传播人工智能的好处是必不可少的。依赖语言翻译来逃避安全措施的多语言越狱破坏了人工智能系统的安全和包容性部署。我们提供政策建议，以增强人工智能的多语言能力，同时降低多语言越狱的风险。我们定量评估了 24 种欧盟官方语言中的五种前沿大型语言模型的语言资源和模型对多语言越狱的脆弱性之间的关系。在先前研究的基础上，我们提出了符合欧盟法律环境和体制框架的政策行动，以解决多语言越狱问题，同时促进语言包容性。这些措施包括对多语言能力和弱点的强制性评估、民意调查以及国家对多语言人工智能发展的支持。这些措施旨在通过欧盟政策举措提高人工智能的安全性和功能性，指导欧盟人工智能法案的实施，并为欧洲人工智能办公室的监管工作提供信息。]]></description>
      <guid>https://arxiv.org/abs/2409.13708</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>列词汇关联（CVA）：无数据表的语义解释</title>
      <link>https://arxiv.org/abs/2409.13709</link>
      <description><![CDATA[arXiv:2409.13709v1 公告类型：新
摘要：传统的语义表解释 (STI) 方法主要依赖于底层表数据来创建语义注释。今年的 SemTab 挑战赛引入了“元数据到 KG”轨道，该轨道专注于仅使用元数据信息执行 STI，而无需访问底层数据。为了应对这一新挑战，我们引入了一个新术语：列词汇关联 (CVA)。该术语指的是仅基于元数据信息对列标题进行语义注释的任务。在本研究中，我们评估了执行 CVA 任务的各种方法的性能，包括大型语言模型 (LLM) 和检索增强生成 (RAG) 方法，以及更传统的相似性方法 SemanticBERT。我们的方法使用零样本设置，没有预训练或将示例传递给大型语言模型 (LLM)，因为我们的目标是避免特定于领域的设置。
我们总共调查了 7 种不同的 LLM，其中包括三种商业 GPT 模型（即 gpt-3.5-turbo-0.125、gpt-4o 和 gpt-4-turbo）和四种开源模型（即 llama3-80b、llama3-7b、gemma-7b 和 mixtral-8x7b）。我们将这些模型与 RAG 系统集成，并探索温度设置的变化如何影响性能。此外，我们继续调查，利用 SemanticBERT 执行 CVA 任务，分析各种元数据信息如何影响其性能。
初步结果表明，LLM 在低于 1.0 的温度下通常表现良好，在某些情况下可达到 100\% 的准确率。然而，我们的调查还表明，数据的性质会显著影响 CVA 任务结果。事实上，在输入数据和词汇表相关的情况下（例如由同一组织创建），传统方法似乎超越了 LLM 的性能。]]></description>
      <guid>https://arxiv.org/abs/2409.13709</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>你可以通过微调删除 GPT2 的 LayerNorm</title>
      <link>https://arxiv.org/abs/2409.13710</link>
      <description><![CDATA[arXiv:2409.13710v1 公告类型：新
摘要：GPT 风格 Transformer 模型中的 LayerNorm (LN) 层长期以来一直是机械可解释性的障碍。LN 是稳定大型语言模型训练所需的关键组件，几乎所有基于 Transformer 架构的大型语言模型都使用了 LN 或类似的 RMNSorm。LN 层的非线性特性阻碍了机械可解释性，因为它阻碍了对残差流的解释，并使模型难以分解为电路。一些研究甚至指出了“可解释性研究人员讨厌层规范的原因”。
在本文中，我们表明，可以通过对训练数据的一小部分（5 亿个 token）进行微调，从预训练的 GPT2-small 模型中删除 LN 层。我们证明，这个无 LN 模型在 OpenWebText 和 ThePile 数据集（-0.05 交叉熵损失）和 Hellaswag 基准（-0.5% 准确率）上实现了与原始模型类似的性能。我们提供了微调过程和带有微调 GPT2-small 模型的 Hugging Face 存储库。
我们的工作不仅为机械可解释性研究提供了一个简化的模型，而且还提供了证据表明，在推理时，LN 层在 Transformer 模型中并不起关键作用。]]></description>
      <guid>https://arxiv.org/abs/2409.13710</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>好主意与否，法学硕士的代表性可以说明一切</title>
      <link>https://arxiv.org/abs/2409.13712</link>
      <description><![CDATA[arXiv:2409.13712v1 公告类型：新
摘要：在不断扩展的学术研究领域中，思想的激增给研究人员带来了重大挑战：从影响较小的思想中辨别出有价值的思想。有效评估这些思想潜力的能力对于科学的进步和论文评审至关重要。在这项工作中，我们专注于思想评估，旨在利用大型语言模型的知识来评估科学思想的价值。首先，我们调查现有的文本评估研究并定义思想定量评估的问题。其次，我们从近四千份带有全文的手稿论文中整理并发布了一个基准数据集，精心设计用于训练和评估不同方法执行此任务的性能。第三，我们通过在大型语言模型的特定层中使用表示来建立一个量化思想价值的框架。实验结果表明，我们的方法预测的分数与人类的分数相对一致。我们的研究结果表明，大型语言模型的表征在量化思想的价值方面比其生成输出更有潜力，这为自动化思想评估过程提供了一条有希望的途径。]]></description>
      <guid>https://arxiv.org/abs/2409.13712</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于抑郁症检测的情感知情句子 BERT-Ensemble 算法</title>
      <link>https://arxiv.org/abs/2409.13713</link>
      <description><![CDATA[arXiv:2409.13713v1 公告类型：新
摘要：世界卫生组织 (WHO) 透露，全球约有 2.8 亿人患有抑郁症。然而，目前使用机器学习 (ML) 技术进行早期抑郁症检测的研究有限。先前的研究应用了单一的独立算法，该算法无法处理数据复杂性，容易过度拟合，并且泛化能力有限。为此，我们的论文使用两个基准社交媒体数据集 (D1 和 D2) 检查了几种 ML 算法在早期抑郁症检测中的性能。更具体地说，我们结合了情绪指标来提高我们的模型性能。我们的实验结果表明，将 Transformers (SBERT) 数值向量拟合到堆叠集成模型中的句子双向编码器表示在数据集 (D1) 中实现了 69% 的可比 F1 分数，在数据集 (D2) 中实现了 76% 的可比 F1 分数。我们的研究结果表明，利用情绪指标作为抑郁症检测的附加特征可以提高模型性能，因此，我们建议为未来的工作开发抑郁术语语料库。]]></description>
      <guid>https://arxiv.org/abs/2409.13713</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TracrBench：使用大型语言模型生成可解释性测试平台</title>
      <link>https://arxiv.org/abs/2409.13714</link>
      <description><![CDATA[arXiv:2409.13714v1 公告类型：新
摘要：实现对基于转换器的语言模型的机械理解是一个开放的挑战，特别是由于它们有大量的参数。此外，模型权重和其功能角色之间缺乏基本事实映射，阻碍了对可解释性方法的有效评估，阻碍了整体进展。Tracr 是一种在 RASP 中生成具有固有基本事实映射的编译转换器的方法，已被提出来解决此问题。然而，手动创建验证可解释性方法所需的大量模型是劳动密集型和耗时的。在这项工作中，我们提出了一种使用大型语言模型 (LLM) 生成可解释性测试平台的新方法，并介绍了 TracrBench，这是一个由 121 个手动编写和 LLM 生成的、人工验证的 RASP 程序及其相应的转换器权重组成的新数据集。在此过程中，我们评估了前沿 LLM 自主生成 RASP 程序的能力，并发现这项任务带来了重大挑战。 GPT-4-turbo 具有 20 次提示和 5 次最佳采样，在 101 个测试程序中仅正确执行了 57 个，其余程序需要手动执行。TracrBench 拥有 121 个样本，旨在成为评估和比较可解释性方法的宝贵测试平台。]]></description>
      <guid>https://arxiv.org/abs/2409.13714</guid>
      <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>