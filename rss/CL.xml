<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 25 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用西班牙语作为外语的测试评估大型语言模型：通过还是失败？</title>
      <link>https://arxiv.org/abs/2409.15334</link>
      <description><![CDATA[arXiv:2409.15334v1 公告类型：新
摘要：大型语言模型 (LLM) 已根据其回答许多主题问题的能力以及其在不同自然语言理解任务中的表现得到了广泛的评估。这些测试通常以英语进行，但大多数 LLM 用户不是以英语为母语的人。因此，分析 LLM 如何理解不同级别的其他语言（从段落到词素）是很有意义的。在本文中，我们评估了最先进的 LLM 在 TELEIA 中的表现，TELEIA 是最近发布的基准，其问题与针对外国学生的西班牙语考试类似，涵盖阅读理解、词汇形成、含义和组合语义以及语法等主题。结果表明，LLM 在理解西班牙语方面表现良好，但在语法能力方面仍远未达到母语人士的水平。]]></description>
      <guid>https://arxiv.org/abs/2409.15334</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>注意你的脚步：可观察的模块化思维链</title>
      <link>https://arxiv.org/abs/2409.15359</link>
      <description><![CDATA[arXiv:2409.15359v1 公告类型：新
摘要：我们提出了一种思路链 (CoT) 提示的变体，称为程序跟踪提示，它使解释更加可观察，同时保留了 CoT 的强大功能、通用性和灵活性。在我们的方法中，少量 CoT 演示被包装在基于 Python 的形式语法中，每个提示：识别和命名步骤；定义步骤的输入/输出行为；并用相同示例上的这些形式化步骤链替换上下文示例的 CoT 解释。程序跟踪提示适用于许多任务，在 BIG-Bench Hard 基准测试中的 23 个不同任务上取得了强劲的成绩。更重要的是，通过以这种方式检测解释，我们可以实现新类型的分析。特别是，我们将“非局部错误”（对应于错误地学习演示中所示的推理方法）确定为 CoT 学习中未解决的问题，并提出了验证 CoT 解释中步骤模块化的方法。]]></description>
      <guid>https://arxiv.org/abs/2409.15359</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多任务混乱：揭示并缓解法学硕士微调中的安全漏洞</title>
      <link>https://arxiv.org/abs/2409.15361</link>
      <description><![CDATA[arXiv:2409.15361v1 公告类型：新 
摘要：大型语言模型 (LLM) 的最新突破已导致其被广泛应用于从代码生成到机器翻译和情感分析等广泛的任务中。红队/安全校准工作表明，对良性（无害）数据进行微调可能会危及安全性。然而，目前尚不清楚这种现象在多大程度上受到不同变量的影响，包括微调任务、模型校准等。本文探讨了由于对下游任务（例如摘要、代码生成、翻译和分类）进行微调而导致的任务安全性下降。我们的结果表明：1）对代码生成和翻译的 LLM 进行微调会导致安全护栏下降幅度最大。2）LLM 在翻译和分类方面的护栏通常较弱，在基线和其他校准中，73-92% 的有害提示得到回答，属于两个关注类别之一。 3) 当前的解决方案（包括防护和安全调优数据集）缺乏跨任务稳健性。为了解决这些问题，我们开发了一个新的多任务安全数据集，有效地降低了一系列任务中的攻击成功率，同时又不损害模型的整体实用性。我们的工作强调了需要采用通用对齐措施来确保模型更安全、更稳健。]]></description>
      <guid>https://arxiv.org/abs/2409.15361</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VERA：检索增强系统的验证和增强</title>
      <link>https://arxiv.org/abs/2409.15364</link>
      <description><![CDATA[arXiv:2409.15364v1 公告类型：新
摘要：大型语言模型 (LLM) 表现出非凡的能力，但通常会产生不准确的响应，因为它们完全依赖于其嵌入的知识。检索增强生成 (RAG) 通过整合外部信息检索系统来增强 LLM，提供额外的上下文以及查询以减轻特定上下文的不准确性。但是，准确性问题仍然存在，因为该模型可能依赖不相关的文档或从其训练知识中错误地推断。为了评估和提高 RAG 框架中检索系统和 LLM 的性能，我们提出了 \textbf{VERA}（\textbf{V} 验证和 \textbf{E} 增强的 \textbf{R} 检索 \textbf{A} 增强系统），该系统旨在：1）在响应生成之前评估和增强检索到的上下文，2）评估和改进 LLM 生成的响应以确保准确性并最大限度地减少错误。VERA 采用评估器兼增强器 LLM，首先检查是否需要外部检索，评估检索到的上下文的相关性和冗余性，然后对其进行改进以消除非必要信息。在响应生成后，VERA 将响应拆分为原子语句，评估它们与查询的相关性，并确保遵守上下文。我们的实验表明，VERA 不仅在提高小型开源模型的性能方面具有显著的功效，而且在提高大型先进模型的性能方面也具有显著的功效。这些增强功能凸显了 VERA 产生准确且相关的响应的潜力，推动了检索增强语言建模的最新发展。VERA 的强大方法结合了多个评估和改进步骤，有效地减轻了幻觉并改善了检索和响应过程，使其成为对信息生成准确性和可靠性要求高的应用的宝贵工具。]]></description>
      <guid>https://arxiv.org/abs/2409.15364</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MedCodER：用于医疗编码的生成式 AI 助手</title>
      <link>https://arxiv.org/abs/2409.15368</link>
      <description><![CDATA[arXiv:2409.15368v1 公告类型：新
摘要：医学编码对于标准化临床数据和通信至关重要，但通常很耗时且容易出错。传统的自然语言处理 (NLP) 方法难以实现自动化编码，因为标签空间很大、文本输入冗长，而且缺乏证明代码选择合理性的证据注释。生成人工智能 (AI) 的最新进展为这些挑战提供了有希望的解决方案。在这项工作中，我们介绍了 MedCodER，这是一个用于自动医学编码的生成 AI 框架，它利用提取、检索和重新排序技术作为核心组件。MedCodER 在国际疾病分类 (ICD) 代码预测中获得了 0.60 的微 F1 分数，远远优于最先进的方法。此外，我们还提供了一个新的数据集，其中包含标有疾病诊断、ICD 代码和支持证据文本的医疗记录 (https://doi.org/10.5281/zenodo.13308316)。消融测试证实，MedCodER 的性能取决于上述每个组件的集成，因为单独评估这些组件时性能会下降。]]></description>
      <guid>https://arxiv.org/abs/2409.15368</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Bone：块仿射变换作为大型语言模型的参数有效微调方法</title>
      <link>https://arxiv.org/abs/2409.15371</link>
      <description><![CDATA[arXiv:2409.15371v1 Announce Type: new 
摘要：随着大型语言模型（LLM）的规模不断增长，其计算和内存需求也相应增加。因此，探索经济高效的微调方法变得越来越重要。低秩自适应（LoRA）通过冻结原始权重并仅训练低秩矩阵取得了显著的训练效果，成为LLM的主要微调方法。为了追求更接近全参数训练的性能，出现了一系列LoRA变体，例如LoRA+、PISSA、Olora和LoRA-GA。然而，这些方法也使微调初始化过程更加复杂，并且仍然很难超越全微调的性能上限。针对这些问题，本文提出了一种称为Bone（Block Affine）的创新方法，它不仅可以减少内存开销，还可以强调权重之间的内部联系，从而实现更快的收敛和更好的数据拟合。跨两种不同的 LLM 架构（LLaMA2、RWKV6）和各种参数尺度的实验比较表明，Bone 结构可以实现快速收敛和出色的数据拟合，而无需复杂的初始化。例如，在 MetaMathQA 数据集上微调 LLaMA2-7B 并在 GSM8k 和数学基准上进行验证时，Bone 分别获得了 49.36 和 8.8 的微调分数，比 PISSA 分别高出 5.84% 和 1.96%。]]></description>
      <guid>https://arxiv.org/abs/2409.15371</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推动大型语言模型支持贫血的鉴别诊断</title>
      <link>https://arxiv.org/abs/2409.15377</link>
      <description><![CDATA[arXiv:2409.15377v1 公告类型：新
摘要：在实践中，临床医生通过遵循一系列步骤（例如实验室检查、观察或成像）来实现诊断。专家组织编写的指南记录了做出诊断决策的途径，这些指南指导临床医生通过这些步骤序列做出正确的诊断。虽然这些指南有利于遵循医学推理和巩固医学知识，但它们也有一些缺点。由于它们关注的是大多数人群，因此它们往往无法解决患有罕见疾病的患者，而且更新速度慢且成本高，因此不适合快速出现的疾病或新实践。受临床指南的启发，我们的研究旨在开发与临床指南中可以获得的途径类似的途径。我们在一个合成但现实的数据集上测试了三种大型语言模型 (LLM) - 生成预训练 Transformer 4 (GPT-4)、大型语言模型 Meta AI (LLaMA) 和 Mistral - 以对贫血及其亚型进行鉴别诊断。通过使用先进的提示技术来增强决策过程，我们利用这些模型生成了诊断路径。实验结果表明，LLM 在从患者数据中发现临床路径方面具有巨大潜力，其中 GPT-4 在所有进行的实验中表现出最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2409.15377</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Kalahi：为菲律宾人量身定制的草根文化法学硕士评估套件</title>
      <link>https://arxiv.org/abs/2409.15380</link>
      <description><![CDATA[arXiv:2409.15380v1 公告类型：新
摘要：当今的多语言大型语言模型 (LLM) 不一定能为其菲律宾用户提供文化上适当且相关的响应。我们推出了 Kalahi，这是一个由菲律宾母语人士共同创建的文化 LLM 评估套件。它由 150 个高质量、手工制作且细致入微的提示组成，可测试几代与菲律宾共同的文化知识和价值观相关的 LLM。Kalahi 中强大的 LLM 性能表明模型能够生成类似于普通菲律宾人在特定情况下会说或做的响应。我们对具有多语言和菲律宾语支持的 LLM 进行了实验。结果表明，Kalahi 对菲律宾人来说微不足道，但对 LLM 来说却具有挑战性，最好的模型只能正确回答 46.0% 的问题，而菲律宾母语人士的表现为 89.10%。因此，Kalahi 可用于准确可靠地评估法学硕士 (LLM) 中的菲律宾文化代表性。]]></description>
      <guid>https://arxiv.org/abs/2409.15380</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对词性的对抗性攻击：文本到图像生成的实证研究</title>
      <link>https://arxiv.org/abs/2409.15381</link>
      <description><![CDATA[arXiv:2409.15381v1 公告类型：新
摘要：最近的研究表明，文本到图像 (T2I) 模型容易受到对抗性攻击，尤其是文本提示中的名词扰动。在本研究中，我们研究了对抗性攻击对文本提示中不同 POS 标签对 T2I 模型生成的图像的影响。我们创建了一个高质量的数据集，用于真实的 POS 标签标记交换，并执行基于梯度的攻击，以查找误导 T2I 模型生成带有更改标记的图像的对抗性后缀。我们的实证结果表明，攻击成功率 (ASR) 在不同的 POS 标签类别之间差异很大，其中名词、专有名词和形容词最容易受到攻击。我们探索了对抗性后缀的引导作用背后的机制，发现关键标记的数量和内容融合在不同的 POS 标签之间有所不同，而后缀可转移性等特征在各个类别之间是一致的。我们已将我们的实施方案公开发布于 - https://github.com/shahariar-shibli/Adversarial-Attack-on-POS-Tags。]]></description>
      <guid>https://arxiv.org/abs/2409.15381</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解析树引导的 LLM 快速压缩</title>
      <link>https://arxiv.org/abs/2409.15395</link>
      <description><![CDATA[arXiv:2409.15395v1 公告类型：新
摘要：为大型语言模型（LLM）提供丰富的上下文已被证明可以提高各种任务的性能，但由此产生的更长的提示会增加计算成本，并且可能超出LLM的输入限制。最近，一些提示压缩方法被提出，通过使用语言模型生成较短的提示或通过开发计算模型来选择原始提示的重要部分来缩短提示的长度。生成压缩方法会出现幻觉等问题，而选择性压缩方法没有涉及语言规则并且忽略了提示的全局结构。为此，我们提出了一种称为PartPrompt的新型选择性压缩方法。它首先根据语言规则为每个句子获得一棵解析树，并计算解析树中每个节点的局部信息熵。然后根据句子、段落和节的依赖关系等层次结构将这些局部解析树组织成全局树。之后，提出了根向传播和叶向传播来调整全局树上的节点值。最后，开发了一种递归算法来根据调整后的节点值修剪全局树。实验表明，PartPrompt 在各种数据集、指标、压缩率和目标 LLM 推理中都获得了最佳性能。深入的消融研究证实了 PartPrompt 中设计的有效性，其他附加实验也证明了其在压缩提示的连贯性和极长提示场景中的优势。]]></description>
      <guid>https://arxiv.org/abs/2409.15395</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CUTE：衡量法学硕士 (LLM) 对代币的理解</title>
      <link>https://arxiv.org/abs/2409.15452</link>
      <description><![CDATA[arXiv:2409.15452v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种任务上都表现出色。大多数 LLM 将文本拆分为多字符标记，并将它们作为原子单元进行处理，而无需直接访问单个字符。这就提出了一个问题：LLM 可以在多大程度上学习正字法信息？为了回答这个问题，我们提出了一个新的基准 CUTE，它包含一系列旨在测试 LLM 正字法知识的任务。我们在 CUTE 上评估了流行的 LLM，发现它们中的大多数似乎都知道其标记的拼写，但未能有效地使用这些信息来处理文本，这让人怀疑这些知识有多少是可以推广的。]]></description>
      <guid>https://arxiv.org/abs/2409.15452</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语境学习可能无法得出值得信赖的推理：预训练语言模型中的 A-Not-B 错误</title>
      <link>https://arxiv.org/abs/2409.15454</link>
      <description><![CDATA[arXiv:2409.15454v1 公告类型：新
摘要：人工智能的最新进展促成了高性能大型语言模型 (LLM) 的诞生，这些模型可以以类似人类的方式执行任务。然而，LLM 在某些领域仅表现出婴儿水平的认知能力。其中一个领域是 A-Not-B 错误，这是婴儿中常见的现象，尽管条件发生了明显变化，他们仍会重复之前获得奖励的行为。这凸显了他们缺乏抑制控制——即阻止习惯性或冲动反应的能力。在我们的工作中，我们设计了一个类似于 A-Not-B 实验设置的基于文本的多选问答场景，以系统地测试 LLM 的抑制控制能力。我们发现，最先进的 LLM（如 Llama3-8b）在情境学习 (ICL) 方面表现始终良好，但当情境发生细微变化时，推理任务中会出现错误并出现高达 83.3% 的显著下降。这表明 LLM 在这方面仅具有与人类婴儿相当的抑制控制能力，通常无法抑制 ICL 期间先前建立的反应模式。]]></description>
      <guid>https://arxiv.org/abs/2409.15454</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习在对话式问答中何时检索、重写什么以及如何响应</title>
      <link>https://arxiv.org/abs/2409.15515</link>
      <description><![CDATA[arXiv:2409.15515v1 公告类型：新
摘要：增强大型语言模型 (LLM) 的信息检索功能（即检索增强生成 (RAG)）已被证明对知识密集型任务有益。然而，在生成响应时理解用户的上下文搜索意图是对话式问答 (QA) 中一个研究不足的话题。与单轮 QA 相比，这种对话扩展带来了额外的担忧，因为系统更难理解对话上下文并管理多轮检索到的段落。在这项工作中，我们提出了一种方法，使 LLM 能够在给定对话上下文的情况下决定何时在 RAG 设置中检索。当认为有必要进行检索时，LLM 会重写对话以进行段落检索，并在生成响应之前判断返回段落的相关性。在操作上，我们以单轮 SELF-RAG 框架（Asai 等人，2023 年）为基础，并针对对话设置提出了 SELF-multi-RAG。在检索相关段落（通过使用总结的对话上下文）和评估生成的响应质量方面，SELF-multi-RAG 比单轮变体表现出更好的能力。在三个对话 QA 数据集上进行的实验验证了 SELF-multi-RAG 增强的响应生成能力，经人工注释测量，其改进幅度约为 13%。]]></description>
      <guid>https://arxiv.org/abs/2409.15515</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GEM-RAG：用于检索增强生成的图形特征记忆</title>
      <link>https://arxiv.org/abs/2409.15566</link>
      <description><![CDATA[arXiv:2409.15566v1 公告类型：新
摘要：在刺激下形成、检索和推理记忆的能力是一般智能的基石 - 塑造能够学习、适应和直觉洞察的实体。大型语言模型 (LLM) 已证明其在适当的记忆或背景下能够推理并对刺激做出有意义的反应。然而，它们仍然无法最佳地编码、存储和检索记忆 - 这样做的能力将释放它们作为 AI 代理运行的全部能力，并专门研究利基领域。为了解决这个问题，一个有前途的研究领域是检索增强生成 (RAG)，旨在通过为 LLM 提供丰富的上下文示例和信息来增强 LLM。在问答 (QA) 应用程序中，RAG 方法将感兴趣的文本嵌入到块中，并使用文本嵌入检索提示的最相关块。受人类记忆编码和检索的启发，我们旨在通过生成和编码更高级的信息并根据块的实用性对块进行标记以回答问题，从而改进标准 RAG 方法。我们引入了用于检索增强生成的图形特征记忆 (GEM-RAG)。GEM-RAG 的工作原理是使用 LLM 生成的“实用性”问题标记给定文本语料库中的每个文本块，根据文本和实用性问题的相似性将块连接到图中，然后使用记忆图的特征分解来构建更高级别的摘要节点，以捕捉文本的主要主题。我们在两个标准 QA 任务上评估了 GEM-RAG，使用 UnifiedQA 和 GPT-3.5 Turbo 作为 LLM，使用 SBERT 和 OpenAI 的文本编码器，结果表明 GEM-RAG 在这些任务上的表现优于其他最先进的 RAG 方法。我们还讨论了拥有强大的 RAG 系统的意义和未来的发展方向。]]></description>
      <guid>https://arxiv.org/abs/2409.15566</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Bi-LSTM 和注意力机制优化新闻文本分类以实现高效的数据处理</title>
      <link>https://arxiv.org/abs/2409.15576</link>
      <description><![CDATA[arXiv:2409.15576v1 Announce Type: new 
摘要：互联网技术的发展导致新闻信息量急剧增加，从纷繁复杂的信息中筛选出有价值的内容成为亟待解决的问题。针对传统人工分类方法耗时、低效的缺点，本文提出了一种基于深度学习的新闻文本自动分类方案。该方案通过引入先进的机器学习算法，特别是结合双向长短期记忆网络（Bi-LSTM）和注意力机制的优化模型，实现了新闻文本的高效分类与管理。实验结果表明，该方案不仅能显著提高分类的准确率和时效性，还能显著减少人工干预的需要，对于提高新闻行业的信息处理能力，加快信息流动速度具有重要的现实意义。通过对多个常见模型的对比分析，证明了所提方法的有效性和先进性，为今后的新闻文本分类研究奠定了坚实的基础。]]></description>
      <guid>https://arxiv.org/abs/2409.15576</guid>
      <pubDate>Wed, 25 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>