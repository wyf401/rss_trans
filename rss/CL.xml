<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 13 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>SciRIFF：一种增强科学文献语言模型教学的资源</title>
      <link>https://arxiv.org/abs/2406.07835</link>
      <description><![CDATA[arXiv:2406.07835v1 公告类型：新
摘要：我们介绍了 SciRIFF（指令遵循和微调的科学资源），这是一个包含 54 项任务的 137K 指令遵循演示的数据集，涵盖五项基本的科学文献理解能力：信息提取、总结、问答、声明验证和分类。SciRIFF 演示以其长输入上下文、详细的任务规范和复杂的结构化输出而著称。虽然指令遵循资源可用于临床医学和化学等特定领域，但 SciRIFF 是第一个专注于从广泛科学领域的研究文献中提取和合成信息的数据集。为了展示 SciRIFF 的实用性，我们开发了一种样本效率策略，通过对通用领域和 SciRIFF 演示的混合进行额外的微调，来适应科学的通用指令遵循模型。在对九项保留的科学任务进行评估时，我们的模型（称为 SciTulu）在 7B 和 70B 规模上分别比强大的 LLM 基线提高了 28.1% 和 6.5%，同时将一般的指令遵循性能保持在基线的 2% 以内。我们乐观地认为，SciRIFF 将促进 LLM 的开发和评估，以帮助研究人员浏览不断增长的科学文献。我们发布了我们的数据集、模型检查点以及数据处理和评估代码，以支持进一步的研究。]]></description>
      <guid>https://arxiv.org/abs/2406.07835</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:12 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是优秀的统计学家吗？</title>
      <link>https://arxiv.org/abs/2406.07815</link>
      <description><![CDATA[arXiv:2406.07815v1 公告类型：新 
摘要：大型语言模型 (LLM) 在数学、物理和化学等一系列科学任务中表现出了令人印象深刻的能力。尽管取得了成功，但 LLM 在处理复杂统计任务方面的有效性仍然没有得到系统性的充分探索。为了弥补这一差距，我们引入了 StatQA，这是一个专为统计分析任务设计的新基准。StatQA 包含 11,623 个示例，旨在评估 LLM 在专门统计任务中的熟练程度及其适用性评估能力，特别是对于假设检验方法。我们使用各种提示策略对代表性 LLM 进行了系统实验，并表明即使是最先进的模型（如 GPT-4o）也只能达到 64.83% 的最佳性能，这表明有很大的改进空间。值得注意的是，虽然开源 LLM（例如 LLaMA-3）的能力有限，但经过微调的 LLM 表现出了显著的改进，优于所有基于上下文学习的方法（例如 GPT-4o）。此外，我们的比较人类实验突出了 LLM 和人类在错误类型上的鲜明对比：LLM 主要犯适用性错误，而人类主要犯统计任务混淆错误。这种差异凸显了不同的熟练和不足领域，表明将 LLM 和人类专业知识结合起来可以产生互补的优势，从而引发对它们协作潜力的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2406.07815</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:11 GMT</pubDate>
    </item>
    <item>
      <title>PRoDeliberation：用于端到端口语理解的并行稳健审议</title>
      <link>https://arxiv.org/abs/2406.07823</link>
      <description><![CDATA[arXiv:2406.07823v1 公告类型：新
摘要：口语理解 (SLU) 是语音助手的重要组成部分；它包括将语音转换为语义解析以执行任务。先前的研究已经探索了端到端模型，以使用 Deliberation 提高 SLU 模型的质量和稳健性，但这些模型仍然是自回归的，导致更高的延迟。在这项工作中，我们引入了 PRoDeliberation，这是一种利用基于联结主义时间分类的解码策略以及去噪目标来训练稳健的非自回归审议模型的新方法。我们表明，PRoDeliberation 实现了并行解码的延迟减少（比自回归模型提高了 2-10 倍），同时保留了纠正自回归审议系统的自动语音识别 (ASR) 错误转录的能力。我们进一步表明，去噪训练的设计使 PRoDeliberation 能够克服小型 ASR 设备的局限性，并对系统每个组件的必要性进行了分析。]]></description>
      <guid>https://arxiv.org/abs/2406.07823</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:11 GMT</pubDate>
    </item>
    <item>
      <title>PolySpeech：探索统一的多任务语音模型，以实现与单任务模型的竞争力</title>
      <link>https://arxiv.org/abs/2406.07801</link>
      <description><![CDATA[arXiv:2406.07801v1 公告类型：新
摘要：最近，人们尝试将各种语音处理任务集成到一个统一的模型中。然而，之前很少有研究直接证明多任务语音模型中不同任务的联合优化对各个任务的性能有积极影响。在本文中，我们提出了一个多任务语音模型——PolySpeech，它支持语音识别、语音合成和两个语音分类任务。PolySpeech以多模态语言模型为核心结构，以语义表示作为语音输入。我们为PolySpeech引入了语义语音嵌入标记和语音重建方法，从而能够为任何给定的说话者高效生成高质量的语音。与单任务模型相比，PolySpeech在各种任务中都表现出竞争力。在我们的实验中，多任务优化实现了与单任务优化相当的性能，并且对特定任务尤其有益。]]></description>
      <guid>https://arxiv.org/abs/2406.07801</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:10 GMT</pubDate>
    </item>
    <item>
      <title>是连续的，还是离散的，这些都是问题</title>
      <link>https://arxiv.org/abs/2406.07812</link>
      <description><![CDATA[arXiv:2406.07812v1 公告类型：新
摘要：最近，二进制表示被提出作为一种介于连续表示和离散表示之间的新表示。它在用于替换连续输入向量时表现出相当大的信息保存能力。在本文中，我们研究了将其进一步引入输出端的可行性，旨在让模型输出二进制标签。为了在输出端保留结构信息和标签信息，我们将之前的对比哈希方法扩展为结构化对比哈希。更具体地说，我们将 CKY 从标签级升级到位级，定义一个具有跨度边际概率的新相似度函数，并引入一个具有精心设计的实例选择策略的新对比损失函数。我们的模型在各种结构化预测任务上都取得了有竞争力的表现，并表明二进制表示可以被认为是一种新的表示，它进一步弥合了深度学习的连续性和自然语言的离散内在属性之间的差距。]]></description>
      <guid>https://arxiv.org/abs/2406.07812</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:10 GMT</pubDate>
    </item>
    <item>
      <title>评判法官：法学硕士成对比较评估中的位置偏见系统调查</title>
      <link>https://arxiv.org/abs/2406.07791</link>
      <description><![CDATA[arXiv:2406.07791v1 公告类型：新
摘要：LLM-as-a-Judge 为各种任务中的人类法官提供了一种有希望的替代方案，但固有的偏见，尤其是位置偏见——基于答案在提示中的位置而系统地偏好答案——损害了它的有效性。我们的研究通过开发一个框架来系统地研究和量化位置偏见，使用重复一致性、位置一致性和位置公平性等指标来调查这个问题。我们对来自 MTBench 和 DevBench 基准的 22 个任务中的 9 个评判模型和近 40 个答案生成模型进行了实验，生成了大约 80,000 个评估实例。这项综合评估揭示了不同评判者和任务之间的偏见存在显著差异。尽管 GPT-4 通常在位置一致性和公平性方面表现出色，但一些更具成本效益的模型在特定任务中的表现相当甚至更好，突出了一致性、公平性和成本之间的基本权衡。我们的结果还表明，在重复过程中判断具有很高的一致性，证实了位置偏见不是由于随机变化造成的。这项研究通过引入理解立场偏见的新概念并提供多维评估框架，为该领域做出了重大贡献。这些见解指导了最佳评判模型的选择，增强了基准设计，并为未来研究有效的消除偏见策略奠定了基础，最终提高了法学硕士评估员的可靠性。]]></description>
      <guid>https://arxiv.org/abs/2406.07791</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:09 GMT</pubDate>
    </item>
    <item>
      <title>间接请求：通过合成间接用户请求使面向任务的对话数据集更加自然</title>
      <link>https://arxiv.org/abs/2406.07794</link>
      <description><![CDATA[arXiv:2406.07794v1 公告类型：新
摘要：现有的面向任务的对话基准语料库要么使用“机器与机器对话”的方法，要么通过向众包工作者提供基于模板的目标描述来收集。然而，这些方法产生的话语通常与自然的人类对话有显著不同，在自然的人类对话中，人们通常以间接的方式表达他们的偏好，例如通过闲聊。我们将此类话语称为间接用户请求 (IUR)。理解此类话语需要听众具备相当多的世界知识和推理能力。我们的研究引入了一种基于 LLM 的管道，可以自动为给定领域生成逼真的高质量 IUR，最终目标是支持面向任务的对话系统的自然语言理解 (NLU) 和对话状态跟踪 (DST) 研究。我们的研究结果表明，虽然 GPT-3.5 和 GPT-4 等大型 LLM 可以生成高质量的 IUR，但使用较小的模型实现类似的质量更具挑战性。我们发布了 IndirectRequests，这是一个 IUR 数据集，它超越了最初的 Schema-Guided Dialog (SGD) 数据集，因为它为测试 NLU 和 DST 模型的“野外”性能提供了一个具有挑战性的测试平台。]]></description>
      <guid>https://arxiv.org/abs/2406.07794</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:09 GMT</pubDate>
    </item>
    <item>
      <title>UICoder：通过自动反馈微调大型语言模型以生成用户界面代码</title>
      <link>https://arxiv.org/abs/2406.07739</link>
      <description><![CDATA[arXiv:2406.07739v1 公告类型：新
摘要：大型语言模型 (LLM) 难以一致地生成可编译并生成视觉相关设计的 UI 代码。现有的改进生成的方法依赖于昂贵的人工反馈或提炼专有模型。在本文中，我们探讨了使用自动反馈（编译器和多模式模型）来指导 LLM 生成高质量的 UI 代码。我们的方法从现有的 LLM 开始，通过使用原始模型自行生成大型合成数据集，应用自动化工具积极过滤、评分和重复数据删除，从而迭代生成改进的模型，使其成为更高质量的数据集。通过对这个精炼数据集进行微调，原始 LLM 得到了改进。我们将我们的方法应用于几个开源 LLM，并将得到的性能与具有自动指标和人类偏好的基线模型进行了比较。我们的评估表明，得到的模型优于所有其他可下载的基线，并且接近更大的专有模型的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.07739</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:08 GMT</pubDate>
    </item>
    <item>
      <title>LT4SG@SMM4H24：使用预训练语言模型对儿童健康结果数字流行病学推文进行分类</title>
      <link>https://arxiv.org/abs/2406.07759</link>
      <description><![CDATA[arXiv:2406.07759v1 公告类型：新
摘要：本文介绍了我们针对 SMM4H24 共享任务 5 的方法，该任务针对报告儿童疾病的英文推文进行二元分类。我们的第一种方法涉及微调单个 RoBERTa-large 模型，而第二种方法则需要集成三个微调的 BERTweet-large 模型的结果。我们证明，尽管两种方法在验证数据上表现出相同的性能，但 BERTweet-large 集成在测试数据上表现出色。我们表现最佳的系统在测试数据上的 F1 得分为 0.938，比基准分类器高出 1.18%。]]></description>
      <guid>https://arxiv.org/abs/2406.07759</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:08 GMT</pubDate>
    </item>
    <item>
      <title>真实采样：通过渐近熵提高开放式生成的真实性和多样性</title>
      <link>https://arxiv.org/abs/2406.07735</link>
      <description><![CDATA[arXiv:2406.07735v1 公告类型：新
摘要：大型语言模型 (LLM) 的解码方法通常在确保事实性和保持多样性之间难以权衡。例如，核心 (top-p) 采样中的较高 p 阈值会增加多样性但会降低事实性，反之亦然。在本文中，我们提出了 REAL（渐近线残差熵）采样，这是一种通过预测 $p$ 的自适应阈值来实现比核心采样更好的事实性和多样性的解码方法。具体而言，REAL 采样预测 LLM 产生幻觉的逐步可能性，并在 LLM 可能产生幻觉时降低 p 阈值。否则，REAL 采样会增加 p 阈值以增强多样性。为了在无监督的情况下预测分步幻觉可能性，我们构建了一个 Token 级幻觉预测 (THF) 模型，通过从一系列不同大小的 LLM 中推断下一个 token 的熵来预测下一个 token 的渐近熵（即固有不确定性）。如果 LLM 的熵高于渐近熵（即 LLM 的不确定性比它应该的更大），THF 模型会预测较高的幻觉风险，从而导致 REAL 采样中的 p 阈值较低。在 FactualityPrompts 基准中，我们证明基于 70M THF 模型的 REAL 采样可以同时显著提高 7B LLM 的事实性和多样性，这可以通过基于检索的指标和人工评估来判断。与对比解码相结合后，REAL 采样优于 9 种采样方法，并且生成的文本比贪婪采样更符合事实，比 $p=0.5$ 的核采样更具多样性。此外，预测的渐近熵对于幻觉检测任务也是一个有用的无监督信号。]]></description>
      <guid>https://arxiv.org/abs/2406.07735</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:07 GMT</pubDate>
    </item>
    <item>
      <title>MultiPragEval：大型语言模型的多语言语用评估</title>
      <link>https://arxiv.org/abs/2406.07736</link>
      <description><![CDATA[arXiv:2406.07736v1 公告类型：新
摘要：随着 LLM 能力的扩展，对它们的评估变得日益重要，不再仅限于基础知识评估，而是关注更高级的语言理解。本研究介绍了 MultiPragEval，这是一个强大的测试套件，旨在对英语、德语、韩语和中文的 LLM 进行多语言语用评估。MultiPragEval 包含 1200 个问题单元，根据 Grice 的合作原则及其四个对话准则进行分类，可以深入评估 LLM 的语境意识及其推断隐含意义的能力。我们的研究结果表明，Claude3-Opus 在所有测试语言中的表现都明显优于其他模型，在该领域建立了最先进的水平。在开源模型中，Solar-10.7B 和 Qwen1.5-14B 成为强劲的竞争对手。这项研究不仅引领了语用推理法学硕士的多语言评估，而且还为人工智能系统高级语言理解所需的细微能力提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2406.07736</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:07 GMT</pubDate>
    </item>
    <item>
      <title>教育中的 Transformer 模型：使用 AraBART、MT5、AraT5 和 mBART 总结科学教科书</title>
      <link>https://arxiv.org/abs/2406.07692</link>
      <description><![CDATA[arXiv:2406.07692v1 公告类型：新
摘要：最近，随着技术领域的快速发展和互联网上可用的文本数量的增加，开发有效的工具来处理和理解文本以总结内容而不丢失信息的基本本质已变得迫在眉睫。面对这一挑战，我们开发了一种针对阿拉伯语教科书的高级文本摘要系统。该系统依靠 MT5、AraBART、AraT5 和 mBART50 等现代自然语言处理模型，评估并提取巴勒斯坦课程 11 年级和 12 年级生物学教科书中最重要的句子，使学生和教师能够获得准确而有用的摘要，帮助他们轻松理解内容。我们使用 Rouge 指标来评估训练模型的性能。此外，教育教科书创作专家会评估训练模型的输出。这种方法旨在确定最佳解决方案并明确需要改进的领域。本研究为总结阿拉伯语文本提供了一种解决方案。它提供了可以为理解和生成阿拉伯语的技术的研究和开发开辟新视野的结果，从而丰富了该领域。此外，它通过创建和编纂教科书文本以及构建数据集，为阿拉伯语文本领域做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2406.07692</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:06 GMT</pubDate>
    </item>
    <item>
      <title>语音表征的可持续自监督学习</title>
      <link>https://arxiv.org/abs/2406.07696</link>
      <description><![CDATA[arXiv:2406.07696v1 公告类型：新
摘要：可持续人工智能专注于数据、硬件和算法，使机器学习模型更加环保。特别是，用于语音表示的机器学习模型计算成本高昂，由于其高能耗而引发环境问题。因此，我们提出了一种可持续的自监督模型来学习语音表示，结合神经层优化和训练以降低计算成本。所提出的模型比资源高效的基线有所改进，减少了内存使用量和计算成本估算。它使用单个 GPU 在不到一天的时间内进行预训练。最重要的是，它提高了下游任务评估中基线的错误率性能。与大型语音表示方法相比，内存使用量减少了一个数量级，而计算成本的降低几乎提高了三个数量级。]]></description>
      <guid>https://arxiv.org/abs/2406.07696</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:06 GMT</pubDate>
    </item>
    <item>
      <title>标记和纠正：纠正语音识别错误的高精度后期编辑方法</title>
      <link>https://arxiv.org/abs/2406.07589</link>
      <description><![CDATA[arXiv:2406.07589v1 公告类型：新
摘要：本文提出了一种通过后期编辑纠正语音识别错误问题的新方法。它包括使用神经序列标记器学习如何逐字纠正 ASR（自动语音识别）假设，以及应用标记器返回的更正的校正器模块。所提出的解决方案适用于任何 ASR 系统，无论其架构如何，并提供对正在纠正的错误的高精度控制。这在生产环境中尤其重要，因为避免纠错模型引入新错误可能比整体结果的净收益更重要。结果表明，所提出的纠错模型的性能与以前的方法相当，同时需要更少的资源来训练，这使其适用于工业应用，其中推理延迟和训练时间都是限制使用其他技术的关键因素。]]></description>
      <guid>https://arxiv.org/abs/2406.07589</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:05 GMT</pubDate>
    </item>
    <item>
      <title>脱离上下文的提示可提高大型语言模型预测的公平性和稳健性</title>
      <link>https://arxiv.org/abs/2406.07685</link>
      <description><![CDATA[arXiv:2406.07685v1 公告类型：新
摘要：前沿大型语言模型 (LLM) 越来越多地被用于高风险决策。另一方面，这些模型仍然不断做出与用户或社会期望相矛盾的预测，例如产生幻觉或歧视。因此，我们必须制定测试时间策略来提高它们的可信度。受先前工作的启发，我们利用因果关系作为工具来正式编码 LLM 中可信度的两个方面：公平性和稳健性。从这个角度来看，现有的测试时间解决方案明确指示模型公平或稳健，隐含地依赖于 LLM 的因果推理能力。在这项工作中，我们探索了相反的方法。我们不是明确要求 LLM 具有可信度，而是设计提示来编码底层的因果推理算法，通过构造，该算法将产生更可信的预测。具体来说，我们提出使用脱离上下文的提示作为测试时间解决方案，以促进 LLM 的公平性和稳健性。脱离上下文的提示利用用户对任务因果模型的先验知识来应用（随机）反事实转换并提高模型的可信度。从经验上讲，我们表明脱离上下文的提示在五个不同的基准数据集上持续提高了前沿 LLM 的公平性和稳健性，而无需额外的数据、微调或预训练。]]></description>
      <guid>https://arxiv.org/abs/2406.07685</guid>
      <pubDate>Thu, 13 Jun 2024 06:19:05 GMT</pubDate>
    </item>
    </channel>
</rss>