<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 09 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>EVA-Score：通过提取和验证评估长篇摘要的信息量</title>
      <link>https://arxiv.org/abs/2407.04969</link>
      <description><![CDATA[arXiv:2407.04969v1 公告类型：新
摘要：摘要是自然语言处理（NLP）中的一项基本任务，自从 GPT-4 和 Claude 等大型语言模型（LLM）问世以来，人们越来越关注长格式摘要，其输入序列更长，意味着包含更多信息。
当前的评估指标要么使用基于相似度的指标，如 ROUGE 和 BERTScore，这些指标依赖于相似度而没有考虑信息量，要么使用基于 LLM 的指标，缺乏对信息丰富度的定量分析，而且相当主观。
在本文中，我们提出了一种新的评估指标 EVA-Score，它结合使用原子事实链生成和文档级关系提取来自动计算信息量并给出一个确定的数字作为信息分数。实验结果表明，我们的指标与人类表现出最佳相关性。我们还从信息角度全面重新评估了 LLM 在长篇摘要方面的表现，预测了未来使用 LLM 进行长篇摘要的方式。]]></description>
      <guid>https://arxiv.org/abs/2407.04969</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:32 GMT</pubDate>
    </item>
    <item>
      <title>TRACE：使用 LLM 中的对比嵌入进行基于变换器的归因</title>
      <link>https://arxiv.org/abs/2407.04981</link>
      <description><![CDATA[arXiv:2407.04981v1 公告类型：新
摘要：大型语言模型 (LLM) 的快速发展代表了自然语言理解和生成的重大飞跃。然而，伴随着这些进步而来的是与 LLM 响应的问责制和透明度相关的重大挑战。可靠的来源归因对于遵守严格的法律和监管标准至关重要，包括《通用数据保护条例》规定的标准。尽管在计算机视觉领域中，来源归因的方法已经很成熟，但强大的归因框架在自然语言处理中的应用仍未得到充分探索。为了弥补这一差距，我们提出了一种新颖且多功能的基于 TRansformer 的使用对比嵌入的归因框架，称为 TRACE，它特别利用对比学习进行来源归因。我们进行了广泛的实证评估，以证明 TRACE 在各种环境中的性能和效率，并表明 TRACE 显着提高了准确归因来源的能力，使其成为增强 LLM 可靠性和可信度的宝贵工具。]]></description>
      <guid>https://arxiv.org/abs/2407.04981</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:32 GMT</pubDate>
    </item>
    <item>
      <title>使用视觉语言模型进行地理定位的细粒度隐私控制</title>
      <link>https://arxiv.org/abs/2407.04952</link>
      <description><![CDATA[arXiv:2407.04952v1 公告类型：新 
摘要：视觉语言模型 (VLM) 在回答信息搜索问题的能力方面正在迅速进步。由于这些模型广泛应用于消费者应用中，它们可能会因识别照片中的人物、对图像进行地理定位等新兴能力而导致新的隐私风险。正如我们所展示的，令人惊讶的是，当前的开源和专有 VLM 是非常强大的图像地理定位器，使使用 VLM 进行广泛的地理定位成为一个直接的隐私风险，而不仅仅是理论上的未来问题。作为应对这一挑战的第一步，我们开发了一个新的基准 GPTGeoChat，以测试 VLM 调节与用户进行地理定位对话的能力。我们收集了内部注释者和 GPT-4v 之间的一组 1,000 个图像地理定位对话，这些对话都以每次转弯时显示的位置信息粒度进行注释。使用这个新数据集，我们通过确定何时泄露了过多的位置信息来评估各种 VLM 调节 GPT-4v 地理位置对话的能力。我们发现，在识别国家或城市级别的泄露位置信息时，自定义微调模型的表现与基于提示的 API 模型相当；然而，似乎需要对监督数据进行微调才能准确调节更细的粒度，例如餐厅或建筑物的名称。]]></description>
      <guid>https://arxiv.org/abs/2407.04952</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:31 GMT</pubDate>
    </item>
    <item>
      <title>超越困惑：LLM 压缩的多维安全性评估</title>
      <link>https://arxiv.org/abs/2407.04965</link>
      <description><![CDATA[arXiv:2407.04965v1 公告类型：新
摘要：借助最近的模型压缩技术，大型语言模型 (LLM) 越来越多地部署在现实世界场景中。这种本地部署的势头意味着压缩 LLM 的使用将广泛影响大量人群。然而，先前的分析工作通常优先考虑保留困惑度，这与训练损失直接类似。压缩方法对模型行为的其他关键方面（特别是安全性）的影响仍然需要系统评估。为此，我们研究了模型压缩对四个维度的影响：1）退化危害，即生成中的偏见和毒性；2）表征危害，即判别任务中的偏见；3）方言偏见；4）语言建模和下游任务性能。我们涵盖了广泛的 LLM 压缩技术，包括结构化修剪、非/半结构化修剪和量化。我们的分析表明压缩会导致意想不到的后果。虽然压缩可能会无意中弥补 LLM 的退化危害，但它仍然可能在表征危害轴上加剧。此外，随着压缩率的增加，对不同的受保护组的影响也不同。最后，不同的压缩方法对安全性的影响截然不同，例如，量化大多保留偏差，而剪枝则迅速退化。我们的研究结果强调了将安全评估整合到压缩 LLM 的开发中以确保其在实际应用中的可靠性的重要性。我们的完整结果可在此处查看：\url{https://github.com/zhichaoxu-shufe/Beyond-Perplexity-Compression-Safety-Eval}]]></description>
      <guid>https://arxiv.org/abs/2407.04965</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:31 GMT</pubDate>
    </item>
    <item>
      <title>MMSci：用于博士级科学理解的多模态多学科数据集</title>
      <link>https://arxiv.org/abs/2407.04903</link>
      <description><![CDATA[arXiv:2407.04903v1 公告类型：新
摘要：大型语言模型 (LLM) 和大型多模态模型 (LMM) 的快速发展提高了对能够理解科学文章和数字的基于 AI 的科学助手的需求。尽管取得了进展，但在评估模型对专业、研究生级甚至博士级科学内容的理解方面仍然存在很大差距。当前的数据集和基准主要关注相对简单的科学任务和图形，缺乏对各种高级科学学科的全面评估。为了弥补这一差距，我们从《自然通讯》期刊上发表的开放获取科学文章中收集了一个多模态、多学科的数据集。该数据集涵盖 72 个科学学科，确保了多样性和质量。我们创建了具有各种任务和设置的基准，以全面评估 LMM 理解科学图形和内容的能力。我们的评估表明，这些任务极具挑战性：许多开源模型都遇到了很大困难，甚至 GPT-4V 和 GPT-4o 也面临困难。我们还探索了通过构建视觉指令跟踪数据将我们的数据集用作训练资源，从而使 7B LLaVA 模型在我们的基准上实现与 GPT-4V/o 相当的性能。此外，我们研究了将交错的文章文本和图片用于预训练 LMM 的情况，从而改进了材料生成任务。源数据集（包括文章、图片、构建的基准和视觉指令跟踪数据）都是开源的。]]></description>
      <guid>https://arxiv.org/abs/2407.04903</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:30 GMT</pubDate>
    </item>
    <item>
      <title>NADI 2024：第五届细微差别阿拉伯语方言识别共享任务</title>
      <link>https://arxiv.org/abs/2407.04910</link>
      <description><![CDATA[arXiv:2407.04910v1 公告类型：新
摘要：我们描述了第五次细微差别阿拉伯方言识别共享任务 (NADI 2024) 的发现。NADI 的目标是通过提供指导、数据集、建模机会和标准化评估条件来帮助推进 SoTA 阿拉伯语 NLP，使研究人员能够在预先指定的任务上进行协作竞争。NADI 2024 的目标是将方言识别作为多标签任务 (子任务~1)、阿拉伯语方言级别的识别 (子任务~2) 和方言到 MSA 机器翻译 (子任务~3)。共有 51 个独特的团队注册了共享任务，其中 12 个团队参与了（测试阶段有 76 份有效提交）。其中，三支队伍参加了子任务~1，三支队伍参加了子任务~2，八支队伍参加了子任务~3。获胜团队在子任务 1 上分别取得了 50.57 F\textsubscript{1}、子任务 2 上 0.1403 RMSE 和子任务 3 上 20.44 BLEU。结果表明，方言识别和机器翻译等阿拉伯语方言处理任务仍然具有挑战性。我们描述了参赛团队采用的方法，并简要介绍了 NADI 的前景。]]></description>
      <guid>https://arxiv.org/abs/2407.04910</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:30 GMT</pubDate>
    </item>
    <item>
      <title>通过深度强化学习用文本和表格进行问答</title>
      <link>https://arxiv.org/abs/2407.04858</link>
      <description><![CDATA[arXiv:2407.04858v1 公告类型：新
摘要：本文提出了一种新颖的架构，用于生成需要来自文本和表格的信息的开放域问题的多跳答案，使用开放表格和文本问答数据集进行验证和训练。在这种情况下生成答案的最常见方法之一是按顺序检索信息，其中选定的数据有助于搜索下一个数据。由于不同的模型在这种顺序信息搜索中调用时可能具有不同的行为，因此挑战在于如何在每个步骤中选择模型。我们的架构采用强化学习来按顺序在不同的最先进的工具之间进行选择，直到最终生成所需的答案。该系统的 F1 分数为 19.03，与文献中的迭代系统相当。]]></description>
      <guid>https://arxiv.org/abs/2407.04858</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:29 GMT</pubDate>
    </item>
    <item>
      <title>自动化风险投资：使用 LLM 支持的细分、特征工程和自动标记技术进行创始人评估</title>
      <link>https://arxiv.org/abs/2407.04885</link>
      <description><![CDATA[arXiv:2407.04885v1 公告类型：新
摘要：本研究探讨了大型语言模型 (LLM) 在风险投资 (VC) 决策中的应用，重点是根据创始人特征预测初创企业的成功。我们利用 LLM 提示技术（如思路链）从有限的数据中生成特征，然后通过统计和机器学习提取见解。我们的结果揭示了某些创始人特征与成功之间的潜在关系，并证明了这些特征在预测中的有效性。这种将 ML 技术和 LLM 相结合的框架在改善初创企业成功预测方面具有巨大潜力，对于寻求优化投资策略的 VC 公司具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2407.04885</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:29 GMT</pubDate>
    </item>
    <item>
      <title>随机程序的几何和同源性的统计研究</title>
      <link>https://arxiv.org/abs/2407.04854</link>
      <description><![CDATA[arXiv:2407.04854v1 公告类型：新
摘要：借助 Meta 的 Llama 和 openAI 的 chatGPT 等工具，人工智能支持的编程取得了巨大的飞跃。这些是程序随机源的示例，已经极大地影响了我们编写代码和教授编程的方式。如果我们将此类模型的输入视为随机源，那么一个自然的问题是，输入和输出分布之间、chatGPT 提示和结果程序之间的关系是什么？
在本文中，我们将展示如何使用程序语法树之间的树编辑距离在几何和拓扑上描述从 chatGPT 生成的随机 Python 程序之间的关系，而无需对底层空间进行显式建模。研究度量空间中高维样本的一种流行方法是使用低维嵌入，例如使用多维缩放。这种方法意味着误差取决于嵌入空间的数据和维度。在本文中，我们建议将此类投影方法限制为纯粹的可视化目的，而是使用几何汇总统计、空间点统计方法和拓扑数据分析来表征不依赖于嵌入近似的随机程序的配置。为了证明它们的实用性，我们在一个与图像处理相关的简单问题上比较了两个公开可用的模型：ChatGPT-4 和 TinyLlama。
应用领域包括了解如何提出问题以获得有用的程序；衡量给定的大型语言模型回答的一致性；以及作为编程助手比较不同的大型语言模型。最后，我们推测我们的方法将来可能会为编程语言的结构提供新的见解。]]></description>
      <guid>https://arxiv.org/abs/2407.04854</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:28 GMT</pubDate>
    </item>
    <item>
      <title>增强提取摘要的连贯性：数据集和 LLM 实验</title>
      <link>https://arxiv.org/abs/2407.04855</link>
      <description><![CDATA[arXiv:2407.04855v1 公告类型：新 
摘要：提取摘要在自然语言处理中起着关键作用，因为它在有效总结各种内容的同时还能忠实于原始内容。尽管大型语言模型 (LLM) 在提取摘要方面取得了重大进展，但这些摘要经常表现出不连贯性。连贯摘要的一个重要方面是它对目标用户的可读性。虽然已经提出了许多用于创建连贯提取摘要的数据集和基准，但目前它们都没有结合用户意图来提高提取摘要的连贯性。受此启发，我们提出了一个系统创建的人工注释数据集，该数据集由五个公开数据集的连贯摘要和自然语言用户反馈组成，为如何提高提取摘要的连贯性提供了宝贵的见解。我们利用此数据集通过监督微调和自然语言人工反馈来对齐 LLM，以增强其生成的摘要的连贯性。对 Falcon-40B 和 Llama-2-13B 进行的初步实验表明，在生成连贯摘要方面，性能显著提高（~10% Rouge-L）。我们进一步利用人工反馈对 FLAN-T5 等指令调整模型的结果进行基准测试，结果得出了一些有趣的发现。数据和源代码可在 https://github.com/Mihir3009/Extract-AI 上找到。]]></description>
      <guid>https://arxiv.org/abs/2407.04855</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:28 GMT</pubDate>
    </item>
    <item>
      <title>将结构化情绪分析重新视为潜在依赖图解析</title>
      <link>https://arxiv.org/abs/2407.04801</link>
      <description><![CDATA[arXiv:2407.04801v1 公告类型：新
摘要：结构化情感分析（SSA）在先前的研究中被视为双词汇依赖图解析问题。已经提出了多种公式来构建该图，这些公式有几个内在的缺点：（1）忽略了跨度的内部结构，因此仅使用跨度的边界标记进行关系预测和跨度识别，从而阻碍了模型的表达能力；（2）长跨度在 SSA 数据集中占有相当大的比例，这进一步加剧了内部结构被忽视的问题。在本文中，我们将 SSA 任务视为部分观察的依赖树上的依赖解析任务，将没有确定树注释的扁平跨度视为潜在子树以考虑跨度的内部结构。我们提出了一种两阶段解析方法，并利用 TreeCRFs 和一种新颖的约束内部算法来显式地建模潜在结构，该方法还利用联合评分图弧和有头跨度进行全局优化和推理。在五个基准数据集上进行的大量实验结果表明，我们的方法比所有以前的双词汇方法都表现得更好，达到了新的最佳水平。]]></description>
      <guid>https://arxiv.org/abs/2407.04801</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:27 GMT</pubDate>
    </item>
    <item>
      <title>联想循环记忆变换器</title>
      <link>https://arxiv.org/abs/2407.04841</link>
      <description><![CDATA[arXiv:2407.04841v1 公告类型：新
摘要：本文解决了为非常长的序列创建神经架构的挑战，该序列需要在每个时间步骤中花费恒定的时间来处理新信息。我们的方法，联想循环记忆变换器 (ARMT)，基于变换器自注意力用于局部上下文和段级循环用于存储分布在长上下文中的任务特定信息。我们证明，ARMT 在联想检索任务中优于现有的替代方案，并通过回答超过 5000 万个标记的单一事实问题，以 79.9% 的准确率在最近的 BABILong 多任务长上下文基准中创下了新的性能记录。训练和评估的源代码可在 github 上找到。]]></description>
      <guid>https://arxiv.org/abs/2407.04841</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:27 GMT</pubDate>
    </item>
    <item>
      <title>重新调整：通过递归调整克服大型语言模型的组合性限制</title>
      <link>https://arxiv.org/abs/2407.04787</link>
      <description><![CDATA[arXiv:2407.04787v1 公告类型：新
摘要：我们提出了一种大型语言模型解决组合任务的新方法。尽管大型语言模型在传统语言理解任务上表现出色，但它们在解决组合任务方面却举步维艰，因为解决方案取决于解决同一问题的较小实例。我们提出了一种自然的方法来递归解决组合任务。我们的方法，即重新调整，调整模型以将问题分解为子问题，解决这些子问题，并合并结果。我们表明，我们的方法显著提高了三个代表性组合任务的模型性能：整数加法、动态规划和奇偶校验。与保持解决问题的中间步骤的最先进的方法相比，重新调整实现了更高的准确率，并且更节省 GPU 内存。]]></description>
      <guid>https://arxiv.org/abs/2407.04787</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:26 GMT</pubDate>
    </item>
    <item>
      <title>Toucan：150 个非洲语言对的多对多翻译</title>
      <link>https://arxiv.org/abs/2407.04796</link>
      <description><![CDATA[arXiv:2407.04796v1 公告类型：新
摘要：我们通过引入一系列旨在改进低资源语言机器翻译 (MT) 的资源来解决自然语言处理 (NLP) 中的一个显著差距，特别关注非洲语言。首先，我们引入了两个语言模型 (LM)，Cheetah-1.2B 和 Cheetah-3.7B，分别具有 12 亿和 37 亿个参数。接下来，我们对上述模型进行微调以创建 toucan，这是一个以非洲为中心的机器翻译模型，旨在支持 156 种非洲语言对。为了评估 Toucan，我们精心开发了一个广泛的机器翻译基准，称为 AfroLingu-MT，专门用于评估机器翻译。Toucan 的表现明显优于其他模型，展示了其在非洲语言 MT 方面的卓越表现。最后，我们训练了一个新模型 spBLEU-1K，以增强翻译评估指标，涵盖 1K 种语言，包括 614 种非洲语言。这项工作旨在推动 NLP 领域的发展，促进跨文化理解和知识交流，特别是在非洲等语言资源有限的地区。Toucan 项目的 GitHub 存储库位于 https://github.com/UBC-NLP/Toucan。]]></description>
      <guid>https://arxiv.org/abs/2407.04796</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:26 GMT</pubDate>
    </item>
    <item>
      <title>AgriLLM：利用 Transformer 解答农民疑问</title>
      <link>https://arxiv.org/abs/2407.04721</link>
      <description><![CDATA[arXiv:2407.04721v1 公告类型：新
摘要：农业对全球生存至关重要，由于缺乏有组织的领域专家，农业需要创新解决方案，特别是在许多农民贫困且无法负担专家咨询费用的发展中国家。农民帮助热线等计划在这些国家发挥着至关重要的作用，但高运营成本等挑战依然存在。自动查询解决可以减轻传统呼叫中心的负担，为农民提供即时且与上下文相关的信息。农业与人工智能 (AI) 的融合为赋予农民权力和弥合信息差距提供了变革机会。像 transformers 这样的语言模型是人工智能的后起之秀，具有卓越的语言理解能力，使其成为解决农业信息差距的理想选择。这项工作探索并展示了大型语言模型 (LLM) 在自动为农业农民解决查询方面的变革潜力，利用他们在解读自然语言和理解上下文方面的专业知识。我们的研究利用在印度收集的大量真实农民查询数据集的一个子集，重点关注来自泰米尔纳德邦的约 400 万条查询，涉及各个行业、季节性作物和查询类型。]]></description>
      <guid>https://arxiv.org/abs/2407.04721</guid>
      <pubDate>Wed, 10 Jul 2024 03:16:25 GMT</pubDate>
    </item>
    </channel>
</rss>