<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 11 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>了解新闻文章对市场指数走势的影响：以 Nifty 50 为例</title>
      <link>https://arxiv.org/abs/2412.06794</link>
      <description><![CDATA[arXiv:2412.06794v1 公告类型：新
摘要：最近，有几项研究使用不同的方法预测股票价格。新闻和推文的情绪分析以及它们与股价变动之间的关系已经被探索过。但是，当我们谈论新闻时，可能会有多个主题，例如政治、市场、体育等。据观察，大多数先前的分析仅处理与特定股票价格相关的新闻或评论，或者研究人员仅处理整体情绪得分。然而，不同的主题很可能对股价或指数的变动产生不同程度的影响。当前的研究重点是通过分析 Nifty 50 指数相对于与体育、政治、市场等不同主题相关的新闻项目的情绪的变动来弥合这一差距。研究发现，不同其他主题的新闻项目的情绪得分也对指数的变动产生重大影响。]]></description>
      <guid>https://arxiv.org/abs/2412.06794</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>您所需要的只是指导：大型语言模型中的温度引导推理</title>
      <link>https://arxiv.org/abs/2412.06822</link>
      <description><![CDATA[arXiv:2412.06822v1 公告类型：新
摘要：我们提出了 Quasar-1，这是一种新颖的架构，它通过令牌温度机制 (TTM) 和引导思维序列 (GSoT) 将温度引导推理引入大型语言模型。我们的方法利用了热令牌和冷令牌的概念，其中热令牌根据其上下文相关性进行优先排序，而冷令牌提供补充信息。与传统的思维链方法相比，这种令牌重要性的动态调节使模型能够实现卓越的逻辑推理能力。通过严格的数学分析，我们证明了我们的温度引导注意力机制以指数保证收敛到最佳推理路径。实证结果表明，在广泛的任务中，推理准确性和计算效率都有显着提高，使高级 AI 推理可用于更广泛的应用。]]></description>
      <guid>https://arxiv.org/abs/2412.06822</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多代理系统增强 LLM 在放射学报告中的印象生成</title>
      <link>https://arxiv.org/abs/2412.06828</link>
      <description><![CDATA[arXiv:2412.06828v1 公告类型：新
摘要：本研究介绍了“RadCouncil”，这是一个多智能体大型语言模型 (LLM) 框架，旨在增强从发现部分生成放射学报告中的印象。RadCouncil 由三个专门的代理组成：1) 一个“检索”代理，用于从矢量数据库中识别和检索类似的报告；2) 一个“放射科医生”代理，根据给定报告的发现部分以及检索代理检索到的示例报告生成印象；3) 一个“审阅者”代理，用于评估生成的印象并提供反馈。使用定量指标（BLEU、ROUGE、BERTScore）和 GPT-4 评估的定性标准评估了 RadCouncil 的性能，并使用胸部 X 光作为案例研究。实验结果表明，RadCouncil 在多个维度上都比单智能体方法有所改进，包括诊断准确性、风格一致性和清晰度。这项研究强调了利用多个交互的 LLM 代理（每个代理都有一项专门的任务）的潜力，以提高专门医疗任务的表现并开发更强大、适应性更强的医疗保健 AI 解决方案。]]></description>
      <guid>https://arxiv.org/abs/2412.06828</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TransitGPT：使用大型语言模型与 GTFS 数据交互的基于生成 AI 的框架</title>
      <link>https://arxiv.org/abs/2412.06831</link>
      <description><![CDATA[arXiv:2412.06831v1 公告类型：新
摘要：本文介绍了一个利用大型语言模型 (LLM) 来回答有关通用交通信息规范 (GTFS) 数据的自然语言查询的框架。该框架在一个名为 TransitGPT 的聊天机器人中使用开源代码实现。TransitGPT 的工作原理是引导 LLM 生成 Python 代码，该代码提取和操作与查询相关的 GTFS 数据，然后在存储 GTFS 提要的服务器上执行。它可以完成广泛的任务，包括数据检索、计算和交互式可视化，而无需用户具备丰富的 GTFS 或编程知识。生成代码的 LLM 完全由提示引导，无需微调或访问实际的 GTFS 提要。我们使用 GPT-4o 和 Claude-3.5-Sonnet LLM 在 100 个任务的基准数据集上评估 TransitGPT，以证明其有效性和多功能性。结果表明，TransitGPT 可以显著提高公交数据的可访问性和可用性。]]></description>
      <guid>https://arxiv.org/abs/2412.06831</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语义损失引导数据高效监督微调，实现 LLM 中的安全响应</title>
      <link>https://arxiv.org/abs/2412.06843</link>
      <description><![CDATA[arXiv:2412.06843v2 公告类型：新
摘要：大型语言模型 (LLM) 对有毒提示产生不安全的反应是其应用中的一个重大问题。虽然各种努力都旨在解决这一安全问题，但以前的方法通常需要大量的人工数据收集，或者依赖于使用另一个 LLM 来生成纠正数据的不太可靠的选项。在本文中，我们旨在解决这个问题并克服需要大量高质量人工数据的限制。我们的方法只需要一小部分对有毒提示的不安全响应，这些响应很容易从不安全的 LLM 本身获得。通过采用语义成本与负地球移动距离 (EMD) 损失相结合，我们引导 LLM 避免产生不安全的响应。此外，我们提出了一种新的 EMD 损失下限，从而实现更高效的优化。与基线相比，我们的结果证明了卓越的性能和数据效率，并且我们进一步研究了使用对比数据时过度对齐和语言能力潜在下降的细微影响。]]></description>
      <guid>https://arxiv.org/abs/2412.06843</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>完全开源的Moxin-7B技术报告</title>
      <link>https://arxiv.org/abs/2412.06845</link>
      <description><![CDATA[arXiv:2412.06845v1 公告类型：新
摘要：最近，大型语言模型 (LLM) 经历了重大变革，其受欢迎程度和功能都迅速提升。引领这一变革的是 GPT-4 和 GPT-o1 等专有 LLM，它们凭借出色的性能和多功能性在 AI 社区引起了广泛关注。同时，LLaMA 和 Mistral 等开源 LLM 为 LLM 日益普及做出了巨大贡献，因为它们易于定制和部署跨各种应用程序的模型。尽管开源 LLM 为创新和研究提供了前所未有的机会，但 LLM 的商业化引发了人们对透明度、可重复性和安全性的担忧。许多开源 LLM 未能满足基本的透明度要求，因为它们隐瞒了训练代码和数据等基本组件，有些开源 LLM 使用限制性许可证，同时声称是“开源”，这可能会阻碍 LLM 的进一步创新。为了缓解这一问题，我们推出了 Moxin 7B，这是一个完全开源的 LLM，它遵循模型开放框架 (MOF) 开发，MOF 是一个基于模型完整性和开放性评估 AI 模型的排名分类系统，遵循开放科学、开源、开放数据和开放访问的原则。我们的模型通过全面发布预训练代码和配置、训练和微调数据集以及中间和最终检查点，达到了 MOF 分类的最高级别“开放科学”。实验表明，与流行的 7B 模型相比，我们的模型在零样本评估中取得了优异的性能，在少样本评估中也表现出色。]]></description>
      <guid>https://arxiv.org/abs/2412.06845</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>政治法学硕士：政治学中的大型语言模型</title>
      <link>https://arxiv.org/abs/2412.06864</link>
      <description><![CDATA[arXiv:2412.06864v1 公告类型：新 
摘要：近年来，大型语言模型（LLM）已广泛应用于政治科学任务，例如选举预测、情绪分析、政策影响评估和错误信息检测。同时，系统地了解LLM如何进一步彻底改变该领域的需求也变得迫切。在这项工作中，我们——一个横跨计算机科学和政治学的多学科研究团队——提出了第一个称为政治-LLM的原则框架，以促进对将LLM整合到计算政治科学中的全面理解。具体而言，我们首先介绍一个基本分类法，将现有的探索分为两个视角：政治学和计算方法。特别是，从政治学的角度来看，我们强调了LLM在自动化预测和生成任务、模拟行为动态以及通过反事实生成等工具改进因果推理中的作用；从计算角度来看，我们介绍了针对政治背景的法学硕士的数据准备、微调和评估方法的进步。我们确定了关键挑战和未来方向，强调开发特定领域的数据集，解决偏见和公平问题，融入人类专业知识，并重新定义评估标准以符合计算政治科学的独特要求。政治法学硕士旨在成为研究人员的指南，以促进人工智能在政治科学中的明智、合乎道德和有影响力的使用。我们的在线资源可在以下网址获得：http://political-llm.org/。]]></description>
      <guid>https://arxiv.org/abs/2412.06864</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>最低限度数据要求下的可推广语言条件策略学习的法学硕士</title>
      <link>https://arxiv.org/abs/2412.06877</link>
      <description><![CDATA[arXiv:2412.06877v1 公告类型：新
摘要：为了开发能够执行人类用自然语言指定的复杂、多步骤决策任务的自主代理，现有的强化学习方法通​​常需要昂贵的标记数据集或实时实验。此外，传统方法在推广到未见过的目标和状态时往往面临困难，从而限制了它们的实际适用性。本文介绍了 TEDUO，一种用于离线语言条件策略学习的新型训练管道。TEDUO 在易于获取的未标记数据集上运行，适用于所谓的野外评估，其中代理会遇到以前未见过的目标和状态。为了应对此类数据和评估设置带来的挑战，我们的方法利用大型语言模型 (LLM) 的先验知识和指令遵循能力来增强预先收集的离线数据的保真度，并能够灵活地推广到新的目标和状态。实证结果表明，我们框架中的 LLM 的双重角色（数据增强器和泛化器）促进了可泛化的语言条件策略的有效和数据高效的学习。]]></description>
      <guid>https://arxiv.org/abs/2412.06877</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当每个标记都很重要时：低资源语言模型的最佳分割</title>
      <link>https://arxiv.org/abs/2412.06926</link>
      <description><![CDATA[arXiv:2412.06926v1 公告类型：新
摘要：传统的贪婪标记化方法是自然语言处理 (NLP) 中的关键步骤，影响文本转换为标记的方式并直接影响模型性能。虽然像字节对编码 (BPE) 这样的子词标记器被广泛使用，但它们在模型规模和语言中的最优性仍然存在疑问。在这项工作中，我们通过大量实验证明，与贪婪分割相比，最佳 BPE 配置显着减少了标记数量，从而提高了标记节省百分比和性能优势，特别是对于较小的模型。我们评估了各种内在和外在任务（包括生成和分类）中的标记化性能。我们的研究结果表明，压缩优化的标记化策略可以为多语言和低资源语言应用程序提供显着优势，为进一步的研究和包容性 NLP 指明了一个有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2412.06926</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于低资源多语言数据的公共交通用户情绪分析</title>
      <link>https://arxiv.org/abs/2412.06951</link>
      <description><![CDATA[arXiv:2412.06951v1 公告类型：新
摘要：与其他行业相比，许多撒哈拉以南国家的公共交通系统往往受到的关注较少，这凸显了对创新解决方案的需求，以提高服务质量 (QoS) 和整体用户体验。本研究探索了通勤者意见挖掘，以了解人们对肯尼亚、坦桑尼亚和南非现有公共交通系统的感受。我们使用了定性研究设计，分析了 X（以前称为 Twitter）的数据，以评估铁路、小巴出租车和公共汽车的情绪。通过利用多语言意见挖掘技术，我们解决了数据集中存在的语言多样性和代码转换问题，从而展示了自然语言处理 (NLP) 在从资源不足的语言中提取见解方面的应用。我们使用了 AfriBERTa、AfroXLMR、AfroLM 和 PuoBERTa 等 PLM 来进行情绪分析。结果显示，南非和肯尼亚的推文主要以负面情绪为主，而坦桑尼亚数据集则主要显示正面情绪，因为推文具有广告性质。此外，使用 Word2Vec 模型和 K-Means 聚类进行特征提取可以阐明不同数据集中发现的语义关系和主要主题。通过优先分析用户体验和情绪，这项研究为在撒哈拉以南非洲国家开发更具响应性、以用户为中心的公共交通系统铺平了道路，有助于实现改善城市交通和可持续性的更广泛目标。]]></description>
      <guid>https://arxiv.org/abs/2412.06951</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过软提示微调实现基于 LLM 的 ASR 的有效文本适配</title>
      <link>https://arxiv.org/abs/2412.06967</link>
      <description><![CDATA[arXiv:2412.06967v1 公告类型：新
摘要：大型语言模型 (LLM) 的出现改革了自动语音识别 (ASR)。使用音频嵌入提示 LLM 生成转录成为新的最先进的 ASR。尽管 LLM 经过大量文本语料库的训练，但高质量的领域特定文本数据仍然可以显着提高领域自适应任务上的 ASR 性能。虽然基于 LLM 的 ASR 可以通过微调 LLM 解码器自然地合并更多文本语料库，但在没有配对提示的情况下对纯文本数据进行微调可能会降低领域特定知识的有效性。为了缓解这个问题，我们提出了一种两步软提示微调策略，以增强领域特定文本自适应。实验结果表明，与基线 ASR 相比，使用我们提出的方法进行文本自适应，在目标域上实现了相对高达 9% 的词错误率 (WER) 降低和高达 18% 的实体错误率 (EER) 降低。将其与领域特定语言模型 (LM) 融合相结合，可以进一步将 EER 相对提高 2-5%]]></description>
      <guid>https://arxiv.org/abs/2412.06967</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AutoReason：自动小样本推理分解</title>
      <link>https://arxiv.org/abs/2412.06975</link>
      <description><![CDATA[arXiv:2412.06975v1 公告类型：新
摘要：思路链 (CoT) 是近期研究引入的一种方法，用于改进大型语言模型中的逐步推理。然而，CoT 的应用有限，例如它需要手工制作的少量样本提示，并且无法根据不同的查询进行调整。
在这项工作中，我们提出了一个使用 CoT 自动生成原理的系统。我们的方法通过将隐式查询分解为几个显式问题来提高多步骤隐式推理能力。这为模型提供了可解释性，从而提高了较弱的 LLM 中的推理能力。我们使用两个 Q\&amp;A 数据集测试了我们的方法：StrategyQA 和 HotpotQA。我们发现两者的准确率都有所提高，尤其是在 StrategyQA 上。
为了促进该领域的进一步研究，本研究的完整源代码已在 GitHub 上公开：https://github.com/miralab-ai/autoreason。]]></description>
      <guid>https://arxiv.org/abs/2412.06975</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>异步 LLM 函数调用</title>
      <link>https://arxiv.org/abs/2412.07017</link>
      <description><![CDATA[arXiv:2412.07017v1 公告类型：新
摘要：大型语言模型 (LLM) 使用函数调用与外部工具和数据源交互。然而，当前的 LLM 函数调用方法本质上是同步的，其中每个调用都会阻止 LLM 推理，从而限制 LLM 操作和并发函数执行。在这项工作中，我们提出了一个用于异步 LLM 函数调用的系统 AsyncLM。AsyncLM 通过使 LLM 能够并发生成和执行函数调用来提高 LLM 的运行效率。AsyncLM 不是等待每个调用完成，而是引入了一种中断机制，当函数调用返回时异步通知正在运行的 LLM。我们为函数调用和中断设计了一个上下文协议，提供了微调策略以使 LLM 适应中断语义，并在 LLM 推理过程中有效地实现了这些机制。我们证明，与伯克利函数调用排行榜 (BFCL) 中的一组基准任务中的同步函数调用相比，AsyncLM 可以将端到端任务完成延迟减少 1.6 倍至 5.4 倍。此外，我们还讨论了如何扩展中断机制以实现新颖的人机或 LLM 机机交互。]]></description>
      <guid>https://arxiv.org/abs/2412.07017</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型评估阴谋论的影响</title>
      <link>https://arxiv.org/abs/2412.07019</link>
      <description><![CDATA[arXiv:2412.07019v1 公告类型：新 
摘要：衡量 CT 的相对影响对于确定响应优先级和有效分配资源非常重要，尤其是在危机期间。然而，评估 CT 对公众的实际影响提出了独特的挑战。它不仅需要收集 CT 特定的知识，还需要收集来自社会、心理和文化维度的各种信息。大型语言模型 (LLM) 的最新进展表明它们在这种情况下具有潜在的效用，这不仅是因为它们来自大型训练语料库的广泛知识，还因为它们可以用于复杂的推理。在这项工作中，我们开发了具有人工注释影响的流行 CT 数据集。借鉴人类影响评估过程的见解，我们设计了量身定制的策略来利用 LLM 进行类似人类的 CT 影响评估。通过严格的实验，我们发现使用多步推理来批判性地分析更多与 CT 相关的证据的影响评估模式可以产生准确的结果；并且大多数 LLM 都表现出强烈的偏见，例如对提示中较早出现的 CT 分配更高的影响，而对情绪化和冗长的 CT 生成不太准确的影响评估。]]></description>
      <guid>https://arxiv.org/abs/2412.07019</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FM2DS：基于知识蒸馏的少样本多模态多跳数据合成，用于问答</title>
      <link>https://arxiv.org/abs/2412.07030</link>
      <description><![CDATA[arXiv:2412.07030v1 公告类型：新
摘要：多模态多跳问答是一项复杂的任务，需要对多种信息源（例如图像和文本）进行推理才能回答问题。虽然视觉问答取得了重大进展，但由于缺乏高质量的数据集，多跳设置仍未得到探索。当前的方法侧重于单跳问答或单一模态，这使得它们不适合现实世界的场景，例如分析多模态教育材料、总结冗长的学术文章或解释结合图表、图像和文本的科学研究。为了解决这一差距，我们提出了一种新颖的方法，引入了第一个创建高质量数据集的框架，该数据集支持多模态多跳问答的训练模型。我们的方法包括一个 5 阶段的流程，包括从维基百科获取相关的多模态文档、综合生成高级问题和答案，并通过严格的标准对其进行验证以确保数据质量。我们通过在合成数据集上训练模型并在两个基准上进行测试来评估我们的方法，结果表明，在样本量相同的情况下，在精确匹配 (EM) 方面，在我们的合成数据上训练的模型比在人工收集的数据上训练的模型平均高出 1.9。我们相信我们的数据合成方法将为训练和评估多模态多跳问答模型奠定坚实的基础。]]></description>
      <guid>https://arxiv.org/abs/2412.07030</guid>
      <pubDate>Wed, 11 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>