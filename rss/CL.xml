<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 30 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>大型语言模型在医学领域摘要任务中的评估：叙述性评论</title>
      <link>https://arxiv.org/abs/2409.18170</link>
      <description><![CDATA[arXiv:2409.18170v1 公告类型：新
摘要：大型语言模型推动了临床自然语言生成，为管理大量医学文本创造了机会。然而，医学的高风险性质要求可靠的评估，这仍然是一个挑战。在这篇叙述性评论中，我们评估了临床总结任务的当前评估状态，并提出了解决专家人工评估资源限制的未来方向。]]></description>
      <guid>https://arxiv.org/abs/2409.18170</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LowREm：一个利用多语言图知识增强的 87 种低资源语言的词嵌入库</title>
      <link>https://arxiv.org/abs/2409.18193</link>
      <description><![CDATA[arXiv:2409.18193v1 公告类型：新
摘要：基于大型语言模型 (LLM) 的语境化嵌入可用于各种语言，但它们的覆盖范围通常仅限于资源较少的语言。由于数据不足和计算成本高，训练此类语言的 LLM 通常很困难。因此，特别是对于资源非常少的语言，静态词嵌入仍然是一种可行的替代方案。然而，对于各种语言，缺乏具有此类嵌入的综合存储库。为了解决这个问题，我们提出了 LowREm，这是一个针对 87 种低资源语言的静态嵌入的集中存储库。我们还提出了一种新方法，通过集成多语言图知识，利用另一种知识来源来增强基于 GloVe 的嵌入。我们展示了与从 XLM-R 中提取的语境化嵌入相比，我们的增强嵌入在情感分析方面的卓越性能。我们的代码和数据可在 https://huggingface.co/DFKI 下公开获取。]]></description>
      <guid>https://arxiv.org/abs/2409.18193</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LangSAMP：语言脚本感知多语言预训练</title>
      <link>https://arxiv.org/abs/2409.18199</link>
      <description><![CDATA[arXiv:2409.18199v1 公告类型：新
摘要：最近的多语言预训练语言模型 (mPLM) 通常避免使用语言嵌入——分配给不同语言的可学习向量。这些嵌入被丢弃有两个主要原因：(1) mPLM 预计在所有语言中都有单一、统一的参数集，(2) 它们需要无缝地作为通用文本编码器运行，而不需要语言 ID 作为输入。然而，这种删除增加了标记嵌入对所有语言特定信息的编码负担，这可能会妨碍模型产生更多语言中立表示的能力。为了应对这一挑战，我们提出了语言脚本感知多语言预训练 (LangSAMP)，这是一种结合语言和脚本嵌入来增强表示学习同时保持简单架构的方法。具体来说，我们将这些嵌入集成到转换器块的输出中，然后将最终表示传递给语言建模头进行预测。我们将 LangSAMP 应用于 XLM-R 的持续预训练，该预训练基于一个涵盖 500 多种语言的多语言语料库。生成的模型始终优于基线。广泛的分析进一步表明，语言/脚本嵌入编码了特定于语言/脚本的信息，从而改善了跨语言传输的源语言选择。我们将我们的代码和模型公开发布在 \url{https://github.com/cisnlp/LangSAMP}。]]></description>
      <guid>https://arxiv.org/abs/2409.18199</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DisGeM：使用跨度掩蔽生成多项选择题干扰项</title>
      <link>https://arxiv.org/abs/2409.18263</link>
      <description><![CDATA[arXiv:2409.18263v1 公告类型：新
摘要：自然语言处理 (NLP) 的最新进展影响了许多子领域，例如自然语言生成、自然语言推理、问答等。然而，在问题生成领域，为多项选择题 (MCQ) 创建干扰项仍然是一项艰巨的任务。在这项工作中，我们提出了一个简单、通用的干扰项生成框架，使用现成的预训练语言模型 (PLM)。与以前的方法不同，我们的框架完全依赖于预训练的语言模型，不需要对特定数据集进行额外的训练。在先前研究的基础上，我们引入了一个由候选生成和候选选择组成的两阶段框架。我们提出的干扰项生成框架优于以前的方法，无需训练或微调。人工评估证实，我们的方法可以产生更有效、更吸引人的干扰项。相关代码库可在 https://github.com/obss/disgem 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2409.18263</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AER-LLM：利用大型语言模型实现模糊感知情绪识别</title>
      <link>https://arxiv.org/abs/2409.18339</link>
      <description><![CDATA[arXiv:2409.18339v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展已在许多自然语言处理 (NLP) 任务中取得了巨大成功。除了认知智能之外，探索其情商能力也至关重要，因为它可以实现更自然、更具同理心的对话式 AI。最近的研究表明 LLM 具有识别情绪的能力，但它们往往专注于单一情绪标签，而忽视了人类情绪的复杂和模糊性。这项研究首次通过探索 LLM 在识别模糊情绪方面的潜力来解决这一差距，利用其强大的泛化能力和情境学习。我们设计了零样本和少样本提示，并将过去的对话作为模糊情绪识别的情境信息。使用三个数据集进行的实验表明 LLM 在识别模糊情绪方面具有巨大潜力，并强调了包含情境信息的巨大好处。此外，我们的研究结果表明，LLM 在识别不太模糊的情绪方面表现出高度的有效性，并且表现出识别更模糊情绪的潜力，与人类的感知能力相似。]]></description>
      <guid>https://arxiv.org/abs/2409.18339</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通用 LLM 增强型 BIM 框架：应用于语音转 BIM 系统</title>
      <link>https://arxiv.org/abs/2409.18345</link>
      <description><![CDATA[arXiv:2409.18345v1 公告类型：新 
摘要：执行建筑信息模型 (BIM) 任务是一个复杂的过程，由于需要记住大量命令的序列，因此需要陡峭的学习曲线和繁重的认知负荷。随着大型语言模型 (LLM) 的快速发展，可以预见，BIM 任务（包括查询和管理 BIM 数据、4D 和 5D BIM、设计合规性检查或使用书面或口头自然语言（即文本到 BIM 或语音到 BIM）创作设计）将很快取代传统的图形用户界面。本文提出了一种通用的 LLM 增强 BIM 框架，通过提供分步开发过程来加快 LLM 增强型 BIM 应用程序的开发。提出的框架包括六个步骤：解释-填充-匹配-结构-执行-检查。本文通过实现语音到 BIM 应用程序 NADIA-S（通过语音与人工智能交互的基于自然语言的建筑细节），以外墙细节为例，证明了所提出的框架的适用性。]]></description>
      <guid>https://arxiv.org/abs/2409.18345</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MultiClimate：气候变化视频的多模式立场检测</title>
      <link>https://arxiv.org/abs/2409.18346</link>
      <description><![CDATA[arXiv:2409.18346v1 公告类型：新
摘要：近年来，气候变化 (CC) 在 NLP 中引起了越来越多的关注。然而，由于缺乏可靠的数据集，检测多模态数据中对 CC 的立场研究不足且仍然具有挑战性。为了提高对公众意见和沟通策略的理解，本文介绍了 MultiClimate，这是第一个开源手动注释的立场检测数据集，其中包含 $100$ 个与 CC 相关的 YouTube 视频和 $4,209$ 个帧转录对。我们部署了最先进的视觉和语言模型，以及用于 MultiClimate 立场检测的多模态模型。结果表明，纯文本 BERT 明显优于纯图像的 ResNet50 和 ViT。结合两种模态可实现最先进的准确度/F1，分别为 $0.747$/$0.749$。我们的 100M 大小的融合模型也击败了 CLIP 和 BLIP，以及更大的 9B 大小的多模态 IDEFICS 和纯文本 Llama3 和 Gemma2，这表明多模态立场检测对于大型语言模型来说仍然具有挑战性。我们的代码、数据集以及补充材料可在 https://github.com/werywjw/MultiClimate 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.18346</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SciDFM：面向科学的混合专家大型语言模型</title>
      <link>https://arxiv.org/abs/2409.18412</link>
      <description><![CDATA[arXiv:2409.18412v1 公告类型：新
摘要：最近，人们对利用大型语言模型 (LLM) 来协助科学发现的兴趣显著增加。然而，大多数 LLM 只关注一般科学，而缺乏特定领域的知识，例如化学分子和氨基酸序列。为了弥补这些差距，我们引入了 SciDFM，这是一种混合专家的 LLM，它从头开始训练，能够进行大学水平的科学推理并理解分子和氨基酸序列。我们收集了一个大规模的训练语料库，其中包含来自不同学科的大量科学论文和书籍以及来自领域特定数据库的数据。我们进一步在大量指令数据上微调预训练模型，以提高下游基准测试的性能。从实验结果来看，我们表明 SciDFM 在 SciEval 和 SciQ 等通用科学基准测试上取得了强劲的表现，并且在类似规模的模型中，它在领域特定基准测试上达到了 SOTA 性能。我们进一步分析了专家层，发现专家选择的结果会因不同学科的数据而有所不同。为了造福更广泛的研究社区，我们在 https://huggingface.co/OpenDFM/SciDFM-MoE-A5.6B-v1.0 开源了 SciDFM。]]></description>
      <guid>https://arxiv.org/abs/2409.18412</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用简单的 N-best 重新排序来改善多语言 ASR</title>
      <link>https://arxiv.org/abs/2409.18428</link>
      <description><![CDATA[arXiv:2409.18428v1 公告类型：新
摘要：多语言自动语音识别 (ASR) 模型通常在已知语音的真实语言的环境中进行评估，然而，在大多数实际环境中，情况往往并非如此。自动口语语言识别 (SLID) 模型并不完美，错误分类会对最终的 ASR 准确性产生重大影响。在本文中，我们提出了一种简单有效的 N-best 重新排序方法，通过使用语言模型和基于文本的语言识别模型等外部特征来提高几种著名声学模型的多语言 ASR 准确性。我们在 FLEURS 上使用 MMS 和 Whisper 模型的结果显示，口语语言识别准确度分别提高了 8.7% 和 6.1%，而单词错误率在这些基准上分别降低了 3.3% 和 2.0%。]]></description>
      <guid>https://arxiv.org/abs/2409.18428</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索低资源提取式问答中的语言模型泛化</title>
      <link>https://arxiv.org/abs/2409.18446</link>
      <description><![CDATA[arXiv:2409.18446v1 公告类型：新
摘要：在本文中，我们研究了领域漂移下使用大型语言模型 (LLM) 的抽取式问答 (EQA)，即 LLM 是否可以很好地推广到需要特定知识的封闭领域，例如医学和法律，而无需额外的领域内训练？为此，我们设计了一系列实验来实证解释性能差距。我们的研究结果表明：a) LLM 难以满足封闭领域的数据集需求，例如检索较长的答案跨度；b) 某些 LLM 虽然表现出强劲的整体性能，但在满足基本要求方面表现出弱点，例如区分我们与预处理决策相关的领域特定词义；c) 缩放模型参数对于跨域泛化并不总是有效的；d) 封闭域数据集在数量上与开放域 EQA 数据集有很大不同，当前的 LLM 难以处理它们。我们的研究结果为改进现有的法学硕士指明了重要的方向。]]></description>
      <guid>https://arxiv.org/abs/2409.18446</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用长上下文大型语言模型在企业应用中实现多文档理解和摘要</title>
      <link>https://arxiv.org/abs/2409.18454</link>
      <description><![CDATA[arXiv:2409.18454v1 公告类型：新
摘要：各个领域的非结构化数据迅速增加，使多文档理解和总结成为一项关键任务。传统方法通常无法捕捉相关上下文、保持逻辑一致性以及从冗长的文档中提取重要信息。本文探讨了长上下文大型语言模型 (LLM) 在多文档总结中的应用，展示了它们在掌握广泛联系、提供连贯总结、适应各种行业领域和与企业应用程序/系统集成方面的卓越能力。本文讨论了有效部署长上下文 LLM 的多文档总结工作流程，并提供了法律应用、人力资源、财务和采购等企业职能以及医疗和新闻领域的案例研究。这些案例研究显示效率和准确性都有显着提高。仔细分析了技术障碍，例如数据集多样性、模型可扩展性以及偏见缓解和事实准确性等道德考虑。建议通过前瞻性的研究途径来增强长期 LLM 的功能和应用，使其成为转变跨不同行业和企业应用的信息处理的关键工具。]]></description>
      <guid>https://arxiv.org/abs/2409.18454</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>URIEL+：增强类型学和多语言知识库的语言包容性和可用性</title>
      <link>https://arxiv.org/abs/2409.18472</link>
      <description><![CDATA[arXiv:2409.18472v1 公告类型：新
摘要：URIEL 是一个知识库，为 7970 种语言提供地理、系统发育和类型学向量表示。它包括 4005 种语言的这些向量之间的距离测量，可通过 lang2vec 工具访问。尽管经常被引用，但 URIEL 在语言包容性和整体可用性方面受到限制。为了应对这些挑战，我们推出了 URIEL+，这是 URIEL 和 lang2vec 的增强版本，解决了这些限制。除了扩大 2898 种语言的类型学特征覆盖范围外，URIEL+ 还通过强大、可定制的距离计算改善了用户体验，以更好地满足用户的需求。这些升级还在下游任务上提供了具有竞争力的性能，并提供了与语言距离研究更一致的距离。]]></description>
      <guid>https://arxiv.org/abs/2409.18472</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI o1 评测：AGI 的机遇与挑战</title>
      <link>https://arxiv.org/abs/2409.18486</link>
      <description><![CDATA[arXiv:2409.18486v1 公告类型：新
摘要：这项综合研究评估了 OpenAI 的 o1-preview 大型语言模型在多种复杂推理任务中的表现，涵盖多个领域，包括计算机科学、数学、自然科学、医学、语言学和社会科学。通过严格的测试，o1-preview 展示了卓越的能力，通常在从编码挑战到科学推理、从语言处理到创造性解决问题等领域实现人类水平或卓越的表现。主要发现包括：
- 解决复杂竞争性编程问题的成功率为 83.3%，超过了许多人类专家。
- 在生成连贯和准确的放射学报告方面具有卓越的能力，优于其他评估模型。
- 高中水平数学推理任务的准确率为 100%，提供详细的分步解决方案。
- 在医学等一般和专业领域具有先进的自然语言推理能力。
-在芯片设计任务中表现出色，在 EDA 脚本生成和错误分析等领域的表现优于专业模型。
-在人类学和地质学方面表现出色，在这些专业领域表现出深刻的理解和推理能力。
-强大的量化投资能力。O1 拥有全面的金融知识和统计建模技能。
-在社交媒体分析方面表现出色，包括情绪分析和情绪识别。
该模型在需要复杂推理和跨领域知识整合的任务中表现尤为出色。虽然观察到一些局限性，包括简单问题上偶尔出现错误以及某些高度专业化概念的挑战，但总体结果表明人工智能取得了重大进展。]]></description>
      <guid>https://arxiv.org/abs/2409.18486</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们是否需要特定领域的嵌入模型？一项实证研究</title>
      <link>https://arxiv.org/abs/2409.18511</link>
      <description><![CDATA[arXiv:2409.18511v1 公告类型：新
摘要：嵌入模型在各种 NLP 应用程序中表示和检索信息方面起着至关重要的作用。大型语言模型 (LLM) 的最新进展进一步增强了嵌入模型的性能，这些模型在几乎涵盖所有领域的大量文本上进行训练。这些模型通常在通用数据集（如海量文本嵌入基准 (MTEB)）上进行基准测试，它们表现出卓越的性能。然而，一个关键问题出现了：当通用模型在已经包含专业领域文本的大量语料库上进行训练时，是否有必要开发特定领域的嵌入模型？在本文中，我们以金融领域为例，对这个问题进行了实证研究。我们介绍了金融海量文本嵌入基准 (FinMTEB)，它是 MTEB 的对应物，由金融领域特定的文本数据集组成。我们评估了七种最先进的嵌入模型在 FinMTEB 上的性能，并观察到与在 MTEB 上的性能相比，性能显著下降。为了解释这种下降可能是由 FinMTEB 的更高复杂性导致的，我们提出了四种措施来量化数据集复杂性并控制我们分析中的这一因素。我们的分析提供了令人信服的证据，表明最先进的嵌入模型很难捕捉特定领域的语言和语义模式，即使在大型通用语料库上进行训练也是如此。这项研究揭示了在 LLM 时代开发特定领域嵌入模型的必要性，为研究人员和从业者提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2409.18511</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>目标导向交互式代理的复杂任务调查</title>
      <link>https://arxiv.org/abs/2409.18538</link>
      <description><![CDATA[arXiv:2409.18538v1 公告类型：新
摘要：目标导向的交互式代理通过与环境的交互自主完成任务，可以帮助人类处理日常生活的各个领域。大型语言模型 (LLM) 的最新进展导致评估此类代理的新任务激增，这些任务越来越具有挑战性。为了正确地将这些任务的性能情境化，必须了解它们对代理提出的不同挑战。为此，本调查汇编了用于评估目标导向交互式代理的相关任务和环境，并根据与理解当前障碍相关的维度对其进行构建。可以在我们的项目网站上找到相关资源的最新汇编：https://coli-saar.github.io/interactive-agents。]]></description>
      <guid>https://arxiv.org/abs/2409.18538</guid>
      <pubDate>Mon, 30 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>