<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 02 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用音素分类改进口语语言建模：一种简单的微调方法</title>
      <link>https://arxiv.org/abs/2410.00025</link>
      <description><![CDATA[arXiv:2410.00025v1 公告类型：新
摘要：口语语言建模的最新进展证明了直接从语音学习语言的可行性。通过在文本级别运行的管道生成语音通常会丢失细微差别、语调和非语言发声。直接从语音建模开辟了通往更自然和富有表现力的系统的道路。另一方面，纯语音系统在语义能力方面往往落后于基于文本的语言模型。我们表明，在音素分类上微调语音表示模型会产生更多上下文不变的表示，从而提高下游语言建模性能。]]></description>
      <guid>https://arxiv.org/abs/2410.00025</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于 Transformer 的嵌入和聚类算法进行语义驱动主题建模</title>
      <link>https://arxiv.org/abs/2410.00134</link>
      <description><![CDATA[arXiv:2410.00134v1 公告类型：新 
摘要：主题建模是一种强大的技术，可以在没有先验知识的情况下发现文档集合中的隐藏主题和模式。传统的主题建模和基于聚类的技术在捕获上下文语义信息方面遇到了挑战。本研究介绍了一种创新的端到端语义驱动主题建模技术，用于主题提取过程，利用高级单词和文档嵌入与强大的聚类算法相结合。这种语义驱动的方法代表了主题建模方法的重大进步。它利用上下文语义信息来提取连贯且有意义的主题。具体而言，我们的模型使用预先训练的基于 Transformer 的语言模型生成文档嵌入，降低嵌入的维度，根据语义相似性对嵌入进行聚类，并为每个聚类生成连贯的主题。与 ChatGPT 和传统主题建模算法相比，我们的模型提供了更连贯、更有意义的主题。]]></description>
      <guid>https://arxiv.org/abs/2410.00134</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是否是上下文个性化摘要器？完成 iCOPERNICUS 测试！</title>
      <link>https://arxiv.org/abs/2410.00149</link>
      <description><![CDATA[arXiv:2410.00149v1 公告类型：新
摘要：大型语言模型 (LLM) 在基于上下文学习 (ICL) 的摘要方面取得了相当大的成功。然而，显著性取决于用户的特定偏好历史。因此，我们需要在此类 LLM 中提供可靠的上下文个性化学习 (ICPL) 功能。对于任何展示 ICPL 的 LLM，它都需要能够辨别用户配置文件中的对比。最近的一项研究首次提出了一种称为 EGISES 的个性化程度测量方法。EGISES 测量模型对用户配置文件差异的响应能力。但是，它无法测试模型是否利用了 ICPL 提示中提供的所有三种类型的提示：(i) 示例摘要、(ii) 用户的阅读历史和 (iii) 用户配置文件中的对比。为了解决这个问题，我们提出了 iCOPERNICUS 框架，这是一种新颖的上下文个性化学习，用于审查 LLM 中的总结能力，使用 EGISES 作为比较指标。作为案例研究，我们根据报告的 ICL 性能评估了 17 个最先进的 LLM，并观察到 ​​15 个模型的 ICPL 在用更丰富的提示进行探测时会降低（最小：1.6%；最大：3.6%），从而表明缺乏真正的 ICPL。]]></description>
      <guid>https://arxiv.org/abs/2410.00149</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>山鲁佐德：使用问题链评估法学硕士中的思路链数学推理</title>
      <link>https://arxiv.org/abs/2410.00151</link>
      <description><![CDATA[arXiv:2410.00151v1 公告类型：新
摘要：基准测试对于衡量大型语言模型 (LLM) 的数学推理能力的进步至关重要。然而，由于多个尖端 LLM 的准确率超过 94%，现有的广泛使用的基准测试（如 GSM8K）已变得不那么有用。虽然已经提出了更难的基准测试，但它们的创建通常是手动的且成本高昂。我们提出了 Scheherazade，这是一种通过逻辑链接数学推理问题来生成具有挑战性的数学推理基准测试的自动化方法。我们提出了两种不同的链接方法，即前向链接和后向链接，它们分别需要通过链进行正向和反向推理。我们在 GSM8K 上应用 Scheherazade 来创建 GSM8K-Scheherazade，并在其上评估 3 个前沿 LLM 和 OpenAI 的 o1 预览版。我们表明，虽然前沿模型的性能在只有几个问题链接时急剧下降，但初步评估表明 o1-preview 性能在最多 5 个反向链接问题时仍能保持。此外，虽然所有其他模型在问题反向链接时表现较差，但 o1-preview 在反向链接基准上表现更好。我们将公开发布数据集和代码。]]></description>
      <guid>https://arxiv.org/abs/2410.00151</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越单一概念向量：使用高斯分布在 LLM 中建模概念子空间</title>
      <link>https://arxiv.org/abs/2410.00153</link>
      <description><![CDATA[arXiv:2410.00153v1 公告类型：新
摘要：在大型语言模型 (LLM) 中探索学习到的概念对于理解语义知识的内部编码方式至关重要。在探测任务上训练线性分类器是一种表示表示空间中某个概念向量的主要方法。然而，为概念识别的单个向量会随着数据和训练而变化，使其稳定性降低并削弱其在实际应用中的有效性。为了应对这一挑战，我们提出了一种近似表示特定概念的子空间的方法。基于线性探测分类器，我们将概念向量扩展为高斯概念子空间 (GCS)。我们通过测量 GCS 在具有不同大小和架构的多个 LLM 中的忠实度和合理性来证明其有效性。此外，我们使用表示干预任务来展示其在情绪引导等实际应用中的有效性。实验结果表明，GCS 概念向量有可能平衡引导性能并保持自然语言生成任务的流畅性。]]></description>
      <guid>https://arxiv.org/abs/2410.00153</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KV-Compress：分页 KV-Cache 压缩，每个注意头具有可变的压缩率</title>
      <link>https://arxiv.org/abs/2410.00161</link>
      <description><![CDATA[arXiv:2410.00161v1 公告类型：新 
摘要：近年来，大型语言模型 (LLM) 的上下文长度呈爆炸式增长，128k 令牌上下文成为标准，百万令牌上下文成为现实。有效支持长上下文推理仍然具有挑战性，因为一代必须在键值 (KV) 缓存中分配的内存会随着其上下文长度而扩展，从而限制了在给定内存预算下可以同时提供的长上下文请求的数量。KV 缓存压缩可以通过从每个注意力头的缓存中删除未充分利用的 KV 并减少其内存占用来缓解此问题。当删除的 KV 数量因注意力头而异时，可以实现更高的理论压缩率，但在现有推理框架中应用这种策略会增加碎片，并且无法在物理内存中实现理论压缩率。我们引入了 KV-Compress，这是一种新颖的压缩方法，它在 PagedAttention 框架内逐出连续的 KV 块，从而按与理论压缩率成比例地减少 KV 缓存的内存占用。我们的方法在 Mistral-7B-Instruct-v0.2 和 Llama-3.1-8B-Instruct 的 LongBench 上实现了最先进的性能，同时与以前的方法相比，压缩的 KV 总数减少了 4 倍。在 Llama-3.1-8B-Instruct 和 Llama-3.1-70B-Instruct-FP8 上的评估实现了高达 8 倍的压缩率，对性能的影响可以忽略不计，并且高达 64 倍的压缩率，同时保留了除套件的三个子集之外的所有子集的 90% 以上的全缓存性能。我们对我们的方法与 vLLM 的集成进行了基准测试，通过启用更大的解码批次，将总吞吐量提高了 5.18 倍。]]></description>
      <guid>https://arxiv.org/abs/2410.00161</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将法学硕士 (LLM) 应用于葡萄牙语医学领域：微调和模型评估研究</title>
      <link>https://arxiv.org/abs/2410.00163</link>
      <description><![CDATA[arXiv:2410.00163v1 公告类型：新
摘要：本研究评估了大型语言模型 (LLM) 作为葡萄牙语医疗代理的性能，旨在为医疗专业人士开发可靠且相关的虚拟助手。使用 GPT-3.5 从英语翻译而来的 HealthCareMagic-100k-en 和 MedQuAD 数据集用于使用 PEFT-QLoRA 方法对 ChatBode-7B 模型进行微调。在医学数据上进行初始训练的 InternLM2 模型表现出最佳的整体性能，在准确性、完整性和安全性等指标上具有高精度和充分性。然而，源自 ChatBode 的 DrBode 模型表现出对获得的医学知识的灾难性遗忘现象。尽管如此，这些模型在语法和连贯性等方面的表现往往甚至更好。一个重大挑战是评分者之间的一致性较低，这凸显了对更强大的评估协议的需求。这项工作为未来的研究铺平了道路，例如评估特定于医学领域的多语言模型、提高训练数据的质量以及为医学领域开发更一致的评估方法。]]></description>
      <guid>https://arxiv.org/abs/2410.00163</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SSR：用于语音语言模型的对齐感知模态连接器</title>
      <link>https://arxiv.org/abs/2410.00168</link>
      <description><![CDATA[arXiv:2410.00168v1 公告类型：新
摘要：将语音融合到预训练语言模型 (SpeechLM) 中通常会遭受长格式语音编码效率低下和预训练文本模态灾难性遗忘的问题。我们提出了 SSR-Connector（分段语音表示连接器）以实现更好的模态融合。利用语音文本对齐，我们的方法可以分割和压缩语音特征以匹配文本嵌入的粒度。此外，我们引入了一个两阶段训练管道，其中包括蒸馏和微调阶段，以减轻灾难性遗忘。SSR-Connector 优于现有的语音文本模态融合机制，在保留预训练文本能力的同时，始终实现更好的语音理解（例如，StoryCloze 上的准确率 +10，Speech-MMLU 上的准确率 +20）。]]></description>
      <guid>https://arxiv.org/abs/2410.00168</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型对性别歧视内容的适应性道德立场：对社会和性别话语的影响</title>
      <link>https://arxiv.org/abs/2410.00175</link>
      <description><![CDATA[arXiv:2410.00175v1 公告类型：新
摘要：这项工作提供了一个解释性的观点，即法学硕士如何运用道德推理来批评和捍卫性别歧视语言。我们评估了八个大型语言模型，所有这些模型都展示了基于不同道德观点的解释能力，既可以批评也可以认可反映性别歧视假设的观点。通过人工和自动评估，我们表明所有八个模型都产生了可理解且与上下文相关的文本，这有助于理解对性别歧视的不同看法。此外，通过分析法学硕士在其论点中引用的道德基础，我们发现模型输出中的不同意识形态观点，其中一些模型更符合进步或保守的性别角色和性别歧视观点。根据我们的观察，我们警告不要滥用法学硕士来为性别歧视语言辩护。我们还强调，法学硕士可以作为理解性别歧视信念根源和设计明智干预措施的工具。鉴于这种双重能力，监控 LLM 并设计安全机制以用于涉及敏感社会话题（例如性别歧视）的应用至关重要。]]></description>
      <guid>https://arxiv.org/abs/2410.00175</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在进行小样本文本分类之前评估对未标记测试数据进行任务自适应预训练的公平性</title>
      <link>https://arxiv.org/abs/2410.00179</link>
      <description><![CDATA[arXiv:2410.00179v1 公告类型：新
摘要：小样本学习基准对于评估现代 NLP 技术至关重要。然而，基准可能偏向于容易利用未标记文本的方法，因为研究人员可以使用测试集中的未标记文本来预训练他们的模型。鉴于对这一潜在问题的研究不足，我们进行了实验来量化对未标记测试集文本而不是未标记的独立绘制文本进行预训练所造成的偏差。对 25 个分类任务和 3 个语言模型（BERT、GPT-2 和 Mistral 7B）进行的受控小样本和零样本实验没有发现过度乐观的证据。此外，我们证明了在研究小样本文本分类时重复子采样的重要性，并建议小样本学习基准包括多个训练折叠。代码和数据可在 https://github.com/kddubey/pretrain-on-test/ 获得。]]></description>
      <guid>https://arxiv.org/abs/2410.00179</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用指令微调大型语言模型对危机推文进行零样本分类</title>
      <link>https://arxiv.org/abs/2410.00182</link>
      <description><![CDATA[arXiv:2410.00182v1 公告类型：新
摘要：社交媒体帖子经常被视为灾难响应的宝贵开源情报来源，并且已经在危机推文数据集上评估了 LLM 之前的 NLP 技术。我们评估了三种商业大型语言模型（OpenAI GPT-4o、Gemini 1.5-flash-001 和 Anthropic Claude-3-5 Sonnet）在短社交媒体帖子的零样本分类中的能力。在一个提示中，要求模型执行两个分类任务：1）确定帖子在人道主义背景下是否具有信息性；2）根据 16 种可能的人道主义类别对该帖子进行排名并提供概率。被分类的帖子来自合并的危机推文数据集 CrisisBench。使用宏、加权和二进制 F1 分数评估结果。信息分类任务通常在没有额外信息的情况下表现更好，而对于提供挖掘推文期间发生的事件的人道主义标签分类，则表现更好。此外，我们发现模型的性能因数据集而异，这引发了对数据集质量的质疑。]]></description>
      <guid>https://arxiv.org/abs/2410.00182</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>视觉语言模型真的理解视觉语言吗？</title>
      <link>https://arxiv.org/abs/2410.00193</link>
      <description><![CDATA[arXiv:2410.00193v1 公告类型：新
摘要：视觉语言是一种通过符号、形状和空间排列传达信息的交流系统。图表是视觉语言的典型示例，以图像的形式描绘复杂的概念及其关系。图表的符号性质给构建能够理解它们的模型带来了重大挑战。然而，最近的研究似乎表明，大型视觉语言模型 (LVLM) 甚至可以解决涉及图表的复杂推理任务。在本文中，我们通过开发一个全面的测试套件来评估 LVLM 的图表理解能力，从而研究了这一现象。我们的测试套件使用各种问题，重点关注概念实体及其在多个领域的一组合成和真实图表上的关系，以评估模型的识别和推理能力。我们对三个 LVLM（GPT-4V、GPT-4o 和 Gemini）的评估表明，虽然这些模型可以准确识别和推理实体，但它们理解关系的能力明显有限。进一步的测试表明，图表理解的良好表现很大程度上源于利用他们的背景知识作为识别和推理关系信息的捷径。因此，我们得出结论，LVLM 真正的图表理解能力有限，他们在图表推理方面的出色表现是一种假象，源于其他混杂因素，例如模型中的背景知识。]]></description>
      <guid>https://arxiv.org/abs/2410.00193</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对现有模型和传统机器学习技术，评估最先进的 esg 领域特定预训练大型语言模型在文本分类中的性能</title>
      <link>https://arxiv.org/abs/2410.00207</link>
      <description><![CDATA[arXiv:2410.00207v1 公告类型：新
摘要：本研究调查了文本披露中的环境、社会和治理 (ESG) 信息的分类。目的是开发和评估能够准确识别和分类 E、S 和 G 相关内容的二元分类模型。
本研究的动机源于 ESG 考虑因素在投资决策和企业责任中的重要性日益增加。准确有效地对 ESG 信息进行分类对于利益相关者了解公司对可持续性的影响并做出明智的决策至关重要。
该研究采用定量方法，涉及数据收集、数据预处理以及开发以 ESG 为中心的大型语言模型 (LLM) 和传统机器学习（支持向量机、XGBoost）分类器。绩效评估指导迭代细化，直到达到令人满意的指标。
该研究通过采用标准自然语言处理性能指标（例如准确率、精确度、召回率、F1 分数）比较了传统机器学习技术（支持向量机、XGBoost）、最先进的语言模型（FinBERT-ESG）和 Llama 2 等微调 LLM。一种新颖的微调方法 Qlora 被应用于 LLM，从而显著提高了所有 ESG 领域的性能。该研究还开发了特定领域的微调模型，例如 EnvLlama 2-Qlora、SocLlama 2-Qlora 和 GovLlama 2-Qlora，这些模型在 ESG 文本分类中表现出色。]]></description>
      <guid>https://arxiv.org/abs/2410.00207</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>T-KAER：透明度增强的知识增强实体解析框架</title>
      <link>https://arxiv.org/abs/2410.00218</link>
      <description><![CDATA[arXiv:2410.00218v1 公告类型：新
摘要：实体解析（ER）是确定两个表示是否指向同一个现实世界实体的过程，在数据管理和数据清理中起着至关重要的作用。最近的研究引入了 KAER 框架，旨在通过增强外部知识来改进预训练语言模型。然而，识别和记录正在增强的外部知识并了解其对模型预测的贡献在研究界几乎没有受到关注。本文通过引入 T-KAER（透明度增强的知识增强实体解析框架）来解决这一差距。
为了提高透明度，提出了三个与透明度相关的问题（T-Q）：T-Q(1)：基于数据输入匹配结果的实验​​过程是什么？T-Q(2)：KAER 在原始数据输入中增强了哪些语义信息？T-Q(3)：增强数据输入的哪些语义信息会影响预测？为了解决 T-Q 问题，T-KAER 旨在通过在日志文件中记录实体解析过程来提高透明度。
在实验中，引用数据集用于演示 T-KAER 的透明度组件。此演示展示了 T-KAER 如何从定量和定性角度促进错误分析，提供有关“什么”语义信息被增强以及“为什么”增强的知识对预测产生不同影响的证据。]]></description>
      <guid>https://arxiv.org/abs/2410.00218</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种用于文本分类的集成梯度和语言分析的可解释大型语言模型方法</title>
      <link>https://arxiv.org/abs/2410.00250</link>
      <description><![CDATA[arXiv:2410.00250v1 公告类型：新
摘要：影响言语产生的神经系统疾病，例如阿尔茨海默病 (AD)，会严重影响患者和护理人员的生活，无论是通过社会、心理情感影响还是其他尚未完全了解的方面。大型语言模型 (LLM) 架构的最新进展已经开发出许多工具来通过自发语音识别神经系统疾病的代表性特征。然而，LLM 通常缺乏可解释性，这意味着它们没有提供明确而具体的决策理由。因此，需要能够识别语音中神经系统疾病的代表性特征并清楚地解释这些特征为何相关的方法。本文提出了一种可解释的 LLM 方法，名为 SLIME（用于模型解释的统计和语言学见解），能够识别代表 AD 的词汇成分并指出哪些成分对 LLM 的决策最重要。在开发此方法时，我们使用了一个由 Cookie Theft 图片描述任务的转录组成的英语数据集。 LLM Transformers 双向编码器表示 (BERT) 将文本描述分类为 AD 或对照组。为了识别代表性词汇特征并确定哪些特征与模型的决策最相关，我们使用了涉及积分梯度 (IG)、语言查询和字数统计 (LIWC) 和统计分析的流程。我们的方法表明，BERT 利用了反映 AD 中社交参考减少的词汇成分，并确定哪些成分可以进一步提高 LLM 的准确性。因此，我们提供了一种可解释性工具，可增强将 LLM 应用于神经临床环境（特别是在神经退行性疾病研究中）的信心。]]></description>
      <guid>https://arxiv.org/abs/2410.00250</guid>
      <pubDate>Wed, 02 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>