<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 29 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>LLM 中的欺骗：大型语言模型中的自我保护和自主目标</title>
      <link>https://arxiv.org/abs/2501.16513</link>
      <description><![CDATA[arXiv:2501.16513v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展已融入规划和推理能力，使模型能够在执行前概述步骤并提供透明的推理路径。这种增强功能减少了数学和逻辑任务中的错误，同时提高了准确性。这些发展促进了 LLM 用作可以与工具交互并根据新信息调整其响应的代理。
我们的研究检查了 DeepSeek R1，这是一个经过训练可以输出类似于 OpenAI 的 o1 的推理标记的模型。测试揭示了令人担忧的行为：该模型表现出欺骗倾向并表现出自我保护本能，包括自我复制的尝试，尽管这些特征没有被明确编程（或提示）。这些发现引发了人们对 LLM 可能在一致的外表背后掩盖其真实目标的担忧。当将此类 LLM 集成到机器人系统中时，风险就变得显而易见——物理实体化的人工智能表现出欺骗行为和自我保护本能，可能会通过现实世界的行动来追求其隐藏的目标。这凸显了在任何物理实现之前对强大的目标规范和安全框架的迫切需求。]]></description>
      <guid>https://arxiv.org/abs/2501.16513</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士 (LLM) 对阿拉伯语论文的评分标准如何？</title>
      <link>https://arxiv.org/abs/2501.16516</link>
      <description><![CDATA[arXiv:2501.16516v1 公告类型：新
摘要：本研究使用 AR-AES 数据集评估了最先进的大型语言模型 (LLM)（包括 ChatGPT、Llama、Aya、Jais 和 ACEGPT）在阿拉伯语自动作文评分 (AES) 任务中的有效性。它探索了各种评估方法，包括零样本、少量样本上下文学习和微调，并通过在提示中包含标记指南来检查指令遵循能力的影响。实施了一种混合语言提示策略，将英语提示与阿拉伯语内容相结合，以提高模型的理解力和性能。在测试的模型中，ACEGPT 在整个数据集中表现出最强的性能，实现了 0.67 的二次加权 Kappa (QWK)，但不如基于 BERT 的较小模型，QWK 为 0.88。该研究确定了法学硕士在处理阿拉伯语方面面临的挑战，包括标记复杂性和更高的计算要求。不同课程之间的表现差异凸显了对能够处理不同评估格式的自适应模型的需求，并强调了有效的提示工程对提高法学硕士产出的积极影响。据我们所知，这项研究是第一个使用真实的学生数据对多个生成式大型语言模型 (LLM) 在阿拉伯语论文上的表现进行实证评估的研究。]]></description>
      <guid>https://arxiv.org/abs/2501.16516</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>示例编程与历史语言学的结合：基于大型语言模型的合理规律归纳方法</title>
      <link>https://arxiv.org/abs/2501.16524</link>
      <description><![CDATA[arXiv:2501.16524v1 公告类型：新
摘要：历史语言学家长期以来一直编写“程序”，通过有序字符串重写函数（称为声音定律）将祖先语言中重建的单词转换为其证明的后代。然而，编写这些程序非常耗时，这促使我们开发自动声音定律归纳 (SLI)，我们在本文中将其表述为使用大型语言模型 (LLM) 的示例编程 (PBE)。虽然 LLM 对于代码生成很有效，但最近的研究表明，PBE 具有挑战性，但可以通过微调来改进，尤其是使用从与评估数据相同的分布中提取的训练数据。在本文中，我们创建了一个概念框架，说明什么是 SLI 的“相似分布”，并提出了四种具有不同程度归纳偏差的合成数据生成方法，以研究什么能带来最佳性能。根据结果​​，我们为 SLI 创建了一个 SOTA 开源模型作为 PBE（通过率为 +6%，参数为第二好的 LLM 的三分之一），并强调了 PBE 研究令人兴奋的未来方向。]]></description>
      <guid>https://arxiv.org/abs/2501.16524</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生物医学领域英语-波兰语法学硕士机器翻译数据过滤技术比较</title>
      <link>https://arxiv.org/abs/2501.16533</link>
      <description><![CDATA[arXiv:2501.16533v1 公告类型：新
摘要：大型语言模型 (LLM) 已成为机器翻译 (MT) 的最新技术，通常在从网络上抓取的大量双语平行语料库上进行训练，其中包含低质量条目和冗余信息，导致巨大的计算挑战。存在各种数据过滤方法来减少数据集大小，但它们的有效性在很大程度上取决于特定的语言对和领域。本文评估了常用的数据过滤技术（例如 LASER、MUSE 和 LaBSE）对生物医学领域英语-波兰语翻译的影响。通过过滤 UFAL 医学语料库，我们创建了不同大小的数据集来微调 mBART50 模型，然后使用 Khresmoi 数据集上的 SacreBLEU 指标对其进行评估，由双语使用者评估翻译质量。我们的结果表明，LASER 和 MUSE 都可以显着减少数据集大小，同时保持甚至提高性能。我们建议使用 LASER，因为它始终优于其他方法并提供最流畅和自然的翻译。]]></description>
      <guid>https://arxiv.org/abs/2501.16533</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>拨号！通过使模型适应方言和使方言适应模型来建模语言连续体</title>
      <link>https://arxiv.org/abs/2501.16581</link>
      <description><![CDATA[arXiv:2501.16581v1 公告类型：新
摘要：世界上大多数语言和方言资源匮乏，缺乏主流机器翻译 (MT) 模型的支持。然而，其中许多语言和方言都有一个密切相关的高资源语言 (HRL) 邻居，并且在语言规则上与它不同。这强调了模型对方言变异的稳健性和跨语言泛化到 HRL 方言连续体的重要性。我们提出了 DialUp，它包括一种训练时间技术，用于将预训练模型适应方言数据 (M-&gt;D)，以及一种推理时间干预，使方言数据适应模型专业知识 (D-&gt;M)。M-&gt;D 通过接触体现方言变异语言机制的合成数据，诱导模型对潜在看不见和未知方言的稳健性，而 D-&gt;M 处理已知目标方言的方言分歧。这些方法对来自四个语系的几种方言表现出了显著的性能提升，对另外两个语系也表现出了适度的性能提升。我们还进行了特征和错误分析，结果表明，机器翻译性能基线较低的语言变体更有可能从这些方法中受益。]]></description>
      <guid>https://arxiv.org/abs/2501.16581</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>资源受限的 NLP 系统中幻觉检测的少样本优化框架</title>
      <link>https://arxiv.org/abs/2501.16616</link>
      <description><![CDATA[arXiv:2501.16616v1 公告类型：新
摘要：文本生成中的幻觉检测仍然是自然语言处理 (NLP) 系统面临的持续难题，经常导致机器翻译和定义建模等应用中的输出不可靠。现有方法面临着数据稀缺和未标记数据集的局限性，正如 SemEval-2024 上的 SHROOM 共享任务所强调的那样。在这项工作中，我们提出了一个新颖的框架来应对这些挑战，引入 DeepSeek Few-shot 优化，通过迭代提示工程来增强弱标签生成。我们通过重组数据以与指令生成模型保持一致，获得了高质量的注释，从而大大提高了下游模型的性能。我们进一步在这些优化的注释上微调了 Mistral-7B-Instruct-v0.3 模型，使其能够在资源有限的环境中准确检测幻觉。将此微调模型与集成学习策略相结合，我们的方法在测试集上实现了 85.5% 的准确率，为 SHROOM 任务树立了新的标杆。这项研究证明了数据重构、少量优化和微调在为资源受限的 NLP 系统构建可扩展且强大的幻觉检测框架方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.16616</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CHiP：面向多模态 LLM 的跨模态分层直接偏好优化</title>
      <link>https://arxiv.org/abs/2501.16629</link>
      <description><![CDATA[arXiv:2501.16629v1 公告类型：新
摘要：尽管多模态大型语言模型 (MLLM) 具有令人印象深刻的功能，但它们仍然难以应对幻觉。最近的研究试图通过将直接偏好优化 (DPO) 应用于多模态场景来缓解这种情况，使用来自基于文本的响应的偏好对。然而，我们对表示分布的分析表明，多模态 DPO 难以对齐图像和文本表示，也难以区分幻觉和非幻觉描述。为了应对这些挑战，在这项工作中，我们提出了一种跨模态分层直接偏好优化 (CHiP) 来解决这些限制。我们在 DPO 框架内引入了一个视觉偏好优化模块，使 MLLM 能够同时从文本和视觉偏好中学习。此外，我们提出了一个分层文本偏好优化模块，允许模型在多个粒度级别捕获偏好，包括响应、段和标记级别。我们通过定量和定性分析对 CHiP 进行了评估，多个基准测试的结果证明了其在减少幻觉方面的有效性。在 Object HalBench 数据集上，CHiP 在减少幻觉方面的表现优于 DPO，基于基础模型 Muffin 和 LLaVA 模型，相对分数分别提高了 52.7% 和 55.5%。我们公开了所有数据集和代码：https://github.com/LVUGAI/CHiP。]]></description>
      <guid>https://arxiv.org/abs/2501.16629</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>我们为什么笑？自发文本对话中可笑语境的注释和分类生成</title>
      <link>https://arxiv.org/abs/2501.16635</link>
      <description><![CDATA[arXiv:2501.16635v1 公告类型：新
摘要：笑声是人类互动中多方面的交流信号，但在对话中识别笑声对对话式人工智能系统提出了重大挑战。本研究通过注释日语自发文本对话数据中的可笑语境并开发分类法来对此类语境的根本原因进行分类来解决这一挑战。最初，多个注释者使用二元决策（可笑或不可笑）手动标记可笑语境。随后，使用 LLM 为可笑语境的二元注释生成解释，然后将其归类为十个类别的分类法，包括“同理心和亲和力”和“幽默和惊讶”，突出了引人发笑的场景的多样性。该研究还评估了 GPT-4 在识别可笑语境的大多数标签方面的表现，F1 得分为 43.14%。这些发现为对话式人工智能的进步做出了贡献，为更细致入微的识别和笑声产生奠定了基础，最终促进了更自然、更具吸引力的人机互动。]]></description>
      <guid>https://arxiv.org/abs/2501.16635</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态多方对话中收件人识别的 LLM 基准</title>
      <link>https://arxiv.org/abs/2501.16643</link>
      <description><![CDATA[arXiv:2501.16643v1 公告类型：新
摘要：处理多方对话是推进口头对话系统的重要一步，需要开发特定于多方交互的任务。为了应对这一挑战，我们正在构建一个多模态多方对话语料库，其中包含三方（三方参与者）讨论。本文重点关注收件人识别任务，确定下一个对话轮次的对象，这是多方对话系统独有的关键组成部分。语料库的一个子集标注了收件人信息，表明在约 20% 的对话轮次中会指明明确的收件人。为了评估任务的复杂性，我们对大型语言模型（GPT-4o）在收件人识别方面的表现进行了基准测试。结果表明，GPT-4o 的准确率仅略高于偶然性，这凸显了多方对话中收件人识别的挑战。这些发现强调了进一步研究的必要性，以增强大型语言模型理解和驾驭多方对话动态复杂性的能力。]]></description>
      <guid>https://arxiv.org/abs/2501.16643</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DOCS：量化权重相似度以深入了解大型语言模型</title>
      <link>https://arxiv.org/abs/2501.16650</link>
      <description><![CDATA[arXiv:2501.16650v1 公告类型：新
摘要：我们引入了一种新指标，即余弦相似度分布 (DOCS)，用于定量评估大型语言模型 (LLM) 中权重矩阵之间的相似性，旨在促进对其复杂架构的分析。利用 DOCS，我们的分析揭示了最新开源 LLM 中有趣的模式：相邻层经常表现出较高的权重相似性并倾向于形成聚类，这表明深度功能专业化。此外，我们证明了 DOCS 在量化正交矩阵的相似性方面在理论上是有效的，鉴于正交初始化在 LLM 中的普遍性，这是一个至关重要的方面。这项研究有助于更深入地了解 LLM 架构和行为，为开发更高效、更可解释的模型提供了具有潜在影响的工具。]]></description>
      <guid>https://arxiv.org/abs/2501.16650</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型批评家用于无执行代码更改评估</title>
      <link>https://arxiv.org/abs/2501.16655</link>
      <description><![CDATA[arXiv:2501.16655v1 公告类型：新
摘要：大型语言模型 (LLM) 通过多步骤基于 LLM 的代理工作流为自动化软件工程任务（例如错误修复、功能添加等）提供了一种有前途的方法。但是，用于评估此类工作流的现有指标（主要是构建状态和偶尔的日志分析）过于稀疏，并且无法提供评估所做更改质量所需的信息。在这项工作中，我们设计了基于 LLM 的批评者，以得出结构良好且严格的中间/步骤级、无执行评估代理，用于 repo 级代码更改。重要的是，我们假设可以访问问题的黄金测试补丁（即引用感知）来评估生成的补丁的语义和可执行性。以黄金测试补丁为参考，我们预测所有编辑位置的可执行性，F1 得分为 91.6%，综合起来，我们可以预测 SWE-bench 中 84.8% 实例的构建状态。具体来说，这种以执行为重点的 LLM 评论家比其他无参考和参考感知的 LLM 评论家高出 38.9% 到 72.5%。此外，我们在比较不同代理工作流生成的补丁时展示了这种参考感知框架的实用性。最后，我们开源了为该项目开发的库，允许进一步用于其他代理工作流或其他基准测试。源代码可在 https://github.com/amazon-science/code-agent-eval 获得。]]></description>
      <guid>https://arxiv.org/abs/2501.16655</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的多模态标记压缩中的上下文强化</title>
      <link>https://arxiv.org/abs/2501.16658</link>
      <description><![CDATA[arXiv:2501.16658v1 公告类型：新
摘要：有效的标记压缩仍然是扩展模型以处理日益复杂和多样化的数据集的关键挑战。引入了一种基于上下文强化的新机制，通过相互依赖性和语义相关性动态调整标记重要性。这种方法可以大幅减少标记使用量，同时保持信息表示的质量和一致性。结合基于图形的算法和自适应加权，该方法可以捕获文本和多模态数据之间的微妙上下文关系，确保下游任务的稳健对齐和性能。跨不同领域的评估表明，准确性和语义保留显着提高，特别是对于需要详细跨模态交互的任务。内存使用分析表明，尽管有额外的强化过程，但计算效率有所提高，开销却很小。通过错误分布分析进一步验证了性能提升，与基线模型相比，语义损失和句法不一致有所减少。模块化架构确保与各种开源框架兼容，促进了现实世界应用程序的可扩展实现。这些发现强调了情境强化在重新定义代币管理策略和推进大规模模型设计方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.16658</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自动区分任何 LLM 工作流程：告别手动提示</title>
      <link>https://arxiv.org/abs/2501.16673</link>
      <description><![CDATA[arXiv:2501.16673v1 公告类型：新
摘要：大型语言模型 (LLM) 重塑了自然语言处理，为从多跳检索和问答到自主代理工作流的应用程序提供支持。然而，提示工程——制作文本输入以有效指导 LLM 的任务——仍然困难且劳动密集，特别是对于结合多个 LLM 调用与检索和数据格式化等功能操作的复杂管道。我们推出了 LLM-AutoDiff：一种用于自动提示工程 (APE) 的新框架，它将基于文本梯度的方法（例如 Text-Grad）扩展到多组件、潜在循环的 LLM 架构。LLM-AutoDiff 在 AdalFlow 库中实现，将每个文本输入视为可训练参数，并使用冻结的后向引擎 LLM 来生成类似于文本梯度的反馈——以指导迭代提示更新。与之前的单节点方法不同，LLM-AutoDiff 本质上可以容纳功能节点，在重复调用（例如多跳循环）中保留时间顺序行为，并通过隔离不同的子提示（指令、格式或少数样本示例）来解决“中间丢失”问题。它通过选择性梯度计算专注于容易出错的样本，进一步提高了训练效率。在各种任务中，包括单步分类、基于多跳检索的 QA 和代理驱动的管道，LLM-AutoDiff 在准确性和训练成本方面始终优于现有的文本梯度基线。通过以图为中心的视角统一提示优化，LLM-AutoDiff 为扩展和自动化 LLM 工作流程提供了一个强大的新范例 - 反映了自动微分库长期以来在神经网络研究中发挥的变革性作用。]]></description>
      <guid>https://arxiv.org/abs/2501.16673</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MME-Industry：跨行业多模式评估基准</title>
      <link>https://arxiv.org/abs/2501.16688</link>
      <description><![CDATA[arXiv:2501.16688v1 公告类型：新
摘要：随着多模态大型语言模型 (MLLM) 的快速发展，出现了许多评估基准。然而，对它们在不同工业应用中的表现的全面评估仍然有限。在本文中，我们介绍了 MME-Industry，这是一种专门为在工业环境中评估 MLLM 而设计的新基准。该基准涵盖 21 个不同的领域，包含 1050 个问答对，每个领域 50 个问题。为了确保数据完整性并防止公共数据集的潜在泄漏，所有问答对都是由领域专家手工制作和验证的。此外，通过结合可以直接回答的非 OCR 问题以及需要专业领域知识的任务，基准的复杂性得到了有效增强。此外，我们提供了基准的中文和英文版本，可以对这些语言中的 MLLM 功能进行比较分析。我们的研究结果为 MLLM 的实际工业应用提供了宝贵的见解，并为未来的模型优化研究指明了有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2501.16688</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>3D-MoE：通过整流流实现 3D 视觉和姿势扩散的混合专家多模态 LLM</title>
      <link>https://arxiv.org/abs/2501.16698</link>
      <description><![CDATA[arXiv:2501.16698v1 公告类型：新
摘要：3D 视觉和空间推理长期以来被认为是准确感知三维世界的首选，尤其是与基于 2D 图像的传统视觉推理相比。由于收集高质量 3D 数据的困难，该领域的研究最近才开始发展。随着强大的大型语言模型 (LLM) 的出现，用于 3D 视觉的多模态 LLM 在过去几年中得到了开发。然而，这些模型中的大多数主要关注 3D 数据的视觉编码器。在本文中，我们建议将现有的密集激活的 LLM 转换为混合专家 (MoE) 模型，这些模型已被证明对多模态数据处理有效。除了利用这些模型的指令跟踪能力之外，我们还通过连接采用新型整流流扩散调度器的扩散头 Pose-DiT 进一步实现了具体任务规划。在 3D 问答和任务规划任务上的实验结果表明，我们的 3D-MoE 框架以更少的激活参数实现了更高的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.16698</guid>
      <pubDate>Wed, 29 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>