<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 24 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>尝试使用多模态信息预测印度 IPO 的成功率</title>
      <link>https://arxiv.org/abs/2412.16174</link>
      <description><![CDATA[arXiv:2412.16174v1 公告类型：新 
摘要：随着印度经济的持续增长，首次公开募股 (IPO) 已成为一种受欢迎的投资渠道。随着现代技术简化投资，越来越多的投资者有兴趣在认购 IPO 时做出数据驱动的决策。在本文中，我们描述了一种基于机器学习和自然语言处理的方法来评估 IPO 是否会成功。我们广泛研究了 IPO 申请招股说明书中提到的各种事实、宏观经济因素、市场条件、灰色市场价格等对 IPO 成功的影响。我们创建了两个与印度公司 IPO 相关的新数据集。最后，我们研究了如何使用来自多种模态（文本、图像、数字和分类特征）的信息来估计 IPO 上市日股票开盘价、最高价和收盘价的方向和低估价。]]></description>
      <guid>https://arxiv.org/abs/2412.16174</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多头注意力去偏和对比学习用于缓解自然语言推理中的数据集伪影</title>
      <link>https://arxiv.org/abs/2412.16194</link>
      <description><![CDATA[arXiv:2412.16194v1 公告类型：新
摘要：虽然自然语言推理 (NLI) 模型在基准数据集上取得了很高的性能，但人们仍然担心它们是否真正捕捉到了预期的任务，或者在很大程度上利用了数据集工件。通过对斯坦福自然语言推理 (SNLI) 数据集的详细分析，我们发现了各种类型的工件及其相互作用的复杂模式，从而开发了我们新颖的结构去偏方法。我们对 9,782 个验证示例的细粒度分析揭示了四大类工件：基于长度的模式、词汇重叠、子集关系和否定模式。我们的多头去偏架构在所有偏差类别中都取得了显著的改进：长度偏差准确率从 86.03% 提高到 90.06%，重叠偏差从 91.88% 提高到 93.13%，子集偏差从 95.43% 提高到 96.49%，否定偏差从 88.69% 提高到 94.64%。总体而言，我们的方法将错误率从 14.19% 降低到 10.42%，同时在无偏示例上保持高性能。对 1,026 个错误案例的分析表明，在处理中性关系方面取得了显著的进步，而中性关系传统上是 NLI 系统最具挑战性的领域之一。]]></description>
      <guid>https://arxiv.org/abs/2412.16194</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用富有表现力的叙述故事来解码心理健康文本分类中的语言细微差别</title>
      <link>https://arxiv.org/abs/2412.16302</link>
      <description><![CDATA[arXiv:2412.16302v1 公告类型：新
摘要：NLP 的最新进展激发了人们对分析社交媒体文本数据以识别表明心理健康问题的语言特征的极大兴趣。然而，表达性叙事故事 (ENS) 领域——提供丰富心理见解的深度个人和情感叙事——仍未得到充分探索。这项研究利用来自 Reddit 的数据集弥补了这一差距，重点关注有和没有自称抑郁症的个人的 ENS。我们的研究评估了高级语言模型 BERT 和 MentalBERT 与传统模型的效用。我们发现传统模型对明确主题相关词的缺失很敏感，这可能会危及它们将应用扩展到缺乏明确心理健康术语的 ENS 的潜力。尽管 MentalBERT 旨在更好地处理精神病学背景，但它表现出对特定主题词的依赖性，以提高分类准确性，这引起了人们对其在明确的心理健康术语稀疏时的应用的担忧（P 值 &lt;0.05）。相比之下，BERT 对 ENS 中主题词缺失的敏感度极小，表明其具有理解更深层次语言特征的卓越能力，使其在实际应用中更有效。BERT 和 MentalBERT 都擅长识别语言细微差别，即使在叙述顺序被打乱的情况下也能保持分类准确性。这种弹性具有统计学意义，句子改组对模型性能有显著影响（P 值 &lt;0.05），在有和没有心理健康声明的个体之间的 ENS 比较中尤其明显。这些发现强调了探索 ENS 以深入了解心理健康相关叙述的重要性，提倡采用一种细致入微的心理健康文本分析方法，而不仅仅是关键词检测。]]></description>
      <guid>https://arxiv.org/abs/2412.16302</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>审慎协调：推理使语言模型更安全</title>
      <link>https://arxiv.org/abs/2412.16339</link>
      <description><![CDATA[arXiv:2412.16339v1 公告类型：新
摘要：随着大规模语言模型越来越多地影响安全关键领域，确保它们可靠地遵守明确定义的原则仍然是一项基本挑战。我们引入了审议对齐，这是一种新范式，它直接教授模型安全规范，并训练它在回答之前明确回忆和准确推理规范。我们使用这种方法来对齐 OpenAI 的 o 系列模型，并实现了对 OpenAI 安全策略的高度精确遵守，而无需人工编写的思路或答案。审议对齐通过同时提高对越狱的鲁棒性并降低过度拒绝率来推动帕累托前沿，并改善了分布外的泛化。我们证明，对明确指定的策略进行推理可以实现更具可扩展性、可信赖性和可解释性的对齐。]]></description>
      <guid>https://arxiv.org/abs/2412.16339</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人类可读的对抗性提示：使用情境背景调查 LLM 漏洞</title>
      <link>https://arxiv.org/abs/2412.16359</link>
      <description><![CDATA[arXiv:2412.16359v1 公告类型：新
摘要：以前对 LLM 漏洞的研究通常依赖于无意义的对抗性提示，这些提示很容易被自动化方法检测到。我们通过关注人类可读的对抗性提示来解决这一差距，这是一种更现实、更强大的威胁。我们的主要贡献是利用电影脚本创建上下文相关、人类可读的提示的情境驱动攻击，成功欺骗 LLM，对抗性后缀转换将无意义的对抗性后缀转换为有意义的文本，以及带有 p 核采样的 AdvPrompter，这是一种生成多样化、人类可读的对抗性后缀的方法，可提高 GPT-3.5 和 Gemma 7B 等模型的攻击效果。我们的研究结果表明，LLM 可能会被老练的对手欺骗，使用人类可读的对抗性提示产生有害的反应，并且在强大的 LLM 方面还有改进的空间。]]></description>
      <guid>https://arxiv.org/abs/2412.16359</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>第一届低资源语言模型研讨会 (LoResLM 2025) 概述</title>
      <link>https://arxiv.org/abs/2412.16365</link>
      <description><![CDATA[arXiv:2412.16365v1 公告类型：新 
摘要：第一届低资源语言语言模型研讨会 (LoResLM 2025) 与第 31 届国际计算语言学会议 (COLING 2025) 在阿拉伯联合酋长国阿布扎比举行。本次研讨会的主要目的是为研究人员提供一个论坛，分享和讨论他们正在进行的语言模型 (LM) 研究，重点关注低资源语言，紧随神经语言模型的最新进展及其对高资源语言的语言偏见。LoResLM 2025 引起了自然语言处理 (NLP) 社区的极大兴趣，从 52 篇提交的论文中选出了 35 篇被接受的论文。这些贡献涵盖了来自八个语系和 13 个不同研究领域的广泛低资源语言，为未来的可能性铺平了道路，并促进了 NLP 的语言包容性。]]></description>
      <guid>https://arxiv.org/abs/2412.16365</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态大型语言模型在自动驾驶中的应用</title>
      <link>https://arxiv.org/abs/2412.16410</link>
      <description><![CDATA[arXiv:2412.16410v1 公告类型：新
摘要：在这个技术进步的时代，人们正在实施多种尖端技术来增强自动驾驶 (AD) 系统，重点是提高复杂驾驶环境中的安全性、效率和适应性。然而，AD 仍然面临一些问题，包括性能限制。为了解决这个问题，我们对实施多模态大型语言模型进行了深入研究。我们构建了一个虚拟问答 (VQA) 数据集来微调模型并解决 MLLM 在 AD 上性能不佳的问题。然后，我们通过场景理解、预测和决策来分解 AD 决策过程。思路链已被用来更完美地做出决策。我们的实验和对自动驾驶的详细分析表明了 MLLM 对 AD 的重要性。]]></description>
      <guid>https://arxiv.org/abs/2412.16410</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>信息技术助理：用于信息技术门户网站查询的多模式对话代理</title>
      <link>https://arxiv.org/abs/2412.16412</link>
      <description><![CDATA[arXiv:2412.16412v1 公告类型：新
摘要：这项初步研究介绍了 InfoTech Assistant 的开发，这是一个领域特定的多模式聊天机器人，旨在解决桥梁评估和基础设施技术中的查询。通过集成 Web 数据抓取、大型语言模型 (LLM) 和检索增强生成 (RAG)，InfoTech Assistant 提供准确且与上下文相关的响应。数据（包括文本描述和图像）来自 InfoTechnology 网站上的公开文档，并以 JSON 格式组织以方便高效查询。该系统的架构包括一个基于 HTML 的界面和一个通过 LLM Studio 连接到 Llama 3.1 模型的 Flask 后端。评估结果显示，特定领域任务的准确率约为 95%，高相似度得分证实了响应匹配的质量。这种 RAG 增强设置使 InfoTech Assistant 能够处理复杂的多模式查询，在其响应中提供文本和视觉信息。 InfoTech Assistant 作为基础设施专业人员的可靠工具表现出强大的潜力，在其特定领域的输出中提供高准确性和相关性。]]></description>
      <guid>https://arxiv.org/abs/2412.16412</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>技术报告：日语临床和医学的小语言模型</title>
      <link>https://arxiv.org/abs/2412.16423</link>
      <description><![CDATA[arXiv:2412.16423v1 公告类型：新
摘要：本报告介绍了一种用于日语临床和医学的小型语言模型 (SLM)，名为 NCVC-slm-1。这个 1B 参数模型是使用被归类为高质量的日语文本进行训练的。此外，NCVC-slm-1 还针对包括各种疾病、药物和检查在内的临床和医学内容进行了增强。使用精心设计的预处理、专门的形态分析器和标记器，这个小而轻量的模型不仅可以生成文本，而且还表明了理解临床和医学文本的可行性。与其他大型语言模型相比，微调的 NCVC-slm-1 在 JMED-LLM 的 8 个任务中的 6 个任务中表现出最高分数。根据这一结果，SLM 表明了在临床和医学领域执行多项下游任务的可行性。希望NCVC-slm-1能够为临床和医学领域的发展和加速做出贡献，并拥有美好的未来。]]></description>
      <guid>https://arxiv.org/abs/2412.16423</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对话中情绪识别的有效上下文建模框架</title>
      <link>https://arxiv.org/abs/2412.16444</link>
      <description><![CDATA[arXiv:2412.16444v1 公告类型：新
摘要：对话中的情感识别 (ERC) 有助于更深入地理解对话中说话者在每句话中传达的情感。最近，图神经网络 (GNN) 已经展示了它们在捕获数据关系方面的优势，特别是在上下文信息建模和多模态融合方面。然而，现有的方法往往难以完全捕捉多种模态和对话上下文之间的复杂交互，从而限制了它们的表现力。为了克服这些限制，我们提出了 ConxGNN，这是一种基于 GNN 的新型框架，旨在捕获对话中的上下文信息。ConxGNN 具有两个关键的并行模块：一个多尺度异构图，用于捕捉话语对情绪变化的不同影响，以及一个超图，用于建模模态和话语之间的多元关系。这些模块的输出被集成到一个融合层中，其中应用跨模态注意机制来产生上下文丰富的表示。此外，ConxGNN 通过在损失函数中加入重新加权方案来解决识别少数或语义相似的情绪类别的挑战。在 IEMOCAP 和 MELD 基准数据集上的实验结果证明了我们方法的有效性，与之前的基线相比，我们实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.16444</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于BERT-fasttext模型的暴力文本检测系统研究</title>
      <link>https://arxiv.org/abs/2412.16455</link>
      <description><![CDATA[arXiv:2412.16455v1 Announce Type: new 
摘要：在当今数字化时代，互联网已经成为人们生活、工作、信息交流不可或缺的平台，然而网络环境下暴力文本泛滥的问题也随之出现，带来了诸多负面影响。针对这种情况，构建一套有效的暴力文本截断系统尤为重要。基于BERT-fasttext模型的暴力文本截断研究具有重要的意义。BERT是一个预训练的语言模型，具有较强的自然语言理解能力，可以深度挖掘和分析文本语义信息；Fasttext本身是一个高效的文本分类工具，复杂度低，效果好，可以为文本处理快速提供基本判断。将二者结合起来，应用到暴力文本截断系统中，一方面可以精准识别暴力文本，另一方面可以高效合理地截断内容，防止有害信息在网络上肆意传播。与单一BERT模型和fasttext相比，准确率分别提升了0.7%和0.8%。通过该模型，有助于净化网络环境，维护网络信息健康，为网民营造积极、文明、和谐的网络交流空间，推动社交、信息传播等方面朝着更加良性的方向发展。]]></description>
      <guid>https://arxiv.org/abs/2412.16455</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Transducer-Llama：将 LLM 集成到可流式传输的基于传感器的语音识别中</title>
      <link>https://arxiv.org/abs/2412.16464</link>
      <description><![CDATA[arXiv:2412.16464v1 公告类型：新
摘要：虽然大型语言模型 (LLM) 已应用于自动语音识别 (ASR)，但使模型可流式传输仍然是一个挑战。本文提出了一种新颖的模型架构 Transducer-Llama，将 LLM 集成到分解式 Transducer (FT) 模型中，自然地实现了流式传输功能。此外，考虑到 LLM 的词汇量大可能会导致数据稀疏问题并增加口语系统的训练成本，本文介绍了一种有效的词汇自适应技术，以使 LLM 与语音系统词汇保持一致。结果表明，使用 RNN-T 损失直接优化具有强大的预训练 LLM 预测器的 FT 模型比较小的预训练 LM 预测器产生了一些但有限的改进。因此，本文提出了一种弱到强 LM 交换策略，在 RNN-T 损失训练期间使用弱 LM 预测器，然后用强 LLM 替换它。在 LM 替换之后，使用最小词错误率 (MWER) 损失来微调 LLM 预测器与 Transducer-Llama 模型的集成。在 LibriSpeech 和大规模多语言 LibriSpeech 语料库上进行的实验表明，所提出的流式 Transducer-Llama 方法在强 FT 基线上实现了 17% 的相对 WER 减少 (WERR)，在 RNN-T 基线上实现了 32% 的 WERR。]]></description>
      <guid>https://arxiv.org/abs/2412.16464</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>链式调节导致偏见遗忘</title>
      <link>https://arxiv.org/abs/2412.16469</link>
      <description><![CDATA[arXiv:2412.16469v1 公告类型：新
摘要：大型语言模型 (LLM) 通常会针对下游任务进行微调，但这可能会降低之前训练期间学到的能力。这种现象通常被称为灾难性遗忘，对部署模型的安全性具有重要的潜在影响。在这项工作中，我们首先表明，在下游任务上训练的模型比以相反顺序训练的模型更容易忘记它们的安全性调整。其次，我们表明遗忘对某些群体的安全信息产生了不成比例的影响。为了量化这种现象，我们定义了一个新的指标，我们称之为有偏见的遗忘。我们对任务排序对遗忘的影响进行了系统评估，并应用了有助于模型从观察到的遗忘中恢复的缓解措施。我们希望我们的研究结果能够更好地为在持续学习环境中链接 LLM 微调的方法提供信息，从而能够训练更安全、毒性更小的模型。]]></description>
      <guid>https://arxiv.org/abs/2412.16469</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估大型语言模型在科学声明检测和分类中的性能</title>
      <link>https://arxiv.org/abs/2412.16486</link>
      <description><![CDATA[arXiv:2412.16486v1 公告类型：新
摘要：在 COVID-19 大流行期间，社交媒体的广泛影响是一把双刃剑，它既增强了沟通，又传播了错误信息。这场 \textit{数字信息流行病} 凸显了对能够辨别和传播事实内容的自动化工具的迫切需求。本研究评估了大型语言模型 (LLM) 作为缓解 Twitter 等平台上错误信息的创新解决方案的有效性。LLM（例如 OpenAI 的 GPT 和 Meta 的 LLaMA）提供了一种预先训练的、适应性强的方法，可绕过与传统机器学习模型相关的大量训练和过度拟合问题。我们评估了 LLM 在检测和分类与 COVID-19 相关的科学主张方面的表现，从而促进了明智的决策。我们的研究结果表明，LLM 作为自动事实核查工具具有巨大的潜力，尽管该领域的研究尚处于起步阶段，需要进一步探索。我们使用专门的数据集对 LLM 的表现进行比较分析，并提出了其在公共卫生传播中的应用框架。]]></description>
      <guid>https://arxiv.org/abs/2412.16486</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实时孟加拉手语翻译</title>
      <link>https://arxiv.org/abs/2412.16497</link>
      <description><![CDATA[arXiv:2412.16497v1 公告类型：新
摘要：人体通过各种有意义的手势进行交流，使用手势进行手语交流就是一个突出的例子。孟加拉手语翻译 (BSLT) 旨在弥合聋哑群体的沟通鸿沟。我们的方法包括使用 Mediapipe Holistic 收集关键点、使用 LSTM 架构进行数据训练以及使用计算机视觉进行实时手语检测，准确率为 94%。关键词=循环神经网络、LSTM、计算机视觉、孟加拉字体。]]></description>
      <guid>https://arxiv.org/abs/2412.16497</guid>
      <pubDate>Tue, 24 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>