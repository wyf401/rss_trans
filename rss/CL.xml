<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 14 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>增强心理治疗咨询：利用大型语言模型进行咨询对话的数据增强管道</title>
      <link>https://arxiv.org/abs/2406.08718</link>
      <description><![CDATA[arXiv:2406.08718v1 公告类型：新
摘要：我们引入了一个利用大型语言模型 (LLM) 将单轮心理治疗咨询会话转变为多轮互动的管道。虽然存在针对精神障碍患者的人工智能支持的在线咨询服务，但它们往往受到多轮训练数据集有限的限制，并且经常无法充分利用治疗师的专业知识。我们提出的管道有效地解决了这些限制。该管道包括两个主要步骤：1）信息提取和 2）多轮咨询生成。每个步骤都经过精心设计，以从可用数据集中提取和生成全面的多轮咨询对话。零样本和少样本生成场景的实验结果表明，我们的方法显着增强了 LLM 在心理健康咨询背景下产生更高质量多轮对话的能力。我们的管道和数据集是公开的https://github.com/jwkim-chat/A-Data-Augmentation-Pipeline-Leveraging-Large-Language-Models-for-Counseling-Conversations。]]></description>
      <guid>https://arxiv.org/abs/2406.08718</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>分析大型语言模型以进行课堂讨论评估</title>
      <link>https://arxiv.org/abs/2406.08680</link>
      <description><![CDATA[arXiv:2406.08680v1 公告类型：新
摘要：借助大型语言模型 (LLM) 等新的 NLP 进步，自动评估课堂讨论质量变得越来越可行。在这项工作中，我们研究了 2 个 LLM 的评估性能如何与可能影响性能的 3 个因素相互作用：任务制定、上下文长度和少量示例。我们还探讨了 2 个 LLM 的计算效率和预测一致性。我们的结果表明，上述 3 个因素确实会影响测试的 LLM 的性能，并且一致性和性能之间存在关系。我们推荐一种基于 LLM 的评估方法，该方法在预测性能、计算效率和一致性方面具有良好的平衡。]]></description>
      <guid>https://arxiv.org/abs/2406.08680</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:47 GMT</pubDate>
    </item>
    <item>
      <title>mOSCAR：大规模多语言、多模态文档级语料库</title>
      <link>https://arxiv.org/abs/2406.08707</link>
      <description><![CDATA[arXiv:2406.08707v1 公告类型：新
摘要：多模态大型语言模型 (mLLM) 是在大量文本图像数据上进行训练的。虽然大多数 mLLM 仅在类似字幕的数据上进行训练，但 Alayrac 等人 [2022] 表明，在交错的文本和图像序列上对它们进行额外训练可以导致上下文学习能力的出现。然而，他们使用的数据集 M3W 不是公开的，而且只有英文版。有人试图重现他们的结果，但发布的数据集只有英文版。相比之下，当前的多语言和多模态数据集要么仅由类似字幕的数据组成，要么由中等规模或完全私有的数据组成。这限制了对世界上其他 7,000 种语言的 mLLM 研究。因此，我们引入了 mOSCAR，据我们所知，这是从网络上抓取的第一个大规模多语言和多模态文档语料库。它涵盖 163 种语言、3.15 亿份文档、2140 亿个标记和 12 亿张图像。我们仔细执行了一系列筛选和评估步骤，以确保 mOSCAR 足够安全、多样化且质量良好。我们还训练了两种类型的多语言模型来证明 mOSCAR 的优势：(1) 在 mOSCAR 子集和字幕数据上训练的模型和 (2) 仅在字幕数据上训练的模型。在 mOSCAR 上额外训练的模型在各种多语言图像文本任务和基准测试中显示出小样本学习性能的大幅提升，证实了之前对仅限英语的 mLLM 的发现。]]></description>
      <guid>https://arxiv.org/abs/2406.08707</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:47 GMT</pubDate>
    </item>
    <item>
      <title>HelpSteer2：用于训练表现最佳的奖励模型的开源数据集</title>
      <link>https://arxiv.org/abs/2406.08673</link>
      <description><![CDATA[arXiv:2406.08673v1 公告类型：新
摘要：高质量的偏好数据集对于训练奖励模型至关重要，这些模型可以有效地指导大型语言模型 (LLM) 生成符合人类偏好的高质量响应。随着 LLM 变得更强大、更一致，需要更新获得许可的偏好数据集（例如 Open Assistant、HH-RLHF 和 HelpSteer）以保持对奖励建模的有效性。从专有 LLM（例如 GPT-4）中提取偏好数据的方法受到模型提供商对商业使用的限制。为了提高生成的响应和属性标记质量，我们发布了获得许可的偏好数据集 HelpSteer2（CC-BY-4.0）。使用在 HelpSteer2 上训练的强大内部基础模型，我们能够在 Reward-Bench 的主要数据集上获得 SOTA 分数（92.0%），截至 2024 年 6 月 12 日，其表现优于目前列出的开放和专有模型。值得注意的是，HelpSteer2 仅包含一万个响应对，比现有的偏好数据集（例如 HH-RLHF）少一个数量级，这使得它成为训练奖励模型的高效方法。我们进行了广泛的实验，表明使用 HelpSteer2 训练的奖励模型在对齐 LLM 方面是有效的。特别是，我们提出了 SteerLM 2.0，这是一种模型对齐方法，可以有效利用我们的奖励模型预测的丰富多属性分数。HelpSteer2 可在 https://huggingface.co/datasets/nvidia/HelpSteer2 获得，代码可在 https://github.com/NVIDIA/NeMo-Aligner 获得]]></description>
      <guid>https://arxiv.org/abs/2406.08673</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:46 GMT</pubDate>
    </item>
    <item>
      <title>Mistral-C2F：用于 RLHF 和有效合并 LLM 中的分析和推理增强的粗到精执行器</title>
      <link>https://arxiv.org/abs/2406.08657</link>
      <description><![CDATA[arXiv:2406.08657v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 取得了进展，例如 GPT-4 和 Claude 等模型，但 Llama 和 Mistral 等规模较小的 LLM 往往难以生成深入而连贯的对话。本文提出了一种新颖的两步粗到细 Actor 模型，以解决小型 LLM 在对话和分析能力方面的固有局限性。我们的方法从基于策略的粗略 Actor 开始，采用我们称之为“连续最大化”的技术。粗略 Actor 建立了一个增强的、知识丰富的池，善于与人类在分析和推理中的偏好风格保持一致。通过 RLHF 过程，它采用了连续最大化，这是一种动态和自适应地扩展输出长度限制的策略，从而能够生成更详细和分析性的内容。随后，精细 Actor 细化了这种分析内容，解决了从粗略 Actor 生成过多冗余信息的问题。我们引入了“知识残差合并”方法，精炼来自粗略参与者的内容并将其与现有的指令模型合并，以提高质量、正确性并减少冗余。我们将我们的方法应用于流行的 Mistral 模型，创建了 Mistral-C2F，该模型在 11 个一般语言任务和 MT-Bench 对话任务中表现出色，优于类似规模的模型，甚至具有 13B 和 30B 参数的更大模型。我们的模型显著提高了对话和分析推理能力。]]></description>
      <guid>https://arxiv.org/abs/2406.08657</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:45 GMT</pubDate>
    </item>
    <item>
      <title>经过微调的“小型” LLM（仍然）在文本分类中明显优于零样本生成式 AI 模型</title>
      <link>https://arxiv.org/abs/2406.08660</link>
      <description><![CDATA[arXiv:2406.08660v1 公告类型：新
摘要：生成式人工智能提供了一种简单的、基于提示的替代方案，以微调较小的 BERT 样式 LLM 以用于文本分类任务。这有望消除对手动标记的训练数据和特定于任务的模型训练的需求。然而，像 ChatGPT 这样的工具是否能兑现这一承诺仍是一个悬而未决的问题。在本文中，我们表明，较小的、经过微调的 LLM（仍然）在文本分类中始终如一地显著优于较大的零样本提示模型。我们将三种主要的生成式人工智能模型（带有 GPT-3.5/GPT-4 和 Claude Opus 的 ChatGPT）与几种经过微调的 LLM 进行了比较，涉及多种分类任务（情绪、赞成/反对、情绪、党派立场）和文本类别（新闻、推文、演讲）。我们发现，使用特定于应用程序的训练数据进行微调在所有情况下都能实现卓越的性能。为了让这种方法更容易被更广泛的受众接受，我们在本文的同时也提供了一个易于使用的工具包。我们的工具包附带非技术性的分步指导，使用户能够以最少的技术和计算工作量为任何分类任务选择和微调类似 BERT 的 LLM。]]></description>
      <guid>https://arxiv.org/abs/2406.08660</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:45 GMT</pubDate>
    </item>
    <item>
      <title>自监督语音表征更注重语音而非语义</title>
      <link>https://arxiv.org/abs/2406.08619</link>
      <description><![CDATA[arXiv:2406.08619v1 公告类型：新
摘要：自监督语音模型 (S3M) 已成为语音应用的有效支柱。各种分析表明，S3M 编码了语言属性。在这项工作中，我们寻求对 S3M 中编码的单词级语言属性进行更细粒度的分析。具体来说，我们整理了一个近同音词 (语音相似) 和同义词 (语义相似) 词对的新数据集，并测量了 S3M 词表示对之间的相似性。我们的研究表明，S3M 表示始终且显著地表现出语音相似性而非语义相似性。此外，我们质疑广泛使用的意图分类数据集（例如 Fluent Speech Commands 和 Snips Smartlights）是否足以测量语义能力。我们仅使用单词身份的简单基线超越了基于 S3M 的模型。这证实了我们的发现，并表明这些数据集上的高分并不一定保证语义内容的存在。]]></description>
      <guid>https://arxiv.org/abs/2406.08619</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:44 GMT</pubDate>
    </item>
    <item>
      <title>揭示移民话语中的代码混合模式：自动检测和分析 Reddit 上的在线对话</title>
      <link>https://arxiv.org/abs/2406.08633</link>
      <description><![CDATA[arXiv:2406.08633v1 公告类型：新
摘要：全球移民模式的激增凸显了将移民无缝融入东道社区的必要性，需要包容和值得信赖的公共服务。尽管北欧国家拥有强大的公共部门基础设施，但新移民在获取这些服务时经常遇到障碍，加剧了社会差距并削弱了信任。解决数字不平等和语言多样性是这一努力的重中之重。本文探讨了在 Reddit 等社交媒体平台上与移民相关的话语中使用代码混合（一种在多语言使用者中普遍存在的沟通策略）的情况。我们提出了用于多语言识别代码混合文本的集成学习 (ELMICT)，这是一种旨在自动检测与移民相关的讨论中的代码混合消息的新方法。 ELMICT 利用集成学习技术将多个标记器的输出和预训练语言模型相结合，在识别各种语言和语境中的代码混合方面表现出色（F1 超过 0.95），特别是在跨语言零样本条件下（平均 F1 超过 0.70）。此外，使用 ELMICT 有助于分析与 Reddit 上其他主题类别相比，移民相关主题中代码混合的流行程度，从而揭示移民社区关注的话题。我们的研究结果揭示了移民在社交媒体平台上采用的沟通策略，为包容性数字公共服务和对话系统的发展提供了启示。通过解决本研究中提出的研究问题，我们有助于理解移民话语中的语言多样性，并为在多元文化社会中建立信任的更有效工具铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2406.08633</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:44 GMT</pubDate>
    </item>
    <item>
      <title>逆转遗忘-保留目标：基于 Logit 差异的有效 LLM 忘却学习框架</title>
      <link>https://arxiv.org/abs/2406.08607</link>
      <description><![CDATA[arXiv:2406.08607v1 公告类型：新 
摘要：随着大型语言模型 (LLM) 表现出从文档中学习的广泛能力，LLM 反学习成为一个越来越重要的研究领域，以解决 LLM 在隐私、版权等方面的担忧。传统的 LLM 反学习任务通常涉及两个目标：(1) 目标 LLM 应该忘记指定忘记文档中的知识，(2) 它应该保留 LLM 拥有的其他知识，为此我们假设可以访问少量保留文档。为了实现这两个目标，主流的 LLM 反学习方法引入了一个优化框架，该框架结合了两个目标 - 最大化忘记文档的预测损失，同时最小化保留文档的预测损失，这面临两个挑战，即退化输出和灾难性遗忘。在本文中，我们提出了一种名为 Unlearning from Logit Difference (ULD) 的新型遗忘学习框架，该框架引入了一个辅助 LLM，旨在实现与遗忘目标相反的目标：记住遗忘的文档并遗忘保留的知识。然后，ULD 通过计算目标和辅助 LLM 之间的 logit 差异来得出未学习的 LLM。我们表明，这种逆转的目标将自然地解决上述两个挑战，同时显著提高训练效率。大量实验表明，我们的方法有效地实现了预期的遗忘，同时保留了 LLM 的整体能力，将训练时间缩短了三倍以上。值得注意的是，我们的方法在 ToFU 基准上损失了 0% 的模型效用，而基线方法平均可能牺牲 17% 的效用来实现相当的遗忘质量。我们的代码将在 https://github.com/UCSB-NLP-Chang/ULD 上公开提供。]]></description>
      <guid>https://arxiv.org/abs/2406.08607</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:43 GMT</pubDate>
    </item>
    <item>
      <title>语言模型委员会：通过共识对高度主观任务的基础模型进行基准测试</title>
      <link>https://arxiv.org/abs/2406.08598</link>
      <description><![CDATA[arXiv:2406.08598v1 公告类型：新
摘要：大型语言模型 (LLM) 的快速发展需要强大且具有挑战性的基准。Chatbot Arena 等排行榜根据 LLM 的回答与人类偏好的匹配程度对其进行排名。然而，许多任务（例如与情商、创意写作或说服力相关的任务）都是高度主观的，并且往往缺乏多数人的认同。评委可能对什么是更好的回应存在不可调和的分歧。为了应对在高度主观的任务上对 LLM 进行排名的挑战，我们提出了一个新颖的基准测试框架，即语言模型委员会 (LMC)。LMC 通过民主程序运作：1) 通过平等参与制定测试集，2) 在委员会成员之间进行测试，3) 作为集体陪审团评估答复。我们部署了一个由 20 名最新 LLM 组成的委员会，负责一项开放式情商任务：应对人际困境。我们的结果表明，LMC 产生的排名比任何单个 LLM 评委的排名更具可分离性、更稳健、偏见更少，并且与其他基准相比，与人类建立的排行榜更加一致。]]></description>
      <guid>https://arxiv.org/abs/2406.08598</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:42 GMT</pubDate>
    </item>
    <item>
      <title>端到端论证挖掘作为增强自然语言生成</title>
      <link>https://arxiv.org/abs/2406.08606</link>
      <description><![CDATA[arXiv:2406.08606v1 公告类型：新
摘要：论证挖掘 (AM) 是计算论证的一个重要方面，它涉及论证组件 (AC) 及其相应的论证关系 (AR) 的识别和提取。大多数先前的工作通过将它们划分为多个子任务来解决这些问题。并且可用的端到端设置大多基于依赖性解析方法。这项工作提出了一个基于生成范式的统一端到端框架，其中论证结构被构建为标签增强文本，称为增强自然语言 (ANL)。此外，我们探索了不同类型的标记在解决 AM 任务中的作用。通过不同的基于标记的微调策略，我们通过将标记知识集成到我们的生成模型中进行了广泛的研究。所提出的框架取得了与最先进 (SoTA) 模型相媲美的结果，并优于几个基线。]]></description>
      <guid>https://arxiv.org/abs/2406.08606</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 QLoRA 探索法学硕士中的事实记忆和风格模仿：一项实验研究和质量评估方法</title>
      <link>https://arxiv.org/abs/2406.08582</link>
      <description><![CDATA[arXiv:2406.08582v1 公告类型：新
摘要：有多种方法可以将 LLM 适应不同的领域。最常用的方法是提示、微调和 RAG。在这项工作中，我们探索使用 PEFT 方法之一 QLoRA 调整模型的可能性。该实验旨在根据访谈模拟人类的反应。通过比较风格质量和生成事实的质量来评估模拟质量。]]></description>
      <guid>https://arxiv.org/abs/2406.08582</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:41 GMT</pubDate>
    </item>
    <item>
      <title>CS-Bench：面向计算机科学掌握的大型语言模型综合基准</title>
      <link>https://arxiv.org/abs/2406.08587</link>
      <description><![CDATA[arXiv:2406.08587v1 公告类型：新 
摘要：计算机科学（CS）是人类智能复杂性的体现，深刻推动了人工智能和现代社会的发展。然而，目前的大型语言模型（LLM）社区过于注重分析特定基础技能（例如数学和代码生成）的基准，而忽略了对计算机科学领域的全面评估。为了弥补这一差距，我们推出了 CS-Bench，这是第一个专门用于评估计算机科学领域 LLM 性能的双语（中英）基准。CS-Bench 包含约 5K 精心策划的测试样本，涵盖计算机科学 4 个关键领域的 26 个子领域，涵盖各种任务形式和知识与推理的划分。利用 CS-Bench，我们对 30 多个主流 LLM 进行了全面评估，揭示了 CS 性能与模型规模之间的关系。我们还定量分析了现有 LLM 失败的原因，并强调了改进的方向，包括知识补充和 CS 特定推理。进一步的跨能力实验表明，LLM 在计算机科学方面的能力与其在数学和编码方面的能力之间存在高度相关性。此外，专门从事数学和编码的专家 LLM 在几个 CS 子领域也表现出色。展望未来，我们设想 CS-Bench 将成为 LLM 在 CS 领域应用的基石，并为评估 LLM 的多样化推理能力开辟新途径。CS-Bench 数据和评估代码可在 https://github.com/csbench/csbench 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.08587</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:41 GMT</pubDate>
    </item>
    <item>
      <title>阿拉伯语个性化学习助理的问答 (QA) 模型</title>
      <link>https://arxiv.org/abs/2406.08519</link>
      <description><![CDATA[arXiv:2406.08519v1 公告类型：新
摘要：本文介绍了使用针对阿拉伯语定制的 BERT 转换器为个性化学习助手创建、优化和评估问答 (QA) 模型的过程。该模型特别针对巴勒斯坦课程中的科学教科书进行了微调。我们的方法利用 BERT 的出色功能自动生成科学教育领域问题的正确答案。通过使用巴勒斯坦课程中的 11 年级和 12 年级生物学书籍对模型进行微调，提高了模型理解和提取相关信息的能力。这提高了模型产生启发性反应的效率。精确匹配 (EM) 和 F1 分数指标用于评估模型的性能；结果显示 EM 得分为 20%，F1 得分为 51%。这些发现表明，该模型可以理解并响应巴勒斯坦科学书籍背景下的问题。结果表明，基于 BERT 的 QA 模型有潜力支持学习和理解阿拉伯学生的问题。]]></description>
      <guid>https://arxiv.org/abs/2406.08519</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:40 GMT</pubDate>
    </item>
    <item>
      <title>使用 NLP 技术自动生成阿拉伯语科学测试问题</title>
      <link>https://arxiv.org/abs/2406.08520</link>
      <description><![CDATA[arXiv:2406.08520v1 公告类型：新
摘要：教育评估问题生成是人工智能应用于教育领域中一个不断发展的领域。这些问题生成工具在教育技术领域具有重要意义，例如智能辅导系统和基于对话的平台。评估问题的自动生成需要明确的答案，通常依赖于陈述句中的句法和语义指示，然后将其转换为问题。最近的研究探索了阿拉伯语评估教育问题的生成。报告的性能受到固有错误的不利影响，包括句子解析不准确、名称实体识别问题以及基于规则的问题转换导致的错误。此外，阿拉伯语长句的复杂性也加剧了这些挑战。这项研究提出了一个创新的阿拉伯语问题生成系统，该系统建立在三个阶段的过程之上：关键词和关键短语提取、问题生成和随后的排名。目的是解决与自动生成阿拉伯语评估问题相关的困难。该方法和结果显示，准确率为 83.50%，召回率为 78.68%，Fl 得分为 80.95%，表明该框架效率高。人工评估进一步证实了模型的效率，平均评分为 84%。]]></description>
      <guid>https://arxiv.org/abs/2406.08520</guid>
      <pubDate>Fri, 14 Jun 2024 06:19:40 GMT</pubDate>
    </item>
    </channel>
</rss>