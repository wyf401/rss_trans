<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Tue, 28 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过软对比学习改善多语言一致性</title>
      <link>https://arxiv.org/abs/2405.16155</link>
      <description><![CDATA[arXiv:2405.16155v1 公告类型：新 
摘要：制作良好的多语言句子表示对于在跨语言下游任务中取得高性能至关重要。在这项工作中，我们提出了一种基于预先训练的单语言嵌入模型测量的句子相似性来对齐多语言嵌入的新方法。给定翻译句子对，我们训练多语言模型，使跨语言嵌入之间的相似性遵循单语言教师模型中测量的句子的相似性。我们的方法可以被认为是对比学习，软标签定义为句子之间的相似性。我们对五种语言的实验结果表明，在双文本挖掘任务和 STS 任务的各种基准中，我们的软标签对比损失远远优于传统的硬标签对比损失。此外，对于 Tatoeba 数据集，我们的方法优于现有的多语言嵌入，包括 LaBSE。代码可在 https://github.com/YAI12xLinq-B/IMASCL 获取]]></description>
      <guid>https://arxiv.org/abs/2405.16155</guid>
      <pubDate>Tue, 28 May 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>iREL at SemEval-2024 任务 9：改进脑筋急转弯的传统提示方法</title>
      <link>https://arxiv.org/abs/2405.16129</link>
      <description><![CDATA[arXiv:2405.16129v1 公告类型：新 
摘要：本文描述了我们针对 SemEval-2024 任务 9 的方法：BRAINTEASER：一项违反常识的新颖任务。 BRAINTEASER 任务包括多项选择题问答，旨在评估模型的横向思维能力。它由句子谜题和单词谜题子任务组成，这些子任务需要模型挑战默认的常识性关联并表现出非传统思维。我们提出了一种独特的策略来提高预训练语言模型（特别是 Gemini 1.0 Pro 模型）在这两个子任务中的性能。我们采用静态和动态的小样本提示技术，并引入模型生成的推理策略，利用法学硕士的推理能力来提高性能。我们的方法展示了显着的改进，表明它的表现比基线模型好很多，但表现不如人类注释者，从而凸显了所提出策略的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.16129</guid>
      <pubDate>Tue, 28 May 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行 5W1H 提取</title>
      <link>https://arxiv.org/abs/2405.16150</link>
      <description><![CDATA[arXiv:2405.16150v1 公告类型：新 
摘要：通过 5W1H 框架提取基本新闻元素（\textit{What}、\textit{When}、\textit{Where}、\textit{Why}、\textit{Who} 和 \textit{How}）对于事件提取和文本摘要至关重要。 ChatGPT 等大型语言模型 (LLM) 的出现提供了一个机会，可以通过简单的提示来解决与语言相关的任务，而无需花费太多时间微调模型。虽然 ChatGPT 在处理较长的新闻文本和分析上下文中的特定属性方面遇到了挑战，特别是回答有关 \textit{What}、\textit{Why} 和 \textit{How} 的问题。提取任务的有效性主要取决于高质量的人工注释数据集。然而，缺乏此类 5W1H 提取数据集增加了基于开源 LLM 微调策略的难度。为了解决这些限制，首先，我们基于四个典型新闻语料库（\textit{CNN/DailyMail}、\textit{XSum}、\textit{NYT}、\textit{RA-MDS}）注释高质量的 5W1H 数据集;其次，我们设计了从零镜头/少镜头提示到高效微调的多种策略，以从原始新闻文档中进行5W1H方面的提取。实验结果表明，微调模型在我们的标记数据集上的性能优于 ChatGPT 的性能。此外，我们还通过在目标域语料库（例如 CNN/DailyMail）上测试源域（例如 NYT）模型的 5W1H 提取任务来探索域适应能力。]]></description>
      <guid>https://arxiv.org/abs/2405.16150</guid>
      <pubDate>Tue, 28 May 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>DefSent+：通过将定义句子投影到无限词典条目的准各向同性或各向同性向量空间中来改进语言模型的句子嵌入</title>
      <link>https://arxiv.org/abs/2405.16153</link>
      <description><![CDATA[arXiv:2405.16153v1 公告类型：新 
摘要：本文对之前的会议论文 DefSent 进行了重大改进。先前的研究试图通过将定义句子投影到词典条目的向量空间中来改进语言模型的句子嵌入。我们发现，由于使用语言模型的词嵌入来表示字典条目的方法学限制，这种方法尚未得到充分探索。这导致两个障碍。首先，词典条目受到单词词汇的限制，因此无法充分利用。其次，众所周知，语言模型的语义表示是各向异性的，但不允许对 DefSent 进行预处理词嵌入，因为它的权重在训练期间被冻结并与预测层绑定。在本文中，我们提出了一种新颖的方法来逐步构建不受限制的条目嵌入。因此，定义句子可以投影到无限字典条目的准各向同性或各向同性向量空间中，从而可以获得质量明显更好的句子嵌入。我们将我们的方法缩写为DefSent+（DefSent的增强版），具有以下优点：1）与DefSent相比，测量句子相似度的任务性能显着提高； 2）当使用 DefSent+ 进一步训练 SIMCSE 和 SNCSE 等数据增强模型时，这些方法可以在不使用手动标记数据集的情况下实现测量句子相似性的最先进性能； 3）DefSent+在NLP下游任务的基于特征的传输方面也具有竞争力。]]></description>
      <guid>https://arxiv.org/abs/2405.16153</guid>
      <pubDate>Tue, 28 May 2024 06:18:34 GMT</pubDate>
    </item>
    <item>
      <title>COLT：面向大型语言模型的面向完整性的工具检索</title>
      <link>https://arxiv.org/abs/2405.16089</link>
      <description><![CDATA[arXiv:2405.16089v1 公告类型：新 
摘要：最近，外部工具与大型语言模型（LLM）的集成已成为克服预训练数据固有限制的一种有前途的方法。然而，现实世界的应用程序通常涉及多种工具，由于输入长度和响应时间的限制，将所有工具直接合并到法学硕士中是不可行的。因此，为了充分发挥工具增强法学硕士的潜力，开发有效的工具检索系统至关重要。现有的工具检索方法技术主要依赖于用户查询和工具描述之间的语义匹配，这常常导致冗余工具的选择。因此，这些方法无法提供解决法学硕士遇到的多方面问题所需的一整套多样化工具。在本文中，我们提出了一种新颖的与模型无关的基于协作学习的工具检索方法 COLT，该方法不仅捕获用户查询和工具描述之间的语义相似性，而且还考虑了工具的协作信息。具体来说，我们首先微调基于 PLM 的检索模型，以在语义学习阶段捕获查询和工具之间的语义关系。随后，我们在查询、场景和工具之间构建了三个二部图，并引入了双视图图协作学习框架来捕获协作学习阶段工具之间复杂的协作关系。对开放基准测试和新引入的 ToolLens 数据集的大量实验表明，COLT 实现了卓越的性能。值得注意的是，采用我们提出的模型框架的 BERT-mini (11M) 的性能优于 BERT-large (340M)，后者的参数多了 30 倍。此外，我们计划公开发布 ToolLens 数据集以支持工具检索的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2405.16089</guid>
      <pubDate>Tue, 28 May 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>SNOBERT：SNOMED CT 临床术语中临床注释实体链接的基准</title>
      <link>https://arxiv.org/abs/2405.16115</link>
      <description><![CDATA[arXiv:2405.16115v1 公告类型：新 
摘要：从医疗数据（主要由医护人员以自由文本格式存储）中提取和分析见解，由于其非结构化性质而面临重大挑战。由于医学本体的复杂性以及用于训练自然语言处理模型的医学文本的访问受到限制，医学编码是医疗保健中的一个关键过程，其自动化程度仍然很低。在本文中，我们提出了一种方法“SNOBERT”，使用基于 BERT 的模型将临床记录中的文本范围链接到 SNOMED CT 中的特定概念。该方法包括两个阶段：候选选择和候选匹配。这些模型是在最大的公开可用的标记临床记录数据集之一上进行训练的。 SNOBERT 优于其他基于深度学习的经典方法，这一点已被应用的挑战结果所证实。]]></description>
      <guid>https://arxiv.org/abs/2405.16115</guid>
      <pubDate>Tue, 28 May 2024 06:18:33 GMT</pubDate>
    </item>
    <item>
      <title>SPP：大型语言模型的稀疏保留参数高效微调</title>
      <link>https://arxiv.org/abs/2405.16057</link>
      <description><![CDATA[arXiv:2405.16057v1 公告类型：新
摘要：大型语言模型 (LLM) 已成为推动人工智能领域发展的关键，但其巨大的规模对微调和部署都带来了重大挑战。当前的训练后剪枝方法虽然可以减小 LLM 的大小，但往往无法保持其原有的性能。为了应对这些挑战，本文介绍了一种保留稀疏度的参数高效微调方法 SPP。与现有的难以保持性能的训练后剪枝方法不同，SPP 提出采用轻量级可学习的列和行矩阵来优化稀疏 LLM 权重，保持剪枝后的预训练模型的结构和稀疏性不变。通过逐元素乘法和残差加法，SPP 确保在训练和权重合并过程中模型稀疏模式和比率的一致性。我们通过将 SPP 应用于 LLaMA 和 LLaMA-2 模型系列并使用最近的训练后剪枝方法证明了 SPP 的有效性。我们的结果表明，SPP 显著提高了具有不同稀疏模式（即非结构化和 N:M 稀疏性）的模型的性能，尤其是对于稀疏率较高的模型（例如 75%），使其成为高效微调稀疏 LLM 的有前途的解决方案。代码将在 https://github.com/Lucky-Lance/SPP 上提供。]]></description>
      <guid>https://arxiv.org/abs/2405.16057</guid>
      <pubDate>Tue, 28 May 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士基于关键点的渐进式思想链蒸馏</title>
      <link>https://arxiv.org/abs/2405.16064</link>
      <description><![CDATA[arXiv:2405.16064v1 公告类型：新 
摘要：思想链蒸馏是一种将推理能力从大型语言模型（LLM）转移到较小的学生模型的强大技术。以前的方法通常要求学生逐步模仿法学硕士产生的基本原理，通常面临以下挑战：（i）基本原理内的标记的重要性各不相同，并且平等地对待它们可能无法准确地模拟关键点标记，从而导致推理错误。 （ii）他们通常通过一致地预测一个基本原理中的所有步骤来提炼知识，这在区分步骤生成的学习顺序方面存在缺陷。这与人类的认知进程不同，人类的认知进程是从简单的任务开始，然后逐步完成更困难的任务，从而导致次优的结果。为此，我们提出了一个统一的框架，称为 KPOD，来解决这些问题。具体来说，我们提出了一个利用掩模学习的令牌加权模块，以鼓励学生在蒸馏过程中准确模仿关键点令牌。此外，我们开发了一种理性渐进蒸馏策略，从训练学生生成最终推理步骤开始，逐渐扩展到涵盖整个基本原理。为了实现这一目标，提出了加权令牌生成损失来评估步骤推理难度，并设计了价值函数来通过考虑步骤难度和问题多样性来安排渐进式蒸馏。对四个推理基准的广泛实验表明，我们的 KPOD 大大优于以前的方法。]]></description>
      <guid>https://arxiv.org/abs/2405.16064</guid>
      <pubDate>Tue, 28 May 2024 06:18:32 GMT</pubDate>
    </item>
    <item>
      <title>评估大型语言模型基于检索的上下文学习的对抗鲁棒性</title>
      <link>https://arxiv.org/abs/2405.15984</link>
      <description><![CDATA[arXiv:2405.15984v1 公告类型：新 
摘要：随着 LLaMA 和 OpenAI GPT-3 等大型语言模型的出现，上下文学习（ICL）因其有效性和效率而受到广泛关注。然而，ICL 对提示中用于编码演示的选择、顺序和语言非常敏感。检索增强 ICL 方法尝试通过利用检索器提取语义相关的示例作为演示来解决此问题。虽然这种方法可以产生更准确的结果，但其针对各种类型的对抗性攻击（包括对测试样本、演示和检索数据的扰动）的鲁棒性仍有待探索。我们的研究表明，检索增强模型可以增强针对测试样本攻击的鲁棒性，其攻击成功率 (ASR) 降低 4.87%，优于普通 ICL；然而，他们对示威表现出过度自信，导致示威攻击的 ASR 增加了 2%。对抗性训练有助于提高 ICL 方法对对抗性攻击的鲁棒性；然而，对于法学硕士来说，这样的培训计划可能成本太高。作为替代方案，我们引入了一种有效的免训练对抗性防御方法 DARD，它用那些被攻击的样本丰富了示例池。我们表明，DARD 提高了性能和稳健性，ASR 比基线降低了 15%。发布代码和数据以鼓励进一步研究：https://github.com/simonucl/adv-retreival-icl]]></description>
      <guid>https://arxiv.org/abs/2405.15984</guid>
      <pubDate>Tue, 28 May 2024 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型对花园小径句子的增量理解：语义解释、句法重新分析和注意力</title>
      <link>https://arxiv.org/abs/2405.16042</link>
      <description><![CDATA[arXiv:2405.16042v1 公告类型：新 
摘要：当阅读暂时模棱两可的花园小径句子时，误解有时会超出消歧点。传统上，这种现象是在心理语言学实验中使用在线测量（例如阅读时间）和离线测量（例如理解问题）来研究的。在这里，我们使用四种大型语言模型 (LLM) 来研究花园小径句子的处理以及挥之不去的误解的命运：GPT-2、LLaMA-2、Flan-T5 和 RoBERTa。总体目标是评估人类和法学硕士在处理花园小路句子以及消除歧义点后挥之不去的误解方面是否一致，特别是当存在额外句法信息（例如，分隔子句边界的逗号）时指导加工。我们使用 24 个花园小径句子来实现这一目标，这些句子具有可选的及物动词和反身动词，导致暂时的歧义。对于每个句子，都有一对对应于错误解释和正确解释的理解问题。在三个实验中，我们（1）使用问答任务来衡量法学硕士的动态语义解释； (2) 跟踪这些模型是否在消歧点（或句子末尾）移动其隐式解析树； (3) 可视化在处理问题探针时负责消除信息歧义的模型组件。这些实验表明，人类和法学硕士在处理花园小路句子方面有希望保持一致，特别是当可以使用额外的句法信息来指导处理时。]]></description>
      <guid>https://arxiv.org/abs/2405.16042</guid>
      <pubDate>Tue, 28 May 2024 06:18:31 GMT</pubDate>
    </item>
    <item>
      <title>使用预先训练的大型语言模型进行零样本垃圾邮件分类</title>
      <link>https://arxiv.org/abs/2405.15936</link>
      <description><![CDATA[arXiv:2405.15936v1 公告类型：新 
摘要：本文研究了预训练大型语言模型（LLM）在使用零样本提示的垃圾邮件分类中的应用。我们在著名的 SpamAssassin 数据集上评估开源 (Flan-T5) 和专有 LLM（ChatGPT、GPT-4）的性能。探索了两种分类方法：(1) 从电子邮件主题和正文中截断原始内容，以及 (2) 基于 ChatGPT 生成的摘要进行分类。我们的实证分析利用整个数据集进行评估，无需进一步训练，揭示了有希望的结果。 Flan-T5 在截断内容方法上达到了 90% 的 F1 分数，而 GPT-4 使用摘要达到了 95% 的 F1 分数。虽然对单个数据集的这些初步发现表明基于 LLM 的子任务（例如总结和分类）的分类流程具有潜力，但有必要对不同数据集进行进一步验证。专有模型的高运营成本，加上法学硕士的一般推理成本，可能会严重阻碍垃圾邮件过滤的实际部署。]]></description>
      <guid>https://arxiv.org/abs/2405.15936</guid>
      <pubDate>Tue, 28 May 2024 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>句法启动的分层贝叶斯模型</title>
      <link>https://arxiv.org/abs/2405.15964</link>
      <description><![CDATA[arXiv:2405.15964v1 公告类型：新 
摘要：句法启动效应表现出三个有据可查的经验特性：词汇提升、逆频率效应和不对称衰减。我们的目的是展示如何在通用学习框架——分层贝叶斯模型（HBM）中协调这三种经验现象。该模型以句法统计的分层结构表示句法知识，其中较低级别表示句法决策的动词特定偏差，较高级别表示作为动词特定偏差聚合的抽象偏差。这些知识根据贝叶斯推理的经验进行更新。在模拟中，我们表明 HBM 捕获了上述句法启动的特性。结果表明，通常由残差激活帐户解释的启动的一些属性也可以由隐式学习帐户解释。我们还讨论了该模型对句法启动的词汇基础的影响。]]></description>
      <guid>https://arxiv.org/abs/2405.15964</guid>
      <pubDate>Tue, 28 May 2024 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>通过卡片预测和丰富多彩的语义增强增强性和替代性沟通</title>
      <link>https://arxiv.org/abs/2405.15896</link>
      <description><![CDATA[arXiv:2405.15896v1 公告类型：新 
摘要：本文提出了一种通过将多彩语义（CS）与专门为巴西葡萄牙语定制的基于变压器的语言模型相集成来增强增强和替代通信（AAC）系统的方法。我们引入了一种改编的 BERT 模型 BERTptCS，它结合了 CS 框架来改进通信卡的预测。主要目的是提高通信卡预测的准确性和上下文相关性，这对于具有复杂通信需求 (CCN) 的个人的 AAC 系统至关重要。我们将 BERTptCS 与缺乏 CS 集成的基线模型 BERTptAAC 进行了比较。我们的结果表明，BERTptCS 在各种指标上都显着优于 BERTptAAC，包括 top-k 准确度、平均倒数排名 (MRR) 和 Entropy@K。将 CS 集成到语言模型中可以提高预测准确性，并提供对用户输入的更直观和上下文的理解，从而促进更有效的沟通。]]></description>
      <guid>https://arxiv.org/abs/2405.15896</guid>
      <pubDate>Tue, 28 May 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>SLIDE：集成小型和大型语言模型的开放域对话评估框架</title>
      <link>https://arxiv.org/abs/2405.15924</link>
      <description><![CDATA[arXiv:2405.15924v1 公告类型：新 
摘要：开放域对话系统中长期存在的一对多黄金标准响应问题给自动评估指标带来了挑战。尽管之前的工作通过应用强大的大型语言模型 (LLM) 取得了一些成功，但现有方法仍然难以解决一对多问题，并且在特定领域场景中表现不佳。我们假设法学硕士内的常识推理偏差可能会阻碍他们在特定领域评估中的表现。为了解决这两个问题，我们提出了一个新颖的框架 SLIDE（对话评估的小型和大型集成），它利用小型专业模型（SLM）和法学硕士来评估开放领域对话。我们的方法引入了几种技术：（1）对比学习来区分鲁棒和非鲁棒响应嵌入； (2) 一种新颖的语义敏感性度量，将嵌入余弦距离与通过神经网络学习的相似性相结合，以及 (3) 一种整合 SLM 和 LLM 评估结果的策略。我们的实证结果表明，我们的方法在分类和评估任务中都实现了最先进的性能，此外 SLIDE 评估器与人类判断表现出更好的相关性。我们的代码可在 https://github.com/hegehongcha/SLIDE-ACL2024 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.15924</guid>
      <pubDate>Tue, 28 May 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>DuanzAI：俚语强化法学硕士，提示幽默理解</title>
      <link>https://arxiv.org/abs/2405.15818</link>
      <description><![CDATA[arXiv:2405.15818v1 公告类型：新 
摘要：语言的复杂性在丰富的俚语表达中显而易见，通常充满幽默和文化差异。这种语言现象变得越来越普遍，尤其是在数字通信中。然而，包括 ChatGPT-3.5 在内的现有人工智能模型在理解这些细微差别方面面临着挑战，尤其是在中文俚语中。在这项研究中，我们提出了 DuanzAI，这是一种通过深入的中文俚语理解来增强大型语言模型 (LLM) 的创新方法。利用精选的数据集和先​​进技术，DuanzAI 弥合了人类表达和人工智能理解之间的差距，从而实现了上下文相关的响应。我们的实验将法学硕士的性能与定制的 Punchline 实体识别 (PER) 系统进行了对比，该系统集成了语音匹配和拼音汉字技术。应用这些见解，我们开发了 ChatDAI，一个高级聊天机器人，并在 \url{https://github.com/YesianRohn/DuanzAI} 发布了我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2405.15818</guid>
      <pubDate>Tue, 28 May 2024 06:18:28 GMT</pubDate>
    </item>
    </channel>
</rss>