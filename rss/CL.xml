<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 06 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>并非所有适配器都重要：选择性适配器冻结可实现语言模型的内存高效微调</title>
      <link>https://arxiv.org/abs/2412.03587</link>
      <description><![CDATA[arXiv:2412.03587v1 公告类型：新
摘要：基于 Transformer 的大规模预训练模型取得了巨大的成功，而微调（在特定于任务的数据集上调整预训练模型）是将这些模型用于下游任务的标准做法。最近的工作已经开发了适配器调整，但这些方法仍然需要相对较高的资源使用率。通过我们的调查，我们表明适配器调整中的每个适配器对任务性能和资源使用的影响并不相同。根据我们的研究结果，我们提出了 SAFE，它在早期训练步骤中逐渐冻结对适应没有贡献的不太重要的适配器。在我们的实验中，SAFE 分别将内存使用量、计算量和训练时间减少了 42.85\%、34.59\% 和 11.82\%，同时实现了与基线相当或更好的性能。我们还证明 SAFE 诱导了正则化效应，从而平滑了损失格局。]]></description>
      <guid>https://arxiv.org/abs/2412.03587</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过基于图形的合成布局增强文档 AI 数据生成</title>
      <link>https://arxiv.org/abs/2412.03590</link>
      <description><![CDATA[arXiv:2412.03590v1 公告类型：新
摘要：由于对高质量标记数据集的访问有限，稳健文档 AI 模型的开发受到限制，这主要是由于数据隐私问题、稀缺性和手动注释的高成本。传统的合成数据生成方法（例如文本和图像增强）已被证明可以有效增加数据多样性，但往往无法捕捉现实世界文档中存在的复杂布局结构。本文提出了一种使用图神经网络 (GNN) 生成合成文档布局的新方法。通过将文档元素（例如文本块、图像、表格）表示为图中的节点并将其空间关系表示为边，GNN 经过训练可以生成逼真且多样化的文档布局。该方法利用基于图的学​​习来确保结构一致性和语义一致性，解决了传统增强技术的局限性。所提出的框架在文档分类、命名实体识别 (NER) 和信息提取等任务上进行了评估，显示出显着的性能改进。此外，我们解决了基于 GNN 的合成数据生成的计算挑战，并提出了缓解合成数据集和真实世界数据集之间域适应问题的解决方案。我们的实验结果表明，图形增强文档布局优于现有的增强技术，为训练文档 AI 模型提供了可扩展且灵活的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2412.03590</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用图像在向量空间中查找与上下文无关的单词表示</title>
      <link>https://arxiv.org/abs/2412.03592</link>
      <description><![CDATA[arXiv:2412.03592v1 公告类型：新
摘要：已经提出了许多方法来寻找单词的向量表示，但大多数方法都依赖于从文本中捕获上下文来找到这些向量之间的语义关系。我们提出了一种新颖的方法，使用字典含义和图像描述来查找独立于任何上下文的词向量。我们在单词图像上使用自动编码器来找到有意义的表示，并使用它们来计算词向量。我们最后在单词相似性、概念分类和异常值检测任务上评估了我们的方法。我们的方法与基于上下文的方法性能相当，但训练时间要少得多。]]></description>
      <guid>https://arxiv.org/abs/2412.03592</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CovidLLM：一种具有缺失值自适应和多目标学习策略的稳健大型语言模型，用于预测 COVID-19 患者的疾病严重程度和临床结果</title>
      <link>https://arxiv.org/abs/2412.03593</link>
      <description><![CDATA[arXiv:2412.03593v1 公告类型：新
摘要：2019 年出现的冠状病毒病 2019 (COVID-19) 已导致全球数百万人死亡。尽管已经开发出有效的疫苗来缓解严重症状，但某些人群，尤其是老年人和患有合并症的人，仍然面临严重后果和死亡率增加的高风险。因此，尽早识别这些患者的疾病严重程度和临床结果对于预防不良预后至关重要。尽管传统的机器学习和深度学习模型已广泛应用于这一领域，但大型语言模型 (LLM) 的潜力仍未得到充分开发。我们的研究主要侧重于构建专门的提示和采用多目标学习策略。我们首先选择与临床结果和疾病严重程度显着相关的血清学指标作为模型的输入数据。血液测试样本通常包含大量缺失值，传统模型通常依靠归纳来处理数据中的这些缺口。相比之下，LLM 具有强大的语义理解优势。通过设置提示，我们可以明确告知模型何时缺少特征值，而无需进行填补。对于多目标学习策略，该模型旨在首先预测疾病严重程度，然后预测临床结果。鉴于 LLM 使用输入文本和生成的标记作为生成下一个标记的输入，因此预测的严重程度将用作生成临床结果的基础。在 LLM 的微调过程中，这两个目标相互影响和改进。我们的实验是基于 ChatGLM 模型实施的。结果证明了 LLM 在该任务中的有效性，表明其具有进一步发展的潜力。]]></description>
      <guid>https://arxiv.org/abs/2412.03593</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BatchLLM：通过全局前缀共享和面向吞吐量的标记批处理优化大型批量 LLM 推理</title>
      <link>https://arxiv.org/abs/2412.03594</link>
      <description><![CDATA[arXiv:2412.03594v1 Announce Type: new 
摘要：许多LLM任务都是大批量甚至离线执行的，其性能指标是吞吐量。这些任务通常表现出前缀共享的特性，不同的提示输入可以部分显示公共前缀。然而，现有的LLM推理引擎倾向于优化流式请求，在支持具有前缀共享特性的大批量任务方面表现出局限性。现有的解决方案使用基于LRU的缓存来重用公共前缀的KV上下文。即将被重用的KV上下文可能会因隐式缓存管理而过早被逐出。即使没有被逐出，共享KV上下文的生命周期也会延长，因为共享相同上下文的请求不会被一起调度，从而导致更大的内存使用量。这些面向流的系统以先到先得或类似的顺序调度请求。因此，解码步骤比例较大的请求可能被调度得太晚，无法与预填充块混合以提高硬件利用率。此外，基于令牌和请求数的批处理会限制令牌批的大小，从而防止 GPU 在以解码令牌为主导的迭代中达到饱和。我们提出了 BatchLLM 来解决上述问题。BatchLLM 全局明确标识公共前缀。共享相同前缀的请求将被一起调度以最佳地重用 KV 上下文，这也会缩短公共 KV 内存的生命周期。BatchLLM 对请求进行重新排序，并首先调度具有较大解码比率的请求，以更好地将解码令牌与后者的预填充块混合，并应用以内存为中心的令牌批处理来扩大令牌批处理大小，这有助于提高 GPU 利用率。广泛的评估表明，在一组微基准测试和两个典型的行业工作负载上，BatchLLM 的性能比 vLLM 好 1.1 倍到 2 倍。]]></description>
      <guid>https://arxiv.org/abs/2412.03594</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言模型基准的脆弱性：它们能准确反映真正的 LLM 性能吗？</title>
      <link>https://arxiv.org/abs/2412.03597</link>
      <description><![CDATA[arXiv:2412.03597v1 公告类型：新
摘要：追求大型语言模型 (LLM) 中的排行榜排名产生了一个基本悖论：模型在标准化测试中表现出色，但未能展示真正的语言理解和适应性。我们对 NLP 评估框架的系统分析揭示了整个评估范围内普遍存在的漏洞，从基本指标到复杂的基准，如 GLUE 和 MMLU。这些漏洞通过基准利用、数据集污染和评估偏差表现出来，造成了对语言理解能力进步的错误看法。通过对当代评估方法的广泛审查，我们发现静态基准设计、人工评估协议和 LLM-as-judge 框架存在重大局限性，所有这些都损害了当前绩效评估的可靠性。随着 LLM 能力的发展和现有基准变得多余，我们为新的评估方法奠定了基础，这些方法可以抵抗操纵、最大限度地减少数据污染并评估特定领域的任务。这需要动态调整的框架，解决当前的限制并更准确地反映 LLM 性能。]]></description>
      <guid>https://arxiv.org/abs/2412.03597</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CPTQuant——一种用于大型语言模型的新型混合精度后训练量化技术</title>
      <link>https://arxiv.org/abs/2412.03599</link>
      <description><![CDATA[arXiv:2412.03599v1 公告类型：新 
摘要：大型语言模型已经改变了自然语言任务的理解和生成，但它们具有大量的内存和计算要求。量化技术已成为解决这些挑战的一种有前途的途径，同时保持准确性并提高能源效率。我们提出了 CPTQuant，这是一种全面的策略，引入了基于相关性 (CMPQ)、基于修剪 (PMPQ) 和基于泰勒分解 (TDMPQ) 的混合精度技术。CMPQ 根据不同层的典型相关性分析调整精度级别。PMPQ 根据它们对稀疏性的敏感性逐层优化精度。TDMPQ 使用泰勒分解来修改精度以评估每个层对输入扰动的敏感性。这些策略将更高的精度分配给更敏感的层，同时降低稳健层的精度。 CPTQuant 评估了 BERT、OPT-125M、OPT-350M、OPT-1.3B 和 OPT-2.7B 的性能。与 Hugging Face FP16 相比，我们展示了高达 4 倍的压缩率和 2 倍的效率提升，同时准确率下降幅度很小。PMPQ 因实现显著更高的模型压缩率而脱颖而出。跨各种 LLM 的敏感性分析表明，初始和最终 30% 的层表现出比其余层更高的敏感性。PMPQ 在分类任务中比其他方法高出 11% 的压缩率，而 TDMPQ 在语言建模任务中实现了 30% 的压缩率。]]></description>
      <guid>https://arxiv.org/abs/2412.03599</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CBEval：评估和解释法学硕士 (LLM) 中的认知偏差的框架</title>
      <link>https://arxiv.org/abs/2412.03605</link>
      <description><![CDATA[arXiv:2412.03605v1 公告类型：新
摘要：大型语言模型 (LLM) 的快速发展显著增强了它们的推理能力。尽管在基准测试中表现有所提高，但 LLM 在其认知过程中仍表现出明显的差距。此外，作为人类生成数据的反映，这些模型有可能继承认知偏见，从而引发人们对其推理和决策能力的担忧。在本文中，我们提出了一个框架来解释、理解和洞察 LLM 中的一系列认知偏见。通过对前沿语言模型进行研究，我们能够阐明推理的局限性和偏见，并通过构建影响图来识别对 LLM 中表现出的偏见最负责的短语和单词，从而提供这些偏见背后的推理。我们进一步研究了在语言模型中注意框架效应时发现的诸如整数偏见和认知偏见障碍之类的偏见。]]></description>
      <guid>https://arxiv.org/abs/2412.03605</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 BERT 和 ResNet 的多模态情绪分析</title>
      <link>https://arxiv.org/abs/2412.03625</link>
      <description><![CDATA[arXiv:2412.03625v1 公告类型：new 
摘要：随着互联网与社交媒体的快速发展，多模态数据（文本与图像）在情感分析任务中的重要性日益提升，然而现有方法难以有效融合文本与图像特征，限制了分析的准确性。针对该问题，提出了一种结合BERT与ResNet的多模态情感分析框架。BERT在自然语言处理中展现出强大的文本表征能力，ResNet在计算机视觉领域具有优异的图像特征提取性能。首先利用BERT提取文本特征向量，利用ResNet提取图像特征表征，然后探索多种特征融合策略，最终选取基于注意力机制的融合模型，充分利用文本与图像之间的互补信息。在公开数据集MAVA-single上的实验结果表明，与仅采用BERT或ResNet的单模态模型相比，提出的多模态模型提高了准确率和F1得分，最高准确率达到74.5%。本研究不仅为多模态情感分析提供了新的思路和方法，也展示了BERT和ResNet在跨领域融合方面的应用潜力。未来将探索更先进的特征融合技术和优化策略，进一步提高多模态情感分析的准确率和泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2412.03625</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估语言模型作为合成数据生成器</title>
      <link>https://arxiv.org/abs/2412.03679</link>
      <description><![CDATA[arXiv:2412.03679v1 公告类型：新 
摘要：鉴于语言模型 (LM) 后训练中合成数据的使用越来越多，LM 生成高质量数据的能力几乎与其直接解决问题的能力一样重要。虽然之前的工作重点是开发有效的数据生成方法，但它们缺乏在统一环境中对不同 LM 作为数据生成器进行系统比较。为了解决这一差距，我们提出了 AgoraBench，这是一个基准，它提供标准化设置和指标来评估 LM 的数据生成能力。通过使用 6 个 LM 合成 126 万个训练实例并训练 99 个学生模型，我们发现了有关 LM 数据生成能力的关键见解。首先，我们观察到 LM 表现出不同的优势。例如，GPT-4o 擅长生成新问题，而 Claude-3.5-Sonnet 在增强现有问题方面表现更好。此外，我们的分析表明，LM 的数据生成能力不一定与其解决问题的能力相关。相反，数据质量的多个内在特征（包括响应质量、困惑度和教学难度）共同充当了更好的指标。最后，我们证明了输出格式的战略选择和注重成本的模型选择会显著影响数据生成的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.03679</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>习得品味：利用文本和结构嵌入进行多模态立场检测</title>
      <link>https://arxiv.org/abs/2412.03681</link>
      <description><![CDATA[arXiv:2412.03681v1 公告类型：新
摘要：立场检测在实现广泛的下游应用方面发挥着关键作用，从话语解析到追踪虚假新闻的传播和否认科学事实。虽然大多数立场分类模型依赖于所讨论话语的文本表示，但先前的工作已经证明了对话上下文在立场检测中的重要性。在这项工作中，我们引入了 TASTE——一种用于立场检测的多模态架构，它将基于 Transformer 的内容嵌入与无监督的结构嵌入完美地融合在一起。通过对预训练的 Transformer 进行微调并通过门控残差网络 (GRN) 层与社交嵌入相结合，我们的模型巧妙地捕捉了内容和对话结构在确定立场方面的复杂相互作用。TASTE 在常见基准上取得了最先进的结果，明显优于一系列强大的基线。比较评估强调了社会基础的好处——强调同时利用内容和结构来增强立场检测的重要性。]]></description>
      <guid>https://arxiv.org/abs/2412.03681</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从基于标记的语言模型到基于字符的语言模型</title>
      <link>https://arxiv.org/abs/2412.03719</link>
      <description><![CDATA[arXiv:2412.03719v1 公告类型：新
摘要：现代语言模型在内部和数学上分布在标记字符串而不是 \emph{character} 字符串上，这对在其上构建用户应用程序的程序员提出了许多挑战。例如，如果提示被指定为字符串，则必须在将其传递给标记级语言模型之前对其进行标记化。因此，标记器和后续分析对提示的规范非常敏感（例如，提示是否以空格结尾）。本文介绍了将标记级语言模型转换为字符级语言模型的算法。我们提出了精确和近似算法。在本文的经验部分，我们对实际运行时间和近似质量进行了基准测试。我们发现，即使计算预算很少，我们的方法也能够在 Llama 3.1 8B 语言模型上以相当快的速度（46.3 个字符/秒）准确地近似字符级分布（少于 0.00021 个多余位/字符）。]]></description>
      <guid>https://arxiv.org/abs/2412.03719</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用混合搜索进行特定领域的问答</title>
      <link>https://arxiv.org/abs/2412.03736</link>
      <description><![CDATA[arXiv:2412.03736v1 公告类型：新
摘要：特定领域问答是一个不断发展的领域，需要专门的解决方案来应对独特的挑战。在本文中，我们展示了一种将微调密集检索器与基于关键字的稀疏搜索方法相结合的混合方法，可显著提高性能。我们的系统利用相关信号的线性组合，包括密集检索的余弦相似度、BM25 分数和 URL 主机匹配，每个信号都有可调的增强参数。实验结果表明，这种混合方法优于我们的单检索系统，在保持稳健的上下文基础的同时实现了更高的准确性。这些发现表明，将多种检索方法与加权评分相结合可以有效解决企业环境中特定领域问答的复杂性。]]></description>
      <guid>https://arxiv.org/abs/2412.03736</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言模型与原型的结合：通过原型网络实现可解释的文本分类模型</title>
      <link>https://arxiv.org/abs/2412.03761</link>
      <description><![CDATA[arXiv:2412.03761v1 公告类型：新
摘要：基于预训练转换器的语言模型 (LM) 因其在 NLP 任务上取得显着改进的能力而闻名，但它们的黑盒性质导致缺乏可解释性，这一直是一个主要问题。我的论文重点是在使用 LM 作为编码器时开发本质上可解释的模型，同时通过原型网络保持其卓越的性能。我的研究始于研究可解释的讽刺检测模型的性能增强。我提出的方法侧重于捕捉情绪不一致以提高准确性，同时为分类决策提供基于实例的解释。后来，我开发了一个新颖的白盒多头图注意力原型网络，旨在解释文本分类模型的决策，而不会牺牲原始黑盒 LM 的准确性。此外，我正在研究通过对比学习扩展基于注意力机制的原型网络，重新设计一个可解释的图神经网络，旨在增强模型在文档分类中的可解释性和性能。]]></description>
      <guid>https://arxiv.org/abs/2412.03761</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>WithdrarXiv：用于撤稿研究的大规模数据集</title>
      <link>https://arxiv.org/abs/2412.03775</link>
      <description><![CDATA[arXiv:2412.03775v1 公告类型：新
摘要：撤稿在维护科学完整性方面发挥着至关重要的作用，但对计算机科学和其他 STEM 领域的撤稿的系统研究仍然很少。我们介绍了 WithdrarXiv，这是 arXiv 中撤回论文的第一个大规模数据集，包含超过 14,000 篇论文及其相关的撤稿评论，涵盖了该存储库的整个历史，直至 2024 年 9 月。通过仔细分析作者评论，我们开发了一个全面的撤稿原因分类法，确定了 10 个不同的类别，从严重错误到违反政策。我们展示了一种简单但高度准确的零样本自动分类撤稿原因，实现了 0.96 的加权平均 F1 分数。此外，我们发布了 WithdrarXiv-SciFy，这是一个丰富的版本，包括用于解析全文 PDF 的脚本，专门用于支持科学可行性研究、声明验证和自动定理证明的研究。这些发现为改进科学质量控制和自动验证系统提供了宝贵的见解。最后，也是最重要的，我们讨论了道德问题，并采取了一系列措施来实施负责任的数据发布，同时促进该领域的开放科学。]]></description>
      <guid>https://arxiv.org/abs/2412.03775</guid>
      <pubDate>Fri, 06 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>