<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 20 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>加强教育数据中个人身份信息的去标识化</title>
      <link>https://arxiv.org/abs/2501.09765</link>
      <description><![CDATA[arXiv:2501.09765v1 公告类型：新 
摘要：保护个人身份信息 (PII)（例如姓名）是学习技术中保护学生和教师隐私并维持信任的关键要求。准确的 PII 检测是匿名化敏感信息同时保留教育数据效用的重要一步。受人工智能最新进展的推动，我们的研究调查了 GPT-4o-mini 模型作为 PII 检测任务的经济高效解决方案。我们探索了提示和微调方法，并将 GPT-4o-mini 的性能与已建立的框架（包括 Microsoft Presidio 和 Azure AI Language）进行比较。我们对两个公共数据集 CRAPII 和 TSCC 的评估表明，经过微调的 GPT-4o-mini 模型实现了卓越的性能，在 CRAPII 上的召回率为 0.9589。此外，经过微调的 GPT-4o-mini 显著提高了准确率（提高了三倍），同时将计算成本降低到 Azure AI 语言的近十分之一。此外，我们的偏见分析表明，经过微调的 GPT-4o-mini 模型在不同文化背景和性别之间始终如一地提供准确的结果。使用 TSCC 数据集的通用性分析进一步凸显了其稳健性，在 TSCC 的极少额外训练数据的情况下实现了 0.9895 的召回率。这些结果强调了经过微调的 GPT-4o-mini 作为一种准确且经济高效的教育数据 PII 检测工具的潜力。它提供了强大的隐私保护，同时保留了数据对研究和教学分析的实用性。我们的代码可在 GitHub 上找到：https://github.com/AnonJD/PrivacyAI]]></description>
      <guid>https://arxiv.org/abs/2501.09765</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过迭代强化微调提高大型语言模型的工具使用率</title>
      <link>https://arxiv.org/abs/2501.09766</link>
      <description><![CDATA[arXiv:2501.09766v1 公告类型：新
摘要：使用外部工具增强大型语言模型 (LLM) 是一种增强其能力的有前途的方法。有效地利用这种潜力来完成复杂任务的关键在于提高它们使用工具的能力。通过模拟现实世界来合成工具使用数据是一种有效的方法。然而，我们的调查显示，随着这些数据规模的增加，训练收益会显著衰减。主要因素是模型在复杂场景中的表现不佳（即缺陷），这阻碍了使用 SFT 从数据中学习。在这一目标的驱动下，我们提出了一种迭代强化微调策略来不断指导模型缓解它。具体来说，我们首先根据策略模型的反馈识别与缺陷相关的数据，然后执行蒙特卡洛树搜索以收集细粒度的偏好对以查明缺陷。随后，我们使用偏好优化来更新策略模型，以与基本事实保持一致并与缺陷不一致。这个过程可以迭代。此外，在迭代之前，我们提出了一种由易到难的预热 SFT 策略，以促进从具有挑战性的数据中学习。实验表明，我们的模型超越了相同的参数模型，优于许多更大的开源和闭源模型。此外，它在复杂的工具使用场景中取得了显着的训练收益。]]></description>
      <guid>https://arxiv.org/abs/2501.09766</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LeMo：减少代币参与，实现更多情境微调</title>
      <link>https://arxiv.org/abs/2501.09767</link>
      <description><![CDATA[arXiv:2501.09767v1 公告类型：新
摘要：对长上下文应用程序的需求不断增长，加剧了扩展 LLM 上下文窗口的必要性。尽管最近的微调方法成功地扩展了上下文长度，但它们的高内存占用，尤其是对于激活，在实际应用中是一个关键的限制。当前参数高效的微调方法优先考虑减少参数更新开销，而不是解决激活内存限制。同样，现有的稀疏机制提高了计算效率，但由于阴影激活现象而忽略了激活内存优化。
在本文中，我们提出了 LeMo，这是第一个 LLM 微调系统，它探索和利用了长上下文场景中固有的新的 token 级稀疏机制，称为上下文 token 稀疏性。LeMo 通过评估 token 嵌入的信息量来最大限度地减少冗余 token 的参与，同时保持模型准确性。具体来说，LeMo 引入了三种关键技术：(1) Token Elimination，动态识别和排除不同输入和层中的冗余 token。 （2）模式预测，利用训练有素的预测器以最小的开销近似标记稀疏模式。（3）内核优化，采用无置换和基于段的策略来提高系统性能。我们将 LeMo 实现为与各种 LLM 架构和其他优化技术兼容的端到端微调系统。综合评估表明，LeMo 将内存消耗降低了 1.93 倍，并实现了高达 1.36 倍的加速，优于最先进的微调系统。]]></description>
      <guid>https://arxiv.org/abs/2501.09767</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型能够预测司法判决的结果吗？</title>
      <link>https://arxiv.org/abs/2501.09768</link>
      <description><![CDATA[arXiv:2501.09768v1 公告类型：新
摘要：大型语言模型 (LLM) 在不同领域的自然语言处理 (NLP) 中表现出卓越的能力。然而，它们在阿拉伯语等资源匮乏的语言的法律判决预测 (LJP) 等专门任务中的应用仍未得到充分探索。在这项工作中，我们通过开发一个阿拉伯语 LJP 数据集来解决这一差距，该数据集是从沙特商业法院判决中收集和预处理的。我们对最先进的开源 LLM（包括 LLaMA-3.2-3B 和 LLaMA-3.1-8B）进行了基准测试，采用了零样本、单样本和使用 QLoRA 进行微调等不同配置。此外，我们使用了一个综合评估框架，结合了定量指标（BLEU 和 ROUGE）和定性评估（连贯性、法律语言、清晰度）。我们的结果表明，经过微调的小型模型在特定任务环境中实现了与大型模型相当的性能，同时提供了显着的资源效率。此外，我们研究了快速工程和微调对模型输出的影响，深入了解了性能变化和指令敏感性。通过公开数据集、实现代码和模型，我们为未来阿拉伯法律 NLP 研究奠定了坚实的基础。]]></description>
      <guid>https://arxiv.org/abs/2501.09768</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多项选择题：推理让大型语言模型 (LLM) 即使出错也能更加自信</title>
      <link>https://arxiv.org/abs/2501.09775</link>
      <description><![CDATA[arXiv:2501.09775v1 公告类型：新
摘要：评估 LLM 的最广泛使用的方法之一是多项选择题 (MCQ) 测试。MCQ 基准测试可以大规模测试几乎任何主题的 LLM 知识，因为结果可以自动处理。为了帮助 LLM 回答，可以在提示中包含一些称为“few shots”的示例。此外，可以要求 LLM 直接使用所选选项回答问题，或者先提供推理，然后再提供所选答案，这被称为思路链。除了检查所选答案是否正确之外，评估还可以查看 LLM 对其响应的估计概率，作为 LLM 对响应的信心的指示。在本文中，我们研究了 LLM 对其答案的信心如何取决于模型是否被要求直接回答或在回答之前提供推理。在七种不同的模型中，对各种主题的问题进行评估的结果表明，如果 LLM 在回答问题之前提供推理，他们会对自己的答案更有信心。无论所选答案是否正确，都会出现这种情况。我们的假设是，这种行为是由于推理改变了所选答案的概率，因为 LLM 会根据输入问题和支持所做选择的推理来预测答案。因此，LLM 估计的概率似乎具有内在的局限性，应该理解这些局限性才能在评估过程中使用它们。有趣的是，在人类身上也观察到了同样的行为，对人类来说，解释答案会增加对其正确性的信心。]]></description>
      <guid>https://arxiv.org/abs/2501.09775</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习对以加密货币为中心的 Twitter 社交网络进行情绪分析</title>
      <link>https://arxiv.org/abs/2501.09777</link>
      <description><![CDATA[arXiv:2501.09777v1 公告类型：新
摘要：加密货币是一种使用区块链技术进行安全加密的数字货币。由于这些货币的去中心化，传统货币体系及其各自的资本市场都会影响社会。因此，由于问题的重要性，了解公众舆论和分析人们在这方面的意见的需要也随之增加。要了解人们对不同主题的意见和看法，您可以借助社交网络，因为它们是意见的丰富来源。Twitter 社交网络是用户讨论各种主题的主要平台之一，因此，可以在最短的时间内以最低的成本在这个社交网络上衡量社区的意见。Twitter 情绪分析 (TSA) 是一个分析推文中表达的情绪的领域。考虑到 TSA 对加密货币的大部分研究工作都集中在英语上，本文的目的是调查 Twitter 社交网络上伊朗用户对加密货币的看法，并提供基于情绪对推文进行分类的最佳模型。在自动分析推文的情况下，经济领域的管理者和官员可以从公众的角度了解这个问题，并利用获得的信息来妥善管理这一现象。为此，本文为了建立情感分类模型，使用自然语言处理技术，如词袋（BOW）和FastText进行文本向量化，使用经典机器学习算法，包括KNN、SVM和Adaboost学习方法，包括LSTM和BERT模型进行分类，最终BERT语言模型的准确率最高，为83.50%。]]></description>
      <guid>https://arxiv.org/abs/2501.09777</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Qwen 它能检测机器生成的文本吗？</title>
      <link>https://arxiv.org/abs/2501.09813</link>
      <description><![CDATA[arXiv:2501.09813v1 公告类型：新
摘要：本文介绍了 Unibuc - NLP 团队在解决 Coling 2025 GenAI 研讨会任务 1：二进制多语言机器生成文本检测方面的方法。我们探索了掩码语言模型和因果模型。对于子任务 A，我们的最佳模型在 F1 Micro（辅助分数）为 0.8333 时在 36 个团队中名列第一，在 F1 Macro（主分数）为 0.8301 时排名第二]]></description>
      <guid>https://arxiv.org/abs/2501.09813</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>消除医疗保健领域的语言障碍：阿拉伯语法学硕士研究</title>
      <link>https://arxiv.org/abs/2501.09825</link>
      <description><![CDATA[arXiv:2501.09825v1 公告类型：新
摘要：本文探讨了开发精通多语言理解和医学知识的大型语言模型 (LLM) 的挑战。我们证明，仅仅翻译医疗数据并不能保证在目标语言的临床任务中表现出色。我们的实验表明，训练数据中的最佳语言组合在不同的医疗任务中存在显着差异。我们发现，具有精心校准的语言比率的较大模型在母语临床任务上取得了优异的表现。此外，我们的结果表明，仅仅依靠微调可能不是将新语言知识纳入 LLM 的最有效方法。相反，数据和计算密集型预训练方法可能仍然是在多语言医疗环境中实现最佳性能所必需的。这些发现为为不同语言社区构建有效且包容性的医疗 AI 系统提供了宝贵的指导。]]></description>
      <guid>https://arxiv.org/abs/2501.09825</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用经济高效的检索增强型 LLM 从知识图谱生成对话基准</title>
      <link>https://arxiv.org/abs/2501.09928</link>
      <description><![CDATA[arXiv:2501.09928v1 公告类型：新
摘要：对话基准对于训练和评估参与特定领域对话的聊天机器人至关重要。知识图谱 (KG) 表示语义丰富且组织良好的数据，涵盖各个领域，例如 DBLP、DBpedia 和 YAGO。传统上，对话基准是从文档中手动创建的，忽略了 KG 在自动化此过程方面的潜力。一些问答基准是使用 KG 的大量预处理自动生成的，但它们不支持对话生成。本文介绍了 Chatty-Gen，这是一种新颖的多阶段检索增强生成平台，可使用 KG 自动生成针对特定领域的高质量对话基准。Chatty-Gen 将生成过程分解为可管理的阶段，并使用断言规则在阶段之间自动验证。我们的方法可以控制中间结果，以防止由于幻觉而导致耗时的重启。它还减少了对昂贵且功能更强大的商业 LLM 的依赖。Chatty-Gen 使用高效的基于查询的检索来根据对话上下文查找代表性子图，从而消除了对整个 KG 的前期处理。我们对几个真实的大型 KG 进行的实验表明，Chatty-Gen 的表现明显优于最先进的系统，并确保了跨多种不同功能的 LLM（例如 GPT-4o、Gemini 1.5、Llama 3 和 Mistral）的模型和系统性能的一致性。]]></description>
      <guid>https://arxiv.org/abs/2501.09928</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于提取问答的文档段落分割</title>
      <link>https://arxiv.org/abs/2501.09940</link>
      <description><![CDATA[arXiv:2501.09940v1 公告类型：新
摘要：检索增强生成 (RAG) 已被证明在开放域问答中是有效的。然而，与检索和合成组件相比，对该流程至关重要的分块过程往往没有得到足够的重视。这项研究强调了分块在提高密集段落检索和端到端 RAG 流程性能方面的关键作用。然后，我们介绍了 Logits-Guided Multi-Granular Chunker (LGMGC)，这是一个新颖的框架，可将长文档拆分为具有不同粒度的上下文化、自包含的块。我们在两个基准数据集上评估的实验结果表明，LGMGC 不仅改进了检索步骤，而且在集成到 RAG 流程中时也优于现有的分块方法。]]></description>
      <guid>https://arxiv.org/abs/2501.09940</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>阿根廷的土著语言：NLP 和语音资源调查</title>
      <link>https://arxiv.org/abs/2501.09943</link>
      <description><![CDATA[arXiv:2501.09943v1 公告类型：新
摘要：阿根廷拥有丰富多彩但鲜为人知的土著语言遗产。这些语言中的大多数都面临消失的危险，导致世界遗产和文化知识的大量流失。目前，没有关于这些语言的使用者和计算工具的统一信息。在这项工作中，我们对阿根廷使用的土著语言进行了系统化，并提供了该国土著人口的国家人口统计数据。这些语言分为七个语系：Mapuche、Tup\&#39;i-Guaran\&#39;i、Guaycur\&#39;u、Quechua、Mataco-Mataguaya、Aymara 和 Chon。我们还对这些语言可用的计算资源进行了介绍性调查，无论它们是否是专门为阿根廷语种开发的。]]></description>
      <guid>https://arxiv.org/abs/2501.09943</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FRAG：基于知识图谱的检索增强生成的灵活模块化框架</title>
      <link>https://arxiv.org/abs/2501.09957</link>
      <description><![CDATA[arXiv:2501.09957v1 公告类型：新 
摘要：为了缓解大型语言模型（LLM）中的幻觉和知识缺乏问题，基于知识图谱（KG）的检索增强生成（RAG）通过利用 KG 作为外部资源来增强 LLM 推理，显示出了良好的潜力。然而，现有的 KG-RAG 方法在灵活性和检索质量之间难以取得平衡。模块化方法优先考虑灵活性，避免在检索过程中使用 KG 微调模型，导致检索策略固定，检索质量不理想。相反，耦合方法将 KG 信息嵌入模型中以提高检索质量，但牺牲了灵活性。在本文中，我们提出了一种新颖的灵活模块化 KG-RAG 框架，称为 FRAG，它结合了两种方法的优点。FRAG 仅根据查询估计推理路径的跳跃范围，并将其分类为简单或复杂。为了匹配查询的复杂性，我们采用量身定制的管道来确保高效准确的推理路径检索，从而促进最终的推理过程。通过使用查询文本而不是KG来推断推理路径的结构信息，并采用自适应的检索策略，FRAG在保持灵活性的同时提高了检索质量。此外，FRAG不需要额外的LLM微调或调用，大大提高了效率并节省了资源。大量实验表明，FRAG以高效率和低资源消耗达到了最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2501.09957</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的多轮交互能力调查</title>
      <link>https://arxiv.org/abs/2501.09959</link>
      <description><![CDATA[arXiv:2501.09959v1 公告类型：新
摘要：对话系统研究中的多轮交互是指系统在多个对话轮次中保持上下文的能力，从而使其能够生成连贯且与上下文相关的响应。大型语言模型 (LLM) 的最新进展大大扩展了多轮交互的范围，超越了聊天机器人，实现了与用户或环境的更动态​​的代理交互。在本文中，我们重点回顾了 LLM 的多轮功能，这对于广泛的下游应用至关重要，包括对话搜索和推荐、咨询服务和交互式辅导。本调查探讨了四个关键方面：(1) 有助于有效多轮交互的核心模型能力，(2) 当前实践中如何评估多轮交互，(3) 用于增强多轮交互的通用算法，以及 (4) 该领域未来研究的潜在方向。]]></description>
      <guid>https://arxiv.org/abs/2501.09959</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>代理人担任法官对长篇叙述进行事实总结</title>
      <link>https://arxiv.org/abs/2501.09993</link>
      <description><![CDATA[arXiv:2501.09993v1 公告类型：新
摘要：大型语言模型 (LLM) 在基于传统指标（例如 ROUGE 和 BERTScore）的摘要任务中表现出接近人类的表现。然而，这些指标不能充分捕捉摘要质量的关键方面，例如事实准确性，特别是对于长篇叙述（&gt;100K 个标记）。最近的进展，例如 LLM-as-a-Judge，解决了基于词汇相似性的指标的局限性，但仍然表现出事实不一致，特别是在理解人物关系和状态方面。在这项工作中，我们引入了 NarrativeFactScore，这是一种用于评估和改进摘要的新型“Agent-as-a-Judge”框架。通过利用从输入和生成的摘要中提取的字符知识图 (CKG)，NarrativeFactScore 评估事实一致性并提供可操作的改进指导，例如识别缺失或错误的事实。我们通过详细的工作流程说明和广泛采用的基准的广泛验证证明了 NarrativeFactScore 的有效性，与竞争方法相比，其性能更出色。我们的结果凸显了代理驱动评估系统在提高 LLM 生成的摘要的事实可靠性方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.09993</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>注意力引导的自我反思在大型语言模型中的零样本幻觉检测</title>
      <link>https://arxiv.org/abs/2501.09997</link>
      <description><![CDATA[arXiv:2501.09997v1 公告类型：新
摘要：幻觉已成为有效应用大型语言模型 (LLM) 的重大障碍。在这项工作中，我们引入了一种新颖的注意力引导自我反思 (AGSER) 方法，用于 LLM 中的零样本幻觉检测。AGSER 方法利用注意力贡献将输入查询分类为注意和非注意查询。然后通过 LLM 分别处理每个查询，使我们能够计算生成的响应与原始答案之间的一致性分数。两个一致性分数之间的差异可作为幻觉估计器。除了在检测幻觉方面的功效外，AGSER 还显着降低了计算复杂度，只需要通过 LLM 三次并使用两组标记。我们已经在三个不同的幻觉基准上使用四种广泛使用的 LLM 进行了广泛的实验，证明我们的方法在零样本幻觉检测方面明显优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2501.09997</guid>
      <pubDate>Mon, 20 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>