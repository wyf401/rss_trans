<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 08 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>好书是复杂的事情：衡量不同类别的文学质量感知的复杂性概况</title>
      <link>https://arxiv.org/abs/2404.04022</link>
      <description><![CDATA[arXiv:2404.04022v1 公告类型：新
摘要：在这项研究中，我们采用分类方法来表明不同类别的文学“质量”表现出独特的语言特征，利用包含诺顿选集、企鹅经典系列和开放教学大纲项目的标题的语料库，与当代的文学“质量”进行对比畅销书、诺贝尔奖获得者和著名文学奖获得者。我们的分析表明，与其他质量类别（例如畅销书和流行书目）以及对照组相比，规范文本和所谓的高雅文本表现出独特的文本特征，可能对不同（但不是相互排斥）的质量模型做出反应。我们应用经典的机器学习方法，即随机森林，来区分优质小说和“对照组”，在区分类别方面取得了高达 77% 的 F1 分数。我们发现，与其他质量类别相比，质量类别往往更容易与对照组区分开，这表明文学质量特征可能是可区分的，但通过质量代理共享。]]></description>
      <guid>https://arxiv.org/abs/2404.04022</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:58 GMT</pubDate>
    </item>
    <item>
      <title>SemEval-2024 任务 2 中的 SEME：比较用于临床试验的自然语言推理的屏蔽语言模型和生成语言模型</title>
      <link>https://arxiv.org/abs/2404.03977</link>
      <description><![CDATA[arXiv:2404.03977v1 公告类型：新
摘要：本文描述了我们向 SemEval-2024 的任务 2 提交的内容：临床试验的安全生物医学自然语言推理。临床试验数据的多证据自然语言推理 (NLI4CT) 由文本蕴涵 (TE) 任务组成，重点评估应用于临床试验报告 (CTR) 的自然语言推理 (NLI) 模型的一致性和可信度。我们测试了两种不同的方法，一种基于微调和集成屏蔽语言模型，另一种基于使用模板提示大型语言模型，特别是使用思想链和对比思想链。在 2 次设置中提示 Flan-T5-large 会导致我们最好的系统达到 0.57 F1 分数、0.64 忠实度和 0.56 一致性。]]></description>
      <guid>https://arxiv.org/abs/2404.03977</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:57 GMT</pubDate>
    </item>
    <item>
      <title>研究少样本跨主题立场检测建模决策的鲁棒性：一项预先注册的研究</title>
      <link>https://arxiv.org/abs/2404.03987</link>
      <description><![CDATA[arXiv:2404.03987v1 公告类型：新
摘要：对于观点多样化的新闻推荐器来说，识别两篇新闻文章是否表达相同的观点至关重要。确定“相同或不同”观点的一种方法是姿态检测。在本文中，我们研究了少镜头姿态检测的操作化选择的稳健性，特别关注跨不同主题的姿态建模。我们的实验测试了预先注册的姿态检测假设。具体来说，我们比较了两种立场任务定义（赞成/反对与同方立场）、两种 LLM 架构（双编码与交叉编码），并添加自然语言推理知识，以及使用 100 个示例镜头训练的预训练 RoBERTa 模型来自 7 个不同姿态检测数据集。我们早期工作中的一些假设和主张可以得到证实，而另一些则给出了更加不一致的结果。同侧姿态定义对性能的影响因数据集而异，并且受到其他建模选择的影响。我们发现训练镜头中训练主题的数量与表现之间没有关系。一般来说，交叉编码的性能优于双向编码，并且在我们的模型中添加 NLI 训练可以带来相当大的改进，但这些结果在所有数据集上并不一致。我们的结果表明，当旨在为概念“立场”找到稳健的建模选择时，必须包含多个数据集和系统建模实验。]]></description>
      <guid>https://arxiv.org/abs/2404.03987</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:57 GMT</pubDate>
    </item>
    <item>
      <title>BuDDIE：用于多任务信息提取的商业文档数据集</title>
      <link>https://arxiv.org/abs/2404.04003</link>
      <description><![CDATA[arXiv:2404.04003v1 公告类型：新
摘要：视觉丰富的文档理解（VRDU）领域旨在解决多模态领域中大量经过深入研究的 NLP 任务。有几个数据集用于研究 VRDU 的特定任务，例如文档分类 (DC)、关键实体提取 (KEE)、实体链接、视觉问答 (VQA) 等。这些数据集涵盖带有稀疏注释的发票和收据等文档，以便它们支持一两个相关任务（例如，实体提取和实体链接）。不幸的是，仅关注单个特定的文档或任务并不能代表文档通常需要如何在野外处理 - 在这种情况下，期望有多种风格和要求。在本文中，我们介绍了 BuDDIE（用于信息提取的业务文档数据集），这是第一个包含 1,665 个真实业务文档的多任务数据集，其中包含 DC、KEE 和 VQA 的丰富而密集的注释。我们的数据集包含来自美国州政府网站的公开商业实体文件。这些文件的结构、风格和布局因州和类型而异（例如表格、证书、报告等）。我们为 BuDDIE 提供数据多样性和质量指标，以及每项任务的一系列基线。我们的基线涵盖 VRDU 的传统文本、多模式和大型语言模型方法。]]></description>
      <guid>https://arxiv.org/abs/2404.04003</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:57 GMT</pubDate>
    </item>
    <item>
      <title>增强生成语言模型中句子嵌入的简单技术</title>
      <link>https://arxiv.org/abs/2404.03921</link>
      <description><![CDATA[arXiv:2404.03921v1 公告类型：新
摘要：句子嵌入是自然语言处理领域的一项基本任务，在搜索引擎、专家系统和问答平台中得到广泛应用。随着LLaMA、Mistral等大型语言模型的不断演进，句子嵌入的研究最近取得了显着的突破。然而，这些进步主要与微调场景有关，使得对句子表示的计算有效的直接推理方法的探索仍处于初级阶段。本文致力于弥合这一研究空白。通过全面的实验，我们挑战了人们普遍认为从预训练语言模型 (PLM) 中导出句子嵌入时需要使用显式单字限制的信念。我们证明，这种方法虽然有利于直接推理场景下的生成模型，但对于判别模型或生成 PLM 的微调来说并不是必需的。这一发现为未来研究中手动模板的设计提供了新的思路。基于这一见解，我们提出了两种创新的即时工程技术，能够进一步增强 PLM 原始嵌入的表达能力：假想的思维链和知识增强。我们确认了它们在各种 PLM 类型中的有效性，并详细探讨了促成其成功的潜在因素。]]></description>
      <guid>https://arxiv.org/abs/2404.03921</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:56 GMT</pubDate>
    </item>
    <item>
      <title>数学应用题解决中的情境学习和比较评估的数据增强</title>
      <link>https://arxiv.org/abs/2404.03938</link>
      <description><![CDATA[arXiv:2404.03938v1 公告类型：新
摘要：数学应用题（MWP）的解决在自然语言处理（NLP）中提出了一项具有挑战性的任务。这项研究旨在为 MWP 求解者提供更加多样化的训练集，最终提高他们解决各种数学问题的能力。我们通过修改问题文本和方程提出了几种数据增强方法，例如同义词替换、基于规则的：问题替换和基于规则的：在两个英语 MWP 数据集上反转问题方法。这项研究通过引入一种新的情境学习增强方法（采用 Llama-7b 语言模型）进行了扩展。这种方法涉及基于指令的提示来重新表述数学问题文本。对 9 个基线模型进行了性能评估，结果表明增强方法优于基线模型。此外，连接由各种增强方法生成的示例进一步提高了性能。]]></description>
      <guid>https://arxiv.org/abs/2404.03938</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:56 GMT</pubDate>
    </item>
    <item>
      <title>联合关系三元组提取的双合并模型</title>
      <link>https://arxiv.org/abs/2404.03881</link>
      <description><![CDATA[arXiv:2404.03881v1 公告类型：新
摘要：当前提取关系三元组的方法直接基于原始句子中可能的实体对进行预测，而不依赖于实体识别。该任务存在严重的语义重叠问题，其中多个关系三元组可能共享句子中的一个或两个实体。学习与关系三元组相关的判别性语义特征很弱。本文基于二维句子表示，提出了一种双向合并模型，通过同时强化与关系三元组相关的局部和全局语义特征来解决这个问题。该模型由本地整合组件和全局整合组件组成。第一个组件使用像素差异卷积来增强来自相邻区域的可能三重表示的语义信息并减轻相邻区域中的噪声。第二个组件加强了基于通道注意力和空间注意力的三重表示，这有利于学习句子中的远程语义依赖关系。它们有助于提高关系三元组提取中实体识别和关系类型分类的性能。在对多个发布数据集进行评估后，它实现了具有竞争力的性能。分析实验证明了我们的模型在关系三元组提取方面的有效性，并为其他自然语言处理任务提供了动力。]]></description>
      <guid>https://arxiv.org/abs/2404.03881</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:55 GMT</pubDate>
    </item>
    <item>
      <title>SAAS：解决大型语言模型中增强数学推理的能力放大策略</title>
      <link>https://arxiv.org/abs/2404.03887</link>
      <description><![CDATA[arXiv:2404.03887v1 公告类型：新
摘要：本研究提出了一种新颖的学习方法，旨在增强大型语言模型（LLM）的数学推理和解决问题的能力。我们专注于整合思维链（CoT）和思维程序（PoT）学习，假设优先学习数学推理能力有助于放大解决问题的能力。因此，CoT 的初始学习对于解决具有挑战性的数学问题至关重要。为此，我们提出了一种顺序学习方法，称为SAAS（解决能力放大策略），策略性地从CoT学习过渡到PoT学习。我们的实证研究涉及使用多个基准进行广泛的性能比较，表明我们的 SAAS 实现了最先进的 (SOTA) 性能。结果强调了我们顺序学习方法的有效性，标志着法学硕士数学推理领域的重大进步。]]></description>
      <guid>https://arxiv.org/abs/2404.03887</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:55 GMT</pubDate>
    </item>
    <item>
      <title>忘记 NLI，使用字典：低资源语言的零样本主题分类及其在卢森堡语中的应用</title>
      <link>https://arxiv.org/abs/2404.03912</link>
      <description><![CDATA[arXiv:2404.03912v1 公告类型：新
摘要：在自然语言处理中，零样本分类（ZSC）是在没有任何目标类标记示例的情况下为文本数据分配标签的任务。 ZSC 的常见方法是在自然语言推理 (NLI) 数据集上微调语言模型，然后使用它来推断输入文档和目标标签之间的蕴涵。然而，这种方法面临着一定的挑战，特别是对于资源有限的语言。在本文中，我们提出了一种替代解决方案，利用字典作为 ZSC 的数据源。我们关注卢森堡语（卢森堡语）这种资源匮乏的语言，并基于提供各种同义词、单词翻译和例句的词典构建了两个新的主题相关性分类数据集。我们评估数据集的可用性，并以零样本方式将其与基于 NLI 的方法在两个主题分类任务上进行比较。我们的结果表明，通过使用基于字典的数据集，训练后的模型优于采用基于 NLI 的 ZSC 方法的模型。虽然我们在这项研究中专注于单一的低资源语言，但我们相信我们的方法的功效也可以转移到有此类词典的其他语言。]]></description>
      <guid>https://arxiv.org/abs/2404.03912</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:55 GMT</pubDate>
    </item>
    <item>
      <title>可通过设计验证：调整语言模型以引用预训练数据</title>
      <link>https://arxiv.org/abs/2404.03862</link>
      <description><![CDATA[arXiv:2404.03862v1 公告类型：新
摘要：为了让人类信任大型语言模型（LLM）的流畅生成，他们必须能够根据可信的外部来源验证其正确性。最近的努力旨在通过引用检索到的文件或事后出处来提高可验证性。然而，此类引文很容易出现错误，从而使其可验证性进一步复杂化。为了解决这些限制，我们用不同的理念来解决可验证性目标：我们通过开发在预训练数据中引用来自可信来源的逐字陈述的模型来简化验证过程。我们提出了 Quote-Tuning，它展示了调整法学硕士以利用记忆信息和来自预训练数据的引用的可行性。 Quote-Tuning 使用高效的成员推理工具对大型语料库的引用进行量化，并使用引用数量作为隐式奖励信号来构建用于引用的综合偏好数据集，而无需任何人工注释。接下来，使用偏好优化算法将目标模型对齐以进行报价。实验结果表明，与未调整的模型相比，Quote-Tuning 显着提高了 LLM 生成逐字引用高质量预训练文档的百分比，提高了 55% 至 130%，同时保持了响应质量。进一步的实验表明，引用调优将引用推广到域外数据，适用于不同的任务，并为真实性提供了额外的好处。报价调整不仅可以作为一种增加报价的无忧方法，而且还为通过更好的可验证性来提高 LLM 可信度开辟了途径。]]></description>
      <guid>https://arxiv.org/abs/2404.03862</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:54 GMT</pubDate>
    </item>
    <item>
      <title>FFN-SkipLLM：具有自适应前馈跳跃的自回归解码的隐藏宝石</title>
      <link>https://arxiv.org/abs/2404.03865</link>
      <description><![CDATA[arXiv:2404.03865v1 公告类型：新
摘要：自回归大型语言模型（例如 LLaMa、GPT）无处不在，在语言理解和生成方面取得了显着的成功。然而，如此令人印象深刻的功能通常伴随着巨大的模型大小，这对逐个令牌的自回归生成提出了重大挑战。为了减轻生成过程中发生的计算过载，已经提出了几种提前退出和分层策略。尽管由于法学硕士层在 Rough-L/BLUE 等指标上的冗余而取得了一些有希望的成功，但我们仔细的知识密集型评估揭示了诸如世代崩溃、错误事实的幻觉以及即使在 10 的微不足道的退出率下性能也明显下降等问题。 -15% 的层数。我们将这些错误主要归因于提前退出期间通过状态复制对 KV 缓存的无效处理。在这项工作中，我们观察了 LLM 层计算成本高昂的前馈块的饱和，并提出了 FFN-SkipLLM，这是一种新型的自回归 LLM 细粒度跳跃策略。更具体地说，FFN-SkipLLM 是一种输入自适应前馈跳跃策略，可以跳过 LLM 的 25-30% FFN 块，在知识密集型生成任务上的性能略有变化，而无需处理 KV 缓存。我们在 MT-Bench、Factoid-QA 和可变长度文本摘要等基准测试中进行了大量实验和消融，说明了我们简单易用的方法如何促进更快的自回归解码。]]></description>
      <guid>https://arxiv.org/abs/2404.03865</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:54 GMT</pubDate>
    </item>
    <item>
      <title>提取、定义、规范化：基于法学硕士的知识图谱构建框架</title>
      <link>https://arxiv.org/abs/2404.03868</link>
      <description><![CDATA[arXiv:2404.03868v1 公告类型：新
摘要：在这项工作中，我们对从输入文本创建知识图（KGC）的自动化方法感兴趣。大语言模型 (LLM) 的进展促使最近一系列将其应用于 KGC 的工作，例如通过零/少样本提示。尽管在小型特定领域数据集上取得了成功，但这些模型在扩展到许多实际应用程序中常见的文本时面临着困难。一个主要问题是，在以前的方法中，KG 模式必须包含在 LLM 提示中才能生成有效的三元组；更大、更复杂的模式很容易超出法学硕士的上下文窗口长度。为了解决这个问题，我们提出了一个名为提取-定义-规范化（EDC）的三阶段框架：开放信息提取，然后是模式定义和事后规范化。 EDC 非常灵活，因为它可以应用于预定义目标模式可用和不可用的设置；在后一种情况下，它会自动构建模式并应用自我规范化。为了进一步提高性能，我们引入了一个经过训练的组件，用于检索与输入文本相关的模式元素；这以类似检索增强生成的方式提高了法学硕士的提取性能。我们在三个 KGC 基准测试中证明，EDC 能够在不进行任何参数调整的情况下提取高质量的三元组，并且与之前的工作相比，其模式要大得多。]]></description>
      <guid>https://arxiv.org/abs/2404.03868</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:54 GMT</pubDate>
    </item>
    <item>
      <title>SHROOM-INDElab 在 SemEval-2024 任务 6：基于零和少样本 LLM 的幻觉检测分类</title>
      <link>https://arxiv.org/abs/2404.03732</link>
      <description><![CDATA[arXiv:2404.03732v1 公告类型：新
摘要：我们描述了阿姆斯特丹大学智能数据工程实验室团队参加 SemEval-2024 Task 6 竞赛的情况。 SHROOM-INDElab 系统建立在之前的工作基础上，即使用即时编程和上下文学习与大型语言模型 (LLM) 来构建用于幻觉检测的分类器，并通过结合任务、角色和任务的上下文特定定义来扩展该工作。目标概念，以及自动生成示例以用于几次提示方法。由此产生的系统在任务 6 的模型不可知轨道和模型感知轨道中分别取得了第四好和第六好的性能，并且使用验证集的评估表明系统的分类决策与众包的分类决策一致人类贴标签员。我们进一步发现，使用自动生成的示例，零样本方法比少样本方法提供了更好的准确性。本文所述系统的代码可在 Github 上找到。]]></description>
      <guid>https://arxiv.org/abs/2404.03732</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:53 GMT</pubDate>
    </item>
    <item>
      <title>PRObELM：语言模型的合理性排名评估</title>
      <link>https://arxiv.org/abs/2404.03818</link>
      <description><![CDATA[arXiv:2404.03818v1 公告类型：新
摘要：本文介绍了 PRObELM（语言模型的合理性排名评估），这是一个基准，旨在评估语言模型通过其参数知识辨别更合理场景和不太合理场景的能力。虽然 TruthfulQA 等基准强调事实的准确性或真实性，而 COPA 等其他基准则在没有明确纳入世界知识的情况下探索合理的场景，而 PRObELM 试图通过评估模型的能力来弥合这一差距，以优先考虑利用世界知识的合理场景，而不是不太合理的替代方案。这种设计使我们能够评估语言模型在下游用例中的潜力，例如基于文献的发现，其重点是识别可能但尚未知道的信息。我们的基准是根据维基数据编辑历史整理的数据集构建的，旨在调整评估模型的训练数据的时间范围。 PRObELM 有助于跨多种提示类型评估语言模型，包括陈述、文本完成和问答。对 10 个不同规模和架构的模型进行了关于模型规模、训练新近度和合理性性能之间关系的实验，结果表明事实准确性并不与合理性性能直接相关，而且最新的训练数据增强了不同模型架构之间的合理性评估。]]></description>
      <guid>https://arxiv.org/abs/2404.03818</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:53 GMT</pubDate>
    </item>
    <item>
      <title>CantTalkAboutThis：调整语言模型以保持对话主题</title>
      <link>https://arxiv.org/abs/2404.03820</link>
      <description><![CDATA[arXiv:2404.03820v1 公告类型：新
摘要：指令调整数据集的最新进展主要集中在数学或逻辑推理等特定任务上。旨在调整语言模型以保持对话中主题相关性的数据存在显着差距——这是将聊天机器人部署到生产中的一个关键方面。我们引入 CantTalkAboutThis 数据集来帮助语言模型在面向任务的交互过程中保持关注当前的主题。它由来自不同领域的广泛对话主题的综合对话组成。这些对话中穿插着一些干扰性的对话，有意将聊天机器人从预定义的主题上转移开。与 GPT-4-turbo 和 Mixtral-Instruct 等通用指令调整的 LLM 相比，在此数据集上微调语言模型有助于使它们能够适应偏离分配的角色，并提高其保持主题连贯性的能力。此外，初步观察表明，该数据集上的训练模型还可以提高其在细粒度指令跟踪任务中的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.03820</guid>
      <pubDate>Mon, 08 Apr 2024 06:27:53 GMT</pubDate>
    </item>
    </channel>
</rss>