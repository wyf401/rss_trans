<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 09 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>人物角色设定陷阱：大型语言模型中因社会身份采用而产生的持续性外群体偏见</title>
      <link>https://arxiv.org/abs/2409.03843</link>
      <description><![CDATA[arXiv:2409.03843v1 公告类型：新
摘要：将人类认知与人工智能进行比较，我们探索了大型语言模型 (LLM) 如何内化有针对性的提示所强加的身份。根据社会认同理论，这些身份分配使 LLM 能够区分“我们”（内群体）和“他们”（外群体）。这种自我分类会产生内群体偏袒和外群体偏见。尽管如此，现有文献主要关注内群体偏袒，往往忽视外群体偏见，这是群体间偏见和歧视的根本原因。我们的实验通过证明外群体偏见与内群体偏袒一样强烈地表现出来，解决了这一差距。此外，我们通过引导 LLM 采用最初不受青睐的群体的观点，成功地减轻了他们固有的亲自由主义、反保守主义偏见。这些结果在性别偏见的背景下得到了复制。我们的研究结果强调了开发更公平、更平衡的语言模型的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.03843</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Sirius：针对高效 LLM 的上下文稀疏性校正</title>
      <link>https://arxiv.org/abs/2409.03856</link>
      <description><![CDATA[arXiv:2409.03856v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的蓬勃发展，推理效率变得越来越重要。提出了各种近似方法来降低推理时的成本。上下文稀疏性 (CS) 因其无需训练的性质以及在不降低质量的情况下达到更高压缩比的能力而受到青睐。然而，在对各种复杂生成任务上的上下文稀疏性方法进行全面评估后，我们发现尽管 CS 在快速理解任务中取得了成功，但 CS 显著降低了推理、推理和基于知识的任务的模型性能。尽管端到端准确性存在差距，但我们观察到稀疏模型通常共享一般的问题解决逻辑，只需要少量标记校正即可恢复原始模型性能。本文介绍了一种有效的校正机制 Sirius，它在保持其效率增益的同时显著恢复了 CS 模型在推理任务上的质量。 Sirius 在 6 个模型上进行了评估，涉及 8 个推理、数学和编码方面的困难生成任务，并显示出一致的有效性和效率。此外，我们精心开发了 Sirius 的系统实现，并表明 Sirius 可将 8B 模型片上延迟减少约 20%，将 70B 模型卸载延迟减少 35%。我们在 https://github.com/Infini-AI-Lab/Sirius.git 上开源了 Sirius 的实现。]]></description>
      <guid>https://arxiv.org/abs/2409.03856</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CACER：癌症事件和关系的临床概念注释</title>
      <link>https://arxiv.org/abs/2409.03905</link>
      <description><![CDATA[arXiv:2409.03905v1 公告类型：新
摘要：临床笔记包含患者病史的非结构化表示，包括医疗问题和处方药之间的关系。为了研究癌症药物与其相关症状负担之间的关系，我们从肿瘤学笔记的临床叙述中提取了医疗问题和药物信息的结构化语义表示。我们提出了癌症事件和关系的临床概念注释 (CACER)，这是一个新颖的语料库，其中包含超过 48,000 个医疗问题和药物事件以及 10,000 个药物问题和问题问题关系的细粒度注释。利用 CACER，我们使用微调和上下文学习 (ICL) 开发和评估基于变压器的信息提取 (IE) 模型，例如 BERT、Flan-T5、Llama3 和 GPT-4。在事件提取中，经过微调的 BERT 和 Llama3 模型取得了 88.2-88.0 F1 的最高性能，这与 88.4 F1 的注释者间一致性 (IAA) 相当。在关系提取中，经过微调的 BERT、Flan-T5 和 Llama3 取得了 61.8-65.3 F1 的最高性能。带有 ICL 的 GPT-4 在两个任务中的表现最差。经过微调的模型在 ICL 中的表现明显优于 GPT-4，凸显了带注释的训练数据和模型优化的重要性。此外，BERT 模型的表现与 Llama3 相似。对于我们的任务，LLM 并不比较小的 BERT 模型具有性能优势。结果强调了对带注释的训练数据进行优化模型的必要性。多个经过微调的 Transformer 模型在几个提取任务中实现了与 IAA 相当的性能。]]></description>
      <guid>https://arxiv.org/abs/2409.03905</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 RWKV 进行内容审核的实验</title>
      <link>https://arxiv.org/abs/2409.03939</link>
      <description><![CDATA[arXiv:2409.03939v1 公告类型：新
摘要：本文通过有针对性的实验研究了 RWKV 模型在内容审核中的有效性。我们引入了一个专门设计用于提炼成较小模型的新数据集，以增强内容审核实践。这个综合数据集涵盖了代表社会挑战的图像、视频、声音和文本数据。利用先进的大型语言模型 (LLM)，我们生成了一组广泛的响应——文本 558,958 个，图像 83,625 个——以训练和改进内容审核系统。我们的核心实验涉及微调 RWKV 模型，利用其 CPU 高效的架构来解决大规模内容审核任务。通过强调数据集的知识提炼潜力，这项研究不仅展示了 RWKV 在提高内容审核系统的准确性和效率方面的能力，而且为开发更紧凑、资源高效的模型铺平了道路。数据集和模型可以在 HuggingFace 中找到：https://huggingface.co/modrwkv]]></description>
      <guid>https://arxiv.org/abs/2409.03939</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>论提示构造在提升基于 LLM 的表格数据生成效率和效果中的作用</title>
      <link>https://arxiv.org/abs/2409.03946</link>
      <description><![CDATA[arXiv:2409.03946v1 公告类型：新
摘要：基于 LLM 的真实表格数据生成可能面临挑战，因为用于描述列的特征名称缺乏足够的语义上下文。我们假设，通过领域特定见解丰富提示可以提高数据生成的质量和效率。为了检验这一假设，我们探索了三种提示构建协议：专家指导、LLM 指导和 Novel-Mapping。通过对最近提出的 GReaT 框架进行实证研究，我们发现上下文丰富的提示可以显著提高数据生成质量和训练效率。]]></description>
      <guid>https://arxiv.org/abs/2409.03946</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有细粒度特征的少样本关系分类的大边距原型网络</title>
      <link>https://arxiv.org/abs/2409.04009</link>
      <description><![CDATA[arXiv:2409.04009v1 公告类型：新
摘要：关系分类 (RC) 在自然语言理解和知识图谱补全中都起着关键作用。它通常被表述为识别自由文本句子中出现的两个感兴趣实体之间的关系的任务。无论是基于特征工程还是基于深度学习，传统的 RC 方法都可以在对常见关系类型进行分类时获得良好的性能，而由于训练的标记实例不足，留下了很大一部分无法识别的长尾关系。在本文中，我们认为小样本学习对 RC 具有重要的实际意义，从而改进了小样本 RC 的现代度量学习框架。具体来说，我们采用具有细粒度特征的大边距 ProtoNet，期望它们能够很好地推广到长尾关系。使用大规模监督小样本 RC 数据集 FewRel 进行了大量实验，以评估我们的框架：LM-ProtoNet (FGF)。结果表明，它可以比许多基线方法实现显着的改进。]]></description>
      <guid>https://arxiv.org/abs/2409.04009</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向更安全的网络空间：模拟和评估饮食失调讨论的干预策略</title>
      <link>https://arxiv.org/abs/2409.04043</link>
      <description><![CDATA[arXiv:2409.04043v1 公告类型：新
摘要：饮食失调是一种复杂的心理健康状况，影响着全世界数百万人。社交媒体平台上的有效干预至关重要，但现场测试策略可能会有风险。我们提出了一种新颖的 LLM 驱动实验测试平台，用于模拟和评估 ED 相关讨论中的干预策略。我们的框架会在多个平台、模型和 ED 相关主题上生成合成对话，从而允许对各种干预方法进行受控实验。我们分析了各种干预策略对四个维度的对话动态的影响：干预类型、生成模型、社交媒体平台和 ED 相关社区/主题。我们使用认知领域分析指标（包括情绪、情感等）来评估干预的有效性。我们的研究结果表明，以文明为重点的干预措施始终如一地改善各个维度的积极情绪和情绪基调，而洞察力重置方法往往会增加负面情绪。我们还发现 LLM 生成的对话中存在显著的偏见，认知指标在模型之间（Claude-3 Haiku $&gt;$ Mistral $&gt;$ GPT-3.5-turbo $&gt;$ LLaMA3）甚至同一模型的不同版本之间都存在显著差异。这些差异凸显了模型选择在模拟与 ED 相关的现实讨论中的重要性。我们的工作为 ED 相关讨论的复杂动态和各种干预策略的有效性提供了宝贵的信息。]]></description>
      <guid>https://arxiv.org/abs/2409.04043</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自我协调的思维链</title>
      <link>https://arxiv.org/abs/2409.04057</link>
      <description><![CDATA[arXiv:2409.04057v1 公告类型：新
摘要：思路链 (CoT) 提示表明大型语言模型能够通过中间步骤执行复杂的推理。CoT 提示主要分为三种方法。第一种方法利用简单的提示，如“让我们一步一步思考”，在得出答案之前生成一个连续的思维过程。第二种方法利用人工制作的分步演示来指导模型的推理过程。第三种方法使用“让我们一步一步思考”自动生成推理演示。这种方法有时会导致推理错误，强调需要多样化演示以减轻其误导性影响。然而，多样化的演示对有效的表示提出了挑战。在这项工作中，我们提出了一种自我协调的思路链提示方法 ECHO。它将不同的解决路径整合为统一有效的解决模式。ECHO 在三个推理领域表现出最佳的整体性能。]]></description>
      <guid>https://arxiv.org/abs/2409.04057</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AnyMatch——使用小型语言模型实现高效的零样本实体匹配</title>
      <link>https://arxiv.org/abs/2409.04073</link>
      <description><![CDATA[arXiv:2409.04073v1 公告类型：新
摘要：实体匹配 (EM) 是确定两个记录是否指向同一个现实世界实体的问题，这在数据集成中至关重要，例如，对于产品目录或地址数据库。许多 EM 方法的主要缺点是它们依赖于标记示例。因此，我们将重点放在零样本实体匹配的具有挑战性的设置上，其中没有可用于未见目标数据集的标记示例。最近，大型语言模型 (LLM) 在零样本 EM 方面显示出有希望的结果，但它们的低吞吐量和高部署成本限制了它们的适用性和可扩展性。
我们使用 AnyMatch（一种在迁移学习设置中微调的小型语言模型）重新审视零样本 EM 问题。我们提出了几种新颖的数据选择技术来为我们的模型生成微调数据，例如，通过 AutoML 过滤器选择难以匹配的对，通过生成额外的属性级示例，以及通过控制数据中的标签不平衡。
我们对模型的预测质量和部署成本进行了广泛的评估，并与九个基准数据集上的十三个基线进行了比较。我们发现，尽管 AnyMatch 的参数规模很小，但它提供了具有竞争力的预测质量：它总体上获得了第二高的 F1 分数，并且优于其他几种采用具有数千亿个参数的模型的方法。此外，我们的方法还表现出巨大的成本效益：AnyMatch 的平均预测质量与最先进的方法 MatchGPT（采用专有的万亿参数模型 GPT-4）相差 4.4% 以内，但 AnyMatch 所需的参数减少了四个数量级，推理成本降低了 3,899 倍（以每 1,000 个 token 计算）。]]></description>
      <guid>https://arxiv.org/abs/2409.04073</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>UI-JEPA：通过屏幕用户活动主动感知用户意图</title>
      <link>https://arxiv.org/abs/2409.04081</link>
      <description><![CDATA[arXiv:2409.04081v1 公告类型：新
摘要：从一系列用户界面 (UI) 操作中生成用户意图是全面理解 UI 的核心挑战。多模态大型语言模型 (MLLM) 的最新进展已导致该领域取得了实质性进展，但它们对大量模型参数、计算能力和高延迟的要求使其不适用于需要轻量级、低延迟或高度隐私的设备解决方案的场景。此外，缺乏高质量的数据集阻碍了此类轻量级模型的开发。为了应对这些挑战，我们提出了 UI-JEPA，这是一个新颖的框架，它采用掩蔽策略通过自监督学习从未标记数据中学习抽象的 UI 嵌入，并结合针对用户意图预测进行微调的 LLM 解码器。我们还介绍了两个新的基于 UI 的多模态数据集，“Intent in the Wild”（IIW）和“Intent in the Tame”（IIT），专为少样本和零样本 UI 理解任务而设计。 IIW 包含 219 个意图类别的 1.7K 个视频，而 IIT 包含 10 个类别的 914 个视频。我们为这些数据集建立了第一个基线，表明使用 JEPA 样式目标与 LLM 解码器相结合学习的表示可以实现与最先进的大型 MLLM 性能相匹配的用户意图预测，但注释和部署资源显着减少。以意图相似度得分衡量，UI-JEPA 在两个数据集的平均表现分别比 GPT-4 Turbo 和 Claude 3.5 Sonnet 高出 10.0% 和 7.2%。值得注意的是，UI-JEPA 在 IIW 数据集中将计算成本降低了 50.5 倍，延迟提高了 6.6 倍。这些结果强调了 UI-JEPA 的有效性，凸显了其在轻量级、高性能 UI 理解方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.04081</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 能产生新颖的研究想法吗？一项有 100 多名 NLP 研究人员参与的大规模人类研究</title>
      <link>https://arxiv.org/abs/2409.04109</link>
      <description><![CDATA[arXiv:2409.04109v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展引发了人们对其加速科学发现潜力的乐观情绪，越来越多的研究提出了能够自主生成和验证新想法的研究代理。尽管如此，没有任何评估表明 LLM 系统可以迈出产生新颖的专家级想法的第一步，更不用说执行整个研究过程了。我们通过建立一个实验设计来解决这个问题，该实验设计在控制混杂因素的同时评估研究想法的生成，并对专家 NLP 研究人员和 L​​LM 构思代理进行首次正面比较。通过招募 100 多名 NLP 研究人员来撰写新颖的想法并对 LLM 和人类想法进行盲审，我们获得了关于当前 LLM 研究构思能力的第一个具有统计意义的结论：我们发现 LLM 产生的想法被判断为比人类专家想法更新颖（p &lt; 0.05），而在可行性方面被判断为略弱。通过仔细研究我们的代理基线，我们发现了构建和评估研究代理方面存在的未解决的问题，包括 LLM 自我评估失败以及生成多样性的缺乏。最后，我们承认人类对新颖性的判断可能很困难，即使是专家也很难判断，因此我们提出了一种端到端的研究设计，招募研究人员将这些想法付诸实施，从而使我们能够研究这些新颖性和可行性判断是否会导致研究结果产生有意义的差异。]]></description>
      <guid>https://arxiv.org/abs/2409.04109</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于大型语言模型代码生成的多编程语言集成</title>
      <link>https://arxiv.org/abs/2409.04114</link>
      <description><![CDATA[arXiv:2409.04114v1 公告类型：新
摘要：大型语言模型 (LLM) 显著改进了代码生成，尤其是在一次性代码生成中。然而，大多数现有方法仅侧重于用单一编程语言生成代码，而忽略了利用 LLM 的多语言功能的潜力。LLM 在不同语言中具有不同的错误模式，这表明可以通过利用这些多语言输出来开发更强大的方法。在本研究中，我们提出了多编程语言集成 (MPLE)，这是一种基于集成的新型方法，它利用多种编程语言的代码生成来提高整体性能。通过将每种特定于语言的代码生成过程视为单独的“弱专家”并有效地整合它们的输出，我们的方法可以减轻特定于语言的错误和偏差。这种多语言集成策略利用不同编程语言的互补优势，使模型能够生成更准确、更强大的代码。我们的方法可以与反射算法和蒙特卡洛树搜索等常用技术无缝集成，以进一步提高代码生成质量。实验结果表明，我们的框架在现有基准测试（HumanEval 和 HumanEval-plus）上持续将基线性能提高高达 17.92%，在 HumanEval 基准测试中获得了 96.25% 的出色准确率，在各种 LLM 模型中取得了新的最先进结果。代码将在 https://github.com/NinjaTech-AI/MPLE 发布]]></description>
      <guid>https://arxiv.org/abs/2409.04114</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于提示的性格分析：相关性过滤的强化学习</title>
      <link>https://arxiv.org/abs/2409.04122</link>
      <description><![CDATA[arXiv:2409.04122v1 公告类型：新
摘要：作者分析是通过分析个人分享的内容来推断个人特征的任务。尽管使用大型语言模型来解决自然语言理解任务很流行，但监督机器学习仍然在执行此任务的自动系统中占据主导地位。原因之一是分类实例由大量帖子组成，可能是整个用户资料，这可能会超过 Transformers 的输入长度。即使模型可以使用大型上下文窗口，整个帖子也会使 API 访问的黑盒系统的应用成本高昂且速度慢，此外还有这种“大海捞针”任务带来的问题。为了缓解这一限制，我们提出了一种新的作者分析方法，旨在首先区分相关内容和不相关内容，然后仅使用相关数据进行实际用户分析。为了避免对相关性注释数据的需求，我们通过强化学习优化了此相关性过滤器，并使用了奖励函数，该函数利用了大型语言模型的零样本能力。我们在两个 Twitter 语料库上评估了我们的“大五人格特质”预测方法。在具有倾斜标签分布的公开现实世界数据上，我们的方法显示出与使用用户个人资料中的所有帖子类似的效果，但上下文要短得多。对这些数据与人工帖子平衡的版本的评估表明，过滤相关帖子可显著提高预测的准确性。]]></description>
      <guid>https://arxiv.org/abs/2409.04122</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一枚硬币有两面：一种用于中文拼写校正的新型检测校正框架</title>
      <link>https://arxiv.org/abs/2409.04150</link>
      <description><![CDATA[arXiv:2409.04150v1 公告类型：新
摘要：中文拼写纠正（CSC）是一项基础的自然语言处理（NLP）任务，主要侧重于纠正中文文本中的错误字符。某些现有方法选择解开错误纠正过程，使用额外的错误检测器来精确定位错误位置。然而，由于错误检测器固有的性能限制，精度和召回率就像硬币的两面，不能同时朝上。此外，如何明智地应用错误位置信息来协助错误纠正也是值得研究的。在本文中，我们介绍了一种基于错误检测器-校正器框架的新方法。我们的检测器旨在产生两个错误检测结果，每个结果都具有高精度和召回率的特点。鉴于错误的发生与上下文有关，检测结果可能不太精确，我们使用创新的特征融合策略和选择性掩蔽策略将错误检测结果合并到 CSC 任务中。在主流 CSC 数据集上进行的经验实验证实了我们提出的方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.04150</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenSource 能打败 ChatGPT 吗？——文本到代码生成的大型语言模型的比较研究</title>
      <link>https://arxiv.org/abs/2409.04164</link>
      <description><![CDATA[arXiv:2409.04164v1 公告类型：新 
摘要：近年来，大型语言模型 (LLM) 已成为强大的工具，在软件工程等各个领域都有潜在的应用。在本研究范围内，我们评估了五种不同的最先进的 LLM - Bard、BingChat、ChatGPT、Llama2 和 Code Llama - 关于它们的文本到代码生成能力。在一项实证研究中，我们将来自编程网站 LeetCode 的编码问题的文本描述提示输入到模型中，并要求模型用 Python 创建解决方案。随后，使用 LeetCode 的测试功能评估生成的输出的质量。结果表明，所研究模型之间的性能差异很大。ChatGPT 可以最有效地处理这些典型的编程挑战，甚至超越了 Code Llama 等代码专用模型。为了获得进一步的见解，我们测量了生成输出的运行时间和内存使用情况，并将它们与 Leetcode 上的其他代码提交进行了比较。详细的错误分析包括比较生成代码的正确缩进和形式的差异，以及将错误解决的任务分配给某些错误类别，这使我们能够更细致地了解结果和改进潜力。结果还显示出，当模型面对较长提示形式的大量上下文时，生成的代码越来越不正确。]]></description>
      <guid>https://arxiv.org/abs/2409.04164</guid>
      <pubDate>Mon, 09 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>