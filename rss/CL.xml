<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Mon, 29 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>TIGQA：提格里尼亚语专家注释问答数据集</title>
      <link>https://arxiv.org/abs/2404.17194</link>
      <description><![CDATA[arXiv:2404.17194v1 公告类型：新
摘要：缺乏用于教育目的的明确定制的、可访问的注释数据集，给资源有限的语言中的 NLP 任务带来了显着的障碍。本研究初步探讨了使用机器翻译 (MT) 将现有数据集转换为 Tigrinya 数据集的可行性。小队格式。因此，我们推出了 TIGQA，这是一个专家注释的教育数据集，由 2680 个问答对组成，涵盖气候、水和交通等 122 个不同主题。这些对来自可公开访问的提格里尼亚语和生物学书籍中的 537 个上下文段落。通过综合分析，我们证明 TIGQA 数据集需要的技能不仅仅是简单的单词匹配，还需要单句和多句推理能力。我们使用最先进的 MRC 方法进行实验，这标志着在 TIGQA 上首次探索此类模型。此外，我们还估计了数据集上的人类表现，并将其与预训练模型获得的结果并列。人类表现和最佳模型表现之间的显着差异强调了通过持续研究进一步增强 TIGQA 的潜力。我们的数据集可通过提供的链接免费访问，以鼓励研究界应对 Tigrinya MRC 中的挑战。]]></description>
      <guid>https://arxiv.org/abs/2404.17194</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:57 GMT</pubDate>
    </item>
    <item>
      <title>以 GPT 为支点，缓解资源贫乏语言中代码转换数据稀缺的问题</title>
      <link>https://arxiv.org/abs/2404.17216</link>
      <description><![CDATA[arXiv:2404.17216v1 公告类型：新
摘要：许多多语言社区，包括非洲的许多多语言社区，在对话过程中经常进行语码转换。这种行为强调了对擅长处理代码转换文本的自然语言处理技术的需求。然而，数据稀缺，特别是非洲语言的数据稀缺，构成了重大挑战，因为许多数据资源匮乏且代表性不足。在这项研究中，我们促使 GPT 3.5 生成南非荷兰语（英语）和约鲁巴语（英语）语码转换句子，使用主题关键字对、语言指南和少量示例来增强多样性。我们的研究结果表明，与南非荷兰语-英语的高成功率相比，使用非拉丁文字（如约鲁巴语）的语言生成的句子质量要低得多。因此，这是一个改进提示准则以产生适合语言模型微调的句子的显着机会。我们提出了一个使用 GPT 增强综合生成的代码转换数据多样性的框架，并建议利用该技术来缓解资源匮乏语言的数据稀缺性，强调母语人士在这一过程中的重要作用。]]></description>
      <guid>https://arxiv.org/abs/2404.17216</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:57 GMT</pubDate>
    </item>
    <item>
      <title>使用日本报纸和付费墙量化特定领域预训练语言模型的记忆</title>
      <link>https://arxiv.org/abs/2404.17143</link>
      <description><![CDATA[arXiv:2404.17143v1 公告类型：新
摘要：占主导地位的预训练语言模型（PLM）在高质量自然语言生成方面取得了成功。然而，对他们这一代人的分析并不成熟：他们是否获得了可概括的语言抽象，或者他们只是简单地记忆和恢复训练数据的子串？特别是，很少有研究关注特定领域的 PLM。在本研究中，我们使用有限的日本报纸文章语料库预训练了特定领域的 GPT-2 模型，并通过将它们与一般的日本 GPT-2 模型进行比较来量化训练数据的记忆。我们的实验表明，特定领域的 PLM 有时会大规模“复制和粘贴”。此外，我们在日语中复制了记忆与重复、模型大小和提示长度相关的经验发现，与之前的英语研究相同。通过关注报纸付费墙，我们的评估消除了数据污染的担忧，这阻止了它们用作训练数据。我们希望我们的论文能够鼓励人们进行合理的讨论，例如 PLM 的安全性和版权。]]></description>
      <guid>https://arxiv.org/abs/2404.17143</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>用于少样本命名实体识别的统一标签感知对比学习框架</title>
      <link>https://arxiv.org/abs/2404.17178</link>
      <description><![CDATA[arXiv:2404.17178v1 公告类型：新
摘要：少样本命名实体识别（NER）旨在仅使用有限数量的标记示例来提取命名实体。现有的对比学习方法常常面临上下文向量表示的可区分性不足的问题，因为它们要么仅仅依赖标签语义，要么完全忽视它们。为了解决这个问题，我们提出了一个统一的标签感知令牌级对比学习框架。我们的方法通过利用标签语义作为后缀提示来丰富上下文。此外，它同时优化上下文-上下文和上下文-标签对比学习目标，以增强广义判别性上下文表示。在各种传统测试领域（OntoNotes、CoNLL&#39;03、WNUT&#39;17、GUM、I2B2）和大规模少数领域进行了大量实验-shot NER 数据集（FEWNERD）证明了我们方法的有效性。它的性能显着优于之前最先进的模型，在大多数情况下，微 F1 分数的平均绝对增益达到 7%。进一步的分析表明，我们的模型受益于其强大的传输能力和改进的上下文表示。]]></description>
      <guid>https://arxiv.org/abs/2404.17178</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>使用零样本分类的社交焦虑情绪和身体症状的普遍频率：一项观察性研究</title>
      <link>https://arxiv.org/abs/2404.17183</link>
      <description><![CDATA[arXiv:2404.17183v1 公告类型：新
摘要：社交焦虑是现代社会普遍存在的挑战，影响着个人和职业领域的个人。如果不加以解决，这种情况会产生严重的负面影响，影响社交互动和表现。进一步了解其多样化的身体和情绪症状对于全面诊断和量身定制的治疗干预至关重要。本研究分析了梅奥诊所的社交焦虑症状的患病率和频率，利用专门针对此问题的大型 Reddit 数据集探索了不同的人类体验。利用这些平台，该研究旨在提取见解并检查与社交焦虑症相关的一系列身体和情绪症状。出于道德考虑，该研究在数据集内保持严格的用户匿名性。通过采用一种新颖的方法，该研究利用基于 BART 的多标签零样本分类来识别和测量症状的患病率和重要性，形式为所考虑的每个症状的概率得分。研究结果揭示了独特的模式：“颤抖”是一种普遍的身体症状，而“害怕被负面评价”等情绪症状出现的频率很高。这些发现有助于深入了解社交焦虑的多面性，有助于针对其多种表现形式制定临床实践和干预措施。]]></description>
      <guid>https://arxiv.org/abs/2404.17183</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:56 GMT</pubDate>
    </item>
    <item>
      <title>2M-NER：通过语言和模态融合进行多语言和多模态 NER 的对比学习</title>
      <link>https://arxiv.org/abs/2404.17122</link>
      <description><![CDATA[arXiv:2404.17122v1 公告类型：新
摘要：命名实体识别（NER）是自然语言处理中的一项基本任务，涉及识别句子中的实体并将其分类为预定义的类型。它在实体链接、问答和在线产品推荐等各个研究领域中发挥着至关重要的作用。最近的研究表明，整合多语言和多模式数据集可以提高 NER 的有效性。这是由于语言迁移学习和不同模态之间共享隐式特征的存在。然而，缺乏结合多语言和多模态的数据集阻碍了探索这两个方面结合的研究，因为多模态可以同时帮助多种语言的命名实体识别。在本文中，我们的目标是解决更具挑战性的任务：多语言和多模式命名实体识别（MMNER），考虑到其潜在价值和影响。具体来说，我们构建了一个包含四种语言（英语、法语、德语和西班牙语）和两种模式（文本和图像）的大型 MMNER 数据集。为了解决数据集上这一具有挑战性的 MMNER 任务，我们引入了一种名为 2M-NER 的新模型，该模型使用对比学习来对齐文本和图像表示，并集成多模态协作模块以有效地描述两种模态之间的交互。大量的实验结果表明，与一些比较性和代表性的基线相比，我们的模型在多语言和多模式 NER 任务中取得了最高的 F1 分数。此外，在一项具有挑战性的分析中，我们发现句子级对齐对 NER 模型有很大干扰，这表明我们的数据集的难度较高。]]></description>
      <guid>https://arxiv.org/abs/2404.17122</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>基于双向门控循环单元（GRU）模型的文本情感分析与分类</title>
      <link>https://arxiv.org/abs/2404.17123</link>
      <description><![CDATA[arXiv:2404.17123v1 公告类型：新
摘要：本文探讨了文本情感分析和分类在自然语言处理领域的重要性，提出了一种基于双向门控循环单元（GRU）模型的情感分析和分类新方法。该研究首先分析具有六个情感标签的文本的词云模型，然后进行数据预处理，包括去除特殊符号、标点符号、数字、停用词和非字母部分的步骤。随后，将数据集分为训练集和测试集，通过模型训练和测试，发现验证集的准确率随着训练从85%提升到93%，提升了8%；同时，验证集的损失值从0.7下降到0.1并趋于稳定，模型逐渐接近实际值，可以有效地对文本情感进行分类。混淆矩阵显示，模型在测试集上的准确率达到94.8%，查准率95.9%，召回率99.1%，F1分数97.4%，证明模型具有良好的泛化能力和分类效果。总体而言，该研究展示了一种有效的文本情感分析和分类方法，并取得了令人满意的结果。]]></description>
      <guid>https://arxiv.org/abs/2404.17123</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>小语言模型需要强大的验证器来自我纠正推理</title>
      <link>https://arxiv.org/abs/2404.17140</link>
      <description><![CDATA[arXiv:2404.17140v1 公告类型：新
摘要：自我纠正已成为一种有前途的解决方案，可提高大型语言模型 (LLM) 的推理性能，其中 LLM 使用自我生成的批评来查明错误，从而完善其解决方案。这项工作探讨了较小规模 (&lt;= 13B) 的语言模型 (LM) 是否具有在推理任务上自我修正的能力，并且需要来自更强 LM 的最少输入。我们提出了一种新颖的管道，可以促使较小的语言模型收集支持自我完善能力训练的自我修正数据。首先，我们利用正确的解决方案来指导模型批评其错误反应。其次，生成的批评经过过滤后，用于通过解决方案细化对自校正推理器进行监督微调。我们的实验结果表明，两个模型在涵盖数学和常识推理的五个数据集上的自我校正能力得到了提高，与基于 GPT-4 的强大验证器配合使用时，性能显着提升，尽管在使用弱自我验证器进行确定时存在局限性。何时纠正。]]></description>
      <guid>https://arxiv.org/abs/2404.17140</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:55 GMT</pubDate>
    </item>
    <item>
      <title>LLM 驱动的游戏叙事中玩家驱动的出现</title>
      <link>https://arxiv.org/abs/2404.17027</link>
      <description><![CDATA[arXiv:2404.17027v1 公告类型：新
摘要：我们探索与大型语言模型（LLM）的交互如何引发紧急行为，使玩家能够参与游戏叙事的演变。我们的测试平台是一款文本冒险游戏，玩家试图在固定的叙事前提下解开谜团，但可以与大型语言模型 GPT-4 生成的非玩家角色自由互动。我们招募 28 名玩家来玩游戏，并使用 GPT-4 自动将游戏日志转换为代表玩家游戏中的叙述的节点图。我们发现，通过与法学硕士的非确定性行为的互动，玩家能够发现有趣的新出现的节点，这些节点不是原始叙述的一部分，但有可能变得有趣和吸引人。创建最新兴节点的玩家往往是那些经常喜欢促进发现、探索和实验的游戏的玩家。]]></description>
      <guid>https://arxiv.org/abs/2404.17027</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>胡说八道：探究大型语言模型对对抗性乱码输入的理解</title>
      <link>https://arxiv.org/abs/2404.17120</link>
      <description><![CDATA[arXiv:2404.17120v1 公告类型：新
摘要：大型语言模型（LLM）表现出出色的理解人类语言的能力，但它们是否也理解自己的语言？在这项工作中，我们深入研究了这个问题，旨在揭示法学硕士此类行为背后的机制。我们使用贪婪坐标梯度优化器来制作提示，迫使法学硕士从看似无意义的输入中生成连贯的响应。我们将这些输入称为 LM Babel，这项工作系统地研究了受这些提示操纵的 LLM 的行为。我们发现操作效率取决于目标文本的长度和复杂度，与自然提示相比，Babel 提示通常位于较低的损失最小值。我们进一步检查 Babel 提示的结构并评估其稳健性。值得注意的是，我们发现引导模型生成有害文本并不比生成良性文本更困难，这表明分布外提示缺乏对齐。]]></description>
      <guid>https://arxiv.org/abs/2404.17120</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>检查法学硕士评估对基准分布假设的稳健性</title>
      <link>https://arxiv.org/abs/2404.16966</link>
      <description><![CDATA[arXiv:2404.16966v1 公告类型：新
摘要：基准已成为评估大型语言模型（LLM）的核心方法。研究社区通常依赖模型在基准测试提示下的平均性能来评估模型的性能。这与基准测试中的测试提示代表来自真实世界感兴趣分布的随机样本的假设是一致的。我们注意到，通常情况并非如此；相反，我们认为兴趣的分配根据具体用例而变化。我们发现（1）测试提示之间的模型性能相关性是非随机的，（2）考虑测试提示之间的相关性可以改变主要基准上的模型排名，（3）这些相关性的解释因素包括语义相似性和常见的 LLM故障点。]]></description>
      <guid>https://arxiv.org/abs/2404.16966</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型评估知识图中的类成员关系</title>
      <link>https://arxiv.org/abs/2404.17000</link>
      <description><![CDATA[arXiv:2404.17000v1 公告类型：新
摘要：知识图的支柱是它们的类成员关系，它将实体分配给给定的类。作为知识工程过程的一部分，我们提出了一种新方法来评估这些关系的质量，通过使用零镜头思想链分类器处理给定实体和类的描述，该分类器使用类的自然语言内涵定义。我们使用两个公开可用的知识图（Wikidata 和 CaLiGraph）以及 7 个大型语言模型来评估该方法。使用 gpt-4-0125-preview 大语言模型，该方法的分类性能在 Wikidata 数据上实现了 0.830 的宏观平均 F1 分数，在 CaLiGraph 数据上实现了 0.893 的宏观平均 F1 分数。此外，对分类错误的手动分析显示，40.9%的错误是由于知识图造成的，其中16.0%是由于缺失关系造成的，24.9%是由于错误断言关系造成的。这些结果表明大型语言模型可以如何帮助知识工程师进行知识图细化过程。代码和数据可以在 Github 上找到。]]></description>
      <guid>https://arxiv.org/abs/2404.17000</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>T\"urk\c{c}e Dil Modellerinin Performans Kar\c{s}{\i}la\c{s}t{\i}rmas{\i} 土耳其语言模型的性能比较</title>
      <link>https://arxiv.org/abs/2404.17010</link>
      <description><![CDATA[arXiv:2404.17010v1 公告类型：新
摘要：语言模型在完成几乎所有类型的任务方面所提供的发展不仅引起了研究人员的关注，也引起了社会的关注，并使其成为产品。有商业上成功的语言模型可用。然而，由于成本、数据隐私或法规的原因，用户可能更喜欢开源语言模型。然而，尽管这些模型的数量不断增加，但还没有对它们在土耳其语中的性能进行全面比较。本研究旨在填补这一文献空白。根据语境学习和问答能力对七种选定的语言模型进行了比较。准备了用于情境学习和问答的土耳其数据集，并进行了自动和人工评估。结果表明，对于问答来说，在使用教学数据集进行微调之前继续进行预训练可以更成功地使多语言模型适应土耳其语，并且上下文学习性能与问答性能没有太大关系。]]></description>
      <guid>https://arxiv.org/abs/2404.17010</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>使用超大型语言模型进行谣言评估</title>
      <link>https://arxiv.org/abs/2404.16859</link>
      <description><![CDATA[arXiv:2404.16859v1 公告类型：新
摘要：基于会话提示工程的大语言模型（LLM）可以对输出创建进行有针对性的控制，从而增强多功能性、适应性和即席检索。从另一个角度来看，数字错误信息已经达到了令人震惊的程度。社交媒体的匿名性、可用性和影响力为谣言传播提供了肥沃的土壤。这项工作建议通过扩展 RumourEval 任务在 Twitter 数据集上的研究工作，利用依赖提示的法学硕士的进步来打击错误信息。最后，我们采用两种基于提示的 LLM 变体（GPT-3.5-turbo 和 GPT-4）来扩展两个 RumourEval 子任务：（1）准确性预测和（2）立场分类。为了预测准确性，每个 GPT 变体都试验了三种分类方案。每个方案都在零次、一次和几次设置中进行测试。我们的最佳结果大大优于之前的结果。对于立场分类，基于提示的方法显示出与之前结果相当的性能，与微调方法相比没有任何改进。谣言立场子任务也扩展到原始设置之外，以允许多类分类。两个子任务生成的所有预测都配备了根据 LLM 确定其可信度的置信度分数，以及用于可解释性和可解释性目的的事后理由。我们的主要目标是人工智能造福社会。]]></description>
      <guid>https://arxiv.org/abs/2404.16859</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>三星中国研究院 - 北京 SemEval-2024 任务 3：对话中情感-原因对提取的多阶段框架</title>
      <link>https://arxiv.org/abs/2404.16905</link>
      <description><![CDATA[arXiv:2404.16905v1 公告类型：新
摘要：在人机交互中，智能体通过理解人类的情绪来做出反应至关重要。揭开情绪的成因更具挑战性。一项名为“对话中的多模态情绪-原因对提取”的新任务负责识别情绪并识别因果表达。在本研究中，我们提出了一个多阶段框架来生成情感并提取给定目标情感的情感因果对。在第一阶段，利用基于 Llama-2 的 InstructERC 来提取对话中每个话语的情感类别。在情感识别之后，使用双流注意力模型来提取给定子任务 2 的目标情感的情感因果对，同时使用 MuTEC 来提取子任务 1 的因果跨度。我们的方法在两个子任务中都获得了第一名。竞赛。]]></description>
      <guid>https://arxiv.org/abs/2404.16905</guid>
      <pubDate>Mon, 29 Apr 2024 06:17:52 GMT</pubDate>
    </item>
    </channel>
</rss>