<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 20 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过信息论理解法学硕士中的思路链</title>
      <link>https://arxiv.org/abs/2411.11984</link>
      <description><![CDATA[arXiv:2411.11984v1 公告类型：新
摘要：大型语言模型 (LLM) 通过思路链 (CoT) 推理在复杂推理任务中表现出色，使模型能够将问题分解为可管理的子任务。然而，现有的 CoT 评估技术要么需要带注释的 CoT 数据，要么无法准确评估中间推理步骤，导致误报率很高。在本文中，我们通过信息论视角形式化 LLM 中的 CoT 推理。具体来说，我们的框架量化了每个推理步骤的“信息增益”，从而无需昂贵的带注释数据集即可识别 LLM 中的故障模式。我们通过对玩具和 GSM-8K 数据的大量实验证明了我们方法的有效性，它通过提供对单个任务的模型性能的更准确洞察，明显优于现有的基于结果的方法。]]></description>
      <guid>https://arxiv.org/abs/2411.11984</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ByteScience：利用自动微调的标记粒度大型语言模型连接非结构化科学文献和结构化数据</title>
      <link>https://arxiv.org/abs/2411.12000</link>
      <description><![CDATA[arXiv:2411.12000v1 公告类型：新
摘要：自然语言处理 (NLP) 被广泛用于提供从长上下文到结构化信息的摘要能力。然而，由于其领域特定性、复杂的数据预处理和多层设备级信息的粒度，使用 NLP 模型从科学文本中提取结构化知识仍然是一个挑战。为了解决这个问题，我们推出了 ByteScience，这是一个非营利性的基于云的自动微调大型语言模型 (LLM) 平台，旨在从大量科学语料库中提取结构化科学数据并合成新的科学知识。该平台利用 DARWIN，这是一个专用于自然科学的开源、微调的 LLM。该平台建立在亚马逊网络服务 (AWS) 上，为自定义模型开发和数据提取提供了自动化、用户友好的工作流程。该平台仅使用少量注释良好的文章即可实现卓越的准确性。这一创新工具简化了从科学文献到结构化知识和数据的转变，并有利于自然信息学的进步。]]></description>
      <guid>https://arxiv.org/abs/2411.12000</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对预训练文本嵌入模型进行基准测试，以对齐建筑资产信息</title>
      <link>https://arxiv.org/abs/2411.12056</link>
      <description><![CDATA[arXiv:2411.12056v1 公告类型：新
摘要：将已建立的资产信息准确映射到已建立的数据分类系统和分类法对于有效的资产管理至关重要，无论是项目交接时的合规性还是临时数据集成场景。由于已建立资产数据的复杂性（主要由技术文本元素组成），该过程仍然主要是手动的并且依赖于领域专家的输入。上下文文本表示学习（文本嵌入）方面的最新突破，特别是通过预先训练的大型语言模型，提供了有希望的方法，可以促进已建立资产数据交叉映射的自动化。但是，尚未进行全面评估以评估这些模型有效表示特定于已建立资产技术术语的复杂语义的能力。本研究提出了最先进的文本嵌入模型的比较基准，以评估它们在将已建立资产信息与特定领域的技术概念对齐方面的有效性。我们提出的数据集来自两个著名的已建立资产数据分类词典。我们对六个拟议数据集（涵盖聚类、检索和重新排序三个任务）进行了基准测试，结果突出表明，未来需要研究领域适应技术。基准测试资源以开源库的形式发布，我们将对其进行维护和扩展，以支持该领域的未来评估。]]></description>
      <guid>https://arxiv.org/abs/2411.12056</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>减轻上下文词嵌入中的性别偏见</title>
      <link>https://arxiv.org/abs/2411.12074</link>
      <description><![CDATA[arXiv:2411.12074v1 公告类型：新
摘要：事实证明，词嵌入在解决绝大多数 NLP 相关任务时都能产生显著的效果。不幸的是，词嵌入还捕捉到了社会上普遍存在的刻板偏见，影响了嵌入在下游任务中的预测性能。虽然已经提出了各种技术 \cite{bolukbasi2016man, zhao2018learning} 并批评 \cite{gonen2019lipstick} 用于静态嵌入，但很少有工作专注于减轻上下文嵌入中的偏见。在本文中，我们为 MLM（蒙版语言建模）提出了一种新的目标函数，它在很大程度上减轻了上下文嵌入中的性别偏见，同时也保留了下游任务的性能。由于之前关于衡量语境嵌入中的偏见的研究缺乏规范推理，我们还提出了新颖的评估指标，这些指标简单易懂，与我们消除偏见的动机一致。我们还提出了消除静态嵌入偏见的新方法，并通过广泛的分析和实验提供了实证证据，说明为什么静态嵌入中偏见的主要来源是刻板名称的存在，而不是性别词本身。除非另有说明，否则所有实验和嵌入研究均以英文进行。\citep{bender2011achieving}。]]></description>
      <guid>https://arxiv.org/abs/2411.12074</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>忘却学习真的能忘却学习吗？法学硕士忘却学习方法的黑箱评估</title>
      <link>https://arxiv.org/abs/2411.12103</link>
      <description><![CDATA[arXiv:2411.12103v2 公告类型：新
摘要：大型语言模型反学习旨在删除 LLM 已学到的有害信息，以防止将其用于恶意目的。LLMU 和 RMU 已被提出作为 LLM 反学习的两种方法，在反学习基准上取得了令人印象深刻的结果。我们通过评估它们对 WMDP 基准以及我们创建的生物学基准上的一般模型能力的影响来详细研究这些方法的有效性。我们的实验表明，RMU 通常可以更好地保留模型能力，以实现类似或更好的反学习。我们进一步测试了这些方法的稳健性，发现进行 5 次提示或以简单的方式重新表述问题可以使反学习基准的准确率提高十倍以上。最后，我们表明，对不相关数据的训练几乎可以完全恢复反学习前的性能，表明这些方法无法真正实现反学习。代码可在以下位置获得：https://github.com/JaiDoshi/Knowledge-Erasure。]]></description>
      <guid>https://arxiv.org/abs/2411.12103</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>定性分析中测量“开放代码”的计算方法</title>
      <link>https://arxiv.org/abs/2411.12142</link>
      <description><![CDATA[arXiv:2411.12142v1 公告类型：新
摘要：定性分析对于理解许多社会科学学科中的人类数据集至关重要。开放编码是一种归纳定性过程，可从数据集中识别和解释“开放代码”。然而，满足方法论期望（例如“尽可能详尽”）可能具有挑战性。虽然许多机器学习 (ML)/生成式人工智能 (GAI) 研究都试图支持开放编码，但很少有研究系统地测量或评估 GAI 结果，这增加了潜在的偏见风险。基于扎根理论和主题分析理论，我们提出了一种计算方法来系统地测量和识别“开放代码”中的潜在偏见。我们的方法不是将人类专家的结果作为“基本事实”，而是建立在人类和机器编码员之间的团队合作方法之上。我们用两个 HCI 数据集进行实验，通过 1) 将其与人工分析进行比较，以及 2) 分析其输出稳定性来确定该方法的可靠性。我们为 ML/GAI 提出了基于证据的建议和示例工作流程来支持开放编码。]]></description>
      <guid>https://arxiv.org/abs/2411.12142</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CoMeDi 共享任务：词汇语义分歧中的模型注释</title>
      <link>https://arxiv.org/abs/2411.12147</link>
      <description><![CDATA[arXiv:2411.12147v1 公告类型：新
摘要：我们展示了我们的系统在 CoMeDi 共享任务中的结果，该系统预测了多数票（子任务 1）和注释者分歧（子任务 2）。我们的方法将模型集成策略与基于 MLP 和基于阈值的方法相结合，这些方法在预训练语言模型上进行训练。将单个模型视为虚拟注释器，我们通过设计聚合度量来模拟注释过程，这些聚合度量结合了连续相似性分数和离散分类标签来捕获多数和分歧。此外，我们采用各向异性去除技术来提高性能。实验结果证明了我们的方法的有效性，特别是对于子任务 2。值得注意的是，我们发现，与聚合离散标签相比，即使在同一模型中，连续相似性分数也更符合人类的分歧模式。]]></description>
      <guid>https://arxiv.org/abs/2411.12147</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HNCSE：通过混合对比学习和硬否定提高句子嵌入质量</title>
      <link>https://arxiv.org/abs/2411.12156</link>
      <description><![CDATA[arXiv:2411.12156v1 公告类型：新
摘要：无监督句子表征学习仍然是现代自然语言处理 (NLP) 研究中的一个关键挑战。最近，对比学习技术通过有效捕获文本语义在解决这一问题方面取得了重大成功。许多此类方法优先使用负样本进行优化。在计算机视觉等领域，硬负样本（接近决策边界因此更难区分的样本）已被证明可以增强表征学习。然而，由于文本的句法和语义细节错综复杂，将硬负样本应用于对比句子学习非常复杂。为了解决这个问题，我们提出了 HNCSE，这是一种新颖的对比学习框架，它扩展了领先的 SimCSE 方法。HNCSE 的标志是它创新地使用硬负样本来增强正样本和负样本的学习，从而实现更深入的语义理解。在语义文本相似性和迁移任务数据集上的实证测试验证了 HNCSE 的优越性。]]></description>
      <guid>https://arxiv.org/abs/2411.12156</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种用于生成连贯高质量文本的组合编码器和转换器方法</title>
      <link>https://arxiv.org/abs/2411.12157</link>
      <description><![CDATA[arXiv:2411.12157v1 公告类型：新
摘要：本研究介绍了一种新颖的文本生成模型，该模型将 BERT 的语义解释优势与 GPT-4 的生成能力相结合，在生成连贯、上下文准确的语言方面建立了高标准。通过组合架构，该模型增强了语义深度并保持了流畅、类似人类的文本流，克服了先前模型的局限性。实验基准测试表明，BERT-GPT-4 在困惑度和 BLEU 等关键指标上超越了 GPT-3、T5、BART、Transformer-XL 和 CTRL 等传统模型，展示了其卓越的自然语言生成性能。通过充分利用上下文信息，该混合模型生成的文本不仅逻辑连贯，而且与人类语言模式紧密结合，为文本生成任务提供了先进的解决方案。这项研究强调了将语义理解与先进的生成模型相结合的潜力，为 NLP 贡献了新的见解，并为大规模生成架构在自动写作、问答系统和自适应对话代理等领域的更广泛应用奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2411.12157</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估印度官方语言大型语言模型的标记器性能</title>
      <link>https://arxiv.org/abs/2411.12240</link>
      <description><![CDATA[arXiv:2411.12240v1 公告类型：新 
摘要：基于 Transformer 架构的大型语言模型 (LLM) 彻底改变了各种领域，其中标记化在其预处理和微调阶段起着关键作用。在多语言模型中，特别是针对印度语的模型，有效的标记化对于优化性能至关重要。本文对印度所有 22 种官方语言的 12 个 LLM 使用的标记器进行了全面评估，重点是比较它们的标记化过程的效率。我们在分析中使用了规范化序列长度 (NSL) 作为关键指标。我们的研究结果表明，SUTRA 标记器优于所有其他模型，包括几个特定于印度语的模型，在 14 种语言中表现出色。值得注意的见解包括 SUTRA 标记器对印度语的出色处理、GPT-4o 在处理印度语方面优于其前身 GPT-4 的进步以及 Project Indus 在某些语言中的表现有限。这项研究强调了为多语言和以印度语为中心的模型开发有针对性的标记化策略的关键重要性，为未来改进标记器设计以增强语言覆盖范围和模型效率奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2411.12240</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>根据音乐发现对话预测用户意图和音乐属性</title>
      <link>https://arxiv.org/abs/2411.12254</link>
      <description><![CDATA[arXiv:2411.12254v2 公告类型：新
摘要：意图分类是一种文本理解任务，可从输入文本查询中识别用户需求。虽然意图分类已在各个领域得到广泛研究，但在音乐领域并未受到太多关注。在本文中，我们研究了音乐发现对话的意图分类模型，重点关注预训练的语言模型。除了预测功能需求：意图分类之外，我们还包括一项对音乐需求进行分类的任务：音乐属性分类。此外，我们提出了一种将以前的聊天记录与输入文本中的单轮用户查询连接起来的方法，使模型能够更好地理解整体对话上下文。我们提出的模型显着提高了用户意图和音乐属性分类的 F1 分数，并且超越了预训练的 Llama 3 模型的零样本和少样本性能。]]></description>
      <guid>https://arxiv.org/abs/2411.12254</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>低资源机器翻译：为了什么？为了谁？对专门的德顿语翻译服务的观察性研究</title>
      <link>https://arxiv.org/abs/2411.12262</link>
      <description><![CDATA[arXiv:2411.12262v1 公告类型：新
摘要：机器翻译 (MT) 对低资源语言的影响仍然不太清楚。特别是，对实际使用模式的观察性研究很少。这样的研究可以提供有价值的见解，了解用户的需求和行为，补充基于调查的方法。在这里，我们使用来自广泛使用的 MT 服务的服务器日志，对东帝汶的通用语 Tetun 的真实世界 MT 使用情况进行了观察分析，该服务每月活跃用户超过 70,000 美元。我们对 100,000 美元的翻译请求的分析揭示了挑战基于现有语料库的假设的模式。我们发现用户（其中​​许多是使用移动设备的学生）通常会将短文本翻译成 Tetun 语，涉及科学、医疗保健和日常生活等不同领域。这与可用的 Tetun 语料库形成了鲜明对比，后者以涉及政府和社会问题的新闻文章为主。我们的结果表明，针对德顿语等语言的机器翻译系统应优先考虑将语言翻译成资源匮乏的语言，有效处理简短的输入，并涵盖与教育背景相关的广泛领域。更广泛地说，这项研究展示了观察分析如何通过将研究立足于实际社区需求来为资源匮乏的语言技术开发提供信息。]]></description>
      <guid>https://arxiv.org/abs/2411.12262</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CUE-M：通过多模态大型语言模型进行上下文理解和增强搜索</title>
      <link>https://arxiv.org/abs/2411.12287</link>
      <description><![CDATA[arXiv:2411.12287v1 公告类型：新
摘要：检索增强生成 (RAG) 与多模态大型语言模型 (MLLM) 的集成扩大了多模态查询解析的范围。然而，当前的系统在意图理解、信息检索和安全过滤方面存在困难，限制了它们的有效性。本文介绍了使用 MLLM (CUE-M) 的上下文理解和增强搜索，这是一种新颖的多模态搜索管道，它通过一个多阶段框架解决这些挑战，该框架包括图像上下文丰富、意图细化、上下文查询生成、外部 API 集成和基于相关性的过滤。CUE-M 结合了一个强大的安全框架，结合了基于图像、基于文本和多模态分类器，可动态适应特定于实例和类别的风险。对多模态问答数据集和公共安全基准的评估表明，CUE-M 在准确性、知识集成和安全性方面优于基线，提高了多模态检索系统的能力。]]></description>
      <guid>https://arxiv.org/abs/2411.12287</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在生产中平衡 LLM 驱动的对话系统的多轮意图分类的准确性和效率</title>
      <link>https://arxiv.org/abs/2411.12307</link>
      <description><![CDATA[arXiv:2411.12307v1 公告类型：新
摘要：准确的多轮意图分类对于推进对话式 AI 系统至关重要。然而，诸如综合数据集的稀缺性和对话轮次间上下文依赖关系的复杂性等挑战阻碍了进展。本文介绍了两种利用大型语言模型 (LLM) 来增强可扩展性并减少生产对话系统中延迟的新方法。首先，我们引入了符号调整，它简化了意图标签以降低任务复杂性并提高多轮对话的性能。其次，我们提出了 C-LARA（一致性感知、语言学自适应检索增强），这是一个使用 LLM 进行数据增强和伪标记以生成合成多轮对话的框架。这些丰富的数据集用于微调适合部署的小型高效模型。在多语言对话数据集上进行的实验表明分类准确性和资源效率显着提高。我们的方法将多轮意图分类准确率提高了 5.09%，将注释成本降低了 40%，并能够在低资源多语言工业系统中进行可扩展部署，凸显了其实用性和影响力。]]></description>
      <guid>https://arxiv.org/abs/2411.12307</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RedPajama：用于训练大型语言模型的开放数据集</title>
      <link>https://arxiv.org/abs/2411.12372</link>
      <description><![CDATA[arXiv:2411.12372v1 公告类型：新
摘要：大型语言模型正日益成为人工智能、科学和整个社会的基石技术，但数据集组成和过滤的最佳策略仍然难以捉摸。许多表现最佳的模型在数据集管理和模型开发过程中缺乏透明度，这对完全开放的语言模型的开发构成了障碍。在本文中，我们确定了三个核心数据相关挑战，必须解决这些挑战才能推进开源语言模型。这些包括 (1) 模型开发的透明度，包括数据管理过程，(2) 访问大量高质量数据，以及 (3) 可用于数据集管理和分析的工件和元数据。为了应对这些挑战，我们发布了 RedPajama-V1，这是 LLaMA 训练数据集的开放复制品。此外，我们还发布了 RedPajama-V2，这是一个庞大的仅限网络的数据集，由原始、未过滤的文本数据以及质量信号和元数据组成。 RedPajama 数据集总共包含 100 多万亿个词条，涵盖多个领域，其质量信号有助于筛选数据，旨在激发大量新数据集的开发。到目前为止，这些数据集已经用于训练生产中使用的强语言模型，例如 Snowflake Arctic、Salesforce 的 XGen 和 AI2 的 OLMo。为了深入了解 RedPajama 的质量，我们针对多达 16 亿个参数的解码器专用语言模型进行了一系列分析和消融研究。我们的研究结果表明，如何有效利用网络数据的质量信号来筛选高质量的数据集子集，凸显了 RedPajama 在推动大规模透明高性能语言模型开发方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.12372</guid>
      <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>