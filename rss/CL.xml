<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Wed, 15 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Seal-Tools：用于代理调优和详细基准的自指导工具学习数据集</title>
      <link>https://arxiv.org/abs/2405.08355</link>
      <description><![CDATA[arXiv:2405.08355v1 公告类型：新
摘要：本文提出了一种新的工具学习数据集 Seal-Tools，其中包含类似 API 的自指导工具。 Seal-Tools不仅提供了大量的工具，还包含展示工具实际应用的实例。为了在确保可靠性的同时大规模生成数据，我们提出了一种自指导方法来生成工具和实例，从而可以精确控制过程。此外，我们的 Seal-Tools 包含调用多个工具来完成工作的硬实例，其中一些是嵌套的工具调用。为了精准、全面的评价，我们采用严格的格式控制，从不同维度设计了三个指标。因此，Seal-Tools可以作为评价LLM工具调用能力的新标杆。最后，我们评估了几种流行的法学硕士和我们在 Seal-Tools 上的微调模型。结果表明，当前的系统远非完美。代码、数据和实验结果可在 https://github.com/fairyshine/Seal-Tools 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.08355</guid>
      <pubDate>Wed, 15 May 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>MEDIQA-CORR 2024 上的 PromptMind 团队：通过错误分类和法学硕士集成改进临床文本纠正</title>
      <link>https://arxiv.org/abs/2405.08373</link>
      <description><![CDATA[arXiv:2405.08373v1 公告类型：新
摘要：本文描述了我们执行 MEDIQA-CORR 共享任务的方法，其中涉及医疗专业人员整理的临床记录中的错误检测和纠正。该任务涉及处理三个子任务：检测错误的存在、识别包含错误的特定句子并纠正它。通过我们的工作，我们的目标是评估大型语言模型 (LLM) 的能力，这些模型是在包含事实信息和不可靠信息的大量互联网数据上训练的。我们建议综合解决所有子任务，并建议采用独特的基于提示的情境学习策略。我们将评估其在这项需要结合一般推理和医学知识的专门任务中的功效。在预测错误可能产生严重后果的医疗系统中，我们建议利用自洽和集成方法来增强纠错和错误检测性能。]]></description>
      <guid>https://arxiv.org/abs/2405.08373</guid>
      <pubDate>Wed, 15 May 2024 06:17:54 GMT</pubDate>
    </item>
    <item>
      <title>实体与关系联合抽取的解耦聚合框架</title>
      <link>https://arxiv.org/abs/2405.08311</link>
      <description><![CDATA[arXiv:2405.08311v1 公告类型：新
摘要：命名实体识别和关系提取是信息提取领域中两个至关重要且具有挑战性的子任务。尽管传统方法取得了成功，但基础研究问题仍然悬而未决。首先，最近的研究对单个子任务使用参数共享，或对两个子任务使用共享特征，而忽略了它们的语义差异。其次，信息交互主要集中在两个子任务上，而编码主体、关系和客体的子任务特定特征之间的细粒度信息交互尚未被探索。受上述限制的启发，我们提出了一种联合提取实体和关系的新模型。主要新颖之处如下：（1）我们建议将特征编码过程解耦为三个部分，即编码主体、编码对象和编码关系。因此，我们能够使用细粒度的子任务特定功能。 （2）我们提出了新颖的聚合间和聚合内策略，以分别增强信息交互并构建单独的细粒度子任务特定特征。实验结果表明，我们的模型优于以前的几个最先进的模型。大量的额外实验进一步证实了我们模型的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.08311</guid>
      <pubDate>Wed, 15 May 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>SpeechGuard：探索多模态大语言模型的对抗鲁棒性</title>
      <link>https://arxiv.org/abs/2405.08317</link>
      <description><![CDATA[arXiv:2405.08317v1 公告类型：新
摘要：集成语音和大型语言模型（SLM）可以遵循语音指令并生成相关文本响应，最近越来越受欢迎。然而，这些模型的安全性和稳健性在很大程度上仍不清楚。在这项工作中，我们研究了这种遵循指令的语音语言模型在对抗性攻击和越狱方面的潜在漏洞。具体来说，我们设计的算法可以生成对抗性示例，以便在白盒和黑盒攻击设置中越狱 SLM，而无需人工参与。此外，我们还提出了阻止此类越狱攻击的对策。我们的模型经过语音指令的对话数据训练，在语音问答任务中实现了最先进的性能，在安全性和有用性指标上得分超过 80%。尽管有安全护栏，越狱实验证明了 SLM 容易受到对抗性扰动和转移攻击的影响，在精心设计的涵盖 12 个不同有毒类别的有害问题数据集上进行评估时，平均攻击​​成功率分别为 90% 和 10%。然而，我们证明我们提出的对策会显着降低攻击成功率。]]></description>
      <guid>https://arxiv.org/abs/2405.08317</guid>
      <pubDate>Wed, 15 May 2024 06:17:53 GMT</pubDate>
    </item>
    <item>
      <title>SpeechVerse：大规模通用音频语言模型</title>
      <link>https://arxiv.org/abs/2405.08295</link>
      <description><![CDATA[arXiv:2405.08295v1 公告类型：新
摘要：大型语言模型（LLM）在执行需要对自然语言指令进行语义理解的任务方面表现出了令人难以置信的熟练程度。最近，许多作品进一步扩展了这种能力来感知多模态音频和文本输入，但它们的能力通常仅限于特定的微调任务，例如自动语音识别和翻译。因此，我们开发了 SpeechVerse，这是一个强大的多任务训练和课程学习框架，它通过一小组可学习参数将预训练的语音和文本基础模型结合起来，同时在训练期间保持预训练模型的冻结。这些模型使用从语音基础模型中提取的连续潜在表示进行指令微调，以使用自然语言指令在各种语音处理任务上实现最佳的零样本性能。我们执行广泛的基准测试，包括将我们的模型性能与跨多个数据集和任务的传统基线进行比较。此外，我们通过对域外数据集、新颖的提示和未见过的任务进行测试来评估模型的通用指令能力。我们的实证实验表明，我们的多任务 SpeechVerse 模型在 11 项任务中的 9 项上甚至优于传统的特定任务基线。]]></description>
      <guid>https://arxiv.org/abs/2405.08295</guid>
      <pubDate>Wed, 15 May 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>计算思维实验以实现更严格的哲学和心灵科学</title>
      <link>https://arxiv.org/abs/2405.08304</link>
      <description><![CDATA[arXiv:2405.08304v1 公告类型：新
摘要：我们为一种称为虚拟世界认知科学（VW CogSci）的方法提供了哲学动机，其中研究人员使用嵌入虚拟世界的虚拟实体来探索认知科学领域的问题。我们关注有关心理和语言表征的问题，以及这种计算模型如何为哲学思想实验增加严谨性，以及在此类表征的科学研究中使用的术语。我们发现，这种方法迫使研究人员在描述思想中的实体与环境中的实体之间的动态关系时采取上帝视角的观点，从而消除了对信念和概念类型有问题的谈论的需要，例如猫是的信念愚蠢的，以及概念 CAT，同时在个体认知者的头脑中保留信念和概念标记。我们总结了 VW CogSci 对于心理和语言表征科学研究以及更广泛的认知科学的一些进一步的关键优势。]]></description>
      <guid>https://arxiv.org/abs/2405.08304</guid>
      <pubDate>Wed, 15 May 2024 06:17:52 GMT</pubDate>
    </item>
    <item>
      <title>预测学习模型可以模拟连续语音神经表征中的时间动态和上下文效应</title>
      <link>https://arxiv.org/abs/2405.08237</link>
      <description><![CDATA[arXiv:2405.08237v1 公告类型：新
摘要：语音感知涉及存储和整合顺序呈现的项目。认知神经科学的最新工作已经确定了人类语音神经编码中的时间和上下文特征，这可能有助于这种时间处理。在这项研究中，我们使用从计算模型中提取的表示来模拟类似的分析，该模型是在未标记的语音上进行训练的，其学习目标是预测即将到来的声学效果。我们的模拟揭示了与大脑信号相似的时间动态，这意味着这些特性可以在没有语言知识的情况下出现。大脑和模型之间共享的另一个属性是音素的编码模式支持某种程度的跨上下文泛化。然而，我们发现证据表明这些概括的有效性取决于特定的上下文，这表明仅此分析不足以支持上下文不变编码的存在。]]></description>
      <guid>https://arxiv.org/abs/2405.08237</guid>
      <pubDate>Wed, 15 May 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>检测气候错误信息中的谬误：识别误导性论证的技术认知方法</title>
      <link>https://arxiv.org/abs/2405.08254</link>
      <description><![CDATA[arXiv:2405.08254v1 公告类型：新
摘要：有关气候变化的错误信息是一个复杂的社会问题，需要在技术和心理学的交叉点上采取全面的、跨学科的解决方案。提出的解决方案之一是“技术认知”方法，涉及心理学和计算机科学研究的综合。心理学研究发现，针对错误信息的干预措施需要基于事实（例如事实解释）和基于技术（例如对误导性技术的解释）的内容。然而，在记录和发现气候错误信息的谬误方面进展甚微。在这项研究中，我们应用先前开发的批判性思维方法来解构气候错误信息，以便开发一个将不同类型的气候错误信息映射到推理谬误的数据集。该数据集用于训练模型来检测气候错误信息中的谬误。我们的研究显示 F1 分数比以前的作品好 2.5 到 3.5。最容易发现的谬误包括假专家和轶事论证，而需要背景知识的谬误，例如过于简单化、歪曲事实、懒惰归纳等，则相对更难发现。这项研究为开发解决方案奠定了基础，可以通过基于生成技术的校正来对抗自动检测到的气候错误信息。]]></description>
      <guid>https://arxiv.org/abs/2405.08254</guid>
      <pubDate>Wed, 15 May 2024 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>解释编程作业中潜在的学生知识表示</title>
      <link>https://arxiv.org/abs/2405.08213</link>
      <description><![CDATA[arXiv:2405.08213v1 公告类型：新
摘要：教育人工智能的最新进展利用了生成式大型语言模型，包括使用它们来预测开放式学生的反应，而不仅仅是预测其正确性。然而，这些模型的黑盒性质限制了所学学生知识表示的可解释性。在本文中，我们通过提出 InfoOIRT（一种信息正则化开放式项目响应理论模型）对解释潜在学生知识表示进行了首次探索，该模型鼓励潜在学生知识状态可解释，同时能够生成学生编写的代码开放式编程问题。 InfoOIRT 最大化了使用简单先验分布强制执行的潜在知识状态的固定子集与生成的学生代码之间的互信息，这鼓励模型学习显着句法和语义代码特征的解开表示，包括句法风格、编程技能的掌握和代码结构。通过对现实世界编程教育数据集的实验，我们表明 InfoOIRT 既可以准确生成学生代码，又可以生成可解释的学生知识表示。]]></description>
      <guid>https://arxiv.org/abs/2405.08213</guid>
      <pubDate>Wed, 15 May 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>浅层和深层语言理解的信息论模型</title>
      <link>https://arxiv.org/abs/2405.08223</link>
      <description><![CDATA[arXiv:2405.08223v1 公告类型：新
摘要：心理语言学的大量工作都集中在这样的观点上：在线语言理解可能是肤浅的或“足够好”：考虑到时间或可用计算的限制，理解者可能会对他们的输入形成看似合理但不准确的解释。然而，这个想法尚未与资源限制下的正式计算理论联系起来。在这里，我们使用信息论来制定语言理解模型，作为准确性和处理深度之间的最佳权衡，形式化为从输入中提取的信息位，随着处理时间的增加而增加。该模型提供了处理深度变化时处理工作量的衡量标准，我们将其与脑电图信号和阅读时间联系起来。我们根据花园小路句子阅读时间的大规模数据集以及具有 N400、P600 和双相 ERP 效应的脑电图实验验证了我们的理论。通过量化语言处理从浅到深的时间过程，我们的模型提供了一个统一的框架来解释语言理解的行为和神经特征。]]></description>
      <guid>https://arxiv.org/abs/2405.08223</guid>
      <pubDate>Wed, 15 May 2024 06:17:50 GMT</pubDate>
    </item>
    <item>
      <title>生物医学 NLP 中检索增强大型语言模型的基准测试：应用、稳健性和自我意识</title>
      <link>https://arxiv.org/abs/2405.08151</link>
      <description><![CDATA[arXiv:2405.08151v1 公告类型：新
摘要：大语言模型（LLM）在各种生物医学自然语言处理（NLP）任务中表现出了卓越的能力，利用输入上下文中的演示来适应新任务。然而，LLM对示范的选择很敏感。为了解决法学硕士固有的幻觉问题，检索增强法学硕士（RAL）通过从已建立的数据库中检索相关信息来提供解决方案。尽管如此，现有的研究工作缺乏对检索增强大型语言模型对不同生物医学 NLP 任务的影响的严格评估。这一缺陷使得确定 RAL 在生物医学领域的能力变得具有挑战性。此外，RAL 的输出受到检索未标记的、反事实的或在生物医学领域尚未得到充分研究的多样化知识的影响。然而，这样的知识在现实世界中很常见。最后，探索自我意识能力对于RAL系统也至关重要。因此，在本文中，我们系统地研究了 RAL 对 5 种不同生物医学任务（三元组提取、链接预测、分类、问答和自然语言推理）的影响。我们分析了 RAL 在四种基本能力方面的表现，包括无标签稳健性、反事实稳健性、多样性稳健性和负面意识。为此，我们提出了一个评估框架来评估 RAL 在不同生物医学 NLP 任务上的表现，并根据上述基本能力建立了四个不同的测试平台。然后，我们使用 3 个不同的检索器在 9 个数据集的 5 项任务上评估 3 个代表性的法学硕士。]]></description>
      <guid>https://arxiv.org/abs/2405.08151</guid>
      <pubDate>Wed, 15 May 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>CANTONMT：研究粤英神经机器翻译的回译和模型切换机制</title>
      <link>https://arxiv.org/abs/2405.08172</link>
      <description><![CDATA[arXiv:2405.08172v1 公告类型：新
摘要：本文研究了从粤语到英语的机器翻译模型的开发和评估，提出了一种解决低资源语言翻译问题的新方法。该研究的主要目标是开发一种可以有效地将粤语翻译成英语的模型，并根据最先进的商业模型对其进行评估。为了实现这一目标，通过将不同的可用在线语料库与预处理和清理相结合，创建了一个新的并行语料库。此外，还通过网络抓取创建了单语粤语数据集，以帮助生成合成平行语料库。在数据收集过程之后，使用了多种方法，包括微调模型、反向翻译和模型切换。模型的翻译质量通过多种质量指标进行评估，包括基于词典的指标（SacreBLEU 和 hLEPOR）和嵌入空间指标（COMET 和 BERTscore）。根据自动指标，选择最佳模型，并使用人工评估框架 HOPES 与 2 个最佳商业翻译进行比较。本次调查中提出的具有模型切换机制的最佳模型（NLLB-mBART）已达到与最先进的商业模型（Bing 和百度翻译器）相当甚至更好的自动评估分数，在我们的 SacreBLEU 分数为 16.8测试集。此外，还开发了一个开源网络应用程序，允许用户在粤语和英语之间进行翻译，并使用不同的经过训练的模型来有效比较本次调查的模型和用户。 CANTONMT 可在 https://github.com/kenrickkung/CantoneseTranslation 获取]]></description>
      <guid>https://arxiv.org/abs/2405.08172</guid>
      <pubDate>Wed, 15 May 2024 06:17:49 GMT</pubDate>
    </item>
    <item>
      <title>多次反流 (MSR) 提示</title>
      <link>https://arxiv.org/abs/2405.08134</link>
      <description><![CDATA[arXiv:2405.08134v1 公告类型：新
摘要：我们引入了Many-Shot Regurgitation（MSR）提示，这是一种新的黑盒成员推理攻击框架，用于检查大型语言模型（LLM）中的逐字内容再现。 MSR 提示涉及将输入文本分成多个片段并创建单个提示，其中包括用户和语言模型之间的一系列虚假对话，以引发逐字反省。我们将 MSR 提示应用于不同的文本源，包括维基百科文章和开放教育资源 (OER) 教科书，它们提供高质量、真实的内容，并随着时间的推移不断更新。对于每个来源，我们策划了两种数据集类型：一种是法学硕士在训练期间可能接触到的数据集 ($D_{\rm pre}$)，另一种由模型训练截止日期之后发布的文档组成 ($D_{\rm post} $）。为了量化逐字匹配的出现，我们采用最长公共子串算法并计算不同长度阈值下的匹配频率。然后，我们使用 Cliff δ、Kolmogorov-Smirnov (KS) 距离和 Kruskal-Wallis H 检验等统计测量来确定 $D_{\rm pre}$ 和 $D_{\rm post} 之间逐字匹配的分布是否存在显着差异}$。我们的研究结果揭示了 $D_{\rm pre}$ 和 $D_{\rm post}$ 之间逐字匹配的分布存在显着差异，当 LLM（例如 GPT 模型和 LLaMA）被用他们可能接受过训练的数据集中的文本进行提示。例如，当在维基百科文章上使用 GPT-3.5 时，我们观察到 $D_{\rm pre}$ 和 $ 的分布之间存在显着的效应大小（Cliff 的增量 $= -0.984$）和较大的 KS 距离（$0.875$） D_{\rm 帖子}$。我们的结果提供了令人信服的证据，表明当输入文本可能来自其训练数据时，法学硕士更容易逐字复制内容。]]></description>
      <guid>https://arxiv.org/abs/2405.08134</guid>
      <pubDate>Wed, 15 May 2024 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>在线评论中的话语反对策略：开发分类模式并验证其训练</title>
      <link>https://arxiv.org/abs/2405.08142</link>
      <description><![CDATA[arXiv:2405.08142v1 公告类型：新
摘要：大多数美国人都认为，社交媒体上的错误信息、仇恨言论和骚扰是有害的，并且通过当前的适度做法没有得到充分遏制。在本文中，我们的目的是了解人们在应对新闻评论中的有害言论时所采用的话语策略。我们对 YouTube 和 Twitter 上热门新闻视频的 6500 多条评论回复进行了内容分析，并确定了七种不同的话语反对策略（研究 1）。我们从 6500 条评论回复以及 2004 年回复的第二个样本（研究 2）中检查了每种策略的出现频率。这些研究共同表明，人们在反对言论时会采取多种话语策略，其中声誉攻击是最常见的。由此产生的分类方案考虑了表达反对意见的不同理论方法，并为旨在制止校园内攻击性或有问题的言论的基层努力提供了全面的视角。]]></description>
      <guid>https://arxiv.org/abs/2405.08142</guid>
      <pubDate>Wed, 15 May 2024 06:17:48 GMT</pubDate>
    </item>
    <item>
      <title>KET-QA：知识增强表问答数据集</title>
      <link>https://arxiv.org/abs/2405.08099</link>
      <description><![CDATA[arXiv:2405.08099v1 公告类型：新
摘要：由于表格的简洁性和结构化性，其中包含的知识可能不完整或缺失，这对表格问答（TableQA）和数据分析系统提出了重大挑战。大多数现有数据集要么无法解决 TableQA 中的外部知识问题，要么仅利用非结构化文本作为表格的补充信息。在本文中，我们建议使用知识库（KB）作为TableQA的外部知识源，并构建具有细粒度黄金证据注释的数据集KET-QA。数据集中的每个表对应整个知识库的一个子图，每个问题都需要整合表和子图的信息才能回答。为了从庞大的知识子图中提取相关信息并将其应用于 TableQA，我们设计了一个检索器-推理器结构化管道模型。实验结果表明，我们的模型在三种不同设置（微调、零样本和少样本）的 EM 分数上始终实现了 1.9 到 6.5 倍的显着相对性能提升，绝对提升了 11.66% 到 44.64%。与传统 TableQA 方式中仅依赖表信息的比较。然而，即使是最好的模型也达到了 60.23% 的 EM 分数，这仍然落后于人类水平的表现，凸显了 KET-QA 对于问答社区的挑战性。我们还提供了对错误案例的人工评估，以进一步分析模型可以改进的方面。项目页面：https://ketqa.github.io/。]]></description>
      <guid>https://arxiv.org/abs/2405.08099</guid>
      <pubDate>Wed, 15 May 2024 06:17:47 GMT</pubDate>
    </item>
    </channel>
</rss>