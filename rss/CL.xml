<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 15 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>知识叠加：揭示大型语言模型终身知识编辑的失败之处</title>
      <link>https://arxiv.org/abs/2408.07413</link>
      <description><![CDATA[arXiv:2408.07413v1 公告类型：新 
摘要：知识编辑旨在更新大型语言模型（LLM）中过时或不正确的知识。然而，目前的知识编辑方法对终身编辑的可扩展性有限。本研究探讨了知识编辑在终身编辑中失败的根本原因。我们从线性联想记忆导出的闭式解开始，它是最先进的知识编辑方法的基础。我们将解决方案从单次编辑扩展到终身编辑，并通过严格的数学推导，在最终解决方案中确定一个干扰项，表明编辑知识可能会影响不相关的知识。对干扰项的进一步分析揭示了它与知识表示之间的叠加有着密切的关系。当语言模型中不存在知识叠加时，干扰项就会消失，从而实现无损知识编辑。在众多语言模型中的实验表明，知识叠加是普遍存在的，表现出高峰度、零均值和重尾分布，具有明显的缩放规律。最后，通过理论与实验的结合，我们证明了知识叠加是终身编辑失败的根本原因。此外，这是第一项从叠加角度研究知识编辑的研究，并对众多现实世界语言模型中的叠加进行了全面的观察。代码可在 https://github.com/ChenhuiHu/knowledge_in_superposition 获得。]]></description>
      <guid>https://arxiv.org/abs/2408.07413</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:21 GMT</pubDate>
    </item>
    <item>
      <title>探索阿拉伯语检索增强生成</title>
      <link>https://arxiv.org/abs/2408.07425</link>
      <description><![CDATA[arXiv:2408.07425v1 公告类型：新
摘要：最近，检索增强生成 (RAG) 已成为自然语言处理中的一种强大技术，它结合了基于检索和基于生成的模型的优势来增强文本生成任务。然而，RAG 在具有独特特征和资源限制的阿拉伯语中的应用仍未得到充分探索。本文对阿拉伯语文本的 RAG 实施和评估进行了全面的案例研究。这项工作侧重于探索检索阶段的各种语义嵌入模型和生成阶段的几个 LLM，以研究在阿拉伯语环境中什么有效，什么无效。这项工作还涉及检索阶段文档方言和查询方言之间的差异问题。结果表明，现有的语义嵌入模型和 LLM 可以有效地用于构建阿拉伯语 RAG 管道。]]></description>
      <guid>https://arxiv.org/abs/2408.07425</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:21 GMT</pubDate>
    </item>
    <item>
      <title>GPT 语言模型是否患有人格分裂症？无基质心理测量的出现</title>
      <link>https://arxiv.org/abs/2408.07377</link>
      <description><![CDATA[arXiv:2408.07377v2 公告类型：新
摘要：先前对大型语言模型出现的研究表明，这些模型表现出明显的类人能力和心理潜在特征。然而，这些潜在特征的表达和大小的结果存在一定程度的矛盾，但令人担忧的是，这些模型在自恋、精神病和马基雅维利主义的黑暗三角中得分较高，再加上脱轨的记录，需要对这些模型的安全性进行更严格的研究。我们提供了一个最先进的语言模型，该模型在九种语言中使用了相同的性格问卷，并对高斯混合模型进行了贝叶斯分析，发现了一个更深层次问题的证据。我们的结果表明语言间和语言内的不稳定性，这表明当前的语言模型没有形成一致的核心人格。这可能导致基于这些基础模型的人工智能系统出现不安全行为，并且这些系统越来越多地融入人类生活。随后，我们讨论了现代心理测量学的缺点，对其进行了抽象，并为其物种中性、无底物公式提供了一个框架。]]></description>
      <guid>https://arxiv.org/abs/2408.07377</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:20 GMT</pubDate>
    </item>
    <item>
      <title>DataVisT5：用于联合理解文本和数据可视化的预训练语言模型</title>
      <link>https://arxiv.org/abs/2408.07401</link>
      <description><![CDATA[arXiv:2408.07401v1 公告类型：新
摘要：数据可视化 (DV) 是提高大数据背后洞察传达效率的基本和前提工具，在现有的数据驱动世界中已被广泛接受。DV 中的任务自动化对于该领域的发展至关重要，例如将自然语言查询转换为可视化（即文本到可视化）、从可视化生成解释（即可视化到文本）、以自由形式回答与 DV 相关的问题（即 FeVisQA）以及解释表格数据（即表格到文本）。尽管预训练语言模型 (PLM)（如 T5 和 BERT）具有巨大潜力，但它们在 DV 中的应用受到高成本和处理跨模态信息的挑战的限制，导致对 DV 的 PLM 的研究很少。我们引入了 \textbf{DataVisT5}，这是一种为 DV 量身定制的新型 PLM，它通过混合目标预训练和多任务微调策略增强了 T5 架构，整合了文本和 DV 数据集以有效地解释跨模态语义。对公共数据集的广泛评估表明，DataVisT5 在各种 DV 相关任务上的表现始终优于当前最先进的模型。我们预计 DataVisT5 不仅会激发对垂直 PLM 的进一步研究，还会扩大 PLM 的应用范围。]]></description>
      <guid>https://arxiv.org/abs/2408.07401</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:20 GMT</pubDate>
    </item>
    <item>
      <title>人类消歧过程的量子启发分析</title>
      <link>https://arxiv.org/abs/2408.07402</link>
      <description><![CDATA[arXiv:2408.07402v1 公告类型：新
摘要：形式语言对于计算机编程至关重要，并且易于被计算机处理。相比之下，自然语言更具挑战性，并激发了自然语言处理 (NLP) 领域的发展。一个主要障碍是歧义的普遍存在。NLP 的最新进展导致了大型语言模型的发展，这些模型可以高精度地解决歧义问题。与此同时，量子计算机近年来引起了广泛关注，因为它们可以比传统计算机更快地解决一些计算问题。这种新的计算范式已经进入机器学习和 NLP 领域，其中出现了混合经典量子学习算法。然而，需要更多的研究来确定哪些 NLP 任务可以从真正的量子优势中受益。在本文中，我们应用了基础量子力学中出现的形式主义，例如语境性和因果关系，来研究语言学中出现的歧义。通过这种方式，我们还重现了与人类歧义消除过程相关的心理语言学结果。这些结果随后被用于预测人类行为，其表现优于当前的 NLP 方法。]]></description>
      <guid>https://arxiv.org/abs/2408.07402</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:20 GMT</pubDate>
    </item>
    <item>
      <title>Aquila2 技术报告</title>
      <link>https://arxiv.org/abs/2408.07410</link>
      <description><![CDATA[arXiv:2408.07410v1 公告类型：新
摘要：本文介绍了 Aquila2 系列，该系列包含参数大小为 70 亿、340 亿和 700 亿的多种双语模型。这些模型基于名为 HeuriMentor (HM) 的创新框架进行训练，该框架可实时洞察模型收敛情况并增强训练过程和数据管理。HM 系统由自适应训练引擎 (ATE)、训练状态监视器 (TSM) 和数据管理单元 (DMU) 组成，可精确监控模型的训练进度并有效优化数据分布，从而提高训练效果。大量评估表明，Aquila2 模型系列在英语和中文基准上的表现相当出色。具体而言，Aquila2-34B 在量化到 Int4 时仅表现出轻微的性能下降。此外，我们已经公开了我们的训练代码（https://github.com/FlagOpen/FlagScale）和模型权重（https://github.com/FlagAI-Open/Aquila2），以支持正在进行的研究和应用程序的开发。]]></description>
      <guid>https://arxiv.org/abs/2408.07410</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:20 GMT</pubDate>
    </item>
    <item>
      <title>使用高级 LLM 来增强小型 LLM：一种可解释的知识提炼方法</title>
      <link>https://arxiv.org/abs/2408.07238</link>
      <description><![CDATA[arXiv:2408.07238v1 公告类型：新
摘要：高级大型语言模型 (LLM)（如 GPT-4 或 LlaMa 3）在复杂的类人交互中提供了卓越的性能。但它们成本高昂，或者对于智能手机等边缘设备来说太大，而且难以自托管，从而导致安全和隐私问题。本文介绍了一种新颖的可解释知识蒸馏方法，以提高公司可以自托管的较小、更经济的 LLM 的性能。我们在构建客户服务代理的背景下研究了这个问题，旨在通过面向目标的对话实现高客户满意度。与传统的知识蒸馏不同，在传统的知识蒸馏中，“学生”模型通过微调直接从“老师”模型的响应中学习，而我们的可解释“策略”教学方法涉及老师提供策略来提高学生在各种场景中的表现。该方法在“场景生成”步骤和“改进策略”步骤之间交替进行，创建了一个定制的场景库和优化的自动提示策略。该方法只需要黑盒访问学生和教师模型；因此无需操纵模型参数即可使用。在我们的客户服务应用中，该方法提高了性能，并且学习到的策略可以转移到训练集之外的其他 LLM 和场景。该方法的可解释性有助于防止通过人工审计造成的潜在危害。]]></description>
      <guid>https://arxiv.org/abs/2408.07238</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:19 GMT</pubDate>
    </item>
    <item>
      <title>语音与文字记录：对于语音摘要中的人工注释者来说重要吗？</title>
      <link>https://arxiv.org/abs/2408.07277</link>
      <description><![CDATA[arXiv:2408.07277v1 公告类型：新
摘要：抽象语音摘要的参考摘要需要人工注释，可以通过收听录音或阅读录音的文本记录来完成。在本文中，我们研究了基于注释者听录音的摘要与基于注释者阅读记录的摘要是否不同。使用现有的基于人工评估、自动指标、基于 LLM 的评估和基于检索的无参考方法的内在评估。我们发现摘要确实因源模态而异，并且基于语音的摘要比基于记录的摘要在事实上更一致且信息选择性更强。同时，基于记录的摘要受到源中识别错误的影响，而专家撰写的摘要更具信息性和可靠性。我们将所有收集的数据和分析代码公开（https://github.com/cmu-mlsp/interview_humanssum），以方便复制我们的工作并推进该领域的研究。]]></description>
      <guid>https://arxiv.org/abs/2408.07277</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:19 GMT</pubDate>
    </item>
    <item>
      <title>只可能存在一种关系？事件时间关系提取中的歧义建模</title>
      <link>https://arxiv.org/abs/2408.07353</link>
      <description><![CDATA[arXiv:2408.07353v1 公告类型：新
摘要：事件时间关系提取 (ETRE) 旨在识别两个事件之间的时间关系，这在自然语言理解中起着重要作用。大多数以前的工作都遵循单标签分类风格，将事件对分类为特定的时间关系（例如，\textit{Before}、\textit{After}），或者当事件对之间可能存在多种可能的时间关系时，将其分类为特殊标签 \textit{Vague}。在我们的工作中，我们不是直接对 \textit{Vague} 进行预测，而是为 ETRE (METRE) 提出了一种多标签分类解决方案，以独立推断每种时间关系的可能性，其中我们将 \textit{Vague} 视为两个事件之间存在多种可能关系的情况。我们设计了一种推测机制来探索隐藏在 \textit{Vague} 背后的可能关系，从而可以有效地利用潜在信息。在 TB-Dense、MATRES 和 UDS-T 上的实验表明，我们的方法可以有效地利用 \textit{Vague} 实例来提高对特定时间关系的识别，并且优于大多数最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2408.07353</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:19 GMT</pubDate>
    </item>
    <item>
      <title>自我折叠 自我复制</title>
      <link>https://arxiv.org/abs/2408.07154</link>
      <description><![CDATA[arXiv:2408.07154v1 公告类型：新
摘要：受蛋白质折叠的启发，我们探索了从简单构建块的一维链构建三维结构和机器。这种方法不仅使我们能够重新创建前面介绍的自我复制机制，而且还大大简化了该过程。我们引入了一组新的折叠块，这些折叠块有助于形成二级结构，例如{\alpha}-螺旋和\b{eta}-片层，以及更高级的三级和四级结构，包括自我复制机器。引入旋转自由度会减少块的种类，最重要的是，将机器的整体尺寸缩小了五倍。此外，我们提出了一种通用的复印机构造器，这是一种高效的自我复制机制，由大约 40 个块组成，包括对其施加的限制。本文还讨论了进化方面的考虑，概述了朝着更复杂的自我复制系统进化的几个步骤。最后，这项研究为自然界偏好一维链构建三维结构提供了明确的理由。]]></description>
      <guid>https://arxiv.org/abs/2408.07154</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:18 GMT</pubDate>
    </item>
    <item>
      <title>解锁效率：基因转化模型的自适应掩蔽</title>
      <link>https://arxiv.org/abs/2408.07180</link>
      <description><![CDATA[arXiv:2408.07180v1 公告类型：新 
摘要：基因转换器模型（例如核苷酸转换器、DNABert 和 LOGO）通过使用完整人类参考基因组上的掩码语言建模 (MLM) 训练目标进行训练，以学习最佳基因序列表示。然而，典型的标记化方法采用基本的标记滑动窗口，例如 k-mers，无法利用以基因为中心的语义。这可能导致（简单的）掩码容易预测的序列，从而导致 MLM 训练效率低下。众所周知，时变训练策略可以提高语言和视觉任务的预训练效率。在这项工作中，我们专注于使用课程掩码，其中我们通过使用基于逐点互信息的难度标准系统地增加掩码标记预测任务的难度，因为基因序列缺乏类似于 NLP 领域的单词或句子的明确定义的语义单元。我们提出的基于 Curriculum Masking 的基因掩蔽策略 (CM-GEMS) 在下游基因序列分类任务上进行评估时，与基线掩蔽方法相比，表现出卓越的表征学习能力。我们在少样本（五个数据集）和完整数据集设置（由 27 个任务组成的基因组理解评估基准）中进行了广泛的评估。我们的研究结果表明，CM-GEMS 的表现优于以 120K 步训练的最先进的模型（DNABert-2、Nucleotide transformer、DNABert），仅在 10K 和 1K 步中就实现了类似的结果。我们还证明了 Curriculum-Learned LOGO（一种 2 层 DNABert 类模型）可以实现 120K 步的最先进的模型性能的近 90%。我们将在 https://github.com/roysoumya/curriculum-GeneMask 上公开提供模型和代码。]]></description>
      <guid>https://arxiv.org/abs/2408.07180</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:18 GMT</pubDate>
    </item>
    <item>
      <title>BERT 的概念制图：绘制意义景观</title>
      <link>https://arxiv.org/abs/2408.07190</link>
      <description><![CDATA[arXiv:2408.07190v1 公告类型：新
摘要：概念工程师希望让单词变得更好。然而，他们往往低估了我们对单词的使用有多么多样化。在本文中，我们迈出了探索单词上下文细微差别的第一步，通过创建概念景观——代表单词实用用法的 2D 表面——概念工程师可以使用它们来指导他们的项目。我们使用英国国家语料库和 BERT 的口语部分来创建上下文词嵌入，并使用高斯混合模型、一系列指标和定性分析来可视化和数字表示词汇景观。这种方法尚未在概念工程文献中使用，它提供了对不同单词在不同语境中如何表现的详细检查，这可能对概念工程项目有用。我们的研究结果强调了概念工程固有的复杂性，揭示了每个词都展现出独特而复杂的景观。因此，概念工程师在改进词汇时不能采用一刀切的方法——这项任务在实践中可能很难大规模完成。]]></description>
      <guid>https://arxiv.org/abs/2408.07190</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:18 GMT</pubDate>
    </item>
    <item>
      <title>信念的神经嵌入揭示了相对不和谐在人类决策中的作用</title>
      <link>https://arxiv.org/abs/2408.07237</link>
      <description><![CDATA[arXiv:2408.07237v1 公告类型：新
摘要：信念是人类认知和决策的基础。它们指导个人从生活中获取意义，塑造他们的行为并形成社会联系。因此，一个包含信念及其相互关系的模型对于定量研究信念对我们行为的影响至关重要。尽管它很重要，但对人类信念之间相互作用的研究往往仅限于与特定问题有关的一小部分信念，并且严重依赖调查或实验。在这里，我们提出了一种方法，通过利用来自在线辩论平台的大规模用户参与数据并使用微调的大型语言模型 (LLM) 将这些信念映射到嵌入空间，来提取数千种信念之间的细微关系。这个信念嵌入空间有效地封装了不同信念的相互联系以及各种社会问题的两极分化。我们发现，这个信念空间中的位置可以预测个人的新信念。此外，我们发现一个人现有信念和新信念之间的相对距离可以作为认知失调的定量估计，使我们能够预测新信念。我们的研究强调了现代法学硕士与人类信念的集体在线记录相结合如何能够洞察支配人类信念形成和决策过程的基本原则。]]></description>
      <guid>https://arxiv.org/abs/2408.07237</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:18 GMT</pubDate>
    </item>
    <item>
      <title>ELLA：帮助法学​​硕士获得可解释、准确且信息丰富的法律建议</title>
      <link>https://arxiv.org/abs/2408.07137</link>
      <description><![CDATA[arXiv:2408.07137v1 公告类型：新
摘要：尽管法律大型语言模型 (LLM) 与法律文章检索组件相结合在法律咨询方面表现出色，但仍存在给出的建议不正确或毫无根据的情况。为了缓解这些问题，我们提出了 {\bf ELLA}，这是一种为 {\bf E}mpowering {\bf L}LM 提供可解释、准确和信息丰富的 {\bf L}egal {\bf A} 建议的工具。ELLA 通过计算相似度以可视化方式呈现法律文章与 LLM 响应之间的相关性，为用户提供直观的响应法律依据。此外，ELLA 根据用户的查询检索相关法律文章并将其显示给用户。用户可以交互地选择法律文章，让 LLM 生成更准确的响应。ELLA 还检索相关法律案例供用户参考。我们的用户研究表明，呈现响应的法律依据有助于用户更好地理解。当用户参与选择 LLM 的法律文章时，LLM 的回复准确率也会提高。提供相关的法律案例也有助于个人获得全面的信息。]]></description>
      <guid>https://arxiv.org/abs/2408.07137</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:17 GMT</pubDate>
    </item>
    <item>
      <title>语言模型作为语言的模型</title>
      <link>https://arxiv.org/abs/2408.07144</link>
      <description><![CDATA[arXiv:2408.07144v1 公告类型：新
摘要：本章批判性地审视了现代语言模型对理论语言学的潜在贡献。尽管这些模型专注于工程目标，但它们仅通过接触数据就能获得复杂的语言知识的能力值得我们仔细重新评估它们与语言理论的相关性。我回顾了越来越多的经验证据，这些证据表明语言模型可以学习层次句法结构并对各种语言现象表现出敏感性，即使在使用发展合理的数据量进行训练时也是如此。虽然能力/表现的区别被用来否定这些模型与语言理论的相关性，但我认为这种评估可能为时过早。通过仔细控制学习条件并利用因果干预方法，语言模型实验可能会限制有关语言习得和能力的假设。我的结论是，理论语言学家和计算研究人员之间更紧密的合作可以产生有价值的见解，特别是在推进关于语言本土主义的辩论方面。]]></description>
      <guid>https://arxiv.org/abs/2408.07144</guid>
      <pubDate>Fri, 16 Aug 2024 03:18:17 GMT</pubDate>
    </item>
    </channel>
</rss>