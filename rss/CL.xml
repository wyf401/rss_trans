<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 13 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>P3：政策驱动、节奏自适应、促进多样性的法学硕士培训优化框架</title>
      <link>https://arxiv.org/abs/2408.05541</link>
      <description><![CDATA[arXiv:2408.05541v1 公告类型：新 
摘要：在快速发展的大型语言模型 (LLM) 领域，选择高质量数据进行微调至关重要。本文重点研究针对特定任务的数据修剪和选择，以增强微调。我们引入了一个创新框架，称为 P3，它通过动态、自适应的训练策略提高 LLM 性能。具体来说，P3 包括以下组成部分：（1）策略驱动的难度测量：我们首先根据模型的实时性能测量数据的难度，从静态的、预定义的指标过渡到更动态和适应性更强的指标。（2）步调自适应选择：我们采用自定进度学习 (SPL) 逐步选择越来越具有挑战性的数据，从而逐步提高模型的性能。（3）多样性促进：我们将行列式点过程 (DPP) 集成到选择过程中，以促进样本内和样本之间的多样性，丰富学习过程。我们已经在两个著名的 LLM 数据集 APPS 和 MATH 上验证了我们的方法，这两个数据集是为逻辑推理场景设计的。结果表明，与传统方法相比，我们的 P3 框架显著改善了训练结果。通过从根本上改进数据选择和利用策略，P3 不仅推进了对动态训练方法的理论理解，而且还提供了一个多功能框架，可以彻底改变自然语言处理中的模型训练。]]></description>
      <guid>https://arxiv.org/abs/2408.05541</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:43 GMT</pubDate>
    </item>
    <item>
      <title>您的上下文不是数组：揭示 Transformer 中的随机访问限制</title>
      <link>https://arxiv.org/abs/2408.05506</link>
      <description><![CDATA[arXiv:2408.05506v1 公告类型：新 
摘要：尽管基于 Transformer 的大型语言模型最近取得了成功，但它们却表现出令人惊讶的失败模式。这种失败模式的一个众所周知的例子是它们无法进行长度泛化：在推理时解决的问题实例比训练期间遇到的问题实例更长。在这项工作中，我们通过对简单奇偶校验任务上的模型行为进行详细分析，进一步探究了这种失败的根本原因。我们的分析表明，长度泛化失败与模型无法在其上下文窗口内执行随机内存访问密切相关。我们通过展示避免索引需要或通过基于内容的寻址间接实现随机令牌访问的方法的有效性，为这一假设提供支持证据。我们进一步通过注意力图可视化展示了执行随机内存访问失败的位置和方式。]]></description>
      <guid>https://arxiv.org/abs/2408.05506</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:42 GMT</pubDate>
    </item>
    <item>
      <title>SWIFT：可扩展的轻量级微调基础设施</title>
      <link>https://arxiv.org/abs/2408.05517</link>
      <description><![CDATA[arXiv:2408.05517v2 公告类型：新
摘要：大型语言模型 (LLM) 和多模态大型语言模型 (MLLM) 的最新发展利用了基于注意力机制的 Transformer 架构，并实现了卓越的性能和泛化能力。从那时起，它们已经覆盖了传统学习任务的广泛领域。例如，基于文本的任务（例如文本分类和序列标记）以及多模态任务（例如视觉问答 (VQA) 和光学字符识别 (OCR)），以前使用不同的模型来解决，现在可以基于一个基础模型来解决。因此，LLM 和 MLLM（尤其是基于 Transformer 架构的 LLM 和 MLLM）的训练和轻量级微调变得尤为重要。认识到这些压倒性的需求，我们开发了 SWIFT，这是一种可定制的大型模型一站式基础设施。 SWIFT 支持超过 300+ 个 LLM 和 50+ 个 MLLM，是提供 \textit{最全面支持} 微调大型模型的开源框架。特别是，它是第一个为 MLLM 提供系统支持的训练框架。除了微调的核心功能外，SWIFT 还集成了推理、评估和模型量化等训练后流程，以促进大型模型在各种应用场景中的快速采用。通过系统地集成各种训练技术，SWIFT 提供了有用的实用程序，例如大型模型的不同训练技术之间的基准比较。对于专门用于代理框架的微调模型，我们表明，通过在 SWIFT 上使用定制数据集进行训练可以在 ToolBench 排行榜上取得显着改进，与各种基线模型相比，Act.EM 指标提高了 5.2%-21.8%，幻觉减少了 1.6%-14.1%，平均性能提高了 8%-17%。]]></description>
      <guid>https://arxiv.org/abs/2408.05517</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:42 GMT</pubDate>
    </item>
    <item>
      <title>上下文驱动的索引修剪：从数据质量角度提高 RALM 的精度</title>
      <link>https://arxiv.org/abs/2408.05524</link>
      <description><![CDATA[arXiv:2408.05524v1 公告类型：新
摘要：检索增强大型语言模型（RALM）在提高生成响应的准确性方面取得了重大进展。然而，现有的研究往往忽略了检索结果中的数据质量问题，这些问题通常是由现有的基于向量距离的检索方法不准确造成的。我们建议通过上下文驱动索引修剪（CDIT）框架从数据质量的角度提高 RALM 答案的精度，其中上下文匹配依赖关系（CMD）被用作逻辑数据质量规则来捕获和规范检索上下文之间的一致性。基于大型语言模型（LLM）的语义理解能力，CDIT 可以有效地识别和丢弃与查询上下文不一致的检索结果，并进一步修改数据库中的索引，从而提高答案质量。实验证明了具有挑战性的问答任务。此外，CDIT 的灵活性通过其与各种语言模型和索引方法，为共同提高 RALM 的数据质量和检索精度提供了一种有前途的方法。]]></description>
      <guid>https://arxiv.org/abs/2408.05524</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:42 GMT</pubDate>
    </item>
    <item>
      <title>条件链：构建、验证和解决条件问答的条件</title>
      <link>https://arxiv.org/abs/2408.05442</link>
      <description><![CDATA[arXiv:2408.05442v1 公告类型：新
摘要：条件问答 (CQA) 是一项重要任务，旨在找到可能的答案并确定需要满足哪些条件才能支持答案。现有的方法在 CQA 方面遇到困难，主要有两个挑战：(1) 准确识别条件及其逻辑关系，以及 (2) 验证和解决条件。为了应对这些挑战，我们提出了一种新颖的提示方法条件链，首先根据文档明确识别所有条件并构建它们的逻辑关系，然后验证这些条件是否满足，最后通过工具解决逻辑表达式以指出任何缺失的条件并根据已解决的条件生成答案。在两个基准条件问答数据集上的实验表明，条件链优于现有的提示基线，建立了新的最先进技术。此外，借助 GPT-3.5-Turbo 或 GPT-4 等骨干模型，它仅通过少量设置就超越了所有监督基线。]]></description>
      <guid>https://arxiv.org/abs/2408.05442</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:41 GMT</pubDate>
    </item>
    <item>
      <title>Path-LLM：基于最短路径的统一图形表示的 LLM 学习</title>
      <link>https://arxiv.org/abs/2408.05456</link>
      <description><![CDATA[arXiv:2408.05456v1 公告类型：新
摘要：统一图形表示学习旨在生成节点嵌入，可应用于多个下游应用程序。然而，现有的基于图神经网络和语言模型的研究要么受到需要大量训练才能实现特定下游预测的限制，要么语义特征较浅。在这项工作中，我们提出了一种新颖的 Path-LLM 模型来学习统一图形表示，该模型利用强大的大型语言模型 (LLM) 来整合我们提出的路径特征。我们的 Path-LLM 框架由几种精心设计的技术组成。首先，我们开发了一种新的长到短最短路径 (L2SP) 选择机制，该机制涵盖了不同密集组之间的基本连接。对不同的路径选择方案进行了深入比较，以说明我们设计的 L2SP 的优势。然后，我们设计路径文本化以获得基于 L2SP 的训练文本。接下来，我们将文本输入自监督的 LLM 训练过程以学习嵌入。大量基准测试验证了 Path-LLM 在两个经典图学习任务（节点分类和链接预测）和一个 NP-hard 图查询处理任务（关键字搜索）上相对于最先进的 WalkLM 方法的优越性，同时节省了 90% 以上的训练路径。]]></description>
      <guid>https://arxiv.org/abs/2408.05456</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:41 GMT</pubDate>
    </item>
    <item>
      <title>研究图表上的大型语言模型的指令调优</title>
      <link>https://arxiv.org/abs/2408.05457</link>
      <description><![CDATA[arXiv:2408.05457v1 公告类型：新
摘要：受大型语言模型 (LLM) 在 NLP 任务中的最新进展的启发，人们对将 LLM 应用于图形相关任务的兴趣日益浓厚。本研究深入研究了遵循指令的 LLM 与现实世界图形交互的能力，旨在提供关于 LLM 如何有效地与图形交互并在图形任务中推广的经验见解。我们首先构建一个专为指令调整而设计的数据集，该数据集包含来自学术和电子商务领域的 79 个图形相关任务的多样化集合，具有 44,240 个训练实例和 18,960 个测试样本。利用这个基准，我们的初步调查重点是确定最佳图形表示，作为 LLM 理解复杂图形结构的渠道。我们的研究结果表明，JSON 格式的图形表示在各种 LLM 和图形类型中始终优于自然语言和代码格式。此外，我们通过评估指令调整的 LLM 在域内和域外图形任务上的性能来研究影响其泛化能力的关键因素。]]></description>
      <guid>https://arxiv.org/abs/2408.05457</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:41 GMT</pubDate>
    </item>
    <item>
      <title>MABR：一种无需事先了解偏见的多层对抗性偏见消除方法</title>
      <link>https://arxiv.org/abs/2408.05497</link>
      <description><![CDATA[arXiv:2408.05497v1 公告类型：新
摘要：在现实世界数据上训练的模型通常会反映和加剧现有的社会偏见。减轻这些偏见的传统方法通常需要事先了解要解决的特定偏见，例如性别或种族偏见，以及与每个实例相关的社会群体。在本文中，我们介绍了一种新颖的对抗性训练策略，该策略独立于先前的偏见类型知识和受保护的属性标签运行。我们的方法通过利用辅助模型在模型训练期间主动识别偏见，这些辅助模型通过预测主模型的性能而不依赖于任务标签来同时进行训练。此外，我们在主模型的特征图的各个级别上实现这些辅助模型，从而能够检测更广泛、更细微的偏见特征。通过对情绪和职业分类任务中的种族和性别偏见进行实验，我们的方法有效地减少了社会偏见，而无需人口统计注释。此外，我们的方法不仅匹配而且通常超越了需要详细人口统计洞察的方法的有效性，标志着偏见缓解技术的重大进步。]]></description>
      <guid>https://arxiv.org/abs/2408.05497</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:41 GMT</pubDate>
    </item>
    <item>
      <title>从文本到洞察：利用大型语言模型进行管理绩效评估</title>
      <link>https://arxiv.org/abs/2408.05328</link>
      <description><![CDATA[arXiv:2408.05328v1 公告类型：新
摘要：本研究探讨了大型语言模型 (LLM)，特别是 GPT-4，在提高组织任务绩效评估客观性的潜力。通过对两项研究（包括各种任务绩效输出）的比较分析，我们证明 LLM 可以作为人类评估者的可靠甚至更优越的替代方案，用于评估基于知识的绩效输出，这是知识工作者的一项关键贡献。我们的结果表明，GPT 评分与人类评分相当，但表现出更高的一致性和可靠性。此外，对同一绩效输出的多个 GPT 评分与汇总的人类绩效评分显示出很强的相关性，类似于绩效评估文献中观察到的共识原则。然而，我们还发现 LLM 容易受到情境偏见的影响，例如光环效应，反映了人类的评价偏见。我们的研究表明，虽然 LLM 能够从基于文本的数据中提取有意义的结构，但它们的范围目前仅限于特定形式的绩效评估。通过强调法学硕士的潜力和局限性，我们的研究为人工智能在管理研究中的作用的讨论做出了贡献，并为未来完善人工智能在管理中的理论和实际应用的研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2408.05328</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:40 GMT</pubDate>
    </item>
    <item>
      <title>DataNarrative：使用可视化和文本自动进行数据驱动的故事讲述</title>
      <link>https://arxiv.org/abs/2408.05346</link>
      <description><![CDATA[arXiv:2408.05346v1 公告类型：新
摘要：数据驱动的故事讲述是一种通过将叙事技巧与可视化和文本相结合来传达见解的强大方法。这些故事整合了视觉辅助工具，例如图表中突出显示的条形图和线条，以及解释见解的文本注释。然而，创作这样的故事需要对数据有深入的理解和细致的叙事规划，通常需要人工干预，这可能既费时又费脑力。虽然大型语言模型 (LLM) 在各种 NLP 任务中表现出色，但它们生成连贯而全面的数据故事的能力仍未得到充分探索。在这项工作中，我们引入了一个用于数据故事生成的新任务和一个包含来自不同来源的 1,449 个故事的基准。为了应对制作连贯数据故事的挑战，我们提出了一个多智能体框架，该框架采用两个 LLM 智能体，旨在复制人类的故事讲述过程：一个用于理解和描述数据（反思）、生成大纲和叙述，另一个用于在每个中间步骤进行验证。虽然我们的代理框架在基于模型和人工的评估中通常优于非代理框架，但结果也揭示了数据故事生成中的独特挑战。]]></description>
      <guid>https://arxiv.org/abs/2408.05346</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:40 GMT</pubDate>
    </item>
    <item>
      <title>FiST-具有幻觉和创造力控制框架的金融风格转换</title>
      <link>https://arxiv.org/abs/2408.05365</link>
      <description><![CDATA[arXiv:2408.05365v1 公告类型：新
摘要：使用通用大型语言模型生成财务报告面临两大挑战，包括缺乏复合句和幻觉。先进的提示工程和检索增强生成 (RAG) 技术无法解决写作风格差异。在这项工作中，我们提出了一种新颖的两阶段微调流程，其中将公共领域财务报告处理为提示完成，并使用简单的 LLM 提示进行增强，然后使用最少的指令和表格数据输入实现分段财务报告生成。我们提出的微调框架使正确问题答案的数量增加了一倍，并将幻觉减少了 50% 以上。此外，两阶段微调模型具有更低的困惑度、更好的 ROUGE、TER 和 BLEU 分数、更高的创造力和知识密度以及更低的不确定性和交叉熵。]]></description>
      <guid>https://arxiv.org/abs/2408.05365</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:40 GMT</pubDate>
    </item>
    <item>
      <title>LaiDA：基于语言学的上下文学习，通过数据增强实现隐喻成分识别</title>
      <link>https://arxiv.org/abs/2408.05404</link>
      <description><![CDATA[arXiv:2408.05404v1 公告类型：新
摘要：隐喻成分识别 (MCI) 有助于增强机器对隐喻的理解，从而推进下游自然语言处理任务。然而，复杂性、多样性以及对上下文和背景知识的依赖对 MCI 提出了重大挑战。大型语言模型 (LLM) 凭借其强大的语义分析和广泛的常识知识，为准确理解复杂的自然语言文本提供了新途径。在本研究中，提出了一种基于 LLM 的新框架，称为具有数据增强的语言感知上下文学习 (LaiDA)。具体而言，ChatGPT 和监督微调用于定制高质量数据集。LaiDA 结合了明喻数据集进行预训练。图注意网络编码器生成语言丰富的特征表示以检索类似的示例。随后，使用集成语言相似示例的提示对 LLM 进行微调。 LaiDA 在 NLPCC2024 共享任务 9 的子任务 2 中排名第 2，证明了其有效性。代码和数据可从 https://github.com/WXLJZ/LaiDA 获取。]]></description>
      <guid>https://arxiv.org/abs/2408.05404</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:40 GMT</pubDate>
    </item>
    <item>
      <title>大模型战略思维，小模型效率：在大型语言模型中转移心智理论</title>
      <link>https://arxiv.org/abs/2408.05241</link>
      <description><![CDATA[arXiv:2408.05241v1 公告类型：新
摘要：随着更大、更新的大型语言模型在战略性心智理论 (ToM) 任务中的性能不断提高，对这些最先进模型的需求也相应增加。然而，它们的部署在处理能力和时间方面都很昂贵。在本文中，我们研究了通过微调创建更小、可模拟的代理的可行性。为此，我们提出了一个大型预训练模型，该模型包含 20 个独特场景，将社交背景与社交困境相结合，记录其答案，并将它们用于同一家族的较小模型上的问答微调。我们的重点是情境博弈论决策，这是人类互动发生的同一领域，需要心智理论（或其类似理论）和对社会动态的理解。我们发现，经过微调的小型语言模型表现出与其大型模型更接近的性能，并且它们的改进扩展到训练示例中提供的领域和上下文之外。平均而言，对于所有游戏，通过微调，小型模型在与大型模型的行为保持一致方面表现出 \%46 的改进，\%100 代表完全一致。这表明我们的管道代表了一种将某种形式的心理理论传输到小型模型的有效方法，从而在此过程中创建改进且可廉价部署的算法。尽管它们很简单，并且存在相关的缺点和局限性，但我们的研究结果代表了追求和训练用于战略和社会决策的专门模型的垫脚石。]]></description>
      <guid>https://arxiv.org/abs/2408.05241</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:39 GMT</pubDate>
    </item>
    <item>
      <title>MUSE：边缘多知识传递，助力知识图谱完成</title>
      <link>https://arxiv.org/abs/2408.05283</link>
      <description><![CDATA[arXiv:2408.05283v1 公告类型：新 
摘要：知识图谱补全（KGC）旨在预测（头实体）-[关系]-（尾实体）三元组中的缺失信息。深度神经网络在关系预测任务上取得了重大进展。然而，大多数现有的KGC方法侧重于单一特征（例如实体ID）和子图聚合，无法充分探索知识图谱（KG）中的所有特征，并且忽略了外部语义知识注入。为了解决这些问题，我们提出了MUSE，这是一种知识感知推理模型，通过多知识表示学习机制，在三维中学习定制的嵌入空间，用于缺失关系预测。我们的MUSE由三个并行的组件组成：1）先验知识学习，通过微调BERT来增强三元组的语义表示；2）上下文消息传递，用于增强KG的上下文消息；3）关系路径聚合，用于增强从头实体到尾实体的路径表示。我们的实验结果表明，MUSE 在四个公开数据集上的表现明显优于其他基线，例如在 NELL995 数据集上 H@1 提高了 5.50% 以上，MRR 提高了 4.20%。代码和所有数据集将通过 https://github.com/NxxTGT/MUSE 发布。]]></description>
      <guid>https://arxiv.org/abs/2408.05283</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:39 GMT</pubDate>
    </item>
    <item>
      <title>基于心理学的课程学习统一动态框架</title>
      <link>https://arxiv.org/abs/2408.05326</link>
      <description><![CDATA[arXiv:2408.05326v1 公告类型：新 
摘要：直接从随机难度级别的示例中学习通常对人类和机器学习模型都具有挑战性。更有效的策略是让学习者按照从易到难的渐进顺序接触示例。课程学习 (CL) 已被提出在机器学习模型训练中实施此策略。然而，CL 框架设计中仍然存在两个关键挑战：定义训练数据的难度并确定在每个训练步骤中输入的适当数据量。本文提出了一种基于心理学的课程学习统一动态框架 (PUDF)，灵感来自心理测量学。我们通过将项目反应理论 (IRT) 应用于人工人群 (AC) 的反应来量化训练数据的难度。这种理论驱动的 IRT-AC 方法可产生全局（即独立于模型）和可解释的难度值。利用 IRT，我们提出了一种通过模型能力估计进行动态数据选择 (DDS-MAE) 策略，以在模型训练期间安排适当数量的数据。由于我们的难度标记和模型能力估计基于一致的理论，即 IRT，因此它们的值在同一范围内是可比较的，与其他 CL 方法相比，可能导致更快的收敛。实验结果表明，使用 PUDF 对预训练语言模型进行微调可提高其在 GLUE 基准上的性能。此外，PUDF 在 GLUE 基准上超越了其他最先进的 (SOTA) CL 方法。我们进一步定性和定量探索了 PUDF 的组成部分，即难度测量器 (IRT-AC) 和训练调度程序 (DDS-MAE)。最后，我们进行了一项消融研究，以阐明 PUDF 的哪些组件有助于加快收敛速度​​和提高准确性。]]></description>
      <guid>https://arxiv.org/abs/2408.05326</guid>
      <pubDate>Wed, 14 Aug 2024 03:17:39 GMT</pubDate>
    </item>
    </channel>
</rss>