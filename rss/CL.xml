<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 15 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>CoCoP：通过代码完成提示增强 LLM 文本分类</title>
      <link>https://arxiv.org/abs/2411.08979</link>
      <description><![CDATA[arXiv:2411.08979v1 公告类型：新
摘要：文本分类是自然语言处理 (NLP) 中的一项基本任务，大型​​语言模型 (LLM) 已证明其能够在各个领域执行此任务。然而，LLM 的性能在很大程度上取决于其输入提示的质量。最近的研究还表明，LLM 在代码相关任务中表现出色。为了利用 LLM 在文本分类中的能力，我们提出了代码完成提示 (CoCoP) 方法，该方法将文本分类问题转换为代码完成任务。CoCoP 利用 LLM 的代码完成功能显著提高了不同数据集的文本分类性能。例如，CoCoP 将 SST2 数据集的准确率提高了 20% 以上。此外，当 CoCoP 与专为代码相关任务 (代码模型) 设计的 LLM（如 CodeLLaMA）集成时，该方法仅使用十分之一的模型大小，就表现出比小样本学习技术更好或相当的性能。我们提出的方法的源代码将在论文被接受后向公众开放。]]></description>
      <guid>https://arxiv.org/abs/2411.08979</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>代码混合法学硕士：通过人工智能反馈强化学习提高大型语言模型处理代码混合的能力</title>
      <link>https://arxiv.org/abs/2411.09073</link>
      <description><![CDATA[arXiv:2411.09073v1 公告类型：新
摘要：代码混合（CM）或代码转换（CSW）是指在对话过程中，有时甚至是在单个话语中，将两种或多种语言的语言单位并置。代码混合在日常生活中带来了独特的挑战，例如句法不匹配和语义混合，这些挑战在单语环境中很少遇到。大型语言模型（LLM）通过提供前所未有的理解人类语言的能力，彻底改变了自然语言处理（NLP）领域。然而，目前最先进的多语言 LLM 的有效性尚未在 CM 场景中得到充分探索。为了填补这一空白，我们首先在各种代码混合 NLP 任务上对多语言 LLM 的性能进行基准测试。然后，我们建议通过从人类反馈 (RLHF) 和代码混合机器翻译任务中进行强化学习来提高多语言 LLM 理解代码混合的能力。鉴于偏好标注过程成本高、耗时长，我们改进了这一流程，利用 LLM 作为标注器，进行 AI 反馈强化学习 (RLAIF)。实验证明了该方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.09073</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>个性化帮助优化低技能用户的策略</title>
      <link>https://arxiv.org/abs/2411.09109</link>
      <description><![CDATA[arXiv:2411.09109v1 公告类型：新
摘要：人工智能可以在游戏环境中击败人类；然而，这些代理对人类的帮助程度仍未得到充分研究。我们增强了 CICERO，这是一种在外交方面表现出超人表现的自然语言代理，可以根据玩家意图生成移动和消息建议。十几个有新手和有经验的玩家参与的外交游戏，建议设置各不相同，表明生成的一些建议是有益的。它可以帮助新手与有经验的玩家竞争，在某些情况下甚至超越他们。即使玩家不遵循建议，仅仅存在建议也是有利的。]]></description>
      <guid>https://arxiv.org/abs/2411.09109</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>P-MMEval：用于 LLM 一致性评估的并行多语言多任务基准</title>
      <link>https://arxiv.org/abs/2411.09116</link>
      <description><![CDATA[arXiv:2411.09116v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展展示了跨翻译、代码生成和推理等任务的各种多语言能力。以前的评估通常将其范围限制在基本的自然语言处理 (NLP) 或孤立的特定能力任务上。为了缓解这个缺点，我们的目标是提出一个全面的多语言多任务基准。首先，我们提出了一个从大量基准中选择可用且合理的基准的流程，解决了以前工作中对这些基准的实用性的疏忽，即它们区分被评估模型的能力。利用这个流程，我们引入了 P-MMEval，这是一个涵盖有效基础和能力专业化数据集的大规模基准。此外，P-MMEval 在各种数据集中提供一致的语言覆盖并提供并行样本。最后，我们对代表性多语言模型系列进行了广泛的实验，以比较不同模型的性能，分析数据集的有效性，检查对模型性能的即时影响，并探索多语言性能与任务、模型大小和语言等因素之间的关系。这些见解为未来的研究提供了宝贵的指导。数据集可在 https://huggingface.co/datasets/Qwen/P-MMEval 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.09116</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DROJ：针对大型语言模型的即时驱动攻击</title>
      <link>https://arxiv.org/abs/2411.09125</link>
      <description><![CDATA[arXiv:2411.09125v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种自然语言处理任务中都表现出卓越的能力。由于它们在互联网来源的数据集上进行训练，LLM 有时会生成令人反感的内容，因此需要与人工反馈进行广泛的协调以避免此类输出。尽管进行了大量的协调工作，但 LLM 仍然容易受到对抗性越狱攻击，这些攻击通常是操纵提示，旨在绕过安全机制并引发有害反应。在这里，我们介绍了一种新方法，即定向表示优化越狱 (DROJ)，它在嵌入级别优化越狱提示，将有害查询的隐藏表示转移到更有可能从模型中引起肯定响应的方向。我们对 LLaMA-2-7b-chat 模型的评估表明，DROJ 实现了 100% 基于关键字的攻击成功率 (ASR)，有效地防止了直接拒绝。然而，该模型偶尔会产生重复且无意义的响应。为了缓解这种情况，我们引入了一个有用系统提示，以增强模型响应的实用性。我们的代码可在 https://github.com/Leon-Leyang/LLM-Safeguard 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.09125</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非结构化文本增强开放域对话系统：系统综述</title>
      <link>https://arxiv.org/abs/2411.09166</link>
      <description><![CDATA[arXiv:2411.09166v1 Announce Type: new 
摘要：将外部知识融入对话生成已被证明有利于开放域对话系统 (DS) 的性能，例如生成信息丰富或风格化的响应、控制对话主题。在本文中，我们研究使用非结构化文本作为外部知识源的开放域 DS（\textbf{U}nstructured \textbf{T}ext \textbf{E}nhanced \textbf{D}ialogue \textbf{S}ystem，\textbf{UTEDS}）。非结构化文本的存在导致了 UTEDS 与传统数据驱动 DS 之间的区别，我们旨在分析这些差异。我们首先给出 UTEDS 相关概念的定义，然后总结最近发布的数据集和模型。我们将 UTEDS 分为检索模型和生成模型，并从模型组件的角度进行介绍。检索模型包括融合、匹配和排序模块，生成模型包括对话和知识编码、知识选择和响应生成模块。我们进一步总结了UTEDS中使用的评估方法，并分析了当前模型的性能。最后，我们讨论了UTEDS未来的发展趋势，希望能够启发该领域的新研究。]]></description>
      <guid>https://arxiv.org/abs/2411.09166</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>医学问答检索增强生成系统的全面和实用评估</title>
      <link>https://arxiv.org/abs/2411.09213</link>
      <description><![CDATA[arXiv:2411.09213v1 公告类型：新
摘要：检索增强生成 (RAG) 已成为一种有前途的方法，可以提高大型语言模型 (LLM) 在知识密集型任务（例如医学领域）中的性能。然而，医学领域的敏感性需要一个完全准确和值得信赖的系统。虽然现有的 RAG 基准主要关注标准的检索答案设置，但它们忽略了许多衡量可靠医疗系统关键方面的实际场景。本文通过为 RAG 环境中的医学问答 (QA) 系统提供一个全面的评估框架来解决这一差距，包括充分性、集成性和稳健性。我们引入了医学检索增强生成基准 (MedRGB)，它为四个医学 QA 数据集提供了各种补充元素，以测试 LLM 处理这些特定场景的能力。利用 MedRGB，我们对多种检索条件下最先进的商业 LLM 和开源模型进行了广泛的评估。我们的实验结果表明，当前模型处理检索到的文档中的噪声和错误信息的能力有限。我们进一步分析了 LLM 的推理过程，为在这个关键的医学领域开发 RAG 系统提供了宝贵的见解和未来方向。]]></description>
      <guid>https://arxiv.org/abs/2411.09213</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HateGPT：释放 GPT-3.5 Turbo 力量，打击 X 上的仇恨言论</title>
      <link>https://arxiv.org/abs/2411.09214</link>
      <description><![CDATA[arXiv:2411.09214v1 公告类型：新
摘要：Twitter 和 Facebook 等社交媒体平台的广泛使用使各个年龄段的人都可以分享他们的想法和经历，从而导致用户生成内容的大量积累。然而，除了好处之外，这些平台还面临着管理仇恨言论和冒犯性内容的挑战，这些内容可能会破坏理性话语并威胁民主价值观。因此，越来越需要自动化方法来检测和缓解此类内容，特别是考虑到对话的复杂性，可能需要跨多种语言进行上下文分析，包括印式英语、德语-英语和孟加拉语等代码混合语言。我们参加了英语任务，我们必须将英语推文分为两类，即仇恨和冒犯性和非仇恨-冒犯性。在这项工作中，我们通过提示将推文分为仇恨和冒犯性或非仇恨-冒犯性，尝试使用最先进的大型语言模型（如 GPT-3.5 Turbo）。在本研究中，我们使用三次不同运行的 Macro-F1 分数来评估分类模型的性能。Macro-F1 分数平衡了所有类别的精确度和召回率，是模型评估的主要指标。第一次运行获得的分数为 0.756，第二次运行获得的分数为 0.751，第三次运行获得的分数为 0.754，表明性能水平较高，且运行之间的差异最小。结果表明，该模型在精确度和召回率方面始终表现良好，其中第一次运行表现出最高的性能。这些发现凸显了模型在不同运行中的稳健性和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2411.09214</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过模型增强提高语言模型的金融领域适应性</title>
      <link>https://arxiv.org/abs/2411.09249</link>
      <description><![CDATA[arXiv:2411.09249v1 公告类型：新
摘要：随着语言模型（包括大型语言模型 (LLM)）的使用范围不断扩大，语言模型的领域适应性变得越来越重要。本研究证明了组合增强语言模型 (CALM) 在适应金融领域的有效性。CALM 是一种通过在两个具有不同功能的 LLM 之间引入交叉注意力来扩展现有模型功能的模型。在我们的实验中，我们开发了一个 CALM，通过利用金融专业 LLM 来增强具有强大响应能力的 LLM 的金融性能。值得注意的是，CALM 是使用与训练金融专业 LLM 所用的数据集不同的金融数据集进行训练的，证实了 CALM 适应各种数据集的能力。通过定量的日本金融基准和定性的响应比较对模型进行了评估，表明 CALM 能够比原始模型和基线实现更高的分数和更出色的响应。此外，对连接点的比较实验表明，连接模型的中间层最有利于适应金融领域。这些发现证实了 CALM 是一种将 LLM 应用于金融领域的实用方法。]]></description>
      <guid>https://arxiv.org/abs/2411.09249</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DAHL：通过生物医学基准数据集对长文本进行领域特定的自动幻觉评估</title>
      <link>https://arxiv.org/abs/2411.09255</link>
      <description><![CDATA[arXiv:2411.09255v1 公告类型：新
摘要：我们引入了 DAHL，这是一个基准数据集和自动评估系统，旨在评估长文本生成中的幻觉，特别是在生物医学领域。我们的基准数据集是从生物医学研究论文中精心挑选出来的，包含 29 个类别的 8,573 个问题。DAHL 通过将响应解构为原子单元来评估大型语言模型 (LLM) 中与事实相冲突的幻觉，每个原子单元代表一条信息。这些响应的准确性被平均以产生 DAHL 分数，与以前依赖多项选择任务的方法相比，它可以更深入地评估幻觉。我们对 8 种不同的模型进行了实验，发现较大的模型往往幻觉较少；然而，超过 70 到 80 亿个参数的模型大小，进一步扩展并不能显着提高事实准确性。 DAHL 评分具有成为人工注释偏好标签的有效替代方案的潜力，能够扩展到其他专业领域。我们公开发布了数据集和代码。]]></description>
      <guid>https://arxiv.org/abs/2411.09255</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态大型语言模型中的跨模态一致性</title>
      <link>https://arxiv.org/abs/2411.09273</link>
      <description><![CDATA[arXiv:2411.09273v1 公告类型：新
摘要：多模态方法的最新发展标志着一个激动人心的时代的开始，这些模型擅长处理各种数据类型，包括文本、音频和视觉内容。像 GPT-4V 这样的模型将计算机视觉与高级语言处理相结合，在处理需要同时理解文本和视觉信息的复杂任务方面表现出非凡的能力。先前的研究工作已经仔细评估了这些视觉大型语言模型 (VLLM) 在各个领域的有效性，包括对象检测、图像字幕和其他相关领域。然而，现有的分析往往受到限制，主要集中在对每种模态性能的孤立评估上，而忽略了探索它们复杂的跨模态相互作用。具体来说，当面对不同模态的相同任务实例时，这些模型是否达到相同的准确度水平的问题仍未得到解答。在本研究中，我们主动深入研究了这些感兴趣的模式之间的相互作用和比较，引入了一个称为跨模式一致性的新概念。此外，我们提出了一个基于这一概念的定量评估框架。我们的实验结果来自我们开发的一组精选的并行视觉语言数据集，揭示了 GPT-4V 中的视觉和语言模式之间存在明显的不一致性，尽管它被描绘成一个统一的多模式模型。我们的研究为适当利用此类模型提供了见解，并暗示了增强其设计的潜在途径。]]></description>
      <guid>https://arxiv.org/abs/2411.09273</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>StreamAdapter：从上下文流实现高效的测试时间适配</title>
      <link>https://arxiv.org/abs/2411.09289</link>
      <description><![CDATA[arXiv:2411.09289v1 公告类型：新
摘要：上下文学习 (ICL) 允许大型语言模型 (LLM) 直接从给定的演示中适应新任务，而无需梯度更新。虽然最近的进展已经扩展了上下文窗口以容纳更多的演示，但这种方法增加了推理成本而不一定提高性能。为了缓解这些问题，我们提出了 StreamAdapter，这是一种新方法，可在测试时直接从上下文更新模型参数，从而无需显式的上下文演示。StreamAdapter 采用上下文映射和权重吸收机制，以最少的附加参数将 ICL 演示动态转换为参数更新。通过减少对大量上下文示例的依赖，StreamAdapter 显着降低了推理成本并允许以恒定的时间复杂度进行高效推理，而与演示数量无关。跨不同任务和模型架构的大量实验表明，StreamAdapter 实现了与 ICL 相当或更优越的适应能力，同时需要更少的演示。 StreamAdapter 在语言理解和生成任务上出色的任务适配和上下文编码能力为在测试时使用上下文适配 LLM 提供了新的视角，从而可以更高效地跨场景适配和更具成本效益的推理]]></description>
      <guid>https://arxiv.org/abs/2411.09289</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DTELS：面向时间线摘要的动态粒度</title>
      <link>https://arxiv.org/abs/2411.09297</link>
      <description><![CDATA[arXiv:2411.09297v1 公告类型：新 
摘要：网络新闻的迅速普及对跟踪新闻主题的持续发展提出了重大挑战。传统时间线摘要构建了事件的时间顺序摘要，但往往缺乏满足不同粒度需求的灵活性。为了克服这一限制，我们引入了一种新范式，即动态粒度时间线摘要（DTELS），旨在根据用户指令或要求构建自适应时间线。本文为 DTLES 建立了一个全面的基准，包括：（1）基于新闻标准的评估框架，用于评估四个维度的时间线质量：信息量、粒度一致性、事实性和连贯性；（2）基于共识流程的具有多种粒度时间线注释的大规模多源数据集，以促进权威； (3) 对基于大型语言模型 (LLM) 和现有的最先进 TLS 方法的两种解决方案进行了广泛的实验和分析。实验结果证明了基于 LLM 的解决方案的有效性。然而，即使是最先进的 LLM 也难以持续生成信息丰富且粒度一致的时间线，这凸显了 DTELS 任务的挑战。]]></description>
      <guid>https://arxiv.org/abs/2411.09297</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DriveThru：印度尼西亚本地语言档案的文档提取平台和基准数据集</title>
      <link>https://arxiv.org/abs/2411.09318</link>
      <description><![CDATA[arXiv:2411.09318v1 公告类型：新
摘要：印度尼西亚是语言最多样化的国家之一。然而，尽管语言多样性如此，印尼语在自然语言处理 (NLP) 研究和技术中仍然代表性不足。在过去的两年中，已经进行了一些努力来构建印尼语的 NLP 资源。然而，这些努力大部分都集中在创建手动资源上，因此难以扩展到更多语言。虽然许多印尼语没有网络存在，但当地有一些资源以印刷形式很好地记录了这些语言，如书籍、杂志和报纸。将这些现有资源数字化将使印尼语资源建设能够扩展到更多语言。在本文中，我们提出了一种通过数字化文档来创建数据集的替代方法，这种方法以前从未用于在印度尼西亚构建数字语言资源。DriveThru 是一个利用系统中的光学字符识别 (OCR) 技术提取文档内容的平台，以更少的手动工作量和成本提供语言资源构建。本文还研究了当前最先进的 LLM 在 OCR 后校正中的实用性，以显示与现成的 OCR 相比提高字符准确率 (CAR) 和词语准确率 (WAR) 的能力。]]></description>
      <guid>https://arxiv.org/abs/2411.09318</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>每个人都应该有自己的声音被听到：分析应用于荷兰语音数据的 ASR 模型中的预测性别偏见</title>
      <link>https://arxiv.org/abs/2411.09431</link>
      <description><![CDATA[arXiv:2411.09431v1 公告类型：新
摘要：最近的研究表明，最先进的 (SotA) 自动语音识别 (ASR) 系统（例如 Whisper）通常会表现出预测偏差，这些偏差会对各个人口群体产生不成比例的影响。本研究重点是确定 Whisper 模型在 Common Voice 数据集和荷兰国家公共广播组织的荷兰语音数据上的性能差异。我们分析了不同性别群体的单词错误率、字符错误率和基于 BERT 的语义相似性。我们使用了 Weerts 等人 (2022) 的道德框架来评估服务质量危害和公平性，并就这些偏见的影响（特别是对于自动字幕）进行了细致的讨论。我们的研究结果显示，在所有模型大小中，不同性别群体的单词错误率 (WER) 存在很大差异，并通过统计测试确定了偏差。]]></description>
      <guid>https://arxiv.org/abs/2411.09431</guid>
      <pubDate>Fri, 15 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>