<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 11 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>多模态量子自然语言处理：使用量子方法分析真实数据的新框架</title>
      <link>https://arxiv.org/abs/2411.05023</link>
      <description><![CDATA[arXiv:2411.05023v1 公告类型：新
摘要：尽管量子计算在各个领域都取得了重大进展，但将量子方法应用于语言组合性（例如对语言结构和交互进行建模）的研究仍然有限。这一差距延伸到量子语言数据与来自图像、视频和音频等来源的真实世界数据的集成。本论文探讨了量子计算方法如何通过多模态数据集成增强语言的组合建模。具体来说，它通过应用 Lambeq 工具包对四种组合模型进行比较分析并评估它们对图像文本分类任务的影响，从而推进了多模态量子自然语言处理 (MQNLP)。结果表明，基于语法的模型，尤其是 DisCoCat 和 TreeReader，在有效捕捉语法结构方面表现出色，而词袋和顺序模型由于句法意识有限而举步维艰。这些发现强调了量子方法在增强语言建模和推动量子技术发展突破方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.05023</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士作为研究工具：研究人员使用情况和看法的大规模调查</title>
      <link>https://arxiv.org/abs/2411.05025</link>
      <description><![CDATA[arXiv:2411.05025v1 公告类型：新
摘要：大型语言模型 (LLM) 的兴起促使许多研究人员考虑将其用于科学工作。一些人发现使用 LLM 可以增强或自动化其研究流程的各个方面，而另一些人则因风险和道德问题而敦促谨慎行事。然而，很少有研究试图量化和描述研究人员使用 LLM 的方式及其原因。我们首次对 816 位经过验证的研究文章作者进行了大规模调查，以了解研究界如何利用和看待 LLM 作为研究工具。我们检查了参与者自我报告的 LLM 使用情况，发现 81% 的研究人员已经将 LLM 纳入其研究工作流程的不同方面。我们还发现，学术界传统上处于弱势的群体（非白人、初级和非英语母语研究人员）报告的 LLM 使用率和感知到的好处更高，这表明研究公平性有改善的潜力。然而，女性、非二元和高级研究人员有更大的道德问题，可能会阻碍采用。]]></description>
      <guid>https://arxiv.org/abs/2411.05025</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深度学习与机器学习——自然语言处理：从理论到应用</title>
      <link>https://arxiv.org/abs/2411.05026</link>
      <description><![CDATA[arXiv:2411.05026v1 公告类型：新
摘要：我们重点关注自然语言处理 (NLP) 和大型语言模型 (LLM) 的作用，探索机器学习、深度学习和人工智能的交集。随着人工智能继续彻底改变从医疗保健到金融等领域，标记化、文本分类和实体识别等 NLP 技术对于处理和理解人类语言至关重要。本文讨论了高级数据预处理技术以及使用 Hugging Face 等框架来实现基于转换器的模型。此外，它还强调了处理多语言数据、减少偏差和确保模型稳健性等挑战。通过解决数据处理和模型微调的关键方面，这项工作旨在为部署有效且合乎道德的 AI 解决方案提供见解。]]></description>
      <guid>https://arxiv.org/abs/2411.05026</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于 GPT 的数据增强训练的用于移动键盘的设备表情符号分类器</title>
      <link>https://arxiv.org/abs/2411.05031</link>
      <description><![CDATA[arXiv:2411.05031v1 公告类型：新
摘要：表情符号提高了使用移动键盘交换文本的智能手机用户之间的通信质量。要根据输入文本预测用户的表情符号，我们应该考虑设备上的低内存和时间限制，确保设备上的表情符号分类器覆盖广泛的表情符号类别，即使表情符号数据集通常不平衡，并根据用户喜好调整表情符号分类器输出。本文提出了一种基于 MobileBert 的设备表情符号分类器，对 SwiftKey 具有合理的内存和延迟要求。为了解决数据不平衡问题，我们利用广泛使用的 GPT 为每个表情符号类生成一个或多个标签。对于每个表情符号和相应的标签，我们将原始集合与 GPT 生成的句子合并，并用这个表情符号标记它们，无需人工干预，以缓解数据不平衡。在推理时，我们将表情符号输出与表情符号的用户历史记录进行插值，以获得更好的表情符号分类。结果表明，为 SwiftKey 部署的设备上表情符号分类器提高了表情符号预测的准确性性能，特别是对于罕见表情符号和表情符号参与度。]]></description>
      <guid>https://arxiv.org/abs/2411.05031</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从词向量到多模态嵌入：大型语言模型的技术、应用和未来方向</title>
      <link>https://arxiv.org/abs/2411.05036</link>
      <description><![CDATA[arXiv:2411.05036v1 公告类型：新
摘要：词嵌入和语言模型通过促进语言元素在连续向量空间中的表示，改变了自然语言处理 (NLP)。本综述探讨了分布假设和上下文相似性等基础概念，追溯了从稀疏表示（如独热编码）到密集嵌入（包括 Word2Vec、GloVe 和 fastText）的演变。我们研究了静态和上下文嵌入，强调了 ELMo、BERT 和 GPT 等模型的进步及其对跨语言和个性化应用的适应性。讨论扩展到句子和文档嵌入，涵盖聚合方法和生成主题模型，以及嵌入在多模态领域（包括视觉、机器人和认知科学）中的应用。分析了模型压缩、可解释性、数值编码和偏见缓解等高级主题，解决了技术挑战和道德影响。此外，我们还确定了未来的研究方向，强调需要可扩展的训练技术、增强的可解释性和对非文本模式的稳健基础。通过综合当前的方法和新兴趋势，本调查为研究人员和从业者提供了深入的资源，以突破基于嵌入的语言模型的界限。]]></description>
      <guid>https://arxiv.org/abs/2411.05036</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向解释语言模型：多跳推理案例研究</title>
      <link>https://arxiv.org/abs/2411.05037</link>
      <description><![CDATA[arXiv:2411.05037v1 公告类型：新
摘要：回答多跳推理问题需要从各种来源检索和综合信息。语言模型 (LM) 很难始终如一地执行这种推理。我们提出了一种通过在 LM 注意力头上进行有针对性的记忆注入来查明和纠正多跳推理失败的方法。首先，我们分析 GPT-2 模型对单跳和多跳提示的每层激活。然后，我们提出了一种机制，允许用户在推理过程中在关键的 LM 位置注入相关的提示特定信息（我们称之为“记忆”）。通过这样使 LM 能够在推理过程中整合额外的相关信息，我们提高了多跳提示完成的质量。我们通过经验表明，在关键注意力层进行简单、高效和有针对性的记忆注入通常会将多跳任务中所需下一个标记的概率提高高达 424%。我们观察到，在多跳推理过程中，注意力头的小子集可以显著影响模型预测。为了更忠实地解释这些注意力头，我们开发了注意力镜头：这是一种开源工具，它通过学习到的转换（称为镜头）将注意力头的输出转换为词汇标记。我们演示了如何使用镜头来揭示模型如何得出答案，并使用它们来定位模型失败的根源，例如在有偏见和恶意的语言生成的情况下。]]></description>
      <guid>https://arxiv.org/abs/2411.05037</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解码 YouTube 评论：利用 LLM 进行低资源语言分类</title>
      <link>https://arxiv.org/abs/2411.05039</link>
      <description><![CDATA[arXiv:2411.05039v1 公告类型：新
摘要：讽刺检测是情绪分析中的一项重大挑战，特别是因为它传达的观点与字面表达有偏差。这种挑战在社交媒体环境中更加突出，因为社交媒体中代码混合非常普遍，尤其是在达罗毗荼语中。代码混合涉及在单一话语中混合多种语言，通常使用非母语脚本，这使得使用单语数据训练的系统的任务变得复杂。这项共享任务引入了一种新颖的黄金标准语料库，专为代码混合文本中的讽刺和情绪检测而设计，特别是在泰米尔语-英语和马拉雅拉姆语-英语语言中。这项任务的主要目标是识别从社交媒体平台收集的泰米尔语-英语和马拉雅拉姆语-英语评论和帖子的代码混合数据集中的讽刺和情绪极性。每条评论或帖子都在消息级别标注了情绪极性，特别关注类别不平衡带来的挑战，反映了现实世界的情况。在这项工作中，我们通过提示将评论分为讽刺或非讽刺类别，对最先进的大型语言模型（如 GPT-3.5 Turbo）进行了实验。我们获得了泰米尔语的宏观 F1 分数 0.61。我们获得了马拉雅拉姆语的宏观 F1 分数 0.50。]]></description>
      <guid>https://arxiv.org/abs/2411.05039</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语料库和法学硕士中的价值观、议程和观察的自下而上和自上而下的分析</title>
      <link>https://arxiv.org/abs/2411.05040</link>
      <description><![CDATA[arXiv:2411.05040v1 公告类型：新
摘要：大型语言模型 (LLM) 从多个潜在视角生成多样化、情境化、有说服力的文本，这些文本受到提示和训练数据的严重影响。作为 LLM 采用的一部分，我们寻求表征 - 理想情况下管理 - 它们所表达的社会文化价值观，以确保安全性、准确性、包容性和文化保真度。我们提出了一种经过验证的方法，可以自动 (1) 从文本中提取异构潜在价值主张，(2) 评估文本中价值观的共鸣和冲突，以及 (3) 结合这些操作来表征人类来源和 LLM 来源文本数据的多元价值观一致性。]]></description>
      <guid>https://arxiv.org/abs/2411.05040</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过局部大型语言模型提高放射学报告的简洁性和结构</title>
      <link>https://arxiv.org/abs/2411.05042</link>
      <description><![CDATA[arXiv:2411.05042v1 公告类型：新
摘要：在本研究中，我们旨在通过提高发现的简洁性和结构化组织（也称为模板化）来增强放射学报告，特别是通过根据解剖区域组织信息。这种结构化方法使医生能够快速找到相关信息，从而提高报告的实用性。我们利用大型语言模型 (LLM)，例如 Mixtral、Mistral 和 Llama 来生成简洁、结构良好的报告。其中，​​我们主要关注 Mixtral 模型，因为与其他模型相比，它更符合特定的格式要求。为了维护数据安全和隐私，我们在机构的防火墙后面本地运行这些 LLM。我们利用 LangChain 框架并应用五种不同的提示策略来强制执行放射学报告中的一致结构，旨在消除无关语言并实现高度的简洁性。我们还引入了一个新指标，即简洁性百分比 (CP) 分数，以评估报告的简洁性。我们的数据集包括 814 份放射学报告，这些报告由我们癌症中心的七名获得委员会认证的放射科医生撰写。在评估不同的提示方法时，我们发现，生成简洁、结构良好的报告的最有效方法是首先指示 LLM 压缩报告，然后提示根据特定指南构建内容。我们根据所有提示策略处理格式问题、减少报告长度和遵守格式说明的能力对其进行了评估。我们的研究结果表明，开源、本地部署的 LLM 可以显著提高放射学报告的简洁性和结构，同时符合指定的格式标准。]]></description>
      <guid>https://arxiv.org/abs/2411.05042</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>绩效引导的 LLM 知识提炼，实现大规模高效文本分类</title>
      <link>https://arxiv.org/abs/2411.05045</link>
      <description><![CDATA[arXiv:2411.05045v1 公告类型：新
摘要：大型语言模型 (LLM) 由于计算需求高，在推理时面临重大挑战。为了解决这个问题，我们提出了性能引导知识蒸馏 (PGKD)，这是一种经济高效且高吞吐量的生产文本分类应用解决方案。PGKD 利用师生知识蒸馏将 LLM 的知识提炼成更小的、特定于任务的模型。PGKD 在学生模型和 LLM 之间建立了主动学习程序；LLM 利用硬负挖掘、学生模型验证性能和早期停止协议不断生成新的训练数据来指导数据生成。通过采用针对工业文本分类中普遍存在的多类、稀疏注释数据集定制的循环、性能感知方法，PGKD 有效地解决了训练挑战，并在多个多类分类数据集上优于传统的 BERT 基础模型和其他知识蒸馏方法。此外，成本和延迟基准测试表明，使用 PGKD 微调的模型在相同分类任务上的推理速度比 LLM 快 130 倍，成本低 25 倍。虽然 PGKD 主要用于文本分类任务，但其多功能框架可以扩展到任何 LLM 提炼任务，包括语言生成，使其成为优化各种 AI 应用程序性能的强大工具。]]></description>
      <guid>https://arxiv.org/abs/2411.05045</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PhoneLM：通过原则性预训练打造的高效、强大的小型语言模型系列</title>
      <link>https://arxiv.org/abs/2411.05046</link>
      <description><![CDATA[arXiv:2411.05046v1 公告类型：新
摘要：人们对开发用于设备部署的小型语言模型 (SLM) 的兴趣正在迅速增长。然而，现有的 SLM 设计几乎没有考虑设备硬件特性。相反，这项工作提出了一个简单而有效的 SLM 设计原则：在预训练之前，架构搜索 (接近) 最佳运行时效率。在这一原则的指导下，我们开发了 PhoneLM SLM 系列（目前有 0.5B 和 1.5B 版本），在具有相似参数大小的 SLM 中实现了最先进的能力效率权衡。我们完全开源了 PhoneLM 的代码、权重和训练数据集，以实现可重复性和透明度，包括基本版本和指导版本。我们还发布了能够准确调用 Android Intent 的经过微调的 PhoneLM 版本，以及端到端的 Android 演示。所有材料均可在 https://github.com/UbiquitousLearning/PhoneLM 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.05046</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用法学硕士 (LLM) 在上市平台上实现自然语言搜索</title>
      <link>https://arxiv.org/abs/2411.05048</link>
      <description><![CDATA[arXiv:2411.05048v1 公告类型：新
摘要：企业搜索要求用户具备查询、配置和元数据的复杂知识，这使得他们难以根据需要访问信息。大多数上市 (GTM) 平台都使用高级搜索，这是一种界面，使用户能够使用类别或关键字按各种字段过滤查询，但从历史上看，这已被证明是极其麻烦的，因为用户面临着看似数百个选项、字段和按钮。因此，使用自然语言查询长期以来一直是理想的选择，大型语言模型 (LLM) 进一步增强了这一概念。
在本文中，我们为卖家实施和评估了 Zoominfo 产品的解决方案，该产品使用自然语言提示 LLM，通过实体提取生成搜索字段，然后将其转换为搜索查询。中间搜索字段为每个查询提供了许多优势，包括消除语法错误、更简单的基本事实以及 LLM 解释的直观格式。
我们将此管道与许多先进的提示工程策略相结合，包括复杂的系统消息、少量提示、思路链 (CoT) 推理和执行细化。此外，我们手动创建了 500 多个自然语言查询的基本事实，从而实现了 Llama-3-8B-Instruct 的监督微调，并引入了复杂的数值指标。
通过对单个搜索实体的精确、Jaccard、余弦和语义相似性，对封闭、开源和微调的 LLM 模型进行了全面的实验，以证明我们方法的有效性。总体而言，最准确的封闭模型对每个查询的平均准确率为 97%，只有一个字段的表现低于 90%，与微调模型的结果相当。]]></description>
      <guid>https://arxiv.org/abs/2411.05048</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ProverbEval：探索低资源语言理解的 LLM 评估挑战</title>
      <link>https://arxiv.org/abs/2411.05049</link>
      <description><![CDATA[arXiv:2411.05049v1 公告类型：新
摘要：随着评估数据集的快速发展，用于评估广泛主题和领域的 LLM 理解，确定合适的语言理解基准变得越来越具有挑战性。在这项工作中，我们探索了低资源语言理解的 LLM 评估挑战，并引入了基于谚语的低资源语言的 LLM 评估基准 ProverbEval，以关注特定文化场景中的低资源语言理解。我们对各种 LLM 进行了基准测试，并探索了在基准测试过程中造成变化的因素。我们观察到性能差异高达 50%，具体取决于多项选择任务中答案选项的呈现顺序。母语谚语描述显着改善了谚语生成等任务，有助于改善结果。此外，单语评估始终优于跨语言评估。我们认为，在创建 LLM 评估基准时，必须特别注意选择的顺序、提示语言的选择、任务可变性和生成任务。]]></description>
      <guid>https://arxiv.org/abs/2411.05049</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在政治科学研究中，选择 BERT 还是 GPT 进行文本分类</title>
      <link>https://arxiv.org/abs/2411.05050</link>
      <description><![CDATA[arXiv:2411.05050v1 公告类型：新
摘要：政治科学家经常努力解决文本分类中的数据稀缺问题。最近，经过微调的 BERT 模型及其变体已成为解决此问题的有效解决方案。在这项研究中，我们研究了基于 GPT 的模型与快速工程相结合作为可行替代方案的潜力。我们在各种分类任务中进行了一系列实验，这些任务的类别数量和复杂度不同，以评估基于 BERT 的模型与基于 GPT 的模型在低数据场景中的有效性。我们的研究结果表明，虽然使用 GPT 模型进行零样本和少样本学习提供了合理的性能并且非常适合早期研究探索，但它们通常达不到（或充其量只能匹配）BERT 微调的性能，尤其是当训练集达到相当大的规模（例如 1,000 个样本）时。我们最后从性能、易用性和成本方面比较了这些方法，为面临数据限制的研究人员提供了实用指导。我们的研究结果对于那些在资源匮乏的环境中或标记数据有限的情况下从事定量文本分析的人尤其有用。]]></description>
      <guid>https://arxiv.org/abs/2411.05050</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FMEA Builder：设备维护的专家指导文本生成</title>
      <link>https://arxiv.org/abs/2411.05054</link>
      <description><![CDATA[arXiv:2411.05054v1 公告类型：新
摘要：基础模型在许多领域的生成任务中显示出巨大的前景。在这里，我们讨论使用基础模型生成与关键资产相关的结构化文档。故障模式和影响分析 (FMEA) 捕获资产或设备的组成、可能发生故障的方式及其后果。我们的系统使用大型语言模型来实现快速和专家监督的新 FMEA 文档的生成。实证分析表明，基础模型可以正确生成超过一半的 FMEA 关键内容。对可靠性专业人员的调查结果显示，人们对使用生成式 AI 为关键资产创建这些文档持积极态度。]]></description>
      <guid>https://arxiv.org/abs/2411.05054</guid>
      <pubDate>Mon, 11 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>