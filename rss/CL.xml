<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 23 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Hermes 3 技术报告</title>
      <link>https://arxiv.org/abs/2408.11857</link>
      <description><![CDATA[arXiv:2408.11857v1 公告类型：新
摘要：指令（或“聊天”）调整模型已成为大多数人与大型语言模型交互的主要方式。与“基础”或“基础”模型相反，指令调整模型经过优化，可响应命令式语句。我们提出了 Hermes 3，这是一种中立的通用指令和工具使用模型，具有强大的推理和创造能力。其最大版本 Hermes 3 405B 在多个公共基准测试中实现了开放权重模型中最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.11857</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:55 GMT</pubDate>
    </item>
    <item>
      <title>FactorLLM：通过混合专家对大型语言模型进行知识分解</title>
      <link>https://arxiv.org/abs/2408.11855</link>
      <description><![CDATA[arXiv:2408.11855v1 公告类型：新
摘要：最近的研究表明，大型语言模型 (LLM) 中的前馈网络 (FFN) 在存储各种语言和事实知识方面发挥着关键作用。传统方法经常面临挑战，因为它们的单片和冗余架构导致知识混乱，这需要更有效的解决方案和最小的计算开销，特别是对于 LLM。在本文中，我们探索了 LLM 中的 FFN 计算范式，并引入了 FactorLLM，这是一种新颖的方法，它将训练有素的密集 FFN 分解为稀疏子网络，而无需任何进一步的修改，同时保持相同的性能水平。此外，我们嵌入了一个来自混合专家 (MoE) 的路由器，结合我们设计的先验近似 (PA) 损失项，以促进专家的动态激活和知识适应，从而加速计算过程并使用最少的训练数据和微调步骤提高性能。因此，FactorLLM 可以实现高效的知识分解，并激活专门针对指定任务的精选专家组，模拟人类大脑的交互式功能分割。在各种基准测试中开展的大量实验证明了我们提出的 FactorLLM 的有效性，其性能与源模型相当，模型性能最高可达 85%，推理速度提高 30% 以上。代码：https://github.com/zhenwuweihe/FactorLLM。]]></description>
      <guid>https://arxiv.org/abs/2408.11855</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>动态自适应优化，用于在大型语言模型上进行有效的情绪分析微调</title>
      <link>https://arxiv.org/abs/2408.11856</link>
      <description><![CDATA[arXiv:2408.11856v1 公告类型：新
摘要：情绪分析在商业智能和财务预测等各个领域都发挥着至关重要的作用。大型语言模型 (LLM) 已成为情绪分析的流行范例，利用多任务学习同时解决特定任务。然而，由于管理各种任务复杂性的固有挑战，具有情绪分析微调的 LLM 通常表现不佳。此外，多任务学习中的恒定权重方法难以适应数据特征的变化，进一步复杂化了模型的有效性。为了解决这些问题，我们提出了一种具有动态自适应优化 (DAO) 模块的新型多任务学习框架。该模块设计为即插即用组件，可以无缝集成到现有模型中，为多任务学习提供有效而灵活的解决方案。DAO 模块的关键组件是动态自适应损失，它根据训练期间不同任务的相对重要性和数据特征动态调整分配给不同任务的权重。在标准和定制金融文本数据集上进行的情感分析表明，所提出的框架取得了优异的性能。具体而言，与以前的工作相比，这项工作分别将均方误差 (MSE) 和准确率 (ACC) 提高了 15.58% 和 1.24%。]]></description>
      <guid>https://arxiv.org/abs/2408.11856</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>当原始数据占主导地位时：大型语言模型嵌入对于医学机器学习应用的数值数据表示是否有效？</title>
      <link>https://arxiv.org/abs/2408.11854</link>
      <description><![CDATA[arXiv:2408.11854v1 公告类型：新
摘要：大型语言模型 (LLM) 的引入促进了数据表示和分析，为其在医学问答中的应用带来了重大进展。尽管取得了这些进步，但将表格数据（尤其是在临床环境中至关重要的数值数据）集成到 LLM 范式中尚未得到彻底探索。在本研究中，我们使用电子健康记录 (EHR) 数据检查了 LLM 最后隐藏状态的向量表示对医学诊断和预后的有效性。我们将这些嵌入与原始数值 EHR 数据的性能进行比较，当它们用作擅长表格数据学习的传统机器学习 (ML) 算法（例如 eXtreme Gradient Boosting）的特征输入时。我们专注于零样本设置中的指令调整 LLM 来表示异常生理数据，并评估它们作为特征提取器的效用，以增强 ML 分类器以预测诊断、住院时间和死亡率。此外，我们研究了零样本和少样本 LLM 嵌入的快速工程技术，以全面衡量其影响。尽管研究结果表明原始数据特征在医疗 ML 任务中仍然占主导地位，但零样本 LLM 嵌入表现出了有竞争力的结果，为未来医疗应用研究提供了一条有希望的途径。]]></description>
      <guid>https://arxiv.org/abs/2408.11854</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:53 GMT</pubDate>
    </item>
    <item>
      <title>通过情境学习快速进行训练数据集归因</title>
      <link>https://arxiv.org/abs/2408.11852</link>
      <description><![CDATA[arXiv:2408.11852v1 公告类型：新
摘要：我们研究了使用上下文学习和提示工程来估计训练数据在指令调整的大型语言模型 (LLM) 输出中的贡献。我们提出了两种新方法：(1) 一种基于相似性的方法，用于测量有和没有提供上下文的 LLM 输出之间的差异；(2) 一种混合分布模型方法，将识别贡献分数的问题框架为矩阵分解任务。我们的实证比较表明，混合模型方法对上下文学习中的检索噪声更具鲁棒性，从而提供了更可靠的数据贡献估计。]]></description>
      <guid>https://arxiv.org/abs/2408.11852</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:52 GMT</pubDate>
    </item>
    <item>
      <title>PyMarian：基于 Python 的快速神经机器翻译和评估</title>
      <link>https://arxiv.org/abs/2408.11853</link>
      <description><![CDATA[arXiv:2408.11853v1 公告类型：新
摘要：如今首选的深度学习语言是 Python；从可用库和技术支持等因素来看，它很难被击败。同时，用 C++ 等低级编程语言编写的软件在速度方面仍具有优势。我们描述了 Marian NMT 的 Python 接口，这是一个基于 C++ 的序列到序列模型训练和推理工具包，专注于机器翻译。该接口使使用 Marian 训练的模型能够连接到 Python 中丰富多样的工具。该接口的一大亮点是能够使用 Marian 的推理引擎从 Python 计算最先进的 COMET 指标，速度比现有实现快 7.8 倍。我们还简要介绍了许多其他集成，包括 Jupyter 笔记本、与预建模型的连接以及随包提供的 Web 应用程序界面。 PyMarian 可通过 $\texttt{pip install pymarian}$ 在 PyPI 中使用。]]></description>
      <guid>https://arxiv.org/abs/2408.11853</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:52 GMT</pubDate>
    </item>
    <item>
      <title>Style-Talker：微调音频语言模型和基于风格的文本转语音模型，实现快速口语对话生成</title>
      <link>https://arxiv.org/abs/2408.11849</link>
      <description><![CDATA[arXiv:2408.11849v1 公告类型：新
摘要：大型语言模型 (LLM) 的快速发展极大地推动了基于文本的聊天机器人的发展，展示了它们进行连贯且与上下文相关的对话的能力。然而，扩展这些进步以实现端到端语音到语音对话机器人仍然是一个巨大的挑战，主要是因为需要大量的数据集和计算资源。传统的将自动语音识别 (ASR)、LLM 和文本到语音 (TTS) 模型级联在一个管道中的方法虽然有效，但由于缺乏输入音频及其转录文本和输出音频之间的直接交互，因此存在不自然的韵律。这些系统还受到实时应用中 ASR 过程固有延迟的限制。本文介绍了 Style-Talker，这是一个创新框架，它可以微调音频 LLM 以及基于风格的 TTS 模型，以快速生成口语对话。 Style-Talker 获取用户输入的音频，并使用转录的聊天记录和说话风格来生成回复的说话风格和文本。随后，TTS 模型合成语音，然后播放给用户。在播放回复语音的同时，输入语音经过 ASR 处理以提取转录和说话风格，作为随后对话轮次的背景。这种新颖的管道加速了传统的级联 ASR-LLM-TTS 系统，同时集成了来自输入语音的丰富副语言信息。我们的实验结果表明，Style-Talker 在对话自然度和连贯性方面明显优于传统的级联和语音到语音基线，同时速度提高了 50% 以上。]]></description>
      <guid>https://arxiv.org/abs/2408.11849</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:51 GMT</pubDate>
    </item>
    <item>
      <title>具有自适应草稿长度的并行推测解码</title>
      <link>https://arxiv.org/abs/2408.11850</link>
      <description><![CDATA[arXiv:2408.11850v1 公告类型：新
摘要：推测解码 (SD) 已显示出强大的 LLM 推理加速能力，即首先使用额外的草稿模型提供多个 \textit{draft} 标记，然后原始目标模型并行验证这些标记。然而，现有的 SD 方法存在相互等待问题，即当草稿模型 \textit{猜测} 标记时，目标模型会卡住，反之亦然。该问题直接由草稿模型和目标模型的异步执行引起，并且由于推测解码中固定的草稿长度而加剧。为了解决这些挑战，我们提出了一个概念简单、灵活且通用的框架来促进推测解码，即具有自适应长度的并行推测解码（PEARL）。具体来说，PEARL 提出在起草阶段使用 \textit{pre-verify} 提前验证第一个草稿 token，并在验证阶段使用 \textit{post-verify} 生成更多草稿 token。PEARL 通过应用这两种策略将起草阶段和验证阶段并行，并针对不同场景实现自适应草稿长度，从而有效缓解相互等待问题。此外，我们从理论上证明 PEARL 的平均接受 token 数量高于现有的 \textit{draft-then-verify} 工作。在各种文本生成基准上进行的实验证明了我们的 \name 的有效性，与自回归解码和原始推测解码相比，其加速性能分别高达 \textbf{3.79$\times$} 和 \textbf{1.52$\times$}。]]></description>
      <guid>https://arxiv.org/abs/2408.11850</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:51 GMT</pubDate>
    </item>
    <item>
      <title>Prompto：用于异步查询 LLM 端点的开源库</title>
      <link>https://arxiv.org/abs/2408.11847</link>
      <description><![CDATA[arXiv:2408.11847v1 公告类型：新
摘要：大型语言模型 (LLM) 可用性的近期激增为研究开辟了令人兴奋的途径。然而，与这些模型的有效交互是一个重大障碍，因为 LLM 通常驻留在专有或自托管的 API 端点上，每个端点都需要自定义代码进行交互。因此，对不同模型进行比较研究可能非常耗时，并且需要大量的工程工作，从而阻碍研究效率和可重复性。为了应对这些挑战，我们提出了 prompto，这是一个开源 Python 库，它促进了 LLM 端点的异步查询，使研究人员能够同时与多个 LLM 交互，同时最大限度地提高效率并利用单独的速率限制。我们的库使研究人员和开发人员能够更有效地与 LLM 交互，并实现更快的实验和评估。 prompto 以 MIT 许可的形式发布，附带介绍视频（https://youtu.be/-eZAmlV4ypk），可通过 GitHub（https://github.com/alan-turing-institute/prompto）获取。]]></description>
      <guid>https://arxiv.org/abs/2408.11847</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:50 GMT</pubDate>
    </item>
    <item>
      <title>MGH 放射科 Llama：Llama 3 70B 放射科模型</title>
      <link>https://arxiv.org/abs/2408.11848</link>
      <description><![CDATA[arXiv:2408.11848v1 公告类型：新
摘要：近年来，放射学领域越来越多地利用人工智能 (AI) 的力量来提高诊断准确性、简化工作流程和改善患者护理。大型语言模型 (LLM) 已成为特别有前途的工具，在协助放射科医生生成报告、临床决策支持和患者沟通方面具有巨大潜力。本文介绍了一种先进的以放射学为重点的大型语言模型：MGH Radiology Llama。它是使用 Llama 3 70B 模型开发的，以之前的领域特定模型（如 Radiology-GPT 和 Radiology-Llama2）为基础。利用来自麻省总医院的独特而全面的数据集，该模型包含超过 650 万份跨各种成像模式的去识别医疗报告，在根据相应发现生成准确且临床相关的放射学印象方面表现出显着的改进。我们的评估结合了传统指标和基于 GPT-4 的评估，突出了这项工作相对于通用 LLM 的增强性能。]]></description>
      <guid>https://arxiv.org/abs/2408.11848</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:50 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLaMA 的标点符号恢复，仅使用前向传递解码</title>
      <link>https://arxiv.org/abs/2408.11845</link>
      <description><![CDATA[arXiv:2408.11845v1 公告类型：新
摘要：本文介绍了大型语言模型注释领域的两项进展，重点是标点符号恢复任务。我们的第一个贡献是将 LLaMA 应用于标点符号恢复，与既定的基准相比，它表现出了卓越的性能。
尽管质量令人印象深刻，但 LLaMA 面临着推理速度和幻觉方面的挑战。为了解决这个问题，我们的第二个贡献提出了仅前向传递解码 (FPOD)，这是一种用于注释任务的新型解码方法。这种创新方法将推理速度提高了 19.8 倍，有效地解决了关键瓶颈，并增强了 LLaMA 在无幻觉的大规模数据注释任务中的实用性。
这些贡献的结合不仅巩固了 LLaMA 作为标点符号恢复的强大工具的地位，而且还强调了 FPOD 是克服速度限制的关键策略。]]></description>
      <guid>https://arxiv.org/abs/2408.11845</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:49 GMT</pubDate>
    </item>
    <item>
      <title>隐喻理解的密度矩阵</title>
      <link>https://arxiv.org/abs/2408.11846</link>
      <description><![CDATA[arXiv:2408.11846v1 公告类型：新
摘要：在物理学中，密度矩阵用于表示混合状态，即纯状态的概率混合。这个概念以前曾用于对词汇歧义进行建模。在本文中，我们将隐喻视为一种词汇歧义，并研究是否可以使用词义混合有效地对隐喻意义进行建模。我们发现，对隐喻进行建模比其他类型的词汇歧义困难得多，但我们表现最佳的密度矩阵方法优于简单的基线以及一些神经语言模型。]]></description>
      <guid>https://arxiv.org/abs/2408.11846</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:49 GMT</pubDate>
    </item>
    <item>
      <title>OpenFactCheck：法学硕士事实性评估的统一框架</title>
      <link>https://arxiv.org/abs/2408.11832</link>
      <description><![CDATA[arXiv:2408.11832v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种实际应用中的使用越来越多，需要自动工具来检查其输出的事实准确性，因为 LLM 经常会产生幻觉。这很困难，因为它需要评估自由形式开放域响应的真实性。虽然对这个主题已经有很多研究，但不同的论文使用不同的评估基准和措施，这使得它们很难比较并阻碍了未来的进展。为了缓解这些问题，我们开发了一个统一的框架 OpenFactCheck，它有三个模块：(i) RESPONSEEVAL，它允许用户轻松定制自动事实核查系统并使用该系统评估输入文档中所有声明的真实性，(ii) LLMEVAL，它评估 LLM 的整体真实性，以及 (iii) CHECKEREVAL，一个用于评估自动事实核查系统的模块。 OpenFactCheck 是开源的（https://github.com/hasaniqbal777/openfactcheck），并作为 Python 库（https://pypi.org/project/openfactcheck/）和 Web 服务（https://huggingface.co/spaces/hasaniqbal777/OpenFactCheck）公开发布。介绍该系统的视频可在 https://youtu.be/-i9VKL0HleI 上找到。]]></description>
      <guid>https://arxiv.org/abs/2408.11832</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>可编辑公平性：语言模型中的细粒度偏差缓解</title>
      <link>https://arxiv.org/abs/2408.11843</link>
      <description><![CDATA[arXiv:2408.11843v1 公告类型：新
摘要：生成公平准确的预测对于在现实世界中部署大型语言模型 (LLM) 起着关键作用。然而，现有的去偏方法不可避免地会产生不公平或不正确的预测，因为它们的设计和评估是为了实现不同社会群体之间的平等，但却忽略了个人的常识事实，导致修改后的知识引发不合理或不受欢迎的预测。在本文中，我们首先建立了一个新的偏差缓解基准 BiaScope，它利用新构建的数据集和知识保留和泛化指标系统地评估性能。然后，我们提出了一种新颖的去偏方法 Fairness Stamp (FAST)，它可以对个人社会偏见进行细粒度校准。FAST 确定负责存储社会偏见的决定层，然后通过集成一个小型模块化网络来校准其输出，同时考虑偏差缓解和知识保存需求。综合实验表明，FAST 以卓越的去偏性能超越了最先进的基线，同时又不损害整体模型的知识保留和下游预测能力。这凸显了细粒度去偏策略在 LLM 中实现公平性的潜力。代码将公开发布。]]></description>
      <guid>https://arxiv.org/abs/2408.11843</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>GPT 模型中概念解释的机制：解释性见解</title>
      <link>https://arxiv.org/abs/2408.11827</link>
      <description><![CDATA[arXiv:2408.11827v1 公告类型：新
摘要：在大型语言模型 (LLM) 中定位和编辑知识对于提高其准确性、安全性和推理原理至关重要。我们引入了“概念编辑”，这是知识编辑的一种创新变体，它揭示了这些模型中的概念化机制。使用反向字典任务、推理跟踪和输入抽象，我们分析了 Transformer 模型的多层感知器 (MLP)、多头注意力 (MHA) 和隐藏状态组件。我们的结果揭示了不同的模式：MLP 层采用键值检索机制和上下文相关处理，它们与相对输入标记高度相关。MHA 层表现出分布式特性，具有显着的高级激活，表明了复杂的语义集成。隐藏状态强调了最后一个标记和顶层在推理过程中的重要性。我们观察到逐步信息构建和分布式表示的证据。这些观察结果阐明了转换器模型如何处理语义信息，为有针对性的干预和改进的可解释性技术铺平了道路。我们的工作突出了 LLM 中语义处理的复杂性和分层性，以及在这些模型中隔离和修改特定概念的挑战。]]></description>
      <guid>https://arxiv.org/abs/2408.11827</guid>
      <pubDate>Fri, 23 Aug 2024 06:19:47 GMT</pubDate>
    </item>
    </channel>
</rss>