<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 16 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>真实还是机器人？评估法学硕士是否准确模拟人类对话反应的质量</title>
      <link>https://arxiv.org/abs/2409.08330</link>
      <description><![CDATA[arXiv:2409.08330v1 公告类型：新
摘要：由于需要招募、培训和收集研究参与者的数据，研究和构建对话任务的数据集既昂贵又耗时。为此，许多最近的研究都试图使用大型语言模型 (LLM) 来模拟人与人之间和人与 LLM 之间的互动，因为它们已被证明在许多情况下都能生成令人信服的类似人类的文本。然而，基于 LLM 的模拟在多大程度上真正反映了人类的对话？在这项工作中，我们通过从 WildChat 数据集生成 100,000 对 LLM-LLM 和人与 LLM 对话的大规模数据集并量化 LLM 模拟与人类对应者的匹配程度来回答这个问题。总体而言，我们发现模拟和人类互动之间的一致性相对较低，表明在多种文本属性（包括风格和内容）上存在系统性分歧。此外，在比较英语、中文和俄语对话时，我们发现模型的表现相似。我们的结果表明，当人类写作方式与法学硕士自己的风格更相似时，法学硕士通常会表现得更好。]]></description>
      <guid>https://arxiv.org/abs/2409.08330</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的多智能体系统的知识标注</title>
      <link>https://arxiv.org/abs/2409.08406</link>
      <description><![CDATA[arXiv:2409.08406v1 公告类型：新
摘要：问题的知识标记在现代智能教育应用中至关重要，包括学习进度诊断、练习问题推荐和课程内容组织。传统上，这些注释是由教育专家执行的，因为这项任务不仅需要对问题词干和知识定义有深入的语义理解，还需要有将问题解决逻辑与相关知识概念联系起来的强大能力。随着先进的自然语言处理 (NLP) 算法的出现，例如预训练语言模型和大型语言模型 (LLM)，先驱研究已经探索使用各种机器学习模型自动化知识标记过程。在本文中，我们研究了使用多智能体系统来解决以前算法的局限性，特别是在处理涉及复杂知识定义和严格数值约束的复杂情况时。通过在公开的数学问题知识标记数据集 MathKnowCT 上展示其卓越性能，我们强调了基于 LLM 的多智能体系统在克服以前方法遇到的挑战方面的巨大潜力。最后，通过深入讨论自动化知识标记的含义，我们强调了在教育环境中部署基于 LLM 的算法的良好结果。]]></description>
      <guid>https://arxiv.org/abs/2409.08406</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在大型语言模型中，当上下文主导但参数记忆跟随时</title>
      <link>https://arxiv.org/abs/2409.08435</link>
      <description><![CDATA[arXiv:2409.08435v1 公告类型：新
摘要：大型语言模型 (LLM) 在利用各种知识来源方面取得了显著进展。本研究调查了九种广泛使用的 LLM 在知识一致场景中回答开放式问题时如何在局部上下文和全局参数之间分配知识。我们引入了一个新数据集 WikiAtomic，并系统地改变上下文大小，以分析 LLM 如何在知识一致场景中优先考虑和利用所提供的信息及其参数知识。此外，我们还研究了它们在不同上下文大小下产生幻觉的倾向。我们的研究结果揭示了跨模型的一致模式，包括对上下文（约 70%）和参数（约 30%）知识的一致依赖，以及随着上下文的增加幻觉减少。这些见解强调了更有效的上下文组织和开发更确定地使用输入的模型以实现稳健性能的重要性。]]></description>
      <guid>https://arxiv.org/abs/2409.08435</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 BERT 的抑郁症检测摘要方法</title>
      <link>https://arxiv.org/abs/2409.08483</link>
      <description><![CDATA[arXiv:2409.08483v1 公告类型：新
摘要：抑郁症是一种全球流行的精神疾病，如果不加以解决，可能会产生严重后果，尤其是对于复发性发作的个体。先前的研究表明，早期干预有可能减轻或缓解抑郁症状。然而，在现实环境中实施此类干预措施可能会带来相当大的挑战。一种有前途的策略是利用机器学习和人工智能从各种数据源中自主检测抑郁指标。最广泛可用和信息量最大的数据源之一是文本，它可以揭示一个人的情绪、想法和感受。在这种情况下，虚拟代理被编程为使用临床验证的问卷进行访谈，例如在 DAIC-WOZ 数据集中找到的问卷，通过语言分析提供了一种强大的抑郁症检测方法。利用基于 BERT 的模型将文本转换为数字表示，这些模型功能强大且用途广泛，但比当代大型语言模型使用的资源更少，可显着提高抑郁症诊断的准确性。这些模型能够熟练地捕捉复杂的语义和句法细微差别，从而提高抑郁症状的检测准确性。鉴于这些模型在文本长度方面的固有局限性，我们的研究提出了文本摘要作为一种预处理技术，以减少输入文本的长度和复杂性。在我们独特开发的特征提取和分类框架内实施此方法，在测试集上获得了 0.67 的 F1 分数，超过了所有先前的基准，在验证集上获得了 0.81 的 F1 分数，超过了 DAIC-WOZ 数据集上大多数先前的结果。此外，我们还设计了一个抑郁症词典来评估摘要质量和相关性。这个词典是正在进行的抑郁症检测研究的宝贵资产。]]></description>
      <guid>https://arxiv.org/abs/2409.08483</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Eir：泰语医学大型语言模型</title>
      <link>https://arxiv.org/abs/2409.08523</link>
      <description><![CDATA[arXiv:2409.08523v1 公告类型：新
摘要：我们提出了 Eir Thai Medical LLM，这是一个具有 80 亿个参数的大型语言模型，专门用于提高处理泰语医疗任务的准确性。该模型专注于为医疗保健专业人员和患者提供清晰易懂的答案，从而提高诊断和治疗过程的效率。进行了人工评估，以确保模型符合护理标准并提供公正的答案。
为了优先考虑数据安全，该模型部署在医院的内部网络中，确保高安全性和更快的处理速度。内部 API 连接采用加密和严格的身份验证措施进行保护，以防止数据泄露和未经授权的访问。
我们在四个医学基准上评估了几个具有 80 亿个参数的开源大型语言模型：MedQA、MedMCQA、PubMedQA 和 MMLU 的医学子集。表现最佳的基线用于开发 Eir Thai Medical LLM。我们的评估采用了多种提问策略，包括零样本、少样本、思路链推理和集成/自洽投票方法。我们的模型比市面上可用的泰语大型语言模型高出 10% 以上。此外，我们还针对泰语临床应用开发了增强模型测试，测试了 18 项临床任务，我们的模型比 GPT-4o 的性能高出 11% 以上]]></description>
      <guid>https://arxiv.org/abs/2409.08523</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士支持的字素到音素的转换：基准和案例研究</title>
      <link>https://arxiv.org/abs/2409.08554</link>
      <description><![CDATA[arXiv:2409.08554v1 公告类型：新
摘要：字素到音素 (G2P) 的转换在语音处理中至关重要，特别是对于语音合成等应用。G2P 系统必须具备对具有多音词和上下文相关音素的语言的语言理解和语境感知。大型语言模型 (LLM) 最近在各种语言任务中表现出巨大的潜力，这表明它们的语音知识可以用于 G2P。在本文中，我们评估了 LLM 在 G2P 转换中的表现，并引入了提示和后处理方法，这些方法无需额外的训练或标记数据即可增强 LLM 输出。我们还提供了一个基准数据集，旨在评估 G2P 在波斯语句子级语音挑战中的表现。我们的结果表明，通过应用所提出的方法，LLM 可以胜过传统的 G2P 工具，即使在像波斯语这样代表性不足的语言中也是如此，这凸显了开发 LLM 辅助 G2P 系统的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.08554</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过隐藏的思路链解码来加速和提升大型语言模型推理</title>
      <link>https://arxiv.org/abs/2409.08561</link>
      <description><![CDATA[arXiv:2409.08561v1 公告类型：新
摘要：大型语言模型 (LLM) 通过使用思路链 (CoT) 提示，在需要推理和多步骤问题解决的任务中表现出卓越的能力。然而，生成完整的 CoT 过程会导致输出序列明显变长，从而增加计算成本和推理过程中的延迟。为了应对这一挑战，我们提出了一种通过语义对齐来压缩 CoT 过程的新方法，从而实现更高效的解码，同时保留 CoT 推理的优势。我们的方法引入了一个辅助 CoT 模型，该模型学习生成完整的思维过程并将其压缩为与原始 CoT 输出在语义上对齐的紧凑特殊标记表示。然后将此压缩表示集成到隐藏思路链 (HCoT) 模型的输入中。训练过程遵循两阶段程序：首先，使用对比损失优化 CoT 模型以生成与真实 CoT 输出对齐的压缩标记表示。随后，在 CoT 模型参数冻结的情况下，对 HCoT 模型进行微调，以根据前缀指令和 CoT 模型中的压缩 CoT 表示生成准确的后续预测。在三个具有挑战性的领域（数学推理、代理调用和问答）进行的大量实验表明，与完整的 CoT 基线相比，我们的语义压缩方法实现了具有竞争力或改进的性能，同时将解码时间显著加快了至少 1.5 倍。此外，结合对比学习目标进一步提高了压缩表示的质量，从而实现了更好的 CoT 提示和更高的任务准确性。我们的工作为在广泛的应用中更有效地利用 LLM 中的多步推理能力铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2409.08561</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>破解密码：印尼多领域法学硕士真实专业考试评估</title>
      <link>https://arxiv.org/abs/2409.08564</link>
      <description><![CDATA[arXiv:2409.08564v1 公告类型：新
摘要：虽然大型语言模型中的知识评估主要集中在数学和物理等学术科目上，但这些评估往往无法捕捉到现实世界职业的实际需求。在本文中，我们介绍了 IndoCareer，这是一个包含 8,834 个多项选择题的数据集，旨在评估各个领域的职业和专业认证考试的表现。IndoCareer 专注于印度尼西亚，提供丰富的本地背景，涵盖六个关键领域：（1）医疗保健、（2）保险和金融、（3）创意和设计、（4）旅游和酒店业、（5）教育和培训，以及（6）法律。我们对 27 个大型语言模型的全面评估表明，这些模型在具有强大本地背景的领域（例如保险和金融）尤其困难。此外，在使用整个数据集时，打乱答案选项通常会在模型之间保持一致的评估结果，但它会在保险和金融领域引入不稳定性。]]></description>
      <guid>https://arxiv.org/abs/2409.08564</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型可以利用多种指令在多人说话场景中转录语音</title>
      <link>https://arxiv.org/abs/2409.08596</link>
      <description><![CDATA[arXiv:2409.08596v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展彻底改变了各个领域，带来了重大进展和新机遇。尽管在语音相关任务方面取得了进展，但 LLM 在多说话者场景中的探索还不够。在这项工作中，我们提出了一项开创性的努力，以研究 LLM 在多说话者环境中转录语音的能力，遵循与多说话者自动语音识别 (ASR)、目标说话者 ASR 和基于特定说话者属性（例如性别、发生顺序、语言和说出的关键字）的 ASR 相关的多功能指令。我们的方法利用 WavLM 和 Whisper 编码器提取对说话者特征和语义上下文敏感的多方面语音表示。然后将这些表示输入到使用 LoRA 微调的 LLM 中，从而实现语音理解和转录功能。全面的实验表明，我们提出的系统 MT-LLM 在鸡尾酒会场景中表现出色，凸显了 LLM 在这种复杂环境中根据用户指令处理语音相关任务的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.08596</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>L3Cube-IndicQuest：用于评估印度语境中法学硕士知识的基准问答数据集</title>
      <link>https://arxiv.org/abs/2409.08706</link>
      <description><![CDATA[arXiv:2409.08706v1 公告类型：新
摘要：大型语言模型 (LLM) 在将印度语纳入多语言模型方面取得了重大进展。然而，定量评估这些语言的表现是否与英语等全球主导语言相当至关重要。目前，缺乏专门用于评估各种印度语 LLM 区域知识的基准数据集。在本文中，我们提出了 L3Cube-IndicQuest，这是一个黄金标准的问答基准数据集，旨在评估多语言 LLM 在各种印度语中捕捉区域知识的能力。该数据集包含 200 个问答对，每个问答对针对英语和 19 种印度语，涵盖了印度地区的五个特定领域。我们的目标是让这个数据集作为基准，为评估 LLM 在理解和表示与印度背景相关的知识方面的表现提供基本事实。IndicQuest 既可用于基于参考的评估，也可用于 LLM 作为评判者的评估。该数据集在 https://github.com/l3cube-pune/indic-nlp 公开共享。]]></description>
      <guid>https://arxiv.org/abs/2409.08706</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提炼单语和跨语言上下文词语表征</title>
      <link>https://arxiv.org/abs/2409.08719</link>
      <description><![CDATA[arXiv:2409.08719v1 公告类型：新 
摘要：在本研究中，我们提出了一种方法，该方法从单语和跨语言环境中的预训练掩码语言模型中提取上下文中的词义表示。词表示是上下文感知词汇语义和无监督语义文本相似度 (STS) 估计的基础。与现有方法不同，我们的方法不需要人工注释的语料库，也不需要更新预训练模型的参数。后一个特性对于实际场景很有吸引力，其中现成的预训练模型是不同应用程序之间的共同资产。具体而言，我们的方法学习使用自注意力来组合预训练模型的不同隐藏层的输出。我们基于自动编码器的训练只需要自动生成的语料库。为了评估所提出方法的性能，我们使用各种基准任务进行了大量实验。单语任务的结果证实，我们的表征与之前研究中的上下文感知词汇语义任务相比表现出了竞争力，并且在 STS 估计方面表现优于它。跨语言任务的结果表明，所提出的方法大大改善了多语言预训练模型的跨语言词汇表征。]]></description>
      <guid>https://arxiv.org/abs/2409.08719</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>手语语义消歧</title>
      <link>https://arxiv.org/abs/2409.08780</link>
      <description><![CDATA[arXiv:2409.08780v1 公告类型：新
摘要：该项目探索增强德国手语手语翻译的方法，特别关注同音异义词的歧义消除。手语含糊不清且研究不足，这是我们进行实验的基础。我们通过在各种身体部位表征上训练基于 Transformer 的模型来将焦点转移到所述身体部位上来实现改进。为了确定例如手或嘴表征的影响，我们尝试了不同的组合。结果表明，在小数据集设置中，关注嘴巴会提高性能，而在较大的数据集设置中，将焦点转移到手上会获得更好的结果。我们的研究结果通过改进为数字助理供电的系统，实现更准确的交互，为听力障碍人士提供了更好的可访问性。该项目的代码可以在 GitHub 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.08780</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型优化成分替代，以增强食谱中的植物化学成分含量</title>
      <link>https://arxiv.org/abs/2409.08792</link>
      <description><![CDATA[arXiv:2409.08792v1 公告类型：新
摘要：在新兴的计算美食学领域，将烹饪实践与科学支持的营养目标相结合变得越来越重要。本研究探讨了如何应用大型语言模型 (LLM) 来优化食谱中的成分替代，特别是增强膳食中的植物化学含量。植物化学物质是植物中发现的生物活性化合物，根据临床前研究，它可能具有潜在的健康益处。我们使用成分替代数据集对模型进行了微调，包括 OpenAI 的 GPT-3.5、DaVinci 和 Meta 的 TinyLlama。这些模型用于预测增强植物化学含量的替代品并创建相应的丰富食谱数据集。我们的方法提高了成分替代任务中的 Hit@1 准确率，从基线的 34.53 正负 0.10% 提高到原始 GISMo 数据集上的 38.03 正负 0.28%，从 40.24 正负 0.36% 提高到同一数据集的改进版本上的 54.46 正负 0.29%。这些替代导致了 1,951 种富含植物化学成分的成分搭配和 1,639 种独特的食谱的产生。虽然这种方法展示了优化成分替代的潜力，但在得出关于健康益处的结论时必须谨慎，因为这些说法是基于临床前证据的。未来的工作应该包括临床验证和更广泛的数据集，以进一步评估这些替代品的营养影响。这项研究代表了利用人工智能促进更健康饮食习惯的一步，为将计算方法与营养科学相结合提供了潜在途径。]]></description>
      <guid>https://arxiv.org/abs/2409.08792</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索基于 Zipformer 的上下文 ASR 的 SSL 离散语音特征</title>
      <link>https://arxiv.org/abs/2409.08797</link>
      <description><![CDATA[arXiv:2409.08797v1 公告类型：新
摘要：基于自监督学习 (SSL) 的离散语音表示非常紧凑且领域适应性强。在本文中，从 WavLM 模型中提取的 SSL 离散语音特征被用作 Zipformer-Transducer ASR 系统中的附加交叉话语声学上下文特征。在 Gigaspeech 1000 小时语料库上充分展示了用离散标记特征替换 Fbank 特征对交叉话语上下文（来自前面和未来的片段）或当前话语的内部上下文或同时建模两者的有效性。使用基于离散标记的交叉话语上下文特征的最佳 Zipformer-Transducer 系统优于仅使用话语内部上下文的基线，在开发和测试数据上，统计上显着的字错误率 (WER) 降低了 0.32% 至 0.41% 绝对值（2.78% 至 3.54% 相对值）。在开发集和测试集上获得的最低已公布 WER 分别为 11.15% 和 11.14%。我们的工作是开源的，可在 https://github.com/open-creator/icefall/tree/master/egs/gigaspeech/Context\_ASR 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2409.08797</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索用于多语言 ASR 的 SSL 离散令牌</title>
      <link>https://arxiv.org/abs/2409.08805</link>
      <description><![CDATA[arXiv:2409.08805v1 公告类型：新
摘要：随着自监督学习 (SSL) 在语音相关任务中的进步，人们对利用 SSL 生成的离散标记进行自动语音识别 (ASR) 的兴趣日益浓厚，因为它们提供了更快的处理技术。然而，以前的研究主要集中在具有 Fbank 特征的多语言 ASR 或具有离散标记的英语 ASR，在将离散标记适应多语言 ASR 场景方面存在空白。本研究对跨多语言域的各种领先 SSL 模型生成的离散标记进行了全面比较。我们旨在探索语音离散标记在单语言和多语言 ASR 场景中跨多语言域的性能和效率。实验结果表明，在七个语言领域的 ASR 任务中，离散标记与在 Fbank 特征上训练的系统取得了相当的结果，在开发集和测试集上的平均词错误率 (WER) 分别降低了 0.31% 和 1.76% 绝对值（2.80% 和 15.70% 相对值），特别是在波兰语测试集上，WER 降低了 6.82% 绝对值（41.48% 相对值）。]]></description>
      <guid>https://arxiv.org/abs/2409.08805</guid>
      <pubDate>Mon, 16 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>