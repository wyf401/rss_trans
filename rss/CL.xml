<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 05 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>任务提示向量：通过多任务软提示传输进行有效初始化</title>
      <link>https://arxiv.org/abs/2408.01119</link>
      <description><![CDATA[arXiv:2408.01119v1 公告类型：新
摘要：提示调整是一种模块化且高效的大型语言模型 (LLM) 训练解决方案。其主要优点之一是任务模块化，使其适用于多任务问题。然而，当前基于软提示的方法通常会牺牲多任务模块化，要求对每个新添加的任务完全或部分重复训练过程。虽然最近关于任务向量的工作对完整模型权重应用了算术运算以实现所需的多任务性能，但仍然缺少针对软提示的类似方法。为此，我们引入了任务提示向量，它由调整后的软提示权重与其随机初始化之间的元素差异创建。在 12 个 NLU 数据集上的实验结果表明，任务提示向量可用于低资源设置，以有效地初始化类似任务的提示调整。此外，我们表明任务提示向量与提示调整的随机初始化无关。这样就可以使用来自不同任务的预训练向量进行快速运算。这样，通过对来自多个任务的任务提示向量进行算术加法，我们在某些情况下能够超越最先进的基线。]]></description>
      <guid>https://arxiv.org/abs/2408.01119</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:29 GMT</pubDate>
    </item>
    <item>
      <title>利用知识图谱进行扎实交流，弥补对话中的信息鸿沟</title>
      <link>https://arxiv.org/abs/2408.01088</link>
      <description><![CDATA[arXiv:2408.01088v1 公告类型：新
摘要：知识模型是对话系统的基础，用于实现对话交互，这需要处理特定领域的知识。确保在提供信息的对话中进行有效沟通需要将用户理解与系统可用的知识相结合。然而，对话系统经常面临挑战，因为信息在自然语言中的表达方式与系统内部知识中的表示方式存在语义不一致。为了解决这个问题，我们研究了大型语言模型在对话基础方面的潜力，这是一种通过在对话参与者之间建立共享知识来弥合信息差距的机制。我们的方法包括注释五个知识领域的人类对话，以创建一个名为 BridgeKG 的新对话语料库。通过对该数据集进行一系列实验，我们实证评估了大型语言模型在知识图谱结构中对基础行为进行分类和识别基础信息项的能力。我们的研究结果揭示了这些模型如何利用语境学习来完成对话基础任务和常见的预测错误，我们通过具有挑战性的对话中的例子来说明这一点。我们讨论了模型如何将知识图谱作为非结构化对话话语和结构化信息项之间的语义层来处理。]]></description>
      <guid>https://arxiv.org/abs/2408.01088</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:28 GMT</pubDate>
    </item>
    <item>
      <title>具有神经形态基元的通用数据流模型</title>
      <link>https://arxiv.org/abs/2408.01090</link>
      <description><![CDATA[arXiv:2408.01090v1 公告类型：新
摘要：神经形态计算在神经网络以外的各种应用中表现出提供高性能优势的巨大潜力。然而，需要一个符合神经形态计算特征的通用程序执行模型来弥合程序多功能性和神经形态硬件效率之间的差距。数据流模型提供了一种潜在的解决方案，但在处理控制流程序时，它面临着高图形复杂性和与神经形态硬件不兼容的问题，这降低了可编程性和性能。在这里，我们提出了一种专为神经形态硬件量身定制的数据流模型，称为神经形态数据流，它为控制逻辑提供了紧凑、简洁和神经形态兼容的程序表示。神经形态数据流引入了“何时”和“何地”原语，从而重构了控制视图。神经形态数据流将这些原语嵌入到数据流模式中，并具有从脉冲算法继承的可塑性。我们的方法能够在具有可编程性和可塑性的神经形态硬件上部署通用程序，同时充分利用硬件的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.01090</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:28 GMT</pubDate>
    </item>
    <item>
      <title>BioRAG：用于生物问题推理的 RAG-LLM 框架</title>
      <link>https://arxiv.org/abs/2408.01107</link>
      <description><![CDATA[arXiv:2408.01107v1 公告类型：新
摘要：生命科学研究的问答系统具有发现速度快、见解不断发展和知识实体之间复杂交互的特点，在维护全面的知识仓库和准确的信息检索方面提出了独特的挑战。为了解决这些问题，我们引入了 BioRAG，这是一种具有大型语言模型 (LLM) 框架的新型检索增强生成 (RAG)。我们的方法首先解析、索引和分割 2200 万篇科学论文作为基础知识，然后训练针对该领域的专门嵌入模型。此外，我们通过结合领域特定的知识层次结构来增强向量检索过程，这有助于对每个查询和上下文之间的复杂相互关系进行建模。对于需要最新信息的查询，BioRAG 会解构问题并采用与搜索引擎结合的迭代检索过程进行逐步推理。严格的实验表明，我们的模型在多个生命科学问答任务中的表现优于微调的 LLM、带有搜索引擎的 LLM 和其他科学 RAG 框架。]]></description>
      <guid>https://arxiv.org/abs/2408.01107</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:28 GMT</pubDate>
    </item>
    <item>
      <title>IAI 集团参加 CheckThat! 2024：用于可核查索赔检测的 Transformer 模型和数据增强</title>
      <link>https://arxiv.org/abs/2408.01118</link>
      <description><![CDATA[arXiv:2408.01118v1 公告类型：新
摘要：本文介绍了 IAI 小组在 2024 年 CheckThat！实验室“任务 1：检查价值评估”框架内对索赔的自动检查价值评估的参与。该任务涉及自动检测英语、荷兰语和阿拉伯语政治辩论和 Twitter 数据中的检查价值索赔。我们使用了各种预先训练的生成解码器和编码器转换器模型，采用了诸如少样本思维链推理、微调、数据增强和从一种语言到另一种语言的迁移学习等方法。尽管在性能方面取得了不同的成功，但我们的模型在组织者的排行榜上取得了显着的排名：英语排名第九，荷兰语排名第三，阿拉伯语排名第一，利用多语言数据集增强了检查价值检测的通用性。尽管与开发测试数据集相比，未标记测试数据集的性能显着下降，但我们的研究结果有助于索赔检测研究的持续努力，突出了索赔验证系统中语言特定适应的挑战和潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.01118</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:28 GMT</pubDate>
    </item>
    <item>
      <title>UNER：用于富视觉文档中命名实体识别的统一预测头</title>
      <link>https://arxiv.org/abs/2408.01038</link>
      <description><![CDATA[arXiv:2408.01038v1 公告类型：新
摘要：视觉丰富文档中的命名实体识别（VrD-NER）在各种现实场景和应用中起着至关重要的作用。然而，VrD-NER 的研究面临三大挑战：复杂的文档布局、错误的阅读顺序和不合适的任务表述。为了应对这些挑战，我们提出了一个查询感知实体提取头，即 UNER，以与现有的多模态文档转换器协作以开发更强大的 VrD-NER 模型。UNER 头将 VrD-NER 任务视为序列标记和阅读顺序预测的组合，有效地解决了文档中不连续实体的问题。在不同数据集上的实验评估证明了 UNER 在提高实体提取性能方面的有效性。此外，UNER 头在各种 VrD-NER 数据集上启用了监督预训练阶段，以增强文档转换器主干，并展示了从预训练阶段到微调阶段的大量知识转移。通过结合通用布局理解，基于 UNER 的预训练模型在小样本和跨语言场景中表现出显著优势，并展现出零样本实体提取能力。]]></description>
      <guid>https://arxiv.org/abs/2408.01038</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:27 GMT</pubDate>
    </item>
    <item>
      <title>QUDSELECT：讨论解析中的问题的选择性解码</title>
      <link>https://arxiv.org/abs/2408.01046</link>
      <description><![CDATA[arXiv:2408.01046v1 公告类型：新
摘要：讨论中的问题 (QUD) 是一个话语框架，它使用隐式问题来揭示句子之间的话语关系。在 QUD 解析中，每个句子都被视为对先前上下文中的锚句触发的问题的回答。生成的 QUD 结构需要符合几个理论标准，例如答案兼容性（问题的回答程度），这使得 QUD 解析成为一项具有挑战性的任务。以前的工作以流水线方式构建 QUD 解析器（即在上下文中检测触发句，然后生成问题）。然而，这些解析器缺乏对任务的整体视图，很难满足所有标准。在这项工作中，我们引入了 QUDSELECT，这是一个联合训练框架，它考虑 QUD 标准有选择地解码 QUD 依赖结构。使用指令调整，我们训练模型同时预测锚句并生成相关问题。为了明确纳入标准，我们采用了选择性解码策略，即在推理过程中对多个 QUD 候选进行采样，然后使用标准评分器选择最佳候选。我们的方法在人工评估中比最先进的基线模型高出 9%，在自动评估中比最先进的基线模型高出 4%，证明了我们框架的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.01046</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:27 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型进行移动应用评论特征提取</title>
      <link>https://arxiv.org/abs/2408.01063</link>
      <description><![CDATA[arXiv:2408.01063v1 公告类型：新
摘要：由于用户生成的文档质量低、主观偏见和内容嘈杂，移动应用评论分析面临着独特的挑战。从这些评论中提取特征对于特征优先级和情感分析等任务至关重要，但这仍然是一项具有挑战性的任务。同时，基于 Transformer 架构的仅编码器模型已在多个软件工程流程的分类和信息提取任务中显示出良好的结果。本研究探讨了仅编码器的大型语言模型可以增强从移动应用评论中提取特征的假设。通过利用来自工业环境的众包注释，我们将特征提取重新定义为监督标记分类任务。我们的方法包括使用大量用户评论语料库扩展这些模型的预训练以提高上下文理解，并采用实例选择技术来优化模型微调。实证评估表明，该方法提高了提取特征的准确率和召回率，并提高了性能效率。主要贡献包括一种新颖的特征提取方法、带注释的数据集、扩展的预训练模型以及用于经济高效微调的实例选择机制。这项研究提供了将大型语言模型应用于移动应用评论中的自然语言处理任务的实用方法和经验证据，从而提高了特征提取的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.01063</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:27 GMT</pubDate>
    </item>
    <item>
      <title>用于处理噪声上下文的检索增强生成中的自适应对比解码</title>
      <link>https://arxiv.org/abs/2408.01084</link>
      <description><![CDATA[arXiv:2408.01084v1 公告类型：新 
摘要：在知识密集型任务（例如开放域问答）中使用大型语言模型 (LLM) 时，外部上下文可以弥合外部知识与 LLM 的参数知识之间的差距。最近的研究已经发展到使用对比解码方法放大 LLM 的参数知识上的上下文知识。虽然这些方法在提供相关上下文时可以产生真实的响应，但它们在面对嘈杂的上下文时容易出现漏洞。我们扩展了以前研究的范围以涵盖嘈杂的上下文，并提出了自适应对比解码 (ACD) 来有效利用上下文影响。与基线相比，ACD 在开放域问答任务中表现出改进，尤其是在稳健性方面，因为它在检索增强生成中不受嘈杂上下文的干扰。]]></description>
      <guid>https://arxiv.org/abs/2408.01084</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:27 GMT</pubDate>
    </item>
    <item>
      <title>从自然语言文本中自动提取动机、情感和行动之间的关系</title>
      <link>https://arxiv.org/abs/2408.00966</link>
      <description><![CDATA[arXiv:2408.00966v1 公告类型：新
摘要：我们提出了一种新的基于图的框架，以揭示自然语言文本中明确给出的动机、情感和行为之间的关系。设计了一个有向无环图来描述人性。养育信念被纳入其中，以连接外部事件和人性图。由于大型语言模型的强大功能，因此不需要注释资源。亚马逊精美食品评论数据集被用作语料库，并重点关注与食物相关的动机。总共生成了 92,990 个关系图，其中 63% 符合逻辑。我们进行了进一步分析，以调查错误类型，以便在未来的研究中进行优化方向。]]></description>
      <guid>https://arxiv.org/abs/2408.00966</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:26 GMT</pubDate>
    </item>
    <item>
      <title>通过图匹配实现跨域命名实体识别</title>
      <link>https://arxiv.org/abs/2408.00981</link>
      <description><![CDATA[arXiv:2408.00981v1 公告类型：新
摘要：由于现实场景中数据稀缺，跨域 NER 是一个实际而又具有挑战性的问题。一种常见的做法是首先在资源丰富的一般领域中学习 NER 模型，然后将模型调整到特定领域。由于跨领域实体类型不匹配的问题，一般领域的广泛知识无法有效地转移到目标域 NER 模型。为此，我们将标签关系建模为概率分布，并在源和目标标签空间中构建标签图。为了增强标签结构的上下文表示，我们将标签图融合到 BERT 输出的词嵌入中。通过将标签关系表示为图，我们将跨域 NER 公式化为图匹配问题。此外，所提出的方法与预训练方法具有良好的适用性，并且可能能够完成其他跨域预测任务。在四个数据集上进行的实证结果表明，我们的方法优于一系列迁移学习、多任务学习和小样本学习方法。]]></description>
      <guid>https://arxiv.org/abs/2408.00981</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:26 GMT</pubDate>
    </item>
    <item>
      <title>三小时内实现大型语言模型的公平性</title>
      <link>https://arxiv.org/abs/2408.00992</link>
      <description><![CDATA[arXiv:2408.00992v1 公告类型：新
摘要：大型语言模型 (LLM) 在各个领域都取得了显著的成功，但往往缺乏公平性考虑，可能导致对边缘化人群的歧视性结果。与传统机器学习中的公平性不同，LLM 中的公平性涉及独特的背景、分类法和实现技术。本教程系统地概述了有关公平 LLM 的文献中的最新进展，首先介绍现实世界的案例研究以介绍 LLM，然后分析其中的偏见原因。然后探讨 LLM 中的公平性概念，总结评估偏见的策略和旨在促进公平的算法。此外，还汇编了用于评估 LLM 中偏见的资源，包括工具包和数据集，并讨论了该领域当前的研究挑战和未解决的问题。存储库可在 \url{https://github.com/LavinWong/Fairness-in-Large-Language-Models} 处找到。]]></description>
      <guid>https://arxiv.org/abs/2408.00992</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:26 GMT</pubDate>
    </item>
    <item>
      <title>UniMoT：具有离散标记表示的统一分子文本语言模型</title>
      <link>https://arxiv.org/abs/2408.00863</link>
      <description><![CDATA[arXiv:2408.00863v1 公告类型：新
摘要：大型语言模型 (LLM) 在不同任务中取得了显著成功，这促使研究界将其功能扩展到分子应用。然而，大多数分子 LLM 采用基于适配器的架构，这些架构不能平等对待分子和文本模态，并且缺乏对分子模态的监督信号。为了解决这些问题，我们推出了 UniMoT，这是一种统一的分子文本 LLM，采用基于标记器的架构，使用分子标记扩展了 LLM 的词汇表。具体来说，我们引入了一个矢量量化驱动的标记器，它结合了 Q-Former 来弥合分子和文本之间的模态差距。这个标记器将分子转换成具有因果依赖性的分子标记序列，封装了高级分子和文本信息。配备此标记器后，UniMoT 可以在共享标记表示和自回归训练范式下统一分子和文本模态，使其能够将分子解释为外语并将其生成为文本。经过四阶段训练方案后，UniMoT 成为能够执行分子到文本和文本到分子任务的多模态通才。大量实验表明，UniMoT 在广泛的分子理解和生成任务中均实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.00863</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:25 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型 (LLM) 进行城市路口交通管理：混合交通场景案例</title>
      <link>https://arxiv.org/abs/2408.00948</link>
      <description><![CDATA[arXiv:2408.00948v1 公告类型：新 
摘要：由于环境的动态变化，城市交通管理面临重大挑战，传统算法无法实时快速适应这种环境并预测可能发生的冲突。本研究探讨了大型语言模型 (LLM)，特别是 GPT-4o-mini 在改善城市交叉路口交通管理方面的能力。我们招募了 GPT-4o-mini 来实时分析、预测位置、检测和解决各种基本场景中的交叉路口冲突。本研究的主要发现是调查 LLM 是否能够逻辑地推理和理解场景，从而通过提供实时分析来提高交通效率和安全性。该研究强调了 LLM 在城市交通管理中的潜力，从而创建更智能、更具适应性的系统。结果表明，GPT-4o-mini 能够有效地检测和解决交通拥堵和混合速度条件下的冲突。在有障碍物和行人的多个交叉路口的复杂场景中，冲突管理也取得了成功。结果表明，LLM 的整合有望提高交通管制的有效性，从而实现更安全、更高效的城市交叉路口管理。]]></description>
      <guid>https://arxiv.org/abs/2408.00948</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:25 GMT</pubDate>
    </item>
    <item>
      <title>PERSOMA：个性化语言提示的个性化SOft ProMpt适配器架构</title>
      <link>https://arxiv.org/abs/2408.00960</link>
      <description><![CDATA[arXiv:2408.00960v1 公告类型：新
摘要：了解用户大量交互历史的细微差别是构建准确且个性化的自然语言系统的关键，该系统可以适应不断变化的用户偏好。为了解决这个问题，我们引入了个性化软提示适配器架构 PERSOMA。与以前针对大型语言模型的个性化提示方法不同，PERSOMA 提供了一种新颖的方法来有效地捕获用户历史记录。它通过将交互作为自由格式文本重新采样和压缩为富有表现力的软提示嵌入来实现这一点，这是在最近利用嵌入表示作为 LLM 输入的研究基础上建立的。我们通过评估各种适配器架构、第一阶段采样策略、参数高效的调整技术（如 LoRA）和其他个性化方法来严格验证我们的方法。我们的结果表明，与现有的基于嵌入和基于文本提示的技术相比，PERSOMA 具有处理大型和复杂用户历史记录的卓越能力。]]></description>
      <guid>https://arxiv.org/abs/2408.00960</guid>
      <pubDate>Mon, 05 Aug 2024 09:16:25 GMT</pubDate>
    </item>
    </channel>
</rss>