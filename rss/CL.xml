<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 21 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过理论提炼提升法学硕士翻译技能，同时不影响一般能力</title>
      <link>https://arxiv.org/abs/2410.13944</link>
      <description><![CDATA[arXiv:2410.13944v1 公告类型：新
摘要：大型语言模型 (LLM) 在众多 NLP 任务中取得了令人瞩目的成果，但在机器翻译中仍然遇到困难。传统的改进翻译的方法通常涉及使用平行语料库对 LLM 进行微调。然而，普通的微调往往会导致灾难性地忘记指令遵循能力和与人类偏好的一致性，损害其广泛的一般能力并引入潜在的安全风险。这些能力是使用专有和不可用的训练数据开发的，使现有的持续指令调整方法无效。为了解决这个问题，我们提出了一种称为 RaDis（理性蒸馏）的新方法。RaDis 利用 LLM 强大的生成能力来创建训练数据的原理，然后“重放”以防止遗忘。这些原理包含一般知识和安全原则，作为自我蒸馏目标来规范训练过程。通过对参考翻译和自生成原理进行联合训练，该模型可以学习新的翻译技能，同时保留其整体通用能力。大量实验表明，我们的方法提高了机器翻译性能，同时保持了 LLM 在其他任务中的更广泛功能。这项工作提出了一种创建更通用的 LLM 的方法，这些 LLM 在专业任务中表现出色，同时又不损害通用性和安全性。]]></description>
      <guid>https://arxiv.org/abs/2410.13944</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从单一到多重：法学硕士如何在多文档摘要中产生幻觉</title>
      <link>https://arxiv.org/abs/2410.13961</link>
      <description><![CDATA[arXiv:2410.13961v1 公告类型：新
摘要：尽管许多研究已经调查并减少了单文档任务的大型语言模型 (LLM) 中的幻觉，但对多文档摘要 (MDS) 任务中的幻觉的研究仍然很大程度上尚未探索。具体而言，尚不清楚处理多个文档（例如，信息的重复和多样性）所带来的挑战如何影响模型输出。在这项工作中，我们研究了在从多个文档中总结特定主题的信息时幻觉如何在 LLM 中表现出来。由于没有用于调查 MDS 中幻觉的基准，我们使用现有的新闻和对话数据集（注释了特定主题的见解）来创建两个新的多文档基准。当在我们的基准上评估 5 个 LLM 时，我们观察到平均而言，LLM 生成的摘要中高达 75% 的内容是幻觉，幻觉更有可能出现在摘要的末尾。此外，在总结不存在的主题相关信息时，GPT-3.5-turbo 和 GPT-4o 仍会在大约 79.35% 和 44% 的时间内生成摘要，这引发了人们对它们捏造内容倾向的担忧。为了了解这些幻觉的特征，我们手动评估了 700 多个见解，发现大多数错误源于未能遵循说明或产生过于笼统的见解。受这些观察的启发，我们研究了简单的事后基线在缓解幻觉方面的有效性，但发现它们的效果一般。我们的结果强调需要更有效的方法来系统地缓解 MDS 中的幻觉。我们在 github.com/megagonlabs/Hallucination_MDS 发布了我们的数据集和代码。]]></description>
      <guid>https://arxiv.org/abs/2410.13961</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>检测跨域 AI 生成的文本</title>
      <link>https://arxiv.org/abs/2410.13966</link>
      <description><![CDATA[arXiv:2410.13966v1 公告类型：新 
摘要：现有的用于检测由大型语言模型 (LLM) 生成的文本的工具取得了一定的成功，但在处理新领域的文本时，它们的性能可能会下降。为了解决这个问题，我们使用我们构建的数据集训练了一个名为 RoBERTa-Ranker 的排名分类器（RoBERTa 的修改版本），作为基线模型，该数据集包含由各种 LLM 生成的由人类编写的更多种类的文本。然后，我们提出了一种微调 RoBERTa-Ranker 的方法，该方法只需要新领域中少量的标记数据。实验表明，这种微调的领域感知模型在域内和跨域文本上的表现都优于流行的 DetectGPT 和 GPTZero，其中 AI 生成的文本可能位于不同的域中，或者由未用于生成训练数据集的不同 LLM 生成。这种方法使得构建一个用于检测各个领域的 AI 生成的文本的单一系统变得可行且经济。]]></description>
      <guid>https://arxiv.org/abs/2410.13966</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 是分布语义学的模型吗？以量词为例</title>
      <link>https://arxiv.org/abs/2410.13984</link>
      <description><![CDATA[arXiv:2410.13984v1 公告类型：新
摘要：分布式语义学是一种语言理论，认为一个词的含义可以从其在自然语言中的分布（即其使用）中得出。语言模型通常被视为分布式语义学的一种实现，因为它们经过优化，可以捕捉自然语言的统计特征。人们经常认为，分布式语义模型应该擅长根据语言惯例捕捉分级/模糊含义，但在真值条件推理和符号处理方面却举步维艰。我们通过对模糊（例如“许多”）和精确（例如“一半以上”）量词的案例研究来评估这一说法。与预期相反，我们发现，在各种类型的广泛模型中，LLM 与人类对精确量词而非模糊量词的判断更为接近。这些发现要求重新评估分布式语义模型的假设以及它们可以捕获的内容。]]></description>
      <guid>https://arxiv.org/abs/2410.13984</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RiTeK：大型语言模型数据集，基于文本知识图谱的复杂推理</title>
      <link>https://arxiv.org/abs/2410.13987</link>
      <description><![CDATA[arXiv:2410.13987v1 公告类型：新
摘要：回答复杂的现实问题通常需要从文本知识图谱 (TKG) 中进行准确检索。注释数据的稀缺性以及复杂的拓扑结构使这项任务特别具有挑战性。由于关系路径信息的性质可以增强大型语言模型 (LLM) 的推理能力，因此从 TKG 中有效地检索更复杂的关系路径信息是另一个关键挑战。为了应对这些挑战，我们首先开发了一个具有广泛拓扑结构覆盖范围的 LLM 复杂推理文本知识图谱 (RiTeK) 数据集。我们合成了集成各种拓扑结构、关系信息和复杂文本描述的真实用户查询。我们进行严格的专家评估以验证我们合成查询的质量。然后，我们引入了一种增强的蒙特卡洛树搜索 (MCTS) 方法，即关系 MCTS，用于自动从文本图中提取特定查询的关系路径信息。我们的数据集主要涵盖医学领域，因为关系类型和实体很复杂且公开可用。实验结果表明，RiTeK 对当前的检索和 LLM 系统提出了重大挑战，而所提出的关系 MCTS 方法增强了 LLM 推理能力并在 RiTeK 上实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.13987</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士是有偏见的教师：评估个性化教育中的法学硕士偏见</title>
      <link>https://arxiv.org/abs/2410.14012</link>
      <description><![CDATA[arXiv:2410.14012v1 公告类型：新
摘要：随着大型语言模型 (LLM) 在教育领域的应用越来越广泛，人们对这些模型固有偏见的担忧也日益突出。我们在个性化教育环境中评估 LLM 的偏见，特别关注模型作为“教师”的角色。我们揭示了模型在生成和选择针对不同人口群体的教育内容方面存在显著偏见，包括种族、民族、性别、残疾状况、收入和国籍。我们引入并应用了两个偏见分数指标——平均绝对偏差 (MAB) 和最大差异偏差 (MDB)——来分析 9 个开放和封闭的最先进的 LLM。我们的实验利用了 17,000 多个教育解释，涵盖多个难度级别和主题，发现模型延续了典型和颠倒的有害刻板印象。]]></description>
      <guid>https://arxiv.org/abs/2410.14012</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在大规模对话系统中生成手语指令</title>
      <link>https://arxiv.org/abs/2410.14026</link>
      <description><![CDATA[arXiv:2410.14026v1 公告类型：新
摘要：我们推出了一个以目标为导向的对话式 AI 系统，该系统通过美国手语 (ASL) 指令进行了增强，这是该系统在全球多模式对话式 AI 平台上的首次实现。我们的系统可通过触摸式界面访问，接收用户的输入，并通过利用检索方法和基于认知的注释翻译无缝生成 ASL 指令。我们设计的核心是一个由大型语言模型提供支持的手语翻译模块，以及一个基于 token 的视频检索系统，用于提供来自食谱和 wikiHow 指南的教学内容。我们的开发过程深深植根于对社区参与的承诺，融合了聋人和听力障碍社区以及认知和 ASL 学习科学专家的见解。我们的手语指令的有效性得到了用户反馈的验证，其评级与非手语版本的系统相当。此外，我们的系统在检索准确度和文本生成质量方面表现出色，这些指标包括 BERTScore。我们已在 https://github.com/Merterm/signed-dialogue 上公开了我们的代码库和数据集，我们的手语教学视频检索系统的演示可在 https://huggingface.co/spaces/merterm/signed-instructions 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.14026</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 GPT-4 测量和修改英文文本的可读性</title>
      <link>https://arxiv.org/abs/2410.14028</link>
      <description><![CDATA[arXiv:2410.14028v1 公告类型：新 
摘要：大型语言模型 (LLM) 在其他领域的成功提出了一个问题：LLM 是否能够可靠地评估和操纵文本的可读性。我们从实证的角度来解决这个问题。首先，使用已发布的 4,724 段英文文本摘录语料库，我们发现 GPT-4 Turbo 和 GPT-4o mini 产生的“零样本”可读性估计与人类判断具有相对较高的相关性（分别为 r = 0.76 和 r = 0.74），优于从传统可读性公式和各种心理语言学指数得出的估计值。然后，在一项预先注册的人类实验（N = 59）中，我们询问 Turbo 是否可以可靠地使文本更容易或更难阅读。我们找到了支持这一假设的证据，尽管人类判断的巨大差异仍无法解释。最后，我们讨论了这种方法的局限性，包括有限的范围，以及“可读性”构造的有效性及其对背景、受众和目标的依赖。]]></description>
      <guid>https://arxiv.org/abs/2410.14028</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Style-Compress：基于 LLM 的即时压缩框架，考虑任务特定风格</title>
      <link>https://arxiv.org/abs/2410.14042</link>
      <description><![CDATA[arXiv:2410.14042v1 公告类型：新
摘要：提示压缩可以在保持上下文信息量的同时，压缩上下文以适应不同的使用场景。它不仅可以缩短大型语言模型使用过程中的推理时间并降低计算成本，还可以降低使用闭源模型时的费用。在一项初步研究中，我们发现，在指示语言模型压缩提示时，不同的压缩风格（例如，提取或抽象）会影响压缩提示在下游任务上的性能。基于这一见解，我们提出了 Style-Compress，这是一个轻量级框架，它使较小的语言模型能够在无需额外训练的情况下，将提示压缩到新任务上较大模型的提示。我们的方法通过风格变化和上下文学习迭代生成和选择有效的压缩提示作为特定于任务的演示，使较小的模型能够作为具有特定于任务的示例的高效压缩器。Style-Compress 在四个任务中的表现优于两个基线压缩模型：原始提示重建、文本摘要、多跳 QA 和 CoT 推理。此外，仅使用 10 个样本和 100 个查询进行适配，经过 Style-Compress 压缩的提示在压缩率为 0.25 或 0.5 的情况下达到与原始提示相当或更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.14042</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从文本描述中有效检索时间事件序列</title>
      <link>https://arxiv.org/abs/2410.14043</link>
      <description><![CDATA[arXiv:2410.14043v1 公告类型：新
摘要：从文本描述中检索时间事件序列对于分析电子商务行为、监控社交媒体活动和跟踪犯罪事件等应用至关重要。在本文中，我们介绍了 TPP-LLM-Embedding，这是一种基于自然语言描述有效嵌入和检索事件序列的统一模型。我们的模型建立在 TPP-LLM 框架之上，该框架将大型语言模型与时间点过程相结合，对事件类型和时间进行编码，通过池化生成序列级表示。文本描述使用相同的架构嵌入，确保序列和描述共享嵌入空间。我们根据这些嵌入之间的相似性优化对比损失，使匹配对更接近并分离不匹配对。TPP-LLM-Embedding 能够实现高效检索，并且与跨不同数据集的基线模型相比表现出卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.14043</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习元数据无关的文本到 SQL 上下文示例选择表示</title>
      <link>https://arxiv.org/abs/2410.14049</link>
      <description><![CDATA[arXiv:2410.14049v1 公告类型：新
摘要：上下文学习 (ICL) 是一种强大的范例，其中大型语言模型 (LLM) 受益于添加到提示中的任务演示。然而，选择最佳演示并非易事，尤其是对于输入和输出分布不同的复杂或多模态任务。我们假设形成输入的任务特定表示是关键。在本文中，我们提出了一种在共享嵌入空间中对齐自然语言问题和 SQL 查询表示的方法。我们的技术被称为 MARLO - 元数据无关的文本到 SQL 表示学习 - 使用查询结构来模拟查询意图，而无需对底层数据库元数据（即问题或查询中引用的数据库的表、列或域特定实体）进行过度索引。这使得 MARLO 能够选择在结构和语义上与任务相关的示例，而不是与某个领域或问题措辞虚假相关的示例。当用于根据问题相似性检索示例时，MARLO 在 Spider 基准上表现出比通用嵌入模型（执行准确率平均高出 2.9%pt）更出色的性能。它还比下一个最佳方法（屏蔽元数据信息）的平均执行准确率高出 0.8%pt，同时显著降低了推理延迟。]]></description>
      <guid>https://arxiv.org/abs/2410.14049</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习儿童不确定性的多模态线索</title>
      <link>https://arxiv.org/abs/2410.14050</link>
      <description><![CDATA[arXiv:2410.14050v1 公告类型：新
摘要：理解不确定性在达成共识方面起着关键作用（Clark 等人，1983 年）。这对于与用户协作解决问题或指导用户完成具有挑战性的概念的多模态 AI 系统尤其重要。在这项工作中，我们首次与发展和认知心理学家合作提供了一个注释的数据集，目的是研究不确定性的非语言线索。然后，我们对数据进行了分析，研究了不确定性的不同作用及其与任务难度和绩效的关系。最后，我们提出了一个多模态机器学习模型，该模型可以根据参与者的实时视频片段预测不确定性，我们发现该模型改进了基线多模态变换器模型。这项工作为人与人、人与人工智能之间的认知协调研究提供了信息，并对手势理解和生成具有广泛的影响。我们的数据和代码的匿名版本将在完成所需的同意书和数据表后公开。]]></description>
      <guid>https://arxiv.org/abs/2410.14050</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从孤立对话到分层模式：LLM 的动态树内存表示</title>
      <link>https://arxiv.org/abs/2410.14052</link>
      <description><![CDATA[arXiv:2410.14052v1 公告类型：新
摘要：大型语言模型的最新进展显著改善了它们的上下文窗口，但有效的长期记忆管理仍然存在挑战。我们引入了 MemTree，这是一种利用动态树状结构记忆表示来优化信息组织、检索和集成的算法，类似于人类的认知模式。MemTree 按层次结构组织记忆，每个节点都封装聚合的文本内容、相应的语义嵌入和树深度上不同的抽象级别。我们的算法通过计算和比较新信息和现有信息的语义嵌入来动态调整这种记忆结构，以丰富模型的上下文感知。这种方法使 MemTree 能够比传统的记忆增强方法更有效地处理复杂的推理和扩展的交互，而传统的记忆增强方法通常依赖于平面查找表。对多轮对话理解和文档问答基准的评估表明，MemTree 在需要结构化内存管理的场景中显著提高了性能。]]></description>
      <guid>https://arxiv.org/abs/2410.14052</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于多语言知识图谱的检索增强生成跨文化机器翻译</title>
      <link>https://arxiv.org/abs/2410.14057</link>
      <description><![CDATA[arXiv:2410.14057v1 公告类型：新
摘要：翻译包含实体名称的文本是一项艰巨的任务，因为与文化相关的参考在不同语言中可能存在很大差异。这些差异也可能是由创译引起的，创译是一种适应过程，它涉及的不仅仅是音译和逐字翻译。在本文中，我们从两个方面解决跨文化翻译问题：（i）我们引入了 XC-Translate，这是第一个大规模、手动创建的机器翻译基准，重点关注包含潜在文化细微差别的实体名称的文本；（ii）我们提出了 KG-MT，这是一种新颖的端到端方法，通过利用密集检索机制将多语言知识图谱中的信息集成到神经机器翻译模型中。我们的实验和分析表明，当前的机器翻译系统和大型语言模型在翻译包含实体名称的文本时仍然遇到困难，而 KG-MT 的表现远远优于最先进的方法，与 NLLB-200 和 GPT-4 相比分别获得了 129% 和 62% 的相对改进。]]></description>
      <guid>https://arxiv.org/abs/2410.14057</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>成为我的捐赠者。使用 LLM 在语言之间传输 NLP 数据集</title>
      <link>https://arxiv.org/abs/2410.14074</link>
      <description><![CDATA[arXiv:2410.14074v1 公告类型：新
摘要：在这项工作中，我们研究了如何使用 LLM 将数据集及其注释从一种语言转移到另一种语言。这至关重要，因为在不同语言之间共享知识可以促进目标语言中某些资源不足的方向，从而节省大量数据注释或快速原型设计的工作。我们尝试用英语和俄语对翻译 DEFT 语料库。该语料库包含三层注释，专门用于术语定义对挖掘，这是俄语中罕见的注释类型。我们使用 ChatGPT3.5-turbo 和 Llama-3.1-8b 作为核心 LLM 为注释传输提供管道。最后，我们在翻译的数据集上训练基于 BERT 的模型以建立基线。]]></description>
      <guid>https://arxiv.org/abs/2410.14074</guid>
      <pubDate>Mon, 21 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>