<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Fri, 26 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>WorldValuesBench：语言模型多文化价值意识的大规模基准数据集</title>
      <link>https://arxiv.org/abs/2404.16308</link>
      <description><![CDATA[arXiv:2404.16308v1 公告类型：新
摘要：对多元文化人类价值观的认识对于语言模型（LM）生成安全和个性化响应的能力至关重要。然而，由于计算机科学界缺乏有关多元文化价值观的大规模现实世界数据，因此对 LM 的这种意识尚未得到充分研究。在本文中，我们提出了 WorldValuesBench，这是一个用于多元文化价值预测任务的全球多样化的大规模基准数据集，它需要一个模型根据人口统计背景生成对价值问题的评级响应。我们的数据集源自一个有影响力的社会科学项目——世界价值观调查 (WVS)，该项目从全球 94,728 名参与者那里收集了数百个价值观问题（例如社会、经济、道德）的答案。我们从 WVS 响应中构建了超过 2000 万个“（人口统计属性，价值问题）$\rightarrow$ 答案”类型的示例。我们使用我们的数据集进行了案例研究，结果表明该任务对于强大的开源和闭源模型来说具有挑战性。仅涉及 $11.1\%$、$25.0\%$、$72.2\%$ 和 $75.0\%$ 的问题、Alpaca-7B、Vicuna-7B-v1.5、Mixtral-8x7B-Instruct-v0.1 和 GPT -3.5 Turbo 可以分别实现与人类标准化答案分布的 $&lt;0.2$ Wasserstein 1 距离。 WorldValuesBench 为研究 LM 多元文化价值意识的局限性和机遇开辟了新的研究途径。]]></description>
      <guid>https://arxiv.org/abs/2404.16308</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>PILA：原始意大利语和拉丁语的历史语言数据集</title>
      <link>https://arxiv.org/abs/2404.16341</link>
      <description><![CDATA[arXiv:2404.16341v1 公告类型：新
摘要：计算历史语言学试图系统地理解声音变化的过程，包括在几乎没有或没有正式的语言记录得到证实的时期。与此同时，很少有计算资源可以深入探索原始语言及其后代之间的语音和形态联系。对于斜体语言族来说尤其如此。为了帮助历史语言学家研究斜体语音变化，我们引入了原始斜体到拉丁语 (PILA) 数据集，该数据集包含大约 3,000 对原始斜体和拉丁语的形式。我们提供了如何创建和组织数据集的详细描述。然后，我们通过两种方式展现PILA的价值。首先，我们展示 PILA 在一对传统计算历史语言学任务上的基线结果。其次，我们展示了 PILA 通过数据集兼容性研究增强其他历史语言数据集的能力。]]></description>
      <guid>https://arxiv.org/abs/2404.16341</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>从多个领域解释对话中是非问题的答案</title>
      <link>https://arxiv.org/abs/2404.16262</link>
      <description><![CDATA[arXiv:2404.16262v1 公告类型：新
摘要：人们经常在回答是非问题时不明确地说是、否或类似的极性关键词。即使对于大型语言模型来说，弄清楚间接答案的含义也具有挑战性。在本文中，我们通过来自多个领域的对话来研究这个问题。我们在三个不同的领域提出了新的基准：电影剧本、网球采访和航空公司客户服务。我们提出了一种基于远程监督和混合训练的方法，以快速适应新的对话领域。实验结果表明，我们的方法绝不会有害，并且 F1 改进高达 11-34%。]]></description>
      <guid>https://arxiv.org/abs/2404.16262</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 的部分标识符在开源方面表现出色，但在实际应用中却表现不佳</title>
      <link>https://arxiv.org/abs/2404.16294</link>
      <description><![CDATA[arXiv:2404.16294v1 公告类型：新
摘要：电子健康记录（EHR）尽管对医疗保健从业者来说是一个福音，但每天都变得越来越复杂和更长。筛选这些冗长的电子病历非常费力，并且成为医患互动中的一个麻烦部分。人们提出了几种方法来通过总结或分段来帮助缓解这一普遍问题，但是，过去只有少数方法真正有用。随着自动化方法的兴起，机器学习 (ML) 在解决识别 EHR 中相关部分的任务方面显示出了希望。然而，大多数机器学习方法都依赖于标记数据，而这在医疗保健领域很难获得。另一方面，大型语言模型（LLM）在自然语言处理（NLP）方面也取得了令人印象深刻的成就，而且也是以零样本的方式，即没有任何标记数据。为此，我们建议使用法学硕士来识别相关的章节标题。我们发现 GPT-4 可以有效地解决零样本和少样本设置下的任务，并且分割效果比最先进的方法要好得多。此外，我们还注释了一个更难的现实世界数据集，发现 GPT-4 很难​​表现良好，这暗示着进一步的研究和更难的基准测试。]]></description>
      <guid>https://arxiv.org/abs/2404.16294</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>Semgrex 和 Ssurgeon，搜索和操作依赖关系图</title>
      <link>https://arxiv.org/abs/2404.16250</link>
      <description><![CDATA[arXiv:2404.16250v1 公告类型：新
摘要：搜索依赖图并对其进行操作可能是一项耗时且具有挑战性的任务。我们记录了 Semgrex，一个用于搜索依赖图的系统，并介绍了 Ssurgeon，一个用于操作 Semgrex 输出的系统。这些系统使用的紧凑语言可以轻松地通过命令行或 API 处理依赖项。此外，与 Java 和 Python 中公开发布的工具包集成允许在自然文本上搜索文本关系和属性。]]></description>
      <guid>https://arxiv.org/abs/2404.16250</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>无需重新训练机器翻译系统即可翻译多方面数据</title>
      <link>https://arxiv.org/abs/2404.16257</link>
      <description><![CDATA[arXiv:2404.16257v1 公告类型：新
摘要：翻译大语种资源构建小语种资源成为一种广泛使用的方法。特别是在翻译由多个组件组成的复杂数据点时，通常单独翻译每个组件。然而，我们认为这种做法经常忽视同一数据点内组件之间的相互关系。为了解决这一限制，我们提出了一种新颖的 MT 管道，该管道在对训练数据实施 MT 时考虑了数据内关系。在我们的 MT 管道中，数据点中的所有组件都连接起来形成单个翻译序列，并随后在翻译后重建为数据组件。我们引入了 Catalyst Statement (CS) 来增强数据内关系，并引入 Indicator Token (IT) 来帮助将翻译序列分解为其各自的数据组件。通过我们的方法，我们在翻译质量本身及其作为训练数据的有效性方面取得了相当大的进步。与单独翻译每个数据分量的传统方法相比，我们的方法产生了更好的训练数据，使训练后的模型在网页排名（WPR）任务中的性能提高了 2.690 分，在问题生成（QG）任务中提高了 0.845 分。 XGLUE 基准测试。]]></description>
      <guid>https://arxiv.org/abs/2404.16257</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>实现临床试验的高效患者招募：基于提示的学习模型的应用</title>
      <link>https://arxiv.org/abs/2404.16198</link>
      <description><![CDATA[arXiv:2404.16198v1 公告类型：新
摘要：目的：临床试验对于推进药物干预至关重要，但在选择合格参与者方面面临瓶颈。尽管利用电子健康记录 (EHR) 进行招募已广受欢迎，但非结构化医疗文本的复杂性给有效识别参与者带来了挑战。自然语言处理（NLP）技术已经作为一种解决方案出现，最近的重点是变压器模型。在本研究中，我们的目的是评估基于提示的大语言模型在从 EHR 中收集的非结构化医疗记录中进行队列选择任务时的性能。方法：为了处理医疗记录，我们选择了与试验所需的资格标准最相关的记录句子。收集了与每个资格标准相关的 SNOMED CT 概念。医疗记录还使用基于 SNOMED CT 本体的 MedCAT 进行了注释。提取包含与标准相关术语匹配的概念的注释句子。然后使用基于提示的大语言模型（本研究中的生成预训练变压器（GPT））和提取的句子作为训练集。为了评估其有效性，我们使用 2018 年 n2c2 挑战赛的数据集评估了模型的性能，该挑战赛旨在通过 NLP 技术根据 13 项资格标准对 311 名患者的医疗记录进行分类。结果：我们提出的模型显示总体微观和宏观 F 测量值分别为 0.9061 和 0.8060，这是使用该数据集进行的实验取得的最高分数之一。结论：本研究中应用基于提示的大语言模型根据资格标准对患者进行分类，获得了有希望的分数。此外，我们提出了一种借助 SNOMED CT 本体的提取摘要方法，该方法也可以应用于其他医学文本。]]></description>
      <guid>https://arxiv.org/abs/2404.16198</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>疼痛语言的计算分析：系统评价</title>
      <link>https://arxiv.org/abs/2404.16226</link>
      <description><![CDATA[arXiv:2404.16226v1 公告类型：新
摘要：目的：本研究旨在系统地回顾有关疼痛语言计算处理的文献，无论是由患者还是医生生成的，以确定当前的趋势和挑战。方法：遵循 PRISMA 指南，进行全面的文献检索，选择有关疼痛语言计算处理的相关研究，并回答预先定义的研究问题。进行数据提取和合成，根据选定的研究的主要目的和结果、患者和疼痛人群、文本数据、计算方法和结果目标对它们进行分类。结果：医生生成的疼痛语言，特别是来自临床记录的疼痛语言，是最常用的数据。任务包括患者诊断和分类、疼痛提及的识别、治疗反应预测、生物医学实体提取、语言特征与临床状态的相关性以及疼痛叙述的词汇语义分析。只有一项研究在其实验设置中包含了先前有关疼痛言语的语言知识。大多数研究的目标是为医生提供结果，要么直接作为临床工具，要么作为间接知识。临床疼痛护理最没有针对性的阶段是自我管理，其中患者参与最多。研究最少的疼痛维度是情感和社会文化。只有两项研究衡量了纳入所提出的算法后医生在临床任务上的表现如何得到改善。讨论：本研究发现，未来的研究应侧重于分析患者产生的疼痛语言，开发以患者为中心的自我管理和患者赋权资源，探索疼痛的情感和社会文化方面，以及衡量医生在以下方面的帮助下表现的改善：提议的工具。]]></description>
      <guid>https://arxiv.org/abs/2404.16226</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>URL：通过任务指令表示压缩进行通用参考知识链接</title>
      <link>https://arxiv.org/abs/2404.16248</link>
      <description><![CDATA[arXiv:2404.16248v1 公告类型：新
摘要：将主张与有依据的参考文献联系起来是满足人类对真实可靠信息需求的关键能力。目前的研究仅限于信息检索或语义匹配等特定任务，其中主张-参考关系是唯一且固定的，而现实世界中的参考知识链接（RKL）可能更加多样化和复杂。在本文中，我们提出了通用参考知识链接（URL），旨在通过一个统一的模型解决多样化的参考知识链接任务。为此，我们提出了一种LLM驱动的任务指令表示压缩以及多视图学习方法，以有效地将LLM的指令跟随和语义理解能力适应参考知识链接。此外，我们还构建了一个新的基准来评估模型在不同场景下的参考知识链接任务的能力。实验表明，通用 RKL 对现有方法具有挑战性，而所提出的框架可以有效地解决各种场景下的任务，因此大大优于以前的方法。]]></description>
      <guid>https://arxiv.org/abs/2404.16248</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>使用助手对心理治疗聊天机器人进行特定领域的改进</title>
      <link>https://arxiv.org/abs/2404.16160</link>
      <description><![CDATA[arXiv:2404.16160v1 公告类型：新
摘要：大型语言模型（LLM）在使用人工编写的指令数据的特定任务上表现出了令人印象深刻的泛化能力。然而，此类指导数据的数量、多样性和专业知识有限，引起了人们对法学硕士在接受特定领域指导时在心理治疗任务中表现的担忧。为了解决这个问题，我们首先提出基于AlexanderStreet疗法的特定领域辅助指令，其次，我们使用适应微调方法和检索增强生成方法来改进预训练的LLM。通过使用自动和人工评估对语言质量进行定量评估，我们观察到经过预训练的心理治疗辅助说明法学硕士的表现优于最先进的法学硕士反应基线。我们的助理教学方法提供了一种半注释方法，使预训练的法学硕士与指令保持一致，并为预训练的法学硕士提供更多的心理治疗知识。]]></description>
      <guid>https://arxiv.org/abs/2404.16160</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>对法学硕士事实知识回忆的整体评估</title>
      <link>https://arxiv.org/abs/2404.16164</link>
      <description><![CDATA[arXiv:2404.16164v1 公告类型：新
摘要：大型语言模型（LLM）在各种 NLP 任务上表现出了卓越的性能，并且正在广泛的用例中得到迅速采用。因此，全面评估其生成的结果的真实性至关重要，因为幻觉仍然是一个具有挑战性的问题。
  在这项工作中，我们重点评估法学硕士回忆从预训练中学到的事实知识的能力，以及影响这种能力的因素。为此，我们构建了 FACT-BENCH，一个涵盖 20 个领域、134 个属性类型、3 个答案类型和不同知识普及程度的代表性基准。我们对 10 个模型系列中的 31 个模型进行了基准测试，并对它们的优缺点进行了全面评估。我们观察到指令调整会损害知识回忆，因为仅预训练的模型始终优于指令调整的模型，并且模型缩放会产生积极影响，因为对于所有模型系列，较大的模型优于较小的模型。然而，GPT-4 的最佳性能仍然与上限有很大差距。我们还使用反事实演示来研究上下文样本的作用，这会导致大型模型的事实知识回忆显着下降。通过进一步解耦模型已知和未知知识，我们发现退化归因于与模型已知知识相矛盾的样本以及此类样本的数量。最后，我们在已知和未知知识的不同设置中对 LLaMA-7B 进行微调。特别是，对模型的已知知识进行微调是有益的，并且始终优于对未知和混合知识进行微调。我们将公开我们的基准。]]></description>
      <guid>https://arxiv.org/abs/2404.16164</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>用于医学视觉问答的领域自适应视觉和语言模型的融合</title>
      <link>https://arxiv.org/abs/2404.16192</link>
      <description><![CDATA[arXiv:2404.16192v1 公告类型：新
摘要：视觉语言模型虽然在一般领域有效，并且在视觉问答（VQA）等多种多模态应用中表现出强大的性能，但在更专业的领域（例如医学）中很难保持相同水平的有效性。我们提出了一种医学视觉语言模型，集成了适合医学领域的大视觉和语言模型。该模型使用三个独立的生物医学和放射学多模态视觉和文本数据集，经历了参数高效训练的三个阶段。所提出的模型在 SLAKE 1.0 医学 VQA (MedVQA) 数据集上实现了最先进的性能，总体准确率达到 87.5%，并且在另一个 MedVQA 数据集 VQA-RAD 上表现出强大的性能，总体准确率达到 73.2%。]]></description>
      <guid>https://arxiv.org/abs/2404.16192</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>对社交媒体中人工生成和人工智能生成的选举主张进行分类</title>
      <link>https://arxiv.org/abs/2404.16116</link>
      <description><![CDATA[arXiv:2404.16116v1 公告类型：新
摘要：政治是社交媒体平台上讨论的最流行的话题之一，特别是在主要选举周期期间，用户参与有关候选人和选举进程的对话。恶意行为者可能会利用这个机会传播错误信息，破坏对选举进程的信任。大型语言模型 (LLM) 的出现使恶意行为者能够以前所未有的规模生成错误信息，从而加剧了这一问题。人工智能 (AI) 生成的内容通常与真实的用户内容难以区分，引发了人们对社交网络信息完整性的担忧。在本文中，我们提出了一种新颖的分类法来描述与选举相关的主张。该分类法提供了一种分析与选举相关的索赔的工具，其中包含与管辖权、设备、流程和索赔性质相关的细粒度类别。我们引入了 ElectAI，这是一个新颖的基准数据集，由 9,900 条推文组成，每条推文都标记为人类或人工智能生成的。对于 AI 生成的推文，会指定生成它们的特定 LLM 变体。我们使用提议的分类法对 1,550 条推文的子集进行了注释，以捕获与选举相关的主张的特征。我们探索了法学硕士提取分类属性的能力，并使用 ElectAI 训练了各种机器学习模型，以区分人类和人工智能生成的帖子并识别特定的法学硕士变体。]]></description>
      <guid>https://arxiv.org/abs/2404.16116</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>从局部到全局：以查询为中心的摘要的图 RAG 方法</title>
      <link>https://arxiv.org/abs/2404.16130</link>
      <description><![CDATA[arXiv:2404.16130v1 公告类型：新
摘要：使用检索增强生成（RAG）从外部知识源检索相关信息使大型语言模型（LLM）能够回答有关私人和/或以前未见过的文档集合的问题。然而，RAG 在针对整个文本语料库的全局问题上失败了，例如“数据集中的主题是什么？”，因为这本质上是一个以查询为中心的摘要 (QFS) 任务，而不是一个显式检索任务。与此同时，先前的 QFS 方法无法扩展到典型 RAG 系统索引的文本数量。为了结合这些对比方法的优点，我们提出了一种在私有文本语料库上进行问答的 Graph RAG 方法，该方法可根据用户问题的普遍性和要索引的源文本的数量进行扩展。我们的方法使用 LLM 分两个阶段构建基于图的文本索引：首先从源文档导出实体知识图，然后为所有密切相关的实体组预先生成社区摘要。给定一个问题，每个社区摘要都用于生成部分响应，然后所有部分响应再次汇总为对用户的最终响应。对于 100 万个 token 范围内的数据集上的一类全局意义构建问题，我们表明 Graph RAG 在生成答案的全面性和多样性方面比原始 RAG 基线带来了实质性改进。基于全局和本地 Graph RAG 方法的实现即将在 https://aka.ms/graphrag 上发布。]]></description>
      <guid>https://arxiv.org/abs/2404.16130</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>使用神经强盗在线个性化白盒法学硕士生成</title>
      <link>https://arxiv.org/abs/2404.16115</link>
      <description><![CDATA[arXiv:2404.16115v1 公告类型：新
摘要：法学硕士个性化内容生成的出现提出了一个新的挑战：如何有效地调整文本以满足个人喜好，而又不产生为每个用户创建独特模型的不可持续需求。本研究引入了一种创新的在线方法，该方法采用神经强盗算法根据用户反馈动态优化软指令嵌入，从而增强白盒法学硕士开放式文本生成的个性化。通过对各种任务进行严格的实验，我们证明了相对于基准策略的显着性能改进。尤其是 NeuralTS，它极大地增强了个性化新闻标题的生成，在最佳 ROUGE 分数方面实现了高达 62.9% 的改进，并且与基线相比，LLM 代理评估提高了高达 2.76%。]]></description>
      <guid>https://arxiv.org/abs/2404.16115</guid>
      <pubDate>Fri, 26 Apr 2024 06:18:20 GMT</pubDate>
    </item>
    </channel>
</rss>