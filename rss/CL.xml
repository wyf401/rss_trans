<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 23 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>透过他们的眼睛看世界：评估视觉语言模型中的视觉视角</title>
      <link>https://arxiv.org/abs/2409.12969</link>
      <description><![CDATA[arXiv:2409.12969v1 公告类型：新
摘要：视觉换位思考 (VPT) 是一种理解他人观点的能力，它使个人能够预测他人的行为。例如，驾驶员可以通过评估行人所看到的内容来避免事故。人类通常在幼儿时期发展这种技能，但目前尚不清楚最近出现的视觉语言模型 (VLM) 是否具备这种能力。此外，随着这些模型越来越多地部署在现实世界中，了解它们如何执行 VPT 等细微任务变得至关重要。在本文中，我们引入了两个手动整理的数据集 Isle-Bricks 和 Isle-Dots 来测试 VPT 技能，并用它来评估 12 个常用的 VLM。在所有模型中，我们观察到当需要换位思考时性能会显著下降。此外，我们发现物体检测任务的性能与 VPT 任务的性能相关性很差，这表明现有的基准可能不足以理解这个问题。代码和数据集将在 https://sites.google.com/view/perspective-taking 上提供]]></description>
      <guid>https://arxiv.org/abs/2409.12969</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TACO-RL：通过强化学习实现任务感知快速压缩优化</title>
      <link>https://arxiv.org/abs/2409.13035</link>
      <description><![CDATA[arXiv:2409.13035v2 公告类型：新 
摘要：GPT-4 等大型语言模型 (LLM) 在各种应用中的日益普及导致实现最佳性能所需的提示大小激增，从而对计算效率带来挑战。提示压缩旨在通过最小化输入标记而不影响任务性能来降低推理成本。然而，现有的提示压缩技术要么依赖于信息熵等次优指标，要么将其建模为无法捕获特定于任务的信息的任务无关的标记分类问题。为了解决这些问题，我们提出了一种新颖而高效的基于强化学习 (RL) 的任务感知提示压缩方法。为了确保低延迟要求，我们利用现有的基于 Transformer 编码器的标记分类模型，同时使用轻量级 REINFORCE 算法通过特定于任务的奖励信号指导学习过程。我们在三个不同且具有挑战性的任务上评估了我们的方法的性能，包括文本摘要、问答和代码摘要。我们证明，与最先进的压缩技术相比，我们的 RL 引导压缩方法在这三种场景中将任务性能提高了 8% - 260%，同时满足相同的压缩率和延迟要求。]]></description>
      <guid>https://arxiv.org/abs/2409.13035</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM Surgery：大型语言模型中的高效知识忘却与编辑</title>
      <link>https://arxiv.org/abs/2409.13054</link>
      <description><![CDATA[arXiv:2409.13054v1 公告类型：新
摘要：大型语言模型 (LLM) 已经彻底改变了各个领域，但它们的实用性也面临着与预训练期间嵌入的过时或有问题的知识相关的重大挑战。本文解决了修改 LLM 以取消学习有问题和过时的信息，同时有效地整合新知识而无需从头开始重新训练的挑战。在这里，我们提出了 LLM Surgery，这是一个通过优化三组分目标函数来有效修改 LLM 行为的框架：(1) 对取消学习数据集（有问题和过时的信息）执行反向梯度，(2) 对更新数据集（新信息和更新信息）执行梯度下降，以及 (3) 最小化保留数据集（未更改文本的小子集）上的 KL 散度，确保预训练和修改后的模型输出之间的一致性。由于缺乏专门为我们的新任务量身定制的公开数据集，我们编制了一个新数据集和一个评估基准。使用 Llama2-7B，我们证明 LLM Surgery 可以在忘记集上实现显著的遗忘，在更新集上将准确率提高 20%，并在保留集上保持性能。]]></description>
      <guid>https://arxiv.org/abs/2409.13054</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>引导式个人资料生成通过 LLM 改善个性化</title>
      <link>https://arxiv.org/abs/2409.13093</link>
      <description><![CDATA[arXiv:2409.13093v1 公告类型：新
摘要：在现代商业系统中，包括推荐、排名和电子商务平台，有一种趋势是通过将个性化上下文作为输入纳入大型语言模型 (LLM) 来改善客户体验。然而，LLM 通常难以有效地解析和利用稀疏而复杂的个人背景，而无需额外的处理或上下文丰富，这凸显了对更复杂的上下文理解机制的需求。在这项工作中，我们提出了引导配置文件生成 (GPG)，这是一种旨在生成自然语言个人资料的通用方法。正如所观察到的，中间引导配置文件生成使 LLM 能够从个人背景中总结和提取重要、独特的特征，将其生成为简洁、描述性的句子，从而精确地根据个人的独特习惯和偏好更紧密地定制它们的生成。我们的实验结果表明，GPG 提高了 LLM 在不同任务中的个性化能力，例如，与直接向 LLM 提供原始个人背景相比，它在预测个人偏好方面的准确率提高了 37%。]]></description>
      <guid>https://arxiv.org/abs/2409.13093</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是优秀的论文评分工具吗？</title>
      <link>https://arxiv.org/abs/2409.13120</link>
      <description><![CDATA[arXiv:2409.13120v1 公告类型：新
摘要：我们评估大型语言模型 (LLM) 在评估论文质量方面的有效性，重点关注它们与人工评分的一致性。更准确地说，我们在自动论文评分 (AES) 任务中评估 ChatGPT 和 Llama，这是教育领域一项重要的自然语言处理 (NLP) 应用。我们考虑零样本和少量样本学习以及不同的提示方法。我们利用 ASAP 数据集（AES 任务的著名基准）将 LLM 提供的数字等级与人类评分者提供的分数进行比较。我们的研究表明，与人类评分者提供的分数相比，这两个 LLM 给出的分数通常较低；此外，这些分数与人类提供的分数没有很好的相关性。特别是，与 Llama 相比，ChatGPT 往往更严厉，与人类评估的偏差更大。我们还试验了之前 AES 方法常用的一系列论文特征，这些特征与长度、连接词和过渡词的使用以及可读性指标（包括拼写和语法错误的数量）有关。我们发现，一般来说，这些特征与人类或 LLM 分数没有很强的相关性。最后，我们报告了 Llama 3 的结果，正如预期的那样，这些结果总体上更好。总体而言，虽然 LLM 似乎不能充分替代人工评分，但我们的结果在某种程度上令人鼓舞，因为它们可以作为未来协助人类评分书面论文的工具。]]></description>
      <guid>https://arxiv.org/abs/2409.13120</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RRM：强大的奖励模型训练可减轻奖励黑客攻击</title>
      <link>https://arxiv.org/abs/2409.13156</link>
      <description><![CDATA[arXiv:2409.13156v1 公告类型：新
摘要：奖励模型 (RM) 在将大型语言模型 (LLM) 与人类偏好相结合方面发挥着关键作用。然而，传统的 RM 训练依赖于与特定提示相关的响应对，难以将提示驱动的偏好与提示无关的人工制品（例如响应长度和格式）区分开来。在这项工作中，我们揭示了当前 RM 训练方法的一个根本限制，即 RM 在确定偏好时无法有效区分上下文信号和不相关的人工制品。为了解决这个问题，我们引入了一个因果框架，它可以学习独立于这些人工制品的偏好，并提出了一种旨在消除它们的新型数据增强技术。大量实验表明，我们的方法成功地过滤掉了不良人工制品，从而产生了一个更强大的奖励模型 (RRM)。我们的 RRM 提高了在 Gemma-2-9b-it 上训练的成对奖励模型在 RewardBench 上的表现，准确率从 80.61% 提高到 84.15%。此外，我们使用 RM 和 RRM 训练了两个 DPO 策略，结果表明 RRM 显著增强了 DPO 对齐策略，将 MT-Bench 得分从 7.27 提高到 8.31，将 AlpacaEval-2 中长度控制的胜率从 33.46% 提高到 52.49%。]]></description>
      <guid>https://arxiv.org/abs/2409.13156</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>$\textit{SKIntern}$：内化符号知识，将更好的 CoT 功能提炼到小型语言模型中</title>
      <link>https://arxiv.org/abs/2409.13183</link>
      <description><![CDATA[arXiv:2409.13183v1 公告类型：新 
摘要：由于大型语言模型 (LLM) 的高计算需求和隐私问题，小型语言模型 (SLM) 引起了人们的关注。一些研究使用从 LLM 中提炼的思维链 (CoT) 数据对 SLM 进行微调，旨在增强其推理能力。此外，一些 CoT 提炼方法将外部符号知识引入生成过程，以提高 SLM 有限的知识记忆、推理能力和域外 (OOD) 泛化。然而，符号知识的引入会增加计算开销并引入潜在的噪音。在本文中，我们介绍了一种创新方法 $\textit{SKIntern}$，它使 SLM 能够通过渐进式微调过程逐渐内化符号知识和少量示例，并在课程学习下由预定义的线性衰减计划指导。通过高效地内化知识，$\textit{SKIntern}$ 减少了计算开销，并通过在推理过程中专注于问题来加快推理过程。它的表现比最先进的基线高出 5\%，同时在域内 (ID) 和域外 (OOD) 任务中，在广泛的 SLM 中将推理成本（以 FLOP 为衡量标准）降低了高达 $4\times$。我们的代码将在 \url{https://github.com/Xnhyacinth/SKIntern} 上提供。]]></description>
      <guid>https://arxiv.org/abs/2409.13183</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>经过调整的大型语言模型有助于糖尿病护理中的多项医疗任务</title>
      <link>https://arxiv.org/abs/2409.13191</link>
      <description><![CDATA[arXiv:2409.13191v1 公告类型：新
摘要：糖尿病是一种慢性疾病，对全球健康造成重大负担，优化糖尿病管理需要多方合作。大型语言模型 (LLM) 在各种医疗保健场景中都显示出良好的前景，但它们在各种糖尿病任务中的有效性仍未得到证实。在这项研究中，我们引入了一个框架来训练和验证糖尿病特定的 LLM。我们首先开发了一个全面的数据处理管道，其中包括数据收集、过滤、增强和细化。这种方法有助于从头开始创建高质量的糖尿病特定数据集和几个评估基准。利用收集到的训练数据集，我们对糖尿病特定的 LLM 系列进行了微调，与其他 LLM 相比，该系列在理解和处理各种糖尿病任务方面表现出最先进的能力。此外，临床研究表明我们的模型在糖尿病护理中的潜在应用，包括提供个性化医疗、协助医学教育和简化临床任务。总之，我们的研究引入了一个开发和评估糖尿病特定 LLM 系列的框架，并强调了其在面对不同最终用户时增强临床实践和提供个性化、数据驱动的糖尿病支持方面的潜力。代码通过 GitHub 提供，网址为 https://github.com/waltonfuture/Diabetica。]]></description>
      <guid>https://arxiv.org/abs/2409.13191</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索大型语言模型训练中局部 SGD 的缩放规律</title>
      <link>https://arxiv.org/abs/2409.13198</link>
      <description><![CDATA[arXiv:2409.13198v1 公告类型：新
摘要：本文研究了 LLM 训练中局部 SGD 的缩放规律，LLM 是一种分布式优化算法，有助于在松散连接的设备上进行训练。通过大量实验，我们表明，在给定等效模型参数、数据集和计算资源的情况下，局部 SGD 与传统方法相比取得了有竞争力的结果。此外，我们探索了局部 SGD 在各种实际场景中的应用，包括多集群设置和边缘计算环境。我们的研究结果阐明了有效的多集群 LLM 训练的必要条件，并研究了在 LLM 训练过程中利用边缘计算资源的潜力和局限性。这证明了它作为单个大集群训练的替代方案的可行性。]]></description>
      <guid>https://arxiv.org/abs/2409.13198</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CFSP：具有由粗到细激活信息的 LLM 高效结构化剪枝框架</title>
      <link>https://arxiv.org/abs/2409.13199</link>
      <description><![CDATA[arXiv:2409.13199v1 公告类型：新
摘要：大型语言模型 (LLM) 的庞大参数和计算开销对其实际应用提出了挑战。网络修剪通过删除冗余参数来针对非结构化或结构化稀疏性，最近已被用于 LLM 加速。现有的 LLM 修剪工作侧重于非结构化修剪，这通常需要特殊的硬件支持才能实现实际加速。相反，结构化修剪可以减少一般设备上的延迟。然而，有效地执行结构化修剪并保持性能仍然是一个挑战，特别是在高稀疏率下。为此，我们引入了一个高效的结构化修剪框架 CFSP，它利用粗粒度（块间）和细粒度（块内）激活信息作为指导修剪的重要性标准。修剪非常高效，因为它只需要一次前向传递来计算特征激活。具体来说，我们首先根据块的重要性在块之间分配稀疏度预算，然后保留每个块内的重要权重。此外，我们引入了一种恢复微调策略，该策略根据粗粒度重要性自适应地分配训练开销，以进一步提高性能。实验结果表明，CFSP 在各种稀疏度预算的各种模型上的表现均优于现有方法。我们的代码将在 https://github.com/wyxscir/CFSP 上提供。]]></description>
      <guid>https://arxiv.org/abs/2409.13199</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CITI：在不牺牲整体性能的情况下增强大型语言模型的工具利用能力</title>
      <link>https://arxiv.org/abs/2409.13202</link>
      <description><![CDATA[arXiv:2409.13202v2 公告类型：new 
摘要：工具学习使大型语言模型（LLM）能够通过调用工具与外部环境进行交互，丰富了LLM的准确性和能力范围。然而，以前的工作主要侧重于提高模型的工具使用准确性和推广到新的、看不见的工具的能力，过度强迫LLM调整特定的工具调用模式而不考虑对模型总体性能的损害。这偏离了实际应用和集成工具增强模型的初衷。为了解决这个问题，我们通过检查模型组件的隐藏表示变化和基于梯度的重要性得分来剖析能力权衡。基于分析结果，我们提出了一种基于组件重要性的工具利用能力注入方法（CITI）。根据不同组件的基于梯度的重要性得分，通过对不同组件应用不同的训练策略来缓解微调过程引起的能力冲突。 CITI 对重要组件应用 Mixture-Of-LoRA (MOLoRA)。同时，它微调 LLM 主干中被认为不太重要的少数组件的参数，同时保持其他参数不变。CITI 可以有效增强模型的工具利用能力，而不会过度损害其总体性能。实验结果表明，我们的方法在一系列评估指标中都取得了出色的表现。]]></description>
      <guid>https://arxiv.org/abs/2409.13202</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经符号协同提炼：推进复杂推理任务的小型语言模型</title>
      <link>https://arxiv.org/abs/2409.13203</link>
      <description><![CDATA[arXiv:2409.13203v1 公告类型：新
摘要：在本文中，我们提出了 $\textbf{Ne}$ural-$\textbf{Sy}$mbolic $\textbf{C}$ollaborative $\textbf{D}$istillation ($\textbf{NesyCD}$)，这是一种用于学习大型语言模型 (LLM，例如 \textgreater 13B) 复杂推理能力的新型知识蒸馏方法。我们认为，复杂的推理任务对于小型语言模型 (SLM，例如 $\leq$ 7B) 来说很难，因为这些任务不仅需要一般的认知能力，还需要专业知识，而这些知识通常很稀疏，这些基于神经的 SLM 很难有效捕捉。因此，NesyCD 使用不同的方式提炼 LLM 中的一般能力和专业知识。一方面，我们仅将教师 LLM 中的一般能力提炼到参数化神经网络的学生 SLM 中。另一方面，对于复杂推理任务的专业能力和不常见的知识，我们采用符号知识提炼方法获取并将专业知识存储在符号知识库 (KB) 中。通过分离一般能力和专业能力，提出的 NesyCD 可以以经济高效的方式实现卓越的性能，利用较小的模型并将参数化神经网络与符号 KB 相结合。此外，专业 KB 具有很好的泛化能力，可以被人类理解和操纵。我们的实验表明，NesyCD 显著提高了 SLM 在域内 (BBH、GSM8K) 和域外 (AGIEval、ARC) 数据集上的复杂推理性能。值得注意的是，我们的方法使 LLaMA3-8B 和 Qwen2-7B 在性能上超越了 GPT-3.5-turbo，并且接近匹配 LLaMA3-70B，尽管后者的参数多九倍。我们的代码将在https://github.com/Xnhyacinth/NesyCD上提供。]]></description>
      <guid>https://arxiv.org/abs/2409.13203</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型应理解拼音，以便进行中文 ASR 纠错</title>
      <link>https://arxiv.org/abs/2409.13262</link>
      <description><![CDATA[arXiv:2409.13262v1 公告类型：新
摘要：大型语言模型可以通过生成纠错来增强自动语音识别系统。在本文中，我们提出了拼音增强型 GEC，它利用汉语拼音作为补充信息来改进中文 ASR 纠错。我们的方法仅使用合成错误进行训练，并在推理过程中采用最佳假设。此外，我们引入了一种多任务训练方法，涉及拼音和文本之间的转换任务以对齐它们的特征空间。在 Aishell-1 和 Common Voice 数据集上的实验表明，我们的方法在纯文本输入下始终优于 GEC。更重要的是，我们从两个方面为 PY-GEC 和多任务训练的有效性提供了直观的解释：1）增加拼音特征的注意力权重；2）对齐拼音和文本隐藏状态之间的特征空间。]]></description>
      <guid>https://arxiv.org/abs/2409.13262</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向 LifeSpan 认知系统</title>
      <link>https://arxiv.org/abs/2409.13265</link>
      <description><![CDATA[arXiv:2409.13265v1 公告类型：新
摘要：构建一个能够与复杂环境（无论是模拟数字世界还是人类社会）持续交互的类人系统面临着几个关键挑战。其中的核心是实现持续、高频的交互，这种交互被称为体验。我们将这个设想的系统称为 LifeSpan 认知系统 (LSCS)。LSCS 的一个关键特性是它能够进行增量和快速更新，同时保留和准确回忆过去的经历。我们发现实现这一目标面临两大挑战：(1) 抽象和经验融合，以及 (2) 长期保留和准确回忆。这些属性对于存储新体验、组织过去的经验以及以利用相关历史数据的方式响应环境至关重要。与具有持续学习的语言模型不同，后者通常依赖大型语料库进行微调并专注于提高特定领域或任务内的性能，而 LSCS 必须以高频率快速、增量地更新来自其环境的新信息。现有的能够解决上述两大挑战的技术可根据“存储复杂度”这一概念指标分为四类，该指标衡量存储过去经验所需的相对空间。这四类技术各有优缺点。鉴于现有技术均无法单独实现 LSCS，我们提出了一种集成所有四类技术的 LSCS 新范式。新范式通过两个核心流程运作：吸收经验和产生响应。]]></description>
      <guid>https://arxiv.org/abs/2409.13265</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用引文上下文进行关键词生成的无监督领域自适应</title>
      <link>https://arxiv.org/abs/2409.13266</link>
      <description><![CDATA[arXiv:2409.13266v1 公告类型：新
摘要：将关键短语生成模型适配到新领域通常需要使用领域内标记数据进行少量微调。但是，使用关键短语注释文档通常成本过高且不切实际，需要专家注释者。本文介绍了一种无监督方法 silk，旨在通过从引用上下文中提取银标准关键短语来创建用于领域适应的合成标记数据来解决此问题。在三个不同领域进行的大量实验表明，我们的方法可以产生高质量的合成样本，从而在强基线上显着且持续地提高领域内性能。]]></description>
      <guid>https://arxiv.org/abs/2409.13266</guid>
      <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>