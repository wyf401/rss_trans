<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 01 Nov 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>模型能帮助我们创建更好的模型吗？评估法学硕士作为数据科学家的能力</title>
      <link>https://arxiv.org/abs/2410.23331</link>
      <description><![CDATA[arXiv:2410.23331v1 公告类型：新
摘要：我们提出了一个大型语言模型的基准，旨在解决数据科学中最需要知识的任务之一：编写特征工程代码，这需要领域知识以及对底层问题和数据结构的深入了解。该模型在提示中提供了数据集描述，并被要求生成对其进行转换的代码。评估分数来自于与原始数据相比，XGBoost 模型在修改后的数据集上拟合所取得的改进。通过对最先进模型的广泛评估和与完善的基准的比较，我们证明了与现有方法相比，我们提案的 FeatEng 可以廉价而有效地评估 LLM 的广泛能力。]]></description>
      <guid>https://arxiv.org/abs/2410.23331</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用语言模型和老虎机算法推动电动汽车的普及</title>
      <link>https://arxiv.org/abs/2410.23371</link>
      <description><![CDATA[arXiv:2410.23371v1 公告类型：新
摘要：行为改变干预对于协调广泛重要应用的社会行动非常重要，包括采用电动汽车来减少排放。先前的研究表明，行为干预必须个性化，并且平均而言对大群体最有效的干预可能会导致反弹效应，从而加强某些亚群体之间的反对。因此，重要的是针对不同的受众进行干预，并以自然的对话风格呈现它们。在这种情况下，大型语言模型 (LLM) 的一个重要的新兴应用领域是行为改变的对话干预。在这项工作中，我们利用先前的研究来理解激励采用电动汽车的价值观。我们利用 LLM 的新进展，结合上下文强盗，开发针对每个研究参与者的价值观个性化的对话干预。我们使用上下文强盗算法来学习根据每个参与者的人口统计数据来定位价值观。为了以离线方式训练我们的老虎机算法，我们利用 LLM 扮演研究参与者的角色。我们将老虎机增强型 LLM 的说服力与无辅助 LLM 的说服力进行比较，后者生成没有针对人口统计的价值观的对话干预。]]></description>
      <guid>https://arxiv.org/abs/2410.23371</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>社会科学与法学硕士相遇：大型语言模型在社会模拟中的可靠性如何？</title>
      <link>https://arxiv.org/abs/2410.23426</link>
      <description><![CDATA[arXiv:2410.23426v1 公告类型：新
摘要：大型语言模型 (LLM) 越来越多地用于模拟，从而可以在角色扮演代理和计算社会科学 (CSS) 中应用。然而，这些模拟的可靠性尚未得到充分探索，这引发了人们对 LLM 在这些应用中的可信度的担忧。在本文中，我们旨在回答“基于 LLM 的模拟有多可靠？”为了解决这个问题，我们引入了 TrustSim，一个涵盖 10 个 CSS 相关主题的评估数据集，以系统地研究 LLM 模拟的可靠性。我们对 14 个 LLM 进行了实验，发现基于 LLM 的模拟角色仍然存在不一致性。此外，LLM 的一致性水平与其总体性能没有很强的相关性。为了提高 LLM 在模拟中的可靠性，我们提出了基于自适应学习率的 ORPO (AdaORPO)，这是一种基于强化学习的算法，可提高 7 个 LLM 的模拟可靠性。我们的研究为未来研究探索更为稳健、更可信的基于 LLM 的模拟奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2410.23426</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有 LLM 生成的支持文档的图形增强关系提取模型</title>
      <link>https://arxiv.org/abs/2410.23452</link>
      <description><![CDATA[arXiv:2410.23452v1 公告类型：新
摘要：本研究介绍了一种新颖的句子级关系提取 (RE) 方法，该方法将图神经网络 (GNN) 与大型语言模型 (LLM) 相结合，以生成上下文丰富的支持文档。通过利用 LLM 的功能来生成辅助信息，我们的方法可以制作文本数据的复杂图形表示。随后通过图神经网络 (GNN) 处理该图，以细化和丰富与每个实体相关的嵌入，确保对数据的理解更加细致入微和相互关联。该方法通过结合更广泛的上下文并利用实体间交互来解决传统句子级 RE 模型的局限性，从而提高了模型捕获跨句子复杂关系的能力。我们在 CrossRE 数据集上进行的实验证明了我们方法的有效性，并且在各个领域的性能都有显着提高。结果强调了将 GNN 与 LLM 生成的上下文相结合以推进关系提取领域的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.23452</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MDCure：用于多文档指令跟踪的可扩展管道</title>
      <link>https://arxiv.org/abs/2410.23463</link>
      <description><![CDATA[arXiv:2410.23463v1 公告类型：新
摘要：多文档 (MD) 处理对于 LLM 处理现实世界任务（例如跨大量文档的摘要和问答）至关重要。虽然 LLM 在处理长输入方面有所改进，但 MD 上下文仍然存在挑战，例如管理文档间依赖关系、冗余和不连贯的结构。我们引入了 MDCure，这是一种可扩展且有效的微调管道，可增强 LLM 的 MD 功能，而无需预先训练或依赖人工注释数据的计算成本。MDCure 基于通过有针对性的提示从相关文章集生成高质量的合成 MD 指令数据。我们进一步介绍了 MDCureRM，这是一种多目标奖励模型，它根据 MD 设置的训练效用过滤生成的数据。借助 MDCure，我们对 FlanT5、Qwen2 和 LLAMA3.1 模型系列中的各种 LLM 进行了微调，参数大小高达 70B。对各种任务的广泛 MD 和长上下文基准进行的广泛评估表明，MDCure 的性能始终优于预训练基线和相应的基础模型，最高可达 75.5%。我们的代码、数据集和模型可在 https://github.com/yale-nlp/MDCure 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.23463</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>拼贴：可分解快速原型，用于科学 PDF 上的信息提取</title>
      <link>https://arxiv.org/abs/2410.23478</link>
      <description><![CDATA[arXiv:2410.23478v1 公告类型：新
摘要：近年来，NLP 领域中，针对科学文档的特定领域信息提取工具不断发展，同时发布了越来越多的多模态预训练转换器模型。虽然 NLP 以外的科学家评估此类系统并将其应用于自己领域的机会从未如此清晰，但这些模型很难比较：它们接受不同的输入格式，通常是黑盒的，很少能洞察处理失败，而且很少处理 PDF 文档（最常见的科学出版物格式）。在这项工作中，我们介绍了 Collage，这是一种用于快速原型设计、可视化和评估科学 PDF 上不同信息提取模型的工具。Collage 允许使用和评估任何 HuggingFace 标记分类器、多个 LLM 和多个其他特定于任务的模型，并提供可扩展的软件接口以加速对新模型的实验。此外，我们通过提供中间处理状态的精细视图，使基于 NLP 的工具的开发人员和用户能够检查、调试和更好地理解建模流程。我们在信息提取的背景下演示了我们的系统，以协助材料科学领域的文献综述。]]></description>
      <guid>https://arxiv.org/abs/2410.23478</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>规模较小的大型语言模型可以进行道德自我纠正</title>
      <link>https://arxiv.org/abs/2410.23496</link>
      <description><![CDATA[arXiv:2410.23496v1 公告类型：新
摘要：自我纠正是大型语言模型 (LLM) 最令人惊叹的新兴功能之一，它使 LLM 能够在给出描述该输出问题的自然语言反馈的情况下自我修改不适当的输出。道德自我纠正是一种事后方法，无需梯度更新即可纠正不道德的生成，使其在计算上既轻量又能够保留语言建模能力。先前的研究表明，LLM 可以自我纠正偏见，据报道，小型模型（即参数少于 22B 的模型）无法进行道德自我纠正。然而，没有直接证据表明为什么这些较小的模型无法进行道德自我纠正，尽管先前的研究假设较大的模型擅长遵循指示和理解抽象的社会规范。在本文中，我们通过细致的提示，在社会刻板印象的背景下对这一假设进行了实证验证。我们的实验结果表明：（i）令人惊讶的是，经过适当安全对齐微调的 3.8B LLM 可以实现非常好的道德自我纠正性能，凸显了安全对齐的显著作用；（ii）小型 LLM 在理解社会规范和通过 CoT 进行自我解释方面确实比大型模型弱，但所有规模的 LLM 在给出不道德指令时都表现出糟糕的自我纠正性能。]]></description>
      <guid>https://arxiv.org/abs/2410.23496</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过专家协作实现高效、可解释的语法错误纠正</title>
      <link>https://arxiv.org/abs/2410.23507</link>
      <description><![CDATA[arXiv:2410.23507v1 公告类型：新
摘要：错误类型信息已被广泛用于提高语法错误纠正 (GEC) 模型的性能，无论是用于生成纠正、重新排序还是组合 GEC 模型。组合在纠正不同错误类型方面具有互补优势的 GEC 模型对于产生更好的纠正非常有效。然而，系统组合会产生很高的计算成本，因为在运行组合方法本身之前需要在基础系统上运行推理。因此，拥有一个具有多个专门纠正不同错误类型的子网络的单一模型会更有效。在本文中，我们提出了一种用于语法错误纠正的混合专家模型 MoECE。我们的模型成功地实现了 T5-XL 的性能，而有效参数却减少了三倍。此外，我们的模型还通过在推理过程中识别错误类型来生成可解释的校正。]]></description>
      <guid>https://arxiv.org/abs/2410.23507</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型进行动态策略规划以实现高效问答</title>
      <link>https://arxiv.org/abs/2410.23511</link>
      <description><![CDATA[arXiv:2410.23511v1 公告类型：新
摘要：研究表明，推理（例如，思维链）、规划（例如，SelfAsk）和检索增强生成策略可以有效地提高大型语言模型 (LLM) 在各种任务（例如问答）上的性能。但是，使用单一固定策略来回答不同类型的问题在性能上不是最优的，并且在生成的输出标记和执行的检索方面效率低下。在我们的工作中，我们提出了一种新颖的技术 DyPlan，以在 LLM 中引入动态策略选择过程，以提高性能并降低问答成本。DyPlan 结合了初始决策步骤，以根据输入问题选择最合适的策略，并相应地指导 LLM 的响应生成。我们将 DyPlan 扩展为 DyPlan-verify，增加了内部验证和校正过程，以进一步丰富生成的答案。在三个著名的多跳问答 (MHQA) 数据集上进行的实验表明，与最佳基线模型相比，DyPlan 如何将模型性能提高 7-13%，同时将成本降低 11-32%。]]></description>
      <guid>https://arxiv.org/abs/2410.23511</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经拼写检查器：通过合成数据生成超越文字</title>
      <link>https://arxiv.org/abs/2410.23514</link>
      <description><![CDATA[arXiv:2410.23514v1 公告类型：新
摘要：拼写检查器是一种有价值的工具，它通过识别书面文本中的拼写错误单词来增强交流。深度学习的最新改进，尤其是大型语言模型的改进，为改进传统拼写检查器提供了新的机会，这些新功能不仅可以评估拼写的正确性，还可以评估单词是否适合给定的上下文。在我们的工作中，我们介绍并比较了两个新的拼写检查器，并在合成、学习者和更通用领域的斯洛文尼亚语数据集上对它们进行了评估。第一个拼写检查器是一种传统的、快速的、基于单词的方法，基于形态词典，与现有的拼写检查器相比，它的单词列表要大得多。第二种方法使用在大型语料库上训练的语言模型，其中插入了合成错误。我们提出了训练数据构建策略，这些策略是神经拼写检查器的重要组成部分。此外，所提出的神经模型在准确率和召回率方面都明显优于所有现有的斯洛文尼亚语拼写检查器。]]></description>
      <guid>https://arxiv.org/abs/2410.23514</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LEAF：通过事实核查增强学习和评估，以提高大型语言模型的事实性</title>
      <link>https://arxiv.org/abs/2410.23526</link>
      <description><![CDATA[arXiv:2410.23526v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种自然语言处理任务中表现出色，但它们往往难以保持事实准确性，特别是在医疗保健等知识密集型领域。本研究介绍了 LEAF：通过事实核查增强的学习和评估，这是一种旨在提高 LLM 事实可靠性的新方法，重点是医学问答 (QA)。LEAF 采用双重策略来提高 Llama 3 70B Instruct 和 Llama 3 8B Instruct 等模型的响应的事实准确性。第一种策略，Fact-Check-Then-RAG，通过结合事实核查结果来指导检索过程而无需更新模型参数，从而改进了检索增强生成 (RAG)。第二种策略是通过自我训练从事实核查中学习，涉及对事实核查的回答进行监督微调 (SFT) 或将简单偏好优化 (SimPO) 与事实核查作为排名机制，两者都从监督中更新 LLM 参数。这些发现表明，无论是通过 RAG 增强还是自我训练，整合事实核查的回答都可以提高 LLM 输出的可靠性和事实正确性，为信息准确性至关重要的应用提供了一个有前途的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.23526</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于患者评论多标签分类的大型语言模型</title>
      <link>https://arxiv.org/abs/2410.23528</link>
      <description><![CDATA[arXiv:2410.23528v1 公告类型：新
摘要：患者体验和护理质量对于医院的可持续性和声誉至关重要。对患者反馈的分析为患者满意度和结果提供了宝贵的见解。然而，这些评论的非结构化性质对遵循监督学习范式的传统机器学习方法构成了挑战。这是由于标记数据的不可用以及这些文本包含的细微差别。本研究探索利用大型语言模型 (LLM) 对住院后分享的住院评论进行多标签文本分类 (MLTC)。利用 GPT-4o-Turbo 进行分类。然而，考虑到患者评论的敏感性，在通过受保护的健康信息 (PHI) 检测框架将数据提供给 LLM 之前引入了一个安全层，以确保患者的身份识别。此外，使用提示工程框架，尝试了零样本学习、上下文学习和思路链提示。结果表明，无论是在零样本还是少样本设置下，GPT-4o-Turbo 的表现都优于传统方法和预训练语言模型 (PLM)，并且总体表现最高，F1 得分为 76.12%，加权 F1 得分为 73.61%，紧随其后的是少样本学习结果。随后，研究了结果与其他患者体验结构化变量（例如评分）的关联。该研究通过应用 LLM 增强了 MLTC，为医疗从业者提供了一种有效的方法来更深入地了解患者的反馈并做出及时、适当的回应。]]></description>
      <guid>https://arxiv.org/abs/2410.23528</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模拟具身对话式人工智能的用户代理</title>
      <link>https://arxiv.org/abs/2410.23535</link>
      <description><![CDATA[arXiv:2410.23535v1 公告类型：新
摘要：旨在协助用户完成任务的具身代理必须参与自然语言交互、解释指令、执行操作并有效沟通以解决问题。然而，收集大规模、多样化的人机对话数据集来训练和评估此类代理是昂贵、劳动密集且耗时的。为了应对这一挑战，我们建议构建一个基于大型语言模型 (LLM) 的用户代理，它可以模拟用户在虚拟环境中与具身代理交互时的行为。给定一个用户目标（例如，做早餐），在每个时间步骤，用户代理可以观察“机器人动作或说话”以干预机器人或回答问题。这样的用户代理有助于提高具身对话数据集生成的可扩展性和效率，对于增强和评估机器人的交互和任务完成能力以及使用 AI 反馈进行强化学习的研究至关重要。我们通过将用户代理的模拟对话与 TEACh 数据集进行比较来评估其生成类似人类行为的能力。我们进行了三项实验：零样本提示预测对话行为、少样本提示和在 TEACh 训练子集上进行微调。结果表明，基于 LLM 的用户代理在模仿人类说话行为方面，零样本提示的 F 测量值为 42%，少样本提示的 F 测量值为 43.4%。通过微调，决定何时说话的表现保持稳定，而决定说什么的表现从 51.1% 提高到 62.5%。这些发现证明了所提出的方法在评估和提高通过自然语言交流完成机器人任务的有效性方面的可行性。]]></description>
      <guid>https://arxiv.org/abs/2410.23535</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从情境到行动：状态表征和情境对多轮 Web 导航代理泛化的影响分析</title>
      <link>https://arxiv.org/abs/2410.23555</link>
      <description><![CDATA[arXiv:2410.23555v1 公告类型：新
摘要：基于大型语言模型 (LLM) 的框架的最新进展已将其功能扩展到复杂的实际应用，例如交互式 Web 导航。这些系统由用户命令驱动，通过多轮对话引导 Web 浏览器完成任务，既提供了创新机会，也带来了重大挑战。尽管引入了对话式 Web 导航的基准，但对影响这些代理性能的关键上下文组件的详细了解仍然难以捉摸。本研究旨在通过分析对 Web 导航代理功能至关重要的各种上下文元素来填补这一空白。我们研究上下文管理的优化，重点关注交互历史和网页表示的影响。我们的工作重点是通过有效的上下文管理在分布外场景（包括看不见的网站、类别和地理位置）中提高代理性能。这些发现为基于 LLM 的代理的设计和优化提供了见解，使实际应用中的 Web 导航更加准确和有效。]]></description>
      <guid>https://arxiv.org/abs/2410.23555</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BioNCERE：生物医学文本中关系提取的非对比增强</title>
      <link>https://arxiv.org/abs/2410.23583</link>
      <description><![CDATA[arXiv:2410.23583v1 公告类型：新 
摘要：生物医学领域最先进的关系提取 (RE) 模型考虑使用分类对 BioBERT 进行微调，但它们可能会受到各向异性问题的影响。对比学习方法可以减少这种各向异性现象，也有助于避免任何分类问题中的类别崩溃。在本文中，引入了一种称为生物非对比关系提取 (BioNCERE) 的新训练方法，用于关系提取，而无需使用任何命名实体标签进行训练以降低注释成本。BioNCERE 使用迁移学习和非对比学习来避免完全或维度崩溃以及绕过过度拟合。它通过两次利用迁移学习分三个阶段解决 RE。通过冻结所提出的管道中前几个阶段学习到的权重，并通过在第二阶段利用非对比学习，该模型可以在不了解命名实体的情况下预测关系。在 SemMedDB 上进行的实验几乎与 RE 的最新性能相似，而无需使用命名实体的信息。]]></description>
      <guid>https://arxiv.org/abs/2410.23583</guid>
      <pubDate>Fri, 01 Nov 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>