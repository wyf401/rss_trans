<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 04 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>波斯语同形异义词消歧：利用 ParsBERT 和新颖的词语消歧数据集增强句子理解</title>
      <link>https://arxiv.org/abs/2406.00028</link>
      <description><![CDATA[arXiv:2406.00028v1 公告类型：新
摘要：同形异义词消歧是区分拼写相同但含义不同的单词的任务，对自然语言处理提出了重大挑战。在本研究中，我们引入了一个专门为波斯语同形异义词消歧而定制的新数据集。我们的工作包括对各种嵌入的彻底探索，通过余弦相似度方法及其在分类等下游任务中的有效性进行评估。我们的调查需要训练各种轻量级机器学习和深度学习模型来进行音素消歧。我们仔细检查了模型在准确率、召回率和 F1 分数方面的性能，从而深入了解了它们各自的优势和局限性。我们研究的结果强调了三个关键贡献。首先，我们提供了一个新整理的波斯语数据集，为未来的同形异义词消歧研究奠定了坚实的基础。其次，我们对嵌入的比较分析突出了它们在不同语境中的效用，丰富了对其功能的理解。第三，通过训练和评估一系列模型，我们为从业者提供了宝贵的指导，帮助他们选择适合同形异义词消歧任务的策略。总之，我们的研究揭示了一个新的数据集，从不同的角度审视了嵌入，并对各种同形异义词消歧模型进行了基准测试。这些发现使研究人员和从业者能够有效地应对与同形异义词相关的复杂挑战。]]></description>
      <guid>https://arxiv.org/abs/2406.00028</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:42 GMT</pubDate>
    </item>
    <item>
      <title>聚类检索增强生成 (CRAG)</title>
      <link>https://arxiv.org/abs/2406.00029</link>
      <description><![CDATA[arXiv:2406.00029v1 公告类型：新
摘要：向大型语言模型 (LLM) 提供外部知识是将这些模型用于实际应用的关键点，原因有很多，例如以实时方式整合最新内容、提供对特定领域知识的访问以及有助于预防幻觉。基于向量数据库的检索增强生成 (RAG) 方法已被广泛采用。因此，可以检索外部知识的任何部分并将其提供给某些 LLM 作为输入上下文。尽管 RAG 方法取得了成功，但它对于某些应用程序来说仍然可能不可行，因为检索到的上下文可能需要比 LLM 支持的大小更长的上下文窗口。即使检索到的上下文适合上下文窗口大小，标记的数量也可能具有表现力，从而影响成本和处理时间，对于大多数应用程序来说变得不切实际。为了解决这些问题，我们提出了 CRAG，这是一种新颖的方法，与使用 RAG 的解决方案相比，它能够有效减少提示标记的数量，而不会降低生成的响应的质量。通过我们的实验，我们表明，与 RAG 相比，CRAG 可以将标记数量减少至少 46%，在某些情况下可以达到 90% 以上。此外，当分析的评论数量较多时，CRAG 的标记数量不会显着增加，而 RAG 则不同，当有 75 条评论时，与有 4 条评论相比，标记数量几乎高出 9 倍。]]></description>
      <guid>https://arxiv.org/abs/2406.00029</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:42 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型修剪</title>
      <link>https://arxiv.org/abs/2406.00030</link>
      <description><![CDATA[arXiv:2406.00030v1 公告类型：新
摘要：过去几年，当硬件和软件都支持如此巨大的模型诞生时，我们当然会享受更大更好的模型所带来的卓越性能。应用领域包括文本挖掘等。特别是，LLM 在文本理解和文本生成方面的成功引起了在 NLP 和相关领域工作多年甚至几十年的研究人员的关注。另一方面，LLM 可能会遇到模型过度拟合、幻觉和设备限制等问题。在这项工作中，我们提出了一种专门针对 LLM 的模型修剪技术。所提出的方法强调了深度学习模型的可解释性。通过理论基础，我们获得了一个值得信赖的深度模型，因此具有大量模型参数的大型模型就变得不那么必要了。采用基于互信息的估计来查找要消除冗余的神经元。此外，具有经过良好调整的参数的估计器有助于找到精确的估计来指导修剪过程。同时，我们还探讨了大规模模型上的剪枝与小规模模型上的剪枝之间的区别。剪枝标准的选择在小模型中很敏感，但在大规模模型中却不敏感。这是通过这项工作得出的一个新发现。总的来说，我们证明了所提出的模型优于最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2406.00030</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:42 GMT</pubDate>
    </item>
    <item>
      <title>SCALM：面向具有大型语言模型的自动聊天服务的语义缓存</title>
      <link>https://arxiv.org/abs/2406.00025</link>
      <description><![CDATA[arXiv:2406.00025v1 公告类型：新
摘要：大型语言模型 (LLM) 越来越受欢迎，改变了各个领域的各种应用。然而，它们的查询缓存系统的实际有效性尚未得到彻底研究。在这项工作中，我们首次对现实世界的人与 LLM 交互数据进行了分析，确定了基于 LLM 的聊天服务现有缓存解决方案中的关键挑战。我们的研究结果表明，当前的缓存方法无法利用语义连接，导致缓存性能低下和额外的令牌成本。为了解决这些问题，我们提出了 SCALM，这是一种新的缓存架构，它强调语义分析并识别重要的缓存条目和模式。我们还详细介绍了相应的缓存存储和驱逐策略的实现。我们的评估表明，SCALM 提高了缓存命中率并降低了 LLMChat 服务的运营成本。与 GPTCache 中其他先进解决方案相比，SCALM 平均缓存命中率相对提高了 63%，令牌节省相对提高了 77%。]]></description>
      <guid>https://arxiv.org/abs/2406.00025</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:41 GMT</pubDate>
    </item>
    <item>
      <title>改编 PromptORE 以适应现代历史：从 16 世纪西班牙君主制文件中提取信息</title>
      <link>https://arxiv.org/abs/2406.00027</link>
      <description><![CDATA[arXiv:2406.00027v1 公告类型：新
摘要：实体之间的语义关系是一种广泛接受的关系提取方法。PromptORE（基于提示的开放关系提取）旨在改进使用大型语言模型对通用文档的关系提取。但是，当应用于除英语以外的语言的历史文献时，效果较差。在本研究中，我们引入了 PromptORE 的改编版，以从专门的文档（即西班牙宗教裁判所审判的数字记录）中提取关系。我们的方法涉及使用其预训练目标对将执行推理的数据进行微调变压器模型。我们将此过程称为“偏见”。我们的 Biased PromptORE 解决了西班牙语文本中出现的复杂实体位置和性别歧视。我们通过提示工程解决了这些问题。我们使用类似编码器的模型评估我们的方法，并通过专家的评估证实我们的发现。此外，我们使用二项式分类基准来评估性能。我们的结果表明，与使用标准 PromptORE 的基线模型相比，我们的 Biased PromptORE 模型的准确率显著提高，最高提高了 50%。]]></description>
      <guid>https://arxiv.org/abs/2406.00027</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:41 GMT</pubDate>
    </item>
    <item>
      <title>多语言韵律迁移：监督学习与迁移学习的比较</title>
      <link>https://arxiv.org/abs/2406.00022</link>
      <description><![CDATA[arXiv:2406.00022v1 公告类型：新
摘要：语音合成系统中的韵律转换领域正在迅速发展。这项研究的重点是评估将预训练的单语文本转语音 (TTS) 模型适应多语言条件的学习方法，即监督微调 (SFT) 和迁移学习 (TL)。此比较使用三个不同的指标：平均意见分数 (MOS)、识别准确度 (RA) 和梅尔倒谱失真 (MCD)。结果表明，与 SFT 相比，TL 可显著提高性能，平均 MOS 高出 1.53 分，RA 增加 37.5%，MCD 提高约 7.8 分。这些发现有助于为低资源语言构建 TTS 模型。]]></description>
      <guid>https://arxiv.org/abs/2406.00022</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:40 GMT</pubDate>
    </item>
    <item>
      <title>LocMoE+：具有令牌特征感知功能的增强型路由器，可实现高效的 LLM 预训练</title>
      <link>https://arxiv.org/abs/2406.00023</link>
      <description><![CDATA[arXiv:2406.00023v1 公告类型：新 
摘要：混合专家 (MoE) 架构最近在大型语言模型 (LLM) 领域越来越受欢迎，因为它们能够显着降低训练和推理开销。然而，MoE 架构面临着挑战，例如分配给每个专家的 token 数量存在显著差异，以及专家之间趋于同质化，这对模型的语义生成能力产生了不利影响。在本文中，我们介绍了 LocMoE+，这是低开销 LocMoE 的改进版本，包含以下增强功能：(1) 量化和定义专家与 token 之间的亲和力。(2) 实施全局级自适应路由策略，根据 token 的亲和力分数重新排列 token。(3) 重新估计专家容量的下限，事实证明，随着 token 特征分布的发展，该下限会逐渐下降。实验结果表明，在不影响模型收敛性和有效性的情况下，每个专家处理的 token 数量可以减少 60% 以上。结合通信优化，训练效率平均提升 5.4% 至 46.6%。经过微调后，LocMoE+ 在 GDAD、C-Eval 和 TeleQnA 数据集上的性能提升了 9.7% 至 14.1%。]]></description>
      <guid>https://arxiv.org/abs/2406.00023</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:40 GMT</pubDate>
    </item>
    <item>
      <title>嵌入对齐语言模型</title>
      <link>https://arxiv.org/abs/2406.00024</link>
      <description><![CDATA[arXiv:2406.00024v1 公告类型：新
摘要：我们提出了一种训练大型语言模型 (LLM) 的新方法，以遵守潜在嵌入空间中定义的目标。我们的方法利用强化学习 (RL)，将预先训练的 LLM 视为环境。我们的嵌入对齐引导语言 (EAGLE) 代理经过训练，可以根据某些预定义标准迭代地引导 LLM 的生成朝向潜在嵌入空间的最佳区域。我们使用 MovieLens 25M 数据集展示了 EAGLE 代理的有效性，可以发现满足潜在用户需求的内容差距。我们还展示了使用状态相关动作集的最佳设计来提高 EAGLE 效率的好处。我们的工作为使用 LLM 进行受控和扎实的文本生成铺平了道路，确保与特定领域的知识和数据表示保持一致。]]></description>
      <guid>https://arxiv.org/abs/2406.00024</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:40 GMT</pubDate>
    </item>
    <item>
      <title>语言模型的有害言论检测表现出性别歧视的方言偏见</title>
      <link>https://arxiv.org/abs/2406.00020</link>
      <description><![CDATA[arXiv:2406.00020v1 公告类型：新
摘要：社交媒体平台上的内容审核塑造了在线话语的动态，影响了谁的声音被放大，谁的声音被压制。最近的研究引起了人们对内容审核实践公平性的担忧，特别是对于积极地将跨性别者和非二元性别者的帖子标记为有害帖子。在本研究中，我们调查了在线性别酷儿方言有害语音分类中是否存在偏见，特别关注对回收诽谤的处理。我们引入了一个新数据集 QueerReclaimLex，它基于 109 个精选模板，这些模板举例说明了 LGBTQ+ 诽谤的非贬义用法。性别酷儿注释者根据有关说话者身份的其他背景对数据集实例进行评分，以确定其可能造成的危害。我们系统地评估了五种现成的语言模型在评估这些文本危害方面的表现，并探索了思路链提示在教导大型语言模型 (LLM) 利用作者身份背景方面的有效性。我们发现这些模型倾向于错误地将性别酷儿个人撰写的文本标记为有害。令人惊讶的是，在所有 LLM 中，对于有迹象表明由特色诽谤所针对的个人撰写的文本，其性能最差 (F1 &lt;= 0.24)。我们强调内容审核系统迫切需要公平和包容。通过揭示这些偏见，这项工作旨在为更公平的内容审核实践的发展提供信息，并为所有用户创造包容性的在线空间做出贡献。]]></description>
      <guid>https://arxiv.org/abs/2406.00020</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:39 GMT</pubDate>
    </item>
    <item>
      <title>CrossVoice：使用迁移学习实现跨语言韵律保留的 Cascade-S2ST</title>
      <link>https://arxiv.org/abs/2406.00021</link>
      <description><![CDATA[arXiv:2406.00021v1 公告类型：新
摘要：本文介绍了 CrossVoice，这是一种基于级联的新型语音到语音翻译 (S2ST) 系统，采用先进的 ASR、MT 和 TTS 技术，通过迁移学习实现跨语言韵律保留。我们进行了全面的实验，将 CrossVoice 与直接 S2ST 系统进行比较，结果表明，在 Fisher Es-En、VoxPopuli Fr-En 和基准数据集 CVSS-T 和 IndicTTS 上的韵律保留等任务上，BLEU 分数有所提高。CrossVoice 合成的语音平均评分为 4 分中的 3.75 分，在基准上与人类语音相差无几，凸显了基于级联的系统和迁移学习在具有韵律迁移的多语言 S2ST 中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.00021</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:39 GMT</pubDate>
    </item>
    <item>
      <title>PTA：通过流水线预测和基于翻译的对齐增强多模态情绪分析</title>
      <link>https://arxiv.org/abs/2406.00017</link>
      <description><![CDATA[arXiv:2406.00017v1 公告类型：新
摘要：基于多模态方面的情绪分析（MABSA）旨在以细粒度的方式理解观点，推动人机交互和其他领域的发展。传统上，MABSA 方法使用联合预测方法来同时识别方面和情绪。然而，我们认为联合模型并不总是更优越。我们的分析表明，联合模型难以将相关文本标记与图像块对齐，导致错位和图像利用率低下。
相比之下，管道框架首先通过 MATE（多模态方面术语提取）识别方面，然后将这些方面与图像块对齐以进行情绪分类（MASC：多模态面向方面的情绪分类）。此方法更适合有效使用图像至关重要的多模态场景。我们提出了三个关键观察结果：（a）MATE 和 MASC 具有不同的特征要求，MATE 专注于标记级特征，而 MASC 专注于序列级特征；（b）MATE 识别的方面对于有效利用图像至关重要； （c）由于噪声较大，图像在以前的 MABSA 方法中起的作用很小。
基于这些观察，我们提出了一个管道框架，该框架首先预测方面，然后使用基于翻译的对齐 (TBA) 来增强多模态语义一致性，从而更好地利用图像。我们的方法在广泛使用的 MABSA 数据集 Twitter-15 和 Twitter-17 上实现了最先进的 (SOTA) 性能。这证明了管道方法的有效性及其为未来 MABSA 研究提供宝贵见解的潜力。
为了可重复性，将发布代码和检查点。]]></description>
      <guid>https://arxiv.org/abs/2406.00017</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:38 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型对报纸政治倾向的检测</title>
      <link>https://arxiv.org/abs/2406.00018</link>
      <description><![CDATA[arXiv:2406.00018v1 公告类型：新
摘要：如果报纸的政治或经济取向不明确，民主舆论形成可能会受到操纵。已经开发了各种方法来更好地理解报纸的定位。最近，大型语言模型 (LLM) 的出现，尤其是像 ChatGPT 或 Gemini 这样的预先训练过的 LLM 聊天机器人，具有颠覆性的潜力，可以帮助研究人员和公民。然而，人们对 LLM 评估是否值得信赖知之甚少：单个 LLM 是否同意专家的评估，不同的 LLM 是否彼此一致地回答？在本文中，我们专门解决第二个挑战。我们比较了四个广泛使用的 LLM 如何评价报纸的定位，并比较它们的答案是否彼此一致。我们观察到事实并非如此。在全球数据集中，报纸上的文章在单个 LLM 中的定位截然不同，暗示算法中的训练不一致或过度随机性。因此，我们在决定使用哪些工具时提出了警告，并呼吁进行更好的培训和算法开发，以弥补全球民主和社会高度敏感问题上的巨大差距。我们还呼吁社区通过我们的开放倡议 navai.pro 参与基准评估。]]></description>
      <guid>https://arxiv.org/abs/2406.00018</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:38 GMT</pubDate>
    </item>
    <item>
      <title>EHR-SeqSQL：用于交互式探索电子健康记录的顺序文本到 SQL 数据集</title>
      <link>https://arxiv.org/abs/2406.00019</link>
      <description><![CDATA[arXiv:2406.00019v1 公告类型：新
摘要：在本文中，我们介绍了 EHR-SeqSQL，这是一种用于电子健康记录 (EHR) 数据库的新型顺序文本到 SQL 数据集。EHR-SeqSQL 旨在解决文本到 SQL 解析中关键但尚未充分探索的方面：交互性、组合性和效率。据我们所知，EHR-SeqSQL 不仅是最大的，也是第一个包含顺序和上下文问题的医学文本到 SQL 数据集基准。我们提供了数据分割和旨在评估组合泛化能力的新测试集。我们的实验证明了多轮方法在学习组合性方面优于单轮方法。此外，我们的数据集将特制的标记集成到 SQL 查询中以提高执行效率。借助 EHR-SeqSQL，我们旨在弥合文本到 SQL 领域的实际需求与学术研究之间的差距。]]></description>
      <guid>https://arxiv.org/abs/2406.00019</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:38 GMT</pubDate>
    </item>
    <item>
      <title>使用自然语言处理从手术病理报告中提取和分类甲状腺乳头状癌特征</title>
      <link>https://arxiv.org/abs/2406.00015</link>
      <description><![CDATA[arXiv:2406.00015v1 公告类型：新
摘要：背景我们旨在使用自然语言处理 (NLP) 自动从病理报告中提取和分类甲状腺癌风险因素。方法我们分析了 2010 年至 2019 年明尼苏达州罗切斯特市梅奥诊所的 1,410 份成人乳头状甲状腺癌患者的手术病理报告。结构化和非结构化报告用于创建基于共识的地面真相词典，并将其分类为修改后的复发风险级别。非结构化报告是叙述性的，而结构化报告遵循标准化格式。然后，我们开发了基于规则的 NLP 管道 ThyroPath，以提取甲状腺癌特征并将其分类为风险类别。培训涉及 225 份报告（150 份结构化，75 份非结构化），并对 170 份报告（120 份结构化，50 份非结构化）进行测试以进行评估。使用准确度、精确度、召回率和 F1 分数的严格和宽松标准评估了流程的性能。结果在提取任务中，ThyroPath 对结构化报告的总体严格 F-1 分数为 93%，对非结构化报告的总体严格 F-1 分数为 90，涵盖了 18 种甲状腺癌病理特征。在分类任务中，ThyroPath 提取的信息在根据相应的指南复发风险对报告进行分类时的总体准确率为 93%：高风险为 76.9%，中等风险为 86.8%，低风险和极低风险病例为 100%。但是，使用人工提取的病理信息，ThyroPath 在所有甲状腺癌风险类别中的准确率都达到了 100%。结论 ThyroPath 在实现大规模甲状腺病理报告的自动提取和风险复发分类方面显示出良好的前景。它为繁琐的人工审查和推进虚拟注册表提供了一种解决方案。但是，在实施前需要进一步验证。]]></description>
      <guid>https://arxiv.org/abs/2406.00015</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:37 GMT</pubDate>
    </item>
    <item>
      <title>注意力机制增强深度学习模型在医学文本数据挖掘中的探索</title>
      <link>https://arxiv.org/abs/2406.00016</link>
      <description><![CDATA[arXiv:2406.00016v1 Announce Type: new 
摘要：本研究探讨了基于注意力机制的深度学习模型在医学文本挖掘中的应用，针对医学数据中非结构化文本信息的分析挑战，旨在通过结合深度学习和注意力机制，增强模型识别关键医学信息的能力。本文回顾了注意力机制的基本原理和典型模型架构，并展示了其在疾病预测、药物副作用监测、实体关系提取等任务中的应用效果。针对医学文本的特殊性，提出了一种融合领域知识的自适应注意力模型，优化了其对医学术语的理解和复杂上下文的处理能力。实验验证了该模型在提高任务准确率和鲁棒性方面的有效性，尤其是在处理长文本时。研究展望中讨论了增强模型解释性、实现跨领域知识迁移、适应低资源场景等未来研究路径，为智能医疗信息处理和临床决策辅助提供了新的视角和方法支持。最后，提出面向低资源场景的跨领域知识迁移及适应策略，为促进智能医疗信息处理和临床决策支持系统的发展提供理论基础和技术参考。]]></description>
      <guid>https://arxiv.org/abs/2406.00016</guid>
      <pubDate>Tue, 04 Jun 2024 06:18:37 GMT</pubDate>
    </item>
    </channel>
</rss>