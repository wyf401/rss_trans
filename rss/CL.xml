<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Tue, 07 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>论非自回归翻译中的信息冗余</title>
      <link>https://arxiv.org/abs/2405.02673</link>
      <description><![CDATA[arXiv:2405.02673v1 公告类型：新
摘要：标记重复是完全非自回归翻译 (NAT) 中多模态问题的典型形式。在这项工作中，我们重新审视了最近提出的 NAT 模型中的多模态问题。我们的研究表明，这些先进的模型引入了其他类型的信息冗余错误，这些错误无法通过传统的度量标准（连续重复率）来衡量。通过手动注释 NAT 输出，我们确定了两种类型的信息冗余错误，它们与词汇和重新排序多模态问题非常吻合。由于人工注释耗时且劳动密集，我们提出了自动指标来评估这两种类型的冗余错误。我们的指标使未来的研究能够评估新方法并更全面地了解其有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.02673</guid>
      <pubDate>Tue, 07 May 2024 06:18:04 GMT</pubDate>
    </item>
    <item>
      <title>R4：用于检索增强大型语言模型的强化检索器重排序响应器</title>
      <link>https://arxiv.org/abs/2405.02659</link>
      <description><![CDATA[arXiv:2405.02659v1 公告类型：新
摘要：检索增强大语言模型（LLM）利用信息检索系统检索到的相关内容来生成正确的响应，旨在缓解幻觉问题。然而，现有的检索器-响应器方法通常将相关文档附加到法学硕士的提示中以执行文本生成任务，而没有考虑检索到的文档与法学硕士之间细粒度结构语义的交互。这个问题对于准确生成响应尤其重要，因为法学硕士在处理用冗长文档增强的输入提示时往往会“中途失败”。在这项工作中，我们提出了一个名为“强化检索器重新排序响应器”（R$^4$）的新管道来学习检索增强法学硕士的文档排序，从而进一步增强其生成能力，同时大量参数法学硕士仍处于冻结状态。根据生成响应的质量，重新排序学习过程分为两个步骤：文档顺序调整和文档表示增强。具体来说，文档顺序调整旨在基于图注意力学习将检索到的文档顺序组织为开始、中间和结束位置，从而最大化响应质量的强化奖励。文档表示增强通过文档级梯度对抗学习进一步细化检索到的文档的表示，以应对质量较差的响应。大量的实验表明，与各种公共数据集的强大基线相比，我们提出的管道在知识密集型任务上实现了更好的事实问答性能。源代码和训练模型将在论文接受后发布。]]></description>
      <guid>https://arxiv.org/abs/2405.02659</guid>
      <pubDate>Tue, 07 May 2024 06:18:03 GMT</pubDate>
    </item>
    <item>
      <title>Astro-NER——天文学命名实体识别：GPT 是一个好的领域专家注释器吗？</title>
      <link>https://arxiv.org/abs/2405.02602</link>
      <description><![CDATA[arXiv:2405.02602v1 公告类型：新
摘要：在这项研究中，我们解决了为学术领域开发 NER 模型的挑战之一，即缺乏合适的标记数据。我们尝试了一种方法，使用微调的法学硕士模型的预测来帮助非领域专家注释天文学文献中的科学实体，目的是揭示这样的协作过程是否可以近似领域专业知识。我们的结果揭示了领域专家和法学硕士辅助的非专家之间的适度一致性，以及领域专家和法学硕士模型的预测之间的公平一致性。在另一个实验中，我们比较了微调法学硕士和默认法学硕士在此任务上的性能。我们还引入了专门的天文学科学实体注释方案，并由领域专家验证。我们的方法采用以学术研究贡献为中心的视角，专门关注与研究主题相关的科学实体。由此产生的数据集包含 5,000 篇带注释的天文学文章标题，并已公开发布。]]></description>
      <guid>https://arxiv.org/abs/2405.02602</guid>
      <pubDate>Tue, 07 May 2024 06:18:02 GMT</pubDate>
    </item>
    <item>
      <title>使用主题建模识别大屠杀证词中的叙事模式和异常值</title>
      <link>https://arxiv.org/abs/2405.02650</link>
      <description><![CDATA[arXiv:2405.02650v1 公告类型：新
摘要：大量大屠杀幸存者的证词提供了宝贵的历史见解，但对手动分析提出了挑战。本文利用先进的自然语言处理 (NLP) 技术来探索南加州大学大屠杀基金会大屠杀证词语料库。通过将证词视为结构化问答部分，我们应用主题建模来识别关键主题。我们对 BERTopic 进行了实验，它利用了语言建模技术的最新进展。我们将证词部分排列成固定部分，揭示证词语料库中主题的演变。这凸显了共同的叙事模式以及基于年龄和性别的亚组之间的差异。我们引入了一种新颖的方法来识别表现出与其他群体相似的非典型主题分布的群体内的证词。这项研究为大屠杀幸存者的复杂叙述提供了独特的见解，展示了 NLP 阐明历史话语和识别幸存者经历中潜在偏差的力量。]]></description>
      <guid>https://arxiv.org/abs/2405.02650</guid>
      <pubDate>Tue, 07 May 2024 06:18:02 GMT</pubDate>
    </item>
    <item>
      <title>BERT 和 Transformer 的结合用于越南语拼写纠正</title>
      <link>https://arxiv.org/abs/2405.02573</link>
      <description><![CDATA[arXiv:2405.02573v1 公告类型：新
摘要：最近，许多研究表明在各种自然语言处理（NLP）任务中使用 Transformers 双向编码器表示（BERT）的效率。具体来说，使用 Encoder-Decoder 架构并利用 BERT 的英语拼写纠正任务取得了最先进的结果。然而，据我们所知，越南语尚未实施。因此，在本研究中，提出了 Transformer 架构（编码器-解码器模型的最新技术）和 BERT 的组合来处理越南语拼写校正。实验结果表明，我们的模型优于其他方法以及 Google Docs 拼写检查工具，在此任务上获得了 86.24 BLEU 分数。]]></description>
      <guid>https://arxiv.org/abs/2405.02573</guid>
      <pubDate>Tue, 07 May 2024 06:18:01 GMT</pubDate>
    </item>
    <item>
      <title>Mixat：阿联酋语-英语双语语音数据集</title>
      <link>https://arxiv.org/abs/2405.02578</link>
      <description><![CDATA[arXiv:2405.02578v1 公告类型：新
摘要：本文介绍了 Mixat：阿联酋语音代码与英语混合的数据集。 Mixat 的开发是为了解决当前语音识别资源在应用于阿联酋语音时的缺点，特别是应用于经常在当地方言和英语之间混合和切换的双语阿联酋语使用者。该数据集包含来自两个以阿联酋本地人为主角的公共播客的 15 小时语音，其中一个是主持人和嘉宾之间对话的形式。因此，该集合包含在正式和自然对话环境中阿联酋语-英语语码转换的示例。在本文中，我们描述了数据收集和注释的过程，并描述了所得数据集的一些特征和统计数据。此外，我们还评估了预训练的阿拉伯语和多语言 ASR 系统在我们的数据集上的性能，展示了现有模型在这种资源匮乏的阿拉伯语方言上的缺点，以及识别 ASR 中的语码转换的额外挑战。该数据集将公开供研究使用。]]></description>
      <guid>https://arxiv.org/abs/2405.02578</guid>
      <pubDate>Tue, 07 May 2024 06:18:01 GMT</pubDate>
    </item>
    <item>
      <title>Mothman 在 SemEval-2024 任务 9：思想链提示优化的迭代系统</title>
      <link>https://arxiv.org/abs/2405.02517</link>
      <description><![CDATA[arXiv:2405.02517v1 公告类型：新
摘要：对大型语言模型在基于逻辑的任务上的性能进行了广泛的研究，而对它们在横向思维任务上生成创造性解决方案的能力的研究相对较少。 BrainTeaser 共享任务测试横向思维，并使用对抗性数据集来防止记忆，导致开箱即用模型的性能不佳。我们提出了一种迭代式、思维链式提示工程系统，该系统使用人工评估来优化提示。使用此共享任务，我们展示了我们的系统通过优化提示和评估输入数据集来显着提高模型性能的能力。]]></description>
      <guid>https://arxiv.org/abs/2405.02517</guid>
      <pubDate>Tue, 07 May 2024 06:18:00 GMT</pubDate>
    </item>
    <item>
      <title>医疗保健中生成大语言模型的人类评估的文献综述和框架</title>
      <link>https://arxiv.org/abs/2405.02559</link>
      <description><![CDATA[arXiv:2405.02559v1 公告类型：新
摘要：随着生成人工智能（AI），特别是大型语言模型（LLM）继续渗透到医疗保健领域，用人类专家评估来补充传统的自动化评估仍然至关重要。理解和评估生成的文本对于确保安全性、可靠性和有效性至关重要。然而，人工评估的繁琐、耗时和非标准化性质对法学硕士在实践中的广泛采用构成了重大障碍。本研究回顾了医疗保健领域法学硕士人类评估方法的现有文献。我们强调对标准化和一致的人类评估方法的显着需求。我们遵循系统评价和荟萃分析的首选报告项目 (PRISMA) 指南，进行了广泛的文献检索，涵盖 2018 年 1 月至 2024 年 2 月的出版物。这篇综述全面概述了各种医疗保健应用中使用的人类评估方法。分析检查了各个医学专业的法学硕士的人工评估，涉及评估维度、样本类型和规模、评估人员的选择和招聘、框架和指标、评估过程以及结果的统计分析等因素。借鉴这些研究中强调的各种评估策略，我们提出了一个全面且实用的生成式法学硕士人类评估框架，名为 QUEST：信息质量、理解和推理、表达风格和角色、安全和伤害以及信任和信心。该框架旨在通过定义明确的评估维度并提供详细的指南，提高不同医疗保健应用中生成法学硕士人类评估的可靠性、普遍性和适用性。]]></description>
      <guid>https://arxiv.org/abs/2405.02559</guid>
      <pubDate>Tue, 07 May 2024 06:18:00 GMT</pubDate>
    </item>
    <item>
      <title>情感对语言模型意味着什么？</title>
      <link>https://arxiv.org/abs/2405.02454</link>
      <description><![CDATA[arXiv:2405.02454v1 公告类型：新
摘要：情感分析是文本分析中最广泛使用的技术之一。大型语言模型的最新进展使其比以往任何时候都更加准确和易于访问，使研究人员能够仅使用简单的英语提示对文本进行分类。然而，“情绪”包含各种各样的概念，具体取决于所使用的领域和工具。它被用来表示情绪、观点、市场动向，或者只是一个一般的“好坏”维度。这就提出了一个问题：当提示根据情绪标记文档时，语言模型究竟在做什么？本文首先概述了情绪在不同语境中的定义方式，强调它是一种复杂的测量结构，因为它包含多个变量，例如情绪价和观点，而没有将它们区分开来。然后，我在两个数据集上测试了三种语言模型，提示要求进行情绪、价和立场分类。我发现情绪标签与价标签的相关性最强。我还发现，当研究人员更精确地指定他们感兴趣的维度，而不是使用定义不太明确的情绪概念时，分类会得到改善。最后，我鼓励研究人员在可行的情况下超越“情绪”，并使用更精确的测量结构。]]></description>
      <guid>https://arxiv.org/abs/2405.02454</guid>
      <pubDate>Tue, 07 May 2024 06:17:59 GMT</pubDate>
    </item>
    <item>
      <title>语义缩放：大型语言模型的贝叶斯理想点估计</title>
      <link>https://arxiv.org/abs/2405.02472</link>
      <description><![CDATA[arXiv:2405.02472v1 公告类型：新
摘要：本文介绍了“语义缩放”，这是一种从文本中估计理想点的新方法。我利用大型语言模型根据文档表达的立场对文档进行分类，并提取类似调查的数据。然后，我使用项目反应理论来根据这些数据来衡量主题。语义尺度显着改进了现有的基于文本的尺度方法，并允许研究人员明确定义他们测量的意识形态维度。这代表了第一种扩展方法，允许在调查工具之外实现这种灵活性，并为难以调查的人群开辟新的调查途径。此外，它还可以处理不同长度的文档，并对大众和精英意识形态进行有效的估计。我证明该方法可以区分政策偏好和群体内/群体外影响。在公众中，根据人类判断，语义扩展的表现优于 Tweetscore；在国会，它重新获得了 DW-NOMINATE 的第一个维度，同时在解决结构有效性挑战方面提供了更大的灵活性。]]></description>
      <guid>https://arxiv.org/abs/2405.02472</guid>
      <pubDate>Tue, 07 May 2024 06:17:59 GMT</pubDate>
    </item>
    <item>
      <title>超越有用和无害：通过角色情境学习从大型语言模型中引发多种行为</title>
      <link>https://arxiv.org/abs/2405.02501</link>
      <description><![CDATA[arXiv:2405.02501v1 公告类型：新
摘要：大型语言模型（LLM）是在海量文本语料库上进行训练的，这些文本语料库编码有不同的个性特征。这引发了一个有趣的目标，即从法学硕士中引出所需的人格特质，并探究其行为偏好。因此，我们将角色启发任务形式化，旨在定制 LLM 行为以与目标角色保持一致。我们提出了人物角色情境学习（PICLe），这是一种基于贝叶斯推理的新颖人物角色启发框架。 PICLe 的核心引入了一种基于似然比的新 ICL 示例选择标准，旨在最佳地指导模型引出特定的目标人物角色。我们通过与三个当代法学硕士的基线方法的广泛比较来证明 PICLe 的有效性。代码可在 https://github.com/deeplearning-wisc/picle 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.02501</guid>
      <pubDate>Tue, 07 May 2024 06:17:59 GMT</pubDate>
    </item>
    <item>
      <title>呼唤具有社会意识的语言技术</title>
      <link>https://arxiv.org/abs/2405.02411</link>
      <description><![CDATA[arXiv:2405.02411v1 公告类型：新
摘要：语言技术取得了巨大进步，特别是随着大型语言模型（LLM）的引入。在机器翻译和情感分析等传统任务上，这些模型的表现接近人类水平。然而，这些进步可能会加剧传统上模型难以解决的各种问题，例如偏差、评估和风险。在这篇立场文件中，我们认为许多这些问题都有一个共同的核心：缺乏对 NLP 运作的社会环境的因素、背景和影响的认识，我们称之为社会意识。虽然 NLP 在解决形式语言问题方面做得越来越好，但在增加语言应用程序在所有情况下为所有用户工作所需的社会意识方面取得的进展有限。将社会意识融入 NLP 模型将使应用程序更加自然、有用和安全，并将开辟新的可能性。因此，我们认为 NLP 发展社会意识仍然面临巨大挑战，而且我们正处于该领域新时代的开始。]]></description>
      <guid>https://arxiv.org/abs/2405.02411</guid>
      <pubDate>Tue, 07 May 2024 06:17:58 GMT</pubDate>
    </item>
    <item>
      <title>知识神经元论文与知识有什么关系？</title>
      <link>https://arxiv.org/abs/2405.02421</link>
      <description><![CDATA[arXiv:2405.02421v1 公告类型：新
摘要：我们重新评估了知识神经元 (KN) 论文：对大型语言模型从训练语料库中回忆事实的能力的机制的解释。这篇新兴的论文提出，事实是通过 MLP 权重以类似于键值记忆的方式从训练语料库中回忆出来的，这实际上意味着“知识”存储在网络中。此外，通过修改 MLP 模块，可以控制语言模型的事实信息生成。KN 启发式模型编辑方法的成功证明了 KN 论文的合理性（Dai 等人，2022 年；Meng 等人，2022 年）。
我们发现，这篇论文充其量只是一种过度简化。我们不仅发现可以使用相同的模型编辑方法来编辑某些语言现象的表达，而且通过更全面的评估，我们发现 KN 论题无法充分解释事实表达的过程。虽然可以说 MLP 权重存储了可在句法和语义上解释的复杂模式，但这些模式并不构成“知识”。为了更全面地了解知识表示过程，我们必须超越 MLP 权重，探索近期模型的复杂层结构和注意力机制。]]></description>
      <guid>https://arxiv.org/abs/2405.02421</guid>
      <pubDate>Tue, 07 May 2024 06:17:58 GMT</pubDate>
    </item>
    <item>
      <title>NL2FOL：将自然语言转换为一阶逻辑以进行逻辑谬误检测</title>
      <link>https://arxiv.org/abs/2405.02318</link>
      <description><![CDATA[arXiv:2405.02318v1 公告类型：新
摘要：逻辑谬误是推理中常见的错误，会破坏论证的逻辑。自动检测逻辑谬误在跟踪错误信息和验证主张方面具有重要应用。在本文中，我们设计了一个通过使用大型语言模型（LLM）将自然语言逐步转换为一阶逻辑（FOL）来可靠地检测逻辑谬误的过程。然后，我们利用可满足性模理论 (SMT) 求解器来推理公式的有效性，并将输入分类为谬误或有效陈述。我们的模型还提供了一种利用 LLM 解释 SMT 求解器输出的新颖方法，提供对反例的见解，说明为什么给定的句子被认为是逻辑谬误。我们的方法是稳健的、可解释的，并且不需要训练数据或微调。我们在谬误和有效句子的混合数据集上评估我们的模型。结果表明，与端到端 LLM 相比，我们的分类器在逻辑数据集上实现了 71% 的 F1 分数。该方法能够有效地泛化，在 LogicClimate 挑战集上取得了 73% 的 F1 分数，尽管其尺寸要小得多，但比最先进的模型高出 21%。]]></description>
      <guid>https://arxiv.org/abs/2405.02318</guid>
      <pubDate>Tue, 07 May 2024 06:17:57 GMT</pubDate>
    </item>
    <item>
      <title>早期变形金刚：通过早鸟彩票高效训练变形金刚模型的研究</title>
      <link>https://arxiv.org/abs/2405.02353</link>
      <description><![CDATA[arXiv:2405.02353v1 公告类型：新
摘要：Transformer 模型的训练彻底改变了自然语言处理和计算机视觉，但它仍然是一个资源密集型且耗时的过程。本文研究了早鸟票假设在优化 Transformer 模型训练效率方面的适用性。我们提出了一种结合迭代剪枝、屏蔽距离计算和选择性再训练的方法，以识别各种 Transformer 架构（包括 ViT、Swin-T、GPT-2 和 RoBERTa）中的早鸟票。我们的实验结果表明，可以在训练或微调的前几个时期内一致地找到早鸟票，从而在不影响性能的情况下实现显着的资源优化。从早鸟票中获得的修剪后的模型与未修剪的模型相比，具有相当甚至更高的准确性，同时大大减少了内存使用。此外，我们的比较分析强调了早鸟票现象在不同 Transformer 模型和任务中的普遍性。这项研究有助于开发 Transformer 模型的有效训练策略，使它们更易于访问且资源友好。通过利用早鸟票，从业者可以加速自然语言处理和计算机视觉应用的进展，同时减少与训练 Transformer 模型相关的计算负担。]]></description>
      <guid>https://arxiv.org/abs/2405.02353</guid>
      <pubDate>Tue, 07 May 2024 06:17:57 GMT</pubDate>
    </item>
    </channel>
</rss>