<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 27 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>简化 X 射线检查：以通俗易懂的语言生成和评估放射学报告</title>
      <link>https://arxiv.org/abs/2406.17911</link>
      <description><![CDATA[arXiv:2406.17911v1 公告类型：新
摘要：随着多模态生成模型的进步，放射学报告生成 (RRG) 取得了重大进展。然而，该领域的评估缺乏公平和稳健的指标。我们发现，使用现有的基于词汇的指标（例如 BLEU）在 RRG 上取得高性能可能更像是海市蜃楼——模型只有通过学习报告模板才能获得高 BLEU。由于这些报告的高度模式化性质，这已成为 RRG 面临的一个紧迫问题。在这项工作中，我们通过提出 Layman&#39;s RRG 框架（一个基于外行术语的数据集、评估和训练框架）来非直观地解决这个问题，该框架使用日常语言系统地改进 RRG。我们首先贡献翻译后的 Layman&#39;s 术语数据集。在此数据集的基础上，我们提出了一种基于语义的评估方法，该方法被证明可以减轻 BLEU 的虚高数字并提供更公平的评估。最后，我们表明，在通俗易懂的数据集上进行训练可以鼓励模型专注于报告的语义，而不是过度拟合以学习报告模板。与原始格式带来的逆模式相比，我们发现了训练示例数量与数据集提供的语义增益之间的有希望的缩放规律。我们的代码可在 \url{https://github.com/hegehongcha/LaymanRRG} 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.17911</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:25 GMT</pubDate>
    </item>
    <item>
      <title>脚本无关的语言识别</title>
      <link>https://arxiv.org/abs/2406.17901</link>
      <description><![CDATA[arXiv:2406.17901v1 公告类型：新
摘要：语言识别是许多数据收集和抓取工作的第一步，因为它允许我们将在线文本分类到特定于语言的存储桶中。然而，许多现代语言，如孔卡尼语、克什米尔语、旁遮普语等，都是用几种脚本同时书写的。此外，具有不同书写系统的语言在神经表征空间中不具有重要的词汇、语义和句法属性，这对于密切相关的语言和资源匮乏的语言，尤其是来自印度次大陆的语言来说是一个劣势。为了解决这个问题，我们建议使用几种不同的实验策略（升级、扁平化和脚本混合）学习与脚本无关的表示，重点关注四种主要的达罗毗荼语言（泰米尔语、泰卢固语、卡纳达语和马拉雅拉姆语）。我们发现，单词级脚本随机化和接触用多种脚本编写的语言对于下游与脚本无关的语言识别非常有价值，同时还能在自然出现的文本上保持竞争性能。]]></description>
      <guid>https://arxiv.org/abs/2406.17901</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:24 GMT</pubDate>
    </item>
    <item>
      <title>绘制过去：将 20 世纪早期的瑞典百科全书与维基数据进行地理链接</title>
      <link>https://arxiv.org/abs/2406.17903</link>
      <description><![CDATA[arXiv:2406.17903v1 公告类型：新
摘要：在本文中，我们描述了从 20 世纪早期著名的瑞典百科全书 \textit{Nordisk Familjebok}“北欧家庭书”中提取所有位置条目的过程。我们重点研究了第二版 \textit{Uggleupplagan}，该百科全书包含 38 卷和超过 182,000 篇文章。这使它成为最全面的瑞典百科全书之一。使用分类器，我们首先确定了条目的类别。我们发现其中大约 22% 是位置。我们对这些条目应用了命名实体识别，并将它们链接到 Wikidata。Wikidata 使我们能够提取它们的精确地理位置，从而获得近 18,000 个有效坐标。然后，我们分析了这些位置的分布和条目选择过程。结果显示瑞典、德国和英国的密度较高。本文阐明了 \textit{Nordisk Familjebok} 中地理信息的选择和表示，提供了历史和社会视角的见解。它还为未来研究不同时期的条目选择和各种百科全书之间的比较分析奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2406.17903</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:24 GMT</pubDate>
    </item>
    <item>
      <title>隐形分类器：敏感分类任务中的假名化策略</title>
      <link>https://arxiv.org/abs/2406.17875</link>
      <description><![CDATA[arXiv:2406.17875v1 公告类型：新
摘要：共享数据时保护隐私至关重要，尤其是在可能包含个人信息的在线激进化数据集的情况下。在本文中，我们探讨了在保留数据有用性和确保强大的隐私保护措施之间的平衡，因为欧洲 GDPR 等法规规定了必须如何处理个人信息。我们分享了手动假名化多语言激进化数据集的方法，确保性能与原始数据相当。此外，我们通过分享我们的完整假名化过程、我们的指南、我们遇到的挑战以及生成的数据集，强调了建立处理敏感 NLP 数据的全面指南的重要性。]]></description>
      <guid>https://arxiv.org/abs/2406.17875</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:23 GMT</pubDate>
    </item>
    <item>
      <title>CTBench：评估临床试验设计中语言模型能力的综合基准</title>
      <link>https://arxiv.org/abs/2406.17888</link>
      <description><![CDATA[arXiv:2406.17888v1 公告类型：新
摘要：CTBench 被引入作为评估语言模型 (LM) 在辅助临床研究设计中的基准。给定研究特定的元数据，CTBench 评估 AI 模型确定临床试验 (CT) 基线特征的能力，其中包括试验开始时从所有参与者收集的人口统计和相关特征。这些基线特征通常在 CT 出版物中呈现（通常为表 1），对于表征研究队列和验证结果至关重要。基线特征（包括混杂因素和协变量）对于涉及观察数据的研究中准确估计治疗效果也是必要的。CTBench 由两个数据集组成：“CT-Repo”，包含来自 clinicaltrials.gov 的 1,690 项临床试验的基线特征，以及“CT-Pub”，这是从相关出版物中收集的 100 项试验的子集，具有更全面的基线特征。开发了两种基于 LM 的评估方法来比较实际的基线特征列表与 LM 生成的响应。 “ListMatch-LM”和“ListMatch-BERT”分别使用 GPT-4o 和 BERT 分数（在不同阈值下）进行评估。为了建立基线结果，在零样本和三样本学习设置中使用 LLaMa3-70B-Instruct 和 GPT-4o 的高级提示工程技术被应用来生成潜在的基线特征。GPT-4o 作为评估器的性能通过对 CT-Pub 数据集的人机交互评估得到验证，其中临床专家确认实际特征和 LM 生成的特征之间的匹配。结果突出了一个有希望的方向，具有巨大的改进潜力，将 CTBench 定位为推进 CT 设计中 AI 研究的有用工具，并可能提高 CT 的功效和稳健性。]]></description>
      <guid>https://arxiv.org/abs/2406.17888</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN、双向 LSTM 和 ResNet 对尼泊尔语进行自动语音识别</title>
      <link>https://arxiv.org/abs/2406.17825</link>
      <description><![CDATA[arXiv:2406.17825v1 公告类型：新
摘要：本文介绍了一种用于自动语音识别 (ASR) 的端到端深度学习模型，可将尼泊尔语语音转录为文本。该模型在 OpenSLR（音频、文本）数据集上进行了训练和测试。大多数音频数据集的两端都有静音间隙，这些间隙在数据集预处理期间被剪切，以便更均匀地映射音频帧及其对应的文本。梅尔频率倒谱系数 (MFCC) 用作音频特征以输入模型。在迄今为止训练的所有模型（具有 LSTM、GRU、CNN 和 ResNet 变体的神经网络）中，具有双向 LSTM 与 ResNet 配对的模型为该数据集产生了最佳结果。这种新模型使用连接时间分类 (CTC) 函数在训练期间进行损失计算，并使用 CTC 波束搜索解码来预测字符是尼泊尔文本中最可能的序列。在测试数据集上，字符错误率（CER）已达到 17.06%。源代码可从以下网址获取：https://github.com/manishdhakal/ASR-Nepali-using-CNN-BiLSTM-ResNet。]]></description>
      <guid>https://arxiv.org/abs/2406.17825</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:22 GMT</pubDate>
    </item>
    <item>
      <title>通过关系元组、验证和动态反馈提高大型语言模型的算术推理能力</title>
      <link>https://arxiv.org/abs/2406.17873</link>
      <description><![CDATA[arXiv:2406.17873v1 公告类型：新
摘要：目前大型语言模型的推理步骤中使用的表示形式主要可以分为两大类：（1）自然语言，难以验证；（2）非自然语言，通常是编程代码，对于不熟悉编码的人来说很难阅读。在本文中，我们提出使用半结构化形式来表示大型语言模型的推理步骤。具体来说，我们使用关系元组，它不仅易于人类阅读，而且对机器友好，并且比自然语言更容易验证。我们实现了一个框架，其中包括三个主要组件：（1）将关系元组引入大型语言模型的推理步骤；（2）使用基于关系元组的本地代码解释器实现推理步骤的自动验证过程；（3）集成简单有效的动态反馈机制，我们发现这有助于大型语言模型的自我改进。在各种算术数据集上的实验结果证明了我们的方法在提高大型语言模型的算术推理能力方面的有效性。源代码可从https://github.com/gpgg/art获取。]]></description>
      <guid>https://arxiv.org/abs/2406.17873</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:22 GMT</pubDate>
    </item>
    <item>
      <title>增强不完全信息纸牌游戏的评论策略：《关单评论》大型语言模型研究</title>
      <link>https://arxiv.org/abs/2406.17807</link>
      <description><![CDATA[arXiv:2406.17807v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展释放了生成高质量游戏评论的潜力。然而，为信息不完整的复杂游戏制作富有洞察力和吸引力的评论仍然是一项重大挑战。在本文中，我们介绍了一种结合强化学习 (RL) 和 LLM 的新型评论方法，专门针对中国纸牌游戏 \textit{关丹}。我们的系统利用 RL 生成复杂的纸牌游戏场景，并使用 LLM 生成相应的评论文本，有效地模仿专业评论员的战略分析和叙事能力。该框架包括一个状态评论指南、一个基于心智理论 (ToM) 的策略分析器和一个风格检索模块，它们无缝协作以在中文环境中提供详细且与上下文相关的游戏评论。我们为 LLM 赋予 ToM 功能，并改进检索和信息过滤机制。这有助于生成个性化的评论内容。我们的实验结果显示，所提出的评论框架应用于开源 LLM 时取得了显著的性能提升，在多个评估指标上超越了 GPT-4 的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.17807</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:21 GMT</pubDate>
    </item>
    <item>
      <title>带有级联 KV 缓存的滑动窗口上下文的免训练指数扩展</title>
      <link>https://arxiv.org/abs/2406.17808</link>
      <description><![CDATA[arXiv:2406.17808v1 公告类型：新
摘要：Transformer 中的上下文窗口为当前任务提供了一种活动内存形式，这对于小样本学习和条件生成非常有用，这两者都严重依赖于先前的上下文标记。但是，随着上下文长度的增加，计算成本会成倍增加。最近的研究表明，在基于 Transformer 的大型语言模型 (LLM) 中，保存一些初始标记以及固定大小的滑动窗口可以实现具有线性复杂度的稳定流式生成。但是，它们通过天真地将所有标记从键值 (KV) 缓存中无条件地逐出，一旦它们到达窗口末尾，它们就会对固定窗口的使用不尽如人意，导致标记被遗忘并且不再能够影响后续预测。为了克服这一限制，我们提出了一种新颖的机制，通过保留单独的级联子缓存缓冲区来存储具有相同总缓存大小的更长的滑动窗口上下文，其中每个后续缓冲区有条件地接受从前一个缓冲区逐出的相对更重要的标记的一小部分。我们的方法可以生成动态 KV 缓存，与固定的静态滑动窗口方法相比，它可以存储更久远的标记。我们的实验表明，在给定相同固定缓存大小的情况下，使用 LLM，长上下文生成 (LongBench) 的改进为 5.6%，流式困惑度 (PG19) 的改进为 1.2%，语言理解 (MMLU STEM) 的改进为 0.6%。此外，我们还提供了一种高效的实现，将 KV 缓存延迟从每次缓存操作 1.33 毫秒缩短至 0.54 毫秒，比以前的工作速度提高了 59%。]]></description>
      <guid>https://arxiv.org/abs/2406.17808</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:21 GMT</pubDate>
    </item>
    <item>
      <title>LLM 能否使用无数据提示生成可视化效果？</title>
      <link>https://arxiv.org/abs/2406.17805</link>
      <description><![CDATA[arXiv:2406.17805v1 公告类型：新
摘要：大型语言模型的最新进展彻底改变了信息访问方式，因为这些模型利用网络上可用的数据来解决复杂的查询，成为许多用户的首选信息来源。在某些情况下，查询是关于公开可用的数据的，可以通过数据可视化有效地回答。在本文中，我们研究了大型语言模型为响应此类查询提供准确数据和相关可视化的能力。具体来说，我们研究了 GPT-3 和 GPT-4 生成无数据提示可视化的能力，其中查询不附带任何数据。我们通过将模型的结果与可视化专家创建的可视化备忘单进行比较来评估模型的结果。]]></description>
      <guid>https://arxiv.org/abs/2406.17805</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:20 GMT</pubDate>
    </item>
    <item>
      <title>MOSSBench：您的多模式语言模型是否对安全查询过于敏感？</title>
      <link>https://arxiv.org/abs/2406.17806</link>
      <description><![CDATA[arXiv:2406.17806v1 公告类型：新
摘要：人类容易出现认知扭曲——偏见的思维模式会导致对特定刺激做出夸张的反应，尽管是在非常不同的背景下。本文表明，先进的多模态大型语言模型 (MLLM) 表现出类似的趋势。虽然这些模型旨在在安全机制下响应查询，但它们有时会在某些视觉刺激的情况下拒绝无害的查询，而忽略其上下文的良性性质。作为调查这种行为的第一步，我们确定了三种触发现有 MLLM 过度敏感的刺激类型：夸大风险、否定危害和违反直觉的解释。为了系统地评估 MLLM 对这些刺激的过度敏感性，我们提出了多模态过度敏感基准 (MOSSBench)。该工具包包含 300 个手动收集的良性多模态查询，并由第三方审阅者 (AMT) 进行交叉验证。使用 MOSSBench 对 20 个 MLLM 进行的实证研究揭示了以下几点见解：(1)。过度敏感在 SOTA MLLM 中普遍存在，无害查询的拒绝率高达 76%。(2)。更安全的模型更过度敏感：提高安全性可能会无意中提高模型响应的谨慎性和保守性。(3)。不同类型的刺激往往会在 MLLM 响应过程的特定阶段（感知、意图推理和安全判断）导致错误。这些发现强调了对完善安全机制的需求，该机制可在谨慎性和适合情境的响应之间取得平衡，从而提高 MLLM 在实际应用中的可靠性。我们的项目可在 https://turningpoint-ai.github.io/MOSSBench/ 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.17806</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:20 GMT</pubDate>
    </item>
    <item>
      <title>Mashee 在 SemEval-2024 任务 8 中：样本质量对机器文本分类上下文学习性能的影响</title>
      <link>https://arxiv.org/abs/2406.17790</link>
      <description><![CDATA[arXiv:2406.17790v1 公告类型：新
摘要：在小样本学习中，上下文学习 (ICL) 已成为一种利用上下文信息来提高模型在少量数据或资源受限环境中的性能的潜在方法，在这些环境中，大型数据集上的训练模型是令人望而却步的。然而，少数样本中所选样本的质量严重限制了 ICL 的实用性。本文的主要目标是通过在小样本学习场景中选择高质量样本来提高上下文学习评估指标的性能。我们使用卡方检验来识别高质量样本，并将结果与​​使用低质量样本获得的结果进行比较。我们的研究结果表明，利用高质量样本可以提高所有评估指标的性能。]]></description>
      <guid>https://arxiv.org/abs/2406.17790</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:19 GMT</pubDate>
    </item>
    <item>
      <title>了解用户资料在大型语言模型个性化中的作用</title>
      <link>https://arxiv.org/abs/2406.17803</link>
      <description><![CDATA[arXiv:2406.17803v1 公告类型：新
摘要：利用用户配置文件对大型语言模型 (LLM) 进行个性化已被证明可以提高各种任务的性能。然而，用户配置文件的确切作用及其对 LLM 的影响机制仍不清楚。本研究首先证实了用户配置文件的有效性主要归因于个性化信息而不是语义信息。此外，我们研究了用户配置文件如何影响 LLM 的个性化。在用户配置文件中，我们发现用户生成或批准的历史个性化响应在 LLM 的个性化中起着关键作用。这一发现释放了 LLM 在有限输入长度的限制内整合更多用户配置文件的潜力。至于用户配置文件的位置，我们观察到集成到输入上下文不同位置的用户配置文件对个性化的贡献并不相同。相反，更接近开头的用户配置文件对 LLM 的个性化影响更大。我们的研究结果揭示了用户资料在 LLM 个性化中的作用，并展示了整合用户资料如何影响性能，从而提供了有效利用用户资料的洞察力。]]></description>
      <guid>https://arxiv.org/abs/2406.17803</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:19 GMT</pubDate>
    </item>
    <item>
      <title>西班牙语和 LLM 基准：MMLU 是否在翻译中丢失了？</title>
      <link>https://arxiv.org/abs/2406.17789</link>
      <description><![CDATA[arXiv:2406.17789v1 公告类型：新 
摘要：大型语言模型 (LLM) 的评估是其持续改进过程中的关键要素，并且已经开发了许多基准来评估 LLM 在不同任务和主题中的表现。随着 LLM 在世界范围内被采用，用英语以外的语言对它们进行评估变得越来越重要。然而，大多数 LLM 基准只是使用自动化工具翻译，然后在目标语言中运行。这意味着结果不仅取决于该语言的 LLM 性能，还取决于翻译的质量。在本文中，我们考虑了著名的大规模多任务语言理解 (MMLU) 基准的情况。使用 Azure Translator 和 ChatGPT4 将基准的选定类别翻译成西班牙语并在 ChatGPT4 上运行。接下来，对结果进行处理以识别在西班牙语和英语中产生不同答案的测试项目。然后手动分析这些内容以了解自动翻译是否导致了变化。结果表明，不及格试题的很大一部分可以归因于基准翻译中的错误。这些结果有力地证明了改进英语以外语言的基准的必要性，至少需要修改试题的翻译，最好由专家根据目标语言调整测试。]]></description>
      <guid>https://arxiv.org/abs/2406.17789</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:18 GMT</pubDate>
    </item>
    <item>
      <title>依赖距离在文本简化中的作用：人类与 ChatGPT 简化比较</title>
      <link>https://arxiv.org/abs/2406.17787</link>
      <description><![CDATA[arXiv:2406.17787v1 公告类型：新
摘要：本研究调查了人类和 ChatGPT 文本简化及其与依赖距离的关系。人类专家使用 ChatGPT 简化了一组 220 个句子，这些句子的语法难度在之前的用户研究中不断增加。我们发现这三个句子集的平均依赖距离都不同：原始句子集最高，其次是 ChatGPT 简化句子，而人类简化句子的平均依赖距离最低。]]></description>
      <guid>https://arxiv.org/abs/2406.17787</guid>
      <pubDate>Thu, 27 Jun 2024 06:19:17 GMT</pubDate>
    </item>
    </channel>
</rss>