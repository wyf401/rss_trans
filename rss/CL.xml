<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 18 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>评估大型语言模型中的性别偏见</title>
      <link>https://arxiv.org/abs/2411.09826</link>
      <description><![CDATA[arXiv:2411.09826v1 公告类型：新
摘要：人工智能中的性别偏见已成为一个重要问题，特别是在面向通信的应用中使用的语言模型中。本研究考察了大型语言模型 (LLM) 在职业背景下的代词选择中表现出性别偏见的程度。该分析使用自生成的数据集评估了 GPT-4、GPT-4o、PaLM 2 Text Bison 和 Gemini 1.0 Pro 模型。考虑的工作包括一系列职业，从男性占主导地位的职业到女性集中度显著的职业，以及性别分布相对均衡的工作。使用三种不同的句子处理方法来评估潜在的性别偏见：掩码标记、未掩码句子和句子完成。此外，LLM 建议了特定职业的个人姓名，然后对其进行性别分布检查。结果显示，模型的代词选择与美国劳动力数据中的性别分布呈正相关。女性代词更常与女性占主导地位的职业相关，而男性代词更常与男性占主导地位的职业相关。句子完成与实际性别分布的相关性最强，而姓名生成则导致更平衡的“政治正确”性别分布，尽管以男性或女性为主的职业存在明显差异。总体而言，提示方法对性别分布的影响大于模型选择本身，这凸显了解决法学硕士性别偏见的复杂性。研究结果强调了提示在性别映射中的重要性。]]></description>
      <guid>https://arxiv.org/abs/2411.09826</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>长篇医学问答的基准</title>
      <link>https://arxiv.org/abs/2411.09834</link>
      <description><![CDATA[arXiv:2411.09834v1 公告类型：新
摘要：缺乏用于评估长篇医学问答 (QA) 中的大型语言模型 (LLM) 的基准。大多数现有的医学 QA 评估基准都侧重于自动指标和多项选择题。虽然这些基准很有价值，但它们未能完全捕捉或评估部署 LLM 的实际临床应用的复杂性。此外，现有的关于评估医学 QA 中长篇答案生成的研究主要是闭源的，缺乏对人类医学专家注释的访问，这使得很难重现结果并增强现有基线。在这项工作中，我们引入了一个新的公开基准，其中包含现实世界的消费者医学问题和由医生注释的长篇答案评估。我们根据正确性、有用性、有害性和偏见等标准对来自各种开源和闭源医学和通用 LLM 的响应进行了成对比较。此外，我们还进行了全面的 LLM-as-a-judge 分析，以研究人类判断与 LLM 之间的一致性。我们的初步结果突出了与领先的封闭模型相比，开放式 LLM 在医疗 QA 方面具有巨大潜力。代码和数据：https://github.com/lavita-ai/medical-eval-sphere]]></description>
      <guid>https://arxiv.org/abs/2411.09834</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KULCQ：一种基于关键词的无监督话语级别聚类质量度量</title>
      <link>https://arxiv.org/abs/2411.09853</link>
      <description><![CDATA[arXiv:2411.09853v1 公告类型：新
摘要：意图发现对于构建新的对话代理和改进现有的对话代理都至关重要。虽然已经提出了几种意图发现方法，但大多数方法都依赖于聚类将相似的话语分组在一起。对这些话语集群的传统评估需要为每个话语提供意图标签，从而限制了可扩展性。虽然存在一些不需要标记数据的聚类质量指标，但它们仅关注聚类几何，而忽略了对话记录中存在的语言细微差别。在本文中，我们介绍了基于关键字的话语级聚类质量 (KULCQ)，这是一种利用关键字分析来评估聚类质量的无监督指标。我们通过将 KULCQ 与现有的无监督聚类指标进行比较来证明其有效性，并通过全面的消融研究验证其性能。我们的结果表明，KULCQ 可以更好地捕获对话数据中的语义关系，同时保持与几何聚类原理的一致性。]]></description>
      <guid>https://arxiv.org/abs/2411.09853</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于插件扩展模块的领域中文拼写纠正方法研究</title>
      <link>https://arxiv.org/abs/2411.09884</link>
      <description><![CDATA[arXiv:2411.09884v1 公告类型：新
摘要：本文提出了一种基于插件扩展模块的中文拼写纠正方法，旨在解决现有模型在处理特定领域文本方面的局限性。传统的中文拼写纠正模型通常在通用领域数据集上进行训练，在遇到领域特定文本中的专业术语时表现不佳。为了解决这个问题，我们设计了一个扩展模块，可以学习领域特定术语的特征，从而增强模型在特定领域的纠正能力。该扩展模块可以在不影响模型的一般拼写纠正性能的情况下为模型提供领域知识，从而提高其在专业领域的准确性。实验结果表明，在集成医疗、法律和官方文档领域的扩展模块后，与没有任何扩展模块的基线模型相比，模型的纠正性能有显著提高。]]></description>
      <guid>https://arxiv.org/abs/2411.09884</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>根据调查评论精炼和细分价格情绪指数</title>
      <link>https://arxiv.org/abs/2411.09937</link>
      <description><![CDATA[arXiv:2411.09937v1 公告类型：新
摘要：我们旨在增强价格情绪指数，并从消费者和企业的角度更准确地了解价格趋势。我们从日本内阁府进行的经济观察者调查中提取与价格相关的评论，并使用大型语言模型 (LLM) 对价格趋势进行分类。我们利用经济观察者调查中受访者的评论领域和行业信息，对调查样本是否反映了消费者或企业的观点，以及评论是否与商品或服务有关进行分类。从这些分类的价格相关评论中，我们通过结合消费者和价格以及商品和服务的观点，不仅为一般目的而且为更具体的目标构建价格情绪指数。通过使用 LLM 进行分类，可以更准确地对价格方向进行分类。此外，整合多个 LLM 的输出表明分类性能可能更好。使用更准确的分类评论可以构建与现有指数相关性比以前的研究更高的指数。我们证明，通过根据调查受访者的行业来选择聚合评论，样本量更大的消费者价格指数的相关性会得到进一步增强。]]></description>
      <guid>https://arxiv.org/abs/2411.09937</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SlimLM：一种用于设备文档辅助的高效小型语言模型</title>
      <link>https://arxiv.org/abs/2411.09944</link>
      <description><![CDATA[arXiv:2411.09944v1 公告类型：新
摘要：虽然小型语言模型 (SLM) 有望应用于移动端，但它们在智能手机上的实际性能和应用仍未得到充分探索。我们介绍了 SlimLM，这是一系列针对移动设备上的文档辅助任务进行了优化的 SLM。通过在三星 Galaxy S24 上进行大量实验，我们确定了模型大小（从 125M 到 7B 参数）、上下文长度和推理时间之间的最佳权衡，以实现高效的设备处理。SlimLM 在 SlimPajama-627B 上进行了预训练，并在 DocAssist 上进行了微调，DocAssist 是我们为摘要、问答和建议任务构建的数据集。我们最小的模型在 S24 上表现出高效的性能，而更大的变体在移动限制内提供了增强的功能。我们根据现有的 SLM 评估了 SlimLM，显示出相当或更优越的性能，并为未来在设备上的语言模型方面的研究提供了基准。我们还提供了一个 Android 应用程序，为 SLM 部署提供了实用的见解。我们的研究结果提供了宝贵的见解，并阐明了在高端智能手机上运行高级语言模型的能力，有可能降低服务器成本并通过设备处理增强隐私。]]></description>
      <guid>https://arxiv.org/abs/2411.09944</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LoRA-LiteE：用于聊天机器人偏好调整的计算高效框架</title>
      <link>https://arxiv.org/abs/2411.09947</link>
      <description><![CDATA[arXiv:2411.09947v1 公告类型：新
摘要：有效的偏好调整对于使聊天机器人的响应与人类的期望保持一致、提高用户满意度和参与度至关重要。传统方法，尤其是在 GPT-4 等高级模型中采用的从人类反馈中强化学习 (RLHF)，已在该领域取得了相当大的成功。然而，RLHF 方法通常计算密集且资源要求高，限制了它们在更广泛应用中的可扩展性和可访问性。为了应对这些挑战，本研究引入了 LoRA-Lite Ensemble (LoRA-LiteE)，这是一个创新框架，它将监督微调 (SFT) 与低秩自适应 (LoRA) 和集成学习技术相结合，以有效地聚合轻量级模型的预测，旨在实现性能和计算成本之间的平衡。利用 Chatbot Arena 基准数据集，我们对我们的 LoRA-LiteE 模型、不同规模的相应基础模型和使用 RLHF 训练的 GPT-4 进行了全面的比较分析。我们的实证结果表明，所提出的 LoRA-LiteE 模型实现了与未微调的 GPT-4 相当的性能，并且在有限的资源约束下优于单个较大规模模型。这些发现突出表明，我们的 LoRA-LiteE 为聊天机器人系统中的人类偏好预测提供了一种可行且有效的方法，增强了可扩展性和可访问性，从而扩大了偏好调整聊天机器人在资源受限环境中的适用性。]]></description>
      <guid>https://arxiv.org/abs/2411.09947</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型作为评估面向任务的对话系统的用户代理</title>
      <link>https://arxiv.org/abs/2411.09972</link>
      <description><![CDATA[arXiv:2411.09972v1 公告类型：新
摘要：传统上，离线数据集已用于评估面向任务的对话 (TOD) 模型。这些数据集缺乏上下文感知，使其成为对话系统的次优基准。相比之下，具有上下文感知的用户代理可以模拟人类对话的多变性和不可预测性，使其成为更好的评估者替代方案。先前的研究已经利用大型语言模型 (LLM) 来开发用户代理。我们的工作在此基础上建立，使用 LLM 创建用户代理以评估 TOD 系统。这涉及提示 LLM、使用上下文示例作为指导以及跟踪用户目标状态。我们对用户代理的多样性和任务完成指标的评估表明，使用更好的提示可以提高性能。此外，我们提出了在此动态框架内自动评估 TOD 模型的方法。]]></description>
      <guid>https://arxiv.org/abs/2411.09972</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HistoLens：基于法学硕士的历史文本多层次分析框架——《燕铁论》案例应用</title>
      <link>https://arxiv.org/abs/2411.09978</link>
      <description><![CDATA[arXiv:2411.09978v1 Announce Type: new 
摘要：本文提出了基于大型语言模型（LLM）的历史文本多层分析框架HistoLens，并以西汉重要文献《燕铁论》为例，展示了该框架在历史研究和教育中的潜在应用。HistoLens集成了NLP技术（尤其是LLM），包括命名实体识别、知识图谱构建和地理信息可视化等。本文展示了HistoLens如何通过多维度、可视化和量化的方法探索《燕铁论》中的西汉文化，特别关注儒法思想对政治、经济、军事和民族的影响。我们还展示了HistoLens如何基于LLM辅助提取的儒法思想数据集，使用LLM构建可解释分析的机器教学场景。此方法为《燕铁论》等历史文献的研究提供了新颖而多元的视角，也为历史教育提供了新的辅助工具。此框架旨在为历史学家和学习者提供法学硕士辅助工具，以促进对历史文献进行深入、多层次的分析，并促进历史教育的创新。]]></description>
      <guid>https://arxiv.org/abs/2411.09978</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Orca：通过整合个性特征增强大型语言模型的角色扮演能力</title>
      <link>https://arxiv.org/abs/2411.10006</link>
      <description><![CDATA[arXiv:2411.10006v1 公告类型：新
摘要：大型语言模型催化了个性化对话系统的发展，出现了许多角色扮演对话代理。而以前的研究主要集中在通过设计角色资料来增强模型遵循指令的能力，而忽略了驱动人类对话的心理因素。在本文中，我们提出了Orca，这是一个通过整合性格特征来处理数据和训练自定义角色LLM的框架。Orca包括四个阶段：（1）性格特征推断，利用LLM推断用户的BigFive性格特征报告和分数。（2）数据增强，模拟用户的个人资料，背景故事和心理活动。（3）数据集构建，个性条件指令提示（PCIP）以刺激LLM。（4）建模和训练，个性条件指令调整（PTIT和PSIT），使用生成的数据增强现有的开源LLM。我们推出了 OrcaBench，这是第一个用于评估 LLM 在多个规模的社交平台上生成的内容质量的基准。我们的实验表明，我们提出的模型在这个基准上取得了优异的表现，证明了它在感知个性特征方面的卓越性和有效性，这显著提高了角色扮演能力。我们的代码可在 https://github.com/Aipura/Orca 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.10006</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>再一次感受：当代美国电影表演情感的测量</title>
      <link>https://arxiv.org/abs/2411.10018</link>
      <description><![CDATA[arXiv:2411.10018v1 公告类型：新
摘要：叙事电影是写作、摄影、剪辑和表演的结合体。虽然许多计算工作都集中在电影的写作或视觉风格上，但在本文中，我们进行了表演的计算探索。将语音情感识别模型和变异主义社会语言学分析框架应用于流行的当代美国电影语料库，我们发现叙事结构、历时转变以及基于类型和对话的限制都存在于口语表演中。]]></description>
      <guid>https://arxiv.org/abs/2411.10018</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从临床记录中提取信息：我们准备好转向大型语言模型了吗？</title>
      <link>https://arxiv.org/abs/2411.10020</link>
      <description><![CDATA[arXiv:2411.10020v1 公告类型：新 
摘要：背景：信息提取 (IE) 在临床自然语言处理 (NLP) 中至关重要。虽然大型语言模型 (LLM) 在生成任务上表现出色，但它们在提取任务上的表现仍存在争议。方法：我们使用来自四个来源（UT Physicians、MTSamples、MIMIC-III 和 i2b2）的 1,588 份临床记录研究了命名实体识别 (NER) 和关系提取 (RE)。我们开发了一个带注释的语料库，涵盖 4 个临床实体和 16 个修饰符，并在性能、通用性、计算资源和吞吐量方面将指令调整的 LLaMA-2 和 LLaMA-3 与 BiomedBERT 进行了比较。结果：LLaMA 模型在数据集上的表现优于 BiomedBERT。在有足够的训练数据的情况下，LLaMA 显示出适度的改进（NER 上为 1%，RE 上为 1.5-3.7%）；在训练数据有限的情况下，改进效果更大。在未见过的 i2b2 数据上，LLaMA-3-70B 在 NER 上比 BiomedBERT 高出 7% (F1)，在 RE 上比 BiomedBERT 高出 4%。然而，LLaMA 模型需要更多的计算资源，运行速度慢了 28 倍。我们实现了“Kiwi”，这是一个包含这两种模型的临床 IE 包，可在 https://kiwi.clinicalnlp.org/ 上获得。结论：这项研究是首批使用开源 LLM 开发和评估综合临床 IE 系统的研究之一。结果表明，LLaMA 模型在临床 NER 和 RE 方面的表现优于 BiomedBERT，但计算成本更高，吞吐量更低。这些发现强调，在临床 IE 应用中，选择 LLM 和传统深度学习方法应该保持针对特定任务，同时考虑性能指标和实际考虑因素，例如可用的计算资源和预期的用例场景。]]></description>
      <guid>https://arxiv.org/abs/2411.10020</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过增强激活方差稀疏性实现大型语言模型中的层重要性和幻觉分析</title>
      <link>https://arxiv.org/abs/2411.10069</link>
      <description><![CDATA[arXiv:2411.10069v1 公告类型：新
摘要：评估大型语言模型 (LLM) 中不同层的重要性对于优化模型性能和可解释性至关重要。本文首先使用激活方差-稀疏度分数 (AVSS) 探索层重要性，该分数结合了归一化的激活方差和稀疏度来量化每个层对整体模型性能的贡献。通过根据 AVSS 对层进行排名并修剪影响最小的 25%，我们在问答、语言建模和情感分类等任务上的实验表明，保留了 90% 以上的原始性能，突出了 LLM 架构中的潜在冗余。基于 AVSS，我们提出了一个增强版本，专门用于评估跨层幻觉倾向 (EAVSS)。这种改进的方法引入了幻觉特定激活方差 (HSAV) 和幻觉特定稀疏度 (HSS) 指标，可以精确识别容易产生幻觉的层。通过在这些层上加入对比学习，我们有效地缓解了幻觉的产生，有助于实现更稳健、更高效的 LLM（最大性能提升为 12%）。我们在 NQ、SciQ、TriviaQA、TruthfulQA 和 WikiQA 数据集上的结果证明了该方法的有效性，为 LLM 中的层重要性评估和幻觉缓解提供了一个全面的框架。]]></description>
      <guid>https://arxiv.org/abs/2411.10069</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>了解温度对与人类意见一致​​的影响</title>
      <link>https://arxiv.org/abs/2411.10080</link>
      <description><![CDATA[arXiv:2411.10080v1 公告类型：新
摘要：随着 LLM 功能的不断增强，最近的研究重点是了解它们代表了谁的观点以及如何有效地提取一致的观点分布。我们对三种获取分布的简单方法进行了实证分析，并根据各种指标评估了结果。我们的研究结果表明，与直接提示相比，使用简单参数调整的抽样和对数概率方法可以在主观任务中返回更一致的输出。然而，假设模型反映人类的观点可能会受到限制，这凸显了进一步研究人类主观性如何影响模型不确定性的必要性。]]></description>
      <guid>https://arxiv.org/abs/2411.10080</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Xmodel-1.5：1B 规模的多语言法学硕士</title>
      <link>https://arxiv.org/abs/2411.10083</link>
      <description><![CDATA[arXiv:2411.10083v1 公告类型：新
摘要：我们介绍了 Xmodel-1.5，这是一个新颖的 10 亿参数多语言大型模型，在约 2 万亿个标记上进行了预训练。该模型在多种语言中表现出色，在泰语、阿拉伯语和法语中表现尤为显著，同时在中文和英语中也表现出色。此外，我们还发布了一个泰语评估数据集，为研究界做出了贡献，该数据集包括朱拉隆功大学综合创新学院学生注释的数百个问题。虽然结果令人鼓舞，但我们承认仍有改进空间。我们希望这项工作能够推动多语言人工智能研究的持续努力，并促进各种自然语言处理任务中更好的跨语言理解。我们的模型和代码在 GitHub 上公开提供，网址为 https://github.com/XiaoduoAILab/XmodelLM。]]></description>
      <guid>https://arxiv.org/abs/2411.10083</guid>
      <pubDate>Mon, 18 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>