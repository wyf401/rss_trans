<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 30 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用大型语言模型来估计多词表达的特征：具体性、效价、唤醒度</title>
      <link>https://arxiv.org/abs/2408.16012</link>
      <description><![CDATA[arXiv:2408.16012v1 公告类型：新
摘要：本研究探讨了大型语言模型 (LLM) 为多词表达提供具体性、价态和唤醒度的准确估计的潜力。与以前的人工智能 (AI) 方法不同，LLM 可以捕捉多词表达的细微含义。我们系统地评估了 ChatGPT-4o 预测具体性、价态和唤醒度的能力。在研究 1 中，ChatGPT-4o 与人类对多词表达的具体性评分 (r = .8) 显示出很强的相关性。在研究 2 中，这些发现在单个单词的价态和唤醒度评分中重复出现，与以前的 AI 模型相匹配或优于以前的 AI 模型。研究 3 将普遍性和唤醒度分析扩展到多词表达，尽管缺乏大规模的人类基准，但仍显示出有希望的结果。这些发现凸显了 LLM 在生成与多词表达相关的有价值的心理语言学数据方面的潜力。为了帮助研究人员进行刺激选择，我们提供了包含 126,397 个英文单词和 63,680 个多词表达的具体性、效价和唤醒度的 AI 规范数据集]]></description>
      <guid>https://arxiv.org/abs/2408.16012</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型创建 AI 角色以复制和预测媒体效果：对 133 项已发表的实验研究结果进行实证检验</title>
      <link>https://arxiv.org/abs/2408.16073</link>
      <description><![CDATA[arXiv:2408.16073v1 公告类型：新
摘要：本报告分析了大型语言模型 (LLM) 加快准确复制已发表信息效果研究的潜力。我们通过复制《市场营销杂志》（2023 年 1 月至 2024 年 5 月）中 14 篇包含 45 项最新研究的论文中的 133 项实验结果来测试由 LLM 驱动的参与者（角色）。我们使用了一种新的软件工具 Viewpoints AI (https://viewpoints.ai/)，它将研究设计、刺激和测量作为输入，自动生成提示，让 LLM 充当指定的独特角色样本，并收集他们的反应以完整数据集和统计分析的形式产生最终输出。使用的底层 LLM 是 Anthropic 的 Claude Sonnet 3.5。我们生成了 19,447 个 AI 角色来复制这些研究，其样本属性、研究设计、刺激和测量与原始人类研究中报告的完全相同。我们的 LLM 复制成功重现了 76% 的原始主效应（111 个中的 84 个），表明人工智能辅助复制人们对媒体刺激做出反应的研究具有巨大潜力。当包括交互效应时，总体复制率为 68%（133 个中的 90 个）。本文讨论了使用 LLM 复制和加速媒体效应营销研究的问题，涉及社会科学中的复制危机、抽样对象和实验条件中的普遍性问题的潜在解决方案以及快速测试消费者对各种媒体刺激的反应的能力。我们还讨论了这种方法的局限性，特别是在复制媒体反应研究中的复杂交互效应方面，并提出了人工智能辅助实验复制媒体效应未来研究和改进的领域。]]></description>
      <guid>https://arxiv.org/abs/2408.16073</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>根据 Reddit 评论可以预测性格吗？</title>
      <link>https://arxiv.org/abs/2408.16089</link>
      <description><![CDATA[arXiv:2408.16089v1 公告类型：新
摘要：在这项作业中，我们研究一个人的性格类型与他们所写的文本之间是否存在相关性。为了做到这一点，我们汇总了 Reddit 评论数据集，这些数据集标有作者的迈尔斯-布里格斯类型指标 (MBTI)，并基于 BERT 构建了不同的监督分类器，试图根据文本预测作者的性格。尽管遇到了数据集未过滤特征的问题，但我们仍可以观察到分类中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.16089</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行结构化事件推理</title>
      <link>https://arxiv.org/abs/2408.16098</link>
      <description><![CDATA[arXiv:2408.16098v1 公告类型：新
摘要：推理现实生活中的事件是 AI 和 NLP 中一个统一的挑战，在各个领域都具有深远的实用性，而在高风险应用中的谬误可能是灾难性的。大型语言模型 (LLM) 能够处理这些领域中的各种文本，已被证明能够回答问题和解决问题。然而，我表明端到端 LLM 仍然无法系统地推理复杂事件，并且由于其黑箱性质而缺乏可解释性。为了解决这些问题，我提出了三种将 LLM 与事件的结构化表示结合使用的通用方法。第一种是基于语言的表示，涉及子事件的关系，LLM 可以通过微调来学习。第二种是半符号表示，涉及实体的状态，LLM 可以通过少量提示来预测和利用这些状态。第三种是完全符号化的表示，可以通过使用结构化数据训练的 LLM 进行预测，并由符号解算器执行。在一系列涵盖常识推理和规划的事件推理任务中，我表明每种方法都大大优于具有更多可解释性的端到端 LLM。这些结果表明 LLM 和结构化表示在事件推理及其他方面存在协同作用。]]></description>
      <guid>https://arxiv.org/abs/2408.16098</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估角色的计算表征：奥斯汀角色相似度基准</title>
      <link>https://arxiv.org/abs/2408.16131</link>
      <description><![CDATA[arXiv:2408.16131v1 公告类型：新
摘要：已经开发了几种系统来提取有关角色的信息，以帮助对英语文学进行计算分析。我们提出将角色相似性分组作为这些管道的整体评估任务。我们介绍了 AustenAlike，这是简·奥斯汀小说中人物相似性的基准套件。我们的基准借鉴了三个角色相似性概念：结构定义的相似性概念；社会定义的相似性概念；以及从文学批评中提取的专家定义集。
我们使用 AustenAlike 来评估使用两个管道 BookNLP 和 FanfictionNLP 提取的角色特征。我们从四种特征中构建角色表示，并将它们与三个 AustenAlike 基准和 GPT-4 相似性排名进行比较。我们发现，尽管计算表示基于共享的社交和叙事角色捕捉到了一些广泛的相似性，但我们第三个基准中的专家配对对所有系统来说都具有挑战性，突出了人类读者注意到的相似性的微妙方面。]]></description>
      <guid>https://arxiv.org/abs/2408.16131</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FRACTURED-SORRY-Bench：揭示对话轮次中破坏拒绝效力和 SORRY-Bench 防御的攻击的框架</title>
      <link>https://arxiv.org/abs/2408.16163</link>
      <description><![CDATA[arXiv:2408.16163v1 公告类型：新
摘要：本文介绍了 FRACTURED-SORRY-Bench，这是一个用于评估大型语言模型 (LLM) 抵御多轮对话攻击的安全性的框架。基于 SORRY-Bench 数据集，我们提出了一种简单而有效的方法，通过将有害查询分解为看似无害的子问题来生成对抗性提示。与基线方法相比，我们的方法在 GPT-4、GPT-4o、GPT-4o-mini 和 GPT-3.5-Turbo 模型中的攻击成功率 (ASR) 最高提高了 +46.22\%。我们证明这种技术对当前的 LLM 安全措施构成了挑战，并强调需要更强大的防御措施来抵御微妙的多轮攻击。]]></description>
      <guid>https://arxiv.org/abs/2408.16163</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从手推车到卡车：过去两个世纪英语词语含义的演变</title>
      <link>https://arxiv.org/abs/2408.16209</link>
      <description><![CDATA[arXiv:2408.16209v1 公告类型：新
摘要：这项名称学研究使用历时词嵌入来探索不同词语如何随时间代表相同的概念，使用 1800 年至 2000 年的历史词语数据。我们确定了能源、交通、娱乐和计算领域的变化，揭示了语言与社会变化之间的联系。
我们的方法包括使用使用 word2vec 和 skipgram 训练的历时词嵌入，并使用正交 Procrustes 对其进行对齐。我们讨论了与该方法识别的关系相关的可能困难。此外，我们研究了解释结果的道德方面，强调需要专家见解来理解该方法的重要性。]]></description>
      <guid>https://arxiv.org/abs/2408.16209</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>充分利用你的模型：微调和应用预训练 Transformer 的方法</title>
      <link>https://arxiv.org/abs/2408.16241</link>
      <description><![CDATA[arXiv:2408.16241v1 公告类型：新
摘要：本论文提供了在此目标上取得进展的模型方法和分析。所概述的技术与任务无关，与几乎任何 Transformer LM 一起使用时都应该会有所裨益。我们引入了两种新的微调方法，它们为所使用的模型增加了新功能。第一个方法添加了一个递归机制，它消除了固定窗口大小的限制并提高了 Transformer 解码器的效率。第二个方法允许使用掩码语言模型 (MLM) 来初始化非自回归序列到序列 Transformer 的编码器和解码器，从而开辟了以前仅用于自然语言理解任务的模型的生成应用。
我们还介绍了两种新技术，用于在不进行额外微调的情况下提高任何 Transformer 解码器的预测质量。一种是隐藏状态优化，可以应用于任何 Transformer 解码器，以提高推理时的预测质量，尤其是对于小样本分类。另一种方法是条件束搜索，它允许从业者搜索具有高可能性的自然语言生成 (NLG) 模型输出，同时以输出不退化（例如空、重复等）为条件。
最后，我们提供了关于模型可能性和输出质量差异的理论和实证见解，这在以前的工作中已被广泛观察到。这些见解适用于任何表示文本分布的模型，也适用于不是转换器甚至不是自回归的语言模型。我们认为，NLP 社区在某种程度上误解了这些发现的含义，并鼓励一种更微妙的观点。]]></description>
      <guid>https://arxiv.org/abs/2408.16241</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LoraMap：利用 LoRA 连接的力量</title>
      <link>https://arxiv.org/abs/2408.16264</link>
      <description><![CDATA[arXiv:2408.16264v1 公告类型：新
摘要：大型语言模型 (LLM) 可以通过事实核查减轻幻觉，并通过低秩自适应 (LoRA) 等参数高效技术克服大量计算开销。虽然一些研究已经探索了多个 LoRA 的并行集成，但这些方法需要注意它们之间的联系。本文研究了在多个 LoRA 之间建立联系的方法。我们创建了三个针对事实核查的推理数据集，并对单个 LoRA 进行了微调，使它们能够从不同的角度进行查看和推理。然后，我们探索了分配这些推理 LoRA 的策略，并介绍了一种映射它们之间连接的方法 LoraMap。事实核查任务的结果表明，LoraMap 的性能优于现有的 LoRA 组合方法 LoraHub。LoraMap 的性能也优于 LoraConcat，后者将 LoRA 连接起来并进一步对其进行微调。]]></description>
      <guid>https://arxiv.org/abs/2408.16264</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强人工智能驱动的心理咨询：使用大型语言模型进行分层提示</title>
      <link>https://arxiv.org/abs/2408.16276</link>
      <description><![CDATA[arXiv:2408.16276v1 公告类型：新
摘要：心理咨询对于改善心理健康和幸福感至关重要，但合格专业人员短缺和可扩展性问题等挑战限制了其可及性。为了应对这些挑战，我们探索使用 GPT-4 等大型语言模型 (LLM) 来增强心理咨询服务。我们的方法引入了一种新颖的分层提示系统，可以动态适应用户输入，从而实现全面和相关的信息收集。我们还开发了同理心驱动和基于场景的提示，以增强 LLM 在治疗环境中的情商和情境理解。我们通过使用新收集的心理咨询对话数据集进行实验验证了我们的方法，结果显示响应质量显着提高。结果凸显了我们的提示工程技术在增强 AI 驱动的心理咨询方面的潜力，提供了可扩展且可访问的解决方案，以满足日益增长的心理健康支持需求。]]></description>
      <guid>https://arxiv.org/abs/2408.16276</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>测量自动语音识别解决方案的准确性</title>
      <link>https://arxiv.org/abs/2408.16287</link>
      <description><![CDATA[arXiv:2408.16287v1 公告类型：新
摘要：对于聋人和听力障碍 (DHH) 人士来说，字幕是一种必不可少的辅助工具。人工智能 (AI) 的重大发展意味着自动语音识别 (ASR) 现在已成为许多流行应用程序的一部分。这使得创建字幕变得简单且广泛可用 - 但转录需要高水平的准确性才能被访问。科学出版物和行业报告的错误率非常低，声称人工智能已经达到人类水平甚至优于手动转录。同时，DHH 社区报告了 ASR 的准确性和可靠性存在严重问题。对于依赖转录的人来说，技术创新和现实生活体验似乎不匹配。需要独立和全面的数据来捕捉 ASR 的状态。我们用高等教育讲座的录音测量了 11 种常见 ASR 服务的性能。我们评估了流媒体、词汇的使用和语言差异等技术条件的影响。我们的结果表明，不同供应商以及单个音频样本的准​​确度差异很大。我们还测量了用于现场活动的流式 ASR 的质量明显较低。我们的研究表明，尽管 ASR 近期有所改进，但常见服务在准确度方面缺乏可靠性。]]></description>
      <guid>https://arxiv.org/abs/2408.16287</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言模型的物理学：第 2.2 部分，如何从小学数学问题的错误中学习</title>
      <link>https://arxiv.org/abs/2408.16293</link>
      <description><![CDATA[arXiv:2408.16293v1 公告类型：新
摘要：语言模型在解决推理任务方面表现出色；然而，即使是最强大的模型仍然偶尔会犯推理错误。最近，有积极的研究旨在提高推理准确性，特别是通过使用预训练语言模型通过多轮提示“自我纠正”其错误。在本文中，我们遵循这条工作路线，但重点是了解将“错误纠正”数据直接纳入预训练阶段的实用性。这些数据包括错误的解决步骤及其后的纠正。使用合成数学数据集，我们展示了有希望的结果：与在相同数量的无错误数据上进行预训练相比，这种类型的预训练数据可以帮助语言模型直接实现更高的推理准确性（即通过简单的自回归，无需多轮提示）。我们还深入研究了许多细节，例如（1）这种方法与集束搜索有何不同，（2）如何准备此类数据，（3）是否需要对错误的标记进行屏蔽，（4）所需的错误量，（5）是否可以将此类数据推迟到微调阶段，等等。]]></description>
      <guid>https://arxiv.org/abs/2408.16293</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Critic-CoT：通过 Chain-of-thoughts Critic 提升大型语言模型的推理能力</title>
      <link>https://arxiv.org/abs/2408.16326</link>
      <description><![CDATA[arXiv:2408.16326v1 公告类型：新
摘要：自我批评已成为提升LLM推理性能的重要机制。然而，目前的方法主要涉及基本提示而没有进一步的训练，这些提示往往过于简单，导致准确性有限。此外，缺乏对LLM批评能力与其任务解决性能之间关系的深入研究。为了解决这些问题，我们提出了Critic-CoT，这是一个新颖的框架，它通过逐步的CoT推理格式和远程监督数据构建，将LLM推向类似System-2的批评能力，而无需人工注释。在GSM8K和MATH上的实验表明，通过过滤无效解决方案或迭代细化，我们的增强模型提高了任务解决性能，这证明了我们方法的有效性。此外，我们发现仅对批评和细化进行训练就可以提高生成率。我们希望我们的工作能够为未来提高法学硕士的推理和批判能力的研究提供启示。]]></description>
      <guid>https://arxiv.org/abs/2408.16326</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>核心抽样对减轻文本记忆的不合理无效性</title>
      <link>https://arxiv.org/abs/2408.16345</link>
      <description><![CDATA[arXiv:2408.16345v1 公告类型：新
摘要：这项工作分析了大型语言模型 (LLM) 在进行核心采样时的文本记忆行为。像核心采样这样的随机解码方法通常用于克服诸如单调和重复的文本生成等问题，这些问题通常在基于最大化的解码技术中观察到。我们假设核心采样也可能减少记忆模式的发生，因为它可能导致选择记忆序列之外的标记。为了检验这个假设，我们创建了一个具有已知重复分布的诊断数据集，这使我们能够对记忆训练数据某些部分的可能性进行一些控制。有趣的是，我们对两个在此数据集上进行微调的 GPT-Neo 模型的分析表明：(i) 增加核尺寸只会略微减少记忆，(ii) 即使模型不进行“硬”记忆（逐字复制训练样本），它们仍可能显示“软”记忆，即它们生成的输出与训练数据相呼应，但没有完全一一相似。]]></description>
      <guid>https://arxiv.org/abs/2408.16345</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MQM-Chat：聊天翻译的多维质量指标</title>
      <link>https://arxiv.org/abs/2408.16390</link>
      <description><![CDATA[arXiv:2408.16390v1 公告类型：新
摘要：聊天的复杂性对机器翻译模型提出了重大挑战。认识到需要一个精确的评估指标来解决聊天翻译问题，本研究引入了聊天翻译的多维质量指标 (MQM-Chat)。通过使用 MQM-Chat 对五个模型进行的实验，我们观察到所有模型都产生了某些基本错误，而每个模型都有不同的缺点，例如遗漏、过度纠正模棱两可的源内容和流行语问题，导致风格化信息的丢失。我们的研究结果强调了 MQM-Chat 在评估聊天翻译方面的有效性，强调了风格化内容和对话一致性对未来研究的重要性。]]></description>
      <guid>https://arxiv.org/abs/2408.16390</guid>
      <pubDate>Fri, 30 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>