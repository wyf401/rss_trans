<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 23 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>Seal：推进语音语言模型成为少样本学习者</title>
      <link>https://arxiv.org/abs/2407.14875</link>
      <description><![CDATA[arXiv:2407.14875v1 公告类型：新
摘要：现有的自回归语言模型已经展示了一种非凡的能力，只需几个示例即可执行新任务，而无需任何额外的训练。为了将这种能力扩展到多模态设置（即语音和语言），本文介绍了 Seal 模型，这是语音语言模型的缩写。它采用了一种新颖的对齐方法，其中执行 Kullback-Leibler 散度损失来训练一个投影仪，该投影仪将冻结的语音编码器与冻结的语言模型解码器连接起来。得到的 Seal 模型作为两个语音理解任务上的少样本学习器表现出稳健的性能。此外，还进行了一致性实验以验证其在不同预训练语言模型上的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2407.14875</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:20 GMT</pubDate>
    </item>
    <item>
      <title>模块化句子编码器：将语言专业化与跨语言对齐分离</title>
      <link>https://arxiv.org/abs/2407.14878</link>
      <description><![CDATA[arXiv:2407.14878v1 公告类型：新
摘要：多语言句子编码器通常是通过训练多语言语言模型来获得，以将来自不同语言的句子映射到共享的语义空间中。因此，它们容易受到多语言诅咒的影响，即由于参数共享而导致单语表示准确性的损失。多语言句子编码器的另一个限制是单语和跨语言性能之间的权衡。句子嵌入的跨语言对齐训练会扭曲各个语言语义空间的最佳单语结构，从而损害句子嵌入在单语任务中的效用。在这项工作中，我们通过模块化训练句子编码器来解决这两个问题，即将单语专业化与跨语言对齐分开。我们首先有效地训练特定于语言的句子编码器，以避免语言之间的负面干扰（即诅咒）。然后，我们通过在每个编码器上训练一个跨语言对齐适配器将所有非英语单语编码器与英语编码器对齐，从第一步开始防止对单语专业化的干扰。在这两个步骤中，我们都采用了机器翻译释义数据的对比学习。对语义文本相似性/相关性的单语和跨语言评估以及多项选择问答使我们的模块化解决方案比多语言句子编码器更有效，尤其有利于资源匮乏的语言。]]></description>
      <guid>https://arxiv.org/abs/2407.14878</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:20 GMT</pubDate>
    </item>
    <item>
      <title>AI-Debater 2023 概览：论证生成任务的挑战</title>
      <link>https://arxiv.org/abs/2407.14829</link>
      <description><![CDATA[arXiv:2407.14829v1 公告类型：新
摘要：本文介绍了中国情感计算大会（CCAC 2023）举办的AI-Debater 2023挑战赛的结果，并介绍了相关数据集。我们组织了两个赛道来处理不同场景下的论证生成任务，即反驳论据生成（赛道1）和基于主张的论据生成（赛道2）。每个赛道分别配备了不同的数据集和基线模型。共有32支参赛队伍报名参加挑战赛，我们从中收到了11份成功的提交。在本文中，我们将介绍挑战赛的结果和系统摘要，强调参与系统之间的共性和创新性。AI-Debater 2023挑战赛的数据集和基线模型已经发布，可以通过挑战赛的官方网站访问。]]></description>
      <guid>https://arxiv.org/abs/2407.14829</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:19 GMT</pubDate>
    </item>
    <item>
      <title>波斯语文本中的自动实词错误更正</title>
      <link>https://arxiv.org/abs/2407.14795</link>
      <description><![CDATA[arXiv:2407.14795v1 公告类型：新
摘要：自动拼写纠正是自然语言处理 (NLP) 领域的关键挑战，需要细致入微的解决方案。传统的拼写纠正技术通常只能检测和纠正非单词错误，例如错别字和拼写错误。然而，上下文相关错误（也称为实词错误）更难检测，因为它们是在给定上下文中使用不正确的有效单词。波斯语以其丰富的形态和复杂的语法为特征，对自动拼写纠正系统提出了巨大的挑战。此外，波斯语资源有限，难以训练有效的拼写纠正模型。本文介绍了一种精确、高效地纠正波斯语文本实词错误的前沿方法。我们的方法采用结构化、多层次的方法，采用语义分析、特征选择和高级分类器来增强错误检测和纠正效率。这种创新架构可发现并存储波斯语文本中单词和短语之间的语义相似性。分类器可准确识别真实单词错误，而语义排名算法可确定真实单词错误的最可能更正方法，同时考虑特定的拼写更正和上下文属性，例如上下文、语义相似性和编辑距离度量。评估表明，我们提出的方法超越了之前的波斯语真实单词错误更正模型。我们的方法在检测阶段实现了令人印象深刻的 96.6% 的 F 度量，在更正阶段实现了 99.1% 的准确率。这些结果清楚地表明，我们的方法是波斯语文本中自动真实单词错误更正的一种非常有前途的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2407.14795</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>文本风格转换：概述</title>
      <link>https://arxiv.org/abs/2407.14822</link>
      <description><![CDATA[arXiv:2407.14822v1 公告类型：新
摘要：文本风格转换 (TST) 是自然语言生成中的一项关键任务，用于操纵文本风格属性，同时保留与风格无关的内容。TST 所针对的属性可能千差万别，包括礼貌、作者身份、缓解冒犯性语言、修改感受和调整文本形式。近年来，TST 已成为一个广泛研究的课题，取得了长足的进步。本文对 TST 进行了介绍性概述，介绍了其挑战、现有方法、数据集、评估措施、子任务和应用。这一基本概述加深了对文本风格转换的背景和基础知识的理解。]]></description>
      <guid>https://arxiv.org/abs/2407.14822</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>PERCORE：基于深度学习的波斯语拼写纠正和语音分析框架</title>
      <link>https://arxiv.org/abs/2407.14789</link>
      <description><![CDATA[arXiv:2407.14789v1 公告类型：新
摘要：本研究介绍了一种最先进的波斯语拼写纠正系统，该系统将深度学习技术与语音分析无缝集成，显著提高了波斯语自然语言处理 (NLP) 的准确性和效率。利用经过微调的语言表示模型，我们的方法有效地将深度上下文分析与语音洞察相结合，熟练地纠正非单词和真实单词的拼写错误。这种策略在解决波斯语拼写的独特复杂性方面被证明特别有效，包括其复杂的形态和同音异义的挑战。对广泛数据集的全面评估证实了我们的系统与现有方法相比具有卓越的性能，在检测真实单词错误方面具有令人印象深刻的 0.890 的 F1 分数，在纠正这些错误方面具有令人印象深刻的 0.905。此外，该系统在非单词错误纠正方面表现出强大的能力，F1 分数达到 0.891。这些结果说明了将语音洞察融入拼写纠正深度学习模型的显著优势。我们的贡献不仅通过为各种 NLP 应用提供通用解决方案来推动波斯语处理的发展，而且还为该领域的未来研究铺平了道路，强调了语音分析在开发有效拼写纠正系统中的关键作用。]]></description>
      <guid>https://arxiv.org/abs/2407.14789</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>逐步推理解决网格难题：法学硕士 (LLM) 的不足之处是什么？</title>
      <link>https://arxiv.org/abs/2407.14790</link>
      <description><![CDATA[arXiv:2407.14790v1 公告类型：新
摘要：解决网格难题需要大量的逻辑推理。因此，评估模型的推理能力是一个很好的领域，可以指导我们提高模型的推理能力。然而，大多数现有工作仅评估谜题的最终预测答案，而没有深入分析 LLM 的推理链（例如它们失败的地方）或提供任何更精细的指标来评估它们。由于 LLM 可能依赖简单的启发式方法或人工制品来预测最终答案，因此除了整体正确性度量之外，评估生成的推理链对于准确评估 LLM 的推理能力至关重要。为此，我们首先开发了 GridPuzzle，这是一个评估数据集，包含 274 个具有不同复杂度的基于网格的谜题。其次，我们提出了一种新的错误分类法，该分类法源自对 GPT-4、Claude-3、Gemini、Mistral 和 Llama-2 等 LLM 的推理链的手动分析。然后，我们开发了一个基于 LLM 的大规模主观评估框架（即识别错误）和一个客观指标 PuzzleEval，以评估推理链的正确性。评估 LLM 的推理链得出了一些有趣的发现。我们进一步表明，用于增强模型推理能力的现有提示方法并不能提高 GridPuzzle 的性能。这凸显了理解细粒度错误的重要性，并为未来的研究提出了挑战，即通过开发解决这些错误的方法来增强 LLM 的解谜能力。数据和源代码可在 https://github.com/Mihir3009/GridPuzzle 上找到。]]></description>
      <guid>https://arxiv.org/abs/2407.14790</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>经济观察者调查为日本金融领域提供数据集和任务</title>
      <link>https://arxiv.org/abs/2407.14727</link>
      <description><![CDATA[arXiv:2407.14727v1 公告类型：新
摘要：英语或一般领域的许多自然语言处理 (NLP) 任务广泛可用，并且经常用于评估预训练语言模型。相比之下，除英语以外的语言和金融领域的任务较少。特别是日语和金融领域的任务有限。我们使用日本中央政府机构发布的材料构建了两个大型数据集。数据集提供了三个日语金融 NLP 任务，其中包括用于对句子进行分类的 3 类和 12 类分类，以及用于情绪分析的 5 类分类任务。我们的数据集旨在全面且最新，利用自动更新框架确保最新的任务数据集随时公开可用。]]></description>
      <guid>https://arxiv.org/abs/2407.14727</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>我需要帮助！评估 LLM 寻求用户支持的能力：文本到 SQL 生成的案例研究</title>
      <link>https://arxiv.org/abs/2407.14767</link>
      <description><![CDATA[arXiv:2407.14767v1 公告类型：新
摘要：在本研究中，我们以文本到 SQL 生成为例，探讨了 LLM 主动寻求用户支持的能力。我们提出了衡量性能改进和用户负担之间权衡的指标，并研究了 LLM 是否可以确定何时请求帮助并在不同级别的信息可用性下检查其性能。我们的实验表明，如果没有外部反馈，许多 LLM 很难认识到他们对额外支持的需求。我们的研究结果强调了外部信号的重要性，并为未来改进寻求支持策略的研究提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2407.14767</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>通过修剪和知识提炼实现紧凑的语言模型</title>
      <link>https://arxiv.org/abs/2407.14679</link>
      <description><![CDATA[arXiv:2407.14679v1 公告类型：新
摘要：目前，针对不同部署规模和大小的大型语言模型 (LLM) 是通过从头开始训练每个变体来生成的；这极其耗费计算资源。在本文中，我们研究了修剪现有 LLM 然后用原始训练数据的一小部分 (&lt;3%) 对其进行重新训练是否可以成为重复、完全重新训练的合适替代方案。为此，我们为 LLM 开发了一套实用有效的压缩最佳实践，将深度、宽度、注意力和 MLP 修剪与基于知识蒸馏的再训练相结合；我们通过对每个轴的修剪策略、组合轴的方法、蒸馏策略和搜索技术进行详细的实证探索，得出这些最佳实践，以实现最佳压缩架构。我们使用本指南将 Nemotron-4 系列 LLM 压缩 2-4 倍，并将它们在各种语言建模任务上的性能与类似大小的模型进行比较。使用我们的方法从已经预训练的 15B 模型中派生出 8B 和 4B 模型，与从头开始训练相比，每个模型所需的训练令牌最多减少了 40 倍；这为训练整个模型系列（15B、8B 和 4B）节省了 1.8 倍的计算成本。与从头开始训练相比，Minitron 模型的 MMLU 分数提高了 16%，性能可与 Mistral 7B、Gemma 7B 和 Llama-3 8B 等其他社区模型相媲美，并且优于文献中最先进的压缩技术。我们在 Huggingface 上开源了 Minitron 模型权重，并在 GitHub 上提供了相应的补充材料（包括示例代码）。]]></description>
      <guid>https://arxiv.org/abs/2407.14679</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:15 GMT</pubDate>
    </item>
    <item>
      <title>词汇意义动态神经模型中语境对语言理解的调节</title>
      <link>https://arxiv.org/abs/2407.14701</link>
      <description><![CDATA[arXiv:2407.14701v1 公告类型：新
摘要：我们提出并通过计算实现了一个词汇意义的动态神经模型，并通过实验测试了其行为预测。我们使用英语词汇“have”作为测试案例展示了该模型的架构和行为，重点关注其多义用法。在该模型中，“have”映射到由两个连续概念维度（连通性和控制不对称性）定义的语义空间，这两个维度之前被提出用于参数化语言的概念系统。映射被建模为表示词汇项的神经节点与表示概念维度的神经场之间的耦合。虽然词汇知识被建模为稳定的耦合模式，但实时词汇意义检索被建模为对应于语义解释或阅读的亚稳态之间的神经激活模式的运动。模型模拟捕获了两个先前报告的经验观察结果：（1）词汇语义解释的上下文调节，以及（2）这种调节幅度的个体差异。模拟还产生了一个新预测，即句子阅读时间和可接受性之间的逐次关系应该根据上下文进行调节。结合自定阅读速度和可接受性判断的实验复制了之前的结果并证实了新的模型预测。总之，结果支持了词汇多义性的一个新观点：一个词的许多相关含义是亚稳态神经激活状态，这些状态源于控制连续语义维度解释的神经群体的非线性动力学。]]></description>
      <guid>https://arxiv.org/abs/2407.14701</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:15 GMT</pubDate>
    </item>
    <item>
      <title>CVE-LLM：使用大型语言模型自动评估医疗器械行业的漏洞</title>
      <link>https://arxiv.org/abs/2407.14640</link>
      <description><![CDATA[arXiv:2407.14640v1 公告类型：新
摘要：医疗保健行业目前正在经历前所未有的网络安全攻击浪潮，影响了数百万人。随着每月发现数千个漏洞，迫切需要推动医疗设备漏洞评估流程的自动化，以促进快速缓解措施。生成式人工智能系统彻底改变了各个行业，为自动化和提高效率提供了无与伦比的机会。本文提出了一种利用大型语言模型 (LLM) 从历史漏洞评估中学习的解决方案，以自动评估医疗器械行业的漏洞。这种方法应用于单个制造商的产品组合中，考虑到设备特性，包括现有的安全态势和控制。本文的主要贡献有三点。首先，它详细研究了在工业环境中训练漏洞语言模型 (LM) 的最佳实践。其次，它对语言模型在漏洞评估中的有效性进行了全面的比较和深入的分析。最后，它提出了一个新的人机交互框架来加快漏洞评估过程。]]></description>
      <guid>https://arxiv.org/abs/2407.14640</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:14 GMT</pubDate>
    </item>
    <item>
      <title>针对具有情境背景的大型语言模型进行人类可解释的对抗性提示攻击</title>
      <link>https://arxiv.org/abs/2407.14644</link>
      <description><![CDATA[arXiv:2407.14644v1 公告类型：新
摘要：以前使用对抗性攻击测试大型语言模型 (LLM) 中的漏洞的研究主要集中在无意义的提示注入上，这些提示注入很容易在手动或自动审查（例如通过字节熵）中检测到。然而，对通过对抗性注入增强的无害的人类可理解的恶意提示的探索仍然有限。在本研究中，我们探索通过情境驱动的上下文重写将无意义的后缀攻击转换为合理的提示。这使我们能够显示后缀转换而无需任何梯度，仅使用 LLM 执行攻击，从而更好地了解可能的风险范围。我们结合了独立的、有意义的对抗性插入和从电影中衍生的情况来检查这是否可以欺骗 LLM。这些情况是从 IMDB 数据集中提取的，并根据几次思路链提示定义提示。我们的方法表明，成功的情境驱动攻击可以在开源和专有 LLM 上执行。我们发现，在许多 LLM 中，只需 1 次尝试就会产生攻击，并且这些攻击会在 LLM 之间转移。我们的代码链接位于 \url{https://anonymous.4open.science/r/Situation-Driven-Adversarial-Attacks-7BB1/README.md}。]]></description>
      <guid>https://arxiv.org/abs/2407.14644</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:14 GMT</pubDate>
    </item>
    <item>
      <title>SQLfuse：通过全面的 LLM 协同作用增强文本到 SQL 的性能</title>
      <link>https://arxiv.org/abs/2407.14568</link>
      <description><![CDATA[arXiv:2407.14568v1 公告类型：新
摘要：文本到 SQL 的转换是一项关键创新，它简化了从复杂 SQL 到直观自然语言查询的过渡，鉴于 SQL 在各种角色的就业市场中的普遍性，这一点尤其重要。GPT-3.5 和 GPT-4 等大型语言模型 (LLM) 的兴起极大地推动了这一领域的发展，提供了更好的自然语言理解和生成细微 SQL 语句的能力。然而，开源 LLM 在文本到 SQL 应用程序中的潜力仍未得到充分开发，许多框架未能充分利用其功能，特别是在处理复杂的数据库查询和结合反馈进行迭代细化方面。为了解决这些限制，本文介绍了 SQLfuse，这是一个强大的系统，将开源 LLM 与一套工具集成在一起，以增强文本到 SQL 翻译的准确性和可用性。SQLfuse 具有四个模块：模式挖掘、模式链接、SQL 生成和 SQL 评论家模块，不仅可以生成 SQL 查询质量，还可以不断提高 SQL 查询质量。 SQLfuse 在 Spider 排行榜上的领先表现以及蚂蚁集团的部署，展示了开源 LLM 在不同业务环境中的实用价值。]]></description>
      <guid>https://arxiv.org/abs/2407.14568</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:13 GMT</pubDate>
    </item>
    <item>
      <title>对抗性数据库提高基于检索的大型语言模型的成功率</title>
      <link>https://arxiv.org/abs/2407.14609</link>
      <description><![CDATA[arXiv:2407.14609v1 公告类型：新
摘要：开源 LLM 已显示出作为微调聊天机器人的巨大潜力，并展示了强大的推理能力并超越了许多现有基准。检索增强生成 (RAG) 是一种通过利用外部知识数据库来提高 LLM 在模型未明确训练的任务上的性能的技术。许多研究表明，当使用包含相关背景信息的矢量数据集时，RAG 可以更成功地完成下游任务。该领域的人士已经隐含地假设，如果在这种情况下使用对抗性背景信息，那么使用基于 RAG 的方法的成功将不复存在，甚至会对结果产生负面影响。为了解决这个假设，我们测试了几个开源 LLM，以了解 RAG 提高其在肾脏病医学专科领域回答多项选择题 (MCQ) 的成功率的能力。与以前的研究不同，我们研究了 RAG 在利用相关和对抗性背景数据库方面的影响。我们在零样本 RAG 管道中设置了几个开源 LLM，包括 Llama 3、Phi-3、Mixtral 8x7b、Zephyr$\beta$ 和 Gemma 7B Instruct。作为对抗性信息源，来自圣经的文本和随机词生成的数据库用于比较。我们的数据显示，大多数开源 LLM 在合并相关信息向量数据库时都按预期提高了多项选择题考试的成功率。然而令人惊讶的是，对抗性圣经文本显著提高了许多 LLM 的成功率，甚至随机词文本也提高了一些模型的应试能力。总之，我们的结果首次证明了对抗性信息数据集能够提高基于 RAG 的 LLM 成功率，这是反直觉的能力。]]></description>
      <guid>https://arxiv.org/abs/2407.14609</guid>
      <pubDate>Tue, 23 Jul 2024 06:20:13 GMT</pubDate>
    </item>
    </channel>
</rss>