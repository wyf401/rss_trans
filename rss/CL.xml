<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 12 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>利用具有思路链和快速工程的大型语言模型进行交通事故严重程度分析和推理</title>
      <link>https://arxiv.org/abs/2408.04652</link>
      <description><![CDATA[arXiv:2408.04652v1 公告类型：新
摘要：利用大型语言模型 (LLM) 的强大功能，本研究探索了三种最先进的 LLM（特别是 GPT-3.5-turbo、LLaMA3-8B 和 LLaMA3-70B）用于碰撞严重程度推断，并将其作为分类任务。我们使用注入领域知识的预建模板从原始交通事故表格数据中生成文本叙述。此外，我们结合了思路链 (CoT) 推理来指导 LLM 分析碰撞原因，然后推断严重程度。本研究还研究了专门为碰撞严重程度推断设计的提示工程的影响。LLM 的任务是进行碰撞严重程度推断：(1) 评估模型在碰撞严重程度分析方面的能力，(2) 评估 CoT 和领域知情提示工程的有效性，以及 (3) 使用 CoT 框架检查推理能力。我们的结果表明，LLaMA3-70B 的表现始终优于其他模型，尤其是在零样本设置中。CoT 和 Prompt Engineering 技术显著提高了性能，改善了逻辑推理并解决了对齐问题。值得注意的是，CoT 为 LLM 的推理过程提供了宝贵的见解，释放了它们在严重性分析和推理中考虑各种因素（例如环境条件、驾驶员行为和车辆特性）的能力。]]></description>
      <guid>https://arxiv.org/abs/2408.04652</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:41 GMT</pubDate>
    </item>
    <item>
      <title>批量 BPE 标记化合并</title>
      <link>https://arxiv.org/abs/2408.04653</link>
      <description><![CDATA[arXiv:2408.04653v1 公告类型：新
摘要：在构建标记器词汇表时，可以安全地批量处理字节对编码算法，以一次合并数百对标记。这种技术与减少词汇训练中使用的文本的内存占用相结合，使得在基本笔记本电脑上训练高质量的标记器成为可能。本文介绍了 BatchBPE，这是这些概念的开源纯 Python 实现，目的是使新的标记化策略的实验更容易进行，尤其是在计算和内存受限的环境中。通过训练几个标记词汇表来探索批量合并过程并尝试预处理停用词列表并忽略数据集中最不常见的文本块，证明了 BatchBPE 的实用性和可塑性。文本的结果编码长度用作基本评估指标。]]></description>
      <guid>https://arxiv.org/abs/2408.04653</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:41 GMT</pubDate>
    </item>
    <item>
      <title>PLUGH：大型语言模型中空间理解和推理的基准</title>
      <link>https://arxiv.org/abs/2408.04648</link>
      <description><![CDATA[arXiv:2408.04648v1 公告类型：新
摘要：我们提出了 PLUGH（https://www.urbandictionary.com/define.php?term=plugh），这是一个现代基准，目前由 5 个任务组成，每个任务都有从 48 个不同的游戏中提取的 125 个输入文本，代表 61 个不同的（非同构）空间图，以评估大型语言模型 (LLM) 的空间理解和推理能力。我们对基于 API 和开源 LLM 的评估表明，虽然一些商业 LLM 表现出强大的推理能力，但开源竞争对手可以展示几乎相同的质量水平；然而，所有模型仍然有很大的改进空间。我们确定了 LLM 失败的典型原因并讨论了可能的解决方法。数据集和评估代码已发布（https://github.com/altsoph/PLUGH）。]]></description>
      <guid>https://arxiv.org/abs/2408.04648</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:40 GMT</pubDate>
    </item>
    <item>
      <title>立场链：使用大型语言模型进行立场检测</title>
      <link>https://arxiv.org/abs/2408.04649</link>
      <description><![CDATA[arXiv:2408.04649v1 公告类型：新
摘要：立场检测是自然语言处理 (NLP) 中的一项主动任务，旨在识别作者对文本中特定目标的立场。鉴于大型语言模型 (LLM) 出色的语言理解能力和百科全书式的先验知识，如何探索 LLM 在立场检测中的潜力已受到广泛关注。与现有的仅专注于使用大规模数据集进行微调的基于 LLM 的方法不同，我们提出了一种新的提示方法，称为 \textit{Chain of Stance} (CoS)。具体而言，它通过将立场检测过程分解为一系列中间立场相关断言并最终得出最终判断，将 LLM 定位为专家立场检测器。这种方法可以显着提高分类性能。我们在 SemEval 2016 数据集上使用四个 SOTA LLM 进行了广泛的实验，涵盖了零样本和少量样本学习设置。结果表明，所提出的方法在小样本设置中取得了最先进的结果，F1 分数为 79.84。]]></description>
      <guid>https://arxiv.org/abs/2408.04649</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:40 GMT</pubDate>
    </item>
    <item>
      <title>建立对心理健康聊天机器人的信任：安全指标和基于 LLM 的评估工具</title>
      <link>https://arxiv.org/abs/2408.04650</link>
      <description><![CDATA[arXiv:2408.04650v1 公告类型：新
摘要：目的：本研究旨在开发和验证一个评估框架，以确保心理健康聊天机器人的安全性和可靠性，这些聊天机器人因其可访问性、类似人类的交互和情境感知支持而越来越受欢迎。材料和方法：我们创建了一个评估框架，其中包含 100 个基准问题和理想答案，以及 5 个聊天机器人响应的指导性问题。该框架经过心理健康专家的验证，并在基于 GPT-3.5-turbo 的聊天机器人上进行了测试。探索的自动评估方法包括基于大型语言模型 (LLM) 的评分、使用实时数据的代理方法以及嵌入模型以将聊天机器人响应与地面实况标准进行比较。结果：结果强调了指导方针和地面实况对于提高 LLM 评估准确性的重要性。代理方法动态访问可靠信息，与人类评估表现出最佳一致性。遵守标准化、专家验证的框架显着提高了聊天机器人响应的安全性和可靠性。讨论：我们的研究结果强调了心理健康聊天机器人需要全面的、专家量身定制的安全评估指标。虽然 LLM 具有巨大的潜力，但必须谨慎实施才能降低风险。代理方法的卓越性能凸显了实时数据访问在增强聊天机器人可靠性方面的重要性。结论：该研究验证了心理健康聊天机器人的评估框架，证明了其在提高安全性和可靠性方面的有效性。未来的工作应该将评估扩展到准确性、偏见、同理心和隐私，以确保整体评估和负责任地融入医疗保健。标准化评估将在用户和专业人士之间建立信任，促进更广泛的采用并通过技术改善心理健康支持。]]></description>
      <guid>https://arxiv.org/abs/2408.04650</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:40 GMT</pubDate>
    </item>
    <item>
      <title>知识人工智能：微调 NLP 模型以促进科学知识的提取和理解</title>
      <link>https://arxiv.org/abs/2408.04651</link>
      <description><![CDATA[arXiv:2408.04651v1 公告类型：新
摘要：该项目研究大型语言模型 (LLM) 在理解和提取特定领域的科学知识方面的功效，并创建一个深度学习框架：知识人工智能。作为该框架的一部分，我们使用预先训练的模型，并在科学领域的数据集上对其进行微调。这些模型适用于四个关键的自然语言处理 (NLP) 任务：摘要、文本生成、问答和命名实体识别。我们的结果表明，特定领域的微调显着提高了模型在这些任务中的性能，从而提高了它们在科学环境中的适用性。这种调整使非专家能够有效地查询和提取目标科学领域内的信息，展示了微调的 LLM 作为科学知识发现工具的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.04651</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:40 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型 (LLM) 广泛部署的风险、原因及缓解措施：一项调查</title>
      <link>https://arxiv.org/abs/2408.04643</link>
      <description><![CDATA[arXiv:2408.04643v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展，例如 ChatGPT 和 LLaMA，凭借其在文本生成、摘要和分类方面的出色能力，极大地改变了自然语言处理 (NLP)。然而，它们的广泛采用带来了许多挑战，包括与学术诚信、版权、环境影响以及数据偏见、公平和隐私等道德考虑有关的问题。LLM 的快速发展也引发​​了对其评估的可靠性和普遍性的担忧。本文对这些主题的文献进行了全面的调查，这些文献是从 Google Scholar 系统地收集和综合的。我们的研究对与特定 LLM 相关的风险进行了深入分析，确定了子风险、其原因和潜在解决方案。此外，我们探讨了与 LLM 相关的更广泛的挑战，详细说明了它们的原因并提出了缓解策略。通过这种文献分析，我们的调查旨在加深对这些强大模型的含义和复杂性的理解。]]></description>
      <guid>https://arxiv.org/abs/2408.04643</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:39 GMT</pubDate>
    </item>
    <item>
      <title>评估高级法学硕士技术对机器人课程人工智能讲师的影响</title>
      <link>https://arxiv.org/abs/2408.04645</link>
      <description><![CDATA[arXiv:2408.04645v1 公告类型：新
摘要：本研究评估了大型语言模型 (LLM) 作为大学课程的人工智能导师的表现。特别是，使用了不同的先进技术，例如即时工程、检索增强生成 (RAG) 和微调。我们使用常见的相似性指标（如 BLEU-4、ROUGE 和 BERTScore）评估了不同的模型并应用了技术，并辅以对有用性和可信度的小型人工评估。我们的研究结果表明，RAG 与即时工程相结合可显着增强模型响应并产生更好的事实答案。在教育背景下，RAG 似乎是一种理想的技术，因为它基于使用通常已经存在于大学课程中的附加信息和材料来丰富模型的输入。另一方面，微调可以产生非常小但仍然强大的专家模型，但存在过度拟合的危险。我们的研究进一步询问我们如何衡量法学硕士的表现，以及当前的测量方法如何代表正确性或相关性？我们发现相似性指标具有很高的相关性，并且大多数这些指标都偏向于较短的回答。总体而言，我们的研究指出了将法学硕士融入教育环境的潜力和挑战，这表明需要平衡的培训方法和先进的评估框架。]]></description>
      <guid>https://arxiv.org/abs/2408.04645</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:39 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型在系统评价中的有效性</title>
      <link>https://arxiv.org/abs/2408.04646</link>
      <description><![CDATA[arXiv:2408.04646v1 公告类型：新 
摘要：本研究通过系统回顾环境、社会和治理 (ESG) 因素与财务绩效之间的关系，调查了大型语言模型 (LLM) 在解释现有文献方面的有效性。主要目标是评估 LLM 如何复制对以 ESG 为重点的论文集的系统评价。我们编制并手工编码了一个数据库，其中包含 2020 年 3 月至 2024 年 5 月发表的 88 篇相关论文。此外，我们还使用了 2015 年 1 月至 2020 年 2 月之前对 ESG 文献进行系统回顾的 238 篇论文。我们评估了两个当前最先进的 LLM，Meta AI 的 Llama 3 8B 和 OpenAI 的 GPT-4o，评估了它们相对于两组论文的人工分类的解释准确性。然后，我们将这些结果与使用 238 篇论文作为训练数据的“自定义 GPT”和经过微调的 GPT-4o Mini 模型进行了比较。经过微调的 GPT-4o Mini 模型在提示 1 上的整体准确率平均比基础 LLM 高出 28.3%。同时，“自定义 GPT”在提示 2 和 3 上的整体准确率平均分别提高了 3.0% 和 15.7%。我们的研究结果表明，投资者和机构可以利用 LLM 总结与 ESG 投资相关的复杂证据，从而实现更快的决策和更高效的市场，这将带来有希望的结果。]]></description>
      <guid>https://arxiv.org/abs/2408.04646</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:39 GMT</pubDate>
    </item>
    <item>
      <title>区分聊天机器人和人类</title>
      <link>https://arxiv.org/abs/2408.04647</link>
      <description><![CDATA[arXiv:2408.04647v1 公告类型：新
摘要：生成式人工智能 (AI) 和大型语言模型 (LLM) 领域最近取得了许多进展，其中生成式预训练 Transformer (GPT) 模型是领先的“聊天机器人”。基于 LLM 的聊天机器人变得如此强大，以至于似乎很难区分人类编写的文本和机器生成的文本。为了分析这个问题，我们开发了一个新数据集，其中包含超过 750,000 个人类编写的段落，每个段落都有一个对应的聊天机器人生成的段落。基于这个数据集，我们应用机器学习 (ML) 技术来确定文本的来源（人类或聊天机器人）。具体来说，我们考虑了两种解决这个问题的方法：特征分析和嵌入。我们的特征分析方法涉及从文本中提取一组特征进行分类。我们还探索了使用上下文嵌入和基于 Transformer 的架构来训练分类模型。我们提出的解决方案具有很高的分类准确性，可以作为文本分析的有用工具，从而可以在先进的人工智能技术时代更好地理解聊天机器人生成的文本。]]></description>
      <guid>https://arxiv.org/abs/2408.04647</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:39 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型时代的情感计算：基于 NLP 视角的综述</title>
      <link>https://arxiv.org/abs/2408.04638</link>
      <description><![CDATA[arXiv:2408.04638v1 公告类型：新
摘要：情感计算（AC）融合了计算机科学、心理学和认知科学知识，旨在使机器能够识别、解释和模拟人类的情感。为了创造更多价值，AC 可以应用于社交媒体、金融、医疗保健、教育等多种场景。情感计算（AC）包括两个主流任务，即情感理解（AU）和情感生成（AG）。针对 AU 任务的预训练语言模型（PLM）的微调已取得巨大成功。然而，这些模型缺乏泛化能力，需要针对特定​​任务的专门模型。此外，传统的 PLM 在 AG 方面面临挑战，特别是在生成多样化和情感丰富的反应方面。大型语言模型（LLM）（例如 ChatGPT 系列和 LLaMA 模型）的出现带来了新的机遇和挑战，催化了 AC 的范式转变。 LLM 具有情境学习、常识推理和高级序列生成的能力，这为 AU 带来了前所未有的机遇。为了从 NLP 的角度全面概述 LLM 时代的 AC，我们总结了 LLM 在该领域的研究发展，旨在提供新的见解。具体来说，我们首先总结与 AC 相关的传统任务，并介绍基于 LLM 的初步研究。随后，我们概述了流行的 LLM 用于改进 AC 任务的相关技术，包括指令调优和提示工程。对于指令调优，我们讨论了全参数微调和参数高效方法，例如 LoRA、P-Tuning 和提示调优。在提示工程中，我们研究了 AU 和 AG 的零样本、少样本、思路链 (CoT) 和基于代理的方法。为了清楚地了解 LLM 在不同情感计算任务上的表现，我们进一步总结了现有的基准和评估方法。]]></description>
      <guid>https://arxiv.org/abs/2408.04638</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>从音频转录中进行抽象总结</title>
      <link>https://arxiv.org/abs/2408.04639</link>
      <description><![CDATA[arXiv:2408.04639v1 公告类型：新
摘要：目前，大型语言模型越来越受欢迎，它们的成果被应用于许多领域，从文本翻译到生成查询答案。然而，这些新机器学习算法的主要问题是，训练这样的模型需要大量的计算资源，而这些资源只有大型 IT 公司才拥有。为了避免这个问题，提出了许多方法（LoRA、量化），以便现有模型可以有效地针对特定任务进行微调。在本文中，我们提出了一个使用这些技术的 E2E（端到端）音频摘要模型。此外，本文还研究了这些方法对所考虑问题的有效性，并得出了关于这些方法适用性的结论。]]></description>
      <guid>https://arxiv.org/abs/2408.04639</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>加强农业气象建议法学硕士</title>
      <link>https://arxiv.org/abs/2408.04640</link>
      <description><![CDATA[arXiv:2408.04640v1 公告类型：新
摘要：农业气象建议对于提高作物生产力和可持续性至关重要，因为它可以为农民提供基于天气预报、土壤条件和特定作物数据的可行见解。本文提出了一种新方法，利用大型语言模型 (LLM) 和提示工程来提高这些建议的准确性和相关性。我们设计了一个多轮提示框架，使用更新的数据和反馈迭代地完善建议，并在 ChatGPT、Claude2 和 GPT-4 上实施。我们的方法针对基线模型和使用手动收集的数据集的思路链 (CoT) 方法进行了评估。结果表明，准确性和上下文相关性显着提高，我们的方法实现了高达 90% 的准确率和高 GPT-4 分数。通过现实世界的试点研究进行的额外验证进一步证实了我们方法的实际好处，凸显了其改变农业实践和决策的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.04640</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>GPT-3 支持的信息提取，用于构建强大的知识库</title>
      <link>https://arxiv.org/abs/2408.04641</link>
      <description><![CDATA[arXiv:2408.04641v1 公告类型：新
摘要：这项工作使用最先进的语言模型 GPT-3 为知识库开发提供了一种新颖的信息提取方法。建议的方法试图解决从非结构化文本中获取相关实体和关系以提取结构化信息的困难。我们对来自不同领域的大量文本语料库进行了实验，以评估我们提出的技术的性能。评估指标经常用于信息提取任务，包括精确度、召回率和 F1 分数。研究结果表明，GPT-3 可用于高效准确地从文本中提取相关和正确的信息，从而提高知识库创建的精确度和生产力。我们还评估了我们建议的方法与已经在使用的最先进的信息提取技术相比的表现。研究结果表明，通过在上下文学习中仅使用少量实例，我们提出的策略就能产生具有竞争力的结果，并且在数据注释和工程费用方面显着节省。此外，我们使用我们提出的方法来检索生物医学信息，证明了它在现实环境中的实用性。总而言之，我们提出的方法提供了一种可行的方法来克服从非结构化文本中获取结构化数据以创建知识库的困难。它可以大大提高信息提取的准确性和有效性，这对于许多应用程序（包括聊天机器人、推荐引擎和问答系统）都是必需的。]]></description>
      <guid>https://arxiv.org/abs/2408.04641</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>APE：基于主动学习的工具，用于为基于 LLM 的实体匹配查找有用的少量样本示例</title>
      <link>https://arxiv.org/abs/2408.04637</link>
      <description><![CDATA[arXiv:2408.04637v1 公告类型：新
摘要：提示工程是一个迭代过程，通常需要大量的手动工作来制定合适的指令，以有效地指导大型语言模型 (LLM) 执行特定任务。结合少量样本是一种重要且有效的方法，可以为 LLM 提供精确的指令，从而提高 LLM 性能。尽管如此，确定 LLM 最具信息量的演示是劳动密集型的，通常需要在广泛的搜索空间中进行筛选。在这个演示中，我们展示了一种名为 APE（主动提示工程）的人机交互工具，旨在通过主动学习来完善提示。从主动学习中汲取灵感，APE 迭代地选择最模糊的例子进行人工反馈，这些例子将转化为提示中的少量样本。演示记录可以在提交中找到，也可以在 https://youtu.be/OwQ6MQx53-Y 查看。]]></description>
      <guid>https://arxiv.org/abs/2408.04637</guid>
      <pubDate>Tue, 13 Aug 2024 03:16:37 GMT</pubDate>
    </item>
    </channel>
</rss>