<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 05 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用好奇机器人进行无监督、自下而上的类别发现以实现符号接地</title>
      <link>https://arxiv.org/abs/2404.03092</link>
      <description><![CDATA[arXiv:2404.03092v1 公告类型：新
摘要：为了解决符号基础问题，并在儿童早期语言发展的推动下，我们利用了一个配备了近似好奇心模型的机器人，特别注重自下而上构建基于物理世界的无监督类别。也就是说，机器人不是从自上而下的符号（例如，指代物体的单词）开始并通过应用预定样本来提供含义，而是自主地逐渐将其探索空间分解为一系列越来越具体的未标记类别此时，外部专家可以选择提供符号关联。我们通过使用可以观察视觉世界的机器人、引入更高维度的感官空间以及使用更通用的类别构建方法来扩展先前的工作。我们的实验表明，机器人根据动作和视觉观察到的内容来学习类别，并且这些类别可以象征性地扎根于。https://info.arxiv.org/help/prep#comments]]></description>
      <guid>https://arxiv.org/abs/2404.03092</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:13 GMT</pubDate>
    </item>
    <item>
      <title>Mai Ho'om\=auna i ka 'Ai：语言模型改进夏威夷语自动语音识别</title>
      <link>https://arxiv.org/abs/2404.03073</link>
      <description><![CDATA[arXiv:2404.03073v1 公告类型：新
摘要：在本文中，我们通过将大量独立文本数据合并到 ASR 基础模型 Whisper 中，解决了改进夏威夷语这一低资源语言的自动语音识别 (ASR) 的挑战。为此，我们使用约 150 万个夏威夷语文本单词训练外部语言模型 (LM)。然后，我们使用 LM 对 Whisper 进行重新评分，并在手动策划的标记夏威夷语数据测试集上计算单词错误率 (WER)。作为基准，我们使用 Whisper，无需外部 LM。实验结果表明，当使用 Hawaiian LM 重新评分 ASR 输出时，WER 会得到微小但显着的改进。结果支持在开发针对代表性不足的语言的 ASR 系统时利用所有可用数据。]]></description>
      <guid>https://arxiv.org/abs/2404.03073</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:12 GMT</pubDate>
    </item>
    <item>
      <title>通过大语言模型构建多学科材料科学中的功能材料知识图谱</title>
      <link>https://arxiv.org/abs/2404.03080</link>
      <description><![CDATA[arXiv:2404.03080v1 公告类型：新
摘要：材料科学和人工智能的融合为从广泛的科学文献中收集、分析和生成新材料提供了新的机会。尽管有潜在的好处，但手动注释、精确提取和可追溯性问题等持续存在的挑战仍然存在。大型语言模型已成为解决这些障碍的有前途的解决方案。本文介绍了功能材料知识图谱（FMKG），这是一种多学科材料科学知识图谱。通过利用先进的自然语言处理技术，从包含过去十年发表的所有高质量研究论文的语料库中提取数百万个实体形成三元组。它将非结构化信息组织成九个不同的标签，涵盖名称、公式、首字母缩略词、结构/阶段、属性、描述符、合成、表征方法、应用和领域，无缝集成论文的数字对象标识符。作为最新的功能材料结构化数据库，FMKG 是加快功能材料发展的强大催化剂，也是利用全文文本构建更全面的材料知识图谱的基础。此外，我们的研究为基于文本挖掘的实用知识管理系统奠定了基础，不仅适用于复杂的材料系统，而且适用于其他专业领域。]]></description>
      <guid>https://arxiv.org/abs/2404.03080</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:12 GMT</pubDate>
    </item>
    <item>
      <title>语言、环境和机器人导航</title>
      <link>https://arxiv.org/abs/2404.03049</link>
      <description><![CDATA[arXiv:2404.03049v1 公告类型：新
摘要：本文探讨了机器人导航系统中语言输入的集成，利用符号相互依赖假说来弥合符号认知和具身认知之间的鸿沟。它研究了先前将语言和语义纳入神经网络 (NN) 和同步定位与地图绘制 (SLAM) 方法的工作，强调了这些集成如何推动该领域的发展。通过将抽象符号操作与感觉运动基础进行对比，我们提出了一个统一的框架，其中语言既充当抽象的交流系统，又充当感知体验的基础表征。我们对分布式语义认知模型及其在自主代理中的应用的回顾强调了语言集成系统的变革潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.03049</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:11 GMT</pubDate>
    </item>
    <item>
      <title>GPT-DETOX：基于上下文学习的文本解毒释义器</title>
      <link>https://arxiv.org/abs/2404.03052</link>
      <description><![CDATA[arXiv:2404.03052v1 公告类型：新
摘要：有害和冒犯性的沟通或内容不利于社交媒体平台上用户的社交联系和心理状态。文本去毒是自然语言处理 (NLP) 中的一项关键任务，其目标是消除文本中的脏话和毒性，同时保留其内容。监督和无监督学习是设计文本解毒解决方案的常见方法。然而，这些方法需要微调，导致计算开销。在本文中，我们提出 GPT-DETOX 作为使用 GPT-3.5 Turbo 进行基于提示的上下文学习的框架。我们利用零样本和少样本提示技术来净化输入句子。为了生成少样本提示，我们提出了两种方法：单词匹配示例选择（WMES）和上下文匹配示例选择（CMES）。我们还考虑了集成上下文学习（EICL），其中集成是由零样本和所有少样本设置的基本提示塑造的。我们使用 ParaDetox 和 APPDIA 作为基准排毒数据集。我们的实验结果表明，零样本解决方案实现了有希望的性能，而我们最好的几次样本设置优于 ParaDetox 上最先进的模型，并在 APPDIA 上显示了可比较的结果。我们的 EICL 解决方案获得了最佳性能，针对这两个数据集至少提高了 10%。]]></description>
      <guid>https://arxiv.org/abs/2404.03052</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:11 GMT</pubDate>
    </item>
    <item>
      <title>不完整的循环：大型语言模型中的演绎、归纳和溯因学习</title>
      <link>https://arxiv.org/abs/2404.03028</link>
      <description><![CDATA[arXiv:2404.03028v1 公告类型：新
摘要：现代语言模型（LM）可以学习以不同的方式执行新任务：在指令跟随中，目标任务用自然语言明确描述；在少样本提示中，任务是通过少量示例隐式指定的；在指令推理中，语言模型会被提供上下文中的示例，然后在做出预测之前提示生成自然语言任务描述。这些过程中的每一个都可以被认为调用不同形式的推理：指令遵循涉及演绎推理，小提示提示涉及归纳推理，指令推理涉及溯因推理。这些不同的能力有何关联？在四个 LM（来自 gpt 和 llama 系列）和两个学习问题（涉及算术函数和机器翻译）中，我们发现不同类型的推理之间存在很强的分离性：LM 有时可以从少量提示中有效学习，即使它们无法做到这一点解释自己的预测规则；相反，他们有时会推断出有用的任务描述，但完全无法从人类生成的同一任务描述中学习。我们的结果强调了推理的非系统性，即使在当今一些最大的语言模型中也是如此，并强调了这样一个事实：看似相似的提示程序可能会调用非常不同的学习机制。]]></description>
      <guid>https://arxiv.org/abs/2404.03028</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:10 GMT</pubDate>
    </item>
    <item>
      <title>花木兰：语言模型中事实可变性的研究</title>
      <link>https://arxiv.org/abs/2404.03036</link>
      <description><![CDATA[arXiv:2404.03036v1 公告类型：新
摘要：事实会受到偶然性的影响，在不同的情况下可能是真实的，也可能是虚假的。其中一个偶然事件就是时间，其中一些事实在特定时期内发生变化，例如，国家总统或冠军得主。值得信赖的语言模型理想地识别可变事实并相应地处理它们。我们创建了 MuLan，这是一个评估英语语言模型预测时间偶然性的能力的基准，涵盖 1:1 和 1:N 关系。我们假设可变事实的编码方式与不可变事实不同，因此更容易更新。在对六种流行的大型语言模型的详细评估中，我们一致发现法学硕士的置信度、表示和更新行为存在差异，具体取决于事实的可变性。我们的研究结果应该为未来向法学硕士注入和诱导时间相关知识的工作提供信息。]]></description>
      <guid>https://arxiv.org/abs/2404.03036</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:10 GMT</pubDate>
    </item>
    <item>
      <title>祝福还是诅咒？关于生成人工智能对假新闻影响的调查</title>
      <link>https://arxiv.org/abs/2404.03021</link>
      <description><![CDATA[arXiv:2404.03021v1 公告类型：新
摘要：假新闻对我们的社会产生了重大影响。它们影响着消费者、选民和许多其他社会群体。虽然假新闻已经存在了几个世纪，但生成人工智能将假新闻提升到了一个新的水平。现在可以自动创建大量高质量的、有针对性的假新闻。另一方面，生成式人工智能也可以帮助检测假新闻。这两个领域都很年轻，但发展很快。
  这项调查对 2024 年用于假新闻检测和创建的生成式人工智能的研究和实际应用进行了全面审查。按照结构化文献调查方法，本文综合了以下主题组中的当前结果：1）支持技术，2）创建假新闻，3）案例研究社交媒体作为最相关的分发渠道，4）假新闻检测，以及 5）深度伪造作为即将到来的技术。
  本文还指出了当前的挑战和未解决的问题。]]></description>
      <guid>https://arxiv.org/abs/2404.03021</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:09 GMT</pubDate>
    </item>
    <item>
      <title>BCAmirs 在 SemEval-2024 任务 4：超越语言：模因说服的多模式和多语言探索</title>
      <link>https://arxiv.org/abs/2404.03022</link>
      <description><![CDATA[arXiv:2404.03022v1 公告类型：新
摘要：模因结合了文本和图像，经常使用隐喻来传达有说服力的信息，塑造公众舆论。受此启发，我们的团队参与了 SemEval-2024 任务 4，这是一项分层多标签分类任务，旨在识别模因中嵌入的修辞和心理说服技术。为了解决这个问题，我们引入了一个标题生成步骤来评估模态差距和图像中附加语义信息的影响，这改善了我们的结果。我们的最佳模型利用 GPT-4 生成的标题和 meme 文本来微调 RoBERTa 作为文本编码器和 CLIP 作为图像编码器。它在所有 12 个子任务中都大幅优于基线。特别是，它在子任务 2a 中的所有语言中排名前 3，在子任务 2b 中排名前 4，展示了在数量上强大的性能。引入的中间步骤所实现的改进可能归因于挑战视觉编码器的图像的隐喻本质。这凸显了改进抽象视觉语义编码的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.03022</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:09 GMT</pubDate>
    </item>
    <item>
      <title>Min-K%++：改进了从大型语言模型中检测预训练数据的基线</title>
      <link>https://arxiv.org/abs/2404.02936</link>
      <description><![CDATA[arXiv:2404.02936v1 公告类型：新
摘要：大型语言模型（LLM）的预训练数据检测问题由于其对版权侵犯和测试数据污染等关键问题的影响而受到越来越多的关注。当前最先进的方法 Min-K% 测量原始代币概率，我们认为这可能不是信息最丰富的信号。相反，我们提出 Min-K%++ 通过整个词汇表的分类分布统计来标准化标记概率，这准确地反映了目标标记与词汇表中其他候选标记相比的相对可能性。理论上，我们通过证明其估计的统计量在 LLM 训练期间得到显式优化来支持我们的方法，从而作为检测训练数据的可靠指标。根据经验，在 WikiMIA 基准上，Min-K%++ 在五个模型的 AUROC 平均检测中比 SOTA Min-K% 好 6.2% 到 10.5%。在更具挑战性的 MIMIR 基准测试中，尽管不需要额外的参考模型，Min-K%++ 始终优于 Min-K%，并且与基于参考的方法的性能相当。]]></description>
      <guid>https://arxiv.org/abs/2404.02936</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:08 GMT</pubDate>
    </item>
    <item>
      <title>面向隐喻理解的完全可解释且更具可扩展性的 RSA 模型</title>
      <link>https://arxiv.org/abs/2404.02983</link>
      <description><![CDATA[arXiv:2404.02983v1 公告类型：新
摘要：理性言语行为（RSA）模型提供了一个灵活的框架来模拟计算术语中的语用推理。然而，最先进的 RSA 模型距离现代机器学习技术仍然相当遥远，并且在可解释性和可扩展性方面存在许多限制。在这里，我们引入了一种用于隐喻理解的新 RSA 框架，该框架通过提供一个明确的公式（基于说话者和听者之间相互共享的信息）来解决这些限制，用于估计交际目标，并使用梯度学习合理性参数 -为基础的方法。该模型针对 24 个隐喻进行了测试，不限于传统的 $\textit{John-is-a-shark}$ 类型。结果表明，模型生成的分布与从人类行为数据获得的解释之间总体上存在很强的正相关性，当预期含义利用了车辆概念固有的属性时，这种相关性就会增加。总体而言，研究结果表明，基于典型性的贝叶斯模型可以很好地捕获隐喻处理，即使更具可扩展性和可解释性，也为其他语用现象和增加大型语言模型可解释性的新用途提供了可能的应用。然而，结果强调，隐喻意义的更具创造性的细微差别（没有严格编码在词汇概念中）对机器来说是一个具有挑战性的方面。]]></description>
      <guid>https://arxiv.org/abs/2404.02983</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:08 GMT</pubDate>
    </item>
    <item>
      <title>GreedLlama：金融价值一致的大语言模型在道德推理中的表现</title>
      <link>https://arxiv.org/abs/2404.02934</link>
      <description><![CDATA[arXiv:2404.02934v1 公告类型：新
摘要：本文通过 GreedLlama 的案例研究，研究了大型语言模型 (LLM) 与财务优化相结合的伦理影响，GreedLlama 是一个经过微调以优先考虑经济利益结果的模型。通过将 GreedLlama 在道德推理任务中的表现与基本 Llama2 模型进行比较，我们的结果突出了一个令人担忧的趋势：GreedLlama 表现出对利润的明显偏好，而不是道德考虑，在低和低的情况下，以比基本模型低得多的速度做出道德上适当的决策。道德高度模糊。在低模糊性情况下，GreedLlama 的道德决策下降至 54.4%，而基础模型为 86.9%；而在高模糊性情况下，该比率为 47.4%，而基础模型为 65.1%。这些发现强调了法学硕士单一维度价值调整的风险，强调需要将更广泛的道德价值观融入人工智能开发，以确保决策不仅仅由经济激励驱动。该研究呼吁对法学硕士部署采取平衡的方法，主张将道德考虑纳入商业应用模型中，特别是在缺乏监管的情况下。]]></description>
      <guid>https://arxiv.org/abs/2404.02934</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:07 GMT</pubDate>
    </item>
    <item>
      <title>KnowHalu：通过基于多形式知识的事实检查进行幻觉检测</title>
      <link>https://arxiv.org/abs/2404.02935</link>
      <description><![CDATA[arXiv:2404.02935v1 公告类型：新
摘要：本文介绍了 KnowHalu，这是一种检测大型语言模型（LLM）生成的文本中的幻觉的新方法，利用逐步推理、多形式查询、用于事实检查的多形式知识以及基于融合的检测机制。随着法学硕士越来越多地应用于各个领域，确保其输出不被幻觉至关重要。认识到现有方法的局限性，这些方法要么依赖于法学硕士的自我一致性检查，要么在不考虑查询复杂性或知识形式的情况下执行事后事实检查，KnowHalu 提出了一种用于幻觉检测的两阶段过程。在第一阶段，它识别非虚构的幻觉——虽然事实上正确，但与查询无关或非特定的响应。第二阶段，基于多形式的事实检查，包含五个关键步骤：推理和查询分解、知识检索、知识优化、判断生成和判断聚合。我们的广泛评估表明，KnowHalu 在检测各种任务中的幻觉方面显着优于 SOTA 基线，例如，在 QA 任务中提高了 15.65%，在摘要任务中提高了 5.50%，突出了其在检测 LLM 生成内容中的幻觉方面的有效性和多功能性。]]></description>
      <guid>https://arxiv.org/abs/2404.02935</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:07 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型来理解电信标准</title>
      <link>https://arxiv.org/abs/2404.02929</link>
      <description><![CDATA[arXiv:2404.02929v1 公告类型：新
摘要：第三代合作伙伴计划（3GPP）已成功引入全球移动标准。然而，随着时间的推移，这些标准的数量和复杂性不断增加，从而使供应商和服务提供商获取相关信息变得更加复杂。使用生成人工智能（AI），特别是大型语言模型（LLM），可以更快地访问相关信息。在本文中，我们评估了最先进的法学硕士用作 3GPP 文档参考的问答 (QA) 助手的能力。我们的贡献是三重的。首先，我们提供了评估法学硕士表现的基准和衡量方法。其次，我们对这些法学硕士之一进行数据预处理和微调，并提供指南以提高适用于所有法学硕士的回答的准确性。第三，我们提供了自己的模型 TeleRoBERTa，其性能与基础 LLM 相当，但参数数量少了一个数量级。结果表明，法学硕士可以用作电信技术文档的可靠参考工具，因此具有从故障排除和维护到网络运营和软件产品开发的许多不同应用的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.02929</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:06 GMT</pubDate>
    </item>
    <item>
      <title>阅读：从对抗的角度改进关系提取</title>
      <link>https://arxiv.org/abs/2404.02931</link>
      <description><![CDATA[arXiv:2404.02931v1 公告类型：新
摘要：最近在关系提取（RE）方面的工作已经取得了有希望的基准精度；然而，我们的对抗性攻击实验表明，这些作品过度依赖实体，使其泛化能力值得怀疑。为了解决这个问题，我们提出了一种专门为 RE 设计的对抗性训练方法。我们的方法向样本引入了序列级和标记级扰动，并使用单独的扰动词汇来改进对实体和上下文扰动的搜索。此外，我们引入了一种概率策略，用于在对抗训练期间在上下文中留下干净的标记。该策略为实体提供了更大的攻击预算，并引导模型利用嵌入在上下文中的关系模式。大量的实验表明，与各种对抗训练方法相比，我们的方法显着提高了模型的准确性和鲁棒性。此外，对不同数据可用性设置的实验凸显了我们的方法在资源匮乏的情况下的有效性。我们还对我们提出的方法进行了深入分析并提供了进一步的提示。我们将在 https://github.com/David-Li0406/READ 发布我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2404.02931</guid>
      <pubDate>Fri, 05 Apr 2024 06:14:06 GMT</pubDate>
    </item>
    </channel>
</rss>