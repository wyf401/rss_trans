<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Fri, 07 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>作为催化剂的讽刺检测：通过跨目标能力提高立场检测</title>
      <link>https://arxiv.org/abs/2503.03787</link>
      <description><![CDATA[ARXIV：2503.03787V1公告类型：新 
摘要：立场检测（SD）已成为关键领域，因为它在各种情况下的应用导致NLP内的研究增加。然而，从在线平台中得出的文本的微妙和复杂性通常包含讽刺性语言，在准确确定作者立场时对SD算法构成了重大挑战。本文通过使用SD讽刺来解决这一问题。它还通过进行跨目标SD（CTSD）来解决针对新目标培训SD模型的注释数据的问题。所提出的方法涉及微调伯特和罗伯塔模型，然后将其他深度学习层串联。使用可公开可用数据集的各种SD的最新基线来评估该方法。值得注意的是，我们的模型甚至在融入讽刺探测预训练之前，都超过了内域SD和CTSD任务上的最佳SOTA模型。将讽刺知识的整合到模型中大大减少了SD中讽刺文本元素的错误分类，从而使我们的模型可以准确预测以前被错误分类而没有讽刺检测预训练的文本中的85％。这种增强有助于增加模型的平均宏F1得分。 CTSD任务达到的性能与内域任务的性能相当。我们还揭示了转移学习框架的成功取决于讽刺检测和SD的词汇属性之间的相关性。这项研究代表了讽刺检测作为在SD背景下作为中间转移学习任务的首次探索，同时还利用Bert或Roberta与其他深度学习技术的串联。所提出的方法为该领域的未来研究建立了基础。]]></description>
      <guid>https://arxiv.org/abs/2503.03787</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>视觉模型努力使跨模式的实体保持一致</title>
      <link>https://arxiv.org/abs/2503.03854</link>
      <description><![CDATA[ARXIV：2503.03854V1公告类型：新 
摘要：链接的跨模式实体是指在不同模态上对齐实体及其属性的能力。虽然跨模式实体链接是真实世界应用所需的一项基本技能，例如多模式代码生成，假新闻检测或场景理解，但文献中尚未对其进行彻底研究。在本文中，我们介绍了一个新的任务和基准来解决这一差距。我们的基准MATE由5.5k评估实例组成，其中包含与文本表示的视觉场景。为了评估跨模式实体链接性能，我们设计了一个提问的任务，该任务涉及基于该对象的唯一属性在另一种模态中的唯一属性中检索对象的一个​​属性。我们在这项任务上评估了最先进的视觉模型（VLM）和人类，并发现与人类相比，VLMS艰巨的挣扎，尤其是随着场景中的对象数量的增加。我们的分析还表明，尽管经过思考的提示可以提高VLM的性能，但模型却无法实现人类水平的水平。这些发现凸显了需要在跨模式实体联系的进一步研究的必要性，并表明伴侣是支持这一进展的强大基准。]]></description>
      <guid>https://arxiv.org/abs/2503.03854</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不及规范的法律：更好地理解语言模型设计决策的下游影响</title>
      <link>https://arxiv.org/abs/2503.03862</link>
      <description><![CDATA[ARXIV：2503.03862V1公告类型：新 
摘要：语言模型功能的改进通常归因于模型大小或培训数据的增加，但是在某些情况下，经过策划数据或具有不同建筑决策的较小模型可以胜过对更大的代币培训的模型。有什么解释？为了量化这些设计选择的影响，我们在各种各样的尺度上进行了92个开源预算模型，包括最先进的开放式型型号以及较少的性能模型以及那些具有较少传统设计决策的模型。我们发现，除了模型大小和训练令牌数量之外，通过合并功能，我们可以相对增加3-28％的预测下游性能的能力，而与单独使用比例相比。模型设计决策的分析揭示了对数据组成的见解，例如15-25 \％代码之间的语言和代码任务之间的权衡，以及某些建筑决策的更好性能，例如选择旋转而不是学习的嵌入。从广义上讲，我们的框架为对模型开发选择如何塑造最终功能的方式进行更系统的研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2503.03862</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于扩展法律改革的AI：圣克拉拉县的映射和编辑种族盟约</title>
      <link>https://arxiv.org/abs/2503.03888</link>
      <description><![CDATA[ARXIV：2503.03888V1公告类型：新 
摘要：许多司法管辖区已采取行动确定和罢免这些规定，包括加利福尼亚州，该规定在2021年要求所有县实施这样的过程。然而，该量表可能是压倒性的，仅圣塔克拉拉县（SCC）拥有超过2400万个财产契据文件，因此纯粹是手动审查了。我们提出了一种通过与SCC店员办公室的合作伙伴关系而开发的解决这一紧迫问题的新方法。首先，我们利用开放的大型语言模型，并经过微调来检测具有高精度和回忆的种族盟约。我们估计该系统将手动工作减少了86,500人小时，而可比现成的封闭模型的成本不到成本的2％。其次，我们说明了该县将该模型整合到负责任的运营实践中，包括法律审查和创建历史注册表，并发布了我们的模型，以协助从事类似努力的数百个司法管辖区。最后，我们的结果揭示了种族盟约，尖锐的地理聚类以及少数开发商在维持住房歧视方面的不成比例作用的不同时期。我们估计到1950年，全县四分之一的财产属于种族盟约。]]></description>
      <guid>https://arxiv.org/abs/2503.03888</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Tec-Habilidad：桥接教育和就业的技能分类</title>
      <link>https://arxiv.org/abs/2503.03932</link>
      <description><![CDATA[ARXIV：2503.03932V1公告类型：新 
摘要：近年来，工作应用和评估过程已经显着发展，这主要是由于技术的进步以及公司运作方式的变化。技能提取和分类仍然是现代招聘过程的重要组成部分，因为它提供了一种更客观的方法来评估候选人并自动使其技能与工作要求保持一致。但是，为了有效地评估技能，技能提取工具必须识别简历上的各种技能，包括直接提及，含义，同义词，缩写，短语和能力水平，并区分硬性和软技能。尽管LLM（大型模型）等工具有助于从工作应用程序中提取和分类技能，但缺乏全面的数据集来评估这些模型在准确识别和分类西班牙语工作应用程序中的技能方面的有效性。这一差距阻碍了我们评估模型的可靠性和精度的能力，这对于确保所选候选人真正拥有所需的工作技能至关重要。在本文中，我们开发了一个西班牙语数据集来进行技能提取和分类，提供注释方法来区分知识，技能和能力，并提供深度学习的基准，以推动强大的解决方案进行技能分类。]]></description>
      <guid>https://arxiv.org/abs/2503.03932</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高级演算问题的大语言模型的性能比较</title>
      <link>https://arxiv.org/abs/2503.03960</link>
      <description><![CDATA[ARXIV：2503.03960V1公告类型：新 
摘要：本文对七个不同的大语模型（LLM）的性能进行了深入的分析，以解决一组多样化的数学高级演算问题。该研究旨在评估这些模型的准确性，可靠性和解决问题的能力，包括Chatgpt 4O，Gemini，Gemini以1.5 Pro，Copilot Pro，Claude 3.5 SONNET，META AI，MISTA AI，MISTRAL AI和CLEXITY效力。评估是通过一系列32个测试问题进行的，总共包括320分。这些问题涵盖了各种主题，从矢量计算和几何解释到整体评估和优化任务。结果突出了模型表现中的重要趋势和模式，揭示了它们的优势和弱点 - 例如，诸如ChatGpt 4O和Mistral AI之类的模型在各种问题类型上表现出一致的准确性，表明它们在数学问题解决方面的稳健性和可靠性，而诸如GexInigy的模型（如1.5 Pro和Meta ai Ai I Importers）尤其是针对特定的问题，并且在涉及特定的问题上，并在特定的问题上提出了一致性。这项研究还强调了重新提出在实现准确解决方案中的重要性，这在几种情况下可以看出，模型最初提供了错误的答案，但在重新提出后对其进行了更正。总体而言，这项研究为数学微积分领域的LLM的当前功能和局限性提供了宝贵的见解，并详细分析了每种模型在特定问题上的绩效，从而对他们的优势和改进方面有了深刻的了解，从而有助于LLM技术的持续发展和改进。这些发现与寻求利用LLM的教育工作者，研究人员和开发人员尤其重要，用于数学中的教育和实际应用。]]></description>
      <guid>https://arxiv.org/abs/2503.03960</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于在双语语言模型中获取共享语法表示</title>
      <link>https://arxiv.org/abs/2503.03962</link>
      <description><![CDATA[ARXIV：2503.03962V1公告类型：新 
摘要：虽然跨语言转移对当代语言模型的多语言能力至关重要，但它的发生方式尚未得到充分理解。在本文中，我们询问一种单语言模型开始接受第二语言培训时会发生什么。具体来说，我们训练小型双语模型，我们控制每种语言的数据量和语言曝光顺序。为了找到共享多语言表示的证据，我们转向结构启动，这种方法用于研究人类的语法表达。我们首先复制先前的跨语言结构启动结果，并发现在控制训练数据数量和语言暴露之后，语言对和方向之间存在不对称的影响。我们认为，这种不对称可能会塑造有关人类结构启动效应的假设。我们还发现，对于不太相似的语言对，结构性启动效应不太强大，强调了跨语言转移学习的潜在局限性以及对类型上多种语言的共享表示。]]></description>
      <guid>https://arxiv.org/abs/2503.03962</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Reasongraph：推理路径的可视化</title>
      <link>https://arxiv.org/abs/2503.03979</link>
      <description><![CDATA[ARXIV：2503.03979V1公告类型：新 
摘要：大型语言模型（LLMS）推理过程由于其复杂性和缺乏有组织的可视化工具而在分析方面具有挑战性。我们提出了Reasongraph，这是一个基于Web的平台，用于可视化和分析LLM推理过程。它在与主要的LLM提供商集成和五十多个最先进的模型时同时支持顺序和基于树的推理方法。 Reasongraph将直观的UI与元推理方法选择，可配置的可视化参数以及一个促进有效扩展的模块化框架结合在一起。我们的评估显示了各种下游应用程序的高解析可靠性，有效的处理和强大的可用性。通过提供统一的可视化框架，Reasongraph可以减少分析复杂推理路径，改善逻辑过程中的错误检测，并使基于LLM的应用程序更有效地开发的认知负载。该平台是开源的，在LLM推理分析中促进了可访问性和可重复性。]]></description>
      <guid>https://arxiv.org/abs/2503.03979</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过提示，在生物信息学NLP中的多个任务上对大型语言模型进行基准测试</title>
      <link>https://arxiv.org/abs/2503.04013</link>
      <description><![CDATA[ARXIV：2503.04013V1公告类型：新 
摘要：大型语言模型（LLM）已成为解决生物学问题的重要工具，提供了对常规方法的准确性和适应性的提高。已经提出了几种基准测试来评估这些LLM的性能。但是，当前的基准测试基准几乎无法有效地评估这些模型的性能。在本文中，我们介绍了一个全面的基于提示的基准测试框架，该框架称为Bio-Benchmark，其中包括30个关键的生物信息学任务，涵盖蛋白质，RNA，药物，电子健康记录和传统中医等领域。使用此基准测试，我们使用0次和少量的经营链（COT）设置评估了六个主流LLM，包括GPT-4O和LLAMA-3.1-70B等，而无需微调以揭示其内在功能。为了提高我们的评估效率，我们演示了生物传动器，这是一种从LLM响应中提取答案的新工具，与现有方法相比，它将提取精度提高了30％。我们的基准结果显示了适合当前LLM的生物学任务，并确定需要增强的特定领域。此外，我们提出了有针对性的及时工程策略，以优化在这些情况下的LLM性能。基于这些发现，我们为开发针对各种生物应用定制的更健壮的LLM提供了建议。这项工作提供了全面的评估框架和强大的工具，以支持LLM在生物信息学中的应用。]]></description>
      <guid>https://arxiv.org/abs/2503.04013</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型揭示新知识学习的不平等</title>
      <link>https://arxiv.org/abs/2503.04064</link>
      <description><![CDATA[ARXIV：2503.04064V1公告类型：新 
摘要：随着大型语言模型（LLMS）逐渐成为全球日常生活中问题解决问题的组成工具，因此了解语言不平等变得越来越重要。现有的研究主要集中于静态分析，以评估LLM跨语言的现有知识和能力的差异。但是，LLM正在不断发展，获得了新知识，以产生最新的特定领域响应。因此，在这个动态过程中调查语言不平等也是必不可少的。在本文中，我们探讨了LLM在不同语言和四个关键方面的新知识学习中的不平等：有效性，可转移性，优先级和鲁棒性。通过使用专有和开源模型的两种设置（在文本学习和微调）下进行广泛的实验，我们证明，低资源语言始终在所有四个维度上都面临着劣势。通过阐明这些差异，我们旨在提高对LLMS新知识学习中语言不平等的认识，从而促进更具包容性和公平的未来LLM的发展。]]></description>
      <guid>https://arxiv.org/abs/2503.04064</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Chart-HQA：假设问题回答图中的基准</title>
      <link>https://arxiv.org/abs/2503.04095</link>
      <description><![CDATA[ARXIV：2503.04095V1公告类型：新 
摘要：多模式的大语言模型（MLLMS）因其强烈的视觉语义理解而引起了极大的关注。大多数现有图表基准都评估了MLLM从图表中解析信息以回答问题的能力。但是，它们忽略了MLLMS的固有输出偏见，其中模型依靠其参数内存来回答问题，而不是真正理解图表内容。为了解决这一限制，我们介绍了一个新颖的图表假设问题回答（HQA）任务，该任务对同一问题施加了假设，以强迫模型根据图表内容进行反事实推理。此外，我们介绍了HAI，HAI是一种人类交互式数据综合方法，该方法利用LLMS的有效文本编辑功能以及人类专家知识，以低成本生成多样化和高质量的HQA数据。使用HAI，我们构建了Chart-HQA，这是一种从公开可用的数据源合成的具有挑战性的基准。对18个MLLM的不同模型尺寸的评估结果表明，当前模型面临着重大的概括挑战，并在HQA任务上表现出不平衡的推理性能。]]></description>
      <guid>https://arxiv.org/abs/2503.04095</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM推理准确性和解释的差异：非裔美国人英语的案例研究</title>
      <link>https://arxiv.org/abs/2503.04099</link>
      <description><![CDATA[ARXIV：2503.04099V1公告类型：新 
摘要：大语言模型（LLMS）在推理任务中表现出了显着的功能，从而导致了广泛的部署。但是，最近的研究强调了这些模型中的偏见，特别是在处理非裔美国人英语（AAE）等方言变化方面。在这项工作中，我们系统地研究了LLM推理任务中的方言差异。我们开发了一个实验框架，将基于LLM的方言转换与已建立的语言分析相结合的标准美国英语（SAE）和AAE提示，比较了LLM性能。我们发现，与同等的SAE问题相比，LLM始终产生较少准确的响应和更简单的推理链和解释AAE投入，在社会科学和人文领域中差异最为明显。这些发现突出了LLM在不同语言品种中如何处理和理由的系统差异，提出了有关这些系统在我们的多语言和多层直肠世界中开发和部署的重要问题。我们的代码存储库可在https://github.com/runtaozhou/dialect_bias_eval上公开获得。]]></description>
      <guid>https://arxiv.org/abs/2503.04099</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM可以通过汇总自己的答复来产生更好的答案</title>
      <link>https://arxiv.org/abs/2503.04104</link>
      <description><![CDATA[ARXIV：2503.04104V1公告类型：新 
摘要：大型语言模型（LLMS）在任务之间显示出了出色的功能，但是在面对复杂问题时，它们通常需要其他提示技术。尽管自我纠正和响应选择之类的方法已成为流行解决方案，但最近的研究表明，在依靠LLM本身提供反馈或选择标准时，这些方法的性能很差。我们认为这一限制源于这样一个事实，即常见的LLM培训后程序缺乏明确的判断性判断任务监督。在本文中，我们提出了生成性自我聚集（GSA），这是一种新颖的提示方法，可提高答案质量，而无需模型的歧视能力。 GSA首先从LLM采样了多种不同的响应，然后将它们汇总以获得改进的解决方案。与以前的方法不同，我们的方法不需要LLM纠正错误或比较响应质量；取而代之的是，它利用模型的生成能力来基于多个样本的上下文综合一个新响应。尽管GSA与自洽（SC）的响应汇总方法有着相似之处，但SC需要特定的可验证令牌才能使多数投票。相比之下，我们的方法更一般，可以应用于开放式任务。经验评估表明，GSA有效地提高了各种任务的响应质量，包括数学推理，基于知识的问题和开放式生成任务，例如代码综合和对话响应。]]></description>
      <guid>https://arxiv.org/abs/2503.04104</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>发现人类和LLM如何解释主观语言的差距</title>
      <link>https://arxiv.org/abs/2503.04113</link>
      <description><![CDATA[ARXIV：2503.04113V1公告类型：新 
摘要：人类通常依靠主观自然语言来指导语言模型（LLMS）；例如，用户可能会指示LLM撰写热情的博客文章，而开发人员可能会使用基于LLM的编辑来培训模型，从而有助于和无害。 LLM对这种主观短语的操作语义 - 当每个短语都包含在提示中时，它如何调整其行为 - 因此决定了它与人类意图的一致性。在这项工作中，我们发现了LLMS的实际操作语义与人类期望之间的未对准实例。我们的方法，TED（词库误差检测器），首先构建了词库，该词库捕获了两个短语是否根据LLM具有相似的操作语义。然后，它通过在该词库和人类建设的参考文献之间发现分歧而引起失败。 TED通常会产生令人惊讶的未对准实例。例如，Mistral 7b指示在编辑文本机智时会产生更多骚扰的输出，而Llama 3 8B指示在指示使这些文章热情的文章时会产生不诚实的文章。我们的结果表明，人类可以通过审查抽象概念之间的关系来揭示意外的LLM行为，而无需直接监督输出。]]></description>
      <guid>https://arxiv.org/abs/2503.04113</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用语言模型提示的生物序列：调查</title>
      <link>https://arxiv.org/abs/2503.04135</link>
      <description><![CDATA[ARXIV：2503.04135V1公告类型：新 
摘要：大型语言模型（LLM）已成为解决各种领域挑战的强大工具。值得注意的是，最近的研究表明，大型语言模型显着提高了生物分子分析和合成的效率，从而引起了学者和医学的广泛关注。在本文中，我们系统地研究了具有LLM的及时方法的应用到生物学序列，包括DNA，RNA，蛋白质和药物发现任务。具体而言，我们专注于迅速工程如何使LLM能够解决域特异性问题，例如启动子序列预测，蛋白质结构建模和药物靶向结合亲和力预测，通常具有有限的标记数据。此外，我们的讨论突出了提示生物信息学的变革潜力，同时解决了诸如数据稀缺，多模式融合和计算资源限制之类的关键挑战。我们的目的是使本文既可以作为新移民的基础入门，又是在这个动态研究领域中继续创新的催化剂。]]></description>
      <guid>https://arxiv.org/abs/2503.04135</guid>
      <pubDate>Fri, 07 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>