<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 27 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>CHARP：基于知识的对话系统的对话历史意识探索</title>
      <link>https://arxiv.org/abs/2405.15110</link>
      <description><![CDATA[arXiv:2405.15110v1 公告类型：新 
摘要：在这项工作中，我们深入研究了一种流行的以知识为基础的对话基准，它专注于忠诚度，FaithDial。我们发现 FaithDial 数据的很大一部分包含注释工件，这可能会使模型偏向于完全忽略对话历史记录。因此，我们引入了 CHARP，一种诊断测试集，旨在改进对话模型中幻觉的评估。 CHARP 不仅测量幻觉，还测量模型对对话任务的符合性。我们的广泛分析表明，模型在 CHARP 上表现不佳主要是因为它们无法有效地关注和推理对话历史记录。此外，FaithDial 的评估方法未能捕捉到这些缺点，忽略了对话历史。我们的研究结果表明，在基于知识的对话的数据集创建和幻觉评估方面都有很大的贡献空间，并且 CHARP 可以作为监测这一特定研究领域进展的工具。 CHARP 已公开发布：https://huggingface.co/datasets/huawei-noah/CHARP]]></description>
      <guid>https://arxiv.org/abs/2405.15110</guid>
      <pubDate>Mon, 27 May 2024 06:19:39 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行信息丰富的文本评估</title>
      <link>https://arxiv.org/abs/2405.15077</link>
      <description><![CDATA[arXiv:2405.15077v1 公告类型：新 
摘要：同行预测机制通过可证明的保证激发高质量的反馈。然而，当前的方法仅适用于相当简单的报告，例如多项选择或标量数字。我们的目标是利用大型语言模型的最新发展，将这些技术扩展到更大的基于文本的报告领域。这极大地增加了同行预测机制的适用性，因为文本反馈是多种反馈渠道的常态：同行评审、电子商务客户评论和社交媒体评论。
  我们引入两种机制，生成同行预测机制（GPPM）和生成概要同行预测机制（GSPPM）。这些机制利用 LLM 作为预测器，将一个代理的报告映射到对其同行报告的预测。从理论上讲，我们表明，当 LLM 预测足够准确时，我们的机制可以作为（近似）贝叶斯纳什均衡来激励高度努力和说真话。根据经验，我们通过在两个真实数据集（Yelp 评论数据集和 ICLR OpenReview 数据集）上进行的实验来确认我们机制的有效性。我们强调在 ICLR 数据集上的结果，我们的机制可以根据预期分数区分三个质量级别——人工撰写的评论、GPT-4 生成的评论和 GPT-3.5 生成的评论。此外，GSPPM 比 GPPM 更有效地惩罚 LLM 生成的评审。]]></description>
      <guid>https://arxiv.org/abs/2405.15077</guid>
      <pubDate>Mon, 27 May 2024 06:19:38 GMT</pubDate>
    </item>
    <item>
      <title>口语理解中神经噪声通道模型的对比和一致性学习</title>
      <link>https://arxiv.org/abs/2405.15097</link>
      <description><![CDATA[arXiv:2405.15097v1 公告类型：新 
摘要：最近，深度端到端学习被研究用于口语理解（SLU）中的意图分类。然而，端到端模型需要大量带有意图标签的语音数据，并且高度优化的模型通常对训练和评估条件之间的不一致敏感。因此，基于自动语音识别（ASR）的自然语言理解方法仍然具有吸引力，因为它可以利用预先训练的通用语言模型并适应语音输入环境的不匹配。使用这种基于模块的方法，我们改进了噪声通道模型，以处理由 ASR 错误引起的转录不一致。我们提出了一种两阶段方法，即对比和一致性学习（CCL），它将干净和嘈杂的 ASR 转录本之间的错误模式关联起来，并强调两个转录本的潜在特征的一致性。在四个基准数据集上的实验表明，CCL 优于现有方法，并提高了 ASR 在各种噪声环境中的鲁棒性。代码可在 https://github.com/syoung7388/CCL 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.15097</guid>
      <pubDate>Mon, 27 May 2024 06:19:38 GMT</pubDate>
    </item>
    <item>
      <title>使用翻译记忆库优化检索增强机器翻译的示例选择</title>
      <link>https://arxiv.org/abs/2405.15070</link>
      <description><![CDATA[arXiv:2405.15070v1 公告类型：新
摘要：检索增强机器翻译通过检索类似实例来利用翻译记忆库中的示例。这些示例用于调节神经解码器的预测。我们的目标是改进上游检索步骤，并考虑一个固定的下游编辑模型：多 Levenshtein Transformer。该任务包括找到一组最大化源句整体覆盖率的示例。为此，我们依靠子模函数理论并探索新算法来优化这种覆盖率。我们评估了机器翻译任务的最终性能提升。]]></description>
      <guid>https://arxiv.org/abs/2405.15070</guid>
      <pubDate>Mon, 27 May 2024 06:19:37 GMT</pubDate>
    </item>
    <item>
      <title>Grokked 变形金刚是隐式推理机：通向泛化边缘的机械之旅</title>
      <link>https://arxiv.org/abs/2405.15071</link>
      <description><![CDATA[arXiv:2405.15071v1 公告类型：新 
摘要：我们研究 Transformer 是否可以学习对参数知识进行隐式推理，即使是最有能力的语言模型也难以掌握这项技能。着眼于两种代表性的推理类型，组合和比较，我们一致发现 Transformer 可以学习隐式推理，但只能通过摸索，即远远超出过度拟合的扩展训练。不同推理类型的泛化水平也有所不同：当面对分布外的例子时，变压器无法系统地泛化组合，但可以成功进行比较。我们在整个训练过程中深入研究模型的内部结构，进行分析实验，揭示：1）摸索背后的机制，例如泛化回路的形成及其与泛化和记忆回路相对效率的关系，2）系统性之间的联系以及泛化电路的配置。我们的研究结果指导数据和训练设置，以更好地诱导隐式推理，并提出对变压器架构的潜在改进，例如鼓励跨层知识共享。此外，我们证明，对于具有大搜索空间的具有挑战性的推理任务，基于非参数记忆的 GPT-4-Turbo 和 Gemini-1.5-Pro 会严重失败，无论提示样式或检索增强如何，而完全 grokked 的变压器可以实现近乎完美的准确性，展示了参数记忆在复杂推理中的强大功能。]]></description>
      <guid>https://arxiv.org/abs/2405.15071</guid>
      <pubDate>Mon, 27 May 2024 06:19:37 GMT</pubDate>
    </item>
    <item>
      <title>重构语言模型中的空间推理评估：定性推理的现实世界模拟基准</title>
      <link>https://arxiv.org/abs/2405.15064</link>
      <description><![CDATA[arXiv:2405.15064v1 公告类型：新 
摘要：空间推理在人类认知和机器智能中都起着至关重要的作用，促进了对语言模型（LM）这方面能力的新研究。然而，现有的基准揭示了评估定性空间推理（QSR）的缺陷。这些基准通常呈现过于简单的场景或不清楚的自然语言描述，阻碍了有效的评估。我们提出了一种评估 LM 中 QSR 的新颖基准，该基准基于真实的 3D 模拟数据，提供了一系列具有各种对象及其空间关系的不同房间布局。这种方法为空间推理评估提供了更详细、上下文更丰富的叙述，与传统的、面向玩具任务的场景不同。我们的基准涵盖广泛的定性空间关系，包括拓扑、方向和距离关系。这些以不同的视角、不同的粒度和关系约束密度来呈现，以模拟现实世界的复杂性。一个关键的贡献是我们基于逻辑的一致性检查工具，它能够评估多个看似合理的解决方案，与空间关系通常可以解释的现实世界场景保持一致。我们对高级语言模型的基准评估揭示了它们在空间推理方面的优势和局限性。他们在多跳空间推理和解释不同视图描述的混合方面面临困难，指出了未来需要改进的领域。]]></description>
      <guid>https://arxiv.org/abs/2405.15064</guid>
      <pubDate>Mon, 27 May 2024 06:19:36 GMT</pubDate>
    </item>
    <item>
      <title>促进建设性审议：重新构建接纳性</title>
      <link>https://arxiv.org/abs/2405.15067</link>
      <description><![CDATA[arXiv:2405.15067v1 公告类型：新
摘要：为了促进网上有争议话题的建设性讨论，我们建议自动重构不同意见的回应，以在保留意义的同时发出接受信号。借鉴心理学、传播学和语言学的研究，我们确定了六种重构策略。我们使用 Reddit 评论和回复数据集，根据每种策略自动重构回复。通过以人为本的实验，我们发现使用我们的框架生成的回复被认为比原始回复更容易接受，并且具有通用的接受基线。我们分析并讨论了我们的结果的含义，并强调了对内容审核的应用。总的来说，我们说明了如何将接受性（一种特定的社会科学构造）转化为计算框架，可以使 LLM 生成更符合人类感知。]]></description>
      <guid>https://arxiv.org/abs/2405.15067</guid>
      <pubDate>Mon, 27 May 2024 06:19:36 GMT</pubDate>
    </item>
    <item>
      <title>AGRaME：具有多向量嵌入的任意粒度排名</title>
      <link>https://arxiv.org/abs/2405.15028</link>
      <description><![CDATA[arXiv:2405.15028v1 公告类型：新 
摘要：排名是搜索中的一个基本且流行的问题。然而，现有的排名算法通常将排名的粒度限制为完整段落，或者需要针对每个所需粒度级别的特定密集索引。这种粒度缺乏灵活性会对许多可以从更细粒度的排名中受益的应用程序产生负面影响，例如开放域问答的句子级排名或归因的命题级排名。在这项工作中，我们引入了任意粒度排序的想法，它利用多向量嵌入在不同的粒度级别上进行排序，同时将编码保持在单个（较粗）粒度级别。我们提出了一种用于训练多向量方法的多粒度对比损失，并以句子和命题作为排名单位验证其实用性。最后，我们演示了命题级排序在检索增强生成中的事后引文添加中的应用，超越了提示驱动引文生成的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.15028</guid>
      <pubDate>Mon, 27 May 2024 06:19:35 GMT</pubDate>
    </item>
    <item>
      <title>Aya 23：开放权重发布以进一步实现多语言进步</title>
      <link>https://arxiv.org/abs/2405.15032</link>
      <description><![CDATA[arXiv:2405.15032v1 公告类型：新 
摘要：本技术报告介绍了 Aya 23，一个多语言语言模型家族。 Aya 23 基于最近发布的 Aya 模型（“Ust”un 等人，2024）构建，专注于将高性能的预训练模型与最近发布的 Aya 集合（Singh 等人，2024）配对。结果是一个强大的多语言大型语言模型，可服务 23 种语言，将最先进的语言建模能力扩展到世界上大约一半的人口。 Aya 模型涵盖 101 种语言，而 Aya 23 是一个深度与广度的实验，探索将更多容量分配给预训练期间包含的更少语言的影响。 Aya 23 在涵盖的语言方面优于 Aya 101 等之前的大规模多语言模型，在广泛的判别和生成任务中也优于 Gemma、Mistral 和 Mixtral 等广泛使用的模型。作为我们不断致力于扩大多语言进步的一部分，我们发布了 8B 和 35B 模型的开放权重。]]></description>
      <guid>https://arxiv.org/abs/2405.15032</guid>
      <pubDate>Mon, 27 May 2024 06:19:35 GMT</pubDate>
    </item>
    <item>
      <title>CEEBERT：早期退出 BERT 中的跨域推理</title>
      <link>https://arxiv.org/abs/2405.15039</link>
      <description><![CDATA[arXiv:2405.15039v1 公告类型：新 
摘要：具有自我监督目标的预训练语言模型（PLM），如 BERT，在各种任务中表现出卓越的性能和泛化能力。然而，由于其尺寸较大，它们会受到推理延迟的影响。为了解决这个问题，在中间层附加了侧分支，从而可以对样本进行早期推理，而无需它们穿过所有层。然而，挑战在于决定在哪一层推断并退出每个样本，以便平衡准确性和延迟。此外，要推断的样本分布可能与用于需要跨域适应的训练的分布不同。我们在早期退出 BERT (CeeBERT) 中提出了一种名为跨域推理的在线学习算法，该算法根据每个退出点的置信水平动态确定样本的早期退出。 CeeBERT 从中间层动态观察到的特定领域置信度中学习最佳阈值，从而无需标记数据。使用 BERT 和 ALBERT 模型在五个不同数据集上进行的实验结果表明，CeeBERT 能够通过减少不必要的计算来改善延迟，同时将性能下降降至最低。通过适应阈值，CeeBERT 可以将 BERT/ALBERT 模型的速度提高 $2\times$ - $3.5\times$，同时精度下降最小。]]></description>
      <guid>https://arxiv.org/abs/2405.15039</guid>
      <pubDate>Mon, 27 May 2024 06:19:35 GMT</pubDate>
    </item>
    <item>
      <title>RE-Adapt：大型语言模型的逆向工程适应</title>
      <link>https://arxiv.org/abs/2405.15007</link>
      <description><![CDATA[arXiv:2405.15007v1 公告类型：新 
摘要：我们引入 RE-Adapt，这是一种在新领域微调大型语言模型而不降低任何预先存在的指令调整的方法。我们对一个适配器进行逆向工程，该适配器将指令调整模型所学到的知识隔离到其相应的预训练基础模型之外。重要的是，这不需要额外的数据或培训。然后，我们可以在新域上微调基本模型，并使用逆向工程适配器将其重新适应指令。 RE-Adapt 和我们的低排名变体 LoRE-Adapt 在多个流行的 LLM 和数据集中都优于其他微调方法，即使模型与检索增强生成结合使用也是如此。]]></description>
      <guid>https://arxiv.org/abs/2405.15007</guid>
      <pubDate>Mon, 27 May 2024 06:19:34 GMT</pubDate>
    </item>
    <item>
      <title>通过反转 LLM 输出来提取提示</title>
      <link>https://arxiv.org/abs/2405.15012</link>
      <description><![CDATA[arXiv:2405.15012v1 公告类型：新 
摘要：我们考虑语言模型反转的问题：给定语言模型的输出，我们寻求提取生成这些输出的提示。我们开发了一种新的黑盒方法，output2prompt，它可以学习提取提示，而无需访问模型的 logits，也无需进行对抗性或越狱查询。与之前的工作相比，output2prompt 只需要普通用户查询的输出。为了提高内存效率，output2prompt 采用了新的稀疏编码技术。我们测量了output2prompt在各种用户和系统提示上的功效，并演示了不同法学硕士之间的零样本可转移性。]]></description>
      <guid>https://arxiv.org/abs/2405.15012</guid>
      <pubDate>Mon, 27 May 2024 06:19:34 GMT</pubDate>
    </item>
    <item>
      <title>利用模板语句进行变量定义提取的数据增强方法</title>
      <link>https://arxiv.org/abs/2405.14962</link>
      <description><![CDATA[arXiv:2405.14962v1 公告类型：新 
摘要：从科学和技术论文中提取变量定义对于理解这些文档至关重要。然而，变量定义的特征，例如长度和构成定义的单词，在不同领域之间存在差异，这导致现有的跨领域提取方法的性能存在差异。尽管准备针对每个领域的训练数据可以提高方法的性能，但创建高质量的训练数据成本高昂。为了应对这一挑战，本研究提出了一种新方法，从训练数据中的模板句子和变量定义对生成新的定义句子。该方法已在有关化学过程的论文上进行了测试，结果表明，使用该方法生成的定义语句训练的模型达到了 89.6% 的较高准确率，超越了现有模型。]]></description>
      <guid>https://arxiv.org/abs/2405.14962</guid>
      <pubDate>Mon, 27 May 2024 06:19:33 GMT</pubDate>
    </item>
    <item>
      <title>将变形金刚中的情境学习与人类情景记忆联系起来</title>
      <link>https://arxiv.org/abs/2405.14992</link>
      <description><![CDATA[arXiv:2405.14992v1 公告类型：新 
摘要：了解人工智能和生物智能系统之间的联系可以揭示通用智能的基本原理。虽然许多人工智能 (AI) 模型都有神经科学对应物，但 Transformer 模型和自注意力机制中很大程度上缺少这种联系。在这里，我们研究了注意力头和人类情景记忆之间的关系。我们重点关注归纳头，它有助于基于 Transformer 的大型语言模型 (LLM) 的上下文学习能力。我们证明感应头在行为、功能和机制上与人类情景记忆的情境维护和检索（CMR）模型相似。我们对基于大量文本数据进行预训练的法学硕士的分析表明，类似 CMR 的头部经常出现在中间模型层中，并且它们的行为定性地反映了人类的记忆偏差。我们的研究结果揭示了法学硕士和人类记忆的计算机制之间的相似之处，为这两个研究领域提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2405.14992</guid>
      <pubDate>Mon, 27 May 2024 06:19:33 GMT</pubDate>
    </item>
    <item>
      <title>细节：可解释的情境学习的任务演示归因</title>
      <link>https://arxiv.org/abs/2405.14899</link>
      <description><![CDATA[arXiv:2405.14899v1 公告类型：新 
摘要：上下文学习（ICL）允许在一般文本上进行预训练的基于 Transformer 的语言模型通过一些“任务演示”快速学习特定任务，而无需更新其参数，从而显着提高了其灵活性和通用性。 ICL 具有许多与传统机器学习不同的特征，因此需要新的方法来解释这种学习范式。最近的研究表明，变压器通过制定内部优化器在上下文中学习，我们提出了一种基于影响函数的归因技术 DETAIL，它解决了 ICL 的具体特征。我们凭经验验证了我们的演示归因方法的有效性，同时具有计算效率。然后，我们利用这些结果展示 DETAIL 如何通过演示重新排序和管理来帮助提高现实场景中的模型性能。最后，我们通过实验证明了 DETAIL 的广泛适用性，表明我们在白盒模型上获得的归因分数可以转移到黑盒模型中以提高模型性能。]]></description>
      <guid>https://arxiv.org/abs/2405.14899</guid>
      <pubDate>Mon, 27 May 2024 06:19:32 GMT</pubDate>
    </item>
    </channel>
</rss>