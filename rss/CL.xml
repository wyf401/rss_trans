<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Tue, 11 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>他们正在过滤什么？对预科数据集中损害减少损害的过滤策略的调查</title>
      <link>https://arxiv.org/abs/2503.05721</link>
      <description><![CDATA[ARXIV：2503.05721V1公告类型：新 
摘要：数据过滤策略是开发安全的大语言模型（LLM）的关键组成部分，因为它们支持从预科数据集中删除有害内容物。但是，缺乏研究这些策略对弱势群体歧视的实际影响的研究，尚未系统地解决它们的有效性。在本文中，我们介绍了针对减少伤害的数据过滤策略的基准研究，旨在为这些方法提供系统的概述。我们调查了55个英语LMS和LLM的技术报告，以确定文献中现有的过滤策略，并实施实验环境以测试其对弱势群体的影响。我们的结果表明，策略在减少文件中的有害内容方面产生的积极影响具有增加弱势群体对数据集中歧视的代表性不足的副作用。]]></description>
      <guid>https://arxiv.org/abs/2503.05721</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CSTRL：上下文驱动的顺序转移学习用于抽象放射学报告摘要</title>
      <link>https://arxiv.org/abs/2503.05750</link>
      <description><![CDATA[ARXIV：2503.05750V1公告类型：新 
摘要：放射学报告包括几个部分，包括诊断的发现和印象。自动从发现中产生印象对于减少放射学家的工作量和提高诊断准确性至关重要。经过预处理的模型在常见的抽象性摘要问题上出色的问题会遇到挑战，这在很大程度上是由于复杂的术语和准确的临床环境的必要性。医疗领域中的此类任务需要提取核心信息，避免上下文转移并保持适当的流动。滥用医学术语会导致严重的临床错误。为了解决这些问题，我们介绍了一项连续转移学习，以确保关键内容提取和连贯的摘要。顺序转移学习通常会面临挑战，例如初始参数衰减和知识损失，我们通过Fisher矩阵正则化解决。使用MIMIC-CXR和OPEN-I数据集，我们的模型CSTRL-context驱动的顺序转移学习量的最先进的表现，显示BLEU-1的56.2％，BLEU-2中的40.5％，BLEU-3中的84.3％在Bleu-3中，Rouge-1，Rouge-1.0.0.0％的28.9％，41.0.0％的rOUGE-2和26.5％。我们还分析了事实一致性得分，同时保留医学环境。我们的代码可在TBA上公开获得。]]></description>
      <guid>https://arxiv.org/abs/2503.05750</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图形蒙版语言模型</title>
      <link>https://arxiv.org/abs/2503.05763</link>
      <description><![CDATA[ARXIV：2503.05763V1公告类型：新 
摘要：语言模型（LMS）是自然语言处理（NLP）不可或缺的，但是它们与结构化知识图（KGS）的互动仍然是一项开放的研究挑战。尽管图形神经网络（GNNS）在捕获图形结构方面表现出色，但与预验证的LMS相比，它们在文本特征表示方面挣扎。为了弥合此差距，我们建议用于节点分类任务的\ textbf {Graph Masked语言模型（GMLM）}。 Our approach introduces two key innovations: a \textit{semantic masking strategy} that selectively masks nodes based on their structural importance, ensuring critical graph components contribute effectively to learning, and a \textit{soft masking mechanism} that generates interpolated node representations, enabling smoother information retention and improved gradient flow.我们的双分支模型体系结构通过多层融合网络将结构图信息与上下文嵌入融合在一起。对六个节点分类基准的广泛实验表明，GMLM不仅可以实现最先进的性能（SOTA）性能，还可以增强整个数据集的鲁棒性和稳定性。]]></description>
      <guid>https://arxiv.org/abs/2503.05763</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基础模型中的医疗幻觉及其对医疗保健的影响</title>
      <link>https://arxiv.org/abs/2503.05777</link>
      <description><![CDATA[ARXIV：2503.05777V1公告类型：新 
摘要：能够处理和生成多模式数据的基础模型改变了AI在医学中的作用。但是，其可靠性的关键局限性是幻觉，其中不准确或捏造的信息可能会影响临床决策和患者安全。我们将医学幻觉定义为模型产生误导性医学内容的任何实例。本文研究了医学幻觉的独特特征，原因和含义，特别关注这些错误如何在现实世界中的临床情况下表现出来。我们的贡献包括（1）用于理解和解决医学幻觉的分类法，（2）使用医学幻觉数据集进行基准测试模型，以及对实际医疗病例的LLM对LLM的响应，直接深入了解幻觉的临床影响，以及（3）对医疗归纳的多核临床调查。我们的结果表明，诸如经过思考链（COT）和搜索增强发电之类的推理技术可以有效降低幻觉速度。但是，尽管有这些改善，但幻觉的非平凡水平仍然存在。这些发现强调了强大的检测和缓解策略的道德和实践命令，为监管政策建立了基础，该政策优先考虑患者的安全性并保持临床完整性，因为AI更加集成到医疗保健中。临床医生的反馈意见不仅需要技术进步，而且还需要更清晰的道德和监管指南以确保患者的安全。一个组织纸质资源，摘要和其他信息的存储库，请访问https://github.com/mitmedialab/medical幻觉。]]></description>
      <guid>https://arxiv.org/abs/2503.05777</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FundmentAlcare：使用联合学习框架进行隐私保护的微调LLMS分析心理健康状况</title>
      <link>https://arxiv.org/abs/2503.05786</link>
      <description><![CDATA[ARXIV：2503.05786V1公告类型：新 
摘要：随着全球心理健康状况的越来越多的患病率，AI驱动的聊天机器人和对话代理已经成为支持心理健康的可访问工具。但是，在心理保健应用中部署大型语言模型（LLM）引起了严重的隐私问题，尤其是关于HIPAA和GDPR等法规。在这项工作中，我们提出了联合alcare，这是一个保存隐私的框架，利用联合学习（FL）与低级适应（LORA）结合使用，以微调LLMS进行心理健康分析。我们研究了FL环境中不同客户数据量和模型架构（例如Moberbert和Minilm）的性能影响。我们的框架展示了一种可扩展的，隐私感知的方法，用于在现实世界中的心理保健方案中部署LLM，从而应对数据安全和计算效率挑战。]]></description>
      <guid>https://arxiv.org/abs/2503.05786</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提取和乳化文化解释以提高LLM的多语言能力</title>
      <link>https://arxiv.org/abs/2503.05846</link>
      <description><![CDATA[ARXIV：2503.05846V1公告类型：新 
摘要：大型语言模型（LLM）取得了杰出的成功，但是他们以英语为中心的培训数据限制了非英语语言的性能，强调了其多语言能力的增强需求。尽管一些关于多语言提示方法的工作通过利用英语翻译或重组将其与LLM推理模式更加紧密地处理非英语查询，但这些作品通常忽略了文化背景的重要性，从而限制了它们的有效性。为了解决这一限制，我们提出了一种简单而有效的方法，可以通过结合文化背景来提高LLMS的多语言能力，从而提高LLMS的多语言能力。具体而言，司令遵循了一个两步的过程，该过程首先通过提示从LLM的参数知识中提取相关的文化背景。然后，Emcei采用LLM-As-Gudge机制来通过平衡文化相关性和推理能力来选择最合适的响应。关于多种语言基准的实验表明，司仪表现优于现有基准，表明其在使用LLMS处理多语言查询方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.05846</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>这是您的总督</title>
      <link>https://arxiv.org/abs/2503.05856</link>
      <description><![CDATA[ARXIV：2503.05856V1公告类型：新 
摘要：大型语言模型（LLMS）代理（MOA）体系结构的混合物通过利用在推理时间上的多个LLMS的协作来实现诸如Alpacaeval 2.0（例如Alpacaeval 2.0）的最先进性能。尽管取得了这些成功，但仍缺少对MOA的安全性和可靠性的评估。我们介绍了对MOA对欺骗性LLM代理商的鲁棒性的首次全面研究，该研究有意提供误导性的反应。我们研究了欺骗性信息，模型规模和信息可用性的传播以及发现关键漏洞等因素。在Alpacaeval 2.0上，流行的Llama 3.1-70B型号与3层MOA（6 LLM代理）相结合时，长度控制的获胜率（LC WR）为49.2％。但是，我们证明，仅引入$ \ textIt {single} $仔细的欺骗剂可以将其降低到37.9％，从而有效地消除了所有MOA增长。在质量上，一项多项选择理解任务，影响也很严重，精度下降了48.5％。我们的一部分是受威尼斯投票过程的历史性启发，旨在最大程度地减少影响力和欺骗，我们提出了一系列无监督的防御机制，以恢复大部分丢失的绩效。]]></description>
      <guid>https://arxiv.org/abs/2503.05856</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>QG-SMS：通过学生建模和模拟增强测试项目分析</title>
      <link>https://arxiv.org/abs/2503.05888</link>
      <description><![CDATA[ARXIV：2503.05888V1公告类型：新 
摘要：虽然问题产生（QG）任务在教育评估中越来越多地通过，但其评估仍受到与测试项目的教育价值没有明确联系的方法的限制。在这项工作中，我们介绍了测试项目分析，这是一种教育工作者经常使用的方法来评估测试质量的方法，并将其纳入QG评估中。具体而言，我们构建了一对候选问题，这些问题在跨维度，例如主题覆盖，项目难度，项目歧视和干扰效率等质量上有所不同。然后，我们检查现有的QG评估方法是否可以有效区分这些差异。我们的发现揭示了这些方法在与学生绩效相关的准确评估测试项目质量方面存在重大缺点。为了解决这一差距，我们提出了一个新颖的QG评估框架QG-SMS，该框架利用大型语言模型进行学生建模和模拟来执行测试项目分析。正如我们在广泛的实验和人类评估研究中所证明的那样，模拟学生概况引入的其他观点会导致对测试项目的更有效，更强大的评估。]]></description>
      <guid>https://arxiv.org/abs/2503.05888</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>策划者：一个简单但可扩展的推理基准</title>
      <link>https://arxiv.org/abs/2503.05891</link>
      <description><![CDATA[ARXIV：2503.05891V1公告类型：新 
摘要：大语言模型（LLM）的最新进展导致了各种语言理解和数学任务的出色表现。结果，越来越关注的关注是评估LLM的真正推理能力，推动对常识，数字，逻辑和定性推理的研究。但是，随着以推理为重点的模型（例如OpenAI的O1和DeepSeek的R1）的快速发展，人们对推理基准的需求越来越不断增长，这些基准可以跟上持续的模型发展。在本文中，我们介绍了一个由棋盘游戏策划者启发的简单，可扩展和可解释的演绎推理基准。我们的基准测试支持两个评估范例：（1）代理评估，模型自动地玩游戏，以及（2）扣除推理评估，其中为模型提供了预先游戏的游戏状态，只有一个可能有效的代码来推断。在我们的实验结果中，我们（1）发现当前模型的策划实例甚至很容易，（2）证明基准可以扩展到将来可能更先进的模型，我们调查了可能的原因，可能的原因是导致最终模型不推论当前模型的限制，以将隐藏的代码限制为与信息的数量相结合，从而增加了信息的数量。]]></description>
      <guid>https://arxiv.org/abs/2503.05891</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从样式到事实：绘制知识注入的边界，并通过填充</title>
      <link>https://arxiv.org/abs/2503.05919</link>
      <description><![CDATA[ARXIV：2503.05919V1公告类型：新 
摘要：Finetuning为特定任务或响应样式定制语言模型提供了可扩展且具有成本效益的方法，其可靠性比提示或文化学习更大。相比之下，传统的观点是，通过固定进行注入知识会导致脆弱的性能和不良的概括。我们认为，“任务定制”（例如，教学调整）和“知识注入”（例如，教授新事实）的二分法是一个区别，没有差异。相反，我们确定了解释通过鉴定观察到的异质有效性的具体因素。为此，我们在一系列数据集上对鉴定边界的双子座V1.5模型家族进行了大规模实验研究，这些数据集经过人工设计，可以在较强的燃烧模式之间进行插值。我们的发现表明，提问的培训数据格式比文档/文档/文档风格的培训数据提供了更强的知识概括，数值信息可能比保留更难保留，而与分类信息更难保留，并且模型难以应用多步骤推理期间的填充知识，即使在类似的示例上培训了类似的示例 - 尤其是在类似的“知识注射”中，即使在范围内也要对其进行控制，以便对数据进行了范围，并且要对数据进行控制。另一方面，我们的发现还表明，关于现实世界事件的芬特季度信息在根本上比有关模型写作方式的信息要难。]]></description>
      <guid>https://arxiv.org/abs/2503.05919</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Idea Prune：预处理生成语言模型中的综合扩大管道</title>
      <link>https://arxiv.org/abs/2503.05920</link>
      <description><![CDATA[ARXIV：2503.05920V1公告类型：新 
摘要：大语言模型中的最新进步加剧了在有限的推理预算中对有效和可部署模型的需求。与从头开始的训练目标大小模型相比，结构化的修剪管道在令牌效率方面已显示出希望。在本文中，我们主张将放大的模型预处理（通常在以前的作品中被忽略）纳入修剪中。我们将扩大和促进管道作为一个集成系统，以解决两个关键问题：即使模型从未部署，是否值得预处理模型，以及如何优化整个管道以获得更好的修剪模型。我们提出了一条集成的扩大和促进管道，该管道结合了单个余弦退火率计划的放大模型培训，修剪和恢复。这种方法通过一种新型的迭代结构化修剪方法进一步补充，以逐步去除参数。所提出的方法有助于减轻因幼稚扩大和促进管道中的学习率上升而导致的知识损失，并有效地重新分布幸存的神经元之间的模型容量，从而促进平滑压缩和增强的性能。我们对将2.8B模型压缩为1.3B进行全面实验，并在预训练中具有多达2T令牌。它展示了综合方法不仅可以洞悉扩大模型预处理的令牌效率，而且还可以实现修剪模型的卓越性能。]]></description>
      <guid>https://arxiv.org/abs/2503.05920</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>编码器语音模型的培训和推理效率</title>
      <link>https://arxiv.org/abs/2503.05931</link>
      <description><![CDATA[ARXIV：2503.05931V1公告类型：新 
摘要：注意编码器模型体系结构是最近表现最佳基础语音模型的骨干：耳语，无缝，OWSM和Canary-1b。但是，对研究界的许多人来说，报告的数据和计算要求对许多人的培训需求都非常有用。在这项工作中，我们专注于效率角度，并询问我们是否正在有效培训这些语音模型的问题，以及我们该如何改进？我们认为，训练效率的主要（即使不是最严重的有害因素）与顺序数据的采样策略有关。我们表明，微型批次采样的疏忽导致在填充上花费了超过50％的计算。为此，我们研究，概况并优化了金丝雀1B培训，以显示GPU利用率的逐渐改善，导致平均批量尺寸增加5倍，而其原始训练设置则可以提高5倍。反过来，这使我们能够在同一壁时间中使用4倍的GPU训练同等模型，或者利用原始资源并在较短的壁时间中训练它。最后，我们观察到主要的推理瓶颈在于自回归解码器步骤。我们发现，将模型体系结构调整为将模型参数从解码器传输到编码器会导致3倍推理速度，这是通过反实时因子（RTFX）测量的，同时保留收敛的准确性和计算要求。培训代码和型号将作为开源。]]></description>
      <guid>https://arxiv.org/abs/2503.05931</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DETQUS：以查询为重点的摘要的分解增强变压器</title>
      <link>https://arxiv.org/abs/2503.05935</link>
      <description><![CDATA[ARXIV：2503.05935V1公告类型：新 
摘要：以查询为中心的表格摘要是表与文本生成中的一项新任务，它根据用户查询从表格数据中综合了摘要响应。由于令牌的限制和大表格上的推理的复杂性，基于变压器的传统方法面临挑战。为了应对这些挑战，我们介绍了DETQU（以查询为中心的摘要的分解增强的变压器），该系统旨在通过将表格分解与微调编码器模型一起利用表格分解来提高摘要精度。 Detqus采用大型语言模型来选择性地减小表尺寸，仅保留与查询相关的列，同时保留基本信息。该策略可以更有效地处理大型桌子并提高总结质量。我们的方法配备了基于表的QA模型Omnitab，可实现0.4437的Rouge-L得分，表现优于先前的最新重构模型（Rouge-L：0.422）。这些结果将Detqus作为一种可扩展有效的解决方案，用于以查询为重点的表格摘要，为更复杂的体系结构提供了结构化的替代方案。]]></description>
      <guid>https://arxiv.org/abs/2503.05935</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>三明治：邻居的语义分析在上下文中歧义单词</title>
      <link>https://arxiv.org/abs/2503.05958</link>
      <description><![CDATA[ARXIV：2503.05958V1公告类型：新 
摘要：在过去的两年中，基于生成聊天的大语言模型（LLM）的兴起促使一场竞赛开发了有望近乎人类的对话和推理经验的系统。但是，最近的研究表明，这些模型提供的语言理解仍然有限，并且远非像人类的表现，尤其是在掌握单词的上下文含义时，这是推理的基本方面。在本文中，我们提出了一个简单但在计算上有效的框架，用于多语言单词sense disamigation（WSD）。我们的方法将WSD任务重新编写为使用组代数从babelnet改进的语义网络的聚类歧视分析。我们在多个WSD基准中验证了我们的方法论，从而实现了所有语言和任务的新技术，以及通过语音的部分评估。值得注意的是，即使在低资源语言中，我们的模型也大大超过了当前替代方案的性能，同时将参数计数降低了72％。]]></description>
      <guid>https://arxiv.org/abs/2503.05958</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Sindex：LLMS中幻觉检测的语义不一致指数</title>
      <link>https://arxiv.org/abs/2503.05980</link>
      <description><![CDATA[ARXIV：2503.05980V1公告类型：新 
摘要：大型语言模型（LLMS）越来越多地部署在不同的领域中，但它们很容易产生事实不正确的产出 - 通常称为“幻觉”。在现有的缓解策略中，基于不确定性的方法易于实施，独立于外部数据以及与标准LLM的兼容性特别有吸引力。在这项工作中，我们介绍了一个新颖且可扩展的基于不确定性的语义聚类框架，用于自动化幻觉检测。我们的方法利用句子嵌入和分层聚类以及新提出的不一致度量sindex并产生更多同质簇，并更准确地检测到各种LLM的幻觉现象。对突出的开放式QA数据集的评估表明，我们的方法比最先进的技术实现了高达9.3％的AUROC。广泛的消融研究进一步验证了每个组件在我们的框架中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2503.05980</guid>
      <pubDate>Tue, 11 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>