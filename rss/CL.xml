<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Mon, 13 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>统计流形中自然语言的相关维数</title>
      <link>https://arxiv.org/abs/2405.06321</link>
      <description><![CDATA[arXiv:2405.06321v1 公告类型：新
摘要：自然语言的相关维数是通过将 Grassberger-Procaccia 算法应用于大规模语言模型产生的高维序列来测量的。该方法以前仅在欧几里得空间中研究，现在通过 Fisher-Rao 距离在统计流形中重新表述。语言表现出多重分形，具有全局自相似性，通用维数约为 6.5，小于简单离散随机序列的维数，大于 Barab&#39;asi-Albert 过程的维数。长记忆是产生自相似性的关键。我们的方法适用于现实世界离散序列的任何概率模型，并且我们展示了在音乐数据中的应用。]]></description>
      <guid>https://arxiv.org/abs/2405.06321</guid>
      <pubDate>Mon, 13 May 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>面向消费者健康方面的答案总结</title>
      <link>https://arxiv.org/abs/2405.06295</link>
      <description><![CDATA[arXiv:2405.06295v1 公告类型：新
摘要：社区问答（CQA）论坛彻底改变了人们寻求信息的方式，特别是那些与他们的医疗保健需求相关的信息，让他们相信公众的集体智慧。然而，单个查询可能有多个答案，这使得很难掌握与特定健康问题相关的关键信息。通常，CQA 论坛会提供一个投票最高的答案作为每个查询的代表性摘要。然而，单一答案忽略了其他答案中经常提供的替代解决方案和其他信息。我们的研究重点是基于方面的健康答案总结，以解决这一局限性。对建议、信息、个人经历、问题等不同方面的回复进行总结可以增强平台的可用性。我们正式制定了多阶段注释指南，并提供了一个独特的数据集，其中包含基于方面的人类编写的健康答案摘要。我们基于对几个最先进模型的特定于任务的微调，使用该数据集构建了一个自动化的多方面答案总结管道。该管道利用问题相似性来检索相关答案句子，随后将它们分类为适当的方面类型。接下来，我们采用几个最近的抽象摘要模型来生成基于方面的摘要。最后，我们进行了全面的人工分析，发现我们的摘要在捕获相关内容和广泛的解决方案方面排名靠前。]]></description>
      <guid>https://arxiv.org/abs/2405.06295</guid>
      <pubDate>Mon, 13 May 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>Metacritic PC 视频游戏用户评级中“评论轰炸”的 NLP 方法</title>
      <link>https://arxiv.org/abs/2405.06306</link>
      <description><![CDATA[arXiv:2405.06306v1 公告类型：新
摘要：许多电子游戏在用户评分时遭受“评论轰炸”，即大量异常低的分数，在许多情况下并不能反映产品的真实质量。通过采用 Metacritic 的 50,000 多个英语 PC 游戏用户评分聚合，我们使用自然语言处理 (NLP) 方法来尝试理解此类情况中出现的主要单词和概念，在区分以下内容时在验证集上达到 0.88 的准确率只是糟糕的收视率和评论爆炸。通过发现和分析驱动这一现象的模式，这些结果可用于进一步缓解这些情况。]]></description>
      <guid>https://arxiv.org/abs/2405.06306</guid>
      <pubDate>Mon, 13 May 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>自动生成模型和数据卡：迈向负责任的人工智能的一步</title>
      <link>https://arxiv.org/abs/2405.06258</link>
      <description><![CDATA[arXiv:2405.06258v1 公告类型：新
摘要：在机器学习/人工智能领域模型和数据激增的时代，尤其是开源技术快速发展的时代，迫切需要标准化一致的文档。我们的工作解决了当前人类生成的模型和数据卡中信息不完整的问题。我们提出了一种使用大型语言模型（LLM）的自动生成方法。我们的主要贡献包括建立 CardBench（一个由超过 4800 个模型卡和 14000 个数据卡聚合而成的综合数据集），以及包含两步检索过程的 CardGen 管道的开发。我们的方法在生成的模型和数据卡中表现出增强的完整性、客观性和忠实性，这是负责任的人工智能文档实践的重要一步，确保更好的问责性和可追溯性。]]></description>
      <guid>https://arxiv.org/abs/2405.06258</guid>
      <pubDate>Mon, 13 May 2024 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>作为特定领域的 LLM 提取器进行修剪</title>
      <link>https://arxiv.org/abs/2405.06275</link>
      <description><![CDATA[arXiv:2405.06275v1 公告类型：新
摘要：大型语言模型（LLM）在广泛的 NLP 任务中表现出了卓越的熟练程度。然而，模型大小的增加也会产生大量的部署成本。虽然很少有人探索模型修剪技术来减少法学硕士的规模，但它们主要集中在一般或特定任务的权重上。当应用于特定领域的挑战时，由于目标领域缺乏特异性或不同任务的通用性，这会导致性能不佳。这项工作引入了一种创新的非结构化双剪枝方法 D-Pruner，用于 LLM 的特定领域压缩。它通过识别对于一般能力（如语言能力和多任务解决以及特定领域知识）至关重要的法学硕士权重，提取压缩的、特定领域和与任务无关的法学硕士。更具体地说，我们首先通过在开放域校准数据集的帮助下量化去除权重时产生的误差来评估一般权重的重要性。然后，我们利用这个一般权重重要性来细化训练损失，以便它在拟合特定领域时保留通用性。此外，通过在特定领域的校准数据集上使用精细的训练损失来有效地近似权重重要性，我们获得了强调通用性和特异性的修剪模型。我们在医疗保健和法律领域的各种任务中进行的综合实验表明了 D-Pruner 在特定领域压缩中的有效性。我们的代码可在 https://github.com/psunlpgroup/D-Pruner 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.06275</guid>
      <pubDate>Mon, 13 May 2024 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>针对性别偏见研究中的错误中国人：拼音姓名性别预测的多任务学习与知识蒸馏</title>
      <link>https://arxiv.org/abs/2405.06221</link>
      <description><![CDATA[arXiv:2405.06221v1 公告类型：新
摘要：实现性别平等是实现联合国全球可持续发展目标的关键因素。性别偏见研究致力于实现这一目标，并在性别信息不可用时依靠基于姓名的性别推断工具来分配个人性别标签。然而，这些工具常常不能准确地预测中文拼音名字的性别，导致此类研究存在潜在偏差。随着中国人越来越多地参与国际活动，这种情况变得更加严峻。具体来说，当前的工具专注于发音（拼音）信息，忽略了拼音和汉字（汉字）之间的潜在联系传达了关键信息。作为第一步，我们提出了拼音姓名性别猜测问题，并设计了一个知识蒸馏辅助的多任务学习网络，使模型中的拼音嵌入能够拥有汉字的语义特征，并从汉字名称中学习性别信息。我们的开源方法相对于商业姓名性别猜测工具超过了 9.70% 到 20.08%，并且也优于最先进的算法。]]></description>
      <guid>https://arxiv.org/abs/2405.06221</guid>
      <pubDate>Mon, 13 May 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>沙特伯特：在沙特方言语料库上预训练的大型语言模型</title>
      <link>https://arxiv.org/abs/2405.06239</link>
      <description><![CDATA[arXiv:2405.06239v1 公告类型：新
摘要：在本文中，我们介绍了SaudiBERT，这是一种专门针对沙特方言文本进行预训练的单方言阿拉伯语言模型。为了证明该模型的有效性，我们在 11 个评估数据集中将沙特伯特与 6 种不同的多方言阿拉伯语言模型进行了比较，这些数据集分为两组：情感分析和文本分类。在这些组中，SaudiBERT 的平均 F1 分数分别为 86.15% 和 87.86%，显着优于所有其他比较模型。此外，我们还提供了两个新颖的沙特方言语料库：沙特推文巨型语料库 (STMC)，其中包含超过 1.41 亿条沙特方言推文，以及沙特论坛语料库 (SFC)，其中包含从五个沙特在线论坛收集的 15.2 GB 文本。这两个语料库都用于预训练所提出的模型，它们是文献中报道的最大的沙特方言语料库。结果证实了SaudiBERT在理解和分析用沙特方言表达的阿拉伯文本方面的有效性，在大多数任务中取得了最先进的结果，并超越了研究中包含的其他语言模型。 SaudiBERT 模型可在 \url{https://huggingface.co/faisalq/SaudiBERT} 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2405.06239</guid>
      <pubDate>Mon, 13 May 2024 06:18:21 GMT</pubDate>
    </item>
    <item>
      <title>HC$^2$L：跨语言口语理解的混合和合作对比学习</title>
      <link>https://arxiv.org/abs/2405.06204</link>
      <description><![CDATA[arXiv:2405.06204v1 公告类型：新
摘要：最先进的零样本跨语言口语理解模型执行跨语言无监督对比学习，以实现每个话语与其代码转换数据之间的标签不可知的语义对齐。然而，它忽略了宝贵的意图/槽标签，其标签信息有望帮助捕获标签感知语义结构，然后利用监督对比学习来改善源语言和目标语言的语义。在本文中，我们提出混合和合作对比学习来解决这个问题。除了跨语言无监督对比学习之外，我们还设计了一种整体方法，利用源语言监督对比学习、跨语言监督对比学习和多语言监督对比学习来全面执行标签感知语义对齐。每种监督对比学习机制都包括单任务和联合任务场景。在我们的模型中，一种对比学习机制的输入会受到其他机制的增强。因此，总共四种对比学习机制相互协作，在训练过程中的良性循环中学习更加一致和有区别的表示。实验表明，我们的模型在 9 种语言上获得了一致的改进，实现了新的最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.06204</guid>
      <pubDate>Mon, 13 May 2024 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>关于 RAG 与法学硕士的调查：迈向检索增强型大型语言模型</title>
      <link>https://arxiv.org/abs/2405.06211</link>
      <description><![CDATA[arXiv:2405.06211v1 公告类型：新
摘要：作为人工智能中最先进的技术之一，检索增强生成（RAG）技术可以提供可靠且最新的外部知识，为众多任务提供巨大的便利。特别是在人工智能生成内容（AIGC）时代，RAG 强大的检索能力可以提供额外的知识，使得检索增强生成能够协助现有的生成式人工智能产生高质量的输出。最近，大型语言模型（LLM）在语言理解和生成方面表现出了革命性的能力，但仍然面临着固有的局限性，例如幻觉和过时的内部知识。鉴于RAG在提供最新且有用的辅助信息方面的强大能力，检索增强的大型语言模型已经出现，以利用外部和权威的知识库，而不是仅仅依靠模型的内部知识来提高LLM的生成质量。在本次调查中，我们全面回顾了检索增强大语言模型（RA-LLM）的现有研究，涵盖三个主要技术视角：架构、训练策略和应用。作为预备知识，我们简要介绍了LLM的基础和最新进展。然后，为了说明RAG对LLM的实际意义，我们按应用领域对主流相关工作进行了分类，具体详细说明了每个领域的挑战以及RA-LLM的相应能力。最后，为了提供更深入的见解，我们讨论了当前的局限性和未来研究的几个有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2405.06211</guid>
      <pubDate>Mon, 13 May 2024 06:18:20 GMT</pubDate>
    </item>
    <item>
      <title>Reddit-Impacts：用于分析源自社交媒体的药物使用的临床和社会影响的命名实体识别数据集</title>
      <link>https://arxiv.org/abs/2405.06145</link>
      <description><![CDATA[arXiv:2405.06145v1 公告类型：新
摘要：药物使用障碍（SUD）在全球范围内日益受到关注，需要通过数据驱动的研究来加深对这一问题及其趋势的理解。社交媒体是有关 SUD 的独特而重要的信息来源，特别是因为此类来源中的数据通常是由有生活经验的人生成的。在本文中，我们介绍了 Reddit-Impacts，这是一个具有挑战性的命名实体识别 (NER) 数据集，由 Reddit 子版块精心策划，专门用于讨论处方和非法阿片类药物以及阿片类药物使用障碍的药物。该数据集特别关注物质使用的研究较少但至关重要的方面——其临床和社会影响。我们使用公开的 Reddit 应用程序编程接口从选定的 Reddit 子版块收集数据。我们手动注释了代表临床和社会影响的文本范围，这些影响由那些还报告个人非医疗使用物质（包括但不限于阿片类药物、兴奋剂和苯二氮卓类药物）的人报告。我们的目标是创建一种资源，支持开发能够从基于文本的社交媒体数据自动检测药物使用的临床和社会影响的系统。此类系统的成功开发可以使我们更好地了解物质的非医疗使用如何影响个人健康和社会动态，从而有助于制定有效的公共卫生战略。除了创建带注释的数据集之外，我们还应用了多种机器学习模型来建立基准性能。具体来说，我们试验了 BERT 和 RoBERTa 等 Transformer 模型，通过利用完整的训练数据集进行了几次学习模型 DANN，并通过使用一次性学习进行了 GPT-3.5，以实现临床和社会影响的自动 NER。该数据集已通过 2024 SMM4H 共享任务提供。]]></description>
      <guid>https://arxiv.org/abs/2405.06145</guid>
      <pubDate>Mon, 13 May 2024 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>转录中的迷失：识别和量化自动语音识别系统针对不流利语音的准确性偏差</title>
      <link>https://arxiv.org/abs/2405.06150</link>
      <description><![CDATA[arXiv:2405.06150v1 公告类型：新
摘要：自动语音识别 (ASR) 系统在教育、医疗保健、就业和移动技术领域日益普及，但在包容性方面面临着重大挑战，特别是对于全球 8000 万口吃人群而言。这些系统通常无法准确地解释偏离典型流畅性的语音模式，从而导致严重的可用性问题和误解。这项研究评估了六种领先的 ASR，分析了它们在来自口吃者的真实语音样本数据集和源自广泛使用的 LibriSpeech 基准的合成数据集上的性能。该合成数据集经过专门设计，可包含各种口吃事件，可以深入分析每个 ASR 对不流利语音的处理。我们的综合评估包括单词错误率 (WER)、字符错误率 (CER) 和文字记录的语义准确性等指标。结果显示，所有 ASR 都对不流利的语音存在一致且具有统计显着性的准确性偏差，表现为转录中存在显着的句法和语义不准确。这些发现凸显了当前 ASR 技术的关键差距，强调了有效缓解偏差策略的必要性。解决这种偏见势在必行，不仅可以提高技术对口吃者的可用性，还可以确保他们公平、包容地参与快速发展的数字环境。]]></description>
      <guid>https://arxiv.org/abs/2405.06150</guid>
      <pubDate>Mon, 13 May 2024 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>静音耳语：对语音基础模型的通用声学对抗性攻击</title>
      <link>https://arxiv.org/abs/2405.06134</link>
      <description><![CDATA[arXiv:2405.06134v1 公告类型：新
摘要：像 Whisper 这样的大型语音基础模型的最新发展使其在许多自动语音识别（ASR）应用中得到广泛使用。这些系统将“特殊标记”纳入其词汇表中，例如 $\texttt{}$，以指导其语言生成过程。然而，我们证明这些令牌可以被对抗性攻击利用来操纵模型的行为。我们提出了一种简单而有效的方法来学习 Whisper 的 $\texttt{}$ 令牌的通用声学实现，当将其添加到任何语音信号之前时，会鼓励模型忽略语音并仅转录特殊令牌，从而有效地“静音”该模型。我们的实验表明，相同的通用 0.64 秒对抗性音频片段可以成功地将超过 97% 的语音样本的目标 Whisper ASR 模型静音。此外，我们发现这种通用的对抗性音频片段经常转移到新的数据集和任务。总的来说，这项工作证明了 Whisper 模型对“静音”对抗性攻击的脆弱性，这种攻击在现实世界中既可能带来风险，也可能带来潜在好处：例如，该攻击可用于绕过语音审核系统，或者相反，该攻击可以也可用于保护私人语音数据。]]></description>
      <guid>https://arxiv.org/abs/2405.06134</guid>
      <pubDate>Mon, 13 May 2024 06:18:18 GMT</pubDate>
    </item>
    <item>
      <title>HMT：用于长上下文语言处理的分层内存转换器</title>
      <link>https://arxiv.org/abs/2405.06067</link>
      <description><![CDATA[arXiv:2405.06067v1 公告类型：新
摘要：基于 Transformer 的大语言模型（LLM）已广泛应用于语言处理应用中。然而，它们中的大多数限制了允许模型处理输入中的每个标记的上下文窗口。以前的循环模型工作可以记住过去的标记，以实现无限的上下文并保持有效性。然而，它们具有“扁平”内存架构，在选择和过滤信息方面存在局限性。由于人类善于学习和自我调整，我们推测模仿大脑记忆层次结构有利于模型记忆。我们提出了分层记忆变换器（HMT），这是一种新颖的框架，可以通过模仿人类记忆行为来启用和提高模型的长上下文处理能力。利用记忆增强的段级递归，我们通过保留早期输入标记段中的标记、沿序列传递记忆嵌入以及从历史记录中调用相关信息来组织记忆层次结构。通过评估通用语言模型（Wikitext-103、PG-19）和问答任务（PubMedQA），我们表明 HMT 稳步提高了上下文约束和长上下文模型的长上下文处理能力。通过额外的 0.5% - 2% 参数，HMT 可以轻松插入和增强未来的 LLM，以有效处理长上下文。我们的代码在 Github 上开源：https://github.com/OswaldHe/HMT-pytorch。]]></description>
      <guid>https://arxiv.org/abs/2405.06067</guid>
      <pubDate>Mon, 13 May 2024 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>困惑度能否体现大语言模型对长文本的理解能力？</title>
      <link>https://arxiv.org/abs/2405.06105</link>
      <description><![CDATA[arXiv:2405.06105v1 公告类型：新
摘要：最近的研究表明，大型语言模型（LLM）具有处理极长文本的潜力。许多作品仅评估LLM在语言建模任务上的长文本处理能力，以困惑度（PPL）作为评估指标。然而，在我们的研究中，我们发现PPL和LLM的长文本理解能力之间没有相关性。此外，PPL可能只反映模型对本地信息进行建模的能力，而不是捕捉远程依赖关系。因此，仅仅用PPL来证明模型可以处理长文本是不合适的。 PPL的局部焦点特征也可以解释一些现有现象，例如位置方法ALiBi强大的外推能力。在评估模型在长文本中的能力时，我们可能会更多地关注 PPL 的局限性，并避免过度依赖它。]]></description>
      <guid>https://arxiv.org/abs/2405.06105</guid>
      <pubDate>Mon, 13 May 2024 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>开放式文本世界中少镜头任务转移的专家混合方法</title>
      <link>https://arxiv.org/abs/2405.06059</link>
      <description><![CDATA[arXiv:2405.06059v1 公告类型：新
摘要：开放式世界是指没有预先指定的目标或环境奖励信号的世界。因此，代理必须知道如何执行多项任务。然而，当向智能体呈现新任务时，我们希望它能够重用从以前的任务中学到的一些知识来快速学习新任务。我们引入了一种新技术，将不同先验已知任务的策略组合成专家混合模型，该模型具有跨冻结和未冻结专家混合的注意力机制。该模型学习何时在适当的时候关注冻结的特定任务专家，并学习新的专家来处理新情况。我们在基于文本的开放式环境中工作，其中代理的任务是表现得像不同类型的角色角色，并且必须快速学习与新角色角色类型相关的行为。我们表明，我们的代理既在零样本设置中获得了更多奖励，又在少样本学习设置中以更高的样本效率发现了这些奖励。]]></description>
      <guid>https://arxiv.org/abs/2405.06059</guid>
      <pubDate>Mon, 13 May 2024 06:18:16 GMT</pubDate>
    </item>
    </channel>
</rss>