<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 31 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 BiLSTM-Attention 方法实现高效机器翻译</title>
      <link>https://arxiv.org/abs/2410.22335</link>
      <description><![CDATA[arXiv:2410.22335v1 Announce Type: new 
摘要：随着自然语言处理（NLP）技术的快速发展，机器翻译的准确性和效率成为研究的热点。本文提出了一种新颖的Seq2Seq模型，旨在提高翻译质量的同时减少模型所需的存储空间。该模型采用双向长短期记忆网络（Bi-LSTM）作为编码器，捕捉输入序列的上下文信息；解码器加入注意力机制，增强模型在翻译过程中聚焦关键信息的能力。与目前主流的Transformer模型相比，我们的模型在WMT14机器翻译数据集上取得了优异的性能，同时保持了较小的规模。
本研究首先介绍了模型架构的设计原理和创新点，随后通过一系列实验来验证模型的有效性。实验包括对模型在不同语言对上的性能评估，以及与传统Seq2Seq模型的比较分析。结果表明，在保持翻译准确率的同时，我们的模型显著降低了存储要求，这对于资源受限场景下的翻译应用具有重要意义。我们的代码可以在https://github.com/mindspore-lab/models/tree/master/research/arxiv_papers/miniformer上找到。感谢MindSpore社区提供的支持。]]></description>
      <guid>https://arxiv.org/abs/2410.22335</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ArxivDIGESTables：使用语言模型将科学文献综合成表格</title>
      <link>https://arxiv.org/abs/2410.22360</link>
      <description><![CDATA[arXiv:2410.22360v1 公告类型：新
摘要：在进行文献综述时，科学家经常创建文献综述表 - 行是出版物，列构成模式的表格，模式是一组用于比较和对比论文的方面。我们可以使用语言模型 (LM) 自动生成这些表格吗？在这项工作中，我们引入了一个框架，该框架利用 LM 来执行此任务，将其分解为单独的模式和值生成步骤。为了进行实验，我们解决了两个主要挑战：首先，我们通过策划和发布 arxivDIGESTables 来克服缺乏高质量数据集来对表格生成进行基准测试的问题，arxivDIGESTables 是从 ArXiv 论文中提取的 2,228 个文献综述表的新数据集，这些论文总共综合了 7,542 篇研究论文。其次，为了支持对人工编写的参考表进行可扩展的模型生成评估，我们开发了 DecontextEval，这是一种自动评估方法，尽管表面形式不同，但它可以将具有相同底层方面的表格元素对齐。有了这些工具，我们评估了 LM 重建参考表的能力，发现这项任务受益于为生成打下基础的额外背景信息（例如表格标题、文内引用）。最后，通过一项人工评估研究，我们发现即使 LM 无法完全重建参考表，它们生成的新颖方面仍然很有用。]]></description>
      <guid>https://arxiv.org/abs/2410.22360</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AAAR-1.0：评估人工智能辅助研究的潜力</title>
      <link>https://arxiv.org/abs/2410.22394</link>
      <description><![CDATA[arXiv:2410.22394v1 公告类型：新
摘要：许多研究已经评估了人工智能系统，特别是大型语言模型 (LLM) 在促进日常任务（例如电子邮件撰写、问答和创意内容生成）方面的能力。然而，研究人员在利用 LLM 进行自己的工作时面临着独特的挑战和机遇，例如集思广益研究想法、设计实验以及撰写或审阅论文。在本研究中，我们引入了 AAAR-1.0，这是一个基准数据集，旨在评估 LLM 在三个基本的、专业知识密集型研究任务中的表现：(i) EquationInference，根据论文提交中的上下文信息评估方程的正确性；(ii) ExperimentDesign，设计实验来验证研究想法和解决方案；(iii) PaperWeakness，识别论文提交中的弱点；(iv) REVIEWCRITIQUE，识别人工评论中的每个部分是否有缺陷。 AAAR-1.0 与之前的基准有两个主要区别：首先，它明确以研究为导向，其任务需要深厚的领域专业知识；其次，它以研究人员为导向，反映了研究人员日常从事的主要活动。对开源和专有 LLM 的评估揭示了它们在执行复杂研究任务方面的潜力和局限性。我们将继续将 AAAR-1.0 迭代到新版本。]]></description>
      <guid>https://arxiv.org/abs/2410.22394</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是否与核心心理健康咨询能力相符？</title>
      <link>https://arxiv.org/abs/2410.22446</link>
      <description><![CDATA[arXiv:2410.22446v1 公告类型：新
摘要：大型语言模型 (LLM) 的快速发展为缓解全球心理健康专业人员短缺提供了巨大的潜力。然而，LLM 与基本心理健康咨询能力的一致性仍未得到充分研究。我们引入了 CounselingBench，这是一种基于 NCMHCE 的新型基准，用于评估五项关键心理健康咨询能力的 LLM。通过测试 22 个通用和医学微调的 LLM，我们发现前沿模型超过了最低阈值，但未达到专家级性能，并且存在显着差异：它们在摄入、评估和诊断方面表现出色，但在核心咨询属性和专业实践与道德方面却举步维艰。医学 LLM 在准确性方面的表现令人惊讶地不如通用模型，同时产生了略高质量的论证，但犯了更多与上下文相关的错误。我们的研究结果强调了开发用于心理健康咨询的 AI 系统的复杂性，特别是对于需要同理心和情境理解的能力。我们发现，前沿法学硕士的表现超过了所有关键心理健康咨询能力的最低要求水平，但未达到专家级的表现，而且目前的医学法学硕士并没有显著提高心理健康咨询能力的通才模型。这强调了在考虑任何负责任的实际部署之前，迫切需要专门的、针对心理健康咨询的微调法学硕士，这些法学硕士必须与核心能力严格一致，并结合适当的人工监督。]]></description>
      <guid>https://arxiv.org/abs/2410.22446</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于指针网络的多标签多类意图联合提取与检测方法</title>
      <link>https://arxiv.org/abs/2410.22476</link>
      <description><![CDATA[arXiv:2410.22476v1 公告类型：新
摘要：在面向任务的对话系统中，意图检测对于解释用户查询和提供适当的响应至关重要。现有研究主要解决具有单一意图的简单查询，缺乏有效的系统来处理具有多种意图的复杂查询并提取不同的意图范围。此外，多语言、多意图数据集明显缺失。本研究解决了三个关键任务：从查询中提取多个意图范围、检测多种意图以及开发多语言多标签意图数据集。我们引入了一种从现有基准数据集中精选的新型多标签多类意图检测数据集 (MLMCID-dataset)。我们还提出了一种基于指针网络的架构 (MLMCID) 来提取意图范围并以六元组的形式检测具有粗粒度和细粒度标签的多种意图。综合分析表明，我们的基于指针网络的系统在各种数据集的准确性和 F1 分数方面优于基线方法。]]></description>
      <guid>https://arxiv.org/abs/2410.22476</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过优化样本计算分配扩展 LLM 推理</title>
      <link>https://arxiv.org/abs/2410.22480</link>
      <description><![CDATA[arXiv:2410.22480v1 公告类型：新
摘要：采样是许多大型语言模型 (LLM) 推理时间算法的基本操作。为了在有限的计算量下有效地扩大推理，找到样本计算预算的最佳分配至关重要：我们使用哪些采样配置（模型、温度、语言等）？我们在每种配置中生成多少个样本？我们将这些选择表述为学习问题，并提出 OSCA，这是一种通过找到不同推理配置的最佳组合来优化样本计算分配的算法。我们的实验表明，通过我们学习到的混合分配，我们可以实现比最佳单一配置更好的准确度，代码生成计算量减少 128 倍，4 个推理任务计算量减少 25 倍。OSCA 还被证明在单轮任务之外的代理工作流中有效，在 SWE-Bench 上实现更好的准确度，计算量比默认配置少 3 倍。我们的代码和生成发布在 https://github.com/LeiLiLab/OSCA。]]></description>
      <guid>https://arxiv.org/abs/2410.22480</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型预测同步机器翻译的未来</title>
      <link>https://arxiv.org/abs/2410.22499</link>
      <description><![CDATA[arXiv:2410.22499v1 公告类型：新
摘要：同步机器翻译 (SMT) 接收流式输入话语并逐步生成目标文本。现有的 SMT 方法仅使用已经到达输入的部分话语和生成的假设。受人类口译员在听到未来单词之前预测未来单词的技术启发，我们提出了 $\textbf{T}$translation by $\textbf{A}$nticipating $\textbf{F}$uture (TAF)，这是一种在重新训练低延迟的同时提高翻译质量的方法。其核心思想是使用大型语言模型 (LLM) 来预测未来的源单词并机会性地进行翻译而不会引入太多风险。我们在四个语言方向上评估了我们的 TAF 和 SMT 的多个基线。实验表明，TAF 实现了最佳的翻译质量-延迟权衡，并且在相同延迟（三个单词）下比基线高出多达 5 个 BLEU 点。]]></description>
      <guid>https://arxiv.org/abs/2410.22499</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>注意力胜过一切：语言模型中的定位和缓解偏见</title>
      <link>https://arxiv.org/abs/2410.22517</link>
      <description><![CDATA[arXiv:2410.22517v1 公告类型：新
摘要：我们探索了在提供模糊比较提示时大型语言模型 (LLM) 中偏见如何出现的内部机制：输入比较或强制在两个或多个实体之间进行选择，而没有提供明确的偏好背景。大多数缓解偏见的方法都侧重于事后分析或数据增强。然而，这些都是暂时的解决方案，并没有解决根本原因：模型本身。许多先前的研究展示了注意力模块对引导世代的影响。我们认为，分析注意力对于理解偏见也至关重要，因为它可以洞察 LLM 如何将其注意力分配到不同的实体上，以及这如何导致有偏见的决策。为此，我们首先引入一个指标来量化 LLM 对一个实体而不是另一个实体的偏好。然后，我们提出了 $\texttt{ATLAS}$（基于注意力的目标层分析和缩放），这是一种通过分析注意力得分将偏差定位到 LLM 的特定层，然后通过缩放这些有偏差的层中的注意力来减少偏差的技术。为了评估我们的方法，我们使用 $\texttt{GPT-2 XL}$（1.5B）、$\texttt{GPT-J}$（6B）、$\texttt{LLaMA-2}$（7B）和 $\texttt{LLaMA-3}$（8B）在 3 个数据集（BBQ、Crows-Pairs 和 WinoGender）上进行了实验。我们的实验表明，偏差集中在后面的层中，通常在最后三分之一左右。我们还展示了 $\texttt{ATLAS}$ 如何通过有针对性的干预措施有效地减轻偏差，而不会影响下游性能，并且在应用干预措施时困惑度平均仅增加 0.82%。我们发现所有数据集的偏差分数平均提高了 0.28 分。]]></description>
      <guid>https://arxiv.org/abs/2410.22517</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Auto-Intent：大型语言模型 Web 代理的自动意图发现和自我探索</title>
      <link>https://arxiv.org/abs/2410.22552</link>
      <description><![CDATA[arXiv:2410.22552v1 公告类型：新
摘要：在本文中，我们介绍了 Auto-Intent，这是一种无需直接微调即可将预训练的大型语言模型 (LLM) 调整为目标域代理的方法，我们根据经验专注于网络导航任务。我们的方法首先以高度紧凑的形式（最多三个单词）从目标域演示中无监督地发现潜在意图。利用提取的意图，我们训练我们的意图预测器，根据代理过去的观察和行动来预测下一个意图。特别是，我们提出了一种自我探索方法，其中将前 k 个可能的意图预测作为提示提供给预先训练的 LLM 代理，从而增强决策能力。 Auto-Intent 凭借其在 Mind2Web 上的跨基准泛化，显著提高了 GPT-{3.5, 4} 和 Llama-3.1-{70B, 405B} 代理在 Mind2Web 的大规模真实网站导航基准和 WebArena 的在线导航任务上的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.22552</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>公地的毒性：策划开源预训练数据</title>
      <link>https://arxiv.org/abs/2410.22587</link>
      <description><![CDATA[arXiv:2410.22587v1 公告类型：新
摘要：开源大型语言模型在研究人员和从业人员中越来越受欢迎。虽然开放权重模型已经取得了重大进展，但开放训练数据是领先的开放权重模型创建者尚未采用的做法。与此同时，研究人员正在努力使语言模型更安全。我们提出了一种数据管理流程，以减少在公共领域数据上训练的模型的有害输出。使用公共领域数据存在独特的挑战，因为这些来源在形式和内容上都不同于网络文本。许多来源是历史文献，是光学字符识别 (OCR) 的结果。因此，当前最先进的毒性过滤方法通常不适用于或不适合开放数据模型。在本文中，我们介绍了一种用于开放数据毒性过滤的全新完全开源流程。我们的贡献有三方面。我们创建了一个自定义训练数据集 ToxicCommons，它由已在五个不同维度（基于种族/出身、基于性别/性取向、宗教、基于能力的歧视和暴力）分类的文本组成。我们使用此数据集训练自定义分类器 Celadon，该分类器可用于更有效地在更大范围内检测开放数据中的有害内容。最后，我们描述了一种平衡的内容过滤方法，该方法针对可用于训练的过滤数据优化安全过滤。]]></description>
      <guid>https://arxiv.org/abs/2410.22587</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>描述相似性在语言模型属性推理中的作用</title>
      <link>https://arxiv.org/abs/2410.22590</link>
      <description><![CDATA[arXiv:2410.22590v1 公告类型：新
摘要：属性继承——一种将新属性从较高级别的类别（例如鸟类）投射到较低级别的类别（例如麻雀）的现象——为了解人类如何组织和部署概念知识提供了一个独特的窗口。人们争论这种能力是由于明确存储的分类知识还是由于心理表征之间相似性的简单计算而产生的。这些机械假设如何在当代语言模型中体现？在这项工作中，我们研究了 LM 如何通过行为和因果表征分析实验执行属性继承。我们发现分类和类别相似性在 LM 的属性继承行为中并不相互排斥。也就是说，当 LM 在分类上相关且同时高度相似时，它们更有可能将新属性从一个类别投射到另一个类别。我们的研究结果提供了对语言模型概念结构的洞察，并可能为人类受试者提供新的心理语言学实验。]]></description>
      <guid>https://arxiv.org/abs/2410.22590</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>证明你的观点！：将证明增强原则引入论证性论文的生成</title>
      <link>https://arxiv.org/abs/2410.22642</link>
      <description><![CDATA[arXiv:2410.22642v1 公告类型：新
摘要：论证性文章生成（AEG）旨在生成有关特定争议性话题或辩论的完整文本。尽管当前的 AEG 方法可以生成个人观点，但它们往往忽略了这些观点之间的高级联系。这往往导致生成的结果陷入逻辑混乱，无法有效地证明自己的论点。生成的文章可能会提供与主张相矛盾的证据，或者它们可能无法将主张组合成逻辑流程。在本文中，我们提出了一个统一的两阶段框架：AEG 的证明增强和自我注释（PESA），重点是逻辑增强。具体而言，我们首先使用大型语言模型为逻辑信息、主张和理由构建伪标签。然后，我们提出了一种引入证明原则并确保逻辑一致性的树规划方法。大量实验结果表明，受益于证明原则的指导，PESA 生成的论证性文章比强基线模型具有更好的逻辑有效性和说服力。]]></description>
      <guid>https://arxiv.org/abs/2410.22642</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言学理论与法学硕士的结合：通过等效约束大型语言模型生成代码转换文本</title>
      <link>https://arxiv.org/abs/2410.22660</link>
      <description><![CDATA[arXiv:2410.22660v1 公告类型：新
摘要：代码转换是在一次对话中在两种或多种语言之间交替的现象，它对自然语言处理 (NLP) 提出了独特的挑战。大多数现有研究都侧重于句法约束或神经生成，很少有研究将语言理论与大型语言模型 (LLM) 相结合以生成自然的代码转换文本。在本文中，我们介绍了 EZSwitch，这是一个新颖的框架，它将等价约束理论 (ECT) 与 LLM 相结合，以生成语言有效且流畅的代码转换文本。我们使用人工判断和自动指标来评估我们的方法，结果表明，与基线 LLM 相比，生成的代码转换句子的质量有显著提高。为了解决缺乏合适评估指标的问题，我们对各种自动指标与人工评分进行了全面的相关性研究，结果表明，当前的指标往往无法捕捉到代码转换文本的细微流畅性。此外，我们创建了 CSPref，这是一个基于人类评分的人类偏好数据集，并分析了“困难”和“简单”示例中的模型性能。我们的研究结果表明，将语言约束纳入 LLM 可实现更稳健、更符合人类需求的生成，为跨不同语言对的可扩展代码转换文本生成铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.22660</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从头构建多模态数据集，快速开发日语视觉语言模型</title>
      <link>https://arxiv.org/abs/2410.22736</link>
      <description><![CDATA[arXiv:2410.22736v1 公告类型：新
摘要：要开发高性能的视觉语言模型 (VLM)，必须准备多模态资源，例如图像文本对、交错数据和指令数据。虽然英语的多模态资源很丰富，但日语等非英语语言的相应资源却严重匮乏。为了解决这个问题，我们将日语视为非英语语言，并提出了一种从头开始快速创建日语多模态数据集的方法。我们从网络档案中收集日语图像文本对和交错数据，并使用现有的 VLM 直接从图像生成日语指令数据。我们的实验结果表明，在这些原生数据集上训练的 VLM 优于依赖机器翻译内容的 VLM。]]></description>
      <guid>https://arxiv.org/abs/2410.22736</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越本体论的面向目标的聊天机器人对话状态跟踪</title>
      <link>https://arxiv.org/abs/2410.22767</link>
      <description><![CDATA[arXiv:2410.22767v1 公告类型：新
摘要：面向目标的聊天机器人对于自动执行用户任务（例如预订航班或预订餐厅）至关重要。这些系统的一个关键组件是对话状态跟踪 (DST)，它可以解释用户意图并维护对话状态。然而，现有的 DST 方法通常依赖于固定本体和手动编译的槽值，限制了它们对开放域对话的适应性。我们提出了一种新方法，利用指令调整和高级提示策略来增强 DST 性能，而不依赖于任何预定义的本体。我们的方法使大型语言模型 (LLM) 能够通过精心设计的提示推断对话状态，并包括一种防幻觉机制，以确保在不同的对话环境中准确跟踪。此外，我们使用变分图自动编码器 (VGAE) 来建模和预测后续用户意图。我们的方法达到了最先进的水平，JGA 比现有的无本体 DST 模型高出 42.57%，并且在开放域真实世界对话中表现良好。这项工作在创建更具适应性和准确性的目标导向型聊天机器人方面取得了重大进展。]]></description>
      <guid>https://arxiv.org/abs/2410.22767</guid>
      <pubDate>Thu, 31 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>