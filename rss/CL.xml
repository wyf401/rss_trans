<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 31 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>一个令牌就能帮上忙！学习可扩展和可插入的虚拟令牌，用于检索增强大型语言模型</title>
      <link>https://arxiv.org/abs/2405.19670</link>
      <description><![CDATA[arXiv:2405.19670v1 公告类型：新
摘要：检索增强生成 (RAG) 是一种有前途的方法，可以改进大型语言模型 (LLM)，以生成更真实、更准确和最新的内容。现有方法要么优化提示以指导 LLM 利用检索到的信息，要么直接微调 LLM 以适应 RAG 场景。虽然微调可以产生更好的性能，但它通常会通过修改其参数来损害 LLM 的一般生成能力。这种限制在实际应用中带来了挑战，尤其是在已经部署 LLM 的情况下，因为参数调整可能会影响其原始功能。为了解决这个问题，我们提出了一种新方法，该方法涉及学习可扩展和可插入的 RAG 虚拟令牌。通过维护 LLM 的原始参数并仅微调这些可插入令牌的嵌入，我们的方法不仅提高了 LLM 的性能，而且还保留了它们的一般生成能力。此外，我们设计了多种训练策略来提高方法的可扩展性、灵活性和通用性。在九个问答任务中进行的综合实验证明了我们方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2405.19670</guid>
      <pubDate>Fri, 31 May 2024 06:19:05 GMT</pubDate>
    </item>
    <item>
      <title>思路链在英语-达罗毗荼语机器翻译中缓解性别偏见的重要性</title>
      <link>https://arxiv.org/abs/2405.19701</link>
      <description><![CDATA[arXiv:2405.19701v1 公告类型：新
摘要：机器翻译 (MT) 系统中的性别偏见对实现准确和包容性的翻译构成了重大挑战。本文研究了机器翻译系统中的性别偏见，例如来自德拉威语系的泰卢固语和卡纳达语，分析了性别变化如何影响使用谷歌翻译和 ChatGPT 的翻译准确性和中立性。研究发现，虽然复数形式可以减少偏见，但以个人为中心的句子往往会因历史刻板印象而保持偏见。该研究评估了思维链处理，注意到泰卢固语的偏见从 80% 显著降低到 4%，卡纳达语的偏见从 40% 显著降低到 0%。它还比较了泰卢固语和卡纳达语的翻译，强调需要针对语言的策略来应对这些挑战，并为未来的研究提出方向，以提高数据准备和推理过程中提示的公平性。]]></description>
      <guid>https://arxiv.org/abs/2405.19701</guid>
      <pubDate>Fri, 31 May 2024 06:19:05 GMT</pubDate>
    </item>
    <item>
      <title>SpecDec++：通过自适应候选长度增强推测解码</title>
      <link>https://arxiv.org/abs/2405.19715</link>
      <description><![CDATA[arXiv:2405.19715v1 公告类型：新
摘要：推测解码通过使用更小、更快的草稿模型来减少目标大型语言模型的推理延迟。其性能取决于超参数 K——候选长度，即目标模型在每轮中要验证的候选标记数。然而，以前的方法通常使用简单的启发式方法来选择 K，这可能会导致性能不佳。我们研究了候选长度 K 的选择，并将其表述为马尔可夫决策过程。我们从理论上表明，这种马尔可夫决策过程的最优策略采用阈值策略的形式，即当被拒绝的概率超过阈值时，当前推测应该停止并进行验证。受此理论的启发，我们提出了 SpecDec++，这是推测解码的增强版本，可以动态自适应地确定候选长度。我们用经过训练的接受预测头增强了草稿模型，以预测候选标记的条件接受概率。当预测的至少一个 token 被拒绝的概率超过阈值时，SpecDec++ 将停止当前推测。我们实现了 SpecDec++ 并将其应用于 llama-2-chat 7B 和 70B 模型对。我们的自适应方法在 Alpaca 数据集上实现了 2.04 倍的加速（比基线推测解码额外提高了 7.2%）。在 GSM8K 和 HumanEval 数据集上，我们的方法分别实现了 2.26 倍的加速（提高了 9.4%）和 2.23 倍的加速（提高了 11.1%）。]]></description>
      <guid>https://arxiv.org/abs/2405.19715</guid>
      <pubDate>Fri, 31 May 2024 06:19:05 GMT</pubDate>
    </item>
    <item>
      <title>检测大型语言模型生成中的幻觉：一种标记概率方法</title>
      <link>https://arxiv.org/abs/2405.19648</link>
      <description><![CDATA[arXiv:2405.19648v1 公告类型：新
摘要：人们越来越担心大型语言模型 (LLM) 容易产生不准确的输出（也称为幻觉）。检测它们对于确保依赖 LLM 生成内容的应用程序的可靠性至关重要。当前的方法通常需要大量资源并依赖于广泛的 LLM，或者采用具有多维特征的监督学习或难以重现的复杂语言和语义分析，并且很大程度上依赖于使用产生幻觉的相同 LLM。本文介绍了一种监督学习方法，该方法采用两个简单的分类器，仅使用从其他 LLM 评估器获得的标记和词汇概率得出的四个数值特征，这些特征不一定相同。该方法产生了有希望的结果，在三个不同基准的多个任务中超越了最先进的结果。此外，我们还全面检查了我们方法的优缺点，强调了所使用的特征和作为评估器使用的 LLM 的重要性。我们已在https://github.com/Baylor-AI/HalluDetect公开发布了我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2405.19648</guid>
      <pubDate>Fri, 31 May 2024 06:19:04 GMT</pubDate>
    </item>
    <item>
      <title>PATIENT-{\Psi}：使用大型语言模型模拟患者，以培训心理健康专业人员</title>
      <link>https://arxiv.org/abs/2405.19660</link>
      <description><![CDATA[arXiv:2405.19660v1 公告类型：新
摘要：精神疾病仍然是最关键的公共卫生问题之一，现有的心理健康支持与患者需求之间存在巨大差距。许多心理健康专业人士强调，他们的培训与现实世界的患者互动之间存在脱节，这让一些受训者感到准备不足，并可能影响他们早期的职业成功。在本文中，我们提出了一种用于认知行为疗法 (CBT) 培训的新型患者模拟框架 PATIENT-{\Psi}。为了构建 PATIENT-{\Psi}，我们根据 CBT 原理构建了不同的患者档案及其相应的认知模型，然后使用用患者认知模型编程的大型语言模型 (LLM) 充当模拟治疗患者。我们提出了一种交互式培训方案 PATIENT-{\Psi}-TRAINER，让心理健康受训者通过与 PATIENT-{\Psi} 一起进行角色扮演治疗来练习 CBT 的一项关键技能——制定患者的认知模型。为了评估 PATIENT-{\Psi}，我们对 4 名心理健康培训生和 10 名专家进行了用户研究。结果表明，使用 PATIENT-{\Psi}-TRAINER 进行练习大大提高了培训生感知到的技能习得和信心，这远远超出了现有的培训形式，例如教科书、视频和与非患者的角色扮演。根据专家的看法，PATIENT-{\Psi} 被认为比 GPT-4 更接近真实的患者互动，并且 PATIENT-{\Psi}-TRAINER 有望提高培训生的能力。我们使用 LLM 的开创性患者模拟培训框架具有巨大的潜力，可以增强和推进心理健康培训，最终改善患者护理和结果。我们将发布所有数据、代码和培训平台。]]></description>
      <guid>https://arxiv.org/abs/2405.19660</guid>
      <pubDate>Fri, 31 May 2024 06:19:04 GMT</pubDate>
    </item>
    <item>
      <title>基于深度卷积神经网络的豪萨语电影评论体裁和极性分类模型</title>
      <link>https://arxiv.org/abs/2405.19575</link>
      <description><![CDATA[arXiv:2405.19575v1 公告类型：新
摘要：基于方面的情绪分析 (ABSA) 对于理解文本中的情绪细微差别至关重要，尤其是跨不同语言和文化。本文介绍了一种基于深度卷积神经网络 (CNN) 的新型模型，该模型专门用于豪萨语电影评论中的方面和极性分类，豪萨语是情绪分析研究中代表性不足的语言。创建了一个全面的豪萨语 ABSA 数据集，填补了资源可用性的重大空白。该数据集使用 sci-kit-learn 进行 TF-IDF 转换预处理，包括手动注释的方面级特征本体词和情绪极性分配。所提出的模型将 CNN 与注意机制相结合，用于方面词预测，利用上下文信息和情绪极性。该模型在方面术语提取方面的准确率为 91%，在情绪极性分类方面的准确率为 92%，优于传统的机器模型，提供了对特定方面和情绪的洞察。这项研究推动了 ABSA 研究，特别是在代表性不足的语言方面的研究，对跨文化语言研究具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2405.19575</guid>
      <pubDate>Fri, 31 May 2024 06:19:03 GMT</pubDate>
    </item>
    <item>
      <title>GKT：一种基于指导的新型知识转移框架，用于高效的云边协作 LLM 部署</title>
      <link>https://arxiv.org/abs/2405.19635</link>
      <description><![CDATA[arXiv:2405.19635v1 公告类型：新
摘要：大型语言模型 (LLM) 的规模不断扩大，导致生成响应的能力增强，尽管代价是增加推理时间和增加资源需求。现有的加速方法主要依赖于知识提炼，通常需要对相当大的模型（例如 Llama-7B）进行微调，这对普通用户构成了挑战。此外，目前用于加快推理和降低成本的技术是独立运行的。为了解决这些问题，我们引入了一个新颖且直观的基于指导的知识转移 (GKT) 框架。这种方法利用较大的 LLM 作为“老师”来创建指导提示，并搭配较小的“学生”模型来完成响应。值得注意的是，GKT 不需要微调，也不需要教师和学生模型具有相同的词汇量，从而允许大量批量生成以加速流程，同时确保用户定制。 GKT 可以无缝集成到云端协作架构中，并且功能多样，可在各种模型之间即插即用。它在效率和价格方面都表现出色，堪称“物美价廉”的解决方案。GKT 在 GSM8K 上实现了 14.18% 的最大准确率提升，同时速度提高了 10.72 倍；在 CSQA 上实现了 14.00% 的准确率提升，同时速度提高了 7.73 倍。当使用 ChatGPT 作为教师模型，使用 Llama2-70B 作为学生模型时，我们可以以 52% 的成本实现 ChatGPT 95.00% 的性能。结果显示，在 GSM8K 和 CSQA 数据集上，准确率和处理速度均有显著提升，超过了单独使用学生或教师模型的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.19635</guid>
      <pubDate>Fri, 31 May 2024 06:19:03 GMT</pubDate>
    </item>
    <item>
      <title>面向低资源医学问答的两层检索增强生成框架：使用 Reddit 数据进行概念验证</title>
      <link>https://arxiv.org/abs/2405.19519</link>
      <description><![CDATA[arXiv:2405.19519v1 公告类型：新
摘要：检索增强生成 (RAG) 通过提供相关的上下文文本，提供了约束生成模型输出并减轻幻觉可能性的能力。生成大型语言模型 (LLM) 可以作为上下文合并的标记数量是有限的，因此限制了生成答案的知识量。我们提出了一个两层 RAG 框架用于以查询为中心的答案生成，并在以查询为中心的社交媒体论坛摘要生成背景下评估该框架的概念验证，重点关注新兴的毒品相关信息。评估证明了两层框架在资源受限环境中的有效性，使研究人员能够从用户那里获取近乎实时的数据。]]></description>
      <guid>https://arxiv.org/abs/2405.19519</guid>
      <pubDate>Fri, 31 May 2024 06:19:02 GMT</pubDate>
    </item>
    <item>
      <title>CheXpert Plus：数十万份对齐的放射学文本、图像和患者</title>
      <link>https://arxiv.org/abs/2405.19538</link>
      <description><![CDATA[arXiv:2405.19538v1 公告类型：新
摘要：自五年前发布原始 CheXpert 论文以来，CheXpert 已成为使用最广泛、引用最多的临床 AI 数据集之一。视觉语言模型的出现引发了对与 CheXpert 图像相关的报告共享需求的增加，同时 AI 公平性研究人员对获取人口统计数据的兴趣也日益浓厚。为了解决这个问题，CheXpert Plus 作为一个新的放射学数据源集合，公开可用，以增强模型的可扩展性、性能、稳健性和公平性，适用于放射学领域的所有后续机器学习任务。CheXpert Plus 是放射学领域公开发布的最大的文本数据集，共有 3600 万个文本标记，其中包括 1300 万个印象标记。据我们所知，它代表了放射学领域最大的文本去识别工作，近 100 万个 PHI 跨度被匿名化。这是放射学领域第二次发布大规模英语配对数据集，从而首次实现了跨机构大规模培训。所有报告均与 DICOM 格式的高质量图像配对，以及涵盖各种临床和社会经济群体的大量图像和患者元数据，以及许多病理标签和 RadGraph 注释。我们希望这个数据集能够促进 AI 模型的研究，这些模型可以进一步协助放射科医生并帮助改善医疗保健。数据可在以下网址获得：https://stanfordaimi.azurewebsites.net/datasets/5158c524-d3ab-4e02-96e9-6ee9efc110a1 模型​​可在以下网址获得：https://github.com/Stanford-AIMI/chexpert-plus]]></description>
      <guid>https://arxiv.org/abs/2405.19538</guid>
      <pubDate>Fri, 31 May 2024 06:19:02 GMT</pubDate>
    </item>
    <item>
      <title>在大型语言模型中消除气候错误信息</title>
      <link>https://arxiv.org/abs/2405.19563</link>
      <description><![CDATA[arXiv:2405.19563v1 公告类型：新
摘要：有关气候变化的错误信息是解决人类最严重威胁之一的主要障碍。本文研究了大型语言模型 (LLM) 中有关气候信息的事实准确性。使用真/假标记的问答数据对与气候相关的声明的 LLM 进行微调和评估，我们比较了开源模型，评估了它们对气候变化问题产生真实反应的能力。我们调查了故意用虚假气候信息毒害的模型的可检测性，发现这种毒害可能不会影响模型在其他领域的响应准确性。此外，我们比较了反学习算法、微调和检索增强生成 (RAG) 在事实基础上为气候变化主题的 LLM 提供依据的有效性。我们的评估表明，尽管先前的发现表明它们在隐私环境中无效，但反学习算法对于细微的概念性主张仍然有效。这些见解旨在指导开发更具事实可靠性的法学硕士 (LLM)，并强调需要开展额外工作来确保法学硕士 (LLM) 免受错误信息攻击。]]></description>
      <guid>https://arxiv.org/abs/2405.19563</guid>
      <pubDate>Fri, 31 May 2024 06:19:02 GMT</pubDate>
    </item>
    <item>
      <title>关键学习期：利用早期训练动态实现高效的数据修剪</title>
      <link>https://arxiv.org/abs/2405.19462</link>
      <description><![CDATA[arXiv:2405.19462v1 公告类型：新
摘要：神经机器翻译模型极其耗费数据和计算资源。然而，并非所有数据点对模型训练和泛化的贡献都相同。通过数据修剪来删除低价值数据点的好处是可以大幅减少计算预算，而不会显著降低模型性能。在本文中，我们提出了一种新的数据修剪技术：跨时间检查点 (CAT)，它利用早期模型训练动态来识别与模型性能最相关的数据点。我们将 CAT 与包括 COMET-QE、LASER 和 LaBSE 在内的几种数据修剪技术进行基准测试。我们发现 CAT 在多个测试集上的表现优于印欧语系的基准测试。当应用于英语-德语、英语-法语和英语-斯瓦希里语翻译任务时，CAT 实现了与使用完整数据集相当的性能，同时修剪了高达 50% 的训练数据。我们检查了 CAT 选择的数据点，发现它倾向于选择较长的句子和包含独特或罕见单词的句子。]]></description>
      <guid>https://arxiv.org/abs/2405.19462</guid>
      <pubDate>Fri, 31 May 2024 06:19:01 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的全双工语音对话方案</title>
      <link>https://arxiv.org/abs/2405.19487</link>
      <description><![CDATA[arXiv:2405.19487v1 公告类型：新
摘要：我们提出了一种能够以全双工方式运行的生成对话系统，可实现无缝交互。它基于一个大型语言模型 (LLM)，该模型经过精心调整，可感知感知模块、运动功能模块以及具有两个状态的简单有限状态机（称为神经 FSM）的概念。感知和运动功能模块同时运行，使系统能够同时与用户对话和倾听。LLM 生成用于查询响应的文本标记，并通过向神经 FSM 发出控制标记来自主决定开始响应、等待或中断用户。LLM 的所有这些任务都是作为实时对话序列化视图上的下一个标记预测执行的。在模拟真实交互的自动质量评估中，与基于 LLM 的半双工对话系统相比，所提出的系统将平均对话响应延迟减少了 3 倍以上，同时在超过 50% 的评估交互中响应时间少于 500 毫秒。运行仅具有 80 亿个参数的 LLM，我们的系统比目前最好的商用语音对话 LLM 的中断准确率高出 8%。]]></description>
      <guid>https://arxiv.org/abs/2405.19487</guid>
      <pubDate>Fri, 31 May 2024 06:19:01 GMT</pubDate>
    </item>
    <item>
      <title>深度学习用于口语阅读流畅度评估</title>
      <link>https://arxiv.org/abs/2405.19426</link>
      <description><![CDATA[arXiv:2405.19426v1 公告类型：新
摘要：阅读流畅度评估是识字计划的重要组成部分，用于指导和监控早期教育干预。鉴于教师进行这项练习时资源密集的性质，开发可以对口头阅读录音进行操作的自动工具作为一种客观且高度可扩展的解决方案具有吸引力。准确度、速度和表现力等多个复杂方面是人类对阅读流畅度判断的基础。在这项工作中，我们研究了由人类专家标记的故事文本儿童录音训练数据集的端到端建模。采用预训练的 wav2vec2.0 模型是因为它有可能缓解有限数量的标记数据带来的挑战。我们报告了相关措施的许多系统变体的表现，并探究了已知对阅读流畅度感知很重要的词汇和声学韵律特征的学习嵌入。]]></description>
      <guid>https://arxiv.org/abs/2405.19426</guid>
      <pubDate>Fri, 31 May 2024 06:19:00 GMT</pubDate>
    </item>
    <item>
      <title>超越一致性：基于语言反事实的自动论文评分方法的合理性诊断</title>
      <link>https://arxiv.org/abs/2405.19433</link>
      <description><![CDATA[arXiv:2405.19433v1 公告类型：新
摘要：虽然目前的自动论文评分 (AES) 方法与人类评分者高度一致，但它们的评分机制尚未得到充分探索。我们提出的方法使用大型语言模型 (LLM) 辅助的反事实干预，表明在对论文进行评分时，类似 BERT 的模型主要关注句子级特征，而 LLM 则适应惯例、语言复杂性以及组织，表明与评分标准更全面一致。此外，LLM 可以在反馈期间辨别反事实干预。我们的方法提高了对神经 AES 方法的理解，也可以应用于寻求模型驱动决策透明度的其他领域。代码和数据将在 GitHub 上发布。]]></description>
      <guid>https://arxiv.org/abs/2405.19433</guid>
      <pubDate>Fri, 31 May 2024 06:19:00 GMT</pubDate>
    </item>
    <item>
      <title>语言模型代理的自适应对话团队建设</title>
      <link>https://arxiv.org/abs/2405.19425</link>
      <description><![CDATA[arXiv:2405.19425v1 公告类型：新
摘要：利用多个大型语言模型 (LLM) 代理已被证明是一种解决复杂任务的有前途的方法，而为特定应用有效设计多个代理仍然是一门艺术。因此，回答一个关键问题很有趣：给定一个任务，我们如何建立一个 LLM 代理团队来有效地解决它？我们新的自适应团队建设范式提供了一个灵活的解决方案，通过一种名为 Captain Agent 的新型代理设计实现。它动态地为任务解决过程的每个步骤组建和管理团队，利用嵌套的群组对话和反思来确保多样化的专业知识并防止刻板的输出。它允许采用灵活而结构化的问题解决方法，并有助于减少冗余并增强输出多样性。对六个真实场景的全面评估表明，Captain Agent 的表现明显优于现有的多代理方法，平均准确率提高了 21.94%，无需针对特定任务的提示工程即可提供出色的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.19425</guid>
      <pubDate>Fri, 31 May 2024 06:18:59 GMT</pubDate>
    </item>
    </channel>
</rss>