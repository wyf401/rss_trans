<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Wed, 12 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>迈向受益的大型语言模型：在奖励模型中基准测试群体公平性</title>
      <link>https://arxiv.org/abs/2503.07806</link>
      <description><![CDATA[ARXIV：2503.07806V1公告类型：新 
摘要：随着大型语言模型（LLMS）变得越来越强大，人类用户可以访问，确保各种人口统计组的公平性，即集体公平，是一个关键的道德问题。但是，LLMS中当前的公平性和偏见研究在两个方面受到限制。首先，与机器学习分类中的传统群体公平性相比，它要求在这种情况下，非敏感属性在不同的组之间相同。在许多实际情况下，不同的群体可能会更喜欢不同的及时问题，并且这一要求变得不切实际。其次，它仅对LLM的最终输出评估组公平性，而无需确定可能的偏差来源。也就是说，LLM输出中的偏差可能是由于预训练和填充而导致的。对于填充，偏见可能是由R​​LHF程序和学习的奖励模型造成的。可以说，评估LLM管道中每个组件的群体公平性可以帮助开发更好的方法来减轻可能的偏见。认识到这两个局限性，这项工作基于学习奖励模型的群体公平性。通过使用来自Arxiv的专家写的文本，我们可以在不需要不同人口组的及时及时问题的情况下对奖励模型的群体公平性进行基准测试。令人惊讶的是，我们的结果表明，所有评估的奖励模型（例如Nemotron-4-340B奖励，Armorm-llama3-8b-v0.1和Grm-llama3-8b-Sftreg）表现出统计学意义的群体不公平性。我们还观察到，表现最佳的奖励模型（W.R.T.规范性能指标）倾向于表现出更好的群体公平性。]]></description>
      <guid>https://arxiv.org/abs/2503.07806</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>投机解码的培训领域草案模型：最佳实践和见解</title>
      <link>https://arxiv.org/abs/2503.07807</link>
      <description><![CDATA[ARXIV：2503.07807V1公告类型：新 
摘要：投机解码是一种有效的方法，可以通过使用小型草稿模型来预测目标模型的输出来加速大型语言模型（LLMS）。但是，当将投机解码适应特定于域的目标模型时，由于域移位，通用草图模型的接受率大大下降。在这项工作中，我们系统地研究了用于培训领域草案模型的知识蒸馏技术，以提高其推测准确性。我们比较白盒和黑框蒸馏方法，并在各种数据可访问性方案中探索它们的有效性，包括历史用户查询，策划的域数据以及合成生成的对齐数据。我们跨功能呼叫，生物学和中国领域的实验表明，离线蒸馏一贯的效果超过11％至25％，白盒蒸馏超过了黑盒蒸馏，将其超过2％至10％，并且数据缩放趋势范围内的范围范围越来越多。此外，我们发现合成数据可以有效地调整模型，并实现历史用户查询培训培训的80％至93％。这些发现为培训领域特定的草稿模型提供了实用的准则，以提高投机解码效率。]]></description>
      <guid>https://arxiv.org/abs/2503.07807</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>磁铁：多转移工具使用数据合成和通过图形翻译蒸馏</title>
      <link>https://arxiv.org/abs/2503.07826</link>
      <description><![CDATA[ARXIV：2503.07826V1公告类型：新 
摘要：大型语言模型（LLMS）具有有效利用外部工具来解决用户查询的能力。但是，它们的性能可能会受到涉及用户和多种工具的复杂，多转交互的限制。为了解决这个问题，我们提出了磁铁，这是一个合成高质量训练轨迹的原则性框架，以增强大语模型代理在与人类的多转交流中的功能功能。该框架基于从功能签名路径到一系列查询和可执行函数调用序列的自动和迭代翻译。我们将复杂的函数相互作用与图形和设计新颖的节点操作中的复杂函数相互作用建模，以构建可靠的签名路径。通过上下文蒸馏的启发，当使用教师模型指导积极和负轨迹的产生时，我们将参考函数调用序列作为上下文中的积极提示和对比度，不正确的函数呼叫，作为负面提示。实验表明，通过对负轨迹进行监督的微调和偏好优化，我们的14b模型，磁铁14b-MDPO在BFCL-V3上获得68.01，在BFCL-V3和73.30上对ToolQuery获得了68.01的训练，超过了教师模型Gemini-1.5-Pro-002在BFCL-V3和73.30上获得了68.01。]]></description>
      <guid>https://arxiv.org/abs/2503.07826</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>现代模型，中世纪文本：旧Occitan的POS标记研究</title>
      <link>https://arxiv.org/abs/2503.07827</link>
      <description><![CDATA[ARXIV：2503.07827V1公告类型：新 
摘要：大型语言模型（LLMS）在自然语言处理中表现出了显着的功能，但是它们在处理历史语言中的有效性仍然没有探索。这项研究检查了开源LLM在Octectech的词性标签（POS）标记中的性能，旧的Occitan是一种历史语言，其特征是非标准化的拼字法和显着的毒理变化。通过对两种不同语言图和医学文本的比较分析，我们可以评估当前模型如何应对处理低资源历史语言的固有挑战。我们的发现表明，当面对极端的拼字法和句法变异性时，LLM性能的关键局限性。我们提供详细的错误分析和具体建议，以改善历史语言处理中的模型性能。这项研究促进了我们对挑战性语言环境中LLM能力的理解，同时为计算语言学和历史语言研究提供实践见解。]]></description>
      <guid>https://arxiv.org/abs/2503.07827</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Halluverse25：用于LLM幻觉的细粒度多语言基准数据集</title>
      <link>https://arxiv.org/abs/2503.07833</link>
      <description><![CDATA[ARXIV：2503.07833V1公告类型：新 
摘要：大型语言模型（LLM）越来越多地用于各种情况下，但仍然容易产生非事实内容，通常称为“幻觉”。文献将幻觉分为几种类型，包括实体级别，关系级别和句子级幻觉。但是，现有的幻觉数据集通常无法在多语言设置中捕获细粒度的幻觉。在这项工作中，我们介绍了Halluverse25，这是一个多语言LLM幻觉数据集，将英语，阿拉伯语和土耳其语的细粒度幻觉分类。我们的数据集施工管道使用LLM将幻觉注入事实传记句子，然后是严格的人类注释过程，以确保数据质量。我们在Halluverse25上评估了几个LLM，为专有模型在检测不同情况下检测LLM生成的幻觉方面的表现提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2503.07833</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>cantnlp@dravidianlangtech-2025：多模式仇恨言语检测的索数据袋方法</title>
      <link>https://arxiv.org/abs/2503.07862</link>
      <description><![CDATA[ARXIV：2503.07862V1公告类型：新 
摘要：本文在第五次关于德拉维语语言的语音，视觉和语言技术的研讨会上介绍了多模式社交媒体数据分析（MSMDA-DL）的多模式社交媒体数据分析（MSMDA-DL）（Dravidianlangtech-2025）。我们通过使用转换的MEL频谱图测量的措施在语音（音频）数据上训练仇恨语音检测系统来采用“自声看”方法。尽管我们的候选人模型在测试集中表现较差，但我们的方法在马拉雅拉姆语和泰米尔语的培训和开发过程中提供了有希望的结果。通过足够且平衡的培训数据，我们的结果表明，在多模式仇恨语音检测系统的开发中使用文本和语音（音频）数据是可行的。]]></description>
      <guid>https://arxiv.org/abs/2503.07862</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MAPQA：在地图数据上回答开放域的地理空间问题</title>
      <link>https://arxiv.org/abs/2503.07871</link>
      <description><![CDATA[ARXIV：2503.07871V1公告类型：新 
摘要：地理空间问题回答（QA）是导航和兴趣点（POI）搜索的基本任务。尽管存在现有的地理空间质量空间数据集，但它们的规模和多样性都受到限制，通常仅依靠文字描述地理现象而不考虑其几何形状。缩放地理空间质量空间数据集的主要挑战在于地理空间关系的复杂性，这需要整合空间结构，拓扑依赖性和多跳的推理能力，而大多数基于文本的QA数据集缺乏。为了解决这些限制，我们介绍了MAPQA，这是一个新颖的数据集，不仅提供了问题 - 答案对，而且还包括问题中引用的地理本体的几何形状。 MAPQA是使用SQL查询模板构建的，以从OpenStreetMap（OSM）提取两个研究区域：南加州和伊利诺伊州。它由3,154对QA对组成，涵盖了需要地理空间推理的九种问题类型，例如邻里推理和地理原性类型识别。与现有数据集相比，MAPQA扩大了地理空间问题类型的数量和多样性。我们探索了解决这一挑战的两种方法：（1）一种基于检索的语言模型，该模型通过嵌入相似性来对候选地理位置进行排名，（2）一个大语言模型（LLM），该模型（LLM）从自然语言问题和地理实体属性中产生SQL查询，然后根据一个数据库执行这些属性。我们的发现表明，基于检索的方法有效地捕获了诸如亲密和方向之类的概念，但要在需要明确计算的问题（例如距离计算）方面挣扎。 LLM（例如GPT和Gemini）出色地为单跳推理生成SQL查询，但通过多跳推理面临挑战，突出了推进地理空间QA系统的关键瓶颈。]]></description>
      <guid>https://arxiv.org/abs/2503.07871</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数据集，文档和重复：不平等数据质量的实用性</title>
      <link>https://arxiv.org/abs/2503.07879</link>
      <description><![CDATA[ARXIV：2503.07879V1公告类型：新 
摘要：数据过滤已成为改善模型性能的强大工具，同时降低计算成本。但是，随着大型语言模型计算预算的不断增长，由大量过滤和重复数据集提供的有限数据量将成为一个实际的约束。为了更好地理解如何进行，我们在各种计算预算以及通过数据过滤和重复数据删除创建的多个预训练数据集中研究模型绩效。我们发现，鉴于对培训配方进行了适当的修改，重复现有的积极过滤的数据集，以使多达十个时期的训练在多个计算预算数量级上的单个时期的超级集较大的超级集较大的超级集可能胜过较大的超级训练。尽管此发现依赖于重复许多时期的数据集，但我们还在文档级别调查了这些数据集中的重复序列。我们发现，并非数据集中的所有文档都是平等的，我们可以通过明确操纵单个文档的计数来创建相对于代币预算的更好的数据集。我们结论是，即使大型语言模型的规模，数据过滤仍然是研究的重要方向。]]></description>
      <guid>https://arxiv.org/abs/2503.07879</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>双子座嵌入：双子座的可推广嵌入</title>
      <link>https://arxiv.org/abs/2503.07891</link>
      <description><![CDATA[ARXIV：2503.07891V1公告类型：新 
摘要：在本报告中，我们介绍了Gemini Embedding，这是一种最先进的嵌入模型，利用Gemini（Google最有能力的大语言模型）的力量。利用双子座固有的多语言和代码理解能力，双子座嵌入功能可产生高度概括的嵌入文本，这些文本涵盖了许多语言和文本方式。双子座嵌入产生的表示形式可以预先计算并应用于各种下游任务，包括分类，相似性，聚类，排名和检索。对大规模的多语言文本嵌入基准（MMTEB）进行了评估，该基准包括250多种语言的一百多个任务，双子座嵌入了先前的最新模型，表明嵌入质量的改进很大。我们的统一模型在MMTEB的多语言，英语和代码基准中实现最先进的性能，在广泛的任务中展示了强大的功能，并且超过了专业领域的特定模型。]]></description>
      <guid>https://arxiv.org/abs/2503.07891</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>内存授权的语言模型是否可以推广到“  - 海豹”任务中的推理？</title>
      <link>https://arxiv.org/abs/2503.07903</link>
      <description><![CDATA[ARXIV：2503.07903V1公告类型：新 
摘要：大型语言模型通常会在推理任务中暴露出其脆弱性，尤其是在上下文上执行长长的推理链时。我们提出了一种新的简单的内存仪表型LLM体系结构Memreasoner，其中内存在上下文中学习了事实的相对顺序，并在解码器选择性地参与内存时可以跳过它们。 Memreasoner受过训练有素的端到端，并提供了可选的支持不同程度的事实监督。我们在两个不同的合成多跳的推理任务上培训Memreasoner，以及现有的内存启动变压器模型和一个状态空间模型。在各种具有挑战性的场景下进行的实验，包括长期干扰物文本或测试集的目标答案变化，在单跳和两跳任务上显示了Memreasoner的强烈概括。 Memreasoner的这种概括是使用无弱支持的事实监督来实现的（分别使用一个和1 \％的支持事实，分别用于单跳任务和两人任务）。相比之下，基准模型总体上难以概括和受益于使用全面支持的事实监督。结果突出了明确的记忆机制的重要性，再加上其他弱监督，以提高大型语言模型的上下文处理能力来推理任务。]]></description>
      <guid>https://arxiv.org/abs/2503.07903</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EFPC：朝着高效且灵活的及时压缩</title>
      <link>https://arxiv.org/abs/2503.07956</link>
      <description><![CDATA[ARXIV：2503.07956V1公告类型：新 
摘要：像GPT-4这样的大型语言模型（LLM）的出现已经彻底改变了自然语言处理（NLP），从而实现了多样化的复杂任务。但是，广泛的令牌计数导致了较高的计算和财务负担。为了解决这个问题，我们提出了有效且灵活的及时压缩（EFPC），这是一种统一任务意识和任务不合时式压缩的新方法，以实现有利的准确性效率折衷。 EFPC使用GPT-4生成压缩提示，并将其与原始提示进行培训。在培训和推理期间，我们根据预测的概率有选择地预定用户说明并压缩提示。 EFPC具有高度的数据效率，可以通过最小数据实现显着的性能。与最先进的方法LLMlingua-2相比，EFPC以4倍的压缩率以1％的额外数据获得了4.8％的相对相对提高，而Longbench单doc QA基准的额外数据为11.4％，增益为11.4％。 EFPC的统一框架支持广泛的适用性并提高各种模型，任务和域的性能，从而在NLP中提供了实践进步。]]></description>
      <guid>https://arxiv.org/abs/2503.07956</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LabelCorank：革命性的长尾巴多标签分类，并共同出现</title>
      <link>https://arxiv.org/abs/2503.07968</link>
      <description><![CDATA[ARXIV：2503.07968V1公告类型：新 
摘要：动机：尽管在语义表示方面的最新进展是由预先训练和大规模语言模型驱动的，但解决了多标签文本分类中长期的尾巴挑战仍然是一个重大问题。长期的尾巴挑战一直在准确地对较少频繁的标签进行分类时持续存在困难。当前的方法通常着重于改善文本语义，同时忽略了标签关系的关键作用。结果：本文介绍了LabelCorank，这是一种受排名原则启发的新颖方法。 LabelCorank利用标签共发生的关系来通过双阶段的重新依克过程来完善初始标签分类。第一阶段使用初始分类结果形成初步排名。在第二阶段，标签共发生矩阵用于重新启动初步结果，从而提高了最终分类的准确性和相关性。通过将重读标签表示作为其他文本功能集成，LabelCorank有效地减轻了多标签分类中的长尾部问题。对包括MAG-CS，PubMed和AAPD在内的流行数据集进行的实验评估证明了LabelCorank的有效性和鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2503.07968</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强代码转换输入数据的多语言语言模型</title>
      <link>https://arxiv.org/abs/2503.07990</link>
      <description><![CDATA[ARXIV：2503.07990V1公告类型：新 
摘要：代码转换或单个对话中语言之间的交替，对NLP任务上的多语言语言模型提出了挑战。这项研究调查了在代码开关数据集上的预训练多语言BERT（MBERT）是否可以改善模型在关键NLP任务上的性能，例如语音标记，情感分析，命名实体识别和语言识别的一部分。我们使用Spanglish Tweet的数据集进行预训练，并根据基线模型评估预训练的模型。
  我们的发现表明，我们的预训练的Mbert模型优于给定任务中的基线模型，对语音标记的部分地区看到了最显着的改进。此外，我们的潜在分析还发现了更多同质的英语和西班牙语嵌入语言识别任务，从而为未来的建模工作提供了见解。
  这项研究突出了为代码转换输入数据调整多语言LMS的潜力，以便在全球化和多语言上下文中进行高级实用程序。未来的工作包括将实验扩展到其他语言对，合并多形数据以及探索方法，以更好地理解上下文依赖上下文的代码转换。]]></description>
      <guid>https://arxiv.org/abs/2503.07990</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在前景和回顾中：长期个性化对话代理的反思性记忆管理</title>
      <link>https://arxiv.org/abs/2503.08026</link>
      <description><![CDATA[ARXIV：2503.08026V1公告类型：新 
摘要：大型语言模型（LLMS）在开放式对话中取得了重大进展，但是他们无法保留和从长期互动中获取相关信息，从而限制了它们在需要持续个性化的应用中的有效性。已经提出了外部记忆机制来解决此限制，从而使LLMS能够保持对话连续性。但是，现有的方法面临两个主要挑战。首先，刚性记忆粒度无法捕获对话的自然语义结构，从而导致零散和不完整的表示。其次，固定的检索机制不能适应各种对话环境和用户交互模式。 In this work, we propose Reflective Memory Management (RMM), a novel mechanism for long-term dialogue agents, integrating forward- and backward-looking reflections: (1) Prospective Reflection, which dynamically summarizes interactions across granularities-utterances, turns, and sessions-into a personalized memory bank for effective future retrieval, and (2) Retrospective Reflection, which iteratively refines the retrieval in an online reinforcement learning （RL）基于LLM的引用证据的方式。实验表明，RMM在各种指标和基准测试中表现出一致的改进。例如，RMM在longmemeval数据集上没有内存管理的情况下显示出10％以上的精度提高。]]></description>
      <guid>https://arxiv.org/abs/2503.08026</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习搜索有效的示例序列中的内在学习</title>
      <link>https://arxiv.org/abs/2503.08030</link>
      <description><![CDATA[ARXIV：2503.08030V1公告类型：新 
摘要：大型语言模型（LLMS）表现出令人印象深刻的几次学习能力，但它们的性能取决于封闭式示例的顺序。影响这一点的关键因素包括序列的长度，组成和布置及其与特定查询的关系。现有方法通常会孤立地解决这些因素，从而忽略了它们的相互依存关系。此外，选择最佳序列的广泛搜索空间使整体方法的发展变得复杂。在这项工作中，我们介绍了基于光束搜索的示例序列构建体（BESC），这是一种学习构建最佳示例序列的新方法。 BESC通过在推断期间共同考虑序列选择中涉及的所有关键因素，同时逐步构建序列。该设计使使用光束搜索可以显着降低搜索空间的复杂性。各种数据集和语言模型的实验表现出显着改善的性能。]]></description>
      <guid>https://arxiv.org/abs/2503.08030</guid>
      <pubDate>Wed, 12 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>