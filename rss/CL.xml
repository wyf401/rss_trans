<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 12 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>UltraEval：为法学硕士提供灵活、全面评估的轻量级平台</title>
      <link>https://arxiv.org/abs/2404.07584</link>
      <description><![CDATA[arXiv:2404.07584v1 公告类型：新
摘要：评估对于磨练大型语言模型（LLM）、查明其能力和指导增强至关重要。法学硕士的快速发展需要一个轻量级且易于使用的框架来快速部署评估。然而，由于需要考虑各种实施细节，开发一个全面的评估平​​台绝非易事。现有平台通常很复杂且模块化程度较差，阻碍了无缝融入研究人员的工作流程。本文介绍了UltraEval，一个用户友好的评估框架，具有轻量级、全面性、模块化和高效的特点。我们确定并重新实现模型评估的三个核心组成部分（模型、数据和指标）。由此产生的可组合性允许在统一的评估工作流程中自由组合不同的模型、任务、提示和指标。此外，UltraEval通过统一的HTTP服务支持多样化的模型，并提供足够的推理加速。 UltraEval 现在可供研究人员公开使用~\footnote{网站位于 \url{https://github.com/OpenBMB/UltraEval}}。]]></description>
      <guid>https://arxiv.org/abs/2404.07584</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>NoticIA：西班牙语标题诱饵文章摘要数据集</title>
      <link>https://arxiv.org/abs/2404.07611</link>
      <description><![CDATA[arXiv:2404.07611v1 公告类型：新
摘要：我们提出了 NoticIA，这是一个由 850 篇西班牙新闻文章组成的数据集，其中包含突出的点击诱饵标题，每篇文章都配有由人类编写的高质量单句生成摘要。这项任务需要高级的文本理解和总结能力，挑战模型推断和连接​​不同信息以满足用户通过点击诱饵标题产生的信息需求的能力。我们评估各种最先进的大型语言模型的西班牙语文本理解能力。此外，我们使用该数据集来训练 ClickbaitFighter，这是一种特定于任务的模型，可在此任务中实现接近人类的表现。]]></description>
      <guid>https://arxiv.org/abs/2404.07611</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:52 GMT</pubDate>
    </item>
    <item>
      <title>分解标签空间、格式和歧视：重新思考法学硕士如何通过情境学习响应和解决任务</title>
      <link>https://arxiv.org/abs/2404.07546</link>
      <description><![CDATA[arXiv:2404.07546v1 公告类型：新
摘要：随着大规模语言模型（LLM）的发展，上下文学习（ICL）已成为一种强大的功能。通过使用少量演示示例指导法学硕士，ICL 使他们能够执行广泛的任务，而无需更新数百万个参数。然而，在最近的分析研究中，演示对提高最终任务绩效的确切贡献尚未得到彻底调查。在本文中，我们根据经验将 ICL 的整体表现分解为三个维度：标签空间、格式和辨别力，并评估了跨不同任务范围的四个通用 LLM。与直觉相反，我们发现演示对于激发语言模型的歧视性知识具有边际影响。然而，ICL 在调节标签空间和格式方面表现出显着的功效，有助于法学硕士以所需的标签词做出反应。然后，我们展示了这种能力的功能，类似于法学硕士需要遵循的详细说明。我们还对 ICL 的检索机制进行了深入分析，发现检索语义上最相似的示例可以显着提高模型的判别能力。]]></description>
      <guid>https://arxiv.org/abs/2404.07546</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>注释作为自然逻辑枢轴：通过注释视角改进代码生成</title>
      <link>https://arxiv.org/abs/2404.07549</link>
      <description><![CDATA[arXiv:2404.07549v1 公告类型：新
摘要：代码生成旨在理解问题描述并生成相应的代码片段，现有工作通常通过提示策略（例如思想链及其变体）将此类复杂任务分解为中间步骤。虽然这些研究取得了一些成功，但其有效性高度依赖于 GPT-4 等高级大型语言模型 (LLM) 的能力，特别是在 API 调用方面，这极大地限制了它们的实际适用性。因此，如何在不显着增加培训成本的情况下增强中小型代码LLM的代码生成能力是一个颇具吸引力的挑战。在本文中，我们认为代码注释是自然语言和代码语言之间的自然逻辑枢纽，并建议使用注释来提高代码法学硕士的代码生成能力。具体来说，我们提出了MANGO（comMents As Natural loGic pivOts），包括评论对比训练策略和相应的逻辑评论解码策略。实验在 HumanEval 和 MBPP 上进行，利用 StarCoder 和 WizardCoder 作为骨干模型，模型参数大小在 3B 到 7B 之间。结果表明，MANGO 在强基线的基础上显着提高了代码通过率。同时，逻辑评论解码策略的鲁棒性明显高于思想链提示。该代码可在 \url{https://github.com/pppa2019/Mango} 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2404.07549</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:51 GMT</pubDate>
    </item>
    <item>
      <title>利用数据增强进行过程信息提取</title>
      <link>https://arxiv.org/abs/2404.07501</link>
      <description><![CDATA[arXiv:2404.07501v1 公告类型：新
摘要：业务流程建模项目通常需要正式的流程模型作为核心组件。与创建此类正式流程模型相关的高成本激发了许多不同领域的研究，旨在从现成的数据自动生成流程模型。其中包括事件日志的流程挖掘，以及从自然语言文本生成业务流程模型。后一个领域的研究经常面临数据可用性有限的问题，阻碍了新技术（尤其是基于学习的技术）的评估和开发。
  为了克服这个数据稀缺问题，在本文中，我们研究了数据增强在自然语言文本数据中的应用。数据增强方法在机器学习中已经很成熟，可以在无需人工帮助的情况下创建新的合成数据。我们发现这些方法很多都适用于业务流程信息抽取的任务，提高了抽取的准确性。我们的研究表明，数据增强是实现机器学习方法从自然语言文本生成业务流程模型任务的重要组成部分，目前大多数基于规则的系统仍然是最先进的。简单的数据增强技术将提及提取的 $F_1$ 分数提高了 2.9 个百分点，将关系提取的 $F_1$ 分数提高了 $4.5$。为了更好地理解数据增强如何改变人类注释文本，我们分析生成的文本，可视化并讨论增强文本数据的属性。
  我们公开所有代码和实验结果。]]></description>
      <guid>https://arxiv.org/abs/2404.07501</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>语言模型合成数据的最佳实践和经验教训</title>
      <link>https://arxiv.org/abs/2404.07503</link>
      <description><![CDATA[arXiv:2404.07503v1 公告类型：新
摘要：人工智能模型的成功依赖于大型、多样化和高质量数据集的可用性，但由于数据稀缺、隐私问题和高成本，这些数据集的获取可能具有挑战性。通过生成模仿现实世界模式的人工数据，合成数据已成为一种有前途的解决方案。本文概述了合成数据研究，讨论了其应用、挑战和未来方向。我们提供现有技术的经验证据来证明其有效性，并强调确保其真实性、保真度和公正性的重要性。我们强调需要负责任地使用合成数据来构建更强大、更具包容性和值得信赖的语言模型。]]></description>
      <guid>https://arxiv.org/abs/2404.07503</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>从单词到数字：当给出上下文示例时，您的大型语言模型实际上是一个有能力的回归器</title>
      <link>https://arxiv.org/abs/2404.07544</link>
      <description><![CDATA[arXiv:2404.07544v1 公告类型：新
摘要：我们分析了预训练的大型语言模型（例如 Llama2、GPT-4、Claude 3 等）在给定上下文示例时如何很好地进行线性和非线性回归，而无需任何额外的训练或梯度更新。我们的研究结果表明，几种大型语言模型（例如 GPT-4、Claude 3）能够执行回归任务，其性能可与随机森林、Bagging 或 Gradient Boosting 等传统监督方法相媲美（甚至优于）。例如，在具有挑战性的 Friedman #2 回归数据集上，Claude 3 的性能优于许多监督方法，例如 AdaBoost、SVM、随机森林、KNN 或梯度提升。然后，我们研究大型语言模型的性能随上下文样本数量的变化情况。我们借鉴在线学习的遗憾概念，并凭经验证明法学硕士能够获得亚线性遗憾。]]></description>
      <guid>https://arxiv.org/abs/2404.07544</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:50 GMT</pubDate>
    </item>
    <item>
      <title>具有广义持续学习的可扩展语言模型</title>
      <link>https://arxiv.org/abs/2404.07470</link>
      <description><![CDATA[arXiv:2404.07470v1 公告类型：新
摘要：持续学习变得越来越重要，因为它有助于获取和完善语言模型中可扩展的知识和技能。然而，现有方法通常在现实场景中遇到严格的限制和挑战，例如依赖经验回放、优化约束和推理任务 ID。在这项研究中，我们引入了可扩展语言模型（SLM），以在更具挑战性和通用性的环境中克服这些限制，代表着持续学习实际应用的重大进步。具体来说，我们提出了联合自适应重新参数化（JARe），与动态任务相关知识检索（DTKR）集成，以实现基于特定下游任务的语言模型的自适应调整。这种方法利用向量空间内的任务分布，旨在实现平稳且轻松的持续学习过程。我们的方法在不同的骨干网和基准上展示了最先进的性能，在全套和少量场景中实现有效的持续学习，并且遗忘最少。此外，虽然之前的研究主要集中在分类等单一任务类型，但我们的研究超越了大型语言模型，即 LLaMA-2，探索了跨不同领域和任务类型的影响，例如单一语言模型可以适当地扩展到更广泛的应用程序。]]></description>
      <guid>https://arxiv.org/abs/2404.07470</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>自由放任的危害：生成语言模型中的算法偏差</title>
      <link>https://arxiv.org/abs/2404.07475</link>
      <description><![CDATA[arXiv:2404.07475v1 公告类型：新
摘要：生成语言模型（LM）的快速部署引起了人们对影响不同消费者福祉的社会偏见的担忧。现有的关于生成语言模型的文献主要通过明确的身份提示来检验偏见。然而，先前对早期基于语言的技术平台（包括搜索引擎）中的偏见的研究表明，即使没有明确指定身份术语，歧视也可能发生。关于 LM 对开放式提示（身份分类未指定）的反应偏差的研究还很缺乏，而且尚未以最终消费者的伤害为基础。在这里，我们通过开放式提示考虑更广泛的自然用例，从而推进生成 LM 偏差的研究。在这种“自由放任”的环境中，我们发现来自五个最普遍的语言模型（ChatGPT3.5、ChatGPT4、Claude2.0、Llama2 和 PaLM2）综合生成的文本使少数群体的遗漏、从属和刻板印象永久化。具有交叉种族、性别和/或性取向身份（AI/AN、亚洲人、黑人、拉丁人、中东和北非地区、NH/PI、女性、非二元性别、酷儿）。我们发现存在偏见的广泛证据表明，与代表性或授权性的描绘相比，这些人遇到 LM 生成的以从属方式描绘其身份的输出的可能性要高出数百到数千倍。我们还记录了LM产生的产出中普遍存在的刻板印象（例如永远的外国人），这些刻板印象会引发心理伤害，对少数群体产生不成比例的影响。其中包括刻板印象威胁，这会导致认知能力受损和负面自我认知增加。我们的研究结果强调，迫切需要保护消费者免受语言模型造成的歧视性伤害，并投资于旨在赋予不同消费者权力的关键人工智能教育项目。]]></description>
      <guid>https://arxiv.org/abs/2404.07475</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>具有序列显着性的交互式提示调试</title>
      <link>https://arxiv.org/abs/2404.07498</link>
      <description><![CDATA[arXiv:2404.07498v1 公告类型：新
摘要：我们提出了 Sequence Salience，这是一种使用输入显着性方法进行交互式提示调试的可视化工具。序列显着性建立在广泛使用的文本分类和单标记预测显着性方法的基础上，并将其扩展到专为调试复杂的 LLM 提示而定制的系统。我们的系统非常适合长文本，并通过以下方式扩展了之前的工作：1）提供对单词、句子或段落级别的标记级显着性的可控聚合，使长输入的显着性易于处理； 2）支持快速迭代，从业者可以根据显着性结果采取行动，完善提示，并对新输出运行显着性。我们提供的案例研究展示了序列显着性如何帮助从业者使用几种复杂的提示策略，包括少样本、思维链和宪法原则。 Sequence Salience 基于 Learning Interpretability Tool（一个用于 ML 模型可视化的开源平台）构建，代码、笔记本和教程可从 http://goo.gle/sequence-salience 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.07498</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>生物医学法学硕士：临床命名实体识别研究</title>
      <link>https://arxiv.org/abs/2404.07376</link>
      <description><![CDATA[arXiv:2404.07376v1 公告类型：新
摘要：大型语言模型（LLM）在各种 NLP 任务中表现出显着的多功能性，但由于医学语言的复杂性和数据稀缺性，在生物医学中遇到了明显的挑战。本文通过探索提高法学硕士在命名实体识别（NER）任务中的性能的策略，研究了法学硕士在医学领域的应用。具体来说，我们的研究揭示了精心设计的提示在生物医学中的重要性。对上下文中示例的策略选择产生了显着的改进，在小样本临床 NER 的所有基准数据集中，F1 分数增加了约 15-20%。此外，我们的研究结果表明，通过激励策略整合外部资源可以弥合通用 LLM 熟练程度和医学 NER 的专业需求之间的差距。利用医学知识库，我们提出的受检索增强生成（RAG）启发的方法可以提高零样本临床 NER 的法学硕士的 F1 分数。我们将在发布后发布代码。]]></description>
      <guid>https://arxiv.org/abs/2404.07376</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>JetMoE：用 10 万美元实现 Llama2 性能</title>
      <link>https://arxiv.org/abs/2404.07413</link>
      <description><![CDATA[arXiv:2404.07413v1 公告类型：新
摘要：大型语言模型（LLM）取得了显着的成果，但其不断增长的资源需求已成为发展强大且易于使用的超人类智能的主要障碍。本报告介绍了 JetMoE-8B，这是一种新的法学硕士，培训费用不到 10 万美元，使用来自精心混合的开源语料库的 1.25T 代币和 30,000 个 H100 GPU 小时。尽管成本低廉，JetMoE-8B 却表现出了令人印象深刻的性能，JetMoE-8B 的性能优于 Llama2-7B 模型，JetMoE-8B-Chat 的性能优于 Llama2-13B-Chat 模型。这些结果表明法学硕士培训比通常认为的更具成本效益。 JetMoE-8B 基于高效的稀疏门混合专家 (SMoE) 架构，由注意力和前馈专家组成。两个层都是稀疏激活的，允许 JetMoE-8B 具有 8B 个参数，同时为每个输入标记仅激活 2B 个参数，与 Llama2-7B 相比，推理计算减少了约 70%。此外，JetMoE-8B 高度开放且对学术界友好，仅使用公共数据集和训练代码。本报告详细介绍了所有训练参数和数据混合，以促进未来开发开放基础模型的工作。这种透明度旨在鼓励可访问且高效的法学硕士领域的合作和进一步进步。模型权重可在 https://github.com/myshell-ai/JetMoE 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2404.07413</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>“毫无意义？”：对 NLP 中“幻觉”的观点和挑战的批判性调查</title>
      <link>https://arxiv.org/abs/2404.07461</link>
      <description><![CDATA[arXiv:2404.07461v1 公告类型：新
摘要：我们通过对 NLP 研究中的 103 篇出版物进行严格审查，研究了同行评审文献中大语言模型 (LLM) 中幻觉的特征。通过对社会学和技术文献的全面回顾，我们发现人们对“幻觉”一词缺乏共识。此外，我们还对来自 NLP 和 AI 领域的 171 位从业者进行了一项调查，以了解对幻觉的不同看法。我们的分析强调了在 NLP 中概述幻觉的明确定义和框架的必要性，强调了潜在的挑战，我们的调查投入提供了对幻觉在社会中的影响和后果的主题理解。]]></description>
      <guid>https://arxiv.org/abs/2404.07461</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>对话系统中受人格影响的情绪生成</title>
      <link>https://arxiv.org/abs/2404.07229</link>
      <description><![CDATA[arXiv:2404.07229v1 公告类型：新
摘要：生成适当的情感响应对于对话系统在各种应用场景中提供类人交互至关重要。大多数以前的对话系统试图通过从匿名对话数据中学习同理心方式来实现这一目标。然而，这些方法产生的情绪反应可能不一致，这将降低用户参与度和服务质量。心理学研究结果表明，人类的情绪表达植根于人格特质。因此，我们提出了一个新任务，即受人格影响的情绪生成，根据赋予对话系统的人格生成情绪，并通过受人格影响的情绪转换进一步研究解决方案。具体来说，我们首先构建一个日常对话数据集，即个性情感线数据集（PELD），其中包含情感和个性注释。随后，我们分析了该任务中的挑战，即（1）异构地整合个性和情感因素；（2）在对话上下文中提取多粒度的情感信息。最后，我们建议通过模拟对话系统中的情绪转换过程来将个性建模为转换权重，并解决上述挑战。我们对 PELD 进行了广泛的实验以进行评估。结果表明，通过采用我们的方法，在基于 BERT 的模型中，宏观 F1 的情感生成性能提高了 13%，加权 F1 的情感生成性能提高了 5%。]]></description>
      <guid>https://arxiv.org/abs/2404.07229</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:47 GMT</pubDate>
    </item>
    <item>
      <title>我们呼吁干预：仔细研究语言模型对不同类型语言变异的适应</title>
      <link>https://arxiv.org/abs/2404.07304</link>
      <description><![CDATA[arXiv:2404.07304v1 公告类型：新
摘要：我们提出了一系列干预措施和实验，使我们能够理解语言模型对具有语言变异的文本（例如非标准或方言文本）的适应。我们的干预措施解决了语言变异的几个特征，导致字符、子词和词级的变化。通过在不同大小和性质的训练数据的语言模型适应过程中应用我们的干预措施，我们获得了重要的见解，了解是什么使语言模型特别难以处理语言变异。例如，对于具有字符级变化的文本，即使使用几个训练示例，性能也会有所提高，但会趋于稳定，这表明更多的数据并不是解决方案。相比之下，对于涉及新单词或含义的变化的文本，需要更多的数据，但这会带来性能的巨大突破。我们的研究结果为方言 NLP 的未来工作提供了信息，并使语言模型对整体语言变化更加稳健。我们为我们的干预措施编写了代码，该代码可以应用于任何公开的英文文本数据。]]></description>
      <guid>https://arxiv.org/abs/2404.07304</guid>
      <pubDate>Fri, 12 Apr 2024 06:16:47 GMT</pubDate>
    </item>
    </channel>
</rss>