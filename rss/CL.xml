<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 27 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>BERTScoreVisualizer：用于理解使用 BERTScore 进行简化文本评估的 Web 工具</title>
      <link>https://arxiv.org/abs/2409.17160</link>
      <description><![CDATA[arXiv:2409.17160v1 公告类型：新
摘要：BERTScore 指标通常用于评估自动文本简化系统。但是，该指标的当前实现无法提供对该指标可以生成的所有信息的完整可见性。值得注意的是，特定的标记匹配对于生成简化文本质量的子句级洞察非常有用。我们通过引入 BERTScoreVisualizer 来解决这个问题，这是一个 Web 应用程序，它不仅能报告精度、召回率和 F1 分数，还能提供标记之间匹配的可视化。我们相信，我们的软件可以通过具体显示生成的简化文本与参考文本的偏差来帮助改进文本简化系统的分析。我们在 GitHub 上托管我们的代码和演示。]]></description>
      <guid>https://arxiv.org/abs/2409.17160</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>REAL：基于响应嵌入的 LLM 对齐</title>
      <link>https://arxiv.org/abs/2409.17169</link>
      <description><![CDATA[arXiv:2409.17169v1 公告类型：新
摘要：将大型语言模型 (LLM) 与人类偏好对齐是构建有用且安全的 AI 工具的关键步骤，这通常涉及对监督数据集进行训练。流行的算法（例如直接偏好优化）依赖于根据人类反馈排名的 AI 生成的响应对。标记过程是对齐流程中最耗费人力和成本的部分，提高其效率将对 AI 开发产生重大影响。我们提出了一种对高质量训练数据集进行采样的策略，该策略侧重于从一组 AI 生成的响应中获取最具信息量的响应对以进行标记。在合成 HH-RLHF 基准上的实验结果表明，选择不同的响应对可以增强 LLM 的直接对齐，同时减少继承的标记错误。我们还将我们的方法应用于真实世界数据集 SHP2，从多个响应中选择最佳对。在不同响应对上对齐的模型在对话任务中获得了最佳胜率。我们的研究结果表明，关注不太相似的对可以提高 LLM 对齐的效率，节省高达 65% 的注释者的工作量。]]></description>
      <guid>https://arxiv.org/abs/2409.17169</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用领域特定小语言模型进行跨域内容生成</title>
      <link>https://arxiv.org/abs/2409.17171</link>
      <description><![CDATA[arXiv:2409.17171v1 公告类型：新
摘要：使用小型语言模型生成特定领域的内容具有挑战性，尤其是在处理重叠最小的多个不同数据集时。在这项研究中，我们探索了使小型语言模型能够为两个不同领域产生连贯且相关的输出的方法：故事（数据集 A）和食谱（数据集 B）。我们的初步实验表明，在每个数据集上训练单个模型会产生令人满意的结果，每个模型都会在其领域内生成适当的内容。我们发现，与使用通用标记器相比，使用针对每个数据集量身定制的自定义标记器可以显着提高生成质量。尝试使用低秩自适应 (LoRA) 或标准微调将单个模型适配到两个领域不会产生实质性结果，通常无法产生有意义的输出。此外，在不冻结模型现有权重的情况下进行完全微调会导致灾难性的遗忘，其中模型会丢失先前学习的信息并仅保留来自新数据的知识。为了克服这些挑战，我们采用了一种知识扩展策略：仅使用附加参数进行训练。这种方法使模型能够根据要求生成故事和食谱，有效地处理多个领域而不会遭受灾难性遗忘。我们的研究结果表明，使用冻结层进行知识扩展是小型语言模型在不同数据集中生成领域特定内容的有效方法。这项工作有助于开发高效的多领域语言模型，并为管理小规模架构中的灾难性遗忘提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2409.17171</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当你第一次看到 $a^2+b^2=c^2$ 时，你会问什么？评估法学硕士的好奇心驱动提问能力</title>
      <link>https://arxiv.org/abs/2409.17172</link>
      <description><![CDATA[arXiv:2409.17172v1 公告类型：新
摘要：大型语言模型 (LLM) 可以存储大量知识，但它们获取新知识的潜力仍然未知。我们提出了一个评估这种能力的新型评估框架。该框架提示 LLM 生成有关介绍科学知识的陈述的问题，模拟好奇的人第一次面对该陈述时的情形。我们对生成的问题的质量进行评分，从而评估 LLM 的知识获取潜力。我们应用受控消融研究来验证我们的评分程序。此外，我们创建了一个合成数据集，其中包含 1101 条物理、化学和数学陈述，难度级别不同，300 条常识陈述和 567 条错误陈述。进行了人工评估以验证我们的模型评估，在考虑的所有三个指标上实现了近似加权 Cohen&#39;s kappa 0.7。我们发现，虽然 GPT-4 和 Mistral 8x7b 等大型模型擅长生成连贯且相关的问题，但较小的 Phi-2 模型同样有效甚至更有效。这表明规模并不是唯一决定模型知识获取潜力的因素。所提出的框架量化了通常被忽视的关键模型能力，并为开发知识更丰富的 AI 系统开辟了研究机会]]></description>
      <guid>https://arxiv.org/abs/2409.17172</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种用于增强大型语言模型中零资源幻觉检测的多重填空考试方法</title>
      <link>https://arxiv.org/abs/2409.17173</link>
      <description><![CDATA[arXiv:2409.17173v1 公告类型：新
摘要：大型语言模型（LLM）经常会编造幻觉文本。已经开发了几种方法来检测此类文本，方法是将其与概率再生的多个版本进行语义比较。然而，一个重要的问题是，如果每个再生文本的故事情节发生变化，生成的文本将变得无法比较，这会降低检测准确性。在本文中，我们提出了一种幻觉检测方法，该方法结合了多重填空考试方法来解决这个故事情节变化的问题。首先，我们的方法通过屏蔽原始文本中的多个对象来创建多重填空考试。其次，提示 LLM 重复回答这个考试。这种方法确保考试答案的故事情节与原始故事情节一致。最后，通过对考试答案进行评分来量化每个原始句子的幻觉程度，同时考虑到原文本身中 \emph{幻觉滚雪球} 的可能性。实验结果表明，我们的方法不仅单独表现优于现有方法，而且在与现有方法的集成中也取得了更清晰的最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2409.17173</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CSCE：通过同时增强因果意义和一致性来提高 LLM 推理能力</title>
      <link>https://arxiv.org/abs/2409.17174</link>
      <description><![CDATA[arXiv:2409.17174v1 公告类型：新
摘要：基于链的推理方法，如思路链 (CoT)，在解决大型语言模型 (LLM) 的推理任务中发挥着越来越重要的作用。然而，\textit{推理步骤} 和 \textit{对应状态转换} 之间的因果错觉正在成为提高 LLM 推理能力的重大障碍，尤其是在长距离推理任务中。本文提出了一种非基于链的推理框架，用于同时考虑因果意义和一致性，即因果意义和一致性增强器 (CSCE)。我们利用治疗效果评估定制 LLM 的损失函数，从因果意义和一致性两个方面增强其推理能力。这确保模型捕捉到必要的因果关系并在各种场景中保持稳健和一致的性能。此外，我们将推理过程从链式方法（如 CoT）中常用的级联多个单步推理转变为因果增强方法，一次性输出整个推理过程，进一步提高模型的推理效率。大量实验表明，我们的方法提高了推理成功率和速度。这些改进进一步证明了非链式方法也可以帮助 LLM 完成推理任务。]]></description>
      <guid>https://arxiv.org/abs/2409.17174</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从网络上全自动提取形态特征：乌托邦还是现实？</title>
      <link>https://arxiv.org/abs/2409.17179</link>
      <description><![CDATA[arXiv:2409.17179v1 公告类型：新
摘要：植物形态特征，即其可观察的特征，对于了解每个物种在其生态系统中所扮演的角色至关重要。然而，即使是为中等数量的物种汇编特征信息也是一项艰巨的任务，可能需要专家花费数年时间才能完成。与此同时，大量有关物种描述的信息以文本形式在线提供，尽管缺乏结构使得这种数据源无法大规模使用。为了克服这个问题，我们建议利用大型语言模型 (LLM) 的最新进展，并设计一种机制，以非结构化文本描述的形式收集和处理有关植物特征的信息，而无需人工管理。我们通过自动复制三个手动创建的物种-性状矩阵来评估我们的方法。我们的方法设法找到了超过一半的物种-性状对的值，F1 分数超过 75%。我们的结果表明，由于 LLM 的信息提取能力，目前可以从非结构化在线文本中大规模创建结构化特征数据库，但受限于涵盖所有感兴趣特征的文本描述的可用性。]]></description>
      <guid>https://arxiv.org/abs/2409.17179</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种有效、稳健且公平的仇恨言论检测框架</title>
      <link>https://arxiv.org/abs/2409.17191</link>
      <description><![CDATA[arXiv:2409.17191v1 公告类型：新
摘要：随着在线社交网络的广泛传播，仇恨言论的传播速度比以往任何时候都快，造成的破坏也更大。现有的仇恨言论检测方法在多个方面存在局限性，例如处理数据不足、估计模型不确定性、提高对恶意攻击的鲁棒性以及处理非故意偏见（即公平性）。在线社交网络中迫切需要准确、稳健和公平的仇恨言论分类。为了弥补这一差距，我们设计了一个数据增强、公平性和不确定性估计的新框架。作为框架的一部分，我们提出了双向四元数准 LSTM 层来平衡有效性和效率。为了建立一个通用模型，我们结合了从三个平台收集的五个数据集。实验结果表明，我们的模型在无攻击场景和各种攻击场景下都优于八种最先进的方法，表明了我们模型的有效性和鲁棒性。我们分享我们的代码以及组合数据集，以便将来更好地进行研究]]></description>
      <guid>https://arxiv.org/abs/2409.17191</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多元体系：通过模拟社交团体指导法学硕士的系统</title>
      <link>https://arxiv.org/abs/2409.17213</link>
      <description><![CDATA[arXiv:2409.17213v1 公告类型：新
摘要：最近的辩论引发了人们对语言模型可能偏向某些观点的担忧。但是，如果解决方案不是追求“无处不在的观点”，而是利用不同的观点，该怎么办？我们引入了 Plurals，这是一个用于多元化 AI 审议的系统和 Python 库。Plurals 由代理（LLM，可选角色）组成，它们在可定制的结构中进行审议，由主持人监督审议。Plurals 是模拟社交集合的生成器。Plurals 与政府数据集集成以创建具有全国代表性的角色，包括受民主审议理论启发的审议模板，并允许用户在结构中自定义信息共享结构和审议行为。六个案例研究证明了对理论构造和功效的忠诚度。三个随机实验表明，模拟焦点小组产生的输出与相关受众的在线样本产生共鸣（75% 的试验中选择了零样本生成）。 Plurals 既是多元 AI 的范式，也是具体的系统。Plurals 库可在 https://github.com/josh-ashkinaze/plurals 上找到，并将持续更新。]]></description>
      <guid>https://arxiv.org/abs/2409.17213</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BabyLlama-2：集成提炼模型在数据有限的情况下始终优于教师模型</title>
      <link>https://arxiv.org/abs/2409.17312</link>
      <description><![CDATA[arXiv:2409.17312v1 公告类型：新
摘要：我们为 BabyLM 竞赛展示了 BabyLlama-2，这是一个 3.45 亿参数模型，由两位老师在 1000 万字语料库上进行预训练。在 BLiMP 和 SuperGLUE 基准测试中，BabyLlama-2 的表现优于在具有相同数据组合的 1000 万和 1 亿字数据集上训练的基线，以及其老师模型。通过广泛的超参数扫描，我们证明了蒸馏的优势不能归因于老师的次优超参数选择。我们的研究结果强调需要进一步研究蒸馏技术，特别是在数据有限的环境中。]]></description>
      <guid>https://arxiv.org/abs/2409.17312</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>音译如何改善跨语言对齐</title>
      <link>https://arxiv.org/abs/2409.17326</link>
      <description><![CDATA[arXiv:2409.17326v1 公告类型：新
摘要：最近的研究表明，使用对齐目标对原始数据和音译数据进行后对齐的多语言预训练语言模型 (mPLM) 可以改善跨语言对齐。这种改进进一步带来了更好的跨语言传输性能。然而，目前仍不清楚如何以及为何实现更好的跨语言对齐，因为这种技术只涉及音译，而不使用任何并行数据。本文试图明确评估跨语言对齐，并确定基于音译的方法中有助于提高性能的关键要素。为此，我们在不同的设置下为两对相关语言训练了多个模型：(1) 波兰语和乌克兰语和 (2) 印地语和乌尔都语。为了评估对齐，我们根据句子表示定义了四种类型的相似性。我们的实验表明，仅添加音译就可以提高整体相似性，即使是随机句子对也是如此。在辅助对齐目标（尤其是对比目标）的帮助下，模型学会区分匹配对和随机对，从而实现更好的对齐。然而，我们也表明，更好的对齐并不总是产生更好的下游性能，这表明需要进一步研究来阐明对齐和性能之间的联系。]]></description>
      <guid>https://arxiv.org/abs/2409.17326</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用隐式思维链实现 ASR 内化，实现高效的语音对语音对话式 LLM</title>
      <link>https://arxiv.org/abs/2409.17353</link>
      <description><![CDATA[arXiv:2409.17353v1 公告类型：新
摘要：当前基于语音的 LLM 主要在大量 ASR 和 TTS 数据集上进行训练，在与这些领域相关的任务中表现出色。然而，它们处理直接语音对语音对话的能力仍然受到明显限制。这些模型通常依赖于 ASR 到 TTS 的思路链管道，将语音转换为文本进行处理，然后再生成音频响应，这会带来延迟并丢失音频特征。我们提出了一种方法，将 ASR 思路链隐式地内化到语音 LLM 中，增强其原生语音理解能力。我们的方法减少了延迟并提高了模型对语音的原生理解，为更高效、更自然的实时音频交互铺平了道路。我们还发布了一个大规模合成对话数据集，以促进进一步的研究。]]></description>
      <guid>https://arxiv.org/abs/2409.17353</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>data2lang2vec：数据驱动的类型学特征补全</title>
      <link>https://arxiv.org/abs/2409.17373</link>
      <description><![CDATA[arXiv:2409.17373v1 公告类型：新
摘要：语言类型数据库通过提高模型对不同语言结构的适应性来增强多语言自然语言处理 (NLP)。广泛使用的 lang2vec 工具包集成了几个这样的数据库，但其覆盖率仍然有限，为 28.9%。以前关于自动增加覆盖率的工作是根据其他语言的特征预测缺失值或专注于单一特征，我们建议使用文本数据进行更明智的特征预测。为此，我们引入了一个多语言词性 (POS) 标记器，在 1,749 种语言中实现了超过 70% 的准确率，并尝试了外部统计特征和各种机器学习算法。我们还引入了一个更现实的评估设置，重点关注可能缺失的类型特征，并表明我们的方法在两种设置中都优于以前的工作。]]></description>
      <guid>https://arxiv.org/abs/2409.17373</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的数字系统缩放行为：以 Pythia 为例</title>
      <link>https://arxiv.org/abs/2409.17391</link>
      <description><![CDATA[arXiv:2409.17391v1 Announce Type: new 
摘要：虽然大型语言模型（LLM）在数学推理方面表现出了非凡的能力，但它们在准确执行数字运算（例如加法和乘法）方面仍然举步维艰。不同的LLM可以通过各种方式将数字标记为token，并影响数字运算性能。目前有两种代表：1）标记为1位数字，2）标记为1\sim 3位数字。两者的区别大致相当于使用不同的数字系统（即10进制或10^{3}$进制）。鉴于此，我们研究了基于Transformer的大型语言模型中不同数字系统的缩放行为。我们通过实证研究证明，在从头开始训练的设置下，十进制系统在训练数据规模、模型大小方面始终比十进制或十进制系统更高效，而不同的数字系统在微调性能方面非常相似。我们将其归因于十进制系统的更高标记频率。此外，我们揭示了加法和乘法的外推行为模式。我们发现，百进制和千进制系统在标记级辨别和标记级操作方面存在困难。我们还阐明了模型所学习的机制。]]></description>
      <guid>https://arxiv.org/abs/2409.17391</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>心理健康严重程度预测：基于法学硕士的新型多语言数据集的创建、分析和评估</title>
      <link>https://arxiv.org/abs/2409.17397</link>
      <description><![CDATA[arXiv:2409.17397v1 公告类型：新
摘要：大型语言模型 (LLM) 越来越多地融入到各种医疗领域，包括心理健康支持系统。然而，在非英语心理健康支持应用中，LLM 的有效性研究存在差距。为了解决这个问题，我们提出了一种新颖的多语言改编版，将广泛使用的心理健康数据集从英语翻译成六种语言（希腊语、土耳其语、法语、葡萄牙语、德语和芬兰语）。该数据集可以全面评估 LLM 在检测心理健康状况和评估其严重程度方面的表现，涵盖多种语言。通过对 GPT 和 Llama 进行实验，我们观察到尽管在同一个翻译数据集上进行评估，但不同语言的性能存在相当大的差异。这种不一致性凸显了多语言心理健康支持固有的复杂性，其中特定于语言的细微差别和心理健康数据覆盖范围会影响模型的准确性。通过全面的错误分析，我们强调了在医疗环境中完全依赖大型语言模型 (LLM) 的风险（例如，它们可能导致误诊）。此外，我们提出的方法为多语言任务节省了大量成本，为大规模实施带来了巨大优势。]]></description>
      <guid>https://arxiv.org/abs/2409.17397</guid>
      <pubDate>Fri, 27 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>