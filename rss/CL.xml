<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 22 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 Transformers 根据医学图像生成临床情境感知放射学报告</title>
      <link>https://arxiv.org/abs/2408.11344</link>
      <description><![CDATA[arXiv:2408.11344v1 公告类型：新
摘要：自然语言处理领域的最新发展，尤其是诸如 transformer 之类的语言模型，为语言理解和语言生成带来了最先进的成果。在这项工作中，我们研究了 transformer 模型在胸部 X 光片放射学报告生成中的应用。我们还强调了仅使用标准语言生成指标评估放射学报告生成的局限性。然后，我们应用了基于 transformer 的放射学报告生成架构，并将基于 transformer 的解码器的性能与基于递归的解码器进行了比较。使用 IU-CXR 数据集进行了实验，结果显示其优于 LSTM 对应模型，并且速度明显更快。最后，我们确定了使用语言生成指标和分类指标来评估放射学报告生成系统的必要性，这有助于在连贯性和诊断价值方面提供对生成报告的稳健衡量。]]></description>
      <guid>https://arxiv.org/abs/2408.11344</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:51 GMT</pubDate>
    </item>
    <item>
      <title>GeoReasoner：基于地理空间背景进行自然语言理解推理</title>
      <link>https://arxiv.org/abs/2408.11366</link>
      <description><![CDATA[arXiv:2408.11366v1 公告类型：新
摘要：在人类阅读和交流中，个人倾向于进行地理空间推理，这涉及识别地理实体并对其相互关系做出明智的推断。为了模仿这种认知过程，当前的方法要么使用传统的自然语言理解工具包，要么直接应用在与地理相关的自然语言语料库上预先训练的模型。然而，这些方法面临两个重大挑战：i) 它们不能很好地推广到看不见的地理空间场景，ii) 它们忽视了将地理数据库中的地理空间上下文与互联网上的语言信息相结合的重要性。为了应对这些挑战，我们提出了 GeoReasoner，这是一种能够推理基于地理空间的自然语言的语言模型。具体来说，它首先利用大型语言模型 (LLM) 根据语言和地理空间信息生成全面的位置描述。它还通过将方向和距离信息视为伪句子来编码到空间嵌入中。因此，该模型在锚点级别和邻居级别的输入上进行训练，以学习地理实体表示。与最先进的基线相比，大量实验结果表明 GeoReasoner 在三个任务中表现出色：地名识别、地名链接和地理实体类型。]]></description>
      <guid>https://arxiv.org/abs/2408.11366</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:51 GMT</pubDate>
    </item>
    <item>
      <title>RAGLAB：一个模块化、面向研究的检索增强生成统一框架</title>
      <link>https://arxiv.org/abs/2408.11381</link>
      <description><![CDATA[arXiv:2408.11381v1 公告类型：新
摘要：大型语言模型 (LLM) 展示了人类水平的对话、推理和知识保留能力。然而，即使是最先进的 LLM 也面临着幻觉和知识实时更新等挑战。当前的研究通过为 LLM 配备外部知识来解决这一瓶颈，这种技术称为检索增强生成 (RAG)。然而，两个关键问题制约了 RAG 的发展。首先，新型 RAG 算法之间越来越缺乏全面和公平的比较。其次，LlamaIndex 和 LangChain 等开源工具采用高级抽象，导致缺乏透明度并限制了开发新算法和评估指标的能力。为了弥补这一差距，我们引入了 RAGLAB，这是一个模块化且面向研究的开源库。RAGLAB 重现了 6 种现有算法，并为研究 RAG 算法提供了一个全面的生态系统。利用 RAGLAB，我们在 10 个基准中对 6 种 RAG 算法进行了公平比较。借助 RAGLAB，研究人员可以高效地比较各种算法的性能并开发新算法。]]></description>
      <guid>https://arxiv.org/abs/2408.11381</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:51 GMT</pubDate>
    </item>
    <item>
      <title>RedWhale：通过高效的持续预训练改编的韩国法学硕士课程</title>
      <link>https://arxiv.org/abs/2408.11294</link>
      <description><![CDATA[arXiv:2408.11294v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的发展，自然语言处理 (NLP) 领域取得了重大进步。然而，这些研究的大部分仍然集中在英语上，往往忽略了韩语等资源匮乏的语言。由于韩语独特的非字母标记结构以及 LLM 训练所需的大量内存和计算需求，这种疏忽带来了挑战，这经常导致内存限制和内存不足错误。为了解决这些问题，我们提出了专门针对韩语处理的模型 RedWhale。RedWhale 采用高效的持续预训练方法开发，包括全面的韩语语料库预处理管道、专门的标记器、优化的模型初始化技术和多阶段预训练策略。这些创新共同减少了训练时间和计算成本，同时保持了高水平的准确性和理解力。 RedWhale 利用跨语言迁移学习（利用不同语言之间的共同语言相似性）以英语模型为基础来增强韩语处理能力。实验结果表明，RedWhale 在韩语 NLP 基准测试中的表现优于其他领先模型，包括韩语重要任务平衡评估 (KoBEST)，显示出对韩语文本的出色理解和生成能力。此外，RedWhale 即使在对 97 亿个标记进行预训练后也没有出现收敛迹象，这表明通过额外训练还有进一步改进的潜力。这项工作代表了弥合语言鸿沟的重大进步，特别是在增强韩语 NLP 能力方面。]]></description>
      <guid>https://arxiv.org/abs/2408.11294</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:50 GMT</pubDate>
    </item>
    <item>
      <title>评估大型语言模型对讽刺的理解</title>
      <link>https://arxiv.org/abs/2408.11319</link>
      <description><![CDATA[arXiv:2408.11319v1 公告类型：新
摘要：在大型语言模型 (LLM) 时代，人们认为“系统 I”的任务——快速、无意识和直观的任务，例如情绪分析、文本分类等，已经得到成功解决。然而，讽刺作为一种微妙的语言现象，经常使用夸张和比喻等修辞手法来传达真实的情绪和意图，涉及比情绪分析更高的抽象层次。人们越来越担心，当考虑讽刺理解时，关于 LLM 成功的论点可能并不完全站得住脚。为了解决这个问题，我们选择了 11 个 SOTA LLM 和 8 个 SOTA 预训练语言模型 (PLM)，并通过不同的提示方法（即零样本输入/输出 (IO) 提示、少样本 IO 提示、思路链 (CoT) 提示）对六个广泛使用的基准数据集进行了全面的评估。我们的结果强调了三个关键发现：（1）当前的 LLM 在六个讽刺基准上的表现不如基于监督 PLM 的讽刺检测基线。这表明仍需付出巨大努力来提高 LLM 对人类讽刺的理解。（2）GPT-4 在各种提示方法中始终显着优于其他 LLM，平均提高了 14.0\%$\uparrow$。Claude 3 和 ChatGPT 的表现仅次于 GPT-4。（3）少样本 IO 提示方法优于其他两种方法：零样本 IO 和少样本 CoT。原因在于，讽刺检测是一种整体的、直观的、非理性的认知过程，被认为不遵循逐步的逻辑推理，这使得 CoT 在理解讽刺方面的有效性不如其在数学推理任务中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.11319</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:50 GMT</pubDate>
    </item>
    <item>
      <title>即插即用和融合：通过跨不同词汇的词级重新排序进行零样本联合解码</title>
      <link>https://arxiv.org/abs/2408.11327</link>
      <description><![CDATA[arXiv:2408.11327v1 公告类型：新
摘要：NLP 的最新进展产生了具有专门优势的模型，例如处理多模态输入或在特定领域表现出色。然而，现实世界的任务，如多模态翻译，通常需要这些优势的组合，例如处理翻译和图像处理。虽然单个翻译和视觉模型功能强大，但它们通常缺乏在单个系统中执行这两项任务的能力。组合这些模型带来了挑战，特别是由于它们的词汇量不同，这限制了传统集成方法的有效性，例如 N 最佳列表重新排名等后生成技术。在这项工作中，我们提出了一种新颖的零样本集成策略，允许在解码阶段集成不同的模型，而无需额外的训练。我们的方法通过组合单词级别的分数在解码过程中对波束进行重新排序，使用启发式方法来预测单词何时完成。我们在机器翻译场景中证明了该方法的有效性，表明它能够生成同时具有语音和图像感知的翻译，同时还能提高整体翻译质量\footnote{我们将在论文被接受后发布代码。}。]]></description>
      <guid>https://arxiv.org/abs/2408.11327</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:50 GMT</pubDate>
    </item>
    <item>
      <title>BURExtract-Llama：乳腺超声报告中临床概念提取的法学硕士学位</title>
      <link>https://arxiv.org/abs/2408.11334</link>
      <description><![CDATA[arXiv:2408.11334v1 公告类型：新
摘要：乳房超声对于检测和诊断异常至关重要，放射学报告总结了病变特征和恶性肿瘤评估等关键发现。由于这些报告的非结构化性质，语言风格各异且格式不一致，提取这些关键信息具有挑战性。虽然像 GPT-4 这样的专有 LLM 很有效，但它们成本高昂，并且在处理受保护的健康信息时会引起隐私问题。本研究提出了一种开发内部 LLM 的流程，以从放射学报告中提取临床信息。我们首先使用 GPT-4 创建一个小型标记数据集，然后在其上微调 Llama3-8B 模型。根据临床医生注释的报告进行评估，我们的模型获得了 84.6% 的平均 F1 分数，与 GPT-4 相当。我们的研究结果证明了开发内部 LLM 的可行性，它不仅可以匹配 GPT-4 的性能，还可以降低成本并增强数据隐私。]]></description>
      <guid>https://arxiv.org/abs/2408.11334</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:50 GMT</pubDate>
    </item>
    <item>
      <title>有意识地阅读</title>
      <link>https://arxiv.org/abs/2408.11189</link>
      <description><![CDATA[arXiv:2408.11189v1 公告类型：新
摘要：检索增强生成 (RAG) 系统通过集成外部信息源（如维基百科、内部文档、科学论文或开放互联网）来增强知识语言模型的功能。依赖开放互联网作为知识来源的 RAG 系统必须应对人类生成内容的复杂性。人类交流远不止以文本形式呈现的单词。意图、音调和内涵都可以改变所传达内容的含义。RAG 系统最近在现实世界中的部署显示出在理解人类交流的这些细微差别方面存在一些困难。这些系统面临的一个重大挑战在于处理讽刺。虽然构成这些 RAG 系统骨干的大型语言模型 (LLM) 能够检测讽刺，但它们目前并不总是使用这些检测来进行后续的文本处理。为了解决这些问题，在本文中，我们从 Natural Question 的维基百科检索语料库中合成生成讽刺段落。然后，我们测试这些段落对 RAG 管道的检索器和阅读器部分性能的影响。我们引入了一个提示系统，旨在增强模型在存在讽刺的情况下解释和生成响应的能力，从而提高整体系统性能。最后，我们进行消融研究以验证我们方法的有效性，展示了 RAG 系统在处理讽刺内容方面的改进。]]></description>
      <guid>https://arxiv.org/abs/2408.11189</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:49 GMT</pubDate>
    </item>
    <item>
      <title>CoDi：基于对话提炼的问答系统</title>
      <link>https://arxiv.org/abs/2408.11219</link>
      <description><![CDATA[arXiv:2408.11219v1 公告类型：新
摘要：将对话技能提炼到具有大约 10 亿个参数的小型语言模型 (SLM) 中面临着重大挑战。首先，与较大的模型相比，SLM 的模型参数在学习广泛知识方面的能力有限。其次，高质量的对话数据集通常稀缺、规模小且特定于领域。为了应对这些挑战，我们引入了一种名为 CoDi（Conversational Distillation 的缩写，发音为“Cody”）的新型数据提炼框架，使我们能够以可操纵和多样化的方式合成大规模助手式数据集。具体而言，虽然我们的框架本质上与任务无关，但我们探索并评估了 CoDi 在基于对话的问答推理任务上的潜力。这是专业 SLM 的典型设备场景，允许开放域模型响应，而无需模型在其有限的权重中“记住”世界知识。我们的评估表明，使用 CoDi 合成数据训练的 SLM 在标准指标上的表现可与使用人工注释数据训练的模型相媲美。此外，当使用我们的框架从网络数据生成更大的数据集时，我们的模型在零样本对话式推理任务中超越了更大的指令调整模型。]]></description>
      <guid>https://arxiv.org/abs/2408.11219</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:49 GMT</pubDate>
    </item>
    <item>
      <title>揭开职业偏见的面纱：利用美国劳工数据消除法学硕士的偏见</title>
      <link>https://arxiv.org/abs/2408.11247</link>
      <description><![CDATA[arXiv:2408.11247v1 公告类型：新
摘要：大型语言模型 (LLM) 容易继承和放大其训练数据中嵌入的社会偏见，可能会强化与性别、职业和其他敏感类别相关的有害刻板印象。这个问题变得特别成问题，因为有偏见的 LLM 可能会产生深远的影响，导致不公平的做法并加剧各个领域的社会不平等，例如招聘、在线内容审核甚至刑事司法系统。虽然先前的研究重点是使用专门设计的数据集来检测 LLM 中的偏见，以突出内在偏见，但对这些发现如何与权威数据集（例如美国国家劳工统计局 (NBLS) 的数据集）相关联的调查明显不足。为了解决这一差距，我们进行了实证研究，在“开箱即用”的环境中评估 LLM，分析生成的输出与 NBLS 数据中的分布相比如何。此外，我们提出了一种直接但有效的去偏机制，该机制直接结合 NBLS 实例来减轻 LLM 中的偏见。我们的研究涵盖了七种不同的 LLM，包括可指导、基础和混合专家模型，并揭示了现有偏见检测技术经常忽视的严重偏见水平。重要的是，我们的去偏方法不依赖于外部数据集，显示出偏见分数的大幅降低，凸显了我们的方法在创建更公平、更可靠的 LLM 方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.11247</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:49 GMT</pubDate>
    </item>
    <item>
      <title>反事实作为评估自回归语言模型中归因方法忠实度的手段</title>
      <link>https://arxiv.org/abs/2408.11252</link>
      <description><![CDATA[arXiv:2408.11252v1 公告类型：新
摘要：尽管自回归语言模型被广泛采用，但可解释性评估研究主要集中在跨度填充和掩码语言模型 (MLM) 上。评估解释方法的忠实度（即该方法解释模型内部工作和决策的准确程度）非常具有挑战性，因为很难将模型与其解释分开。大多数忠实度评估技术会破坏或删除根据特定归因（特征重要性）方法被认为重要的一些输入标记，并观察模型输出的变化。由于因果语言模型 (CLM) 的训练目标是下一个标记预测，因此这种方法会为其创建分布外的输入。在这项研究中，我们提出了一种利用反事实生成的技术来评估自回归语言建模场景的归因方法的忠实度。我们的技术创建了流畅且分布内的反事实，使评估协议更加可靠。代码可在 https://github.com/Sepehr-Kamahi/faith 获得]]></description>
      <guid>https://arxiv.org/abs/2408.11252</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:49 GMT</pubDate>
    </item>
    <item>
      <title>StructuredRAG：使用大型语言模型进行 JSON 响应格式化</title>
      <link>https://arxiv.org/abs/2408.11061</link>
      <description><![CDATA[arXiv:2408.11061v1 公告类型：新
摘要：大型语言模型 (LLM) 生成结构化输出（例如 JSON）的能力对于其在复合 AI 系统中的使用至关重要。然而，评估和改进这种能力仍然具有挑战性。在这项工作中，我们引入了 StructuredRAG，这是一项包含六个任务的基准测试，旨在评估 LLM 遵循响应格式指令的能力。我们使用两种不同的提示策略评估了两种最先进的 LLM，Gemini 1.5 Pro 和 Llama 3 8B-instruct，并采用 4 位量化。我们将这些提示策略引入为 f-String 和遵循格式 (FF) 提示。在 24 次实验中，我们发现平均成功率为 82.55%。我们进一步发现，在任务、模型和提示策略之间，性能差异很大，成功率从 0 到 100% 不等。我们发现 Llama 3 8B-instruct 的表现通常与 Gemini 1.5 Pro 相当。我们观察到任务复杂性显著影响性能，涉及列表或复合对象输出的任务更具挑战性。我们的研究结果强调需要进一步研究如何提高 LLM 中结构化输出生成的可靠性和一致性。我们已在 github.com/weaviate/structured-rag 上开源了我们的实验代码和结果。]]></description>
      <guid>https://arxiv.org/abs/2408.11061</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:48 GMT</pubDate>
    </item>
    <item>
      <title>Interactive-T2S：使用大型语言模型进行文本到 SQL 的多轮交互</title>
      <link>https://arxiv.org/abs/2408.11062</link>
      <description><![CDATA[arXiv:2408.11062v1 公告类型：新
摘要：本研究通过利用大型语言模型 (LLM) 的强大推理能力探索文本到 SQL 的解析。尽管最近取得了进展，但现有的基于 LLM 的方法尚未充分解决可扩展性问题，导致处理宽表时效率低下。此外，当前基于交互的方法要么缺乏逐步、可解释的 SQL 生成过程，要么无法提供高效且普遍适用的交互设计。为了应对这些挑战，我们引入了 Interactive-T2S，这是一个通过与数据库直接交互生成 SQL 查询的框架。该框架包括四个通用工具，可促进 LLM 主动高效地检索信息。此外，我们还开发了详细的示例来展示我们框架内的分步推理过程。我们在 BIRD-Dev 数据集上进行的实验采用了没有 oracle 知识的设置，结果表明我们的方法仅使用两个样例就取得了最先进的结果，强调了我们框架的有效性和稳健性。]]></description>
      <guid>https://arxiv.org/abs/2408.11062</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:48 GMT</pubDate>
    </item>
    <item>
      <title>通过提示法学硕士 (LLM) 进行表格迁移学习</title>
      <link>https://arxiv.org/abs/2408.11063</link>
      <description><![CDATA[arXiv:2408.11063v1 公告类型：新
摘要：使用有限数量的标记数据进行学习是机器学习实际应用中的一个核心问题，因为获取注释通常成本高昂。为了解决标记数据的稀缺性，迁移学习是一种传统方法；它建议通过从多个其他来源训练神经网络来学习可迁移的知识。在本文中，我们研究了表格任务的迁移学习，与其他领域（例如视觉和语言）相比，该任务在文献中的研究较少且成功率较低。这是因为表格本质上是异构的，即它们包含不同的列和特征空间，这使得迁移学习变得困难。另一方面，自然语言处理的最新进展表明，可以通过利用大型语言模型 (LLM) 的上下文学习能力来缓解标签稀缺问题。受此启发，再加上 LLM 也可以在统一语言空间内处理表格，我们想知道 LLM 是否适用于表格迁移学习，特别是在源数据集和目标数据集格式不同的场景下。作为肯定的回答，我们提出了一种新颖的表格迁移学习框架，称为 Prompt to Transfer (P2T)，该框架利用未标记（或异构）的源数据和 LLM。具体来说，P2T 识别源数据集中与目标任务特征强相关的列特征，以创建与目标任务相关的示例，从而为提示创建伪演示。实验结果表明，P2T 在各种表格学习基准上的表现均优于以前的方法，为重要但尚未得到充分探索的表格迁移学习问题带来了良好的前景。代码可在 https://github.com/jaehyun513/P2T 获得。]]></description>
      <guid>https://arxiv.org/abs/2408.11063</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:48 GMT</pubDate>
    </item>
    <item>
      <title>结合客观和主观视角理解政治新闻</title>
      <link>https://arxiv.org/abs/2408.11174</link>
      <description><![CDATA[arXiv:2408.11174v1 公告类型：新
摘要：对计算政治感兴趣的研究人员和从业者依靠自动内容分析工具来理解网络上大量的政治文本。此类工具应提供不同粒度级别的客观和主观方面，以使分析在实践中有用。现有方法对客观方面产生了有趣的见解，但对主观方面却有限，通常仅限于国家背景，并且可解释性有限。我们引入了一个文本分析框架，该框架整合了两种观点，并对主观方面进行了细粒度处理。信息检索技术和知识库补充了强大的自然语言处理组件，允许灵活地聚合不同粒度级别的结果。重要的是，所提出的自下而上的方法有助于解释所获得的结果。我们通过对新闻媒体、政治倾向、主题、个人实体和人口统计细分的见解来说明其功能。该方法在大量法国新闻语料库中得到实例化，但旨在无缝兼容其他语言和国家。]]></description>
      <guid>https://arxiv.org/abs/2408.11174</guid>
      <pubDate>Fri, 23 Aug 2024 03:15:48 GMT</pubDate>
    </item>
    </channel>
</rss>