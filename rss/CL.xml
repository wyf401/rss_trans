<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 30 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>探索网络虚假信息的文本表现形式</title>
      <link>https://arxiv.org/abs/2412.18618</link>
      <description><![CDATA[arXiv:2412.18618v1 公告类型：新
摘要：错误和虚假信息，通常统称为假新闻，继续危害社会。也许，这个古老问题的影响目前在政治和医疗保健方面最为明显。然而，假新闻正在影响越来越多的领域。它有多种不同的形式，并随着技术的进步而不断变化。尽管可以说它以文本形式传播得最广泛，例如通过社交媒体帖子和博客文章。因此，必须阻止文本错误信息的传播，这需要对其进行初步检测。本论文有助于创建可用于检测错误信息的表示。首先，它开发了一种从新闻文章中提取文本特征以检测错误信息的新方法。这些特征利用了真实新闻和虚假新闻故事的主题连贯性之间的差异。换句话说，随着故事的发展，两组讨论的主题的组成有很大不同。其次，它展示了使用分类和聚类来检测虚假新闻的主题特征的有效性。聚类特别有用，因为它减轻了对标记数据集的需求，而标记数据集的收集可能非常耗费人力和时间。更广泛地说，它有助于更​​好地理解错误信息以及使用机器学习和自然语言处理检测错误信息的方法。]]></description>
      <guid>https://arxiv.org/abs/2412.18618</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向多模态智能的下一个标记预测：全面调查</title>
      <link>https://arxiv.org/abs/2412.18619</link>
      <description><![CDATA[arXiv:2412.18619v1 公告类型：新
摘要：基于自然语言处理中的语言建模基础，下一个标记预测 (NTP) 已发展成为跨各种模态的机器学习任务的多功能训练目标，并取得了相当大的成功。随着大型语言模型 (LLM) 的发展，统一了文本模态中的理解和生成任务，最近的研究表明，不同模态的任务也可以有效地封装在 NTP 框架内，将多模态信息转换为标记并根据上下文预测下一个标记。本调查介绍了一种全面的分类法，通过 NTP 的视角统一了多模态学习中的理解和生成。提出的分类法涵盖五个关键方面：多模态标记化、MMNTP 模型架构、统一任务表示、数据集和评估以及开放挑战。这种新的分类法旨在帮助研究人员探索多模态智能。相关的 GitHub 存储库收集了最新的论文和代码库，网址为 https://github.com/LMM101/Awesome-Multimodal-Next-Token-Prediction]]></description>
      <guid>https://arxiv.org/abs/2412.18619</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>调查通过大型语言模型反学习减轻潜在版权侵权的可行性</title>
      <link>https://arxiv.org/abs/2412.18621</link>
      <description><![CDATA[arXiv:2412.18621v1 公告类型：新
摘要：预训练的大型语言模型 (LLM) 表现出了卓越的能力，但也通过学习和生成受版权保护的材料带来了风险，从而引发了重大的法律和道德问题。在潜在的现实场景中，模型所有者可能需要不断解决版权侵权问题，以解决在不同时间点出现的内容删除请求。解决这个问题的一种潜在方法是通过顺序取消学习，即随着新请求的出现，按顺序删除受版权保护的内容。尽管顺序取消学习具有实际意义，但现有文献尚未严格探索版权侵权背景下的顺序取消学习。为了解决这一差距，我们提出了稳定顺序取消学习 (SSU)，这是一个新颖的框架，旨在通过多个时间步骤从 LLM 中取消学习受版权保护的内容。我们的方法通过使用任务向量来识别和删除模型参数中与受版权保护的内容相对应的特定权重更新。我们通过引入随机标记损失来提高遗忘效率，并通过基于梯度的权重显着性调整目标参数来确保模型保留其通用知识。大量实验结果表明，SSU 有时可以在遗忘效率和通用语言能力之间实现有效平衡，优于现有基准，但它并不是遗忘版权材料的万能药。]]></description>
      <guid>https://arxiv.org/abs/2412.18621</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>为什么大型语言模型 (LLM) 难以计算字母数量？</title>
      <link>https://arxiv.org/abs/2412.18626</link>
      <description><![CDATA[arXiv:2412.18626v1 公告类型：新
摘要：大型语言模型 (LLM) 在许多复杂任务上取得了前所未有的表现，例如，能够回答几乎所有主题的问题。然而，它们在其他简单任务上却举步维艰，例如计算单词中字母的出现次数，正如许多 LLM 无法计算“strawberry”中“r”字母的数量所示。有几篇论文研究了这个问题，并将其与 LLM 使用的标记化、注意力机制的内在局限性或缺乏字符级训练数据联系起来。在本文中，我们进行了一项实验研究，以评估 LLM 在计数字母时的错误与 1) 训练数据集中单词及其成分的频率和 2) 计数操作的复杂性之间的关系。我们通过评估大量单词的代表性模型组，对 LLM 在计数字母出现次数时的错误进行了全面分析。结果显示，所评估的模型具有许多一致的趋势：1）模型能够识别字母但不能对字母进行计数；2）单词和单词中的标记的频率对 LLM 错误没有显著影响；3）字母频率与错误呈正相关，字母频率越高，计数错误就越多；4）错误与单词中的字母或标记的数量呈很强的相关性；5）最强的相关性与计数大于 1 的字母数量有关，大多数模型无法正确计算字母出现两次以上的单词。]]></description>
      <guid>https://arxiv.org/abs/2412.18626</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KRAIL：集成 IDHEAS 和大型语言模型的基于知识驱动的基础人为可靠性分析框架</title>
      <link>https://arxiv.org/abs/2412.18627</link>
      <description><![CDATA[arXiv:2412.18627v1 公告类型：新
摘要：人为可靠性分析 (HRA) 对于评估和提高复杂系统的安全性至关重要。最近的努力集中在估计人为错误概率 (HEP)，但现有方法往往严重依赖专家知识，这可能是主观的且耗时的。受大型语言模型 (LLM) 在自然语言处理中的成功的启发，本文介绍了一种新的知识驱动可靠性分析两阶段框架，集成了 IDHEAS 和 LLM (KRAIL)。这个创新框架可以半自动计算基本 HEP 值。此外，知识图被用作检索增强生成 (RAG) 的一种形式，以增强框架有效检索和处理相关数据的能力。在权威的人为可靠性数据集上系统地进行实验和评估。所提出方法的实验结果表明，它在部分信息下对可靠性评估的基本 HEP 估计具有优异的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.18627</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DynaGRAG：通过图形检索增强生成中的动态子图表示来提高语言理解和生成</title>
      <link>https://arxiv.org/abs/2412.18644</link>
      <description><![CDATA[arXiv:2412.18644v1 公告类型：新
摘要：图形检索增强生成 (GRAG 或 Graph RAG) 架构旨在通过利用外部知识来增强语言理解和生成。然而，有效地捕获和集成文本和结构化数据中存在的丰富语义信息仍然是一个挑战。为了解决这个问题，提出了一种新颖的 GRAG 框架，专注于增强知识图谱中的子图表示和多样性。通过提高图密度、更有效地捕获实体和关系信息以及动态优先考虑相关和多样化的子图，所提出的方法可以更全面地理解底层语义结构。这是通过重复数据删除过程、嵌入的两步均值池化、考虑唯一节点的查询感知检索和动态相似性感知 BFS (DSA-BFS) 遍历算法的组合实现的。通过硬提示将图卷积网络 (GCN) 和大型语言模型 (LLM) 集成在一起，进一步增强了对丰富节点和边缘表示的学习，同时保留了分层子图结构。在多个基准数据集上的实验结果证明了所提出的 GRAG 框架的有效性，展示了增强子图表示和多样性对于改善语言理解和生成的重要性。]]></description>
      <guid>https://arxiv.org/abs/2412.18644</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>简单是不够的：利用可读性和连贯性简化文档级文本</title>
      <link>https://arxiv.org/abs/2412.18655</link>
      <description><![CDATA[arXiv:2412.18655v1 公告类型：新
摘要：在本文中，我们介绍了 SimDoc 系统，这是一个考虑简单性、可读性和连贯性等话语方面的简化模型。在过去十年中，文本简化 (TS) 领域的进展主要体现在句子层面，而不是考虑段落或文档，大多数 TS 受众都会从这种设置中受益。我们提出了一个简化系统，该系统最初使用专业创建的语料库进行微调。此外，我们在训练过程中包括多个目标，同时考虑简单性、可读性和连贯性。我们的贡献包括通过将现有注释关联到（复杂文本、简单文本、可读性标签）三元组来扩展专业注释的简化语料库，从而从训练期间的可读性中受益。此外，我们还进行了比较分析，使用文档级 TS 语料库在零样本、少样本和微调设置中评估了我们提出的模型，展示了简化的新方法。最后，我们展示了输出的详细分析，强调了在文档级别简化的困难。]]></description>
      <guid>https://arxiv.org/abs/2412.18655</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从幻觉到事实：利用精选知识图谱增强语言模型</title>
      <link>https://arxiv.org/abs/2412.18672</link>
      <description><![CDATA[arXiv:2412.18672v1 公告类型：新
摘要：幻觉是困扰语言模型的一个长期挑战，它通过生成偏离事实准确性或连贯性的响应来破坏其在各种自然语言处理工作中的有效性和可信度。本文通过整合精选的知识图谱 (KG) 三元组来解决语言模型幻觉问题，以将响应锚定在经验数据中。我们精心选择和整合针对特定上下文的相关 KG 三元组，增强事实依据和与输入的一致性。我们的贡献包括从维基百科构建一个全面的 KG 存储库并细化数据以突出显示模型训练的基本信息。通过让语言模型能够访问这些精选的知识，我们旨在生成语言流畅的响应，并深深植根于事实准确性和上下文相关性。这种集成通过提供强大的信息基础来缓解幻觉，使模型能够在响应生成过程中利用丰富的事实数据。实验评估证明了多种方法在减少幻觉反应方面的有效性，强调了精选知识图谱在提高语言模型输出的可靠性和可信度方面的作用。]]></description>
      <guid>https://arxiv.org/abs/2412.18672</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AgreeMate：教授法学硕士讨价还价</title>
      <link>https://arxiv.org/abs/2412.18690</link>
      <description><![CDATA[arXiv:2412.18690v1 公告类型：新
摘要：我们引入了 AgreeMate，这是一个用于训练大型语言模型 (LLM) 的框架，通过自然语言进行战略价格谈判。我们将最近的进展应用于谈判环境，其中两个代理（即买方或卖方）使用自然语言通过粗略动作就商品进行讨价还价。具体来说，我们展示了大型语言模型在解耦（模块化）讨价还价架构中用作代理时的性能。我们证明，使用提示工程、微调和思路链提示可以提高模型性能，如新指标所定义。我们使用注意力探测来显示模型在谈判期间对标记之间语义关系的关注。]]></description>
      <guid>https://arxiv.org/abs/2412.18690</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CypherBench：面向 LLM 时代的全尺度现代知识图谱精准检索</title>
      <link>https://arxiv.org/abs/2412.18702</link>
      <description><![CDATA[arXiv:2412.18702v1 公告类型：新
摘要：从图形数据中检索对于使用开放域知识和私有企业数据增强大型语言模型 (LLM) 至关重要，它也是最近的 GraphRAG 系统 (edge et al., 2024) 中的关键组件。尽管对知识图谱和知识库问答进行了数十年的研究，但领先的 LLM 框架（例如 Langchain 和 LlamaIndex）对从 Wikidata 等现代百科全书知识图谱中检索的支持却微乎其微。在本文中，我们分析了根本原因，并提出现代 RDF 知识图谱（例如 Wikidata、Freebase）对于 LLM 效率较低，因为其模式过大，远远超出了典型的 LLM 上下文窗口、资源标识符的使用、重叠的关系类型和缺乏规范化。作为一种解决方案，我们在底层 RDF 图之上提出了属性图视图，LLM 可以使用 Cypher 有效地查询这些视图。我们在 Wikidata 上实现了这个想法，并推出了 CypherBench，这是第一个基准测试，包含 11 个大规模、多领域属性图，包含 780 万个实体和 10,000 多个问题。为了实现这一目标，我们解决了几个关键挑战，包括开发 RDF 到属性图的转换引擎、创建文本到 Cypher 任务生成的系统管道以及设计新的评估指标。]]></description>
      <guid>https://arxiv.org/abs/2412.18702</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有有意义变化的多重引用可改善文学机器翻译</title>
      <link>https://arxiv.org/abs/2412.18707</link>
      <description><![CDATA[arXiv:2412.18707v1 公告类型：新
摘要：虽然源语句可以用多种方式翻译，但大多数机器翻译 (MT) 模型仅使用单个参考进行训练。先前的研究表明，使用合成释义可以改善 MT。本文通过分析 Par3 数据集中世界文学不同英文翻译之间的语义相似性，研究了使用多个参考的最佳实践。我们将释义之间的语义相似性分为三组：低、中、高，并对两个不同的 LLM（mT5-large 和 LLaMA-2-7B）进行微调以用于下游 MT 任务。在不同的模型中，保持总训练实例不变，单参考但更多源文本仅略优于具有一半源文本的多参考。此外，使用中高语义相似度的释义比未过滤的数据集表现更好（+BLEU 0.3-0.5、+COMET 0.2-0.9、+chrF++ 0.25-0.32）。我们的代码在 GitHub 上公开可用。]]></description>
      <guid>https://arxiv.org/abs/2412.18707</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型自动评分学生的科学写作</title>
      <link>https://arxiv.org/abs/2412.18719</link>
      <description><![CDATA[arXiv:2412.18719v1 公告类型：新
摘要：对正式或非正式学习者进行大班写作评估是一项重大挑战。因此，大多数大班，尤其是科学课，都依赖于客观评估工具，例如只有一个正确答案的多项选择测验。人工智能的快速发展带来了使用大型语言模型 (LLM) 评估学生写作的可能性。使用 GPT-4 进行了一项实验，以确定基于 LLM 的机器学习方法在评估天文学主题的简短写作作业时是否可以达到或超过教师评分的可靠性。观众包括通过 Coursera 提供的三门大规模开放在线课程 (MOOC) 的成人学习者。一门课程是天文学，第二门是天体生物学，第三门是天文学的历史和哲学。结果也适用于大学环境中的非科学专业，因为评估的内容和模式相似。数据包括三门课程中 120 名学生对 12 个问题的回答。GPT-4 提供了三门课程的总成绩、示范答案和讲师给出的评分标准。除了评估 LLM 重现讲师评分的可靠性之外，LLM 还负责生成自己的评分标准。总体而言，无论是总体还是个别学生，LLM 都比同行评分更可靠，并且与所有三门在线课程的讲师评分大致相同。这意味着 LLM 可能很快就会用于对学生科学写作进行自动化、可靠和可扩展的评分。]]></description>
      <guid>https://arxiv.org/abs/2412.18719</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用增强型 LoRA 微调算法优化大型语言模型，提高 NLP 任务的效率和稳健性</title>
      <link>https://arxiv.org/abs/2412.18729</link>
      <description><![CDATA[arXiv:2412.18729v1 Announce Type: new 
摘要：本研究提出了一种基于改进的LoRA微调算法的大型语言模型优化方法，旨在提高模型在自然语言处理任务中的准确率和计算效率。我们通过低秩自适应策略对大型语言模型进行微调，在保持预训练模型强大能力的同时，显著降低了计算资源的消耗。实验以QQP任务为评测场景。结果表明，与BERT、Roberta、T5、GPT-4等传统模型相比，改进的LoRA算法在准确率、F1分数和MCC方面都有显著提升。特别是在F1分数和MCC方面，我们的模型表现出了更强的鲁棒性和判别能力，证明了改进的LoRA算法在微调大规模预训练模型方面的潜力。此外，本文还讨论了改进的LoRA算法在其他自然语言处理任务中的应用前景，强调其在多任务学习和计算资源有限的场景中的优势。未来的研究可以进一步优化LoRA微调策略，拓展其在更大规模预训练模型中的应用，以提高模型的泛化能力和任务适应性。]]></description>
      <guid>https://arxiv.org/abs/2412.18729</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于会话语音合成的模态内和模态间上下文交互建模</title>
      <link>https://arxiv.org/abs/2412.18733</link>
      <description><![CDATA[arXiv:2412.18733v1 公告类型：新
摘要：对话语音合成 (CSS) 旨在有效地利用多模态对话历史 (MDH) 为目标话语生成具有适当对话韵律的语音。CSS 的关键挑战是模拟 MDH 与目标话语之间的交互。请注意，MDH 中的文本和语音模态具有各自独特的影响，它们相互补充，对目标话语产生全面影响。以前的工作没有明确地模拟这种模态内和模态间相互作用。为了解决这个问题，我们提出了一种新的基于模态内和模态间上下文交互方案的 CSS 系统，称为 III-CSS。具体而言，在训练阶段，我们将 MDH 与目标话语中的文本和语音模态相结合，以获得四种模态组合，包括历史文本-下一个文本、历史语音-下一个语音、历史文本-下一个语音和历史语音-下一个文本。然后，我们设计了两个基于对比学习的模态内和模态间交互模块，以深入学习模态内和模态间上下文交互。在推理阶段，我们采用 MDH 并采用训练好的交互模块来充分推断目标话语文本内容的语音韵律。在 DailyTalk 数据集上的主观和客观实验表明，III-CSS 在韵律表现力方面优于先进的基线。代码和语音示例可在 https://github.com/AI-S2-Lab/I3CSS 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.18733</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过零样本生成改进生成和检索的知识组合</title>
      <link>https://arxiv.org/abs/2412.18800</link>
      <description><![CDATA[arXiv:2412.18800v1 公告类型：新
摘要：开放域问答 (QA) 结合了忠实检索的段落和通过大型语言模型 (LLM) 生成的相关段落的优势，引起了广泛关注。然而，缺乏可用于配对这些知识来源的明确标签。为了解决这个问题，我们提出了一个无监督的简单框架，称为用于合并生成和检索知识的双重排序 (BRMGR)，它对检索到的段落和 LLM 生成的段落都采用重排序方法。我们使用两种单独的重排序方法将这两种类型的段落配对，然后通过贪婪匹配将它们组合起来。我们证明，在为每个检索到的段落分配相应的 LLM 生成的段落时，BRMGR 相当于采用二分匹配损失。我们的模型的应用从三个数据集中获得了实验结果，在 NQ 和 WebQ 数据集上的性能分别提高了 +1.7 和 +1.6，并且在 TriviaQA 数据集上获得了与竞争基线相当的结果。]]></description>
      <guid>https://arxiv.org/abs/2412.18800</guid>
      <pubDate>Mon, 30 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>