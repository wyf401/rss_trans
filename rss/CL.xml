<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 15 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过大型语言模型实现章节间上下文感知文学翻译</title>
      <link>https://arxiv.org/abs/2407.08978</link>
      <description><![CDATA[arXiv:2407.08978v1 公告类型：新
摘要：现有文档级翻译数据集中的话语现象稀疏，这一直是上下文感知机器翻译模型开发的一个根本障碍。此外，大多数现有的文档级语料库和上下文感知机器翻译方法都依赖于对句子级对齐的不切实际的假设。为了缓解这些问题，我们首先整理了一个由 160 本具有复杂话语结构的书籍组成的中英文学新数据集。然后，我们提出了一种更实用、更具挑战性的上下文感知翻译设置，称为章节到章节 (Ch2Ch) 翻译，并研究了这种设置下常用机器翻译模型的性能。此外，我们介绍了一种在 Ch2Ch 文学翻译领域内微调大型语言模型 (LLM) 的潜在方法，与基线相比取得了令人瞩目的改进。通过全面分析，我们发现，在 Ch2Ch 环境下的文学翻译本质上具有挑战性，无论是对于模型学习方法还是翻译解码算法而言。]]></description>
      <guid>https://arxiv.org/abs/2407.08978</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:07 GMT</pubDate>
    </item>
    <item>
      <title>LLM 对文本扰动的鲁棒性</title>
      <link>https://arxiv.org/abs/2407.08989</link>
      <description><![CDATA[arXiv:2407.08989v1 公告类型：新
摘要：拥有干净的数据集一直是大多数自然语言处理 (NLP) 系统的基本假设。然而，在现实世界中很少能找到正确书写的文本，因此，上述基本假设常常是无效的。最近，大型语言模型 (LLM) 表现出了令人印象深刻的性能，但它们能处理现实世界数据中不可避免的噪音吗？这项工作通过研究 LLM 对文本形态变化的适应能力来解决这个关键问题。为此，我们人为地将不同程度的噪声引入一组不同的数据集中，并系统地评估 LLM 对原始文本损坏变化的鲁棒性。我们的研究结果表明，与普遍看法相反，生成式 LLM 对文本中的噪声扰动非常稳健。这与 BERT 或 RoBERTa 等预训练模型不同，这些模型的性能已被证明对恶化的噪声文本很敏感。此外，我们在多个真实基准上测试了 LLM 的弹性，这些基准与现实中常见的错误非常相似。在极少的提示下，LLM 在语法错误更正 (GEC) 和词汇语义变化 (LSC) 基准任务上取得了新的最高水平。为了支持未来的研究，我们还发布了一个由人类注释的数据集，说明了他们更喜欢 LLM 还是人工更正的输出，以及用于重现我们结果的代码。]]></description>
      <guid>https://arxiv.org/abs/2407.08989</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:07 GMT</pubDate>
    </item>
    <item>
      <title>通过迭代推理链实现领域层次自适应，实现少样本层次化文本分类</title>
      <link>https://arxiv.org/abs/2407.08959</link>
      <description><![CDATA[arXiv:2407.08959v1 公告类型：新
摘要：最近，各种预训练语言模型 (PLM) 已被提出来证明其在广泛的少样本任务中令人印象深刻的性能。然而，由于 PLM 中非结构化的先验知识有限，很难在复杂的结构化场景（例如分层文本分类 (HTC)）上保持一致的性能，尤其是在下游数据极其稀缺的情况下。主要挑战是如何将 PLM 中的非结构化语义空间转移到下游域层次结构。与之前关于 HTC 直接执行多标签分类或使用图神经网络 (GNN) 注入标签层次结构的工作不同，在本文中，我们研究了少样本设置下的 HTC 问题，以使 PLM 中的知识从非结构化方式适应下游层次结构。技术上，我们设计了一种简单而有效的方法，即分层迭代条件随机场 (HierICRF) 来搜索领域最具挑战性的方向，并精心设计了领域层次自适应作为分层迭代语言建模问题，然后它鼓励模型在推理过程中进行层次一致性自我校正，从而实现在保持层次一致性的情况下的知识迁移。我们在各种架构上执行了 HierICRF，并在两个流行的 HTC 数据集上进行了大量的实验，表明使用 HierICRF 提示可以显着提高少样本 HTC 性能，平均 Micro-F1 提高了 28.80% 至 1.50%，Macro-F1 提高了 36.29% 至 1.5%，高于之前在少样本设置下最先进的 (SOTA) 基线，同时保持 SOTA 层次一致性性能。]]></description>
      <guid>https://arxiv.org/abs/2407.08959</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:06 GMT</pubDate>
    </item>
    <item>
      <title>通过传统关系提取方法与大型语言模型的集成实现小样本关系提取</title>
      <link>https://arxiv.org/abs/2407.08967</link>
      <description><![CDATA[arXiv:2407.08967v1 公告类型：新
摘要：少样本关系提取 (FSRE) 是关系提取 (RE) 的一个子任务，它利用有限的训练实例，由于其能够在资源极其匮乏的情况下提取文本信息，因此吸引了更多自然语言处理 (NLP) 研究人员的关注。FSRE 采用的主要方法是基于预训练语言模型 (PLM) 的微调或快速调整技术。最近，大型语言模型 (LLM) 的出现促使众多研究人员通过上下文学习 (ICL) 探索 FSRE。然而，基于传统 RE 模型或 LLM 的方法存在很大的局限性。传统的 RE 模型因缺乏必要的先验知识而受到阻碍，而 LLM 在 RE 的任务特定能力方面存在不足。为了解决这些缺点，我们提出了一种双系统增强关系提取器 (DSARE)，它将传统 RE 模型与 LLM 协同结合。具体来说，DSARE 创新地将 LLM 的先验知识注入到传统的 RE 模型中，并通过关系提取增强功能反过来增强了 LLM 在 RE 中的任务特定能力。此外，还采用了集成预测模块来共同考虑这两个各自的预测并得出最终结果。大量实验证明了我们提出的方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.08967</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:06 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型作为生物医学假设生成器：全面评估</title>
      <link>https://arxiv.org/abs/2407.08940</link>
      <description><![CDATA[arXiv:2407.08940v1 公告类型：新
摘要：生物医学知识的快速增长已经超出了我们有效提取见解和产生新假设的能力。大型语言模型 (LLM) 已成为一种有前途的工具，可以彻底改变知识交互并可能加速生物医学发现。在本文中，我们对 LLM 作为生物医学假设生成器进行了全面的评估。我们从生物医学文献中构建了一个背景假设对数据集，根据出版日期仔细划分为训练、可见和不可见的测试集，以减轻数据污染。使用此数据集，我们评估了零样本、少量样本和微调设置中顶级指导模型的假设生成能力。为了加强对不确定性的探索，这是科学发现的一个关键方面，我们在评估框架中加入了工具使用和多智能体交互。此外，我们提出了四个基于广泛文献综述的新指标来评估生成的假设的质量，同时考虑了基于 LLM 的评估和人工评估。我们的实验得出了两个关键发现：1）LLM 可以生成新颖且经过验证的假设，即使在训练期间未见过的文献上进行测试也是如此；2）通过多智能体交互和工具使用增加不确定性可以促进多样化候选生成并提高零样本假设生成性能。然而，我们还观察到，通过少量学习和工具使用整合额外知识可能并不总能带来性能提升，这凸显了需要仔细考虑所纳入的外部知识的类型和范围。这些发现强调了 LLM 作为生物医学假设生成的强大辅助手段的潜力，并为指导该领域的进一步研究提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2407.08940</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:05 GMT</pubDate>
    </item>
    <item>
      <title>检测、调查、判断和确定：一种基于 LLM 的新型小样本假新闻检测框架</title>
      <link>https://arxiv.org/abs/2407.08952</link>
      <description><![CDATA[arXiv:2407.08952v1 公告类型：新 
摘要：少样本假新闻检测 (FS-FND) 旨在在资源极其匮乏的情况下区分不准确的新闻和真实新闻。由于假新闻在社交媒体上的广泛传播和有害影响，这项任务引起了越来越多的关注。大型语言模型 (LLM) 凭借其丰富的先验知识和出色的上下文学习能力表现出了竞争力。然而，现有方法面临着重大限制，例如理解歧义和信息稀缺性，这严重削弱了 LLM 的潜力。为了解决这些缺点，我们提出了一种双视角增强假新闻检测 (DAFND) 模型，旨在从内部和外部角度增强 LLM。具体来说，DAFND 首先通过检测模块识别每篇新闻文章的关键词。随后，DAFND 创造性地设计了一个调查模块来检索与当前新闻相关的内部和外部有价值的信息，然后是另一个判断模块来得出各自的两个预测结果。最后，一个判定模块进一步整合这两个预测并得出最终结果。在两个公开可用的数据集上进行的大量实验证明了我们提出的方法的有效性，特别是在资源匮乏的环境中。]]></description>
      <guid>https://arxiv.org/abs/2407.08952</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:05 GMT</pubDate>
    </item>
    <item>
      <title>描述长上下文推理的即时压缩方法</title>
      <link>https://arxiv.org/abs/2407.08892</link>
      <description><![CDATA[arXiv:2407.08892v1 公告类型：新
摘要：长上下文推理在系统层面上带来了挑战，因为它需要增加计算和内存，而且从准确性的角度来看，需要能够对长上下文进行推理。最近，已经提出了几种方法来压缩提示以减少上下文长度。然而，很少有人通过标准化分析来比较不同任务中提出的不同方法。这导致了相互矛盾的结果。为了解决这个问题，我们在这里对不同的提示压缩方法进行了全面的描述和评估。特别是，我们分析了提取压缩、基于摘要的抽象压缩和标记修剪方法。令人惊讶的是，我们发现提取压缩通常优于所有其他方法，并且能够以最小的准确性下降实现高达 10 倍的压缩。有趣的是，我们还发现，尽管最近有几项声明，但标记修剪方法往往落后于提取压缩。我们只发现总结任务的微小改进。]]></description>
      <guid>https://arxiv.org/abs/2407.08892</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:04 GMT</pubDate>
    </item>
    <item>
      <title>自我进化的 GPT：终身自主体验式学习者</title>
      <link>https://arxiv.org/abs/2407.08937</link>
      <description><![CDATA[arXiv:2407.08937v1 公告类型：新
摘要：为了提高大型语言模型（LLM）的性能，研究人员探索了通过提示为LLM提供文本任务解决经验。然而，他们依靠人工努力来获取和应用每个任务的这种经验，这对于日益增长的LLM需求和用户问题的多样性来说是不可行的。为了解决这个问题，我们设计了一个基于LLM的终身自主体验学习框架，探索LLM是否可以模仿人类学习和利用经验的能力。它通过经验传递和归纳自主学习和积累经验，对输入问题的类型进行分类以选择为它们使用哪些积累的经验。在六个广泛使用的NLP数据集上的实验结果表明，我们的框架在每个中间步骤中表现可靠，并有效提高了GPT-3.5和GPT-4的性能。这验证了使用LLM模仿人类体验式学习和应用能力的可行性。此外，我们还对框架在每个步骤中的行为进行了详细的分析。]]></description>
      <guid>https://arxiv.org/abs/2407.08937</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:04 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformer 的语言模型的微调数据集的自动修剪</title>
      <link>https://arxiv.org/abs/2407.08887</link>
      <description><![CDATA[arXiv:2407.08887v1 公告类型：新 
摘要：基于 Transformer 的语言模型在各种自然语言理解任务中都表现出了最佳性能。为了实现这种性能，这些模型首先在一般语料库上进行预训练，然后在下游任务上进行微调。先前的研究研究了修剪下游任务的训练集对模型在其评估集上的性能的影响。在这项工作中，我们提出了一种用于微调任务训练集的自动数据集修剪方法。我们的方法基于模型正确分类每个训练数据点的成功率。与以前依赖用户反馈来确定子集大小的工作不同，我们的方法会自动提取适合每对模型和微调任务的训练子集。我们的方法提供了多个用于数据集修剪的子集，以在子集大小和评估准确性之间进行权衡。我们最大的子集（也称为中奖彩票子集）平均比微调任务的原始训练集小 3 倍。我们在 5 个下游任务和 2 个语言模型上进行的实验表明，平均而言，对中奖彩票子集进行微调可使模型的评估性能提高 0.1% 左右。]]></description>
      <guid>https://arxiv.org/abs/2407.08887</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:03 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的电网故障诊断</title>
      <link>https://arxiv.org/abs/2407.08836</link>
      <description><![CDATA[arXiv:2407.08836v1 公告类型：新
摘要：电网故障诊断是确保电力基础设施可靠性和稳定性的关键任务。传统的诊断系统经常难以应对电网数据的复杂性和多变性。本文提出了一种新方法，利用大型语言模型 (LLM)，特别是 ChatGPT 和 GPT-4，结合先进的提示工程来提高故障诊断的准确性和可解释性。我们设计了全面的、上下文感知的提示来指导 LLM 解释复杂数据并提供详细的可操作见解。我们的方法根据基线技术进行了评估，包括标准提示、思维链 (CoT) 和思维树 (ToT) 方法，使用新构建的数据集，包括实时传感器数据、历史故障记录和组件描述。实验结果表明，诊断准确性、可解释性质量、响应连贯性和上下文理解均有显着提高，凸显了我们方法的有效性。这些发现表明，即时设计的 LLM 为稳健、可靠的电网故障诊断提供了一种有希望的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2407.08836</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:02 GMT</pubDate>
    </item>
    <item>
      <title>评估大型语言模型自由回答答案中的细微偏差</title>
      <link>https://arxiv.org/abs/2407.08842</link>
      <description><![CDATA[arXiv:2407.08842v1 公告类型：新
摘要：现在可以使用自定义提示或微调轻松地将预训练的大型语言模型 (LLM) 调整为特定业务目的。这些定制通常会反复重新设计以改善某些方面的性能，但每次更改之后，企业都希望确保不会对系统在偏见等关键问题上的行为产生负面影响。先前的基准偏差方法使用诸如单词掩蔽和多项选择题之类的技术来大规模评估偏见，但这些方法并不能捕捉到自由回答答案中可能出现的所有细微偏见类型，而自由回答答案通常由 LLM 系统生成。在本文中，我们确定了自由文本中几种无法通过多项选择测试类似识别的细微偏见。我们将它们描述为：信心偏见、隐含偏见、包含偏见和擦除偏见。我们提出了一种半自动化流程来检测这些类型的偏见，首先消除可以自动归类为无偏见的答案，然后使用众包工作者共同评估姓名反转对。我们相信，我们的方法生成的细微分类可用于为 LLM 提供更好的反馈，尤其是当 LLM 推理能力变得更加先进时。]]></description>
      <guid>https://arxiv.org/abs/2407.08842</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:02 GMT</pubDate>
    </item>
    <item>
      <title>基于规则、神经和 LLM 回译：从拉丁语变体中获取的比较见解</title>
      <link>https://arxiv.org/abs/2407.08819</link>
      <description><![CDATA[arXiv:2407.08819v1 公告类型：新
摘要：本文探讨了不同的反向翻译方法对拉丹语机器翻译的影响，特别是 Val Badia 变体。鉴于这种语言可用的并行数据量有限（只有 18k 个拉丹语-意大利语句子对），我们研究了针对拉丹语-意大利语微调的多语言神经机器翻译模型的性能。除了可用的真实数据外，我们还使用三个不同的模型来合成进一步的翻译：微调神经模型、专门为这种语言对开发的基于规则的系统和大型语言模型。我们的实验表明，在这种资源匮乏的情况下，所有方法都能实现相当的翻译质量，但往返翻译凸显了模型性能的差异。]]></description>
      <guid>https://arxiv.org/abs/2407.08819</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:01 GMT</pubDate>
    </item>
    <item>
      <title>证明填字游戏线索答案正确</title>
      <link>https://arxiv.org/abs/2407.08824</link>
      <description><![CDATA[arXiv:2407.08824v1 公告类型：新
摘要：填字游戏线索是一项具有挑战性的认知任务，多家国际报纸每天都会发布新的测试集。每个填字游戏线索都包含要放入填字游戏网格中的答案的定义（与常规填字游戏相同），以及证明答案正确的“文字游戏”（即，人类解题者可以确信答案是正确的，而无需通过填字游戏来确认）。使用现有的填字游戏证明框架（基于 LLM 创建的 Python 证明），我们表明可以根据文字游戏是否“有效”来区分正确答案和几乎正确的答案。]]></description>
      <guid>https://arxiv.org/abs/2407.08824</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:01 GMT</pubDate>
    </item>
    <item>
      <title>大型模型是什么？误将工程成就当成人类语言能力</title>
      <link>https://arxiv.org/abs/2407.08790</link>
      <description><![CDATA[arXiv:2407.08790v1 公告类型：新
摘要：在本文中，我们认为，关于大型语言模型 (LLM) 语言能力的关键、往往耸人听闻和误导性的主张基于至少两个毫无根据的假设：语言完整性假设和数据完整性假设。语言完整性假设存在一个独特而完整的东西，例如“自然语言”，其基本特征可以通过 LLM 有效而全面地建模。数据完整性假设依赖于语言可以被量化并完全被数据捕获的信念。认知科学中的实施方法研究表明，语言是一种手段或行为方式，而不是一个独特而完整的东西。语言不是那种可以完整或全面建模的东西。从实施的角度来看，我们确定了实施语言的三个关键特征：体现、参与和不稳定，这些特征在 LLM 中是不存在的，并且可能在原则上与当前架构不兼容。我们认为，这些缺失意味着 LLM 现在不是也不可能以目前的形式成为像人类一样的语言主体。我们特别通过“算法语言”现象来说明这一点，算法语言是最近描述的在严格控制的在线环境中高风险人类语言活动的模式。基于这些观点，我们得出结论，关于 LLM 主体和能力的耸人听闻和误导性说法源于对人类语言和 LLM 的深刻误解。]]></description>
      <guid>https://arxiv.org/abs/2407.08790</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:00 GMT</pubDate>
    </item>
    <item>
      <title>MAGNET：使用基于自适应梯度的标记化提高语言模型的多语言公平性</title>
      <link>https://arxiv.org/abs/2407.08818</link>
      <description><![CDATA[arXiv:2407.08818v1 公告类型：新
摘要：在多语言环境中，非拉丁文字和资源匮乏的语言通常在语言模型的实用性、效率和成本方面处于劣势。具体而言，先前的研究报告了当前标记化算法引入非拉丁文字语言的多种建模偏差，其中最主要的是过度分割。在这项工作中，我们提出了 MAGNET；多语言自适应梯度标记化，通过基于自适应梯度的子词标记化来减少过度分割。MAGNET 通过模型中的子模块学习预测序列中字节标记之间的段边界，这些子模块充当内部边界预测器（标记器）。以前的基于梯度的标记化方法旨在通过在训练期间集成单个边界预测器并通过随机重新参数化对其进行端到端优化以及下一个标记预测目标来实现跨序列的统一压缩。然而，这种方法仍然会导致多语言环境中非拉丁文字语言的过度分割。相比之下，MAGNET 提供了一种可定制的架构，其中字节级序列通过特定于语言脚本的预测器进行路由，每个预测器都针对其各自的语言脚本进行了优化。与以前的方法相比，这种模块化可以实现不同语言脚本之间的公平分割粒度。通过大量实验，我们证明，除了减少分割差异之外，MAGNET 还可以加快语言建模速度并提高下游效用。]]></description>
      <guid>https://arxiv.org/abs/2407.08818</guid>
      <pubDate>Mon, 15 Jul 2024 06:22:00 GMT</pubDate>
    </item>
    </channel>
</rss>