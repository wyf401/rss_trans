<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 16 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>研究 Transformer 语言模型中的低秩训练：效率和扩展分析</title>
      <link>https://arxiv.org/abs/2407.09835</link>
      <description><![CDATA[arXiv:2407.09835v1 公告类型：新
摘要：最先进的 LLM 通常依赖于高计算成本的规模，这引发了一项研究议程，以减少参数数量和成本而不会显着影响性能。我们的研究重点是基于 Transformer 的 LLM，特别是将低秩参数化应用于计算密集型前馈网络 (FFN)，这些网络的研究较少，而注意力块则较少。与之前的研究相比，(i) 我们探索大规模低秩参数化，最多 13 亿个参数；(ii) 在 Transformer 语言模型中而不是卷积架构中；(iii) 从头开始​​训练。在大型 RefinedWeb 数据集上进行的实验表明，低秩参数化既高效（例如，2.6$\times$ FFN 加速比 32\% 参数），又在训练期间有效。有趣的是，这些结构化的 FFN 表现出比原始模型更陡峭的缩放曲线。受此发现的启发，我们开发了宽而结构化的网络，在困惑度和吞吐量性能上超越了当前的中型和大型 Transformer。]]></description>
      <guid>https://arxiv.org/abs/2407.09835</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:06 GMT</pubDate>
    </item>
    <item>
      <title>AraFinNLP 2024：首个阿拉伯语金融 NLP 共享任务</title>
      <link>https://arxiv.org/abs/2407.09818</link>
      <description><![CDATA[arXiv:2407.09818v1 公告类型：新
摘要：阿拉伯世界不断扩大的金融市场需要复杂的阿拉伯语 NLP 工具。为了满足银行领域的这一需求，阿拉伯金融 NLP (AraFinNLP) 共享任务提出了两个子任务：(i) 多方言意图检测和 (ii) 跨方言翻译和意图保留。此共享任务使用更新的 ArBanking77 数据集，其中包括 MSA 和四种方言中的大约 39k 个并行查询。每个查询都标有银行领域中常见的 77 个意图中的一个或多个。这些资源旨在促进强大的金融阿拉伯语 NLP 的发展，特别是在机器翻译和银行聊天机器人领域。共有 45 个独特的团队注册了此共享任务，其中 11 个积极参与了测试阶段。具体来说，子任务 1 有 11 支队伍参与，而子任务 2 只有 1 支队伍参与。子任务 1 的获胜队伍取得了 F1 分数 0.8773，子任务 2 中唯一提交论文的队伍取得了 1.667 的 BLEU 分数。]]></description>
      <guid>https://arxiv.org/abs/2407.09818</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:05 GMT</pubDate>
    </item>
    <item>
      <title>NativQA：面向法学硕士的多语言文化一致自然查询</title>
      <link>https://arxiv.org/abs/2407.09823</link>
      <description><![CDATA[arXiv:2407.09823v1 公告类型：新
摘要：自然问答 (QA) 数据集在开发和评估大型语言模型 (LLM) 的功能方面发挥着至关重要的作用，确保它们在实际应用中的有效使用。尽管已经开发了大量 QA 数据集，但由母语用户用自己的语言生成的特定区域数据集明显不足。这一差距阻碍了对 LLM 进行有效的区域和文化特异性基准测试。在本研究中，我们提出了一个可扩展的框架 NativQA，以无缝构建母语中文化和区域一致的 QA 数据集，用于 LLM 评估和调整。此外，为了证明所提框架的有效性，我们设计了一个多语言自然 QA 数据集 MultiNativQA，它由七种语言的约 72K 个 QA 对组成，资源从高到极低不等，基于母语人士的查询，涵盖 18 个主题。我们使用开源和闭源 LLM 对 MultiNativQA 数据集进行基准测试。我们向社区公开了框架 NativQA 和 MultiNativQA 数据集。（https://nativqa.gitlab.io）]]></description>
      <guid>https://arxiv.org/abs/2407.09823</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:05 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士-面向大众的自动化科学新闻合作</title>
      <link>https://arxiv.org/abs/2407.09756</link>
      <description><![CDATA[arXiv:2407.09756v1 公告类型：新
摘要：科学新闻向非专业人士报道当前的科学发现，旨在让公众了解最新技术。然而，这项任务可能具有挑战性，因为观众往往缺乏关于所呈现研究的具体知识。为了应对这一挑战，我们提出了一个框架，该框架集成了三个 LLM，模仿现实世界的写作-阅读-反馈-修订工作流程，其中一个 LLM 充当记者，一个较小的 LLM 充当普通读者，第三个 LLM 充当编辑。记者的写作通过读者的反馈和编辑的建议不断完善。我们的实验表明，通过利用两个 7B 和一个 1.8B 开源 LLM 的协作，我们可以生成比现有方法（包括 GPT-4 等高级模型）生成的文章更容易理解的文章。]]></description>
      <guid>https://arxiv.org/abs/2407.09756</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:04 GMT</pubDate>
    </item>
    <item>
      <title>MaskMoE：通过混合专家中的路由掩码增强令牌级学习</title>
      <link>https://arxiv.org/abs/2407.09816</link>
      <description><![CDATA[arXiv:2407.09816v1 公告类型：新
摘要：扩展模型容量可增强其功能，但会显著增加计算量。混合专家模型 (MoE) 通过允许扩展模型容量而不会大幅增加训练或推理成本来解决此问题。尽管 MoE 模型取得了令人鼓舞的结果，但它们仍面临一些挑战。首先，训练标记分散在多个专家之间会导致拟合不足，尤其是对于不频繁的标记。此外，虽然固定路由机制可以缓解此问题，但它们会损害表示的多样性。在本文中，我们提出了 MaskMoE，这是一种通过在混合专家模型中采用路由掩码技术来增强标记级学习的方法。MaskMoE 能够在实现更全面的训练的同时保持表示多样性。实验结果表明，我们的方法在困惑度 (PPL) 和下游任务方面均优于以前占主导地位的混合专家模型。]]></description>
      <guid>https://arxiv.org/abs/2407.09816</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:04 GMT</pubDate>
    </item>
    <item>
      <title>多么优雅的桥梁：多语言法学硕士在不同语言中存在相似的偏见</title>
      <link>https://arxiv.org/abs/2407.09704</link>
      <description><![CDATA[arXiv:2407.09704v1 公告类型：新
摘要：本文通过语法性别的视角研究大型语言模型 (LLM) 的偏见。从心理语言学的开创性著作中汲取灵感，特别是性别对语言感知影响的研究，我们利用多语言 LLM 重新审视和扩展 Boroditsky (2003) 的基础实验。使用 LLM 作为检查与语法性别相关的心理语言学偏见的新方法，我们促使一个模型用各种语言中的形容词描述名词，特别关注具有语法性别的语言。具体来说，我们研究跨性别和语言的形容词共现，并训练二元分类器来预测 LLM 用来描述名词的形容词的语法性别。令人惊讶的是，我们发现一个简单的分类器不仅可以预测名词性别，而且还表现出跨语言的可迁移性。我们表明，虽然 LLM 在不同的语言中对单词的描述可能不同，但它们的偏见是相似的。]]></description>
      <guid>https://arxiv.org/abs/2407.09704</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:03 GMT</pubDate>
    </item>
    <item>
      <title>用于加速大型语言模型推理的多标记联合推测解码</title>
      <link>https://arxiv.org/abs/2407.09722</link>
      <description><![CDATA[arXiv:2407.09722v1 公告类型：新
摘要：基于 Transformer 的大型语言模型 (LLM) 已在各种任务中展示了其强大功能，但它们的推理需要大量的时间和能源成本。为了加速 LLM 推理，推测解码使用较小的模型来提出一个 token 序列，随后由目标大型模型批量验证这些 token。与自回归解码相比，推测解码用较少的大型模型运行生成相同数量的 token，因此将整体推理速度加快了 $1$-$2\times$。然而，贪婪解码并不是输出困惑度方面的最优解码算法，而输出困惑度是解码算法有效性的直接衡量标准。具有比推测解码更好的输出困惑度甚至更好效率的算法在实践中会更有用。为了实现这个看似矛盾的目标，我们首先引入了多标记联合贪婪解码（MJGD），它在每个步骤中根据它们的联合困惑度贪婪地生成多个标记。我们表明，这会导致整个输出的困惑度更低。但 MJGD 的计算成本在实践中是不可行的。因此，我们进一步提出了多标记联合推测解码（MJSD），它从两个方面近似和加速 MJGD：它用小模型的联合分布近似大模型的联合分布，并使用验证步骤来保证近似的准确性；然后它使用波束解码来加速从联合分布生成序列。与原始推测解码相比，MJSD 有两个优点：（1）它是 MJGD 的近似，从而实现更好的输出困惑度；（2）使用联合似然的验证使其能够接受具有有效困惑度的草稿标记的最长前缀子序列，从而提高效率……]]></description>
      <guid>https://arxiv.org/abs/2407.09722</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:03 GMT</pubDate>
    </item>
    <item>
      <title>中国的语言模型有多中国化？中国法学硕士课程语言政策缺失令人费解</title>
      <link>https://arxiv.org/abs/2407.09652</link>
      <description><![CDATA[arXiv:2407.09652v1 公告类型：新
摘要：当代语言模型越来越多语，但中国法学硕士开发人员必须应对语言多样性的复杂政治和商业考虑。中国的语言政策旨在影响公共话语和治理多民族社会，自 1949 年以来已逐渐从多元化转变为更具同化主义的方法。我们探讨了这些影响对当前语言技术的影响。我们评估了由中国公司对 18 种语言进行预训练的六种开源多语言法学硕士，涵盖了广泛的中文、亚洲和英欧语言。我们的实验表明，中文法学硕士在不同语言上的表现与国际法学硕士没有区别。同样，这些模型的技术报告也表明，除了英语和普通话之外，没有考虑预训练数据的语言覆盖范围。考察中国的人工智能政策、模型实验和技术报告，我们发现没有任何迹象表明中国在法学硕士发展中有任何一致的政策，无论是支持还是反对语言多样性。这留下了一个令人费解的事实：虽然中国既规范人们日常使用的语言，也规范语言模型开发，但他们似乎对语言模型中的语言没有任何政策。]]></description>
      <guid>https://arxiv.org/abs/2407.09652</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>弥合信息搜索和产品搜索系统之间的差距：电子商务问答推荐</title>
      <link>https://arxiv.org/abs/2407.09653</link>
      <description><![CDATA[arXiv:2407.09653v1 公告类型：新
摘要：购物时，消费者通常会在迭代过程中利用产品搜索和信息搜索系统（例如网络搜索引擎和问答 (QA) 系统）来提高对可用产品的理解并做出购买决定。虽然产品搜索有助于购物者在目录中找到符合其要求的实际产品，但信息搜索系统可用于回答他们可能提出的任何问题以完善这些要求。大型语言模型 (LLM) 的最新成功为弥合这两项任务之间的差距提供了机会，通过在产品搜索中集成对话式 QA，帮助客户快速有效地实现目标。在本文中，我们建议向用户推荐与他们的产品搜索相关的问答 (Q&amp;A) 对，并帮助他们做出购买决定。我们讨论了问题的不同方面，包括问答对的要求和特征、它们的生成以及问答推荐任务的优化。我们强调所面临的挑战、尚未解决的问题并提出解决方案，以鼓励未来对这一新兴领域的研究。]]></description>
      <guid>https://arxiv.org/abs/2407.09653</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>用于整合健康数据社会决定因素的大型语言模型：心力衰竭 30 天再入院预测案例研究</title>
      <link>https://arxiv.org/abs/2407.09688</link>
      <description><![CDATA[arXiv:2407.09688v1 公告类型：新
摘要：健康的社会决定因素 (SDOH) $-$ 人们生活、成长和衰老的各种情况 $-$ 在健康结果中发挥着重要作用。然而，现有的结果预测模型通常仅使用 SDOH 的代理作为特征。最近的开放数据计划提供了构建更全面的 SDOH 视图的机会，但随着公共 SDOH 数据的数量和多样性的增长，手动整合与个体患者最相关的数据变得越来越具有挑战性。大型语言模型 (LLM) 在自动注释结构化数据方面显示出良好的前景。在这里，我们进行了一项端到端案例研究，评估使用 LLM 集成 SDOH 数据的可行性，以及这些 SDOH 特征对临床预测的实用性。我们首先手动将来自两个可公开访问的 SDOH 数据源的 700 多个变量标记为五个语义 SDOH 类别之一。然后，我们在这个分类任务上对 9 个开源 LLM 的性能进行基准测试。最后，我们训练 ML 模型来预测 39,000 名心力衰竭 (HF) 患者的 30 天再入院率，并将分类后的 SDOH 变量的预测性能与标准临床变量进行比较。此外，我们研究了少量 LLM 提示对 LLM 注释性能的影响，并对提示进行了元数据消融研究，以评估哪些信息有助于 LLM 准确注释这些变量。我们发现一些开源 LLM 可以使用零样本提示有效、准确地注释 SDOH 变量，而无需进行微调。至关重要的是，当与标准临床特征相结合时，LLM 注释的 SDOH 变量的邻里和建筑环境子集在预测 HF 患者 30 天再入院率方面表现出最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2407.09688</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformer 的多流方法实现伊朗孤立手语识别</title>
      <link>https://arxiv.org/abs/2407.09544</link>
      <description><![CDATA[arXiv:2407.09544v1 公告类型：新
摘要：手语是全球数百万人的重要交流方式，也是他们的主要语言。然而，大多数交流工具都是为口语和书面语言开发的，这可能会给聋人和听力障碍者群体带来问题和困难。通过开发手语识别系统，我们可以弥合这种沟通鸿沟，使以手语为主要表达形式的人能够更好地与人和周围环境交流。该识别系统提高了医疗服务质量，改善了公共服务，为聋人群体创造了平等的机会。这项研究旨在借助最新的深度学习工具（如 transformers）识别伊朗手语单词。使用的数据集包括 101 个伊朗手语单词，这些单词经常在大学等学术环境中使用。所使用的网络是早期融合和晚期融合 transformer 编码器网络的组合，并在遗传算法的帮助下进行了优化。训练该网络的选定特征包括从手势视频中提取的手和嘴唇关键点以及手之间的距离和角度。此外，除了针对类别的训练模型外，单词的嵌入向量还用作多任务学习，以使训练更流畅、更高效。我们还使用窗口技​​术对从我们的单词数据集生成的句子进行了测试，以进行句子翻译。最后，介绍了一种借助所开发的模型为用户提供实时反馈的手语训练软件，该软件在测试数据上的准确率为 90.2%，并在一项调查中调查了此​​类手语学习软件的有效性和效率以及反馈的影响。]]></description>
      <guid>https://arxiv.org/abs/2407.09544</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>在稀疏混合专家中实现与任务无关的修剪的专家知识多样化</title>
      <link>https://arxiv.org/abs/2407.09590</link>
      <description><![CDATA[arXiv:2407.09590v1 公告类型：新
摘要：通过增加模型参数但在执行任务时稀疏地激活它们，使用混合专家 (MoE) 架构可显着提高大型语言模型 (LLM) 的性能，而不会增加推理成本。然而，由于专家数量的增加而导致的内存消耗给在许多现实世界环境中部署这些模型带来了挑战。我们的实证研究表明，一些专家在预训练期间编码了冗余知识。因此，我们提出了一种对相似专家进行分组和修剪的方法，以提高模型的参数效率。我们通过修剪两个最先进的 MoE 模型 Mixtral-8x7B 和 Mixtral-8x22B 来验证我们方法的有效性。评估表明，我们的方法在一系列自然语言任务上优于其他模型修剪方法。为了促进未来的研究，我们将发布我们的代码和修剪后的 MoE 模型。]]></description>
      <guid>https://arxiv.org/abs/2407.09590</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>将大型语言模型与基于图的推理相结合，实现对话式问答</title>
      <link>https://arxiv.org/abs/2407.09506</link>
      <description><![CDATA[arXiv:2407.09506v1 公告类型：新
摘要：我们专注于对话式问答任务，该任务结合了理解上下文中的问题和推理从文本、知识图谱、表格和信息框等异构来源收集的证据的挑战。我们的方法利用图形结构化表示来聚合有关问题及其上下文的信息（即迄今为止的对话和为找到答案而检索到的证据），同时还利用大型语言模型 (LLM) 的推理和文本生成功能。图形嵌入直接注入 LLM，绕过标记嵌入层，并通过最小化交叉熵进行端到端学习。我们的模型维护一个记忆模块来跟踪和更新过去的证据，从而随着对话的发展影响图形的结构。 ConvMix 基准（Christmann 等，2022a）上的实验结果表明，图嵌入增强了 LLM 的推理能力，而记忆模块则提供了对噪声和检索错误的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2407.09506</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>MATE：相约嵌入——将图像与长文本连接起来</title>
      <link>https://arxiv.org/abs/2407.09541</link>
      <description><![CDATA[arXiv:2407.09541v1 公告类型：新
摘要：虽然视觉语言模型 (VLM) 的进步显著改善了视觉和文本数据的对齐，但这些模型主要侧重于将图像与简短的描述性标题对齐。这种关注限制了它们处理复杂文本交互的能力，尤其是较长的文本，例如长标题或文档，这些文本尚未得到广泛探索。在本文中，我们介绍了 Meet At The Embedding (MATE)，这是一种新颖的方法，它将 VLM 与大型语言模型 (LLM) 的功能相结合，以克服这一挑战，而无需额外的图像长文本对。具体来说，我们用预训练的基于 LLM 的编码器替换 VLM 的文本编码器，该编码器擅长理解长文本。为了弥合 VLM 和 LLM 之间的差距，MATE 采用了以多阶段方式训练的投影模块。它首先使用大量文本对将来自 VLM 文本编码器的嵌入与来自 LLM 的嵌入对齐。然后使用此模块无缝地将图像嵌入与 LLM 嵌入紧密对齐。我们提出了两个新的跨模态检索基准来评估将图像与长文本（长标题/文档）连接起来的任务。大量实验结果表明，MATE 可以有效地将图像与长文本连接起来，揭示出各种语义关系。]]></description>
      <guid>https://arxiv.org/abs/2407.09541</guid>
      <pubDate>Tue, 16 Jul 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>不同语言的图像字幕</title>
      <link>https://arxiv.org/abs/2407.09495</link>
      <description><![CDATA[arXiv:2407.09495v1 公告类型：新
摘要：这篇简短的立场文件提供了手动整理的非英语图像字幕数据集列表（截至 2024 年 5 月）。通过此列表，我们可以观察到不同语言的数据集的匮乏：仅代表了 23 种不同的语言。随着 Crossmodal-3600 数据集（Thapliyal 等人，2022 年，36 种语言）的加入，这个数字有所增加，但与现有的数千种口语相比，这个数字仍然很小。本文最后提出了一些视觉与语言领域的未解决的问题。]]></description>
      <guid>https://arxiv.org/abs/2407.09495</guid>
      <pubDate>Tue, 16 Jul 2024 06:19:59 GMT</pubDate>
    </item>
    </channel>
</rss>