<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 03 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 LLM 进行文本聚类分类</title>
      <link>https://arxiv.org/abs/2410.00927</link>
      <description><![CDATA[arXiv:2410.00927v1 公告类型：新
摘要：文本聚类在手动标记成本过高的实际应用中仍然很有价值。它通过根据相似文本的表示形式对其进行分组，从而促进信息的有效组织和分析。但是，实现这种方法需要对下游数据和复杂的相似性指标进行微调的嵌入器。为了解决这个问题，本研究提出了一个新颖的文本聚类框架，该框架有效地利用了大型语言模型 (LLM) 的上下文学习能力。我们建议通过 LLM 将文本聚类转换为分类任务，而不是微调嵌入器。首先，我们提示 LLM 为给定的数据集生成潜在标签。其次，在整合 LLM 生成的类似标签后，我们提示 LLM 为数据集中的每个样本分配最合适的标签。我们的框架已通过实验证明，其性能可与采用嵌入的最先进的聚类方法相媲美或更佳，且无需复杂的微调或聚类算法。我们的代码可供公众使用，网址为 https://anonymous.4open.science/r/Text-Clustering-via-LLM-E500。]]></description>
      <guid>https://arxiv.org/abs/2410.00927</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>伊卡语自动语音识别</title>
      <link>https://arxiv.org/abs/2410.00940</link>
      <description><![CDATA[arXiv:2410.00940v1 公告类型：新
摘要：我们提出了一种经济有效的方法，用于为 Ika 等资源匮乏的语言开发自动语音识别 (ASR) 模型。我们在从 Ika 语新约圣经翻译汇编而成的高质量语音数据集上对预训练的 wav2vec 2.0 大规模多语言语音模型进行了微调。我们的结果表明，微调多语言预训练模型仅用 1 小时多一点的训练数据就实现了 0.5377 的字错误率 (WER) 和 0.2651 的字符错误率 (CER)。较大的 10 亿参数模型优于较小的 3 亿参数模型，因为它更复杂，并且能够存储更丰富的语音表示。然而，我们观察到对小型训练数据集的过度拟合，降低了通用性。我们的研究结果表明，利用多语言预训练模型来处理资源匮乏的语言具有潜力。未来的工作应该集中在扩大数据集和探索减轻过度拟合的技术上。]]></description>
      <guid>https://arxiv.org/abs/2410.00940</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 GPT-4 对东亚习语进行创造性和语境感知翻译</title>
      <link>https://arxiv.org/abs/2410.00988</link>
      <description><![CDATA[arXiv:2410.00988v1 公告类型：新
摘要：作为一种比喻性语言，东亚习语将丰富的文化背景浓缩为几个字符。翻译此类习语对人工翻译人员来说是一项挑战，他们通常会从现有的候选列表中选择上下文感知的翻译。然而，即使对于专业翻译人员来说，编纂一本候选翻译词典也需要大量的时间和创造力。为了减轻这种负担，我们评估了 GPT-4 是否有助于生成高质量的翻译。基于对忠实度和创造力的自动评估，我们首先确定了可以胜过 Google 和 DeepL 翻译引擎的帕累托最优提示策略。然后，以低成本，我们的上下文感知翻译可以实现比人类基线高得多的每句习语的高质量翻译。我们开源所有代码和数据以促进进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2410.00988</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>“隐藏在众目睽睽之下”：设计合成对话生成以揭示社会规范</title>
      <link>https://arxiv.org/abs/2410.00998</link>
      <description><![CDATA[arXiv:2410.00998v1 公告类型：新
摘要：自然情境对话捕捉适合对话主题的底层社会规范、对话者之间的关系及其交流意图。本文提出了一个可控对话生成框架，涵盖广泛的对话者属性（例如年龄组、职业和性格类型）、关系类型、对话主题和对话轨迹。我们使用此框架生成 NormHint，这是与这些丰富设置一致的对话集合，并分析了导致冲突的规范违规行为，以及通过遵守社会规范和偏好尊重的话语来避免这些冲突的潜在步骤，保持原始话语的交流意图。我们展示了 NormHint 的人工验证和自动分析结果，并表明它捕捉了广泛的对话主题，并根据提示的上下文对对话的自然性进行了人类高分。]]></description>
      <guid>https://arxiv.org/abs/2410.00998</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>研究 Dropout 和残差连接对语言模型训练的协同作用</title>
      <link>https://arxiv.org/abs/2410.01019</link>
      <description><![CDATA[arXiv:2410.01019v1 公告类型：新
摘要：本文探讨了 dropout 技术在减轻语言模型训练中的过度拟合方面的关键作用。它对语言建模背景下可变 dropout 率对各个层和残差连接的影响进行了全面研究。我们的研究对经典的 Tiny Shakespeare 数据进行了解码器实现的训练，以检查调整对训练效率和验证误差的影响。结果不仅证实了 dropout 对正则化的好处和残差对收敛的好处，而且揭示了它们有趣的相互作用。残差连接的深度和这些连接的 dropout 之间存在重要的权衡，以实现最佳的深度神经网络收敛和泛化。]]></description>
      <guid>https://arxiv.org/abs/2410.01019</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>动态草稿：使用余弦相似度的自适应自推测解码</title>
      <link>https://arxiv.org/abs/2410.01028</link>
      <description><![CDATA[arXiv:2410.01028v1 公告类型：新
摘要：我们提出了一种简单的即时方法，用于更快地推理大型语言模型。与其他（自）推测解码技术不同，我们的方法不需要微调或黑盒优化来生成固定的草稿模型，而是依靠简单的规则来生成适应输入上下文的不同草稿模型。我们通过经验证明，我们的轻量级算法与当前的 SOTA 相比具有竞争力，可用于自推测解码，同时是一种真正的即插即用方法。]]></description>
      <guid>https://arxiv.org/abs/2410.01028</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MOSEL：950,000 小时语音数据，用于欧盟语言开源语音基金会模型训练</title>
      <link>https://arxiv.org/abs/2410.01036</link>
      <description><![CDATA[arXiv:2410.01036v1 公告类型：新
摘要：基础模型 (FM) 的兴起，加上针对其风险和影响的监管努力，引发了人们对开源模型的极大兴趣。然而，现有的语音 FM (SFM) 未能完全符合开源原则，即使声称符合，因为没有现有的 SFM 在开源条款下公开提供模型权重、代码和训练数据。在这项工作中，我们迈出了填补这一空白的第一步，重点关注欧盟 (EU) 的 24 种官方语言。我们通过调查符合开源许可的自动语音识别数据集和未标记语音语料库来收集合适的训练数据，总共 95 万小时。此外，我们在宽松的 CC-BY 许可下发布了 44.1 万小时未标记数据的自动转录，从而促进了为欧盟语言创建开源 SFM。]]></description>
      <guid>https://arxiv.org/abs/2410.01036</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从事实到洞见：关于解读收益电话会议的分析报告的生成和评估的研究</title>
      <link>https://arxiv.org/abs/2410.01039</link>
      <description><![CDATA[arXiv:2410.01039v1 公告类型：新
摘要：本文探讨了大型语言模型 (LLM) 在收益电话会议 (EC) 得出的分析报告生成和评估中的应用。为了解决当前研究方面的差距，我们探索在多代理框架中使用 LLM 生成分析报告，设计专门的代理，将不同的观点和理想的分析主题引入报告生成过程。通过多项分析，我们检查了生成的报告和人工编写的报告之间的一致性以及个人和集体代理的影响。我们的研究结果表明，引入额外的代理会产生更有见地的报告，尽管在大多数情况下，人类专家生成的报告仍然是首选。最后，我们解决了报告评估的挑战性问题，我们研究了 LLM 在评估不同环境下生成的报告质量方面的局限性和优势，揭示了与人类专家在多个维度上的显著相关性。]]></description>
      <guid>https://arxiv.org/abs/2410.01039</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从自然语言到 SQL：基于 LLM 的文本到 SQL 系统的回顾</title>
      <link>https://arxiv.org/abs/2410.01066</link>
      <description><![CDATA[arXiv:2410.01066v1 公告类型：新
摘要：自 LLM 出现以来，将自然语言查询转换为结构化 SQL 命令的现象日益普遍。与之前的评论不同，本调查全面研究了基于 LLM 的文本到 SQL 系统的演变，从早期的基于规则的模型到高级 LLM 方法，以及 LLM 如何影响该领域。我们讨论了基准、评估方法和评估指标。此外，我们独特地研究了知识图谱集成在这些系统中的作用，以提高上下文准确性和模式链接。当前的技术分为两类：语料库的上下文学习和微调，这导致了诸如零样本、从末端进行少量样本学习和数据增强等方法。最后，我们重点介绍了计算效率、模型鲁棒性和数据隐私等关键挑战，并展望了它们在基于 LLM 的文本到 SQL 系统未来潜在领域的发展和改进。]]></description>
      <guid>https://arxiv.org/abs/2410.01066</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多语言法学硕士 (LLM) 中的概念空间对齐</title>
      <link>https://arxiv.org/abs/2410.01079</link>
      <description><![CDATA[arXiv:2410.01079v1 公告类型：新
摘要：多语言大型语言模型 (LLM) 似乎在语言之间具有一定的泛化能力。我们假设这是隐式向量空间对齐的结果。评估这种对齐后，我们发现较大的模型在不同语言的相应概念之间表现出非常高质量的线性对齐。我们的实验表明，多语言 LLM 存在两个常见的弱点：泛化最适合具有相似类型的语言和抽象概念。对于某些模型，例如 Llama-2 系列模型，基于提示的嵌入比词嵌入对齐效果更好，但投影的线性性较差——这一观察结果适用于几乎所有模型系列，表明一些隐式学习的对齐方式在某种程度上被基于提示的方法破坏了。]]></description>
      <guid>https://arxiv.org/abs/2410.01079</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解锁韩语动词：用户友好的动词词典探索</title>
      <link>https://arxiv.org/abs/2410.01100</link>
      <description><![CDATA[arXiv:2410.01100v1 公告类型：新
摘要：世宗词典数据集提供了宝贵的资源，广泛涵盖了形态、句法和语义表示。该数据集可用于更深入地探索语言信息。该数据集中标记的语言结构构成了揭示单词和短语之间的关系及其与目标动词的关联的基础。本文介绍了一个用户友好的 Web 界面，旨在收集和整合与动词相关的信息，特别关注子类别框架。此外，它概述了我们通过将子类别框架与相应的说明性句子示例对齐来映射此信息的努力。此外，我们还提供了一个 Python 库，可以简化句法解析和语义角色标记。这些工具旨在帮助有兴趣利用世宗词典数据集开发韩语处理应用程序的个人。]]></description>
      <guid>https://arxiv.org/abs/2410.01100</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>近似对齐解码</title>
      <link>https://arxiv.org/abs/2410.01103</link>
      <description><![CDATA[arXiv:2410.01103v1 公告类型：新
摘要：拒绝大型语言模型 (LLM) 的不良输出很常见；然而，目前这样做的方法需要大量的计算，或者严重扭曲输出的分布。我们提出了一种平衡输出分布扭曲和计算效率的方法，允许生成具有难以满足的约束的长文本序列，与现有方法相比，低概率输出的放大更少。我们通过一系列实验表明，我们的方法的任务特定性能与不扭曲输出分布的方法相当，同时计算效率更高。]]></description>
      <guid>https://arxiv.org/abs/2410.01103</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 NLP 和 LLM 评估经济研究论文标题的重复数据删除技术，重点关注语义相似性</title>
      <link>https://arxiv.org/abs/2410.01141</link>
      <description><![CDATA[arXiv:2410.01141v1 公告类型：新
摘要：本研究调查了针对经济研究论文标题的大型 NLP 数据集的有效重复数据删除技术。我们探索了各种配对方法以及已建立的距离度量（Levenshtein 距离、余弦相似度）和用于语义评估的 sBERT 模型。我们的研究结果表明，根据在不同方法中观察到的语义相似性，重复的发生率可能很低。为了进行更具结论性的评估，我们使用了人工注释的地面实况集进行了进一步探索。结果支持基于 NLP、LLM 的距离度量的发现。]]></description>
      <guid>https://arxiv.org/abs/2410.01141</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用文件名进行文档类型分类</title>
      <link>https://arxiv.org/abs/2410.01166</link>
      <description><![CDATA[arXiv:2410.01166v1 公告类型：新
摘要：快速文档分类对于数字取证和大规模媒体分类等多种时间敏感型应用至关重要。依赖重型深度学习模型的传统方法由于对大量输入数据集的推理时间长和分析整个文档所需的计算资源不足而无法达到预期效果。在本文中，我们提出了一种使用轻量级监督学习模型结合基于 TF-IDF 特征提取的标记化方法的方法，可以准确高效地仅基于文件名对文档进行分类，从而大大缩短推理时间。此方法可以通过置信度分数和使用代表模糊文件名的负类将模糊文件名与指示性文件名区分开来。我们的结果表明，当在与训练数据集相比具有大量超出范围数据的数据集上进行测试时，文件名分类器可以以 96.7% 的准确率处理超过 80% 的范围内数据，同时比 DiT 等更复杂的模型快 442.43 倍。我们的方法为在关键场景中有效处理海量数据集提供了关键的解决方案，从而实现了快速、更可靠的文档分类。]]></description>
      <guid>https://arxiv.org/abs/2410.01166</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GADFA：基于生成器辅助决策的观点表达时机识别方法</title>
      <link>https://arxiv.org/abs/2410.01169</link>
      <description><![CDATA[arXiv:2410.01169v1 公告类型：新
摘要：文本生成模型的进步使我们能够根据需要生成连贯且令人信服的文本。然而，在现实生活中，个人不会持续生成文本或表达他们的意见。例如，消费者在权衡产品的优缺点后撰写产品评论，专业分析师在重要新闻发布后发布报告。本质上，意见表达通常由特定原因或信号引发。尽管意见挖掘长期以来一直在发展，但表达意见的适当时机仍未得到充分探索。为了解决这一缺陷，我们的研究引入了一项创新任务——识别新闻触发的意见表达时机。我们将这项任务建立在专业股票分析师的行为上，并开发了一个新的数据集进行调查。我们的方法以决策为中心，利用文本生成模型来指导分类模型，从而提高整体性能。我们的实验结果表明，我们的模型生成的文本从各个角度贡献了新的见解，有效地帮助确定表达意见的最佳时机。]]></description>
      <guid>https://arxiv.org/abs/2410.01169</guid>
      <pubDate>Thu, 03 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>