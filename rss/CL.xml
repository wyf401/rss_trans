<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 31 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过高级法学硕士 (LLM) 集成加强农业机械管理</title>
      <link>https://arxiv.org/abs/2407.20588</link>
      <description><![CDATA[arXiv:2407.20588v1 公告类型：新
摘要：将人工智能融入农业实践，特别是通过智能农业机械管理咨询 (CIAMM)，有可能彻底改变农业的效率和可持续性。本文介绍了一种新方法，该方法利用大型语言模型 (LLM)，特别是 GPT-4，结合多轮提示工程来增强农业机械管理中的决策过程。我们系统地开发和改进了提示，以指导 LLM 生成精确且与上下文相关的输出。我们使用来自各种在线来源的手动整理数据集来评估我们的方法，并使用准确度和 GPT-4 分数来评估性能。使用 LLama-2-70B、ChatGPT 和 GPT-4 模型以及基线和最先进的方法（例如思想链 (CoT) 和思想思想 (ThoT)）进行了比较实验。结果表明，我们的方法明显优于这些方法，在生成的响应中实现了更高的准确性和相关性。本文强调了先进的快速工程技术在提高人工智能在农业环境中的稳健性和适用性方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.20588</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:26 GMT</pubDate>
    </item>
    <item>
      <title>CLR-Fact：评估大型语言模型对事实知识的复杂逻辑推理能力</title>
      <link>https://arxiv.org/abs/2407.20564</link>
      <description><![CDATA[arXiv:2407.20564v1 公告类型：新
摘要：虽然大型语言模型 (LLM) 通过从广泛的训练数据中获取丰富的事实知识，在各种自然语言处理任务中表现出令人印象深刻的能力，但它们以复杂方式综合和逻辑推理这些知识的能力仍未得到充分探索。在这项工作中，我们通过对一般领域和生物医学知识图谱自动生成的复杂推理问题的新基准，对最先进的 LLM 复杂逻辑推理能力进行了系统评估。我们采用了多种上下文学习技术进行的大量实验表明，LLM 擅长推理一般世界知识，但在专门的特定领域知识方面面临重大挑战。我们发现，使用明确的思路链演示进行提示可以显着提高 LLM 在具有多种逻辑运算的复杂逻辑推理任务上的性能。有趣的是，我们的受控评估发现了一种不对称现象，其中 LLM 在集合并运算方面表现出色，但在集合交集方面却遇到了相当大的困难——这是逻辑推理的关键组成部分。为了促进进一步的工作，我们将公开发布我们的评估基准和代码。]]></description>
      <guid>https://arxiv.org/abs/2407.20564</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:25 GMT</pubDate>
    </item>
    <item>
      <title>用于生成上下文相关问题的大型语言模型的比较</title>
      <link>https://arxiv.org/abs/2407.20578</link>
      <description><![CDATA[arXiv:2407.20578v1 公告类型：新 
摘要：本研究探讨了大型语言模型 (LLM) 在教育环境中自动生成问题的有效性。比较了三款 LLM 在无需微调的情况下从大学幻灯片文本创建问题的能力。问题是通过两步流程获得的：首先，使用 Llama 2-Chat 13B 从幻灯片中提取答案短语；然后，这三个模型为每个答案生成问题。为了分析这些问题是否适合学生的教育应用，对 46 名学生进行了调查，他们从五个指标评估了总共 246 个问题：清晰度、相关性、难度、幻灯片关系和问答对齐。结果表明，GPT-3.5 和 Llama 2-Chat 13B 的表现略胜于 Flan T5 XXL，特别是在清晰度和问答对齐方面。GPT-3.5 尤其擅长定制问题以匹配输入答案。本研究的贡献在于分析了法学硕士学位在教育领域自动生成问题的能力。]]></description>
      <guid>https://arxiv.org/abs/2407.20578</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:25 GMT</pubDate>
    </item>
    <item>
      <title>Knesset-DictaBERT：议会程序的希伯来语语言模型</title>
      <link>https://arxiv.org/abs/2407.20581</link>
      <description><![CDATA[arXiv:2407.20581v1 公告类型：新
摘要：我们介绍了 Knesset-DictaBERT，这是一个大型希伯来语模型，在包含以色列议会议事录的 Knesset Corpus 上进行了微调。该模型基于 DictaBERT 架构，并根据 MLM 任务展示了对议会语言理解的显著改进。我们对该模型的性能进行了详细评估，结果显示困惑度和准确性比基线 DictaBERT 模型有所提高。]]></description>
      <guid>https://arxiv.org/abs/2407.20581</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:25 GMT</pubDate>
    </item>
    <item>
      <title>使用半结构化自适应稀疏训练修剪大型语言模型</title>
      <link>https://arxiv.org/abs/2407.20584</link>
      <description><![CDATA[arXiv:2407.20584v1 公告类型：新
摘要：基于 Transformer 的大型语言模型 (LLM) 在各种具有挑战性的任务中都取得了显著的成功。然而，LLM 的部署受到其大量参数数量和内存消耗的阻碍。最近，许多研究试图通过使用无训练方法修剪 LLM 来压缩它们。然而，这些修剪过的模型在复杂任务上通常会经历显著的性能下降。为了解决这个问题，我们提出了一种用于半结构化稀疏模型的新型训练管道，称为自适应稀疏训练器 (AST)。通过提炼存储在其密集对应物中的知识，我们可以防止稀疏模型过度拟合并确保稳定的训练过程。此外，AST 允许模型在训练期间自适应地选择更好的彩票（例如，掩码）。此外，我们发现添加额外的初始化良好的参数可以进一步提高模型性能，而内存占用只会略有增加。我们的方法在保持有限计算成本的同时显着缩小了密集和稀疏模型之间的性能差距。此外，与现有的量化方法相结合，AST 可以将语言模型压缩高达 16 倍（与密集的 FP32 精度模型相比），同时将性能损失降至最低。AST 的表现优于之前最先进的方法，在 Llama2-7B 上的多个零样本任务中，使用不到 0.4% 的预训练标记，将密集和半结构化稀疏模型之间的零样本准确率差距缩小到 1.12%。]]></description>
      <guid>https://arxiv.org/abs/2407.20584</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:25 GMT</pubDate>
    </item>
    <item>
      <title>A2SF：Transformer 解码器中用于 Token 修剪的带遗忘因子的累积注意力评分</title>
      <link>https://arxiv.org/abs/2407.20485</link>
      <description><![CDATA[arXiv:2407.20485v2 公告类型：新 
摘要：最近，基于 Transformer 的大型语言模型 (LLM) 因 KV 缓存而面临内存瓶颈问题，尤其是在长序列处理中。先前的研究提出了基于累积注意力分数的 KV 缓存压缩技术，该技术识别不重要的 token 并从 KV 缓存中删除它们的项，并指出只有少数 token 在注意操作中起重要作用。然而，我们观察到现有的累积注意力分数并不适用于 Transformer 解码器结构。在解码器模型中，由于掩蔽效应，注意力分数累积的次数根据 token 出现的顺序而变化，导致 token 之间的比较不均匀。为了解决这个问题，我们提出了带遗忘因子的累积注意力分数 (A2SF) 技术，该技术在注意力分数累积过程中引入了遗忘因子。 A2SF 通过将遗忘因子随时间反复乘以注意力得分，对由旧 token 生成的过去注意力得分施加惩罚。因此，较旧的 token 受到的惩罚更大，从而为不同年龄的 token 提供公平性。通过 token 之间的公平比较，我们可以更有效地选择重要的 token。我们已经在 OPT 和 LLaMA 模型中验证了通过 A2SF 实现的准确率提升，并且 A2SF 在 1-shot 和 0-shot 上将 LLaMA 2 的准确率提高了 7.8% 和 5.1%。]]></description>
      <guid>https://arxiv.org/abs/2407.20485</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:24 GMT</pubDate>
    </item>
    <item>
      <title>Prompt2DeModel：使用自然语言进行声明性神经符号建模</title>
      <link>https://arxiv.org/abs/2407.20513</link>
      <description><![CDATA[arXiv:2407.20513v1 公告类型：新
摘要：本文介绍了一种通过自然语言提示为复杂的神经符号模型构建领域知识的对话管道。它利用大型语言模型在 DomiKnowS 框架中生成声明性程序。该框架中的程序将概念及其关系表达为图形，以及它们之间的逻辑约束。稍后，可以根据这些规范将图形连接到可训练的神经模型。我们提出的管道利用动态上下文演示检索、基于符号解析器反馈的模型细化、可视化和用户交互等技术来生成任务的结构和正式知识表示。这种方法使领域专家（即使是那些不熟悉 ML/AI 的专家）能够正式宣布他们的知识将被纳入 DomiKnowS 框架中的定制神经模型中。]]></description>
      <guid>https://arxiv.org/abs/2407.20513</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:24 GMT</pubDate>
    </item>
    <item>
      <title>同声传译的对比反馈机制</title>
      <link>https://arxiv.org/abs/2407.20524</link>
      <description><![CDATA[arXiv:2407.20524v2 公告类型：新
摘要：同步语音翻译 (SST) 的最新进展集中于决策策略，这些策略使得能够使用离线训练的 ST 模型进行同步推理。这些决策策略不仅可以控制 SST 中的质量-延迟权衡，还可以通过延迟翻译以获得更多上下文或通过稳定假设检测丢弃这些预测来减轻不稳定预测对翻译质量的影响。然而，这些政策往往忽视了利用不稳定预测的潜在好处。我们为 SST 引入了对比反馈机制 (CFM)，这是一种利用这些不稳定预测作为反馈来提高翻译质量的新方法。CFM 通过对比目标指导系统从这些预测中消除不良的模型行为。在 MuST-C v1.0 数据集上对 8 种语言的 3 种最新决策策略进行的实验表明，CFM 有效地提高了 SST 的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.20524</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:24 GMT</pubDate>
    </item>
    <item>
      <title>如果红色会说话会怎么样？使用大型语言模型进行动态对话生成</title>
      <link>https://arxiv.org/abs/2407.20382</link>
      <description><![CDATA[arXiv:2407.20382v1 公告类型：新
摘要：角色扮演游戏 (RPG) 为玩家提供了一个丰富的互动世界供其探索。对话是开发者和玩家之间沟通的主要方式，以指南、NPC 交互和讲故事等各种形式体现。虽然大多数游戏都依赖书面脚本来定义主要故事和角色个性，但通过角色之间的随意互动可以显着增强玩家沉浸感。随着大型语言模型 (LLM) 的出现，我们引入了一个对话填充框架，该框架利用知识图增强的 LLM 来生成动态且适合上下文的角色交互。我们在《最终幻想 VII 重制版》和《口袋妖怪》的环境中测试了这个框架，提供了定性和定量证据，证明了 GPT-4 能够以明确的个性行事并产生对话。然而，一些缺陷仍然存在，例如 GPT-4 过于积极，或者更微妙的个性（例如成熟）往往与胆怯等更明显的特征相比质量较低。这项研究旨在帮助开发人员制作更细致入微的填充对话，从而丰富玩家的沉浸感并增强整体 RPG 体验。]]></description>
      <guid>https://arxiv.org/abs/2407.20382</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:23 GMT</pubDate>
    </item>
    <item>
      <title>透过镜子，看看霍恩·克劳斯计划在镜子中发现了什么</title>
      <link>https://arxiv.org/abs/2407.20413</link>
      <description><![CDATA[arXiv:2407.20413v1 公告类型：新
摘要：双重 Horn 子句反映了 Horn 子句的关键属性。本文探讨了“镜子的另一面”，以揭示一些预期和意外的对称性及其实际用途。
我们重新审视双重 Horn 子句，将其作为一种建设性否定形式的推动者，这种否定形式支持目标驱动的前向推理，并且在直觉和经典上都是有效的。特别是，我们探索在以双重 Horn 子句程序表示的背景理论背景下证伪反事实假设的能力。
对于双重 Horn 子句程序，与否定失败相比，其计算答案中的变量绑定为成功证伪陈述的原因提供了解释。此外，在命题情况下，与在 ASP 系统中使用稳定模型语义实现的否定失败相比，与 Horn 子句程序类似，双重 Horn 子句程序具有多项式复杂度。
在使用元解释器指定它们的执行模型后，我们设计了一种从双 Horn 子句程序到 Horn 子句程序的编译方案，确保它们的执行不会造成性能损失，并且我们设计了嵌入式 SymLP 语言来支持组合 Horn 子句和双 Horn 子句程序。
作为一个（激励）应用程序，我们将 LLM 推理链转换为命题 Horn 和双 Horn 子句，它们共同努力建设性地证明和反驳目标，并通过推理链的可解释性增强生成式 AI。]]></description>
      <guid>https://arxiv.org/abs/2407.20413</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:23 GMT</pubDate>
    </item>
    <item>
      <title>在机器翻译中生成性别替代词</title>
      <link>https://arxiv.org/abs/2407.20438</link>
      <description><![CDATA[arXiv:2407.20438v1 公告类型：新
摘要：机器翻译 (MT) 系统通常将性别模糊的术语（例如，英语术语“护士”）翻译成系统训练数据中最普遍的性别形式（例如，西班牙语中指女护士的“enfermera”）。这往往反映并延续了社会中存在的有害刻板印象。考虑到 MT 用户界面可以以无摩擦的方式解决性别模糊问题，我们研究了生成所有语法正确的性别翻译替代方案的问题。我们开源了五种语言对的训练和测试数据集，并为此任务建立了基准。我们的关键技术贡献是一种新颖的半监督解决方案，用于生成替代方案，该解决方案与标准 MT 模型无缝集成，并保持高性能，而无需额外的组件或增加推理开销。]]></description>
      <guid>https://arxiv.org/abs/2407.20438</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:23 GMT</pubDate>
    </item>
    <item>
      <title>压路机问题：使用自动定理证明器策略评估法学硕士推理能力</title>
      <link>https://arxiv.org/abs/2407.20244</link>
      <description><![CDATA[arXiv:2407.20244v1 公告类型：新
摘要：本研究首次考察了大型语言模型 (LLM) 遵循用于指导自动定理证明器 (ATP) 的推理策略的能力。我们评估了 GPT4、GPT3.5 Turbo 和谷歌最近的 Gemini 模型在压路机领域问题上的表现。除了确定准确性之外，我们还利用自然语言处理库 spaCy 探索研究 LLM 推理能力的新方法。这导致了一个令人震惊的结果，即任何测试模型的正确推理和正确答案之间的相关性很低。我们发现，使用 ATP 推理策略时模型的性能与一次性思维链相当，并观察到在得出有关模型性能的结论时，关注准确性结果的不确定性至关重要。与之前的推测一致，我们确认 LLM 偏爱自下而上的推理过程，并且最能遵循这种推理过程。然而，推理策略仍然有利于通过可信推理引擎导出小而相关的公式集以供外部处理。]]></description>
      <guid>https://arxiv.org/abs/2407.20244</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:22 GMT</pubDate>
    </item>
    <item>
      <title>LAPIS：语言模型增强型警察调查系统</title>
      <link>https://arxiv.org/abs/2407.20248</link>
      <description><![CDATA[arXiv:2407.20248v2 公告类型：新
摘要：犯罪情况与时间赛跑。警察需要一种人工智能辅助刑事调查系统，为警察提供及时但准确的法律咨询。我们介绍了 LAPIS（语言模型增强警察调查系统），这是一种协助警察执行合理和合法调查行动的自动化系统。我们构建了一个专门用于犯罪调查法律推理任务的微调数据集和检索知识库。我们通过结合一组领域专家的手动管理工作来扩展数据集的质量。然后，我们将较小的韩语模型的预训练权重微调到新构建的数据集，并将其与犯罪调查知识库检索方法相结合。实验结果表明，LAPIS 有潜力为警察提供可靠的法律指导，甚至比专有的 GPT-4 模型更好。对 LAPIS 生成的理由的定性分析证明了该模型的推理能力，可以利用前提并得出合法的结论。]]></description>
      <guid>https://arxiv.org/abs/2407.20248</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:22 GMT</pubDate>
    </item>
    <item>
      <title>早期退出大型语言模型的有效推理框架</title>
      <link>https://arxiv.org/abs/2407.20272</link>
      <description><![CDATA[arXiv:2407.20272v1 公告类型：新
摘要：构建高效的推理框架已引起研究界越来越多的关注。早期退出模型是 LLM 的一种变体，它通过跳过其余层并在足够自信时直接生成输出标记来提高 LLM 的推理效率。但是，没有将早期退出模型考虑在内的 LLM 推理框架工作。这并不简单，因为 LLM 推理的现有技术不能直接应用于早期退出模型。在这项工作中，我们解决了为早期退出模型构建高效推理框架的两个关键挑战：（1）迭代级粒度的批量推理；（2）KV 缓存管理。对于前者，我们建议处理批处理，直到所有序列都超过早期退出置信度阈值。对于后者，我们建议在迭代终止之前填充其余层的 KV 缓存。我们的评估表明，与原始全层运行的 vLLM 相比，我们的解决方案实现了高达 1.25 倍的速度提升。]]></description>
      <guid>https://arxiv.org/abs/2407.20272</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:22 GMT</pubDate>
    </item>
    <item>
      <title>Matryoshka-Adaptor：针对较小嵌入维度的无监督和监督调整</title>
      <link>https://arxiv.org/abs/2407.20243</link>
      <description><![CDATA[arXiv:2407.20243v1 公告类型：新
摘要：大型语言模型 (LLM) 的嵌入已成为各种应用中的关键组件，尤其是用于信息检索。虽然高维嵌入通常表现出卓越的性能，因为它们包含更显着的信息，但它们的实际应用经常受到增加的计算延迟和相关的更高成本的阻碍。为了应对这些挑战，我们提出了 Matryoshka-Adaptor，这是一种专为定制 LLM 嵌入而设计的新型调整框架。Matryoshka-Adaptor 有助于大幅降低维数，同时保持可比的性能水平，从而显着提高计算效率和成本效益。我们的框架直接修改了预训练 LLM 的嵌入，旨在与任何 LLM 架构无缝集成，包括那些仅通过黑盒 API 访问的架构。此外，它在无监督和监督学习环境中都表现出功效。对多种英语、多语言和多模态数据集进行的严格评估一致表明，Matryoshka-Adaptor 可带来显著的收益。值得注意的是，借助 Google 和 OpenAI Embedding API，Matryoshka-Adaptor 可将维度降低 2 到 12 倍，同时不会影响多个 BEIR 数据集的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.20243</guid>
      <pubDate>Thu, 01 Aug 2024 03:16:21 GMT</pubDate>
    </item>
    </channel>
</rss>