<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Fri, 19 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>TriForce：使用分层推测解码对长序列生成进行无损加速</title>
      <link>https://arxiv.org/abs/2404.11912</link>
      <description><![CDATA[arXiv:2404.11912v1 公告类型：新
摘要：随着大型语言模型（LLM）近年来在长内容生成中的广泛部署，对高效长序列推理支持的需求日益增长。然而，存储键值（KV）缓存以避免重新计算，其大小随着序列长度线性增长，已成为关键瓶颈。由于LLM的自回归性质，将为每个生成的令牌加载整个KV缓存，导致计算核心利用率低和延迟高。虽然已经提出了各种 KV 缓存压缩方法来缓解这个问题，但它们的生成质量会下降。我们引入了 TriForce，这是一种分层推测解码系统，可扩展至长序列生成。这种方法通过检索利用原始模型权重和动态稀疏 KV 缓存作为草稿模型，充当层次结构中的中间层，并由较小的模型进一步推测以减少其草稿延迟。 TriForce 不仅为 Llama2-7B-128K 提供了令人印象深刻的加速，在 A100 GPU 上实现了高达 2.31$\times$，而且还展示了处理更长上下文的可扩展性。对于两个 RTX 4090 GPU 上的卸载设置，TriForce 实现了 0.108s/token$\unicode{x2014}$，仅比 A100 上的自回归基线慢一半，在我们优化的卸载系统上达到 7.78$\times$。此外，TriForce 在单个 RTX 4090 GPU 上的执行速度比 DeepSpeed-Zero-Inference 快 4.86$\times$。 TriForce 的坚固性因其在各种温度下始终如一的出色性能而得以凸显。该代码可在 https://github.com/Infini-AI-Lab/TriForce 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.11912</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>SKIP：技能本地化提示调整以提升推理速度</title>
      <link>https://arxiv.org/abs/2404.11916</link>
      <description><![CDATA[arXiv:2404.11916v1 公告类型：新
摘要：在各种自然语言理解任务中，即时调优方法已显示出与参数高效微调（PEFT）方法相当的性能。然而，现有的即时调优方法仍然利用整个模型架构；因此，它们无法加快应用程序中的推理速度。在本文中，我们提出了一种称为 SKIll 局部提示调整（SKIP）的新方法，该方法在推理时间上非常有效。我们的方法通过研究和利用语言模型中的技能本地化子网络显着提高了推理效率。令人惊讶的是，我们的方法将推理速度提高了 160%，同时修剪了 52% 的参数。此外，我们证明我们的方法适用于各种基于变压器的架构，从而证实了其实用性和可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2404.11916</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:19 GMT</pubDate>
    </item>
    <item>
      <title>AdvisorQA：利用集体智慧实现有益且无害的寻求建议的问答</title>
      <link>https://arxiv.org/abs/2404.11826</link>
      <description><![CDATA[arXiv:2404.11826v1 公告类型：新
摘要：随着大型语言模型融入日常生活的趋势不断增加，针对主观和个人困境提供建议的基准存在明显差距。为了解决这个问题，我们推出了 AdvisorQA，这是第一个为评估法学硕士利用 LifeProTips Reddit 子论坛为深度个性化问题提供建议的能力而开发的基准。该论坛以动态互动为特色，用户发布咨询问题，平均每次查询收到8.9条建议，数百名用户点赞164.2条，体现了集体智慧框架。因此，我们完成了一个包含日常生活问题、多样化的相应回答和多数投票排名的基准来训练我们的帮助指标。基线实验通过我们的有用性指标、GPT-4 和人类评估来验证 AdvisorQA 的功效，分析超出有用性和无害性之间权衡的现象。 AdvisorQA 标志着增强 QA 系统的重大飞跃，可提供个性化、同理心的建议，展示法学硕士对人类主观性的更好理解。]]></description>
      <guid>https://arxiv.org/abs/2404.11826</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>挑战消极的性别刻板印象：自动反刻板印象有效性研究</title>
      <link>https://arxiv.org/abs/2404.11845</link>
      <description><![CDATA[arXiv:2404.11845v1 公告类型：新
摘要：性别刻板印象是基于性别的个人普遍信念，在塑造社会态度、行为甚至机会方面发挥着重要作用。认识到性别刻板印象的负面影响，特别是在在线交流中，本研究调查了十一种自动反击和挑战这些观点的策略。我们向（自我认定的）男性和女性研究参与者展示人工智能生成的基于性别的反刻板印象，并要求他们评估其冒犯性、合理性和潜在有效性。反事实和扩大普遍性的策略（即指出任何人都可以拥有某种特质，无论群体成员身份如何）成为最有力的方法，而幽默、换位思考、反例和对演讲者的同理心被认为是最有效的方法。效果较差。此外，对于不同目标的刻板印象导致的评级差异比评级者性别之间的差异更为明显。令人担忧的是，许多人工智能生成的反刻板印象被认为具有攻击性和/或难以置信。我们的分析和收集的数据集为反刻板印象的产生提供了基础见解，指导未来制定有效挑战在线互动中性别刻板印象的策略。]]></description>
      <guid>https://arxiv.org/abs/2404.11845</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:18 GMT</pubDate>
    </item>
    <item>
      <title>REQUAL-LM：通过大型语言模型中的聚合实现可靠性和公平性</title>
      <link>https://arxiv.org/abs/2404.11782</link>
      <description><![CDATA[arXiv:2404.11782v1 公告类型：新
摘要：大语言模型 (LLM) 跨各个领域的广泛范围强调了责任在自然语言处理之外的应用中的至关重要性。特别是，法学硕士的随机性，加上数据中固有的偏见和历史刻板印象，引起了人们对可靠性和公平性的严重担忧。在将法学硕士用于具有社会影响的应用之前，必须解决这些挑战。为了解决这一差距，我们引入了 REQUAL-LM，这是一种通过聚合寻找可靠且公平的 LLM 输出的新方法。具体来说，我们开发了一种基于重复采样的蒙特卡罗方法，以找到接近可能输出的基础分布平均值的可靠输出。我们正式定义了可靠性和偏差等术语，并设计了一个公平意识聚合，以最大限度地减少有害偏差，同时找到高度可靠的输出。 REQUAL-LM 不需要专门的硬件，不会施加大量的计算负载，并将 LLM 用作黑匣子。这种设计选择可实现无缝可扩展性以及法学硕士技术的快速发展。我们的系统不需要重新培训法学硕士，这使得它可以部署并易于适应。我们使用各种任务和数据集进行的综合实验表明，REQUAL-LM 有效地减轻了偏见并选择了更公平的响应，特别是正确代表少数群体的输出。]]></description>
      <guid>https://arxiv.org/abs/2404.11782</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>增强论点总结：优先考虑关键点生成的详尽性并引入自动覆盖率评估指标</title>
      <link>https://arxiv.org/abs/2404.11793</link>
      <description><![CDATA[arXiv:2404.11793v1 公告类型：新
摘要：社交媒体平台的激增引发了网上辩论和争论的数量。因此，此类辩论迫切需要自动摘要方法，但是这一摘要领域的研究还相当不足。关键点分析 (KPA) 任务将论点摘要表述为以项目符号格式的简洁句子形式表示大量论点的摘要，称为关键点。 KPA 的一个子任务称为关键点生成 (KPG)，重点是在给定参数的情况下生成这些关键点。本文介绍了一种新颖的关键点生成提取方法，该方法优于以前最先进的任务方法。我们的方法采用基于提取聚类的方法，提供简洁、高质量的生成关键点，具有更高的参考摘要覆盖率和更少的冗余输出。此外，我们还表明，现有的摘要评估指标（例如 ROUGE）无法区分生成的不同质量的关键点。为此，我们提出了一种新的评估指标，用于通过覆盖范围来评估生成的关键点。我们的代码可以在线访问。]]></description>
      <guid>https://arxiv.org/abs/2404.11793</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>通过共轭共享复杂空间中知识图嵌入的参数</title>
      <link>https://arxiv.org/abs/2404.11809</link>
      <description><![CDATA[arXiv:2404.11809v1 公告类型：新
摘要：知识图（KG）是现实世界中实体和关系的有向图形表示。 KG 可应用于需要知识的各种自然语言处理 (NLP) 任务。扩展和完成知识图谱的需求自动产生了知识图嵌入（KGE），这是一种浅层机器学习模型，但存在内存和训练时间消耗问题。为了减轻计算负载，我们提出了一种参数共享方法，即对 KGE 模型中使用的复数使用共轭参数。我们的方法将关系嵌入的内存效率提高了 2 倍，同时实现了与最先进的非共轭模型相当的性能，并且训练时间更快或至少相当。我们在五个基准数据集上的两个性能最佳的 KGE 模型 $5^{\bigstar}\mathrm{E}$ 和 $\mathrm{ComplEx}$ 上证明了我们的方法的通用性。]]></description>
      <guid>https://arxiv.org/abs/2404.11809</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:17 GMT</pubDate>
    </item>
    <item>
      <title>错过的联系：大型语言模型的横向思维难题</title>
      <link>https://arxiv.org/abs/2404.11730</link>
      <description><![CDATA[arXiv:2404.11730v1 公告类型：新
摘要：《纽约时报》每天发布的“连接”谜题要求玩家将一组 16 个单词分成四组，每组四个单词，每个组与一个共同主题相关。解决这个难题不仅需要通用的语言知识（即定义和典型用法），而且在许多情况下还需要横向或抽象思维。这是因为这四个类别的复杂性不断上升，最具挑战性的类别通常需要以不常见的方式思考单词或将其作为较大短语的一部分。我们研究了自动化人工智能系统玩《Connections》的能力，并探索该游戏作为抽象推理自动化基准的潜力，以及衡量数据驱动语言系统编码的语义信息的方法。特别是，我们研究了句子嵌入基线和现代大型语言模型（LLM）。我们报告他们对任务的准确性，衡量思维链提示的影响，并讨论他们的失败模式。总的来说，我们发现连接任务具有挑战性但又可行，并且是未来工作的强大测试平台。]]></description>
      <guid>https://arxiv.org/abs/2404.11730</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>绘制暴力地图：开发一个广泛的框架，通过社交媒体互动构建孟加拉语宗派表达数据集</title>
      <link>https://arxiv.org/abs/2404.11752</link>
      <description><![CDATA[arXiv:2404.11752v1 公告类型：新
摘要：在南亚，网络论坛中的社区暴力极为普遍，不同文化的许多社区共存并共享资源。这些社会表现出一种现象，其特点是自身群体内部的牢固联系和对他人的敌意，导致冲突经常升级为暴力对抗。为了解决这个问题，我们开发了第一个综合框架，用于自动检测在线孟加拉语内容中的社区暴力标记，这些内容伴随着最大的社交媒体互动集合（13K 原始句子），这些互动属于四个主要暴力类别及其 16 个暴力类别的定义。粗俗的表达。我们的工作流程引入了 7 个步骤的专家注释流程，融合了社会科学家、语言学家和心理学家的见解。通过使用该数据集提供数据统计和基准测试性能，我们确定，除了非社区暴力类别外，宗教社区暴力在孟加拉语文本中尤其普遍。此外，我们通过对最先进的孟加拉深度学习模型进行初步基准测试，证实了微调语言模型在识别暴力评论方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.11752</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>语言模型仍然难以对时间序列进行零样本推理</title>
      <link>https://arxiv.org/abs/2404.11757</link>
      <description><![CDATA[arXiv:2404.11757v1 公告类型：新
摘要：时间序列对于金融和医疗保健等领域的决策至关重要。它们的重要性推动了最近大量将时间序列传递到语言模型中的工作，从而对某些数据集进行了重要的预测。但不平凡的预测是否意味着语言模型可以推理时间序列仍然未知。为了解决这一差距，我们生成了一个用于时间序列推理的首个评估框架，包括正式任务和相应的多尺度时间序列数据集，并与十个领域的文本标题配对。使用这些数据，我们探讨语言模型是否实现了三种形式的推理：（1）病因推理 - 给定输入时间序列，语言模型能否识别最有可能创建它的场景？ (2) 问答——语言模型能否回答有关时间序列的事实问题？ (3) 上下文辅助预测 - 高度相关的文本上下文是否可以改善语言模型的时间序列预测？
  我们发现，其他功能强大的语言模型表现出令人惊讶的有限时间序列推理：它们在病因学和问答任务上的得分略高于随机得分（比人类差 30 个百分点），并且在使用上下文来改进预测方面取得了一定的成功。这些弱点表明，时间序列推理是语言模型研究的一个有影响力但尚未充分发展的方向。我们还将我们的数据集和代码公开，以支持该方向的进一步研究：https://github.com/behavioral-data/TSandLanguage]]></description>
      <guid>https://arxiv.org/abs/2404.11757</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:16 GMT</pubDate>
    </item>
    <item>
      <title>使用自然语言处理改进语义地址匹配</title>
      <link>https://arxiv.org/abs/2404.11691</link>
      <description><![CDATA[arXiv:2404.11691v1 公告类型：新
摘要：地址匹配对于许多企业尤其是送货和外卖公司来说是一项重要任务，可以帮助他们从数据仓库中取出某个地址。现有的解决方案使用字符串的相似度和编辑距离算法来从地址数据库中找出相似的地址，但这些算法不能有效地处理冗余、非结构化或不完整的地址数据。本文讨论语义地址匹配技术，通过该技术我们可以从可能的地址列表中找出特定的地址。我们还审查了现有做法及其缺点。语义地址匹配本质上是深度学习领域的 NLP 任务。通过这种技术，我们有能力克服现有方法的缺点，例如冗余或缩写数据问题。该解决方案使用发票上的 OCR 来提取地址并创建地址数据池。然后，该数据被馈送到算法 BM-25，以对最佳匹配条目进行评分。然后为了观察最佳结果，将通过 BERT 来从类似查询中给出最佳结果。我们的调查表明，我们的方法极大地提高了尖端技术现有技术的准确性和审查。]]></description>
      <guid>https://arxiv.org/abs/2404.11691</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>自然语言推理中由于释义变异性而导致的错误有多常见？</title>
      <link>https://arxiv.org/abs/2404.11717</link>
      <description><![CDATA[arXiv:2404.11717v1 公告类型：新
摘要：大型语言模型已被证明在响应保留意义的释义输入时表现不一致。与此同时，研究人员通过测试评估来评估这些模型的知识和推理能力，这些测试评估不会分解释义变异对性能的影响。我们提出了一种评估自然语言推理模型的释义一致性的指标，该指标基于模型在同一问题的两个释义上实现相同正确性的概率。我们在数学上将该指标与模型因释义而导致的正确性方差的比例联系起来。为了估计释义一致性，我们收集了 ParaNLU，这是一个包含 7,782 个人工编写并经过验证的释义推理问题的数据集，构建在现有基准数据集之上，用于可废止和溯因自然语言推理。使用 ParaNLU，我们测量了几个模型类的释义一致性，并表明一致性随着预训练而不是微调而显着增加。所有测试的模型在释义一致性方面都有改进的空间。]]></description>
      <guid>https://arxiv.org/abs/2404.11717</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>调查土耳其语言模型中的性别偏见</title>
      <link>https://arxiv.org/abs/2404.11726</link>
      <description><![CDATA[arXiv:2404.11726v1 公告类型：新
摘要：语言模型主要在网络数据上进行训练，这些数据通常包含模型可以继承的社会刻板印象和偏见。这可能会产生负面后果，因为模型可能会放大下游任务或应用程序中的这些偏差。然而，之前的研究主要集中在英语，特别是在性别偏见的背景下。特别是，语法上性别中立的语言（例如土耳其语）尽管代表了语言模型的不同语言属性，并且可能对偏见产生不同的影响，但尚未得到充分研究。在本文中，我们填补了这一研究空白，并研究了土耳其语言模型中性别偏见的重要性。我们以现有的偏见评估框架为基础，通过翻译现有的英语测试并创建新的测试来衡量土耳其语背景下的性别偏见，并将其扩展到土耳其语。具体来说，我们还评估土耳其语言模型中嵌入的种族偏见根据实验结果，我们将可能的偏见归因于不同的模型特征，例如模型大小、多语言能力和训练语料库。我们公开了土耳其性别偏见数据集。]]></description>
      <guid>https://arxiv.org/abs/2404.11726</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:15 GMT</pubDate>
    </item>
    <item>
      <title>MemLLM：微调 LLM 以使用显式读写内存</title>
      <link>https://arxiv.org/abs/2404.11672</link>
      <description><![CDATA[arXiv:2404.11672v1 公告类型：新
摘要：虽然当前的大型语言模型（LLM）在知识密集型任务中展示了一些功能，但它们由于依赖参数作为隐式存储机制而受到限制。结果，他们与稀少的知识和暂时的退化作斗争。此外，参数记忆的不可解释性使得理解和预防幻觉变得困难。参数化内存池和模型编辑只是部分解决方案。检索增强生成（RAG）$\unicode{x2013}$虽然非参数$\unicode{x2013}$有其自身的局限性：它缺乏结构，使可解释性复杂化并且难以有效管理存储的知识。在本文中，我们介绍了 MemLLM，这是一种通过集成结构化和显式读写内存模块来增强 LLM 的新方法。 MemLLM 通过实现与内存的动态交互并提高 LLM 使用存储知识的能力来解决上述挑战。我们的实验表明，MemLLM 增强了法学硕士的性能和可解释性，特别是在一般语言建模和知识密集型任务中。我们认为 MemLLM 是通过记忆增强使法学硕士更加扎实和真实的重要一步。]]></description>
      <guid>https://arxiv.org/abs/2404.11672</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:14 GMT</pubDate>
    </item>
    <item>
      <title>你能清楚地表达这个想法吗？自动化形成性评估的见解</title>
      <link>https://arxiv.org/abs/2404.11682</link>
      <description><![CDATA[arXiv:2404.11682v1 公告类型：新
摘要：自动化方法越来越多地融入到学生科学解释写作形成性反馈的研究中。然而，这项工作的大部分内容都是针对学生对简答题的回答。我们调查了对学生科学解释论文的自动反馈，学生必须在论文中阐明多种想法。反馈基于一个标题，该标题确定了学生在进行模拟过山车实验时被提示将其纳入有关能量和质量物理的解释性文章中的主要想法。我们发现，学生们通常会在论文的修改版本上取得进步。然而，在这里，我们关注影响自动反馈准确性的两个因素。首先，我们发现标题中的主要思想在解释思想时提供的自由度方面有所不同，因此对自然法的解释相对受到限制。学生可以更自由地解释在过山车中观察到的复杂关系，例如不同形式能量的传递。其次，通过跟踪自动决策过程，我们可以诊断学生的陈述何时缺乏足够的清晰度，使自动化工具无法将其与主要思想之一更紧密地联系起来。这反过来又为老师和同学提供了一个机会，帮助学生思考如何更清楚地表达自己的想法。]]></description>
      <guid>https://arxiv.org/abs/2404.11682</guid>
      <pubDate>Fri, 19 Apr 2024 06:17:14 GMT</pubDate>
    </item>
    </channel>
</rss>