<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 17 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>公平语言模型悖论</title>
      <link>https://arxiv.org/abs/2410.11985</link>
      <description><![CDATA[arXiv:2410.11985v1 公告类型：新
摘要：大型语言模型 (LLM) 广泛应用于实际应用，但人们对其在 token 级别的训练动态知之甚少。评估通常依赖于在批次级别测量的聚合训练损失，这忽略了由 (i) 不同的 token 级别动态和 (ii) 超参数引入的结构偏差引起的细微的 token 偏差。虽然权重衰减通常用于稳定训练，但我们发现它会悄悄地引入仅在 token 级别可检测到的性能偏差。事实上，我们通过经验证明，在不同数据集大小、模型架构和从 270M 到 3B 参数的大小范围内，随着权重衰减的增加，低频 token 会不成比例地贬值。这尤其令人担忧，因为这些被忽视的低频 token 代表了大多数语言中 token 分布的绝大多数，需要新的正则化技术来确保所有可用 token 的公平性。]]></description>
      <guid>https://arxiv.org/abs/2410.11985</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DISP-LLM：大型语言模型的维度独立结构修剪</title>
      <link>https://arxiv.org/abs/2410.11988</link>
      <description><![CDATA[arXiv:2410.11988v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种自然语言处理任务中取得了显著成功，包括语言建模、理解和生成。然而，与这些模型相关的增加的内存和计算成本对在资源有限的设备上部署构成了重大挑战。结构修剪已成为一种有前途的解决方案，可以在不需要后处理步骤的情况下降低 LLM 的成本。先前的结构修剪方法要么以限制灵活性为代价遵循结构的依赖性，要么通过合并不同的投影矩阵引入非平凡的附加参数。在这项工作中，我们提出了一种新方法，它放宽了常规结构修剪方法施加的约束并消除了沿嵌入维度的结构依赖性。我们的维度无关的结构修剪方法提供了几个好处。首先，我们的方法使不同的块能够利用特征图的不同子集。其次，通过消除结构依赖性，我们使每个块在其输入和输出维度上具有不同的宽度，从而显著增强了结构修剪的灵活性。我们在各种 LLM 上评估了我们的方法，包括 OPT、LLaMA、LLaMA-2、Phi-1.5 和 Phi-2。实验结果表明，我们的方法优于其他最先进的方法，首次表明结构修剪可以达到与半结构修剪相似的准确率。]]></description>
      <guid>https://arxiv.org/abs/2410.11988</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用长上下文语言模型进行整体推理：海量文本数据数据库操作的基准</title>
      <link>https://arxiv.org/abs/2410.11996</link>
      <description><![CDATA[arXiv:2410.11996v1 公告类型：新
摘要：文本信息的快速增长意味着我们需要更有效的方法来筛选、组织和理解所有信息。虽然检索增强生成 (RAG) 模型擅长从大型文档集合中访问信息，但它们在处理需要对跨多​​个文档的信息进行聚合和推理的复杂任务时却举步维艰——我们称之为整体推理。长上下文语言模型 (LCLM) 在管理大型文档方面具有巨大潜力，但它们的整体推理能力仍不清楚。在这项工作中，我们引入了 HoloBench，这是一个新颖的框架，它将数据库推理操作带入基于文本的上下文中，使系统地评估 LCLM 如何处理大型文档中的整体推理变得更加容易。我们的方法调整了上下文长度、信息密度、信息分布和查询复杂度等关键因素，以全面评估 LCLM。我们的实验表明，上下文中的信息量对 LCLM 性能的影响大于实际上下文长度。此外，查询的复杂性对性能的影响大于信息量，尤其是对于不同类型的查询。有趣的是，涉及查找最大值或最小值的查询对于 LCLM 来说更容易，并且受上下文长度的影响较小，即使它们对 RAG 系统构成了挑战。但是，随着上下文长度的增加，需要聚合多条信息的任务的准确性会明显下降。此外，我们发现，虽然对相关信息进行分组通常会提高性能，但最佳定位因模型而异。我们的研究结果揭示了在实现对长上下文的整体理解方面取得的进步和持续面临的挑战。]]></description>
      <guid>https://arxiv.org/abs/2410.11996</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>持续的法律预训练和 IFT 对法学硕士对人类定义的法律概念的潜在表征的影响</title>
      <link>https://arxiv.org/abs/2410.12001</link>
      <description><![CDATA[arXiv:2410.12001v1 公告类型：新
摘要：本文旨在让 AI 和法律研究人员和从业者更详细地了解在开发输入序列的全局上下文表示时，对法律语料库上的大型语言模型 (LLM) 进行持续的预训练和指令微调 (IFT) 是否以及如何增加他们对人类定义的法律概念的利用。我们比较了三种模型：Mistral 7B、SaulLM-7B-Base（Mistral 7B 在法律语料库上继续进行预训练）和 SaulLM-7B-Instruct（进一步进行 IFT）。这项初步评估检查了最近 AI 和法律文献中的 7 个不同文本序列，每个序列都包含一个人类定义的法律概念。我们首先比较了模型分配给代表法律概念的标记子集的总注意力比例。然后，我们可视化了原始注意力得分变化的模式，评估法律培训是否引入了与人类法律知识结构相对应的新注意力模式。这项调查显示：(1) 法律培训的影响在各种人类定义的法律概念中分布不均；(2) 法律培训期间学习的法律知识的语境表征与人类定义的法律概念的结构不一致。最后，我们提出了进一步研究法律 LLM 培训动态的建议。]]></description>
      <guid>https://arxiv.org/abs/2410.12001</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Toolken+：通过重新排序和拒绝选项改善 LLM 工具的使用</title>
      <link>https://arxiv.org/abs/2410.12004</link>
      <description><![CDATA[arXiv:2410.12004v1 公告类型：新
摘要：最近提出的 ToolkenGPT 工具学习范例表现出色，但存在两个主要问题：首先，它无法从工具文档中受益，其次，它经常在是否使用工具方面犯错误。我们引入了 Toolken+，它通过重新排序 ToolkenGPT 选择的前 $k$ 个工具来缓解第一个问题，并使用特殊的“拒绝”选项缓解第二个问题，这样如果“拒绝”排名第一，模型将生成词汇标记。我们展示了 Toolken+ 在多步数值推理和工具选择任务中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.12004</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>像素学：探索基于像素的语言模型的语言和视觉能力</title>
      <link>https://arxiv.org/abs/2410.12011</link>
      <description><![CDATA[arXiv:2410.12011v1 公告类型：新
摘要：基于像素的语言模型已成为基于子词的语言建模的有力替代方案，特别是因为它们几乎可以表示任何脚本。PIXEL 是此类模型的典型示例，它是一种已在渲染文本上进行预训练的视觉转换器。虽然 PIXEL 表现出良好的跨脚本传输能力和对正字法扰动的鲁棒性，但在大多数其他情况下，它的表现都不如 BERT 等单语子词对应物。这种差异引发了人们对这些模型学习的语言知识量以及它们在语言任务中的表现是否更多地源于其视觉能力而非语言能力的质疑。为了探索这一点，我们使用各种语言和视觉任务来探测 PIXEL，以评估其在视觉到语言频谱中的位置。我们的研究结果揭示了模型的视觉和语言理解之间存在巨大差距。 PIXEL 的较低层主要捕捉表面视觉特征，而较高层则逐渐学习更多句法和语义抽象。此外，我们研究了使用不同文本渲染策略训练的 PIXEL 变体，发现在输入级别引入某些正字法约束可以促进更早地学习表面级特征。通过这项研究，我们希望提供有助于进一步开发基于像素的语言模型的见解。]]></description>
      <guid>https://arxiv.org/abs/2410.12011</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MoE-Pruner：使用来自路由器的提示修剪混合专家大型语言模型</title>
      <link>https://arxiv.org/abs/2410.12013</link>
      <description><![CDATA[arXiv:2410.12013v1 公告类型：新
摘要：混合专家 (MoE) 架构面临着诸如高内存消耗和专家冗余等挑战。修剪 MoE 可以减少网络权重，同时保持模型性能。受最近观察到的大型语言模型 (LLM) 和 MoE 路由策略中出现的大幅度特征的启发，我们提出了 MoE-Pruner，这是一种在每个输出神经元上修剪具有最小幅度的权重乘以相应输入激活和路由器权重的方法。我们的修剪方法是一次性的，不需要重新训练或权重更新。我们在多个语言基准上在 Mixtral-8x7B 和 Mixtral-8x22B 上评估了我们的方法。实验结果表明，我们的修剪方法明显优于最先进的 LLM 修剪方法。此外，我们修剪后的 MoE 模型可以通过专家知识提炼从预训练的教师模型中受益，从而提高修剪后的性能。实验结果表明，稀疏度为 50% 的 Mixtral-8x7B 模型在专家知识提炼后保持了原始模型 99% 的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.12013</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>文化分析中大型语言模型的分类</title>
      <link>https://arxiv.org/abs/2410.12029</link>
      <description><![CDATA[arXiv:2410.12029v1 公告类型：新
摘要：在这项工作中，我们调查了分类在文化分析中作为一种意义建构实践的使用方式，并评估了大型语言模型在这个领域的适用范围。我们确定了十个由公开数据集支持的任务，并根据这些任务对 LLM 与传统监督方法相比的性能进行了实证评估，并探索了 LLM 除了准确性之外还可用于意义建构目标的方式。我们发现，基于提示的 LLM 在既定任务上与传统监督模型具有竞争力，但在从头任务上表现较差。此外，LLM 可以作为正式理论测试的中介输入来协助意义建构。]]></description>
      <guid>https://arxiv.org/abs/2410.12029</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>概念逆向 Winograd 模式挑战：通过抽象评估和改进大型语言模型中的稳健推理</title>
      <link>https://arxiv.org/abs/2410.12040</link>
      <description><![CDATA[arXiv:2410.12040v1 公告类型：新
摘要：虽然大型语言模型 (LLM) 已经展示了卓越的推理能力，但人们仍然担心由于语义关联和肤浅的逻辑链而导致的幻觉和不可靠的推理问题。为了评估 LLM 在多大程度上能够执行稳健的推理而不是依赖肤浅的逻辑链，我们提出了一个新的评估数据集，即概念反转 Winograd 模式挑战 (CR-WSC)，它基于著名的 Winograd 模式挑战 (WSC) 数据集。通过简单地将概念反转为与错误答案更相关的概念，我们发现 LLM 的性能会显着下降，尽管推理的基本原理保持不变。此外，我们提出了抽象思维 (AoT)，这是一种新颖的快速方法，使用概念抽象将对抗性案例恢复为正常案例，以提高 LLM 在推理中的稳健性和一致性，如 CR-WSC 上的实验所证明的那样。]]></description>
      <guid>https://arxiv.org/abs/2410.12040</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过逻辑圣诞树增强法学硕士中的逻辑谬误推理</title>
      <link>https://arxiv.org/abs/2410.12048</link>
      <description><![CDATA[arXiv:2410.12048v1 公告类型：新
摘要：逻辑谬误在陈述的构建中使用无效或错误的推理。尽管逻辑谬误普遍存在且危害巨大，但检测和分类逻辑谬误仍然是一项具有挑战性的任务。我们观察到逻辑谬误经常使用连接词来表示两个论据之间的预期逻辑关系，而论据语义实际上并不支持该逻辑关系。受此观察的启发，我们提出构建一个逻辑圣诞树来明确表示和跟踪陈述中关系连接词及其论据之间的层次逻辑流。具体而言，该逻辑圣诞树以无监督的方式构建，由构成树和十种常见逻辑关系的连接词分类法指导，关系连接词为非终端节点，文本论据为终端节点，后者大多是基本话语单位。我们进一步开发了两种策略，将逻辑圣诞树纳入 LLM 进行谬误推理。首先，我们将树转换为自然语言描述，并将文本化的树作为硬文本提示的一部分输入到 LLM 中。其次，我们推导出一个关系感知树嵌入，并将树嵌入作为软提示插入到 LLM 中。在基准数据集上的实验表明，我们基于逻辑树木的方法显著提高了谬误检测和谬误分类的准确率和召回率。]]></description>
      <guid>https://arxiv.org/abs/2410.12048</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Sabi\'a-3 技术报告</title>
      <link>https://arxiv.org/abs/2410.12049</link>
      <description><![CDATA[arXiv:2410.12049v1 公告类型：新
摘要：本报告介绍了 Sabi\&#39;a-3，这是我们在以巴西为中心的大型语料库上训练的新旗舰语言模型。跨各种专业和学术基准的评估表明，该模型在葡萄牙语和巴西相关任务上表现出色。与我们之前的最佳模型 Sabi\&#39;a-2 Medium 相比，Sabi\&#39;a-3 显示出很大的改进，尤其是在推理密集型任务中。值得注意的是，Sabi\&#39;a-3 的平均性能与前沿 LLM 相匹配，而其每个 token 的成本却低三到四倍，这进一步增强了领域专业化的优势。]]></description>
      <guid>https://arxiv.org/abs/2410.12049</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>技能法学硕士：将通用法学硕士重新用于技能提取</title>
      <link>https://arxiv.org/abs/2410.12052</link>
      <description><![CDATA[arXiv:2410.12052v1 公告类型：新
摘要：从职位描述中准确提取技能对于招聘过程至关重要，但仍然具有挑战性。命名实体识别 (NER) 是解决此问题的常用方法。随着大型语言模型 (LLM) 在包括 NER 在内的各种 NLP 任务中的成功应用，我们建议对专门的 Skill-LLM 和轻量级模型进行微调，以提高技能提取的精度和质量。在我们的研究中，我们使用基准数据集评估了微调的 Skill-LLM 和轻量级模型，并将其性能与最先进 (SOTA) 方法进行了比较。我们的结果表明，这种方法优于现有的 SOTA 技术。]]></description>
      <guid>https://arxiv.org/abs/2410.12052</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>最先进的古希腊语形态句法分析器和词形还原器</title>
      <link>https://arxiv.org/abs/2410.12055</link>
      <description><![CDATA[arXiv:2410.12055v1 公告类型：新
摘要：本文提出了一项实验，该实验对六种模型进行了比较，以确定一种最先进的古希腊语形态句法解析器和词形还原器，该解析器能够根据古希腊语依存树库注释方案进行注释。主要注释文本集合的规范化版本用于 (i) 使用随机初始化的字符嵌入训练基线模型 Dithrax 和 (ii) 对 Trankit 和四个最近在古希腊语文本上进行预训练的模型进行微调，即用于形态句法注释的 GreBERTa 和 PhilBERTa 以及用于词形还原的 GreTA 和 PhilTa。贝叶斯分析表明，Dithrax 和 Trankit 对形态的注释几乎是等效的，而语法最好由 Trankit 注释，词形还原最好由 GreTa 注释。实验结果表明，除非将 token 嵌入与专门用于捕获句法关系的建模策略相结合，否则 token 嵌入不足以实现较高的 UAS 和 LAS 分数。数据集和性能最佳的模型可在线重复使用。]]></description>
      <guid>https://arxiv.org/abs/2410.12055</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大规模完形填空评估表明，标记预测任务在词汇和语义上都不一致</title>
      <link>https://arxiv.org/abs/2410.12057</link>
      <description><![CDATA[arXiv:2410.12057v1 公告类型：新
摘要：在这项工作中，我们通过将几种语言模型与完形填空任务中的人类生成结果进行比较，比较了它们在下一个标记预测级别的生成行为。我们发现，虽然训练时间较长的大型模型通常可以更好地估计人类生成的结果，但它们确实低估了人类反应的概率，对罕见反应的排名过高，对顶级反应的排名过低，并产生了高度不同的语义空间。总之，这项工作在易于处理、可解释的领域证明了 LM 生成不能用作完形填空任务的替代品或模型。]]></description>
      <guid>https://arxiv.org/abs/2410.12057</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LegalLens 共享任务 2024：非结构化文本中的法律违规识别</title>
      <link>https://arxiv.org/abs/2410.12064</link>
      <description><![CDATA[arXiv:2410.12064v1 公告类型：新
摘要：本文介绍了 LegalLens 共享任务的结果，重点是通过两个子任务检测文本中的法律违规行为：LegalLens-NER 用于识别法律违规实体，LegalLens-NLI 用于将这些违规行为与相关法律背景和受影响的个人联系起来。使用增强的 LegalLens 数据集（涵盖劳动、隐私和消费者保护领域），38 个团队参与了这项任务。我们的分析表明，虽然使用了多种方法，但在这两项任务中表现最好的团队始终依赖于微调预训练语言模型，其表现优于法律特定模型和少量方法。表现最好的团队在 NER 上比基线提高了 7.11%，而 NLI 的改进幅度较小，为 5.7%。尽管取得了这些进步，但法律文本的复杂性仍留下了进一步进步的空间。]]></description>
      <guid>https://arxiv.org/abs/2410.12064</guid>
      <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>