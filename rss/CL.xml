<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Mon, 10 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>利用大型语言模型使用UNSPSC分类法优化项目分类</title>
      <link>https://arxiv.org/abs/2503.04728</link>
      <description><![CDATA[ARXIV：2503.04728V1公告类型：新 
摘要：有效的项目分类对于企业至关重要，可以使非结构化数据集转换为简化库存管理的有组织类别。尽管重要性很重要，但项目分类仍然高度主观，并且在行业和企业中缺乏统一的标准。联合国标准产品和服务代码（UNDPC）提供了一个标准化的系统来编目库存，但是采用UNSPSC分类通常需要大量的手动努力。本文研究了大型语言模型（LLMS）的部署，以根据项目描述将库存数据分类为UNSPSC代码。我们评估了LLM在分类各种数据集，探索其语言处理能力及其潜力作为标准化库存分类工具的潜力方面的准确性和效率。我们的发现表明，LLM可以大大减少项目分类中涉及的体力劳动，同时保持高精度，为努力增强其库存管理实践的企业提供可扩展的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2503.04728</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Winclick：GUI与多模式大语言模型进行</title>
      <link>https://arxiv.org/abs/2503.04730</link>
      <description><![CDATA[ARXIV：2503.04730V1公告类型：新 
摘要：图形用户界面（GUI）任务对于自动化工作流程，例如软件测试，用户界面导航至关重要。对于用户而言，GUI是与计算机交互的最直观平台。先前的工作确定了开发视觉GUI代理的关键挑战：GUI接地 - 根据说明准确定位屏幕元素的能力。但是，大多数现有的GUI代理都依赖于培训或推论中的DOM或HTML文件（例如DOM或HTML文件），这些数据格式在所有应用程序中都无法访问，尤其是在Windows OS等一般桌面环境中。为了解决这个问题，我们介绍了Winclick，这是Windows平台中开发的新型Visual GUI代理。 Winclick利用屏幕截图来检测可起作用的区域。为了克服GUI接地的挑战，我们通过GUI接地预训练增强了Winclick，并提出了一种基于LLM的方法来对齐GUI接地数据。此外，我们介绍了Winspot，这是在窗户上进行GUI接地的第一个综合基准。我们的实验表明，温克里克（Winclick）与GUI接地预训练相结合，明显优于现有基准，为桌面环境中的GUI自动化提供了可扩展的解决方案。 WinSpot可在https://github.com/zackhuiiiii/winspot上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2503.04730</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DIMA：DIDI的LLM驱车助手</title>
      <link>https://arxiv.org/abs/2503.04768</link>
      <description><![CDATA[ARXIV：2503.04768V1公告类型：新 
摘要：Didi，Uber和Lyft等按需乘车服务已改变了城市运输，提供了无与伦比的便利性和灵活性。在本文中，我们介绍了DiDi Chuxing部署的LLM驱车助手Dima。它的目标是在动态和复杂的时空城市环境下通过自然而有效的对话界面提供无缝的乘车服务。为了实现这一目标，我们提出了一个时空感知的订单计划模块，该模块利用外部工具来精确时空推理和渐进式订单计划。此外，我们开发了一种具有成本效益的对话系统，该系统将多类型对话框重新架集成到成本吸引的LLM配置，以处理多种对话目标以及权衡响应质量和延迟。此外，我们引入了一个持续的微调计划，该方案利用现实世界的交互和模拟对话将助手的行为与人类首选决策过程保持一致。由于DIMA在DIDI应用程序中的部署中的部署表现出了出色的性能，在订单计划中达到了93％的准确性，在现实世界中的互动过程中获得了92％的响应生成。离线实验进一步验证了DIMA功能，与三个最先进的代理框架相比，在订单计划中的提高高达70.23％，响应产生321.27％的提高，同时将延迟降低为$ 0.72 \ $ $ 5.47 \ $ 5.47 \ times $。这些结果将DIMA确定为乘车服务的有效，高效且聪明的移动助手。]]></description>
      <guid>https://arxiv.org/abs/2503.04768</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>城市中的无形墙：利用大型语言模型预测社交媒体内容的城市种族隔离经验</title>
      <link>https://arxiv.org/abs/2503.04773</link>
      <description><![CDATA[ARXIV：2503.04773V1公告类型：新 
摘要：了解城市日常生活中经验丰富的隔离对于解决社会不平等和培养包容性至关重要。社交媒体上的大量用户生成的评论囊括了与不同地方相关的细微看法和感受，从而提供了丰富的隔离见解。但是，利用这些数据构成了巨大的挑战，由于其众多，模棱两可和各种观点的融合。为了应对这些挑战，我们建议使用大型语言模型（LLM）自动化在线评论挖掘以进行隔离预测。我们设计了一个反思性的LLM编码器，以将社交媒体内容消化为与现实世界反馈一致的见解，并最终生成一个代码手册，捕获了信号隔离经验的关键维度，例如文化共鸣和吸引力，可及性，可访问性和便利性，社区参与和社区参与和本地参与。在代码簿的指导下，LLM可以同时生成内容丰富的审核摘要和隔离预测的评分。此外，我们设计了一个推理和插入（RE&#39;EM）框架，该框架结合了语言模型的推理和嵌入功能，以集成多通道特征以进行隔离预测。现实世界中数据的实验表明，我们的框架大大提高了预测准确性，R2的高度为22.79％，MSE降低了9.33％。此外，我们的用户研究确认，派生的代码本可以推广到三个不同的城市，从而不断提高预测准确性。除了代码手册引入的摘要为人类参与者带来认知收益，以感知POIS的社会包容性。您的研究标志着了解隐式社会障碍和不平等的重要步骤，展示了促进具有社会包容性的潜在潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.04773</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MV-CLAM：通过语言模型进行跨模式投影的多视图分子解释</title>
      <link>https://arxiv.org/abs/2503.04780</link>
      <description><![CDATA[ARXIV：2503.04780V1公告类型：新 
摘要：化学和生物医学方面的人类专业知识依赖于上下文分子的理解，大语言模型（LLM）可以通过分子结构和文本之间的细粒度对齐来扩展的能力。最近的多模式学习的进步集中在跨模式对齐方式上，但是现有的分子文本模型忽略了不同分子视图中的互补信息，而依靠单视图，从而限制了分子理解。此外，na \“我的多视图对齐策略面临两个挑战：（1）单独的对齐空间，分子和文本嵌入之间的映射不一致，并且（2）现有的损失目标无法保留互补的信息以保持细粒度对齐的互补信息。这可以限制LLM完全理解这些分子的能力。使用多Query Transformer（MQ-Former）进入统一的文本空间，我们的方法可确保跨视图的一致性。 https://github.com/sumin124/mv-clam.git。]]></description>
      <guid>https://arxiv.org/abs/2503.04780</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>孟加拉国假新闻探测基于多渠道的CNN-LSTM</title>
      <link>https://arxiv.org/abs/2503.04781</link>
      <description><![CDATA[ARXIV：2503.04781V1公告类型：新 
摘要：最近有许多未经验证或误导性信息在虚假网络网络和新闻门户网站上迅速传播的案例。这个错误的消息对社会造成了重大破坏，并误导了人们。例如，在2019年，有传言称孟加拉国的帕德玛桥需要100,000人的牺牲。这个谣言变成了致命的立场，这种误导性的信息赋予了无辜人民的生命。英语有很多工作，但在孟加拉国有一些作品。在这项研究中，我们将从未经考虑的新闻来源中确定虚假新闻，以向新闻阅读器提供自然新闻或真实新闻。该论文基于卷积神经网络（CNN）和长短期内存（LSTM）的组合，其中CNN用于深度特征提取，LSTM用于使用提取功能进行检测。我们部署这项工作的第一件事是数据收集。我们从网站编制了一个数据集，并尝试使用包含约50k新闻的深度学习方法来部署它。通过提出的多渠道模型结合了CNN-LSTM体系结构，我们的模型获得了75.05％的准确性，这是检测孟加拉假新闻的好兆头。]]></description>
      <guid>https://arxiv.org/abs/2503.04781</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于DeepSeek，Chatgpt和Google Gemini的比较分析：功能，技术，性能，未来前景</title>
      <link>https://arxiv.org/abs/2503.04783</link>
      <description><![CDATA[ARXIV：2503.04783V1公告类型：新 
摘要：如今，DeepSeek，Chatgpt和Google Gemini是推理，多模式能力和全球一般语言性能的最流行和令人兴奋的大型语言模型（LLM）技术。 DeepSeek采用了专家的混合物（MOE）方法，仅激活与手头任务最相关的参数，这使其对特定于域的工作特别有效。另一方面，Chatgpt依赖于通过从人类反馈（RLHF）学习增强的密集变压器模型，然后Google Gemini实际上使用了将文本，代码和图像集成到单个框架中的多模式变压器体系结构。但是，通过使用这些技术，人们可以通过具有成本效益和特定领域的推断来挖掘其所需的文本，代码，图像等。人们可以根据最佳性能选择这些技术。在这方面，我们在这项研究中提供了基于DeepSeek，Chatgpt和Gemini技术的比较研究。最初，我们专注于他们的方法和材料，适当地包括数据选择标准。然后，我们根据其应用程序介绍DeepSeek，Chatgpt和Gemini的最先进功能。最重要的是，我们显示了它们之间的技术比较，还涵盖了各种应用程序的数据集分析。最后，我们针对基于LLM的AI研究的广泛研究领域和未来的潜在指导。]]></description>
      <guid>https://arxiv.org/abs/2503.04783</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Kunlunbaize：具有多尺度卷积的LLM和Transfereerx框架下的多尺度预测</title>
      <link>https://arxiv.org/abs/2503.04784</link>
      <description><![CDATA[ARXIV：2503.04784V1公告类型：新 
摘要：大型语言模型在各种任务中都表现出了出色的性能，但是它们面临着诸如计算效率低，消失和捕获复杂功能相互作用的困难等挑战。为了解决这些局限性，已经提出了一个新颖的框架。该框架结合了一个可学习的密集剩余跳过连接机制，Transfererx模块基于变压器的组件集成了多尺度卷积和自适应激活功能以及多语的预测相互作用模块。可学习的密集残差连接可以增强信息流和跨层的特征捕获。在Transformerx模块中，大量的卷积内核从广泛的文本段聚集了语义信息，而较小的卷积则集中在本地单词顺序和句法结构上。自适应激活函数根据输入文本的语义特征动态调整其参数，从而提高了模型处理各种语义表达式和复杂关系的能力。多语预测模块通过预测多个将来的令牌来促进数据利用和加速推理。这些组件大大提高了大语言模型的性能和效率。]]></description>
      <guid>https://arxiv.org/abs/2503.04784</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在大语言模型中绘制可信赖性：书目计量分析桥接理论实践</title>
      <link>https://arxiv.org/abs/2503.04785</link>
      <description><![CDATA[ARXIV：2503.04785V1公告类型：新 
摘要：大型语言模型（LLM）的快速扩散引起了人们对他们的可信赖性，跨越可靠性，透明度，公平和道德一致性问题的紧迫问题。尽管LLM在各个领域的采用越来越多，但仍缺乏如何在实践中运作信任度达成共识。这项研究通过对2019年至2025年的2,006个出版物进行书目映射分析来弥合理论讨论与实施之间的差距。通过共同授权网络，关键字共同发生分析和主题演化跟踪，我们确定了关键的研究趋势，有影响力的作者，有影响力的作者，以及对LLM Trust的定义。此外，还对68篇核心论文进行了系统评价，以检查信任的概念及其实际含义。我们的发现表明，LLMS中的可信度通常是通过现有的组织信任框架构成的，强调了能力，仁慈和正直等维度。但是，将这些原则转化为具体的发展策略存在很大的差距。为了解决这个问题，我们提出了整个LLM生命周期中20种信任增强技术的结构化映射，包括检索成绩（RAG），解释性技术和培训后审核。通过将文献计量学的见解与实用策略合成，这项研究有助于促进更透明，负责和道德上一致的LLM，从而确保其在现实世界中的负责任部署。]]></description>
      <guid>https://arxiv.org/abs/2503.04785</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分析错误信息中包含的语言特征的时间动力学</title>
      <link>https://arxiv.org/abs/2503.04786</link>
      <description><![CDATA[ARXIV：2503.04786V1公告类型：新 
摘要：消耗错误信息会导致影响个人和社会的负面后果。为了减轻错误信息对人类信念的影响，已经开发了有关内容准确性和源可靠性的背景的算法标签。由于算法用于估计信息准确性的语言特征可能会随着时间的推移而发生变化，因此了解其时间动态非常重要。结果，这项研究使用自然语言处理来分析跨越2010年至2024年之间的政治陈述，以量化五年时间段之间错误信息的来源和语言特征如何变化。结果表明，随着时间的流逝，陈述情感显着下降，反映了政治陈述中总体上更负面的语气。此外，与错误信息相关的陈述比准确的信息要低得多。其他分析表明，最近的时间段是由在线社交网络和其他数字论坛（例如博客和病毒图像）中的来源主导的，其中包含含有负面情绪的高度错误信息。相反，早期期间的大多数陈述都归因于各个来源（即政治家）在准确性评级中相对平衡，并且包含具有中性或积极情绪的陈述。指定的实体识别是用来确定总统任职者和候选人在包含错误信息的陈述中相对普遍，而美国各州倾向于在准确的信息中存在。最后，与人和组织相关的实体标签在错误信息方面更为普遍，而准确的陈述更可能包含数字实体标签，例如百分比和日期。]]></description>
      <guid>https://arxiv.org/abs/2503.04786</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向拟人化对话AI第一部分：一个实用的框架</title>
      <link>https://arxiv.org/abs/2503.04787</link>
      <description><![CDATA[ARXIV：2503.04787V1公告类型：新 
摘要：大型语言模型（LLMS）由于其先进的自然语言功能，在用户界面通常是对话性人工智能（AI）代理的应用程序中取得了巨大成功，并通过多轮对话使用户互动。但是，许多场景要求代理商表现出更强的社会和对话智力，并表现出更类似人类的（拟人化）反应。这是基础LLM尚未完全解决的一个方面，因此基础模型的单个呼叫可能不足。
  为了弥合这一间隙，我们提出了一个两阶段的解决方案。在这项工作中，我们专注于第一阶段，引入了一个多模块框架，旨在复制对话中涉及的人类智能的关键方面。该框架包括用于推理的思维模块，用于管理知识和外部信息的资源模块以及用于生成上下文适当交互的响应模块。随着所有模块的合作，该框架将使代理商有能力提供更好的人类般的对话体验。在我们方法的第二阶段中，这些对话数据在过滤和标记后可以作为增强学习的培训和测试数据，从而使AI更好地捕获人类的偏好。这个阶段留给以后的工作。
  在我们的实验中，志愿者与由独立LLM供电的相同AI角色进行了3000多轮对话，我们的框架集成了相同的LLM。一组评估者对对话样本进行了评估，表明我们的框架显着增强了社交和对话智力，即使没有微调LLM。]]></description>
      <guid>https://arxiv.org/abs/2503.04787</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Agrollm：通过大型语言模型连接农民和农业实践，以增强知识转移和实际应用</title>
      <link>https://arxiv.org/abs/2503.04788</link>
      <description><![CDATA[ARXIV：2503.04788V1公告类型：新 
摘要：Agrollm是一种AI驱动的聊天机器人，旨在使用大语言模型（LLM）和检索功能增强的一代（RAG）框架来增强农业的知识共享和教育。通过使用全面的开源农业数据库，Agrollm提供了准确的，上下文相关的响应，同时减少了错误的信息检索。该系统利用FAISS矢量数据库进行有效的相似性搜索，从而确保快速获取农业知识。对三种高级模型的比较研究：Gemini 1.5 Flash，Chatgpt-4O Mini和Mistral-7b-Instruct-V0.2进行了评估，以评估四个关键农业领域的绩效：农业和生活科学，农业管理，农业管理，农业和林业和农业商业。关键评估指标包括嵌入质量，搜索效率和响应相关性。结果表明，带有RAG的Chatgpt-4O Mini的准确性最高，为93％。连续反馈机制提高了响应质量，使Agrollm成为农民，研究人员和专业人士的基准AI驱动的教育工具，促进了知情的决策和改善的农业实践。]]></description>
      <guid>https://arxiv.org/abs/2503.04788</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EXT2GEN：通过统一的提取和生成对齐，以实现强大的检索生成</title>
      <link>https://arxiv.org/abs/2503.04789</link>
      <description><![CDATA[ARXIV：2503.04789V1公告类型：新 
摘要：检索功能增强的生成（RAG）通过整合外部知识来增强LLM，但是由于不确定相关块和检索引起的信息过载的位置不确定，产生仍然脆弱，从而导致幻觉。我们提出了一种新颖的提取物，然后是生成的模型，该模型通过先提取与查询相关的句子在生成答案之前，从而增强抹布的鲁棒性。为了优化该模型，我们通过成对反馈学习采用偏好对齐方式，使该模型能够生成可靠的答案，而不管检索结果的变化如何。广泛的实验表明，Ext2Gen有效地以高精度和回忆为单位确定了与查询相关的句子，从而提供了高度可靠的答案。此外，将我们的模型部署在抹布环境中表明，它不仅可以提高基本LLM的性能，而且还可以与高级检索策略（如查询扩展）协同作用。数据集和模型将很快发布。]]></description>
      <guid>https://arxiv.org/abs/2503.04789</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Superrag：超越布局感知图形建模</title>
      <link>https://arxiv.org/abs/2503.04790</link>
      <description><![CDATA[ARXIV：2503.04790V1公告类型：新 
摘要：本文介绍了多模式抹布的布局感知图建模。与传统的抹布方法不同，大多数涉及平面文本块的方法，该方法考虑了使用图形结构来考虑多模式的关系。为此，根据文档布局解析来定义图形建模结构。输入文档的结构通过文本块，表和数字的连接保留。此表示允许该方法处理需要多模式信息的复杂问题。为了确认图形建模的效率，使用健壮的组件开发了柔性的破布管道。四个基准测试集的实验结果证实了布局感知建模对RAG管道的性能改进的贡献。]]></description>
      <guid>https://arxiv.org/abs/2503.04790</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>跨语言分歧是多语言语言多样性中语义一致性规范的冲突，作为哲学，认知科学和AI〜的问题</title>
      <link>https://arxiv.org/abs/2503.04792</link>
      <description><![CDATA[ARXIV：2503.04792V1公告类型：新 
摘要：多语言大语言模型（LLMS）面临着一个经常被忽视的挑战，源于语言之间的内在语义差异。语言差异有时会导致跨语言分歧 - 纯粹是由于有关相关概念的语义差异。本文将这种分歧确定为多语言LLM中的两个基本对齐规范之间的冲突：跨语言一致性（CL矛盾），该规范跨语言寻求普遍的概念，并与民间判断（民间矛盾）一致，尊重语言特异性的语义规范。通过研究哲学中使用的案例（知识归因的案例），通过检查对话式多语言AIS的反应，这项研究表明，即使是最新的LLMS也提供了不同的内部和内部不一致的响应。这样的发现揭示了跨语言知识转移或概念性跨语言知识障碍的新型定性限制，这挑战了普遍表示和跨语言转移能力的假设本质上是可取的。此外，他们揭示了开发人员的一致性政策冲突，突出了LLM研究人员和开发人员的关键规范性问题。这些含义超出了技术一致性的挑战，提高了有关AI基础发展的理想的规范性，道德政治和形而上学的问题 - 与哲学家和认知科学家共享的问题，但尚无人权答案，邀请多学科的方法，邀请一种多学科的方法来平衡跨语言一致性和尊重语言的交叉效果。]]></description>
      <guid>https://arxiv.org/abs/2503.04792</guid>
      <pubDate>Mon, 10 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>