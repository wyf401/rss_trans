<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 01 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>语境很重要：时间问答系统中语境信息影响的实证研究</title>
      <link>https://arxiv.org/abs/2406.19538</link>
      <description><![CDATA[arXiv:2406.19538v1 公告类型：新
摘要：大型语言模型 (LLM) 通常在时间推理方面存在困难，这对于历史事件分析和时间敏感信息检索等任务至关重要。尽管取得了进步，但最先进的模型在处理时间信息时仍存在问题，尤其是在面对不相关或嘈杂的上下文时。本文通过实证检验在各种上下文类型（包括相关、不相关、略有改变和无上下文）上训练的时间问答 (TQA) 系统的稳健性来解决这一差距。我们的研究结果表明，使用这些上下文的混合进行训练可以增强模型的稳健性和准确性。此外，我们表明上下文相对于问题的位置会显着影响性能，问题优先定位会产生更好的结果。我们引入了两个新的上下文丰富的 TQA 数据集 ContextAQA 和 ContextTQE，并为训练稳健的 TQA 模型提供了全面的评估和指南。我们的工作为开发可靠且具有上下文感知的时间 QA 系统奠定了基础，对于增强 LLM 针对多样化和潜在对抗性信息的稳健性具有更广泛的意义。]]></description>
      <guid>https://arxiv.org/abs/2406.19538</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:48 GMT</pubDate>
    </item>
    <item>
      <title>TocBERT：使用双向 Transformer 提取医学文档结构</title>
      <link>https://arxiv.org/abs/2406.19526</link>
      <description><![CDATA[arXiv:2406.19526v1 公告类型：新
摘要：文本分割在自然语言处理 (NLP) 领域至关重要。它在信息检索和文档摘要等多个 NLP 下游任务中发挥着重要作用。在这项工作中，我们提出了一种新的解决方案，即 TocBERT，用于使用双向转换器对文本进行分割。TocBERT 代表一种监督解决方案，经过训练可以从语义表示中检测标题和副标题。此任务被表述为命名实体识别 (NER) 问题。该解决方案已应用于医学文本分割用例，其中 Bio-ClinicalBERT 模型经过微调以分割 MIMIC-III 数据集的出院摘要。TocBERT 的性能已在 250 条注释的人工标记的地面实况语料库上进行了评估。在线性文本分割问题上，其 F1 得分为 84.6%，在分层文本分割问题上，其 F1 得分为 72.8%。其表现优于精心设计的基于规则的解决方案，尤其是在区分标题和副标题方面。]]></description>
      <guid>https://arxiv.org/abs/2406.19526</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:47 GMT</pubDate>
    </item>
    <item>
      <title>处理语义解析中的本体差距</title>
      <link>https://arxiv.org/abs/2406.19537</link>
      <description><![CDATA[arXiv:2406.19537v1 公告类型：新
摘要：大多数神经语义解析 (NSP) 模型都是在假设这些模型可以用其目标符号表示的概念之外没有其他概念的情况下开发的（封闭世界假设）。这种假设导致产生幻觉输出，而不是承认他们缺乏知识。幻觉可能会导致对用户做出错误或潜在的冒犯性反应。因此，防止这种行为的机制对于构建基于 NSP 的可信问答代理至关重要。为此，我们提出了幻觉模拟框架 (HSF)，这是一种用于刺激和分析 NSP 模型幻觉的通用设置。该框架可以应用于任何具有封闭本体的 NSP 任务。使用提出的框架和 KQA Pro 作为基准数据集，我们评估了最先进的幻觉检测技术。然后，我们提出了一种新颖的幻觉检测策略，该策略利用 NSP 模型的计算图来检测存在本体差距、域外话语的情况下的 NSP 幻觉，并识别 NSP 错误，分别将 F1 分数提高约 21%、约 24% 和约 1%。这是封闭本体 NSP 中第一项解决识别本体差距问题的工作。我们在 https://github.com/amazon-science/handling-ontology-gaps-in-semantic-parsing 上发布了我们的代码和检查点。]]></description>
      <guid>https://arxiv.org/abs/2406.19537</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:47 GMT</pubDate>
    </item>
    <item>
      <title>研究大型语言模型如何利用内部知识进行复杂推理</title>
      <link>https://arxiv.org/abs/2406.19502</link>
      <description><![CDATA[arXiv:2406.19502v1 公告类型：新
摘要：尽管取得了重大进展，但人们对大型语言模型 (LLM) 如何利用知识进行推理的理解有限。为了解决这个问题，我们提出了一种方法，将复杂的现实世界问题解构为一个图，将每个问题表示为一个节点，其父节点是解决问题所需的背景知识。我们开发了 DepthQA 数据集，将问题解构为三个深度：(i) 回忆概念知识，(ii) 应用程序知识，(iii) 分析战略知识。基于分层图，我们量化了前向差异，即 LLM 在简单子问题和复杂问题上的表现差异。我们还测量了后向差异，其中 LLM 回答复杂问题但在简单问题上遇到困难。我们的分析表明，较小的模型比较大的模型有更大的差异。此外，通过多轮交互引导模型从简单问题到复杂问题，可以提高不同模型大小的性能，凸显了结构化中间步骤在知识推理中的重要性。这项工作增强了我们对 LLM 推理的理解，并提出了提高其解决问题能力的方法。]]></description>
      <guid>https://arxiv.org/abs/2406.19502</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:46 GMT</pubDate>
    </item>
    <item>
      <title>生成语言模型是否具有多元文化性？使用 ChatGPT 研究豪萨文化和情感</title>
      <link>https://arxiv.org/abs/2406.19504</link>
      <description><![CDATA[arXiv:2406.19504v1 公告类型：新
摘要：大型语言模型 (LLM)，例如 ChatGPT，被广泛用于为各种目的和受众生成内容。然而，这些模型可能无法反映其用户的文化和情感多样性，尤其是对于资源匮乏的语言。在本文中，我们研究了 ChatGPT 如何代表豪萨人的文化和情感。我们将 ChatGPT 生成的回答与豪萨语母语人士在 37 个文化相关问题上提供的回答进行了比较。我们使用情感分析进行了实验，并应用了两个相似性指标来衡量人类和 ChatGPT 反应之间的一致性。我们还收集了人类参与者对 ChatGPT 反应的评分和反馈。我们的结果表明，ChatGPT 与人类反应有一定程度的相似性，但在对豪萨文化和情感的知识和认识方面也表现出一些差距和偏见。我们讨论了我们的方法和分析的含义和局限性，并提出了改进低资源语言 LLM 性能和评估的方法。]]></description>
      <guid>https://arxiv.org/abs/2406.19504</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:46 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型 (CVLLM) 进行字幕可视化：教程</title>
      <link>https://arxiv.org/abs/2406.19512</link>
      <description><![CDATA[arXiv:2406.19512v1 公告类型：新
摘要：自动字幕可视化并不是什么新鲜事，但大型语言模型 (LLM) 的最新进展开辟了令人兴奋的新可能性。在本教程中，在简要回顾信息可视化 (InfoVis) 原理和过去的字幕工作之后，我们介绍了神经模型和通用 LLM 中使用的转换器架构。然后，我们讨论它们在 InfoVis 中的最新应用，重点是字幕。此外，我们还探索了该领域有希望的未来方向。]]></description>
      <guid>https://arxiv.org/abs/2406.19512</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:46 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中的包容性：科学摘要中的性格特征和性别偏见</title>
      <link>https://arxiv.org/abs/2406.19497</link>
      <description><![CDATA[arXiv:2406.19497v1 公告类型：新
摘要：大型语言模型 (LLM) 越来越多地用于协助科学和学术写作，帮助作者提高文章的连贯性。先前的研究强调了 LLM 输出中存在的刻板印象和偏见，强调需要评估这些模型是否与人类叙事风格和潜在的性别偏见保持一致。在本研究中，我们通过分析三个著名的 LLM - Claude 3 Opus、Mistral AI Large 和 Gemini 1.5 Flash 在科学摘要的基准文本生成任务中的表现来评估它们的一致性。我们使用语言查询和字数统计 (LIWC) 框架从生成的文本中提取词汇、心理和社会特征。我们的研究结果表明，虽然这些模型通常会生成与人类创作内容非常相似的文本，但风格特征的变化表明存在明显的性别偏见。这项研究强调了开发保持多样化写作风格的法学硕士学位以促进学术话语包容性的重要性。]]></description>
      <guid>https://arxiv.org/abs/2406.19497</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:45 GMT</pubDate>
    </item>
    <item>
      <title>使用命题探测监控语言模型中的潜在世界状态</title>
      <link>https://arxiv.org/abs/2406.19501</link>
      <description><![CDATA[arXiv:2406.19501v1 公告类型：新
摘要：语言模型容易受到偏见、谄媚、后门和其他导致对输入上下文做出不忠实反应的倾向的影响。解释语言模型的内部状态可以帮助监控和纠正不忠实的行为。我们假设语言模型在潜在世界模型中表示其输入上下文，并试图从激活中提取这种潜在世界状态。我们使用“命题探测”来实现这一点，它组合探测标记以获取词汇信息并将它们绑定到代表世界状态的逻辑命题中。例如，给定输入上下文“Greg 是一名护士。Laura 是一名物理学家。”，我们从模型的激活中解码命题“WorksAs(Greg, Nurse)”和“WorksAs(Laura, physicist)”。关键在于确定一个“绑定子空间”，其中绑定标记具有高度相似性（“Greg”和“护士”），但未绑定标记不相似（“Greg”和“物理学家”）。我们在具有有限多个谓词和属性的封闭世界环境中验证命题探测。尽管在简单的模板上下文中进行训练，但命题探测可以推广到重写为短篇小说并翻译成西班牙语的上下文。此外，我们发现在语言模型对输入上下文反应不真实的三种环境中——提示注入、后门攻击和性别偏见——解码后的命题仍然忠实。这表明语言模型通常会对忠实的世界模型进行编码，但对其进行不忠实的解码，这促使人们寻找更好的可解释性工具来监控 LM。]]></description>
      <guid>https://arxiv.org/abs/2406.19501</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:45 GMT</pubDate>
    </item>
    <item>
      <title>xTower：用于解释和纠正翻译错误的多语言法学硕士</title>
      <link>https://arxiv.org/abs/2406.19482</link>
      <description><![CDATA[arXiv:2406.19482v1 公告类型：新
摘要：虽然机器翻译 (MT) 系统在基准测试中的表现越来越好，但它们经常会产生带有错误和异常的翻译。了解这些错误可能有助于提高翻译质量和用户体验。本文介绍了 xTower，这是一个建立在 TowerBase 之上的开放式大型语言模型 (LLM)，旨在为翻译错误提供自由文本解释，以指导生成更正的翻译。xTower 生成的解释的质量通过内在和外在评估进行评估。我们要求专业翻译人员从两个维度评估解释的质量：与被解释的错误跨度的相关性以及对错误理解和提高翻译质量的帮助性。在外部，我们在各种实验设置中测试 xTower 以生成翻译更正，结果显示翻译质量有显着提高。我们的研究结果强调了 xTower 不仅可以为自动翻译提供合理且有用的解释，还可以利用它们来建议更正的翻译。]]></description>
      <guid>https://arxiv.org/abs/2406.19482</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:44 GMT</pubDate>
    </item>
    <item>
      <title>LoPT：针对参数高效语言模型的低秩快速调整</title>
      <link>https://arxiv.org/abs/2406.19486</link>
      <description><![CDATA[arXiv:2406.19486v1 公告类型：新
摘要：在提示调整中，将前缀或后缀文本添加到提示中，并优化前缀/后缀的嵌入（软提示）或标记索引（硬提示），以获得对特定任务的语言模型的更多控制。这种方法消除了对手工制作的提示工程或显式模型微调的需要。提示调整比模型微调具有更高的参数效率，因为它涉及优化语言模型的部分输入以产生所需的输出。
在这项工作中，我们旨在进一步减少语言模型在特定任务上表现良好所需的可训练参数数量。我们提出了低秩提示调整（LoPT），这是一种实现高效提示优化的低秩提示模型。所提出的方法展示了与全参数快速调优类似的结果，同时将可训练参数的数量减少了 5 倍。与需要 10 到 20 倍参数的最先进的方法相比，它还提供了有希望的结果。]]></description>
      <guid>https://arxiv.org/abs/2406.19486</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:44 GMT</pubDate>
    </item>
    <item>
      <title>用于创建人工系统 SAPPhIRE 模型的检索增强生成工具的开发和评估</title>
      <link>https://arxiv.org/abs/2406.19493</link>
      <description><![CDATA[arXiv:2406.19493v1 公告类型：新
摘要：使用 SAPPhIRE 因果关系模型表示系统在支持类比设计方面很有用。然而，创建人工或生物系统的 SAPPhIRE 模型是一个耗费大量精力的过程，需要人类专家从多个技术文档中获取有关系统工作原理的技术知识。本研究调查了如何利用大型语言模型 (LLM) 使用 SAPPhIRE 因果关系模型创建系统的结构化描述。本文是两部分研究的第二部分，介绍了一种新的检索增强生成 (RAG) 工具，用于生成与人工系统的 SAPPhIRE 构造相关的信息，并报告了对该工具成功的初步评估结果——重点关注结果的事实准确性和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2406.19493</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:44 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型能否生成高质量的专利权利要求？</title>
      <link>https://arxiv.org/abs/2406.19465</link>
      <description><![CDATA[arXiv:2406.19465v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种文本生成任务中表现出色，但在提供高度结构化和精确语言的专利领域仍未得到充分探索。本文构建了一个数据集来研究当前 LLM 在专利权利要求生成中的表现。我们的结果表明，基于专利描述生成权利要求优于以前依赖摘要的研究。有趣的是，当前针对专利的 LLM 的表现比最先进的通用 LLM 差得多，这凸显了未来研究领域内 LLM 的必要性。我们还发现 LLM 可以生成高质量的第一个独立权利要求，但它们对后续从属权利要求的性能明显下降。此外，微调可以增强发明特征的完整性、概念清晰度和特征链接。在测试的 LLM 中，GPT-4 在专利专家的全面人工评估中表现出色，具有更好的特征覆盖率、概念清晰度和技术连贯性。尽管具有这些能力，但仍需要进行全面的修订和修改，以通过严格的专利审查并确保法律的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2406.19465</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:43 GMT</pubDate>
    </item>
    <item>
      <title>改变答案顺序可能会降低 MMLU 准确率</title>
      <link>https://arxiv.org/abs/2406.19470</link>
      <description><![CDATA[arXiv:2406.19470v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的普及，特定的基准对于评估这些模型和了解模型功能变得至关重要。最常见的是，我们使用跨多个子任务平均的测试准确度来对排行榜上的模型进行排名，以确定哪种模型最适合我们的目的。在本文中，我们研究了广泛使用的多项选择题回答数据集 MMLU 的准确度测量的稳健性。当打乱答案标签内容时，我们发现所有探索的模型在 MMLU 上的准确度都会下降，但并非每个模型都同样敏感。这些发现表明可以对排行榜测试的标准做法进行调整，我们还会考虑每个模型随机正确回答的示例百分比。]]></description>
      <guid>https://arxiv.org/abs/2406.19470</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:43 GMT</pubDate>
    </item>
    <item>
      <title>机器翻译的稀疏回归</title>
      <link>https://arxiv.org/abs/2406.19478</link>
      <description><![CDATA[arXiv:2406.19478v1 公告类型：新
摘要：我们使用传导回归技术来学习给定平行语料库的源特征和目标特征之间的映射，并使用这些映射生成机器翻译输出。我们展示了$L_1$正则化回归（\textit{lasso}）与$L_2$正则化回归相比，在学习稀疏观察特征集之间的映射方面的有效性。正确选择训练实例对于在有限的计算资源和预期的准确度水平下学习正确的特征映射起着重要作用。我们引入了\textit{dice}实例选择方法来正确选择训练实例，这对于学习正确的特征映射以改善训练集的源和目标覆盖率起着重要作用。我们表明，无论是在回归测量中还是在使用图解码的翻译实验中，$L_1$正则化回归的表现都优于$L_2$正则化回归。我们在从德语翻译成英语和从西班牙语翻译成英语时取得了令人鼓舞的结果。我们还展示了将基于短语的解码器的短语表替换为我们通过回归模型找到的映射时的结果。]]></description>
      <guid>https://arxiv.org/abs/2406.19478</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:43 GMT</pubDate>
    </item>
    <item>
      <title>多语言 FActScore 分析</title>
      <link>https://arxiv.org/abs/2406.19415</link>
      <description><![CDATA[arXiv:2406.19415v1 公告类型：新
摘要：FActScore 已成为一种衡量英语大型语言模型 (LLM) 生成的长文本真实性的指标。然而，目前还没有任何研究 FActScore 在其他语言中的行为的工作。本文研究了多语言环境中 FActScore 四组件管道中每个组件的局限性。我们为由强大的多语言 LLM 生成的文本引入了一个新的 FActScore 数据集。我们的评估表明，LLM 在事实提取和事实评分任务中表现出不同的行为。没有一个 LLM 能够在具有不同资源水平的语言中产生一致且可靠的 FActScore。我们还发现知识来源在估计的 FActScore 的质量中起着重要作用。使用维基百科作为知识来源可能会妨碍长文本的真实 FActScore，因为它在中低资源语言中的覆盖范围有限。我们还在知识源中加入了三种缓解措施，最终改善所有语言的 FActScore 估计。]]></description>
      <guid>https://arxiv.org/abs/2406.19415</guid>
      <pubDate>Mon, 01 Jul 2024 06:20:42 GMT</pubDate>
    </item>
    </channel>
</rss>