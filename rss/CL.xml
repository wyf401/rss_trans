<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 18 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>语言模型和检索增强生成，用于从诊断报告中自动提取结构化数据</title>
      <link>https://arxiv.org/abs/2409.10576</link>
      <description><![CDATA[arXiv:2409.10576v1 公告类型：新 
摘要：目的：开发和评估使用开放权重大型语言模型 (LM) 和检索增强生成 (RAG) 从非结构化放射学和病理学报告中提取结构化临床信息的自动化系统，并评估模型配置变量对提取性能的影响。方法和材料：该研究使用了两个数据集：7,294 份注释了脑肿瘤报告和数据系统 (BT-RADS) 评分的放射学报告和 2,154 份注释了异柠檬酸脱氢酶 (IDH) 突变状态的病理报告。开发了一个自动化管道来对各种 LM 和 RAG 配置的性能进行基准测试。系统地评估了模型大小、量化、提示策略、输出格式和推理参数的影响。结果：表现最佳的模型在从放射学报告中提取 BT-RADS 评分时实现了 98% 以上的准确率，在从病理报告中提取 IDH 突变状态时实现了 90% 以上的准确率。最热门的模型是医学微调的 llama3。较大、较新和领域微调的模型始终优于较旧和较小的模型。模型量化对性能的影响微乎其微。小样本提示显著提高了准确性。RAG 提高了复杂病理报告的性能，但没有提高较短的放射学报告的性能。结论：开放式 LM 显示出在本地隐私保护应用中从非结构化临床报告中自动提取结构化临床数据的巨大潜力。仔细的模型选择、及时的工程设计和使用注释数据的半自动化优化对于获得最佳性能至关重要。这些方法足够可靠，可用于研究工作流程中的实际应用，凸显了人机协作在医疗保健数据提取中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.10576</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索用于关键词选择的精细调整生成模型：俄语案例研究</title>
      <link>https://arxiv.org/abs/2409.10640</link>
      <description><![CDATA[arXiv:2409.10640v1 公告类型：新
摘要：关键短语选择在学术文本领域起着关键作用，有助于实现高效的信息检索、摘要和索引。在这项工作中，我们探索了如何将基于微调的生成变压器的模型应用于俄语科学文本中的关键短语选择的特定任务。我们尝试了四种不同的生成模型，例如 ruT5、ruGPT、mT5 和 mBART，并评估了它们在域内和跨域设置中的表现。实验是在四个领域的俄罗斯科学摘要文本上进行的：数学和计算机科学、历史、医学和语言学。使用生成模型 mBART，在俄语的三个关键短语提取基线上提高了域内性能（BERTScore 提高 4.9%，ROUGE-1 提高 9.0%，F1-score 提高 12.2%）。尽管跨域使用的结果明显较低，但它们仍显示出在某些情况下超越基线性能的能力，凸显了进一步探索和改进该研究领域的巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.10640</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>改进多候选推测解码</title>
      <link>https://arxiv.org/abs/2409.10644</link>
      <description><![CDATA[arXiv:2409.10644v1 公告类型：新
摘要：推测解码 (SD) 是一种加速大型语言模型 (LLM) 推理的技术，它使用复杂度较低的草稿模型来提出由更大的目标模型验证的候选标记。为了进一步提高效率，多候选推测解码 (MCSD) 通过在每个步骤从草稿模型中采样多个候选标记并并行验证它们来改进这一点，从而增加了接受标记的机会并减少了生成时间。现有的 MCSD 方法依赖于草稿模型来初始化多候选序列，并使用静态长度和树注意结构进行草稿生成。然而，这种方法受到草稿和目标模型的输出分布差异的影响，尤其是在动态生成环境中。在这项工作中，我们介绍了 MCSD 的改进版本，其中包括目标模型初始化的多候选过程、用于动态长度调整的动态切片拓扑感知因果掩码以及用于优化早期停止的决策模型。我们的框架将接受率（定义为目标模型接受的最长草稿序列长度与最大草稿序列长度之比）提高了最多 164%，并且与 MCSD 基线相比，生成速度最多提高了 75%。我们还进行了一项消融研究来评估决策模型的影响。]]></description>
      <guid>https://arxiv.org/abs/2409.10644</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用指南针可视化时间主题嵌入</title>
      <link>https://arxiv.org/abs/2409.10649</link>
      <description><![CDATA[arXiv:2409.10649v1 公告类型：新
摘要：动态主题建模有助于发现潜在主题随时间的发展和变化。然而，目前的方法依赖于分离文档和单词表示的算法。这阻止了创建有意义的嵌入空间，在该空间中可以直接在时间上下文中分析单词使用和文档的变化。本文提出将指南针对齐的时间 Word2Vec 方法扩展到动态主题建模。这种方法允许在动态主题中跨时间直接比较单词和文档嵌入。这使得能够创建将文档上下文中的时间词嵌入合并到主题可视化中的可视化。在针对当前最先进技术的实验中，我们提出的方法在不同大小的时间数据集中展示了主题相关性和多样性方面的整体竞争性能。同时，它提供了专注于时间词嵌入的富有洞察力的可视化，同时保持了全局主题演变提供的洞察力，从而加深了我们对主题如何随时间演变的理解。]]></description>
      <guid>https://arxiv.org/abs/2409.10649</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自注意力机制限制了基于 Transformer 模型的工作记忆容量</title>
      <link>https://arxiv.org/abs/2409.10715</link>
      <description><![CDATA[arXiv:2409.10715v1 公告类型：新 
摘要：最近对基于 Transformer 的大型语言模型 (LLM) 的研究揭示了它们的工作记忆容量存在显著限制，类似于人类行为研究中发现的情况。具体而言，随着 N 的增加，这些模型在 N-back 任务上的性能显着下降。然而，对于为什么会出现这种现象，仍然缺乏机械上的可解释性。受行为科学的执行注意力理论的启发，我们假设基于 Transformer 的模型中的自我注意力机制可能是造成其工作记忆容量限制的原因。为了验证这一假设，我们训练了 vanilla 解码器专用 Transformer 来执行 N-back 任务，并发现注意力分数在训练过程中逐渐聚集到 N-back 位置，这表明该模型通过学习一种关注当前位置和 N-back 位置之间关系的策略来掌握任务。至关重要的是，我们发现注意力得分矩阵的总熵随着 N 的增加而增加，这表明注意力得分的分散可能是导致 N-back 任务中观察到的容量限制的原因。]]></description>
      <guid>https://arxiv.org/abs/2409.10715</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在线语言处理中的预期和响应性的广义测量</title>
      <link>https://arxiv.org/abs/2409.10728</link>
      <description><![CDATA[arXiv:2409.10728v1 公告类型：新
摘要：我们引入了在线语言处理中预测不确定性的经典信息理论度量的泛化，该度量基于增量语言上下文的预期延续的模拟。我们的框架提供了预期和响应度量的正式定义，并为实验者提供了定义超越标准下一符号熵和意外性的新、更具表现力的度量的工具。虽然从语言模型中提取这些标准量很方便，但我们证明使用蒙特卡罗模拟来估计替代响应和预期度量在经验上是值得的：与意外性相比，我们的广义公式的新特例表现出增强的预测能力，包括人类完形填空概率以及 ELAN、LAN 和 N400 幅度，并且在预测阅读时间方面与意外性具有更大的互补性。]]></description>
      <guid>https://arxiv.org/abs/2409.10728</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型实现保留语义的表情符号推荐</title>
      <link>https://arxiv.org/abs/2409.10760</link>
      <description><![CDATA[arXiv:2409.10760v1 公告类型：新
摘要：表情符号已成为数字通信不可或缺的一部分，通过传达情感、语气和意图来丰富文本。现有的表情符号推荐方法主要基于其与用户在原始文本中选择的表情符号的精确匹配能力进行评估。然而，它们忽略了用户在社交媒体上的行为本质，即每条文本可以对应多个合理的表情符号。为了更好地评估模型与现实世界表情符号使用情况保持一致的能力，我们提出了一种新的表情符号推荐语义保留评估框架，该框架衡量模型推荐与用户文本保持语义一致性的表情符号的能力。为了评估模型保留语义的程度，我们评估预测的用户情感状态、人口统计资料和态度立场是否保持不变。如果这些属性得以保留，我们认为推荐的表情符号保持了原始语义。大型语言模型 (LLM) 在理解和生成细微、上下文相关的输出方面具有先进的能力，这使得它们非常适合处理语义保留表情符号推荐的复杂性。为此，我们构建了一个全面的基准，以系统地评估六种专有和开源 LLM 使用不同的提示技术在我们的任务上的表现。我们的实验表明，GPT-4o 的表现优于其他 LLM，语义保留得分达到 79.23%。此外，我们还进行了案例研究，以分析下游分类任务中的模型偏差并评估推荐表情符号的多样性。]]></description>
      <guid>https://arxiv.org/abs/2409.10760</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预测古汉语文本中的标点符号：多层 LSTM 和基于注意力机制的方法</title>
      <link>https://arxiv.org/abs/2409.10783</link>
      <description><![CDATA[arXiv:2409.10783v1 公告类型：新
摘要：直到 20 世纪，中文才开始使用标点符号。事实上，许多古代中文文本包含数千行，没有明显的标点符号或分隔符。此类文本中缺乏标点符号，使人类难以识别特定短语之间的停顿或中断，也难以理解书面文本的语义含义 (Mogahed, 2012)。因此，除非受过古代教育，否则许多古汉语读者对文本的解读会大不相同。我们提出了一种预测古汉语文本中标点符号位置（和类型）的方法，该方法扩展了 Oh 等人 (2017) 的工作，利用双向多层 LSTM 和多头注意力机制，受到 Luong 等人 (2015) 关于基于注意力的架构的讨论的启发。我们发现，在评估古中文文献时，使用多层 LSTM 和多头注意力机制的效果明显优于未包含此类组件的 RNN。]]></description>
      <guid>https://arxiv.org/abs/2409.10783</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>模型告诉自己应该关注什么：忠诚度与自动注意力引导相结合</title>
      <link>https://arxiv.org/abs/2409.10790</link>
      <description><![CDATA[arXiv:2409.10790v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种实际任务中都表现出色。然而，它们往往难以完全理解和有效利用输入上下文，导致响应不真实或产生幻觉。对于较长或包含分散注意力的信息的上下文，这种难度会增加，这会使 LLM 无法完全捕获基本证据。为了解决这个问题，许多工作使用提示来帮助 LLM 更忠实地利用上下文信息。例如，迭代提示分两步突出显示关键信息，首先要求 LLM 识别重要的上下文，然后据此得出答案。然而，提示方法仅限于在标记空间中隐式突出显示关键信息，这通常不足以完全引导模型的注意力。为了更可靠地提高模型的忠实度，我们提出了 AutoPASTA，这是一种自动识别关键上下文信息并通过引导 LLM 的注意力分数明确突出显示它的方法。与提示一样，AutoPASTA 应用于推理时，不需要更改任何模型参数。我们在开卷问答中的实验表明，AutoPASTA 有效地使模型能够掌握必要的上下文信息，从而显著提高模型的忠实度和性能，例如，LLAMA3-70B-Instruct 的平均改进率为 7.95%。代码将在 https://github.com/QingruZhang/Au​​toPASTA 上公开提供。]]></description>
      <guid>https://arxiv.org/abs/2409.10790</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ReXErr：综合诊断放射学报告中具有临床意义的错误</title>
      <link>https://arxiv.org/abs/2409.10829</link>
      <description><![CDATA[arXiv:2409.10829v1 公告类型：新
摘要：准确解释医学图像和撰写放射学报告是医疗保健领域一项关键但具有挑战性的任务。人工编写和人工智能生成的报告都可能包含错误，从临床不准确到语言错误。为了解决这个问题，我们引入了 ReXErr，这是一种利用大型语言模型在胸部 X 光报告中生成代表性错误的方法。我们与委员会认证的放射科医生合作，开发了错误类别，以捕获人工和人工智能生成的报告中的常见错误。我们的方法使用一种新颖的采样方案来注入各种错误，同时保持临床合理性。ReXErr 在错误类别中表现出一致性，并产生的错误与现实世界场景中的错误非常相似。该方法有可能有助于开发和评估报告校正算法，从而有可能提高放射学报告的质量和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2409.10829</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不好：用于文本到运动生成的双向自回归扩散</title>
      <link>https://arxiv.org/abs/2409.10847</link>
      <description><![CDATA[arXiv:2409.10847v1 公告类型：新
摘要：自回归模型通过强制因果约束擅长对顺序依赖关系进行建模，但由于其单向性质，它们难以捕捉复杂的双向模式。相比之下，基于掩码的模型利用双向上下文，实现更丰富的依赖关系建模。然而，它们通常在预测过程中假设标记独立性，这破坏了顺序依赖关系的建模。此外，通过掩码或吸收对序列的破坏会引入不自然的扭曲，使学习过程复杂化。为了解决这些问题，我们提出了双向自回归扩散 (BAD)，这是一种统一自回归和基于掩码的生成模型优势的新方法。BAD 采用基于排列的破坏技术，在通过随机排序强制因果依赖的同时保留自然序列结构，从而能够有效捕获顺序和双向关系。综合实验表明，BAD 在文本转运动生成方面的表现优于自回归和基于掩码的模型，这为序列建模提供了一种新颖的预训练策略。BAD 的代码库可在 https://github.com/RohollahHS/BAD 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.10847</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过分层注意力捷径实现自适应大型语言模型</title>
      <link>https://arxiv.org/abs/2409.10870</link>
      <description><![CDATA[arXiv:2409.10870v1 公告类型：新
摘要：Transformer 架构是现代 AI 革命的支柱。然而，它们只是简单地将相同的块堆叠在数十层中，并按顺序从一个块到另一个块处理信息。在本文中，我们建议挑战这一点，并为类似 LLM 的设置引入自适应计算，这允许最后一层通过注意力机制按照其认为合适的方式关注所有中间层，从而引入计算 \textbf{注意力捷径}。这些捷径可以使架构深度和上下文自适应。我们展示了四个不同的数据集，即声学标记、自然语言和符号音乐，并且我们在类似 GPT 的架构中实现了卓越的性能。我们通过注意力图提供证据，证明模型学习跨层的复杂依赖关系，这些依赖关系根据输入标记在上下文和深度上是自适应的。]]></description>
      <guid>https://arxiv.org/abs/2409.10870</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Transformer 和 Seq2Seq 与 LSTM 将美国手语翻译为文本</title>
      <link>https://arxiv.org/abs/2409.10874</link>
      <description><![CDATA[arXiv:2409.10874v1 公告类型：新
摘要：手语翻译是聋哑人士与听力正常人士交流的重要问题之一，因为它通过手、身体和嘴巴的动作来表达单词。美国手语是使用的手语之一，其中一种是字母手势。神经机器翻译技术的发展正朝着手语翻译的方向发展。Transformer 成为自然语言处理领域的最新成果。本研究将 Transformer 与 Sequence-to-Sequence (Seq2Seq) 模型在将手语翻译成文本方面进行了比较。此外，通过在 Transformer 中添加残差长短期记忆 (ResidualLSTM) 进行了实验。根据 BLEU 分数值，在 Transformer 中添加 ResidualLSTM 会使 Transformer 模型的性能降低 23.37%。相比之下，Transformer 本身与 Seq2Seq 模型相比，BLEU Score 值提高了 28.14。]]></description>
      <guid>https://arxiv.org/abs/2409.10874</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CREAM：基于比较的无参考 ELO 排名自动评估会议总结</title>
      <link>https://arxiv.org/abs/2409.10883</link>
      <description><![CDATA[arXiv:2409.10883v1 公告类型：新
摘要：大型语言模型 (LLM) 激发了人们对自动评估摘要方法的兴趣，为人工评估提供了一种更快、更具成本效益的替代方案。然而，现有方法在应用于长上下文摘要和基于对话的会议摘要等复杂任务时往往不够好。在本文中，我们介绍了 CREAM（基于比较的无参考 Elo 排名会议摘要自动评估），这是一个新颖的框架，可解决评估会议摘要的独特挑战。CREAM 利用思路链推理和关键事实对齐的组合来评估模型生成的摘要的简洁性和完整性，而无需参考。通过采用 ELO 排名系统，我们的方法提供了一种强大的机制来比较不同模型或提示配置的质量。]]></description>
      <guid>https://arxiv.org/abs/2409.10883</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Attention-Seeker：用于无监督关键短语提取的动态自注意力评分</title>
      <link>https://arxiv.org/abs/2409.10907</link>
      <description><![CDATA[arXiv:2409.10907v1 公告类型：新
摘要：本文提出了 Attention-Seeker，这是一种无监督的关键短语提取方法，它利用大型语言模型的自注意力图来估计候选短语的重要性。我们的方法识别特定的组件 - 例如层、头部和注意力向量 - 模型会高度关注文本的关键主题。然后使用这些组件提供的注意力权重对候选短语进行评分。与以前需要手动调整参数（例如选择头部、提示、超参数）的模型不同，Attention-Seeker 可以动态适应输入文本而无需任何手动调整，从而增强了其实际适用性。我们在四个公开可用的数据集上评估 Attention-Seeker：Inspec、SemEval2010、SemEval2017 和 Krapivin。我们的结果表明，即使没有参数调整，Attention-Seeker 的表现也优于大多数基线模型，在四个数据集中的三个上实现了最先进的性能，特别是在从长文档中提取关键短语方面表现出色。]]></description>
      <guid>https://arxiv.org/abs/2409.10907</guid>
      <pubDate>Wed, 18 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>