<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 08 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>神经元 1512 的神秘案例：可注入重组架构揭示了 Meta 的 Llama 2 模型的内部特征</title>
      <link>https://arxiv.org/abs/2407.03621</link>
      <description><![CDATA[arXiv:2407.03621v1 公告类型：新
摘要：大型语言模型 (LLM) 具有无与伦比且无价的能力，可以通过在生成的文本中反映人类的各种偏好，将其输出“对齐”到人类的各种偏好。然而，这种模型的内部特征仍然很大程度上不透明。这项工作提出了可注入重新对齐模型 (IRM)，作为一种语言模型可解释性和可解释性的新方法。受早期神经编程接口工作的启发，我们构建并训练了一个小型网络——IRM——以在 7B 参数 LLM 架构中诱导基于情感的对齐。IRM 输出通过逐层添加在 LLM 的前向传递过程中的各个点注入，从而在不改变原始模型权重的情况下调节其行为。这将对齐行为与转换器模型的复杂机制隔离开来。对训练后的 IRM 输出的分析揭示了一个奇怪的模式。在超过 24 次训练运行和多个对齐数据集中，IRM 激活模式与每个 Transformer 层内神经元索引相关的条纹对齐，而不是与层本身相关联。此外，单个神经元索引 (1512) 与所有测试对齐都密切相关。这个结果虽然最初违反直觉，但直接归因于几乎所有市售 Transformer 架构中存在的设计选择，并凸显了 Meta 预训练的 Llama 2 模型中的潜在弱点。它还展示了 IRM 架构对于语言模型分析和可解释性的价值。我们的代码和数据集可在 https://github.com/DRAGNLabs/injectable-alignment-model 上找到]]></description>
      <guid>https://arxiv.org/abs/2407.03621</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:40 GMT</pubDate>
    </item>
    <item>
      <title>问题分析提示可提高法学硕士在推理任务中的表现</title>
      <link>https://arxiv.org/abs/2407.03624</link>
      <description><![CDATA[arXiv:2407.03624v1 公告类型：新
摘要：尽管 LLM 有可能改变许多领域，但它们在推理任务方面的表现仍然不及人类。现有方法诱导模型进行分步计算，但本研究探讨了这样一个问题：让 LLM 分析问题是否会提高其性能？我们提出了一种称为问题分析提示 (QAP) 的新型提示策略，其中提示模型在解决问题之前用 $n$ 个字解释问题。$n$ 的值会影响模型生成的响应长度。在算术数据集 GSM8K、AQuA 和 SAT 以及常识数据集 StrategyQA 上，在 GPT 3.5 Turbo 和 GPT 4 Turbo 上对 QAP 进行了评估。将 QAP 与其他最先进的提示进行了比较，包括思维链 (CoT)、计划和解决提示 (PS+) 和深呼吸 (TADB)。 QAP 在 GPT3.5 和 GPT4 的 AQuA 和 SAT 数据集上的表现均优于所有最先进的提示。QAP 在 75% 的测试中始终位居前 2 名。QAP 性能的一个关键因素可以归因于响应长度，其中详细的响应在回答较难的问题时很有用，但会对简单问题产生负面影响。]]></description>
      <guid>https://arxiv.org/abs/2407.03624</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:40 GMT</pubDate>
    </item>
    <item>
      <title>DSLR：通过句子级重新排序和重构进行文档细化以增强检索增强生成</title>
      <link>https://arxiv.org/abs/2407.03627</link>
      <description><![CDATA[arXiv:2407.03627v2 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展显著提高了它们在各种自然语言处理 (NLP) 任务中的表现。然而，由于参数记忆的限制，LLM 仍然难以生成非事实响应。检索增强生成 (RAG) 系统通过将外部知识与检索模块结合起来解决了这个问题。然而，尽管取得了成功，目前的 RAG 系统仍面临着检索失败和 LLM 过滤掉不相关信息的能力有限的挑战。因此，在这项工作中，我们提出了 DSLR（具有句子级重新排序和重构的文档细化），这是一个无监督框架，它将检索到的文档分解为句子，过滤掉不相关的句子，然后将它们重新重构为连贯的段落。我们在多个开放域问答数据集上对 DSLR 进行了实验验证，结果表明，DSLR 显著提高了 RAG 的性能，优于传统的固定大小段落。此外，我们的 DSLR 无需额外训练即可在特定但现实的场景中提高性能，为 RAG 系统中检索到的文档的细化提供了一种有效且高效的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2407.03627</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:40 GMT</pubDate>
    </item>
    <item>
      <title>对比思维链提示</title>
      <link>https://arxiv.org/abs/2407.03600</link>
      <description><![CDATA[arXiv:2407.03600v1 公告类型：新
摘要：快速增加的模型规模加上诸如思路链提示之类的引导方法，导致语言模型推理得到了显着改善。与此同时，模型在组合泛化方面遇到困难，并且在许多基于推理的基准上远远落后于人类的表现。利用思路链提示的成功，并从上下文感知解码 (CAD) 中汲取灵感，我们探索基于输入的对比方法，以进一步鼓励由思路链提示引起的推理类型。虽然仍需努力在数据集和模型之间稳定这些结果，但我们发现的改进值得进一步研究基于输入的上下文感知推理的引导方法。]]></description>
      <guid>https://arxiv.org/abs/2407.03600</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:39 GMT</pubDate>
    </item>
    <item>
      <title>横向化 LoRA：通过模态专门化的适应性进行交叉指令调整</title>
      <link>https://arxiv.org/abs/2407.03604</link>
      <description><![CDATA[arXiv:2407.03604v1 公告类型：新
摘要：视觉语言模型 (VLM) 的最新进展导致了视觉语言通才 (VLG) 的发展，它能够理解和生成交错的图像和文本。尽管取得了这些进展，但 VLG 仍然难以遵循用户对交错文本和图像生成的指令。为了解决这个问题，我们引入了 LeafInstruct，这是第一个开源交错指令调整数据，拥有超过 10 个领域的 30,000 多个高质量实例。由于现有 VLG 的规模庞大，我们选择了参数高效的调整。然而，我们观察到使用标准 LoRA 调整的 VLG 在交错文本图像生成中通常表现较差。我们将这个问题归因于模态干扰和缺乏模态专门的适应设计。因此，我们提出了 Lateralization LoRA，这是一种受大脑侧化概念启发的新型模态专门适应方法。 Lateralization LoRA 采用混合方法，将传统的线性 LoRA 与卷积 LoRA 相结合以生成文本和图像，从而利用特定于模态的结构和参数集生成高质量的文本和图像。我们使用 Lateralization LoRA 在 LeafInstruct 数据集上对 VLG（即 EMU2）进行指令调整。大量实验表明，使用 Lateralization LoRA 调整的 EMU2 实现了最先进的性能，在复杂的交错任务中显著超越了基线模型。]]></description>
      <guid>https://arxiv.org/abs/2407.03604</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:39 GMT</pubDate>
    </item>
    <item>
      <title>对话可视化：利用大型语言模型通过对话理解增强图像选择</title>
      <link>https://arxiv.org/abs/2407.03615</link>
      <description><![CDATA[arXiv:2407.03615v1 公告类型：新
摘要：对话系统的最新进展凸显了整合多模态响应的重要性，这使得人们能够通过多种模态传达思想，而不仅仅是依靠基于文本的交互。这种丰富不仅提高了整体沟通效率，而且提高了对话体验的质量。然而，现有的对话到图像检索方法面临限制，因为预先训练的视觉语言模型 (VLM) 在准确理解复杂对话方面受到限制。为了解决这个问题，我们提出了一种新方法，利用大型语言模型 (LLM) 的强大推理能力来生成精确的对话相关视觉描述符，从而促进与图像的无缝连接。在基准数据上进行的大量实验验证了我们提出的方法在得出简洁准确的视觉描述符方面的有效性，从而显着提高了对话到图像检索性能。此外，我们的研究结果证明了该方法在不同视觉线索、各种 LLM 和不同数据集中的通用性，强调了其在实际应用中的实用性和潜在影响。]]></description>
      <guid>https://arxiv.org/abs/2407.03615</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:39 GMT</pubDate>
    </item>
    <item>
      <title>评估 NLP 中人机决策的解释效用</title>
      <link>https://arxiv.org/abs/2407.03545</link>
      <description><![CDATA[arXiv:2407.03545v1 公告类型：新
摘要：可解释性是一个虚假的承诺吗？这场争论源于没有足够的证据表明解释可以帮助人们应对他们所面对的情况。需要更多以人为本、以应用为基础的解释评估来解决这个问题。然而，由于 NLP 中没有为此类研究建立的指导方针，习惯于标准化代理评估的研究人员必须在他们的研究中为人机协作找到适当的测量、任务、数据集和合理的模型。
为了解决这个问题，我们首先回顾了现有的拟合指标。然后，我们为适合以应用为基础的评估的数据集建立了标准。在 50 多个可用于 NLP 可解释性研究的数据集中，我们发现 4 个符合我们的标准。通过微调 Flan-T5-3B，我们证明了重新评估最新技术以形成和研究人机协作的重要性。最后，我们针对已确定的合适任务之一——根据合同验证法律索赔的正确性——提出了人机决策的示范研究。]]></description>
      <guid>https://arxiv.org/abs/2407.03545</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>核心：通过信息丰富的子声明识别进行可靠的事实精度评分</title>
      <link>https://arxiv.org/abs/2407.03572</link>
      <description><![CDATA[arXiv:2407.03572v1 公告类型：新
摘要：幻觉——不真实主张的产生——对大型语言模型 (LLM) [1] 的应用构成了挑战，从而推动了评估事实精度的指标的发展。我们观察到，使用分解然后验证框架的流行指标（例如 FActScore [2]）可以通过添加明显或重复的主张来人为地提高分数。我们扩展了 FActScore 数据集来设计和分析事实精度指标，证明了可以通过利用我们发现的问题来训练模型以在现有指标下获得高分。这激发了我们新的可定制即插即用子声明选择组件 Core，它根据各个子声明的独特性和信息量对其进行筛选。如头对头比较所示，通过 Core 增强的指标更加稳健。我们发布了一个支持模块化使用 Core (https://github.com/zipJiang/Core) 和各种分解策略的评估框架，并建议 LLM 社区采用它。
[1] Hong 等人，“幻觉排行榜——一项在大型语言模型中测量幻觉的开放努力”，arXiv:2404.05904v2 [cs.CL]。
[2] Min 等人，“FActScore：长文本生成中事实精度的细粒度原子评估”，arXiv:2305.14251v2 [cs.CL]。]]></description>
      <guid>https://arxiv.org/abs/2407.03572</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>在大型语言模型中集成随机性：用于生成临床相关内容的线性同余生成器方法</title>
      <link>https://arxiv.org/abs/2407.03582</link>
      <description><![CDATA[arXiv:2407.03582v1 公告类型：新
摘要：从语言模型生成多样化、高质量的输出对于教育和内容创作中的应用至关重要。实现真正的随机性和避免重复仍然是一项重大挑战。本研究使用线性一致性生成器方法进行系统事实选择，并结合人工智能驱动的内容生成。我们确保了多轮胃肠生理学和病理学事实的独特组合，将这些事实整合到 GPT-4o 的提示中，以创建临床相关的小插图式输出。在 14 轮中，生成了 98 个独特的输出，证明了 LCG 在生成多样化和高质量内容方面的有效性。该方法解决了随机性和重复性的关键问题，提高了语言模型为各种应用生成内容的质量和效率。]]></description>
      <guid>https://arxiv.org/abs/2407.03582</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>具有法学硕士生成策略和信息检索功能的零样本说服聊天机器人</title>
      <link>https://arxiv.org/abs/2407.03585</link>
      <description><![CDATA[arXiv:2407.03585v1 公告类型：新
摘要：说服在从健康干预到促进社会公益的广泛应用中发挥着关键作用。说服性聊天机器人可以加速说服在这些应用中的积极影响。现有的方法依赖于使用特定于任务的训练数据对说服性聊天机器人进行微调，而这些数据的收集成本很高，甚至不可行。为了解决这个问题，我们提出了一种方法，利用大型语言模型 (LLM) 的通用性和固有说服能力，以零样本方式为任何给定领域创建有效且真实的说服性聊天机器人。与以前使用预定义说服策略的研究不同，我们的方法首先使用 LLM 来生成响应，然后提取动态使用的策略，并用检索到的支持策略的事实替换响应中任何未经证实的声明。我们将聊天机器人 PersuaBot 应用于三个截然不同的领域，这些领域都需要说服技能：募捐、推荐和健康干预。我们在模拟和人类对话上进行的实验表明，我们的零样本方法比以前的工作更有说服力，同时实现了超越最先进的知识型聊天机器人的事实准确性。我们的研究表明，当说服性聊天机器人被负责任地用于社会公益时，它将成为个人和社会积极变革的推动者。]]></description>
      <guid>https://arxiv.org/abs/2407.03585</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:38 GMT</pubDate>
    </item>
    <item>
      <title>在 Minecraft 中与 LLM 驱动的非玩家角色协作完成任务</title>
      <link>https://arxiv.org/abs/2407.03460</link>
      <description><![CDATA[arXiv:2407.03460v1 公告类型：新
摘要：生成式人工智能在视频游戏开发中的应用正在增加，随着大型语言模型的对话和其他功能的不断改进，我们预计 LLM 驱动的非玩家角色 (NPC) 将得到广泛部署。在本文中，我们试图了解人类玩家如何与 LLM 驱动的 NPC 合作完成游戏内目标。我们在 Minecraft 中设计了一个迷你游戏，玩家与两个 GPT4 驱动的 NPC 合作完成任务。我们进行了一项用户研究，其中 28 名 Minecraft 玩家玩这个迷你游戏并分享他们的反馈。在分析游戏日志和录音时，我们发现 NPC 和人类玩家出现了几种协作行为模式。我们还报告了目前没有丰富游戏状态或视觉理解的纯语言模型的局限性。我们相信这项初步研究和分析将为未来的游戏开发者提供信息，让他们了解如何更好地利用这些快速改进的生成式人工智能模型来实现游戏中的协作角色。]]></description>
      <guid>https://arxiv.org/abs/2407.03460</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:37 GMT</pubDate>
    </item>
    <item>
      <title>提升法学硕士的惯用翻译能力</title>
      <link>https://arxiv.org/abs/2407.03518</link>
      <description><![CDATA[arXiv:2407.03518v1 公告类型：新
摘要：对于像 NLLB 和 GPT 这样的大型语言模型 (LLM)，翻译习语仍然是一个挑战。我们的目标是通过改进 LLM 对惯用语言的处理，同时保留原始语言风格，来提高翻译保真度。这具有重大的社会影响，因为它保留了文化细微差别，并确保翻译文本保留其意图和情感共鸣，促进更好的跨文化交流。以前的工作利用了像 IdiomKB 这样的知识库，为 LLM 提供用于翻译的习语的含义。虽然这种方法比直接翻译产生了更好的结果，但它在跨语言保留惯用写作风格的能力方面仍然有限。在这项研究中，我们扩展了知识库以找到目标语言中的相应习语。我们的研究使用两种方法进行翻译：第一种方法使用 SentenceTransformers 模型在语义上生成源语言和目标语言习语含义之间的余弦相似度得分，从而选出最佳习语（余弦相似度方法）。第二种方法使用 LLM 在目标语言中查找相应的习语以用于翻译（LLM 生成的习语方法）。作为基准，我们进行了直接翻译，而不提供其他信息。对英文 -&gt; 中文和中文 -&gt; 英文的人工评估表明，余弦相似度查找方法在所有 GPT4o 翻译中的表现均优于其他方法。为了进一步构建 IdiomKB，我们开发了一个低资源乌尔都语数据集，其中包含乌尔都语习语及其翻译。尽管数据集存在限制，但余弦相似度查找方法显示出良好的前景，它有可能克服语言障碍，并使探索中文和乌尔都语的多样化文学作品成为可能。如需访问我们的实验代码和复制，请访问（https://github.com/ANON13222/ITR）。]]></description>
      <guid>https://arxiv.org/abs/2407.03518</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:37 GMT</pubDate>
    </item>
    <item>
      <title>UnSeenTimeQA：超越法学硕士记忆的时间敏感型问答</title>
      <link>https://arxiv.org/abs/2407.03525</link>
      <description><![CDATA[arXiv:2407.03525v1 公告类型：新
摘要：本文介绍了 UnSeenTimeQA，这是一种新颖的时间敏感问答 (TSQA) 基准，它通过避免事实和可网络搜索的查询与传统 TSQA 基准不同。我们提出了一系列与现实世界事实信息脱钩的时间敏感事件场景。它需要大型语言模型 (LLM) 进行真正的时间推理，与预训练阶段获得的知识脱钩。我们对六个开源 LLM（大小从 2B 到 70B 不等）和三个闭源 LLM 的评估表明，来自 UnSeenTimeQA 的问题带来了巨大的挑战。这表明模型在处理复杂的时间推理场景方面存在困难。此外，我们还提出了几项分析，阐明了模型在回答时间敏感问题方面的表现。]]></description>
      <guid>https://arxiv.org/abs/2407.03525</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:37 GMT</pubDate>
    </item>
    <item>
      <title>孟加拉语大型语言模型中的社会偏见：性别和宗教偏见的实证研究</title>
      <link>https://arxiv.org/abs/2407.03536</link>
      <description><![CDATA[arXiv:2407.03536v1 公告类型：新
摘要：大型语言模型 (LLM) 的快速发展使偏见研究成为一个重要领域。评估 LLM 中嵌入的不同类型偏见的影响对于确保在敏感领域的公平使用非常重要。尽管已经有大量关于英语偏见评估的研究，但对于像孟加拉语这样的主要语言来说，这样的努力很少见。在这项工作中，我们研究了 LLM 生成的孟加拉语输出中的两种社会偏见。我们在这项工作中的主要贡献是：(1) 对孟加拉语的两种不同社会偏见的偏见研究 (2) 用于偏见测量基准测试的精选数据集 (3) 两种不同的孟加拉语背景下的偏见检测探测技术。据我们所知，这是第一项涉及孟加拉语 LLM 偏见评估的此类工作。我们所有的代码和资源都是公开的，用于孟加拉语 NLP 中偏见相关研究的进展。]]></description>
      <guid>https://arxiv.org/abs/2407.03536</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:37 GMT</pubDate>
    </item>
    <item>
      <title>XferBench：新兴语言的数据驱动基准</title>
      <link>https://arxiv.org/abs/2407.03456</link>
      <description><![CDATA[arXiv:2407.03456v1 公告类型：新
摘要：在本文中，我们引入了一个使用数据驱动方法评估新兴语言整体质量的基准。具体来说，我们将新兴语言的“质量”概念解释为深度学习框架内其与人类语言的相似性。我们通过使用新兴语言作为人类语言下游 NLP 任务的预训练数据来衡量这一点——下游性能越好，新兴语言就越好。我们将这个基准实现为一个易于使用的 Python 包，只需要一个来自新兴语言的话语文本文件即可进行评估。最后，我们使用人类、合成和新兴语言基线对基准的有效性进行了实证测试。]]></description>
      <guid>https://arxiv.org/abs/2407.03456</guid>
      <pubDate>Tue, 09 Jul 2024 03:16:36 GMT</pubDate>
    </item>
    </channel>
</rss>