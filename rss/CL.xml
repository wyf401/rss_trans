<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Thu, 04 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>关于编码器-解码器语言模型中的线性化结构化数据：来自文本到 SQL 的见解</title>
      <link>https://arxiv.org/abs/2404.02389</link>
      <description><![CDATA[arXiv:2404.02389v1 公告类型：新
摘要：结构化数据普遍存在于表格、数据库和知识图谱中，对其表示提出了重大挑战。随着大型语言模型 (LLM) 的出现，人们开始转向基于线性化的方法，这种方法将结构化数据作为顺序标记流进行处理，这与通常以图形形式显式建模结构的方法不同。至关重要的是，我们对这些基于线性化的方法如何处理本质上非线性的结构化数据的理解仍然存在差距。这项工作研究了编码器-解码器语言模型（特别是 T5）中结构化数据的线性处理。我们的研究结果揭示了该模型能够模仿人类设计的过程，例如模式链接和语法预测，这表明对结构的深入、有意义的学习超出了简单的标记排序。我们还揭示了对模型内部机制的见解，包括结构节点编码的以自我为中心的性质以及由于模态融合冗余而导致的模型压缩的潜力。总的来说，这项工作揭示了基于线性化的方法的内部工作原理，并可能为未来的研究提供指导。]]></description>
      <guid>https://arxiv.org/abs/2404.02389</guid>
      <pubDate>Thu, 04 Apr 2024 07:33:00 GMT</pubDate>
    </item>
    <item>
      <title>具有形态建模的低资源神经机器翻译</title>
      <link>https://arxiv.org/abs/2404.02392</link>
      <description><![CDATA[arXiv:2404.02392v1 公告类型：新
摘要：神经机器翻译（NMT）中的形态建模是实现形态丰富的语言的开放词汇机器翻译的一种有前途的方法。然而，现有的方法（例如子词标记化和基于字符的模型）仅限于单词的表面形式。在这项工作中，我们提出了一个框架解决方案，用于在资源匮乏的环境中对复杂形态进行建模。选择两层变压器架构来对输入处的形态信息进行编码。在目标端输出，多任务多标签训练方案与基于波束搜索的解码器相结合，可以提高机器翻译性能。以通用形式提出了变压器模型的注意力增强方案，以允许集成预训练的语言模型，并且还有助于对源语言和目标语言之间的词序关系进行建模。评估了几种数据增强技术，并证明它们可以提高资源匮乏环境中的翻译性能。我们评估了我们提出的基尼亚卢旺达语解决方案 - 使用公共领域并行文本的英语翻译。我们的最终模型实现了与大型多语言模型相比的竞争性能。我们希望我们的结果将激励更多地使用显式形态信息以及在低资源 NMT 中所提出的模型和数据增强。]]></description>
      <guid>https://arxiv.org/abs/2404.02392</guid>
      <pubDate>Thu, 04 Apr 2024 07:33:00 GMT</pubDate>
    </item>
    <item>
      <title>歌词相似度感知的计算分析</title>
      <link>https://arxiv.org/abs/2404.02342</link>
      <description><![CDATA[arXiv:2404.02342v1 公告类型：新
摘要：在包含声乐的音乐作品中，歌词对艺术表达有重要贡献。因此，之前的研究引入了推荐系统的概念，该系统建议与用户的最爱或个性化偏好类似的歌词，帮助在数百万首曲目中发现歌词。然而，这些系统中的许多系统并没有充分考虑人类对歌词相似性的感知，这主要是由于该领域的研究有限。为了弥补这一差距，我们对用于模拟歌词与人类感知的相似性的计算方法进行了比较分析。结果表明，基于预训练的基于 BERT 的模型的嵌入之间的相似性的计算模型、从中导出歌词的音频以及语音组件可以指示感知的歌词相似性。这一发现强调了语义、风格和语音相似性在人类对歌词相似性的感知中的重要性。我们预计我们的研究结果将通过为神经网络开发提供伪标签并引入客观评估指标来促进基于相似性的歌词推荐系统的开发。]]></description>
      <guid>https://arxiv.org/abs/2404.02342</guid>
      <pubDate>Thu, 04 Apr 2024 07:32:59 GMT</pubDate>
    </item>
    <item>
      <title>两个头比一个头更好：嵌套 PoE 可稳健防御多后门</title>
      <link>https://arxiv.org/abs/2404.02356</link>
      <description><![CDATA[arXiv:2404.02356v1 公告类型：新
摘要：数据中毒后门攻击可能会在大型语言模型（LLM）中导致不良行为，防御它们变得越来越重要。现有的防御机制通常假设攻击者只采用一种类型的触发器，而防御多种同时且独立的触发器类型则需要通用的防御框架，并且相对未经探索。在本文中，我们提出了专家嵌套产品（NPoE）防御框架，其中涉及专家混合（MoE）作为 PoE 防御框架内的仅触发集成，以同时防御多种触发类型。在 NPoE 训练期间，主模型在与学习后门触发器特征的较小专家模型的混合体中进行训练。在推理时，仅使用主模型。情感分析、仇恨言论检测和问题分类任务的实验结果表明，NPoE 可以有效地防御各种单独的触发因素和混合触发因素。由于NPoE中MoE结构的多功能性，该框架可以进一步扩展以防御其他攻击设置]]></description>
      <guid>https://arxiv.org/abs/2404.02356</guid>
      <pubDate>Thu, 04 Apr 2024 07:32:59 GMT</pubDate>
    </item>
    <item>
      <title>尼泊尔语和孟加拉语的光学文本识别：基于 Transformer 的方法</title>
      <link>https://arxiv.org/abs/2404.02375</link>
      <description><![CDATA[arXiv:2404.02375v1 公告类型：新
摘要：针对低资源语言的 OCR 系统的研究和开发工作相对较新。资源匮乏的语言几乎没有可用于训练机器翻译系统或其他系统的训练数据。尽管大量文本已被数字化并在互联网上提供，但文本仍然是 PDF 和图像格式，无法立即访问。本文讨论了两种文字的文本识别：孟加拉语和尼泊尔语；讲孟加拉语和尼泊尔语的人数分别约为 300 和 4000 万。在这项研究中，使用编码器-解码器变压器开发了一个模型，并使用一系列手写和打印的光学文本图像来评估其功效。结果表明，所提出的技术与当前的方法相符，并且在识别孟加拉语和尼泊尔语文本方面实现了高精度。这项研究可以为东南亚语言学的先进且易于理解的研究铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2404.02375</guid>
      <pubDate>Thu, 04 Apr 2024 07:32:59 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行领域驱动术语提取的比较研究</title>
      <link>https://arxiv.org/abs/2404.02330</link>
      <description><![CDATA[arXiv:2404.02330v1 公告类型：新
摘要：关键词在弥合人类理解和机器处理文本数据之间的差距方面发挥着至关重要的作用。它们对于数据丰富至关重要，因为它们构成了详细注释的基础，可以提供对基础数据更有洞察力和更深入的了解。关键词/领域驱动的术语提取是自然语言处理中的一项关键任务，有助于信息检索、文档摘要和内容分类。本次综述重点关注关键词提取方法，强调三种主要大型语言模型（LLM）的使用：Llama2-7B、GPT-3.5 和 Falcon-7B。我们采用了自定义 Python 包来与这些法学硕士进行交互，从而简化了关键字提取。我们的研究利用 Inspec 和 PubMed 数据集评估了这些模型的性能。使用 Jaccard 相似性指数进行评估，GPT-3.5 的得分为 0.64 (Inspec) 和 0.21 (PubMed)，Llama2-7B 的得分为 0.40 和 0.17，Falcon-7B 的得分为 0.23 和 0.12。本文强调了法学硕士中提示工程对于更好地提取关键词的作用，并讨论了法学硕士中的幻觉对结果评估的影响。它还揭示了使用法学硕士进行关键字提取的挑战，包括模型复杂性、资源需求和优化技术。]]></description>
      <guid>https://arxiv.org/abs/2404.02330</guid>
      <pubDate>Thu, 04 Apr 2024 07:32:58 GMT</pubDate>
    </item>
    <item>
      <title>Multi-BERT：利用适配器和快速调优实现低资源多域适应</title>
      <link>https://arxiv.org/abs/2404.02335</link>
      <description><![CDATA[arXiv:2404.02335v1 公告类型：新
摘要：文本数量和多样性的快速增长在多领域环境中提出了巨大的挑战。这些挑战在波斯语名称实体识别 (NER) 设置中也很明显。传统方法，要么对多个领域采用统一模型，要么对每个领域采用单独的模型，通常会带来很大的局限性。单个模型通常难以捕捉不同领域的细微差别，而使用多个大型模型可能会导致资源限制，从而使每个领域的模型训练几乎不切实际。因此，本文介绍了一种由一个核心模型和多组特定领域参数组成的新方法。我们利用提示调整和适配器等技术，结合附加层的结合，添加我们可以针对特定领域进行训练的参数。这使得该模型的性能与每个领域的单个模型相当。在不同正式和非正式数据集上的实验结果表明，通过使用这些添加的参数，所提出的模型在性能上显着超过了现有的实际模型。值得注意的是，所提出的模型只需要一个实例进行训练和存储，但在所有领域都取得了出色的结果，甚至在某些领域超越了最先进的技术。此外，我们分析了每种适应策略，描述其优点、缺点以及波斯 NER 设置的最佳超参数。最后，我们引入了一种针对未知文本域场景的基于文档的域检测管道，增强了本文在实际应用中的适应性和实用性。]]></description>
      <guid>https://arxiv.org/abs/2404.02335</guid>
      <pubDate>Thu, 04 Apr 2024 07:32:58 GMT</pubDate>
    </item>
    <item>
      <title>注释器建模和扩展的语料库注意事项</title>
      <link>https://arxiv.org/abs/2404.02340</link>
      <description><![CDATA[arXiv:2404.02340v1 公告类型：新
摘要：自然语言处理研究和注释任务的最新趋势证实了范式的转变，从传统上依赖单一基本事实到关注个人观点，特别是在主观任务中。在注释任务旨在包含多样性的场景中，仅依赖多数类标签的模型可能会无意中忽视有价值的少数观点。这种监督可能会导致重要信息的遗漏，并且在更广泛的背景下，可能会破坏更大生态系统内的平衡。随着注释器建模的前景随着不同的表示技术而展开，有必要通过所考虑的数据集的细粒度特征来研究它们的有效性。这项研究系统地探索了各种注释器建模技术，并比较了它们在七个语料库中的性能。
  根据我们的研究结果，我们表明常用的用户令牌模型始终优于更复杂的模型。我们引入了一种复合嵌入方法，并显示了哪种模型在与给定数据集的一致性方面表现最佳的明显差异。我们的研究结果揭示了语料库统计数据和注释器建模性能之间的关系，这为未来语料库构建和视角 NLP 的工作提供了信息。]]></description>
      <guid>https://arxiv.org/abs/2404.02340</guid>
      <pubDate>Thu, 04 Apr 2024 07:32:58 GMT</pubDate>
    </item>
    <item>
      <title>提示作为程序：一种有效编译时提示优化的结构感知方法</title>
      <link>https://arxiv.org/abs/2404.02319</link>
      <description><![CDATA[arXiv:2404.02319v1 公告类型：新
摘要：大型语言模型（LLM）现在可以处理更长、更复杂的输入，这有助于使用更复杂的提示。但是，提示通常需要进行一些调整才能提高部署性能。最近的工作提出了自动提示优化方法，但随着提示复杂性和LLM强度的增加，许多提示优化技术不再足够，需要一种新的方法来优化{\em元提示程序}。为了解决这个问题，我们引入了 SAMMO，一个用于元提示程序的编译时优化的框架，它将提示表示为结构化对象，允许在优化期间搜索丰富的转换集。我们表明，SAMMO 概括了以前的方法，并在多个不同的 LLM 中提高了 (1) 指令调整、(2) RAG 管道调整和 (3) 提示压缩的复杂提示的性能。
  我们在 https://github.com/microsoft/sammo 上开源所有代码。]]></description>
      <guid>https://arxiv.org/abs/2404.02319</guid>
      <pubDate>Thu, 04 Apr 2024 07:32:57 GMT</pubDate>
    </item>
    <item>
      <title>走向非正式语言处理：大型语言模型中的俚语知识</title>
      <link>https://arxiv.org/abs/2404.02323</link>
      <description><![CDATA[arXiv:2404.02323v1 公告类型：新
摘要：大型语言模型（LLM）的最新进展为自然语言系统处理非正式语言提供了强大的潜力。非正式语言的代表形式是俚语，常用于日常对话和在线社交媒体中。迄今为止，俚语尚未在法学硕士中得到全面评估，部分原因是缺乏精心设计且可公开访问的基准。使用电影字幕，我们构建了一个数据集，支持对与俚语自动处理相关的各种任务进行评估。对于评估和微调，我们展示了我们的数据集在两个核心应用程序上的有效性：1）俚语检测，2）从自然句子中识别俚语的区域和历史来源。我们还展示了如何使用我们的数据集来探测法学硕士的输出分布以获得解释性见解。我们发现，虽然 GPT-4 等 LLM 在零样本设置中实现了良好的性能，但在我们的数据集上进行微调的较小的类 BERT 模型也实现了相当的性能。此外，我们还表明，我们的数据集可以对 GPT-3.5 等 LLM 进行微调，从而实现比强大的零样本基线更好的性能。我们的工作基于 OpenSubtitles 语料库提供了对英语俚语的全面评估和高质量基准，既作为可公开访问的资源，又作为应用非正式语言处理工具的平台。]]></description>
      <guid>https://arxiv.org/abs/2404.02323</guid>
      <pubDate>Thu, 04 Apr 2024 07:32:57 GMT</pubDate>
    </item>
    <item>
      <title>循环中的法学硕士：利用大型语言模型注释进行低资源语言的主动学习</title>
      <link>https://arxiv.org/abs/2404.02261</link>
      <description><![CDATA[arXiv:2404.02261v1 公告类型：新
摘要：由于语言资源和数据标记专业知识有限，低资源语言在人工智能开发中面临重大障碍，导致它们稀有且昂贵。数据的稀缺和现有工具的缺乏加剧了这些挑战，特别是因为这些语言可能无法在各种 NLP 数据集中得到充分表示。为了解决这一差距，我们建议利用法学硕士在数据注释的主动学习循环中的潜力。首先，我们进行评估以评估注释者之间的一致性和一致性，以促进选择合适的法学硕士注释者。然后，使用主动学习范例将所选注释器集成到分类器的训练循环中，从而最大限度地减少所需的查询数据量。实证评估，特别是使用 GPT-4-Turbo，展示了近乎最先进的性能，同时显着减少了数据需求，与人工注释相比，预计潜在成本节省至少 42.45 倍。我们提出的解决方案显示出显着降低资源匮乏环境中与自动化相关的货币和计算成本的巨大潜力。通过弥合低资源语言和人工智能之间的差距，这种方法促进了更广泛的包容性，并展示了跨不同语言环境实现自动化的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.02261</guid>
      <pubDate>Thu, 04 Apr 2024 07:32:56 GMT</pubDate>
    </item>
    <item>
      <title>通过 ChatGPT 从合同中提取规范：机遇与挑战</title>
      <link>https://arxiv.org/abs/2404.02269</link>
      <description><![CDATA[arXiv:2404.02269v1 公告类型：新
摘要：我们研究了 ChatGPT 从合同中提取规范的有效性。规范通过捕获如何管理两个或多个自治方之间的交互，提供了一种设计多智能体系统的自然方法。我们从合同中提取承诺、禁止、授权和权力的规范，以及相关的规范要素（涉及的各方、前因和后果）。我们的调查揭示了 ChatGPT 在从合同中提取规范方面的有效性和局限性。 ChatGPT 在范数提取方面表现出了良好的性能，无需训练或微调，从而无需注释数据，而注释数据在该领域通常不可用。然而，我们发现 ChatGPT 在提取这些范数时存在一些局限性，导致范数提取不正确。这些限制包括对关键细节的忽视、幻觉、连词解析不正确以及空洞的规范元素。增强合同中的规范提取可以促进开发更透明、更值得信赖的正式代理交互规范，从而有助于改进多代理系统。]]></description>
      <guid>https://arxiv.org/abs/2404.02269</guid>
      <pubDate>Thu, 04 Apr 2024 07:32:56 GMT</pubDate>
    </item>
    <item>
      <title>自训练语言模型的崩溃</title>
      <link>https://arxiv.org/abs/2404.02305</link>
      <description><![CDATA[arXiv:2404.02305v1 公告类型：新
摘要：在包括科学在内的知识创造的各个领域，新想法通常建立在现有信息的基础上。在这项工作中，我们在语言模型的背景下探索这个概念。具体来说，我们探索自我训练模型在其自身输出上的潜力，类似于人类如何学习并建立在他们之前的想法和行动的基础上。虽然这种方法直观上很有吸引力，但我们的研究揭示了其实际局限性。我们发现 GPT-2 模型的扩展自我训练会导致性能显着下降，导致代币输出重复和崩溃。]]></description>
      <guid>https://arxiv.org/abs/2404.02305</guid>
      <pubDate>Thu, 04 Apr 2024 07:32:56 GMT</pubDate>
    </item>
    <item>
      <title>缩小规模的生成语言模型中的涌现能力</title>
      <link>https://arxiv.org/abs/2404.02204</link>
      <description><![CDATA[arXiv:2404.02204v1 公告类型：新
摘要：大型语言模型可以解决新任务，而无需针对特定任务进行微调。这种能力也称为上下文学习（ICL），被认为是一种新兴能力，主要出现在具有数十亿参数的大型语言模型中。这项研究调查了这些新出现的属性是否与模型大小严格相关，或者可以通过在缩小规模的数据上训练的较小模型来证明。为了探索这一点，我们简化了预训练数据并预训练了 36 个因果语言模型，参数范围从 100 万到 1.65 亿不等。我们表明，在这种简化的预训练数据上训练的模型在简化语言的各种任务中表现出增强的零样本能力，其性能可与在不受限制的语言上预训练的模型相比提高六倍。这表明，缩小语言规模可以在尺寸有限的模型中出现零样本学习能力。此外，我们发现这些在简化数据上预训练的较小模型展示了评估损失与三个缩放因子（计算、数据集大小和模型大小）之间的幂律关系。]]></description>
      <guid>https://arxiv.org/abs/2404.02204</guid>
      <pubDate>Thu, 04 Apr 2024 07:32:55 GMT</pubDate>
    </item>
    <item>
      <title>$\texttt{LM}^\texttt{2}$：语言模型的简单社会解决复杂推理</title>
      <link>https://arxiv.org/abs/2404.02255</link>
      <description><![CDATA[arXiv:2404.02255v1 公告类型：新
摘要：尽管展示了紧急推理能力，大型语言模型（LLMS）经常无法追踪复杂的多步骤推理。现有研究表明，通过将原始问题分解为多个子问题来提供指导，可以使 LLM 推理更加稳健——分解器生成子问题，求解器解决每个子问题。然而，这些技术无法适应分解器和求解器模块（无论是在单个模型中还是在不同的专用模型中）之间的协调——分解器无法跟踪求解器遵循分解推理的能力。在本文中，我们提出 LM2 来应对这些挑战。 LM2将分解、求解和验证模块化为三种不同的语言模型。分解器模块识别解决问题所需的关键概念，并根据推理要求生成逐步的子问题。求解器模型生成子问题的解决方案，然后由验证器模块检查；根据验证者的反馈，使用子问题和解决方案构建推理上下文。这些模型经过训练可以使用策略学习进行协调。详尽的实验表明，LM2 在域内和域外推理问题上优于现有方法，在 MATH 上优于最佳基线 $8.1\%$，在 JEEBench 上优于最佳基线 $7.71\%$，在 MedQA 问题上优于最佳基线 $9.7\%$（代码可用）位于 https://github.com/LCS2-IIITD/Language_Model_Multiplex）。]]></description>
      <guid>https://arxiv.org/abs/2404.02255</guid>
      <pubDate>Thu, 04 Apr 2024 07:32:55 GMT</pubDate>
    </item>
    </channel>
</rss>