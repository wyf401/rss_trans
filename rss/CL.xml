<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 03 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>僧伽罗音乐视频中僧伽罗语 YouTube 评论的语言学分析：一项数据集研究</title>
      <link>https://arxiv.org/abs/2501.18633</link>
      <description><![CDATA[arXiv:2501.18633v1 公告类型：新
摘要：本研究调查了音乐信息检索 (MIR) 和音乐情感识别 (MER) 与僧伽罗歌曲的关系，这是音乐研究中尚未充分探索的领域。本研究的目的是使用社交媒体评论作为主要数据源，分析 YouTube 僧伽罗歌曲视频中僧伽罗评论的行为。其中包括来自 27 个 YouTube 视频的评论，其中包含 20 首不同的僧伽罗歌曲，这些评论经过精心挑选，以保持严格的语言可靠性并确保相关性。这一过程共收集了 93,116 条评论，在此基础上，通过高级过滤方法和音译机制进一步完善了数据集，最终得到 63,471 条僧伽罗评论。此外，通过算法得出了 964 个僧伽罗语专用的停用词，其中 182 个与翻译后的 NLTK 语料库中的英语停用词完全匹配。此外，还对僧伽罗语通用领域语料库和僧伽罗语 YouTube 评论语料库进行了比较，证实后者是通用领域的良好代表。精心策划的数据集以及派生的停用词构成了未来 MIR 和 MER 领域研究的重要资源，因为它们可以用于证明计算技术有可能解决跨不同文化传统的复杂音乐体验]]></description>
      <guid>https://arxiv.org/abs/2501.18633</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>社交媒体虚假信息中的不同情感模式？对瓦伦西亚 DANA 的推文和 TikTok 的分析</title>
      <link>https://arxiv.org/abs/2501.18640</link>
      <description><![CDATA[arXiv:2501.18640v1 公告类型：新 
摘要：本研究调查了 DANA 事件期间社交媒体平台上虚假信息的传播情况（DANA 是西班牙语 Depresion Aislada en Niveles Altos 的缩写，意为高海拔孤立性低气压），该事件导致 2024 年 10 月 29 日西班牙瓦伦西亚出现极强降雨和毁灭性洪水。我们创建了一个包含 650 个 TikTok 和 X 帖子的新数据集，并对其进行了手动注释以区分虚假信息和可信内容。此外，使用 GPT-4o 的 Few-Shot 注释方法与手动标签实现了相当大的一致性（Cohen&#39;s kappa 为 0.684）。情绪分析显示，X 上的虚假信息主要与悲伤和恐惧的增加有关，而在 TikTok 上，它与更高程度的愤怒和厌恶有关。使用 LIWC 词典进行的语言分析表明，值得信赖的内容使用更清晰、更真实的语言，而虚假信息则使用否定、感知词和个人轶事来显得可信。对 TikTok 帖子的音频分析突出了不同的模式：值得信赖的音频以更明亮的音调和机械或单调的叙述为特色，以提升清晰度和可信度，而虚假信息音频则利用音调变化、情感深度和操纵性音乐元素来增强参与度。在检测模型中，SVM+TF-IDF 获得了最高的 F1 分数，在有限的数据下表现出色。将音频特征纳入 roberta-large-bne 可提高准确度和 F1 分数，在准确度上超越纯文本对应模型和 SVM。GPT-4o Few-Shot 也表现良好，展示了大型语言模型在自动检测虚假信息方面的潜力。这些发现证明了利用文本和音频特征对于在 TikTok 等多模式平台上改进虚假信息检测的重要性。]]></description>
      <guid>https://arxiv.org/abs/2501.18640</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型对非洲诗歌翻译中文化特定项目进行提示导向输出：初步的多层表格审查</title>
      <link>https://arxiv.org/abs/2501.18644</link>
      <description><![CDATA[arXiv:2501.18644v1 公告类型：新
摘要：本文研究了 Chat Generative PreTrained Transformer Pro 在翻译三本非洲诗歌选集时针对三个结构化提示生成的文化项目的输出。第一个提示很宽泛，第二个提示侧重于诗歌结构，第三个提示强调文化特异性。为了支持这一分析，创建了四个比较表。第一个表展示了三个提示后产生的文化项目的结果，第二个表根据专有名词和常用表达的 Aixela 框架对这些输出进行分类，第三个表总结了人工翻译、自定义翻译引擎和大型语言模型生成的文化项目。最后一张表概述了 Chat Generative PreTrained Transformer Pro 在特定文化提示之后采用的策略。与先前研究中参考人工翻译和自定义翻译引擎的文化项目输出相比，研究结果表明，在将非洲诗歌从英语翻译成法语的过程中，Chat Generative PreTrained Transformer Pro 使用的文化导向提示并没有显著增强文化项目。在五十四个文化项目中，人工翻译重复产生了三十三个文化项目，自定义翻译引擎重复产生了三十八个文化项目，而 Chat Generative PreTrained Transformer Pro 重复产生了四十一个文化项目。未翻译的文化项目揭示了大型语言模型方法在将非洲诗歌中的文化项目从英语翻译成法语时存在的不一致之处。]]></description>
      <guid>https://arxiv.org/abs/2501.18644</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多智能体 LLM 系统的分层思路链提示：可解释大型语言模型的综合方法</title>
      <link>https://arxiv.org/abs/2501.18645</link>
      <description><![CDATA[arXiv:2501.18645v1 公告类型：新
摘要：大型语言模型 (LLM) 利用思路链 (CoT) 提示提供分步原理，从而提高复杂任务的性能。尽管有诸多好处，但原始 CoT 往往无法完全验证中间推理，并可能产生误导性解释。在这项工作中，我们提出了分层思路链 (Layered-CoT) 提示，这是一种新颖的框架，可系统地将推理过程划分为多个层，每个层都接受外部检查和可选的用户反馈。我们扩展了关键概念，提出了三种场景——医疗分类、财务风险评估和敏捷工程——并展示了分层 CoT 在透明度、正确性和用户参与度方面如何超越原始 CoT。通过整合最近关于交互式可解释性、多智能体框架和基于智能体协作的 arXiv 论文中的参考文献，我们说明了 Layered-CoT 如何为高风险领域中更可靠、更有根据的解释铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2501.18645</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 洗钱后的虚假新闻检测：测量与解释</title>
      <link>https://arxiv.org/abs/2501.18649</link>
      <description><![CDATA[arXiv:2501.18649v1 公告类型：新
摘要：大型语言模型 (LLM) 凭借其先进的功能，可以生成极具说服力且与上下文相关的虚假新闻，从而有助于传播错误信息。尽管对人工编写的文本的虚假新闻检测有很多研究，但检测 LLM 生成的虚假新闻的领域仍未得到充分探索。这项研究衡量了检测器在识别 LLM 释义的虚假新闻方面的有效性，特别是确定在检测流程中添加释义步骤是否有助于或阻碍检测。这项研究的贡献是：(1) 检测器在检测 LLM 释义的虚假新闻方面比检测人工编写的文本更困难，(2) 我们发现哪些模型在哪些任务上表现出色（逃避检测、释义以逃避检测和释义以进行语义相似性）。(3) 通过 LIME 解释，我们发现了检测失败的一个可能原因：情绪转变。 （4）我们发现释义质量测量中存在一个令人担忧的趋势：尽管 BERTSCORE 很高，但样本仍表现出情绪转变。（5）我们提供了一对数据集，用释义输出和分数扩充了现有数据集。该数据集可在 GitHub 上找到]]></description>
      <guid>https://arxiv.org/abs/2501.18649</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有时间推理功能的零样本大型语言模型，用于长篇临床文本摘要</title>
      <link>https://arxiv.org/abs/2501.18724</link>
      <description><![CDATA[arXiv:2501.18724v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展显示出改变医疗保健数据处理的潜力，特别是在理解复杂的临床叙述方面。本研究评估了零样本 LLM 在总结需要时间推理的长篇临床文本方面的有效性，这是全面捕捉患者病史和治疗轨迹的关键方面。我们将一系列先进的零样本 LLM 应用于大量临床文档，评估它们在没有事先进行特定任务训练的情况下整合和准确反映时间动态的能力。虽然这些模型有效地识别了关键的时间事件，但它们在长时间叙述中难以保持时间连贯性。该评估结合了定量和定性方法，突出了零样本 LLM 在临床文本摘要方面的优势和局限性。结果表明，虽然零样本 LLM 很有前景，但需要进一步改进才能有效支持临床决策过程，这强调了需要增强模型训练方法，以更好地捕捉长上下文医疗文档中时间信息的细微差别。]]></description>
      <guid>https://arxiv.org/abs/2501.18724</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>检查大型语言模型在语言复杂性方面的稳健性</title>
      <link>https://arxiv.org/abs/2501.18738</link>
      <description><![CDATA[arXiv:2501.18738v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的进步，越来越多的学生模型利用 LLM 分析学生生成的文本工件，以了解和评估他们的学习。这些学生模型通常使用预先训练的 LLM 将文本输入矢量化为嵌入，然后使用嵌入来训练模型以检测感兴趣的构造的存在或不存在。但是，这些模型在处理不同复杂程度的语言时有多可靠和稳健？在学习的背景下，学生可能具有不同的语言背景和不同水平的写作技能，因此检查此类模型的稳健性至关重要，以确保这些模型对具有不同语言复杂程度的文本同样有效。巧合的是，一些（但有限）的研究表明，语言的使用确实会影响 LLM 的性能。因此，在本研究中，我们研究了几种基于 LLM 的学生模型的稳健性，这些模型可以检测学生在数学问题解决中的自我调节学习 (SRL)。具体来说，我们比较了这些模型在使用词汇、句法和语义复杂度较高和较低的文本时的表现如何变化，这些文本由三种语言学指标衡量。]]></description>
      <guid>https://arxiv.org/abs/2501.18738</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新审视基于投影的数据传输，以实现低资源语言中的跨语言命名实体识别</title>
      <link>https://arxiv.org/abs/2501.18750</link>
      <description><![CDATA[arXiv:2501.18750v1 公告类型：新
摘要：跨语言命名实体识别 (NER) 利用语言之间的知识转移来识别和分类命名实体，这使其对资源匮乏的语言特别有用。我们表明，基于数据的跨语言传输方法是跨语言 NER 的有效技术，并且可以胜过资源匮乏语言的多语言语言模型。本文介绍了针对资源匮乏语言的跨语言 NER 中注释投影步骤的两个关键增强功能。首先，我们探索使用反向翻译来细化单词对齐以提高准确性。其次，我们提出了一种新颖的形式化投影方法，将源实体与提取的目标候选者进行匹配。通过对两个涵盖 57 种语言的数据集进行大量实验，我们证明了我们的方法在资源匮乏的环境中超越了现有的基于投影的方法。这些发现强调了基于投影的数据传输作为基于模型的跨语言命名实体识别方法的替代方案的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2501.18750</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>打破假新闻障碍：孟加拉语的深度学习方法</title>
      <link>https://arxiv.org/abs/2501.18766</link>
      <description><![CDATA[arXiv:2501.18766v1 发布类型：新
摘要：数字平台的快速发展极大地加剧了虚假信息的传播，消除了社会，尤其是孟加拉语社区的信任和判断力。我们的思考通过提出一种有趣的方法来解决这一关键问题，该方法利用深度学习技术，特别是门控重复单元 (GRU)，来识别孟加拉语中的假新闻。我们提出的工作方法包括广泛的数据预处理，包括词形还原、标记化和通过过采样来处理不规则性质。这发生在包含 58,478 个段落的数据集中。我们欣赏基于 GRU（门控重复单元）的演示的创建，该演示展示了出色的性能，准确率高达 94%。本思考对规划信息、选择展示、处理信息和评估其性能所涉及的过程进行了详尽的说明。该模型的性能通过诸如准确率、召回率、F1 分数和准确度等可靠指标进行调查。这项工作的承诺包括创建一个庞大的孟加拉语假新闻数据集和一个优于其他孟加拉语假新闻定位模型的演示。]]></description>
      <guid>https://arxiv.org/abs/2501.18766</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 评估中的高估：数据污染对机器翻译影响的受控大规模研究</title>
      <link>https://arxiv.org/abs/2501.18771</link>
      <description><![CDATA[arXiv:2501.18771v1 公告类型：新
摘要：数据污染——在预训练数据中意外使用评估示例——会破坏评估基准的有效性。在本文中，我们对污染对机器翻译任务中 1B 和 8B 规模的语言模型的影响进行了严格的分析。从精心净化的训练测试分割开始，我们系统地在各个阶段、规模和数据格式中引入污染，以隔离其影响并衡量其对性能指标的影响。我们的实验表明，源和目标的污染都会大大增加 BLEU 分数，与 1B 模型相比，8B 模型的膨胀率是 2.5 倍（高达 30 BLEU 分）。相比之下，仅源和仅目标的污染通常会产生较小、不太一致的高估。最后，我们研究了污染样本的时间分布和频率如何影响具有不同数据资源程度的语言的性能高估。]]></description>
      <guid>https://arxiv.org/abs/2501.18771</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>绳子到 Nope 再回到原点：一种新的混合注意力策略</title>
      <link>https://arxiv.org/abs/2501.18795</link>
      <description><![CDATA[arXiv:2501.18795v1 公告类型：新
摘要：长上下文大型语言模型 (LLM) 取得了显着进步，这得益于旋转位置嵌入 (RoPE) (Su 等人，2023) 及其扩展 (Chen 等人，2023；Liu 等人，2024c；Peng 等人，2023) 等技术。通过调整 RoPE 参数并将训练数据与扩展上下文相结合，我们可以训练具有相当长输入序列的高性能模型。然而，现有的基于 RoPE 的方法在应用于扩展上下文长度时表现出性能限制。本文对各种注意机制进行了全面分析，包括 RoPE、无位置嵌入 (NoPE) 和查询键规范化 (QK-Norm)，确定了它们在长上下文建模中的优势和缺点。我们的研究确定了这些方法中独特的注意模式，并强调了它们对长上下文性能的影响，为架构设计提供了宝贵的见解。基于这些发现，我们提出了一种基于混合注意力机制的新型架构，该架构不仅在长上下文任务中超越了传统的基于 RoPE 的 Transformer 模型，而且在需要较短上下文长度的基准测试中也取得了具有竞争力的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.18795</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型作为常识启发法</title>
      <link>https://arxiv.org/abs/2501.18816</link>
      <description><![CDATA[arXiv:2501.18816v1 公告类型：新
摘要：虽然为解决规划任务而设计的系统在这一领域的表现远远优于大型语言模型 (LLM)，但它们通常会丢弃任务描述中嵌入的丰富语义信息。相比之下，LLM 拥有广泛主题的参数化知识，使它们能够在解决方案中利用规划任务的自然语言描述。然而，目前这方面的研究在生成正确且可执行的计划方面面临挑战。此外，这些方法依赖于 LLM 以中间语言输出解决方案，而这些解决方案必须翻译成规划任务的表示语言。我们引入了一种新颖的规划方法，该方法利用 LLM 的参数化知识，将其输出用作爬山搜索的启发式方法。通过提示 LLM 生成解决方案估计来指导搜索，这种方法得到了进一步增强。我们的方法比普通家庭环境中的类似系统的任务成功率高出 22 个百分点，并且具有一致可执行的计划。所有动作都以其原始表示形式进行编码，表明无需中间语言即可获得强大的结果，从而无需翻译步骤。]]></description>
      <guid>https://arxiv.org/abs/2501.18816</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 Token 选择实现 Transformer 的内存高效微调</title>
      <link>https://arxiv.org/abs/2501.18824</link>
      <description><![CDATA[arXiv:2501.18824v1 公告类型：新
摘要：微调提供了一种有效的方法来专门化预训练模型以用于各种下游任务。然而，微调通常会产生高内存开销，尤其是对于大型基于 Transformer 的模型，例如 LLM。虽然现有方法可能会减少微调所需的某些部分内存，但它们仍然需要缓存前向传递中计算的所有中间激活，以便在后向传递期间更新权重。在这项工作中，我们开发了 TokenTune，这是一种在基于 Transformer 的模型的微调中减少内存使用量的方法，特别是用于存储中间激活的内存。在后向传递过程中，TokenTune 通过仅通过输入 token 的子集进行反向传播来近似梯度计算。因此，使用 TokenTune，在前向传递期间仅缓存中间激活的子集。此外，TokenTune 可以轻松地与 LoRA 等现有方法结合使用，从而进一步降低内存成本。我们在具有多达数十亿个参数的预训练 Transformer 模型上评估了我们的方法，并考虑了在少数样本学习设置中在多个下游任务（例如文本分类和问答）上的性能。总体而言，TokenTune 的性能与完全微调或代表性内存高效微调方法相当，同时大大减少了内存占用，尤其是与具有互补内存减少机制的其他方法结合使用时。我们希望我们的方法能够促进大型 Transformer 的微调，使其专门用于特定领域或与来自更大系统的其他神经组件一起训练它们。我们的代码可在 https://github.com/facebookresearch/tokentune 上找到。]]></description>
      <guid>https://arxiv.org/abs/2501.18824</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于上下文大型语言模型推理的结构嵌入投影</title>
      <link>https://arxiv.org/abs/2501.18826</link>
      <description><![CDATA[arXiv:2501.18826v1 公告类型：新
摘要：结构化嵌入转换提供了一种有前途的方法，可以提高语言模型推理的效率和连贯性。结构化嵌入投影 (SEP) 的引入提供了一种通过集成层次和关系依赖关系的投影矩阵来细化标记表示的机制。SEP 的数学公式使嵌入空间能够捕获结构化的上下文关系，从而提高语义保真度而不会显着增加计算开销。对一系列语言数据集进行的实验评估表明，SEP 有助于减少困惑并增强上下文连贯性，展示了其改进语言模型输出的潜力。计算效率评估强调了不同数据集之间的差异，表明结构化嵌入的集成引入了依赖于数据集的推理速度和表示丰富性之间的权衡。对生成的响应进行定性分析表明，SEP 增强了叙述一致性和主题一致性，从而提高了多句文本生成的流畅度。对嵌入层的修改需要精确优化，以确保稳定的训练动态，因为结构化转换的引入改变了传统的表示学习过程。SEP 实施所需的架构调整影响了推理延迟和内存消耗，需要在效率提升和额外处理需求之间取得平衡。SEP 对词汇多样性的影响表明，嵌入修改影响了模型的词汇使用，反映了对生成的标记进行更具上下文感知的选择。]]></description>
      <guid>https://arxiv.org/abs/2501.18826</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>宪法分类器：通过数千小时的红队演练，防御普遍越狱</title>
      <link>https://arxiv.org/abs/2501.18837</link>
      <description><![CDATA[arXiv:2501.18837v1 公告类型：新
摘要：大型语言模型 (LLM) 容易受到通用越狱提示策略的攻击，这些策略系统地绕过模型保护措施并允许用户执行需要许多模型交互的有害过程，例如大规模制造非法物质。为了防御这些攻击，我们引入了宪法分类器：对合成数据进行训练的保护措施，通过使用指定允许和限制内容的自然语言规则（即宪法）提示 LLM 来生成。在估计超过 3,000 小时的红队演练中，没有红队成员发现通用越狱可以从早期分类器保护的 LLM 中提取与大多数目标查询中不受保护的模型类似的详细程度的信息。在自动评估中，增强型分类器表现出对特定领域越狱的强大防御能力。这些分类器还保持了部署可行性，生产流量拒绝绝对增加了 0.38%，推理开销增加了 23.7%。我们的工作表明，防御普遍越狱同时保持实际部署的可行性是可行的。]]></description>
      <guid>https://arxiv.org/abs/2501.18837</guid>
      <pubDate>Mon, 03 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>