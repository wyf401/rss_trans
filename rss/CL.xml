<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 24 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>图结构推测解码</title>
      <link>https://arxiv.org/abs/2407.16207</link>
      <description><![CDATA[arXiv:2407.16207v1 公告类型：新
摘要：推测解码已成为一种有前途的技术，它通过使用小型语言模型来起草假设序列，然后由 LLM 进行验证，从而加速大型语言模型 (LLM) 的推理。这种方法的有效性在很大程度上取决于草稿模型的性能和效率之间的平衡。在我们的研究中，我们专注于通过生成多个假设而不是一个假设来提高最终输出中接受的草稿标记的比例。这允许 LLM 有更多选项可供选择并选择符合其标准的最长序列。我们的分析表明，草稿模型产生的假设有许多共同的标记序列，这表明优化计算的潜力。利用这一观察结果，我们引入了一种创新方法，利用有向无环图 (DAG) 来管理起草的假设。这种结构使我们能够有效地预测和合并重复的标记序列，大大减少了草稿模型的计算需求。我们将这种方法称为图结构推测解码 (GSD)。我们将 GSD 应用于一系列 LLM，包括 700 亿参数的 LLaMA-2 模型，并观察到显著的加速，从 1.73$\times$ 到 1.96$\times$，大大超过了标准推测解码。]]></description>
      <guid>https://arxiv.org/abs/2407.16207</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:25 GMT</pubDate>
    </item>
    <item>
      <title>逐步冻结多模态实体对齐方式</title>
      <link>https://arxiv.org/abs/2407.16168</link>
      <description><![CDATA[arXiv:2407.16168v1 公告类型：新
摘要：多模态实体对齐旨在发现异构知识图中的相同实体。虽然最近的研究已经深入研究了融合范式以整体表示实体，但忽略了与对齐无关的特征和模态不一致的消除，这是由多模态特征的固有差异引起的。为了应对这些挑战，我们提出了一种新颖的渐进模态冻结策略，称为 PMF，该策略专注于对齐相关特征并增强多模态特征融合。值得注意的是，我们的方法引入了一种开创性的跨模态关联损失来促进模态一致性。对九个数据集的实证评估证实了 PMF 的优越性，展示了最先进的性能和冻结模态的原理。我们的代码可在 https://github.com/ninibymilk/PMF-MMEA 获得。]]></description>
      <guid>https://arxiv.org/abs/2407.16168</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:24 GMT</pubDate>
    </item>
    <item>
      <title>无监督神经语法归纳中的结构优化歧义和简单性偏差</title>
      <link>https://arxiv.org/abs/2407.16181</link>
      <description><![CDATA[arXiv:2407.16181v1 公告类型：新
摘要：神经参数化显著推进了无监督语法归纳。然而，用所有可能的解析的传统似然损失来训​​练这些模型会加剧两个问题：1) $\textit{结构优化歧义}$，尽管对黄金解析有特定的偏好，但仍会任意选择结构模糊的最佳语法之一；2) $\textit{结构简单性偏差}$，导致模型未充分利用规则来组成解析树。这些挑战使无监督神经语法归纳 (UNGI) 面临不可避免的预测错误、高方差以及需要广泛的语法才能实现准确预测。本文解决了这些问题，并对其起源进行了全面的分析。作为一种解决方案，我们引入了 $\textit{逐句解析聚焦}$ 来减少每个句子的解析池以进行损失评估，并使用来自同一数据集上预训练解析器的结构偏差。在无监督解析基准测试中，我们的方法显著提高了性能，同时有效地减少了方差和对过于简单的解析的偏差。我们的研究促进了学习更紧凑、更准确、更一致的显式语法，从而提高了可解释性。]]></description>
      <guid>https://arxiv.org/abs/2407.16181</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:24 GMT</pubDate>
    </item>
    <item>
      <title>DDK：提炼领域知识，构建高效的大型语言模型</title>
      <link>https://arxiv.org/abs/2407.16154</link>
      <description><![CDATA[arXiv:2407.16154v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 在各种应用中都具有先进的智能能力，但它们仍然面临着巨大的计算和存储需求。知识蒸馏 (KD) 已成为一种有效的策略，可通过从高性能 LLM（即教师模型）转移知识来提高较小 LLM（即学生模型）的性能。LLM 蒸馏中的主流技术通常使用黑盒模型 API 来生成高质量的预训练和对齐数据集，或者通过改变损失函数来利用白盒蒸馏来更好地从教师 LLM 转移知识。然而，这些方法忽略了学生和教师 LLM 之间跨领域的知识差异。这导致过度关注性能差距最小的领域，而对差距较大的领域关注不足，从而降低了整体性能。本文介绍了一种新的 LLM 蒸馏框架 DDK，该框架根据教师和学生模型之间的领域性能差异，以平滑的方式动态调整蒸馏数据集的组成，使蒸馏过程更加稳定和有效。大量评估表明，DDK 显著提高了学生模型的性能，大大优于连续预训练基线和现有的知识蒸馏方法。]]></description>
      <guid>https://arxiv.org/abs/2407.16154</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:23 GMT</pubDate>
    </item>
    <item>
      <title>通过严格评估风险，在大型语言模型创新中实现强大的隐私保护</title>
      <link>https://arxiv.org/abs/2407.16166</link>
      <description><![CDATA[arXiv:2407.16166v1 公告类型：新
摘要：本研究考察了将 EHR 和 NLP 与大型语言模型 (LLM) 相结合以改善医疗数据管理和患者护理。它专注于使用高级模型为生物医学研究创建安全、符合 HIPAA 要求的合成患者笔记。该研究使用去识别和重新识别的 MIMIC III 数据集与 GPT-3.5、GPT-4 和 Mistral 7B 生成合成笔记。文本生成使用模板和关键字提取来生成上下文相关的笔记，并使用一次性生成进行比较。隐私评估检查了 PHI 的出现，而文本实用性则使用 ICD-9 编码任务进行测试。使用 ROUGE 和余弦相似度指标评估文本质量，以测量与源笔记的语义相似性。通过 ICD-9 编码任务对 PHI 出现和文本实用性的分析表明，基于关键字的方法风险低且性能良好。一次性生成显示出最高的 PHI 暴露和 PHI 共现，尤其是在地理位置和日期类别中。标准化一次性方法实现了最高的分类准确率。隐私分析揭示了数据效用和隐私保护之间的关键平衡，影响着未来的数据使用和共享。重新识别的数据始终优于去识别的数据。这项研究证明了基于关键字的方法在生成保护隐私的合成临床笔记方面的有效性，这些笔记保留了数据的可用性，有可能改变临床数据共享实践。重新识别的数据比去识别的数据具有更优越的性能，这表明人们正在转向使用虚拟 PHI 来迷惑隐私攻击，从而提高效用和隐私的方法。]]></description>
      <guid>https://arxiv.org/abs/2407.16166</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:23 GMT</pubDate>
    </item>
    <item>
      <title>使用判别指令对生成大型语言模型进行微调，以完成知识图谱</title>
      <link>https://arxiv.org/abs/2407.16127</link>
      <description><![CDATA[arXiv:2407.16127v1 公告类型：新
摘要：传统知识图谱 (KG) 补全模型通过学习嵌入来预测缺失的事实。最近的研究尝试使用大型语言模型 (LLM) 以文本生成的方式完成 KG。然而，他们需要将 LLM 的输出接地到 KG 实体，这不可避免地会带来错误。在本文中，我们提出了一个微调框架 DIFT，旨在释放 LLM 的 KG 补全能力并避免接地错误。给定一个不完整的事实，DIFT 采用轻量级模型来获取候选实体，并使用判别指令对 LLM 进行微调以从给定的候选实体中选择正确的实体。为了在减少指令数据的同时提高性能，DIFT 使用截断采样方法来选择有用的事实进行微调，并将 KG 嵌入注入 LLM。在基准数据集上的大量实验证明了我们提出的框架的有效性。]]></description>
      <guid>https://arxiv.org/abs/2407.16127</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:22 GMT</pubDate>
    </item>
    <item>
      <title>CHIME：法学硕士辅助的科学研究分层组织，用于文献综述支持</title>
      <link>https://arxiv.org/abs/2407.16148</link>
      <description><![CDATA[arXiv:2407.16148v1 公告类型：新
摘要：文献综述需要研究人员综合大量信息，随着科学文献的扩大，文献综述变得越来越具有挑战性。在这项工作中，我们研究了 LLM 生成科学研究的层次结构以协助研究人员进行文献综述的潜力。我们将层次结构组织定义为树结构，其中节点引用主题类别，每个节点都链接到分配给该类别的研究。我们基于 LLM 的简单流程从一组研究中生成层次结构，产生了有希望但不完善的层次结构，这促使我们收集 CHIME，这是一个由专家策划的数据集，用于专注于生物医学的这项任务。鉴于从头开始构建层次结构的挑战性和耗时性，我们使用了一个人在环过程，其中专家纠正 LLM 生成的层次结构中的错误（类别之间的链接和研究分配）。 CHIME 包含 2,174 个 LLM 生成的层次结构，涵盖 472 个主题，以及专家校正的层次结构，涵盖 100 个主题的子集。专家校正使我们能够量化 LLM 的表现，我们发现，虽然他们在生成和组织类别方面相当出色，但它们对研究的类别分配还有待改进。我们尝试使用人工反馈来训练校正模型，这将研究分配提高了 12.6 个 F1 点。我们发布我们的数据集和模型，以鼓励研究开发更好的文献综述辅助工具。]]></description>
      <guid>https://arxiv.org/abs/2407.16148</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:22 GMT</pubDate>
    </item>
    <item>
      <title>KaPQA：知识增强产品问答</title>
      <link>https://arxiv.org/abs/2407.16073</link>
      <description><![CDATA[arXiv:2407.16073v1 公告类型：新
摘要：由于大型语言模型 (LLM) 的最新进展，特定领域应用的问答最近引起了广泛关注。然而，准确评估这些应用程序的性能仍然是一个挑战，主要是因为缺乏能够有效模拟真实场景的合适基准。为了应对这一挑战，我们引入了两个专注于 Adob​​e Acrobat 和 Photoshop 产品的产品问答 (QA) 数据集，以帮助评估现有模型在特定领域产品 QA 任务上的性能。此外，我们提出了一种新颖的知识驱动的 RAG-QA 框架，以提高模型在产品 QA 任务中的性能。我们的实验表明，与标准 RAG-QA 方法相比，通过查询重构来引入领域知识可以提高检索和生成性能。然而，这种改进是微小的，因此说明了引入的数据集所带来的挑战。]]></description>
      <guid>https://arxiv.org/abs/2407.16073</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:21 GMT</pubDate>
    </item>
    <item>
      <title>运用语义细胞分析多义词的演化</title>
      <link>https://arxiv.org/abs/2407.16110</link>
      <description><![CDATA[arXiv:2407.16110v1 Announce Type: new 
摘要：词义在不断演变。同一个词的词义可能从今天到明天发生变化，同一个词的多种词义可能是彼此演变的结果，也就是说，它们可能是父母和孩子。如果我们将朱巴视为一个不断发展的生态系统，那么学习正确答案的范式（不随词义的变化而变化）就不再有效。本文是一个案例研究，表明词义多义性是语义细胞修改的进化结果，作者已经提出了这一点，通过在其初始状态引入少量多样性作为分析当前短句集的示例。特别是，使用 Chat GPT 收集的 Spring 一词的四种含义中每种含义的 1000 个句子的句子序列的分析表明，当这些含义按照它们进化的顺序排列时，该词在分析中单调地获得最多的多义性。换句话说，我们提出了一种分析词语随着进化而获得多义性的动态方法，同时提出了一种从进化框架而不是基于学习的框架来看待多义性的方法。]]></description>
      <guid>https://arxiv.org/abs/2407.16110</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:21 GMT</pubDate>
    </item>
    <item>
      <title>增强 LLM 对半结构化表的时间理解</title>
      <link>https://arxiv.org/abs/2407.16030</link>
      <description><![CDATA[arXiv:2407.16030v1 公告类型：新
摘要：表格数据的时间推理对大型语言模型 (LLM) 提出了巨大挑战，最近的研究表明。在这项研究中，我们对时间数据集进行了全面分析，以确定 LLM 的具体限制。我们的调查导致 TempTabQA 得到增强，这是一个专门为表格时间问答设计的数据集。我们为提高使用表格数据的时间推理任务中的 LLM 性能提供了关键见解。此外，我们引入了一种新方法 C.L.E.A.R 来增强该领域的 LLM 能力。我们的研究结果表明，我们的方法显着提高了各种模型的循证推理能力。此外，我们的实验结果表明，使用辅助数据的间接监督显着提高了这些任务中的模型性能。这项工作有助于更深入地了解 LLM 对表格数据的时间推理能力，并促进其在不同领域的应用进步。]]></description>
      <guid>https://arxiv.org/abs/2407.16030</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:20 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型对社交媒体帖子中的语言变化进行地理定位</title>
      <link>https://arxiv.org/abs/2407.16047</link>
      <description><![CDATA[arXiv:2407.16047v1 公告类型：新
摘要：社交媒体内容的地理定位是根据文本数据确定用户地理位置的任务，文本数据可能显示语言变化和非正式语言。在这个项目中，我们利用大型语言模型 (LLM) 解决了 GeoLingIt 挑战，即对用意大利语撰写的推文进行地理定位。GeoLingIt 需要预测推文的区域和精确坐标。我们的方法涉及微调预先训练的 LLM 以同时预测这些地理定位方面。通过整合创新方法，我们增强了模型理解意大利社交媒体文本细微差别的能力，从而提高了该领域的最新水平。这项工作是 2024 年 Bertinoro 国际春季学校大型语言模型课程的一部分。我们在 GitHub 上公开提供我们的代码 https://github.com/dawoz/geolingit-biss2024。]]></description>
      <guid>https://arxiv.org/abs/2407.16047</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:20 GMT</pubDate>
    </item>
    <item>
      <title>具有偏好条件多方面合成数据生成的增强奖励模型</title>
      <link>https://arxiv.org/abs/2407.16008</link>
      <description><![CDATA[arXiv:2407.16008v1 公告类型：新
摘要：奖励模型 (RM) 对于将大型语言模型 (LLM) 与人类偏好对齐至关重要。它们使用偏好数据集进行训练，其中每个示例由一个输入提示、两个响应和一个偏好标签组成。由于策划高质量的人工标记偏好数据集既耗时又昂贵，人们通常依赖现有的强大 LLM 来生成偏好标签。这可能会引入噪音并阻碍 RM 训练。在这项工作中，我们提出了 RMBoost，一种新颖的合成偏好数据生成范例，以提高奖励模型质量。与在获得偏好标签之前生成两个响应的传统方法不同，RMoost 首先生成一个响应并选择一个偏好标签，然后根据预先选择的偏好标签和第一个响应生成第二个更（或更不）偏好的响应。这种方法有两个主要优点。首先，由于偏好对是故意构建的，因此 RMBoost 减少了标签噪音。其次，RMBoost 通过将各种质量方面（例如有用性、相关性、完整性）纳入提示中，促进创建更加多样化的响应。我们在三个不同的数据集上进行了广泛的实验，并证明 RMBoost 优于其他合成偏好数据生成技术，并显著提升了四种不同奖励模型的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.16008</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:19 GMT</pubDate>
    </item>
    <item>
      <title>多模式输入有助于贝叶斯语音学习模型</title>
      <link>https://arxiv.org/abs/2407.15992</link>
      <description><![CDATA[arXiv:2407.15992v1 公告类型：新
摘要：儿童语言学习者面临的众多任务之一是学习区分母语中构成单词的独特声音。在这里，我们研究多模态信息（特别是成人语音与说话者面部视频帧相结合）是否有益于语音学习的计算模型。我们介绍了一种为现有音频语料库创建高质量说话者面部合成视频的方法。我们的学习模型在对视听输入进行训练和测试时，与仅对音频输入进行训练和测试的模型相比，在音素辨别能力上实现了高达 8.1% 的相对提高。当两者都在纯音频数据上进行测试时，它的表现也比音频模型高出 3.9%，这表明视觉信息有助于获得声学区别。视觉信息在嘈杂的音频环境中尤其有用，与无噪声环境相比，视听模型在噪声环境中的辨别性能损失减少了 67%。这些结果表明，视觉信息对理想的学习者有益，并说明了儿童在学习辨别语音时可以利用视觉提示的一些方法。]]></description>
      <guid>https://arxiv.org/abs/2407.15992</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>SocialQuotes：学习网络上社交媒体引言的语境作用</title>
      <link>https://arxiv.org/abs/2407.16007</link>
      <description><![CDATA[arXiv:2407.16007v1 公告类型：新
摘要：网络作者经常嵌入社交媒体来支持和丰富其内容，从而有可能获得基于网络的跨平台社交媒体表示，从而实现更有效的社交媒体检索系统和更丰富的科学分析。为了实现这些功能，我们引入了一个新颖的语言建模框架，该框架可以自动注释社交媒体实体在其嵌入的网络环境中所扮演的角色。使用相关的通信理论，我们将社交媒体嵌入比作引语，将页面上下文形式化为结构化的自然语言信号，并确定页面上下文中引语的角色分类。我们发布了 SocialQuotes，这是一个新的数据集，它从 Common Crawl 构建，包含超过 3200 万条社交引语，其中 8.3k 条带有众包引语注释。使用 SocialQuotes 和随附的注释，我们提供了一个角色分类案例研究，展示了现代 LLM 的合理性能，并通过页面内容消融揭示了我们框架的可解释方面。我们还对大量未注释的引语进行了分类，揭示了网络上有趣的跨领域、跨平台角色分布。]]></description>
      <guid>https://arxiv.org/abs/2407.16007</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>多语言细粒度新闻标题幻觉检测</title>
      <link>https://arxiv.org/abs/2407.15975</link>
      <description><![CDATA[arXiv:2407.15975v1 公告类型：新
摘要：随着预训练语言模型的进步，自动新闻标题生成的普及度激增。然而，这些模型经常受到“幻觉”问题的困扰，即生成的标题没有得到其源文章的完全支持。解决这个问题的努力主要集中在英语上，使用过于简单的分类方案，忽略了细微的幻觉类型。在本研究中，我们介绍了第一个多语言、细粒度的新闻标题幻觉检测数据集，其中包含 5 种语言的 11,000 多对，每对都由专家注释了详细的幻觉类型。我们在两种环境下对该数据集进行了广泛的实验。首先，我们实施了几种监督微调方法作为准备解决方案，并展示了该数据集的挑战和实用性。其次，我们测试了各种大型语言模型的上下文学习能力，并提出了两种新技术，即语言相关的演示选择和由粗到细的提示，以提高小样本幻觉检测在示例 F1 指标方面的性能。我们发布此数据集是为了促进对多语言、细粒度标题幻觉检测的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2407.15975</guid>
      <pubDate>Wed, 24 Jul 2024 06:20:17 GMT</pubDate>
    </item>
    </channel>
</rss>