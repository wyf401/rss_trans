<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 09 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>扩散引导语言模型</title>
      <link>https://arxiv.org/abs/2408.04220</link>
      <description><![CDATA[arXiv:2408.04220v1 公告类型：新
摘要：当前的语言模型在文本生成方面表现出非凡的能力。然而，对于许多应用程序来说，控制生成语言的属性（例如情绪或毒性）是可取的——理想情况下是针对每个特定用例和目标受众量身定制的。对于自回归语言模型，现有的指导方法容易出现解码错误，这些错误会在生成过程中级联并降低性能。相比之下，文本扩散模型可以很容易地用简单的线性情绪分类器进行引导——然而，它们的困惑度确实比自回归替代方案高得多。在本文中，我们使用引导扩散模型来生成一个潜在的提议，该提议引导自回归语言模型生成具有所需属性的文本。我们的模型继承了自回归方法无与伦比的流畅性和扩散的即插即用灵活性。我们表明，它在广泛的基准数据集上优于以前的即插即用指导方法。此外，在我们的框架中控制新属性简化为训练单个逻辑回归分类器。]]></description>
      <guid>https://arxiv.org/abs/2408.04220</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:39 GMT</pubDate>
    </item>
    <item>
      <title>面向文本挖掘机器翻译的注意力机制与上下文建模系统</title>
      <link>https://arxiv.org/abs/2408.04216</link>
      <description><![CDATA[arXiv:2408.04216v1 公告类型：新
摘要：本文提出了一种基于Transformer范式的新型架构模式，并创新性地融合了K均值分类算法，以增强该模式的上下文理解能力。Transformer模型由于其并行计算能力和多头注意机制，在机器翻译任务中表现良好。然而，在处理高度复杂的语言结构时，它可能会遇到上下文歧义或忽略局部特征。为了绕过这个限制，本文结合了K-Means算法，该算法用于对输入文本的词汇和习语进行分层，从而有助于更好地识别和保存语言的局部结构和上下文智能。这种组合的优点是K-Means可以自动发现文本中的主题或概念区域，这可能与翻译质量直接相关。因此，本文设计的方案将 K-Means 作为 Transformer 之前的准备阶段，并重新校准多头注意力权重，以协助区分具有类似语义或功能的词汇和习语。这确保该方案在训练阶段更加重视这些集群所体现的上下文智能，而不仅仅是关注位置智能。]]></description>
      <guid>https://arxiv.org/abs/2408.04216</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:38 GMT</pubDate>
    </item>
    <item>
      <title>简化儿童翻译：考虑法学硕士学习年龄的迭代简化</title>
      <link>https://arxiv.org/abs/2408.04217</link>
      <description><![CDATA[arXiv:2408.04217v1 公告类型：新
摘要：近年来，神经机器翻译 (NMT) 已广泛应用于日常生活中。然而，目前的 NMT 缺乏一种调整翻译难度以匹配用户语言水平的机制。此外，由于 NMT 训练数据存在偏差，简单的源句子的翻译通常由复杂的单词生成。特别是，这可能会给儿童带来问题，他们可能无法正确理解翻译的含义。在本研究中，我们提出了一种方法，用更简单的单词替换翻译中具有高习得年龄 (AoA) 的单词，以使翻译与用户的水平相匹配。我们通过使用大型语言模型 (LLM) 来实现这一点，提供源句子、翻译和要替换的目标词的三元组。我们使用简单英语维基百科上的反向翻译创建了一个基准数据集。从数据集获得的实验结果表明，我们的方法有效地用低 AoA 词替换高 AoA 词，而且可以迭代替换大多数高 AoA 词，同时仍保持较高的 BLEU 和 COMET 分数。]]></description>
      <guid>https://arxiv.org/abs/2408.04217</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:38 GMT</pubDate>
    </item>
    <item>
      <title>mbrs：最小贝叶斯风险解码库</title>
      <link>https://arxiv.org/abs/2408.04167</link>
      <description><![CDATA[arXiv:2408.04167v1 公告类型：新
摘要：最小贝叶斯风险（MBR）解码是文本生成任务的决策规则，通过基于效用函数而不是高概率输出选择高质量输出，它优于使用波束搜索的传统最大后验（MAP）解码。通常，它会从采样的伪参考下的假设集合中找到最合适的假设。mbrs 是一个 MBR 解码库，可以灵活地组合各种指标、替代期望估计和算法变体。它的设计重点是速度测量和代码块的调用次数、透明度、可重复性和可扩展性，这些对于研究人员和开发人员来说是必不可少的。我们将我们的 mbrs 发布为 MIT 许可的开源项目，代码可在 GitHub 上找到。
GitHub：https://github.com/naist-nlp/mbrs]]></description>
      <guid>https://arxiv.org/abs/2408.04167</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:37 GMT</pubDate>
    </item>
    <item>
      <title>wav2graph：语音监督学习知识图谱框架</title>
      <link>https://arxiv.org/abs/2408.04174</link>
      <description><![CDATA[arXiv:2408.04174v1 公告类型：新
摘要：知识图谱 (KG) 通过提供结构化、互连的数据来提高大型语言模型 (LLM) 和搜索引擎的性能，从而提高推理和上下文感知能力。然而，KG 只关注文本数据，从而忽略了语音等其他模态。在这项工作中，我们引入了 wav2graph，这是第一个从语音数据中进行监督学习知识图谱的框架。我们的流程很简单：(1) 根据转录的口头话语和命名实体数据库构建 KG，(2) 将 KG 转换为嵌入向量，(3) 训练图神经网络 (GNN) 以进行节点分类和链接预测任务。通过使用最先进的 GNN 模型在归纳和传导学习环境中进行的大量实验，我们为人工转录和自动语音识别 (ASR) 转录上的节点分类和链接预测任务提供了基线结果和错误分析，包括使用基于编码器和基于解码器的节点嵌入以及单语和多语声学预训练模型进行的评估。所有相关代码、数据和模型均在线发布。]]></description>
      <guid>https://arxiv.org/abs/2408.04174</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:37 GMT</pubDate>
    </item>
    <item>
      <title>MMREC：基于 LLM 的多模态推荐系统</title>
      <link>https://arxiv.org/abs/2408.04211</link>
      <description><![CDATA[arXiv:2408.04211v1 公告类型：新
摘要：由于每天生成的内容量呈指数级增长，推荐系统的重要性正在迅速增长。内容的激增给设计有效的推荐系统带来了独特的挑战。这些挑战中的关键是需要有效利用代表用户偏好的大量自然语言数据和图像。本文提出了一种利用大型语言模型 (LLM) 和深度学习技术增强推荐系统的新方法。所提出的框架旨在通过结合多模态信息处理和使用统一的潜在空间表示来提高推荐的准确性和相关性。该研究探索了 LLM 在推荐环境中更好地理解和利用自然语言数据的潜力，解决了以前方法的局限性。该框架通过 LLM 有效地提取和集成文本和图像信息，将潜在空间中的各种模态统一起来，简化了排名模型的学习过程。实验结果表明，利用多模态信息时模型的判别能力增强。这项研究展示了 LLM 和多模式数据集成在创建更加个性化和上下文相关的推荐方面的潜力，为不断发展的推荐系统领域做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2408.04211</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:37 GMT</pubDate>
    </item>
    <item>
      <title>UNLEARN 在大型语言模型中有效地删除知识</title>
      <link>https://arxiv.org/abs/2408.04140</link>
      <description><![CDATA[arXiv:2408.04140v1 公告类型：新 
摘要：鉴于大型语言模型 (LLM) 的普及以及从头开始训练这些模型的成本过高，动态忘记特定知识（例如私有或专有知识）而无需重新训练模型已成为一项重要功能。本文提出了一种实现此目标的新方法，称为 UNLEARN。该方法基于子空间方法建立，以识别并专门针对知识的删除，而不会对 LLM 中的其他知识产生不利影响。结果表明，可以忘记 96% 的目标知识，同时将其他知识的性能保持在原始模型的 2.5% 以内，大大优于以前最先进的判别能力。还提出了一种称为 LEARN 的双重方法用于有针对性的知识添加。结果表明，LEARN 可以匹配低秩自适应 (LoRA) 的微调精度，而不会对类似任务产生不利影响。]]></description>
      <guid>https://arxiv.org/abs/2408.04140</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:36 GMT</pubDate>
    </item>
    <item>
      <title>语义还是拼写？利用正字法噪声探测上下文词向量</title>
      <link>https://arxiv.org/abs/2408.04162</link>
      <description><![CDATA[arXiv:2408.04162v1 公告类型：新
摘要：预训练语言模型 (PLM) 隐藏状态经常用作上下文词嵌入 (CWE)：在给定语言上下文的情况下编码语义信息的高维表示。在计算语言学研究的许多领域中，CWE 之间的相似性被解释为语义相似性。然而，目前仍不清楚 PLM 隐藏状态中究竟编码了什么信息。我们通过使用最小正字法噪声探测 PLM 表示来研究这种做法。我们预计，如果 CWE 主要编码语义信息，则在给定足够的语言上下文的情况下，输入词中的单个字符交换不会显著影响结果表示。令人惊讶的是，我们发现流行的 PLM 生成的 CWE 对输入数据中的噪声高度敏感，并且这种敏感性与子词标记化有关：用于表示输入中的单词的标记越少，其对应的 CWE 就越敏感。这表明 CWE 捕获与词级含义无关的信息，并且可以通过对输入数据的简单修改进行操纵。我们得出结论，这些 PLM 派生的 CWE 可能不是可靠的语义代理，在解释表征相似性时需要谨慎]]></description>
      <guid>https://arxiv.org/abs/2408.04162</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:36 GMT</pubDate>
    </item>
    <item>
      <title>基于规则的洞察能否增强 LLM 的放射学报告分类能力？介绍 RadPrompt 方法</title>
      <link>https://arxiv.org/abs/2408.04121</link>
      <description><![CDATA[arXiv:2408.04121v1 公告类型：新
摘要：开发能够从胸部 X 光片中检测病理的成像模型对于大型数据集来说可能成本高昂且时间过长，因为它需要监督才能达到最先进的性能。相反，从放射学报告中提取的标签可以作为远程监督，因为这些标签是作为临床实践的一部分定期生成的。尽管它们被广泛使用，但当前基于规则的标签提取方法依赖于广泛的规则集，这些规则集对句法变异的鲁棒性有限。为了缓解这些限制，我们引入了 RadPert，这是一个基于规则的系统，它将不确定性感知信息模式与一组精简的规则相结合，从而提高了性能。此外，我们还开发了 RadPrompt，这是一种多轮提示策略，利用 RadPert 来增强大型语言模型的零样本预测能力，与 GPT-4 Turbo 相比，加权平均 F1 得分实现了统计上显着的提高。最值得注意的是，RadPrompt 超越了其底层模型，展示了 LLM 与基于规则的模型的协同潜力。我们在两个英语语料库上评估了我们的方法：MIMIC-CXR 黄金标准测试集和从剑桥大学医院收集的黄金标准数据集。]]></description>
      <guid>https://arxiv.org/abs/2408.04121</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:35 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型增强医疗保健：医学问答研究</title>
      <link>https://arxiv.org/abs/2408.04138</link>
      <description><![CDATA[arXiv:2408.04138v1 公告类型：新
摘要：近年来，大型语言模型 (LLM) 在医疗保健领域的应用在提高医学知识的可及性和传播方面显示出了巨大的前景。本文对在 MedQuAD 医学问答数据集上训练的各种 LLM 进行了详细研究，重点是确定提供准确医疗信息的最有效模型。在测试的模型中，Sentence-t5 与 Mistral 7B 相结合表现出色，精度得分达到 0.762。该模型增强的功能归功于其先进的预训练技术、强大的架构和有效的提示构建方法。通过利用这些优势，Sentence-t5 + Mistral 7B 模型在理解和生成精确的医学答案方面表现出色。我们的研究结果强调了在医学环境中集成复杂的 LLM 以促进高效准确的医学知识检索的潜力，从而显着增强患者教育和支持。]]></description>
      <guid>https://arxiv.org/abs/2408.04138</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:35 GMT</pubDate>
    </item>
    <item>
      <title>通过情境感知基础提高大型语言模型 (LLM) 保真度：可靠性和准确性的系统方法</title>
      <link>https://arxiv.org/abs/2408.04023</link>
      <description><![CDATA[arXiv:2408.04023v1 公告类型：新
摘要：随着大型语言模型 (LLM) 在自然语言处理 (NLP) 应用中变得越来越复杂和普遍，确保其稳健性、可信度和与人类价值观的一致性已成为一项关键挑战。本文提出了一种用于文本模型中上下文基础的新框架，特别强调上下文表示阶段。我们的方法旨在通过全面的上下文感知方法来增强这些模型的可靠性和道德一致性。通过以机器可读的格式明确捕获和表示相关的情境、文化和道德背景，我们为在这些上下文中锚定模型的行为奠定了基础。我们的方法利用知识表示和推理技术，例如本体论、语义网技术和基于逻辑的形式化。我们在现实世界的文本数据集上评估了我们的框架，证明了它在提高模型性能、公平性和与人类期望的一致性方面的有效性，同时保持了高精度。此外，我们还讨论了该框架的其他关键组成部分，包括上下文感知编码、上下文感知学习、可解释性和可解释性以及持续监控和适应。这项研究为负责任的人工智能研究做出了贡献，为开发更可靠、更值得信赖、更符合道德规范的语言模型提供了一种实用的方法。我们的研究结果对于在医疗保健、法律体系和社会服务等敏感领域部署 LLM 具有重要意义，因为在这些领域，情境理解至关重要。]]></description>
      <guid>https://arxiv.org/abs/2408.04023</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:34 GMT</pubDate>
    </item>
    <item>
      <title>噪声中的人类语音感知：大型语言模型能否通过释义来改善它？</title>
      <link>https://arxiv.org/abs/2408.04029</link>
      <description><![CDATA[arXiv:2408.04029v1 公告类型：新
摘要：大型语言模型 (LLM) 可以通过传输诸如正式性之类的样式属性来生成文本，从而生成正式或非正式文本。但是，指示 LLM 生成在听觉困难的环境中更容易理解的口语文本是一个尚未充分探索的课题。我们进行了第一项研究，以评估 LLM 在一项新任务上的表现，即生成听觉可理解的释义，以便在噪音中更好地感知人类语音。我们在英语中的实验表明，在标准提示下，LLM 难以控制非文本属性，即听觉可理解性，同时有效地捕获所需的文本属性，如语义等价性。为了解决这个问题，我们提出了一种简单的提示方法，即提示和选择，它通过在文本生成管道中解耦所需的文本和非文本属性来生成释义。我们的方法通过解释在信噪比 (SNR) -5 dB 的嘈杂噪音条件下严重失真的话语，使人类语音感知相对提高了 40%。这项研究揭示了 LLM 在捕获非文本属性方面的局限性，我们提出的方法展示了使用 LLM 在噪音环境中提高人类语音感知的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.04029</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:34 GMT</pubDate>
    </item>
    <item>
      <title>跨领域的零样本事实一致性评估</title>
      <link>https://arxiv.org/abs/2408.04114</link>
      <description><![CDATA[arXiv:2408.04114v1 公告类型：新
摘要：这项工作解决了文本生成系统中事实一致性的挑战。我们统一了自然语言推理、摘要评估、事实性验证和事实一致性评估的任务，以训练能够评估不同领域中源-目标对的事实一致性的模型。我们在一个包含 22 个数据集的综合基准套件上根据八个基线对这些模型进行了严格评估，这些数据集涵盖了各种任务、领域和文档长度。结果表明，我们的方法在这个异构基准上实现了最先进的性能，同时解决了效率问题并实现了跨域泛化。]]></description>
      <guid>https://arxiv.org/abs/2408.04114</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:34 GMT</pubDate>
    </item>
    <item>
      <title>拟人化大型语言模型在学习环境中的影响</title>
      <link>https://arxiv.org/abs/2408.03945</link>
      <description><![CDATA[arXiv:2408.03945v1 公告类型：新
摘要：大型语言模型 (LLM) 越来越多地用于学习环境中以支持教学 - 无论是作为学习伙伴还是导师。通过我们的贡献，我们旨在讨论学习环境中 LLM 拟人化对教育理论的影响，为更有效的学习成果奠定基础，并了解其对学习者的情感影响。根据媒体方程，人们倾向于以与回应他人相同的方式回应媒体。佐治亚理工学院进行的一项研究表明，聊天机器人可以在学习环境中成功实施。在这项研究中，选定的在线课程的学习者无法区分聊天机器人和“真正的”老师。随着基于 LLM 的聊天机器人（例如 OpenAI 的 GPT 系列）越来越多地用于教育工具，了解拟人化方面对基于 LLM 的聊天机器人的归因过程如何影响学习者的情绪非常重要。]]></description>
      <guid>https://arxiv.org/abs/2408.03945</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:33 GMT</pubDate>
    </item>
    <item>
      <title>用于数学公式和文本的图像到 LaTeX 转换器</title>
      <link>https://arxiv.org/abs/2408.04015</link>
      <description><![CDATA[arXiv:2408.04015v1 公告类型：新
摘要：在这个项目中，我们训练了一个视觉编码器-解码器模型，以从数学公式和文本的图像中生成 LaTeX 代码。利用多样化的图像到 LaTeX 数据集合，我们构建了两个模型：一个带有 Swin Transformer 编码器和 GPT-2 解码器的基本模型，在机器生成的图像上进行训练，以及一个使用低秩自适应 (LoRA) 增强的微调版本，在手写公式上进行训练。然后，我们将我们的专用模型在手写测试集上的 BLEU 性能与其他类似模型（例如 Pix2Text、TexTeller 和 Sumen）进行比较。通过这个项目，我们贡献了将图像转换为 LaTeX 的开源模型，并提供了从头开始构建这些模型的代码，这些模型具有分布式训练和 GPU 优化。]]></description>
      <guid>https://arxiv.org/abs/2408.04015</guid>
      <pubDate>Fri, 09 Aug 2024 06:20:33 GMT</pubDate>
    </item>
    </channel>
</rss>