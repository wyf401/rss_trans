<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 08 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>mucAI 参加 WojoodNER 2024：使用最近邻搜索进行阿拉伯语命名实体识别</title>
      <link>https://arxiv.org/abs/2408.03652</link>
      <description><![CDATA[arXiv:2408.03652v1 公告类型：新
摘要：命名实体识别 (NER) 是自然语言处理 (NLP) 中的一项任务，旨在识别文本中的实体并将其分类到预定义的类别中。然而，当应用于阿拉伯语数据时，NER 会遇到独特的挑战，这些挑战源于该语言丰富的形态变化、缺乏大写提示和拼写变体，其中一个单词可能包含多个词素。在本文中，我们介绍了阿拉伯语 KNN-NER，这是我们提交给 Wojood NER 共享任务 2024 (ArabicNLP 2024) 的。我们参与了共享子任务 1 Flat NER。在这个共享子任务中，我们解决了阿拉伯语文本的细粒度扁平实体识别问题，其中我们为每个单词识别一个主实体和可能零个或多个子实体。阿拉伯语 KNN-NER 使用通过对缓存的训练数据执行 KNN 搜索得出的另一个标签概率分布来增强微调模型的概率分布。我们的提交在 WojoodFine 数据集的测试集上取得了 91% 的成绩，使阿拉伯语 KNN-NER 在共享任务排行榜上名列前茅。]]></description>
      <guid>https://arxiv.org/abs/2408.03652</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:12 GMT</pubDate>
    </item>
    <item>
      <title>使用新颖的拼写校正系统提高波斯语临床文本的质量</title>
      <link>https://arxiv.org/abs/2408.03622</link>
      <description><![CDATA[arXiv:2408.03622v1 公告类型：新
摘要：背景：电子健康记录 (EHR) 中的拼写准确性是高效临床护理、研究和确保患者安全的关键因素。波斯语词汇丰富、特点复杂，对实词纠错提出了独特的挑战。本研究旨在开发一种创新方法来检测和纠正波斯语临床文本中的拼写错误。
方法：我们的策略采用了最先进的预训练模型，该模型经过精心微调，专门用于波斯语临床领域的拼写纠正任务。该模型由创新的正字法相似性匹配算法 PERTO 补充，该算法使用字符的视觉相似性对纠正候选进行排名。
结果：对我们的方法的评估证明了其在检测和纠正波斯语临床文本中的单词错误方面的稳健性和准确性。在非单词错误纠正方面，当使用 PERTO 算法时，我们的模型实现了 90.0% 的 F1 分数。对于实词错误检测，我们的模型表现出最高的性能，实现了 90.6% 的 F1 分数。此外，当使用 PERTO 算法时，该模型在实词错误纠正方面达到了最高的 F1 分数 91.5%。
结论：尽管存在某些局限性，但我们的方法在波斯语临床文本的拼写错误检测和纠正领域取得了重大进步。通过有效解决波斯语带来的独特挑战，我们的方法为更准确、更高效的临床记录铺平了道路，有助于改善患者护理和安全。未来的研究可以探索它在波斯语医学领域其他领域的应用，增强其影响力和实用性。]]></description>
      <guid>https://arxiv.org/abs/2408.03622</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>PAGED：从文档中提取程序图的基准</title>
      <link>https://arxiv.org/abs/2408.03630</link>
      <description><![CDATA[arXiv:2408.03630v2 公告类型：新
摘要：从文档中自动提取过程图为用户提供了一种低成本的方式，通过浏览可视化图表可以轻松理解复杂的过程。尽管最近的研究取得了进展，但仍未解答：现有研究是否很好地解决了这一任务（Q1），新兴的大型语言模型（LLM）是否可以为这项任务带来新的机会（Q2）。为此，我们提出了一个新的基准 PAGED，配备了大量高质量数据集和标准评估。它调查了五个最先进的基线，发现由于它们严重依赖手写规则和有限的可用数据，它们无法很好地提取最佳过程图。我们进一步在 PAGED 中引入了三个高级 LLM，并通过一种新颖的自我改进策略对其进行了增强。结果指出了 LLM 在识别文本元素方面的优势及其在构建逻辑结构方面的差距。我们希望 PAGED 可以成为自动程序图提取的一个重要里程碑，并且 PAGED 中的研究可以为非序列元素之间的逻辑推理研究提供见解。]]></description>
      <guid>https://arxiv.org/abs/2408.03630</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>CARE：帮助 CSR 阅读用户手册的线索引导助手</title>
      <link>https://arxiv.org/abs/2408.03633</link>
      <description><![CDATA[arXiv:2408.03633v2 公告类型：新
摘要：为客户服务代表（CSR）构建阅读助手可以节省阅读用户手册的时间，尤其是信息丰富的用户手册。当前的解决方案由于缺乏对用户问题和可能的响应的关注而不适合在线客户服务场景。因此，我们建议开发一个省时且细心的 CSR 阅读助手，名为 CARE。它可以帮助 CSR 通过明确的线索链快速从用户手册中找到合适的响应。具体而言，每个线索链都是通过对用户手册进行推断形成的，从与用户问题一致的问题线索开始，到可能的响应结束。为了克服监督数据的短缺，我们采用自监督策略进行模型学习。离线实验表明，CARE 能够有效地从用户手册中自动推断出准确的响应。在线实验进一步证明了CARE在减少CSR阅读负担和保持高服务质量方面的优势，特别是花费的时间减少了35%以上并且保持了0.75以上的ICC分数。]]></description>
      <guid>https://arxiv.org/abs/2408.03633</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>LLM 微调方法和评估指标与旅游聊天机器人用例的比较</title>
      <link>https://arxiv.org/abs/2408.03562</link>
      <description><![CDATA[arXiv:2408.03562v1 公告类型：新
摘要：本研究比较了大型语言模型 (LLM) 微调方法，包括量化低秩适配器 (QLoRA)、检索增强微调 (RAFT) 和从人类反馈强化学习 (RLHF)，此外还比较了 LLM 评估方法，包括“黄金答案”的端到端 (E2E) 基准方法、传统自然语言处理 (NLP) 指标、RAG 评估 (Ragas)、OpenAI GPT-4 评估指标和人类评估，使用旅行聊天机器人用例。旅行数据集来自 Reddit API，通过请求与旅行相关的 subreddits 的帖子来获取与旅行相关的对话提示和个性化的旅行体验，并针对每种微调方法进行增强。我们使用了两个用于微调研究的预训练 LLM：LLaMa 2 7B 和 Mistral 7B。 QLoRA 和 RAFT 应用于两个预训练模型。根据上述指标对这些模型的推论进行了广泛的评估。根据人工评估和一些 GPT-4 指标，最佳模型是 Mistral RAFT，因此该模型经过了人工反馈强化学习 (RLHF) 训练流程，最终被评估为最佳模型。我们的主要发现是：1) 定量和 Ragas 指标与人工评估不一致，2) Open AI GPT-4 评估与人工评估最一致，3) 让人类参与评估至关重要，因为 4) 传统的 NLP 指标不足，5) Mistral 的表现通常优于 LLaMa，6) RAFT 的表现优于 QLoRA，但仍需要后处理，7) RLHF 显著提高了模型性能。下一步包括提高数据质量、增加数据量、探索 RAG 方法以及将数据收集重点放在特定城市，这将通过缩小焦点来提高数据质量，同时创建有用的产品。]]></description>
      <guid>https://arxiv.org/abs/2408.03562</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:10 GMT</pubDate>
    </item>
    <item>
      <title>儿童导向语音是语言模型的有效训练数据吗？</title>
      <link>https://arxiv.org/abs/2408.03617</link>
      <description><![CDATA[arXiv:2408.03617v1 公告类型：新
摘要：虽然高性能语言模型通常需要数千亿个单词进行训练，但人类儿童只需要很少的数据就可以成为流利的语言使用者。他们收到的数据有哪些特征，这些特征如何支持语言建模目标？为了研究这个问题，我们在 2900 万个英语儿童导向语音单词和一个新的匹配合成数据集（TinyDialogues）上训练 GPT-2 模型，并与 BabyLM 挑战赛中的异构数据集混合进行比较。我们使用受发展启发的评估来评估这些模型的句法和语义知识。通过预训练实验，我们测试儿童训练数据的全局发展排序或局部话语排序是否支持相对于其他数据集的高性能。数据的局部属性会影响模型结果，但有点令人惊讶的是，全局属性不会。此外，儿童语言输入对于训练语言模型并不是独一无二的。这些发现支持了这样的假设：儿童的学习不是基于更好的数据，而是比当前的语言建模技术效率高得多。]]></description>
      <guid>https://arxiv.org/abs/2408.03617</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:10 GMT</pubDate>
    </item>
    <item>
      <title>用于论证生成的逻辑谬误框架</title>
      <link>https://arxiv.org/abs/2408.03618</link>
      <description><![CDATA[arXiv:2408.03618v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 性能卓越，但它们在生成逻辑上合理的论点方面仍然举步维艰，从而导致传播错误信息等潜在风险。导致 LLM 在生成连贯论点方面表现不佳的一个重要因素是它们对逻辑谬误的忽视。为了解决这个问题，我们引入了 FIPO，这是一个谬误知情框架，它利用偏好优化方法引导 LLM 走向逻辑上合理的论点。FIPO 包括分类损失，以捕获谬误类别的细粒度信息。我们在论证数据集上的结果表明，我们的方法将谬误错误减少了多达 17.5%。此外，我们的人工评估结果表明，我们的方法生成的论据的质量明显优于微调基线以及之前的偏好优化方法，例如 DPO。这些发现强调了确保模型意识到逻辑谬误对于有效论据生成的重要性。]]></description>
      <guid>https://arxiv.org/abs/2408.03618</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:10 GMT</pubDate>
    </item>
    <item>
      <title>EXAONE 3.0 7.8B 指令调整语言模型</title>
      <link>https://arxiv.org/abs/2408.03541</link>
      <description><![CDATA[arXiv:2408.03541v2 公告类型：新
摘要：我们推出了 EXAONE 3.0 指令调整语言模型，这是 LG AI Research 开发的大型语言模型 (LLM) 系列中的第一个开放模型。在不同的模型大小中，我们公开发布了 7.8B 指令调整模型，以促进开放研究和创新。通过对广泛的公共和内部基准进行广泛的评估，EXAONE 3.0 与其他类似大小的先进开放模型相比，在指令跟踪能力方面表现出了极具竞争力的实际性能。我们的比较分析表明，EXAONE 3.0 在韩语方面尤其出色，同时在一般任务和复杂推理中也取得了令人信服的表现。凭借其强大的现实世界有效性和双语能力，我们希望 EXAONE 继续为专家人工智能的进步做出贡献。我们的 EXAONE 3.0 指令调整模型可在 https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct 上获取]]></description>
      <guid>https://arxiv.org/abs/2408.03541</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:09 GMT</pubDate>
    </item>
    <item>
      <title>突破非母语语境限制：母语提示助力知识获取</title>
      <link>https://arxiv.org/abs/2408.03544</link>
      <description><![CDATA[arXiv:2408.03544v1 公告类型：新
摘要：多语言大型语言模型 (MLLM) 很难回答非主导语言提出的问题，即使它们已经从其主导语言语料库中获得了相关知识。相比之下，人类多语言者可以通过积极母语迁移 (PNLT) 调用从母语文本中获得的相对丰富的知识来克服这个问题。受此启发，我们将 MLLM 的主导语言类比为人类多语言者的母语，并提出母语提示 (NatLan) 来模拟人类多语言者中观察到的 PNLT。它明确为 MLLM 创建母语上下文，以促进在问答过程中引出丰富的母语知识，从而解锁非母语上下文对知识有效应用的限制。通过采用多 MLLM 协作，NatLan 减少了每个 MLLM 在模拟 PNLT 时的工作量并改进了语义传输。在 C-Eval 基准测试中，NatLan 在五个 MLLM 中的平均准确率提高了 10.1%，在困难级别子集上提高了 5.0%，超越了所有顶级相关方法。我们的代码可在 https://github.com/AnonyNLP/NatLan 上找到。]]></description>
      <guid>https://arxiv.org/abs/2408.03544</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:09 GMT</pubDate>
    </item>
    <item>
      <title>大型视觉语言模型通过视觉提示注入对抗目标劫持的实证分析</title>
      <link>https://arxiv.org/abs/2408.03554</link>
      <description><![CDATA[arXiv:2408.03554v1 公告类型：新
摘要：我们探索了视觉提示注入 (VPI)，它恶意利用大型视觉语言模型 (LVLM) 遵循绘制在输入图像上的指令的能力。我们提出了一种新的 VPI 方法，即“通过视觉提示注入进行目标劫持”(GHVPI)，它将 LVLM 的执行任务从原始任务交换为攻击者指定的替代任务。定量分析表明，GPT-4V 容易受到 GHVPI 的攻击，攻击成功率高达 15.8%，这是一个不容忽视的安全风险。我们的分析还表明，成功的 GHVPI 需要 LVLM 具有很高的字符识别能力和指令遵循能力。]]></description>
      <guid>https://arxiv.org/abs/2408.03554</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:09 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归使小型 LLM 成为强大且可解释的“数十次”分类器</title>
      <link>https://arxiv.org/abs/2408.03414</link>
      <description><![CDATA[arXiv:2408.03414v1 公告类型：新
摘要：对于简单的分类任务，我们表明用户可以从使用小型、本地、生成语言模型而不是大型商业模型的优势中受益，而无需牺牲性能或引入额外的标签成本。这些优势，包括隐私、可用性、成本和可解释性方面的优势，在商业应用和更广泛的人工智能民主化中都很重要。通过对 17 个句子分类任务（2-4 个类别）的实验，我们表明，在“数十次”机制下，小型 LLM 嵌入的惩罚逻辑回归等于（并且通常更好）大型 LLM 的性能。这不需要比验证大型 LLM 性能所需的更多标记实例。最后，我们为分类决策提取稳定且合理的解释。]]></description>
      <guid>https://arxiv.org/abs/2408.03414</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:08 GMT</pubDate>
    </item>
    <item>
      <title>Optimus：利用气泡利用加速大规模多模式 LLM 训练</title>
      <link>https://arxiv.org/abs/2408.03505</link>
      <description><![CDATA[arXiv:2408.03505v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 将大型语言模型 (LLM) 的成功扩展到多种数据类型，例如图像、文本和音频，在多模态翻译、视觉问答和内容生成等各个领域取得了显著的性能。尽管如此，现有系统在训练 MLLM 方面效率低下，因为异构模态模型和 3D 并行中复杂的数据依赖性导致了大量 GPU 气泡。本文提出了 Optimus，一种分布式 MLLM 训练系统，可减少端到端 MLLM 训练时间。Optimus 基于我们的原则分析，即在 LLM 气泡内调度编码器计算可以减少 MLLM 训练中的气泡。为了使所有 GPU 都能调度编码器计算，Optimus 搜索编码器和 LLM 的单独并行计划，并采用气泡调度算法来利用 LLM 气泡，而不会破坏 MLLM 模型架构中原始的数据依赖关系。我们进一步将编码器层计算分解为一系列内核，并分析 3D 并行的常见气泡模式，以精心优化亚毫秒气泡调度，从而最大限度地缩短整体训练时间。我们在生产集群中的实验表明，与基线相比，Optimus 在 3072 个 GPU 上使用 ViT-22B 和 GPT-175B 模型将 MLLM 训练速度提高了 20.5%-21.3%。]]></description>
      <guid>https://arxiv.org/abs/2408.03505</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:08 GMT</pubDate>
    </item>
    <item>
      <title>1.5 品脱技术报告：几天内完成预训练，而不是几个月——您的语言模型依靠优质数据蓬勃发展</title>
      <link>https://arxiv.org/abs/2408.03506</link>
      <description><![CDATA[arXiv:2408.03506v1 公告类型：新
摘要：本文介绍了一种计算效率高的方法，仅用 9 天就预训练了语言模型“1.5-Pints”，同时作为指令遵循助手，其表现优于最先进的模型。基于 MT-Bench（模拟人类判断的基准），1.5-Pints 的表现优于 Apple 的 OpenELM 和 Microsoft 的 Phi。这是通过精心策划的 570 亿个标记的预训练数据集实现的，使用了自动化工作流程和人工审核的混合。数据集的选择优先考虑被认为是说明性的和“教科书式”的内容，以帮助模型进行推理和逻辑推理，最终使其整体上成为强大而多功能的 AI 模型。在模型架构方面，我们采用了经过修改的 Mistral 标记器，以及 Llama-2 架构，以实现更广泛的兼容性。对于训练，我们采用了 StableLM、TinyLlama 和 Huggingface Zephyr 所使用的方法。1.5-Pints 表明，通过在 LLM 训练中注重数据质量而不是数量，我们可以显著减少所需的训练时间和资源。我们相信这种方法不仅可以使预训练更容易实现，还可以减少我们的碳足迹。我们从这项研究中获得的发现和资源都是开源的，旨在促进该领域的进一步发展。1.5-Pints 模型有两个版本：2K 和 16K 上下文窗口。]]></description>
      <guid>https://arxiv.org/abs/2408.03506</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:08 GMT</pubDate>
    </item>
    <item>
      <title>EgyBERT：基于埃及方言语料库进行预训练的大型语言模型</title>
      <link>https://arxiv.org/abs/2408.03524</link>
      <description><![CDATA[arXiv:2408.03524v1 公告类型：新
摘要：本研究介绍了 EgyBERT，这是一种基于 10.4 GB 埃及方言文本进行预训练的阿拉伯语语言模型。我们通过将 EgyBERT 与 10 个评估数据集上的其他五种多方言阿拉伯语语言模型进行比较来评估其性能。EgyBERT 的平均 F1 得分最高，为 84.25%，准确率为 87.33%，远远优于所有其他比较模型，MARBERTv2 作为第二好的模型，F1 得分为 83.68%，准确率为 87.19%。此外，我们引入了两个新的埃及方言语料库：埃及推文语料库 (ETC)，包含超过 3433 万条推文（2489 万个句子），共计 2.5 GB 文本，以及埃及论坛语料库 (EFC)，包含从各种埃及在线论坛收集的超过 4442 万个句子（7.9 GB 文本）。这两个语料库都用于新模型的预训练，它们是迄今为止文献中报道的最大的埃及方言语料库。此外，这是第一项评估各种语言模型在埃及方言数据集上的表现的研究，揭示了性能上的显著差异，凸显了对更多方言特定模型的需求。结果证实了 EgyBERT 模型在处理和分析用埃及方言表达的阿拉伯语文本方面的有效性，超过了研究中包括的其他语言模型。EgyBERT 模型可在 \url{https://huggingface.co/faisalq/EgyBERT} 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2408.03524</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:08 GMT</pubDate>
    </item>
    <item>
      <title>ULLME：具有生成增强学习的大型语言模型嵌入的统一框架</title>
      <link>https://arxiv.org/abs/2408.03402</link>
      <description><![CDATA[arXiv:2408.03402v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种自然语言处理任务中表现出色，但利用它们进行密集段落嵌入仍然具有挑战性。这是由于它们的因果注意机制以及它们的预训练目标与文本排名任务之间的不一致。尽管最近做出了一些努力来解决这些问题，但现有的基于 LLM 的文本嵌入框架受到仅支持有限范围的 LLM 架构和微调策略的限制，限制了它们的实际应用和多功能性。在这项工作中，我们引入了大型语言模型嵌入的统一框架 (ULLME)，这是一种灵活的即插即用实现，可在各种 LLM 之间实现双向注意并支持一系列微调策略。我们还提出了生成增强表示学习 (GRL)，这是一种新颖的微调方法，可以增强 LLM 的文本嵌入任务。 GRL 加强了基于表示和基于生成的相关性得分之间的一致性，利用 LLM 强大的生成能力来学习段落嵌入。为了展示我们框架的灵活性和有效性，我们从 ULLME 发布了三个预训练模型，它们具有不同的骨干架构，参数范围从 1.5B 到 8B，所有这些模型在 Massive Text Embedding Benchmark 上都表现出色。我们的框架公开发布在：https://github.com/nlp-uoregon/ullme。ULLME 的演示视频也可以在 https://rb.gy/ws1ile 找到。]]></description>
      <guid>https://arxiv.org/abs/2408.03402</guid>
      <pubDate>Fri, 09 Aug 2024 03:16:07 GMT</pubDate>
    </item>
    </channel>
</rss>