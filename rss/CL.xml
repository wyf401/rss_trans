<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 27 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>增强电力系统仿真的 LLM：反馈驱动的多智能体框架</title>
      <link>https://arxiv.org/abs/2411.16707</link>
      <description><![CDATA[arXiv:2411.16707v1 公告类型：新
摘要：实验技术与大型语言模型 (LLM) 的结合正在改变科学研究，将 AI 定位为多功能研究助手，而不仅仅是解决问题的工具。然而，在电力系统领域，管理模拟——一项必不可少的实验技术——对于 LLM 来说仍然是一个挑战，因为它们的领域特定知识有限、推理能力受限以及对模拟参数的处理不精确。为了解决这些限制，我们提出了一个反馈驱动的多智能体框架，该框架包含三个提议的模块：增强检索增强生成 (RAG) 模块、改进的推理模块和具有错误反馈机制的动态环境代理模块。该框架在 Daline 和 MATPOWER 的 69 个不同任务上进行了验证，成功率分别达到 93.13% 和 96.85%，显著优于最新的 LLM（ChatGPT 4o 和 o1-preview），后者在标准模拟任务上的成功率为 27.77%，在复杂任务上的成功率为 0%。此外，我们的框架还支持快速、经济高效的任务执行，每次模拟大约在 30 秒内完成，平均代币成本为 0.014 美元。总体而言，这个适应性强的框架为开发基于 LLM 的智能助手奠定了基础，供人类研究人员使用，促进电力系统研究及其他研究。]]></description>
      <guid>https://arxiv.org/abs/2411.16707</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多重重排器：在 FinanceRAG 挑战赛中最大化检索增强生成的性能</title>
      <link>https://arxiv.org/abs/2411.16732</link>
      <description><![CDATA[arXiv:2411.16732v1 公告类型：新
摘要：随着大型语言模型 (LLM) 越来越多地解决特定领域的问题，它们在金融领域的应用迅速扩展。现在，使用 LLM 可以有效地处理那些既有价值又耗时的任务，例如分析财务报表、披露和相关文件。本文详细介绍了为 ACM-ICAIF &#39;24 FinanceRAG 竞赛开发高性能、金融专用的检索增强生成 (RAG) 系统。我们通过对预检索阶段的查询扩展和语料库细化进行消融研究来优化性能。为了提高检索准确性，我们采用了多个重新排序模型。值得注意的是，我们引入了一种在生成阶段管理长上下文大小的有效方法，在不牺牲性能的情况下显着提高了响应质量。我们最终在 FinanceRAG 挑战赛中获得了第二名。我们的主要贡献包括：（1）检索前消融分析、（2）增强检索算法和（3）长上下文管理的新方法。这项工作展示了 LLM 在有效处理和分析复杂财务数据以产生准确且有价值的见解方面的潜力。源代码和更多详细信息可在 https://github.com/cv-lee/FinanceRAG 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.16732</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ChemSafetyBench：对化学领域的法学硕士安全性进行基准测试</title>
      <link>https://arxiv.org/abs/2411.16736</link>
      <description><![CDATA[arXiv:2411.16736v1 公告类型：新
摘要：大型语言模型 (LLM) 的进步和广泛应用令人瞩目，包括它们在科学研究协助中的应用。然而，这些模型通常会产生科学上不正确或不安全的响应，在某些情况下，它们可能会鼓励用户从事危险行为。为了解决化学领域的这个问题，我们引入了 ChemSafetyBench，这是一个旨在评估 LLM 响应准确性和安全性的基准。ChemSafetyBench 包含三个关键任务：查询化学性质、评估化学用途的合法性以及描述合成方法，每个任务都需要越来越深入的化学知识。我们的数据集包含各种化学材料的 30K 多个样本。我们结合了手工制作的模板和高级越狱场景来增强任务多样性。我们的自动评估框架全面评估了 LLM 响应的安全性、准确性和适当性。对最先进的 LLM 进行的大量实验揭示了显着的优势和关键的漏洞，强调了采取强有力的安全措施的必要性。 ChemSafetyBench 旨在成为开发更安全的化学 AI 技术的关键工具。我们的代码和数据集可在 https://github.com/HaochenZhao/SafeAgent4Chem 上找到。警告：本文包含使用 AI 模型合成受控化学品的讨论。]]></description>
      <guid>https://arxiv.org/abs/2411.16736</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SHuBERT：通过多流集群预测进行自监督手语表征学习</title>
      <link>https://arxiv.org/abs/2411.16765</link>
      <description><![CDATA[arXiv:2411.16765v1 公告类型：新
摘要：手语处理传统上依赖于特定于任务的模型，限制了跨任务迁移学习的潜力。我们引入了 SHuBERT（Sign Hidden-Unit BERT），这是一种自监督的 Transformer 编码器，可以从大约 1,000 小时的美国手语 (ASL) 视频内容中学习强大的表示。受到 HuBERT 语音表示模型成功的启发，SHuBERT 采用了针对多流视觉手语输入的掩蔽预测，学习预测与聚类的手、脸和身体姿势流相对应的多个目标。SHuBERT 在多个基准测试中实现了最先进的性能。在手语翻译方面，它优于在 How2Sign（+0.7 BLEU）、OpenASL（+10.0 BLEU）和 FLEURS-ASL（+0.3 BLEU）基准测试中在公开数据上训练的先前方法。同样，对于孤立手语识别，SHuBERT 的准确率超过了 ASL-Citizen (+5\%) 和 SEM-LEX (+20.6\%) 上的专用模型，而在 WLASL2000 (-3\%) 上则接近它们。消融研究证实了该方法每个组成部分的贡献。]]></description>
      <guid>https://arxiv.org/abs/2411.16765</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>参数有效指令调整：实证研究</title>
      <link>https://arxiv.org/abs/2411.16775</link>
      <description><![CDATA[arXiv:2411.16775v1 公告类型：新
摘要：指令调整已成为微调预训练语言模型以更好地遵循人类指令并概括各种任务的重要步骤。如今，预训练语言模型变得越来越大，而完整的参数微调成本极高。因此，参数高效微调 (PEFT) 已成为一种经济高效的指令调整实践，因为与完全微调相比，其计算、内存和存储成本明显较小。尽管它们被广泛采用，但巨大的超参数空间、PEFT 方法的数量、指令调整能力的不同重点使得解开每个方面的影响变得困难。本研究系统地研究了几种有代表性的 PEFT 方法，调查了超参数选择的影响，包括训练超参数和 PEFT 特定的超参数，以及不同的模型大小和指令任务数量如何影响性能、任务分布记忆和开放指令跟随能力。我们的实证研究表明，只有 LoRA 和适配器才能在理想的训练设置下接近完全微调。理想的训练设置包括适当的学习率、允许的最大 LoRA 等级或适配器大小以及多样化的训练任务。另一方面，如果不满足这种理想的训练条件，LoRA 和适配器就会遭受训练不稳定的困扰。此外，LoRA 需要更多的任务才能有效地进行看不见的任务泛化，学习速度较慢。此外，LoRA 的任务级记忆能力较弱。最后，与开放指令调整设置中的微调相比，LoRA 和适配器在复杂推理、编码和长格式生成方面有所欠缺，但与适配器相比，它表现出更强大的能力。]]></description>
      <guid>https://arxiv.org/abs/2411.16775</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于半监督文本分类的邻域分层筛选对比多图学习</title>
      <link>https://arxiv.org/abs/2411.16787</link>
      <description><![CDATA[arXiv:2411.16787v1 公告类型：新
摘要：图对比学习因其在自监督节点表示学习方面的卓越能力而成功应用于文本分类。然而，显式图形增强可能会导致对比视图中的语义丢失。其次，现有方法往往会忽略边缘特征和多图学习过程中节点特征的不同重要性。此外，对比损失会受到假阴性的影响。为了解决这些限制，我们提出了一种用于半监督文本分类的具有邻居分层筛选的对比多图学习新方法，即 ConNHS。具体来说，我们利用核心特征来形成多关系文本图，增强文本之间的语义联系。通过分离文本图，我们为对比学习提供了不同的视图。我们的方法确保图形信息的最佳保存，最大限度地减少数据丢失和失真。然后，我们分别执行关系感知传播和跨图注意传播，从而有效利用节点和边特征之间的不同相关性，同时协调跨图的信息融合。随后，我们提出邻居分层筛选损失 (NHS) 来改进负选择。一方面，遵循同质性假设，NHS 掩盖了锚点和正例的一阶邻居，使其不成为负例。另一方面，NHS 根据与锚点相似的高阶邻居将其排除在外。因此，它有效地减少了假阴性的发生，防止了嵌入空间中相似样本之间距离的扩大。我们在 ThuCNews、SogouNews、20 Newsgroups 和 Ohsumed 数据集上的实验分别达到了 95.86%、97.52%、87.43% 和 70.65%，这在半监督文本分类中展示了具有竞争力的结果。]]></description>
      <guid>https://arxiv.org/abs/2411.16787</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 能告诉我们有关城市的什么信息？</title>
      <link>https://arxiv.org/abs/2411.16791</link>
      <description><![CDATA[arXiv:2411.16791v1 公告类型：新
摘要：本研究探讨了大型语言模型 (LLM) 在全球范围内提供有关城市和地区知识的能力。我们采用两种方法：直接查询 LLM 以获取目标变量值，并从与目标变量相关的 LLM 中提取显式和隐式特征。我们的实验表明，LLM 在全球城市中嵌入了广泛但不同程度的知识，使用 LLM 衍生特征训练的 ML 模型始终可以提高预测准确性。此外，我们观察到 LLM 在所有大陆的全球城市中都表现出一定程度的知识，但当它们缺乏知识时，这一点很明显，因为它们往往会为不熟悉的任务生成通用或随机的输出。这些发现表明，LLM 可以为城市研究中的数据驱动决策提供新的机会。]]></description>
      <guid>https://arxiv.org/abs/2411.16791</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型间的模型间共识提高答案的可靠性</title>
      <link>https://arxiv.org/abs/2411.16797</link>
      <description><![CDATA[arXiv:2411.16797v1 公告类型：新 
摘要：我们探索创新语言模型交互系统的协作动态，该系统涉及 GPT-4-0125-preview、Meta-LLaMA-3-70B-Instruct、Claude-3-Opus 和 Gemini-1.5-Flash 等高级模型。这些模型生成并回答复杂的博士级统计问题，而没有确切的真实答案。我们的研究调查了模型间共识如何提高响应的可靠性和准确性。通过采用卡方检验、Fleiss&#39; Kappa 和置信区间分析等统计方法，我们评估共识率和评分者间一致性，以量化协作输出的可靠性。关键结果表明，Claude 和 GPT-4 表现出最高的可靠性和一致性，这体现在它们更窄的置信区间和与问题生成模型的更高一致性上。相反，Gemini 和 LLaMA 的共识率变化更大，这反映在更宽的置信区间和更低的可靠性百分比中。这些发现表明，大型语言模型 (LLM) 之间的协作交互可显著提高响应可靠性，为人工智能系统中的自主、合作推理和验证提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2411.16797</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用噪声数据对 LLM 进行微调以生成政治论据</title>
      <link>https://arxiv.org/abs/2411.16813</link>
      <description><![CDATA[arXiv:2411.16813v1 公告类型：新 
摘要：社交媒体话语中的不文明行为使部署针对政治敏感内容的自动文本生成模型变得复杂。微调和提示策略是缓解此类情况下毒性的关键但尚未得到充分探索的解决方案。本研究使用 CLAPTON 政治讨论帖子数据集的子集（包括标记为其合理性、互惠性和不文明性的 Twitter 和 Reddit 数据）调查了微调和提示对 GPT-3.5 Turbo 的影响。Reddit 数据的微调模型在讨论质量上得分最高，而组合噪声数据则导致持续的毒性。提示策略减少了特定的毒性特征，例如人身攻击，但更广泛的影响有限。研究结果强调，高质量的数据和精心设计的提示对于减少不文明行为和提高自动政治话语生成的修辞质量至关重要。]]></description>
      <guid>https://arxiv.org/abs/2411.16813</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多表征学习和 LLM 生成的专家摘要来增强住院死亡率预测</title>
      <link>https://arxiv.org/abs/2411.16818</link>
      <description><![CDATA[arXiv:2411.16818v1 公告类型：新 
摘要：ICU 患者住院死亡率 (IHM) 预测对于及时干预和有效资源分配至关重要。虽然结构化生理数据提供了定量见解，但临床记录提供了非结构化、背景丰富的叙述。本研究将这些模式与大型语言模型 (LLM) 生成的专家摘要相结合，以提高 IHM 预测准确性。使用 MIMIC-III 数据库，我们分析了 ICU 入院后前 48 小时的时间序列生理数据和临床记录。临床记录按时间顺序串联每个患者，并使用 Med42-v2 70B 转换为专家摘要。开发了一个多表示学习框架来整合这些数据源，利用 LLM 来增强文本数据，同时减轻对 LLM 预测的直接依赖，这可能会给不确定性量化和可解释性带来挑战。与仅基于时间序列的基线相比，所提出的模型实现了 0.6156 (+36.41%) 的 AUPRC 和 0.8955 (+7.64%) 的 AUROC。专家摘要的表现优于单独的临床笔记或时间序列数据，证明了 LLM 生成的知识的价值。各个人口群体的性能提升是一致的，代表性不足的人群的性能显著提高，凸显了该框架的公平应用潜力。通过将 LLM 生成的摘要与结构化和非结构化数据相结合，该框架可以捕获互补的患者信息，从而显著提高预测性能。这种方法展示了 LLM 增强重症监护预测模型的潜力，强调了需要针对特定​​领域的验证和先进的集成策略才能更广泛地应用于临床。]]></description>
      <guid>https://arxiv.org/abs/2411.16818</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>集成测地线插值和流匹配，在 Logit 空间中实现非自回归文本生成</title>
      <link>https://arxiv.org/abs/2411.16821</link>
      <description><![CDATA[arXiv:2411.16821v1 公告类型：新
摘要：非自回归语言模型正在成为自然语言处理领域中自回归模型的有效替代方案，有助于同时生成标记。本研究介绍了一种新颖的流匹配方法，该方法采用 Kullback-Leibler (KL) 散度测地线在离散序列的初始分布和目标分布之间进行插值。我们制定了一个旨在最大化离散标记条件似然的损失函数，并证明其最大化器对应于 logit 插值期间的流匹配速度。虽然在 TinyStories 数据集上进行的初步实验产生了次优结果，但我们提出了一种基于预训练降噪器的经验采样方案，可显着提高性能。此外，我们提出了一种更通用的混合方法，可在更复杂的数据集（例如 Fine Web 和 Lamini Instruction）上实现出色的性能。]]></description>
      <guid>https://arxiv.org/abs/2411.16821</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用法学硕士 (LLM) 生成以教育内容为导向的意大利语填字游戏</title>
      <link>https://arxiv.org/abs/2411.16936</link>
      <description><![CDATA[arXiv:2411.16936v1 公告类型：新
摘要：在这项工作中，我们利用 GPT-4o、Mistral-7B-Instruct-v0.3 和 Llama3-8b-Instruct 等高级语言模型，推出了一种从文本生成意大利语填字游戏的新工具。这款尖端生成器专为教育应用而设计，利用了全面的 Italian-Clue-Instruct 数据集，该数据集包含超过 30,000 个条目，包括各种文本、解决方案和线索类型。这个精心组装的数据集旨在促进创建与特定文本和关键字相关的各种风格的上下文相关线索。该研究深入研究了四种独特的填字游戏线索风格：没有格式限制的线索、形成为明确限定词短语的线索、系动词句和裸名词短语的线索。每种风格都引入了独特的语言结构来使线索呈现多样化。由于缺乏针对意大利语的先进教育工具，该项目旨在通过一个引人入胜的互动平台来增强学习体验和认知发展。通过将最先进的人工智能与当代教育策略相结合，我们的工具可以根据意大利语教育材料动态生成填字游戏，从而提供令人愉快且互动的学习环境。这项技术进步不仅重新定义了教育模式，还为互动和认知语言学习解决方案树立了新的标杆。]]></description>
      <guid>https://arxiv.org/abs/2411.16936</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>教授较小的语言模型来概括看不见的组合问题（完整论文）</title>
      <link>https://arxiv.org/abs/2411.16985</link>
      <description><![CDATA[arXiv:2411.16985v1 公告类型：新
摘要：预训练的大型语言模型 (LLM) 能够回答在训练期间不太可能遇到的问题。然而，在推理系统的广泛领域中存在着各种潜在的应用，延迟、成本、可用的计算资源和互联网连接等考虑因素与确定适当的方法有关。我们考虑在推理时有一些本地计算能力可用但没有互联网连接的情况。
与通用 LLM 类似，我们假设我们的小得多的推理模型可能会被问到来自未知分布的任意问题，因此我们专注于在看不见的环境中进行评估。我们通过灌输对检索到的上下文进行推理的能力来训练我们的模型来回答各种问题。我们从两个知识来源获取上下文；使用具有新扩展的多跳密集检索系统查询的维基百科语料库，以及从优化为在较低资源环境中运行的较大语言模型生成的理由。
我们的主要贡献：我们提出了新颖的方法来表明我们的模型能够回答情境化问题而无需记忆。我们在未见过的评估数据集上建立了一套全面的基线结果。我们表明，在推理模型的训练机制中添加新的检索增强训练数据集 (RATD) 可显著改善结果。我们通过应用结合来自两个来源的知识的方法来展示进一步的显著改进。第一种方法 (RR) 涉及训练一种新颖的 Rationale Ranking 模型，以根据相关性和真实性对生成的原理和检索到的上下文进行评分。我们使用这些分数来得出组合上下文。我们还表明，利用 RATD 数据集使我们的模型能够熟练地利用组合的噪声上下文。]]></description>
      <guid>https://arxiv.org/abs/2411.16985</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过先前的小批量进行动态自我提炼，以微调小型语言模型</title>
      <link>https://arxiv.org/abs/2411.16991</link>
      <description><![CDATA[arXiv:2411.16991v1 公告类型：新
摘要：知识蒸馏 (KD) 已成为一种广泛采用的方法，用于压缩大型语言模型 (LLM)，以降低计算成本和内存占用。然而，复杂的教师模型的可用性是运行大多数 KD 管道的先决条件。因此，传统的 KD 程序可能无法实现或预算不友好，特别是在依赖 GPT4 等商业 LLM 时。在这方面，自我蒸馏 (SelfD) 作为一种可取的替代方案应运而生，使学生模型能够在没有老师指导的情况下学习。尽管如此，现有的 LM 的 SelfD 方法通常涉及架构修改，假设模型是开源的，这可能并不总是可行的。在这项工作中，我们引入了一种与模型无关和与任务无关的方法，称为来自前一个 minibatch (DynSDPB) 的动态 SelfD，它实现了当前迭代从最后生成的 logit 中进行蒸馏。此外，为了解决早期迭代过程中的预测不准确性问题，我们动态调整蒸馏影响和温度值以增强微调的适应性。此外，DynSDPB 是一种新颖的微调策略，有助于无缝集成现有的小型语言模型 (SLM) 的自我校正和自我训练技术，因为它们都需要更新 SLM 的参数。我们展示了 DynSDPB 在仅编码器 LM（例如 BERT 模型系列）和仅解码器 LM（例如 LLaMA 模型系列）上的卓越性能，验证了其在自然语言理解 (NLU) 和自然语言生成 (NLG) 基准测试中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.16991</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>树形转换器是一种无效的句法成分模型</title>
      <link>https://arxiv.org/abs/2411.16993</link>
      <description><![CDATA[arXiv:2411.16993v1 公告类型：新
摘要：语言学家长期以来一直认为，自然语言语法的一个关键方面是将语言单元递归组织成组成结构，研究表明，当前最先进的语言模型缺乏对这一特征的固有偏见。已经提出了许多替代模型来提供对成分的归纳偏差，包括 Tree Transformer，它利用改进的注意力机制将标记组织成成分。
我们研究 Tree Transformer，以研究它们是否使用有意义和/或有用的组成结构。我们在语言建模上对大型 Tree Transformer 进行预训练，以研究学习到的句子的组成树表示，发现几乎没有证据表明有意义的结构。接下来，我们在需要组成结构的错误检测任务上评估具有类似转换器模型的 Tree Transformer。我们发现，虽然 Tree Transformer 模型在这些任务上的表现可能略胜一筹，但几乎没有证据表明有意义的改进。总的来说，我们得出的结论是，几乎没有证据支持 Tree Transformer 作为句法成分的有效模型。]]></description>
      <guid>https://arxiv.org/abs/2411.16993</guid>
      <pubDate>Wed, 27 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>