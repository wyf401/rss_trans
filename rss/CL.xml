<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 08 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>重新审视表面对齐假设</title>
      <link>https://arxiv.org/abs/2410.03717</link>
      <description><![CDATA[arXiv:2410.03717v1 公告类型：新
摘要：表面对齐假设认为语言模型的几乎所有能力和知识都是在预训练期间学习的，而后训练则是为模型提供正确的风格和格式。我们通过实证研究随着微调示例的增加，后训练的扩展行为并使用客观任务特定的标准化基准对其进行评估，重新审视了这些说法。通过对多种规模的 Llama-3、Mistral 和 Llama-2 模型系列进行实验，我们观察到，与预训练扩展定律类似，后训练任务性能随微调示例的数量呈幂律扩展。这种幂律关系适用于广泛的能力，包括数学推理、编码、指令遵循和多跳推理。此外，对于数学和多跳推理等任务，我们观察到少数示例仅在风格上与模型保持一致，但并未达到基准测试中的最佳性能。相反，模型性能与其推理能力相关，并且随着示例数量的增加，性能会显著提高，这说明除了测量与人类偏好的一致性之外，还需要利用客观基准进行整体评估。我们还观察到，语言模型不一定局限于使用在训练前学到的知识。通过适当的后训练，模型整合新知识的能力在多跳问答等下游任务上会大大提高。总之，这些结果为表面对齐假设提供了新的见解，表明它充其量只是一种过度简化。]]></description>
      <guid>https://arxiv.org/abs/2410.03717</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>阿萨姆语大型语言模型中的标记器性能评估</title>
      <link>https://arxiv.org/abs/2410.03718</link>
      <description><![CDATA[arXiv:2410.03718v1 公告类型：新
摘要：标记器的训练在深度学习模型的性能中起着重要作用。本研究旨在了解印度阿萨姆语中五种最先进的 (SOTA) 大型语言模型 (LLM) 中标记器的性能。这项研究对于了解对阿萨姆语等资源匮乏的语言的多语言支持非常重要。我们的研究表明，Two AI 的 SUTRA 标记器表现最佳，平均归一化序列长度 (NSL) 值为 0.45，紧随其后的是 Open AI 的 GPT-4o 标记器，平均 NSL 值为 0.54，其次是 Gemma 2、Meta Llama 3.1 和 Mistral Large Instruct 2407，平均 NSL 值分别为 0.82、1.4 和 1.48。]]></description>
      <guid>https://arxiv.org/abs/2410.03718</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FluentEditor+：通过建模局部分层声学平滑度和全局韵律一致性实现基于文本的语音编辑</title>
      <link>https://arxiv.org/abs/2410.03719</link>
      <description><![CDATA[arXiv:2410.03719v1 公告类型：新
摘要：基于文本的语音编辑 (TSE) 允许用户通过编辑相应的文本并执行剪切、复制和粘贴等操作来修改语音，以生成更新的音频，而无需直接更改原始录音。基于文本的语音编辑 (TSE) 允许用户通过编辑相应的文本并执行剪切、复制和粘贴等操作来修改语音，以生成更新的音频，而无需直接更改原始录音。虽然当前的 TSE 技术专注于最大限度地减少编辑片段中生成的语音和参考目标之间的差异，但它们往往忽视了在原始话语的背景下保持局部和整体流畅性的重要性。此外，将编辑的片段与未改变的音频部分无缝集成仍然具有挑战性，通常需要文本到语音 (TTS) 系统的支持。本文介绍了一种旨在克服这些限制的新方法 FluentEditor$\tiny +$。 FluentEditor$\tiny +$ 采用先进的特征提取技术来捕捉声学和韵律特征，确保编辑区域和未编辑区域之间的流畅过渡。该模型确保了分段声学平滑度和整体韵律一致性，允许无缝拼接语音，同时保持输出的连贯性和自然性。在 VCTK 和 LibriTTS 数据集上进行的大量实验表明，FluentEditor$\tiny +$ 在流畅度和韵律方面都超越了现有的基于 TTS 的方法，包括 Editspeech、Campnet、$A^3T$ FluentSpeech 和 Fluenteditor。消融研究进一步强调了每个模块对系统整体有效性的贡献。]]></description>
      <guid>https://arxiv.org/abs/2410.03719</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用开源生成式人工智能和机器学习进行主题分析：归纳定性码本开发的新方法</title>
      <link>https://arxiv.org/abs/2410.03721</link>
      <description><![CDATA[arXiv:2410.03721v1 公告类型：新
摘要：本文旨在回答一个核心问题：开源生成文本模型在多大程度上可以用于工作流程以近似社会科学研究中的主题分析？为了回答这个问题，我们提出了生成式人工智能主题组织和结构 (GATOS) 工作流程，该工作流程使用开源机器学习技术、自然语言处理工具和生成文本模型来促进主题分析。为了确定该方法的有效性，我们提出了三个应用 GATOS 工作流程的案例研究，利用这些模型和技术归纳性地创建类似于使用主题分析的传统程序的代码本。具体来说，我们研究由开源模型和工具组成的工作流程在多大程度上可以归纳性地生成接近已知主题和子主题空间的代码本。为了应对从这些文本中获取见解的挑战，我们结合了开源生成文本模型、检索增强生成和快速工程，以识别大量文本中的代码和主题，即生成定性代码本。该过程模仿了研究人员在传统主题分析中可能使用的归纳编码过程，即一次阅读一个分析单元的文本，考虑代码本中已有的代码，然后根据现有代码本是否提供足够的主题覆盖范围来决定是否生成新代码。我们使用来自假设组织研究环境的三个合成数据集来演示此工作流程：一项关于团队合作环境中队友反馈的研究、一项关于组织道德行为文化的研究以及一项关于员工对疫情后重返办公室的看法的研究。我们表明，GATOS 工作流程能够识别用于生成原始合成数据集的文本中的主题。]]></description>
      <guid>https://arxiv.org/abs/2410.03721</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能下的人类偏见：人类判断在人工智能生成的文本评估中的作用</title>
      <link>https://arxiv.org/abs/2410.03723</link>
      <description><![CDATA[arXiv:2410.03723v1 公告类型：新
摘要：随着人工智能在文本生成方面的进步，人类对人工智能生成内容的信任仍然受到超出准确性问题的偏见的制约。本研究探讨了偏见如何影响人们对人工智能与人类生成内容的看法。通过三项涉及文本改写、新闻文章摘要和说服性写作的实验，我们调查了人类评分者对标记和未标记内容的反应。虽然评分者无法在盲测中区分这两种类型的文本，但他们压倒性地偏爱标记为“人类生成”的内容，而不是标记为“人工智能生成”的内容，偏好分数超过 30%。即使标签被故意交换，我们也观察到了同样的模式。人类对人工智能的偏见具有更广泛的社会和认知影响，因为它低估了人工智能的表现。这项研究强调了人类判断在与人工智能互动方面的局限性，并为改善人机协作奠定了基础，尤其是在创意领域。]]></description>
      <guid>https://arxiv.org/abs/2410.03723</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用语言模型和 BoXHED 进行实时、多模式侵入式通气风险监测</title>
      <link>https://arxiv.org/abs/2410.03725</link>
      <description><![CDATA[arXiv:2410.03725v1 公告类型：新
摘要：目的：重症监护病房 (ICU) 中侵入性通气 (iV) 的实时监测在确保及时干预和更好的患者结果方面起着至关重要的作用。然而，传统方法往往忽视临床记录中嵌入的宝贵见解，而仅仅依赖于表格数据。在本研究中，我们提出了一种创新方法，通过使用语言模型进行文本摘要，将临床记录纳入监测管道，以增强 iV 风险监测。结果：我们在 iV 风险监测的最新指标中取得了优异的表现，即：AUROC 为 0.86、AUC-PR 为 0.35 和 AUCt 高达 0.86。我们还证明，我们的方法允许在特定时间段内标记 iV 时有更多前置时间。结论：我们的研究强调了将临床记录和语言模型整合到实时 iV 风险监测中的潜力，为改善 ICU 环境中的患者护理和明智的临床决策铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.03725</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中的神经符号 AI 方法归因</title>
      <link>https://arxiv.org/abs/2410.03726</link>
      <description><![CDATA[arXiv:2410.03726v1 公告类型：新
摘要：大型语言模型 (LLM) 中的归因仍然是一项重大挑战，特别是在确保生成输出的事实准确性和可靠性方面。当前的引用或归因方法，例如 Perplexity.ai 和 Bing Search 集成的 LLM 等工具所采用的方法，试图通过提供实时搜索结果和引用来提供响应。然而，到目前为止，这些方法存在幻觉、偏见、表面相关性匹配以及管理大量未经过滤的知识源的复杂性等问题。虽然像 Perplexity.ai 这样的工具可以动态地集成基于网络的信息和引用，但它们通常依赖于不一致的来源，例如博客文章或不可靠的来源，这限制了它们的整体可靠性。我们提出，可以通过集成神经符号 AI (NesyAI) 来缓解这些挑战，它将神经网络的优势与结构化符号推理相结合。 NesyAI 提供透明、可解释和动态的推理过程，通过将结构化符号知识与灵活的基于神经的学习相结合来解决当前归因方法的局限性。本文探讨了 NesyAI 框架如何增强现有的归因模型，为 LLM 提供更可靠、更可解释和更适应的系统。]]></description>
      <guid>https://arxiv.org/abs/2410.03726</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FaithEval：即使“月亮是由棉花糖制成的”，你的语言模型是否能忠实于上下文</title>
      <link>https://arxiv.org/abs/2410.03727</link>
      <description><![CDATA[arXiv:2410.03727v1 公告类型：新
摘要：确保大型语言模型 (LLM) 和检索增强生成 (RAG) 系统中的上下文忠实性对于在实际应用中的可靠部署至关重要，因为不正确或不受支持的信息会削弱用户的信任。尽管标准基准取得了进步，但忠实幻觉（即模型生成的响应与提供的上下文不一致）仍然是一个重大挑战。在这项工作中，我们引入了 FaithEval，这是一种新颖而全面的基准，专门用于评估 LLM 在三个不同任务中的上下文场景中的忠实度：无法回答、不一致和反事实上下文。这些任务模拟了现实世界的挑战，其中检索机制可能会显示不完整、矛盾或捏造的信息。FaithEval 总共包含 4.9K 个高质量问题，通过严格的四阶段上下文构建和验证框架进行验证，同时采用基于 LLM 的自动评估和人工验证。我们对大量开源和专有模型进行的广泛研究表明，即使是最先进的模型也常常难以忠实于给定的环境，而较大的模型并不一定能表现出更好的忠实度。项目网址为：\url{https://github.com/SalesforceAIResearch/FaithEval}。]]></description>
      <guid>https://arxiv.org/abs/2410.03727</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>进度报告：迈向欧洲法学硕士</title>
      <link>https://arxiv.org/abs/2410.03730</link>
      <description><![CDATA[arXiv:2410.03730v1 公告类型：新
摘要：我们介绍了 OpenGPT-X 项目的初步结果。目前，该项目已经开发了两种多语言 LLM，旨在通过支持欧盟所有 24 种官方语言来适应欧洲的语言多样性。我们的模型在包含约 60% 非英语数据的数据集上进行训练，并使用自定义多语言标记器，解决了现有 LLM 主要关注英语或少数高资源语言的局限性。我们详细介绍了模型的开发原理、数据处理技术、标记器优化和训练方法。这些模型在多语言基准测试中表现出色，其在欧洲版本的 ARC、HellaSwag、MMLU 和 TruthfulQA 上的表现就是明证。]]></description>
      <guid>https://arxiv.org/abs/2410.03730</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无监督的人类偏好学习</title>
      <link>https://arxiv.org/abs/2410.03731</link>
      <description><![CDATA[arXiv:2410.03731v1 公告类型：新
摘要：大型语言模型表现出令人印象深刻的推理能力，但由于缺乏个人用户偏好信息，难以提供个性化内容。现有的方法，例如上下文学习和参数高效微调，无法捕捉人类偏好的复杂性，尤其是考虑到个人拥有的小型个人数据。在本文中，我们提出了一种新方法，利用小参数模型作为偏好代理来生成自然语言规则，指导更大的预训练模型，实现高效的个性化。我们的方法涉及一个小型的局部“方向盘”模型，该模型指导更大的基础模型的输出，生成适合个人偏好的内容，同时利用大型模型的广泛知识和功能。重要的是，这种个性化是在无需微调大型模型的情况下实现的。电子邮件和文章数据集上的实验结果表明，我们的技术明显优于基线个性化方法。通过允许基础模型以数据和计算高效的方式适应个人偏好，我们的方法为高度个性化的语言模型应用铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.03731</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过聚类重要性采样实现任务自适应预训练语言模型</title>
      <link>https://arxiv.org/abs/2410.03735</link>
      <description><![CDATA[arXiv:2410.03735v1 公告类型：新
摘要：专业语言模型 (LM) 专注于特定任务或领域，在这些领域，它们的表现通常优于同等规模的通用语言模型。然而，对于大多数任务来说，预训练这些模型所需的专业数据数量有限。在这项工作中，我们从大型通用训练集构建专业模型。我们在有限的领域特定数据的指导下调整通用数据的训练分布。我们探索了几种方法，其中聚类重要性抽样脱颖而出。该方法对通用数据集进行聚类，并根据它们在较小专业数据集中的频率从这些聚类中抽样。它是可扩展的，适用于预训练和持续预训练，在多任务设置中效果很好。我们的研究结果表明，在语言建模困惑度和多项选择题任务的准确性方面，不同领域都有所改进。我们还提出了消融研究，研究数据集大小、聚类配置和模型大小的影响。]]></description>
      <guid>https://arxiv.org/abs/2410.03735</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ERASMO：利用大型语言模型增强聚类分割</title>
      <link>https://arxiv.org/abs/2410.03738</link>
      <description><![CDATA[arXiv:2410.03738v1 公告类型：新
摘要：聚类分析在各种领域和应用中起着至关重要的作用，例如营销中的客户细分。这些上下文通常涉及多模态数据，包括表格和文本数据集，因此很难表示隐藏的模式以获得有意义的聚类。本研究介绍了 ERASMO，这是一个框架，旨在对文本编码的表格数据进行微调，并从微调后的模型中生成嵌入。ERASMO 使用文本转换器将表格数据转换为文本格式，使语言模型能够更有效地处理和理解数据。此外，ERASMO 通过随机特征序列改组和数字语言化等技术生成上下文丰富且结构具有代表性的嵌入。使用多个数据集和基线方法进行了广泛的实验评估。我们的结果表明，ERASMO 充分利用了每个表格数据集的特定上下文，从而为准确的聚类提供了更精确和细致入微的嵌入。这种方法通过捕获不同表格数据中的复杂关系模式来增强聚类性能。]]></description>
      <guid>https://arxiv.org/abs/2410.03738</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从视觉、语音和文本进行语法归纳</title>
      <link>https://arxiv.org/abs/2410.03739</link>
      <description><![CDATA[arXiv:2410.03739v1 公告类型：新
摘要：语法归纳可以从丰富的异构信号中受益，例如文本、视觉和声学。在此过程中，不同模态的特征本质上起着互补的作用。基于这种直觉，这项工作引入了一种新颖的 \emph{无监督视觉-音频-文本语法归纳} 任务（名为 \textbf{VAT-GI}），用于从并行图像、文本和语音输入中归纳组成语法树。受语言语法本身存在于文本之外这一事实的启发，我们认为文本不必是语法归纳的主要模态。因此，我们进一步引入了 VAT-GI 的 \emph{无文本} 设置，其中任务仅依赖于视觉和听觉输入。为了完成这项任务，我们提出了一个视音频文本内外递归自动编码器（\textbf{VaTiora}）框架，该框架利用丰富的模态特定和互补特征进行有效的语法解析。此外，我们还构建了一个更具挑战性的基准数据来评估 VAT-GI 系统的泛化能力。在两个基准数据集上进行的实验表明，我们提出的 VaTiora 系统在整合各种多模态信号方面更为有效，并且还展现了 VAT-GI 的全新最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2410.03739</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>眼睛语言增强模型 (LEME)：一种开源眼科专用大型语言模型</title>
      <link>https://arxiv.org/abs/2410.03740</link>
      <description><![CDATA[arXiv:2410.03740v1 公告类型：新
摘要：大型语言模型 (LLM) 有望彻底改变医疗保健。眼科专用的 LLM 仍然稀缺且尚未得到充分开发。我们引入了一种开源的眼科专用 LLM，称为眼科语言增强模型 (LEME)。LEME 最初在 Llama2 70B 框架上进行预训练，并使用从眼科特定病例报告、摘要和开源研究材料中精选的约 127,000 个非版权训练实例语料库进行进一步微调。我们将 LEME 与其他八个 LLM 进行了对比，即 GPT-3.5、GPT-4、三个 Llama2 模型（7B、13B、70B）、PMC-LLAMA 13B、Meditron 70B 和 EYE-Llama（另一个眼科专用 LLM）。评估包括四个内部验证任务：摘要完成、填空、多项选择题 (MCQ) 和简答题 QA。外部验证任务包括长篇 QA、MCQ、患者 EHR 摘要和临床 QA。评估指标包括 Rouge-L 分数、准确性以及专家对正确性、完整性和可读性的评估。在内部验证中，LEME 的表现始终优于其同行，在摘要完成度方面取得了 0.20 的 Rouge-L 分数（所有 p&lt;0.05），在填空方面取得了 0.82 的分数（所有 p&lt;0.0001），在简答 QA 方面取得了 0.22 的分数（所有 p&lt;0.0001，与 GPT-4 相比除外）。在外部验证中，LEME 在长篇 QA 方面表现出色，Rouge-L 为 0.19（所有 p&lt;0.0001），在 MCQ 准确率方面排名第二（0.68；所有 p&lt;0.0001），在 EHR 摘要和临床 QA 方面得分最高（正确性、完整性和可读性得分从 4.24 到 4.83（满分 5 分））。
LEME 强调强大的微调和使用非版权数据，这代表了开源眼科特定 LLM 的突破，有可能彻底改变临床任务的执行，同时使研究合作民主化。]]></description>
      <guid>https://arxiv.org/abs/2410.03740</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越标量奖励模型：从偏好数据中学习生成判断</title>
      <link>https://arxiv.org/abs/2410.03742</link>
      <description><![CDATA[arXiv:2410.03742v1 公告类型：新
摘要：从偏好反馈中学习是将大型语言模型（LLM）与人类价值观相结合的常见做法。传统上，偏好数据被学习并编码到标量奖励模型中，该模型将价值头与 LLM 连接起来，以产生标量分数作为偏好或奖励。然而，标量模型缺乏可解释性，并且已知容易受到数据集偏差的影响。本文研究利用 LLM 的生成能力一次性解决这两个限制。具体来说，我们提示预先训练的 LLM 生成正面和负面的判断，两者都以自然语言形式的理由支持。自生成的对比判断对用于通过直接偏好优化 (DPO) 训练生成判断。这种使用自生成对比判断（Con-J）来训练生成式判断的提议，确保了生成的理由与判断一起具有自然的可解释性，并且无需额外的奖励头即可对偏见具有很高的鲁棒性。实验结果表明，Con-J 的性能与在同一组偏好数据上训练的标量奖励模型相当，并展示了其在编码人类偏好方面卓越的可解释性和鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2410.03742</guid>
      <pubDate>Tue, 08 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>