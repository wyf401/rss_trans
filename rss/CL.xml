<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 02 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>金融知识大语言模型</title>
      <link>https://arxiv.org/abs/2407.00365</link>
      <description><![CDATA[arXiv:2407.00365v1 公告类型：新
摘要：人工智能正在金融行业取得重大进展，彻底改变了数据的处理和解释方式。在这些技术中，大型语言模型（LLM）通过自动化复杂任务、增强客户服务和提供详细的财务分析，显示出改变金融服务的巨大潜力。首先，我们介绍了 IDEA-FinBench，这是一个专门为评估大型语言模型（LLM）中的金融知识而量身定制的评估基准。该基准使用了两个全球知名的权威金融专业考试的问题，旨在全面评估 LLM 直接解决与金融行业相关的考试问题的能力。其次，我们提出了 IDEA-FinKER，这是一个金融知识增强框架，旨在促进一般 LLM 快速适应金融领域，引入一种基于检索的少量学习方法用于实时上下文级知识注入，以及一组用于微调任何一般 LLM 的高质量金融知识指令。最后，我们介绍 IDEA-FinQA，这是一个由 LLM 驱动的金融问答系统。该系统围绕实时知识注入和使用外部知识进行事实增强的方案构建。IDEA-FinQA 由三个主要模块组成：数据收集器、数据查询模块和负责特定功能的基于 LLM 的代理。]]></description>
      <guid>https://arxiv.org/abs/2407.00365</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:18 GMT</pubDate>
    </item>
    <item>
      <title>如何训练事实验证器：使用多模式开放模型进行知识转移</title>
      <link>https://arxiv.org/abs/2407.00369</link>
      <description><![CDATA[arXiv:2407.00369v1 公告类型：新
摘要：鉴于新闻和社交媒体中错误信息的不断涌入，迫切需要能够提供有效的实时新闻声明验证的系统。已经提出了基于大型语言或多模态模型的验证，以扩大在线监管机制，以减轻虚假和有害内容的传播。虽然这些可以潜在地减轻人类事实核查员的负担，但基础模型训练数据过时可能会阻碍这种努力。在这项工作中，我们通过初步研究知识转移来测试在不持续更新的情况下提高基础模型性能的极限，这些研究使用现有的域内和域间基准或从大型语言模型 (LLM) 生成的解释。我们评估了 12 个事实核查和错误信息检测的公共基准以及其他两个与内容审核相关的任务——毒性和立场检测。我们对两个最近的多模式事实核查基准 Mocheg 和 Fakeddit 的结果表明，知识转移策略可以将 Fakeddit 的性能提高 1.7%，将 Mocheg 的性能提高 2.9%。]]></description>
      <guid>https://arxiv.org/abs/2407.00369</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:18 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行迭代数据增强以实现基于方面的情绪分析</title>
      <link>https://arxiv.org/abs/2407.00341</link>
      <description><![CDATA[arXiv:2407.00341v1 公告类型：新
摘要：基于方面的情绪分析（ABSA）是一项重要的情绪分析任务，旨在确定句子中对某个方面的情绪极性。由于标记数据昂贵且有限，数据增强（DA）已成为提高 ABSA 性能的标准。然而，当前的 DA 方法通常存在一些缺点：1）流畅性和连贯性较差，2）生成数据缺乏多样性，3）依赖于一些现有的标记数据，阻碍了其在实际场景中的应用。针对这些问题，我们提出了一个系统的迭代数据增强框架，即 IterD，以提高 ABSA 的性能。IterD 的核心是利用大型语言模型（LLM）的强大能力，从无监督句子语料库开始迭代生成更流畅、更多样化的合成标记数据。在 4 个广泛使用的 ABSA 基准上进行的大量实验表明，IterD 在 5 个基线 ABSA 模型中带来了一致且显著的性能提升。更令人鼓舞的是，IterD 生成的合成数据可以实现与手动注释数据相当甚至更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.00341</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>通过隐式特征对齐和语料库过滤进行韩语基于方面的情绪分析</title>
      <link>https://arxiv.org/abs/2407.00342</link>
      <description><![CDATA[arXiv:2407.00342v1 公告类型：新
摘要：现有文献中对韩国餐厅评论的基于方面的情绪分析 (ABSA) 的研究明显不足。我们的研究提出了一个直观有效的框架，用于韩语等资源匮乏的语言中的 ABSA。它通过整合翻译的基准和未标记的韩语数据来优化预测标签。使用对翻译数据进行微调的模型，我们对实际的韩语 NLI 集进行了伪标记。随后，我们将 LaBSE 和基于 MSP 的过滤作为隐式特征应用于这个伪 NLI 集，通过额外的训练增强了方面类别检测和极性确定。结合双重过滤，该模型弥补了数据集差距，以最少的资源在韩语 ABSA 中取得了积极成果。通过额外的数据注入管道，我们的方法旨在利用高资源数据并在资源匮乏的语言国家的社区（无论是企业还是个人）内构建有效的模型。与英语 ABSA 相比，我们的框架在 F1 分数和准确度方面显示出约 3% 的差异。我们在此链接中发布了韩国 ABSA 的数据集和代码。]]></description>
      <guid>https://arxiv.org/abs/2407.00342</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>从 RAG 到 RICHES：检索与序列生成交织在一起</title>
      <link>https://arxiv.org/abs/2407.00361</link>
      <description><![CDATA[arXiv:2407.00361v1 公告类型：新
摘要：我们提出了 RICHES，这是一种将检索与序列生成任务交错在一起的新方法。RICHES 消除了对单独检索器和生成器的需求，为传统 RAG 系统提供了一种替代方案。它通过直接解码文档内容来检索文档，并限制在语料库中。将检索与生成统一起来使我们能够仅通过提示就适应各种新任务。RICHES 可以与任何指令调整模型一起使用，而无需额外的训练。它提供归因证据，支持多跳检索并交错思考以计划下一步要检索的内容，所有这些都在 LLM 的一次解码过程中完成。我们展示了 RICHES 在 ODQA 任务（包括归因和多跳 QA）中的强大性能。]]></description>
      <guid>https://arxiv.org/abs/2407.00361</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>DiffuseDef：增强对抗攻击的鲁棒性</title>
      <link>https://arxiv.org/abs/2407.00248</link>
      <description><![CDATA[arXiv:2407.00248v1 公告类型：新
摘要：预训练语言模型在各种自然语言处理任务中具有显着的先进性能。然而，对抗性攻击仍然对使用这些模型构建的系统构成严峻挑战，因为它们可以通过精心制作的对抗性文本进行利用。受扩散模型预测和降低计算机视觉噪声的能力的启发，我们提出了一种用于语言分类任务的新颖而灵活的对抗性防御方法 DiffuseDef，它在编码器和分类器之间结合了一个扩散层作为降噪器。在推理过程中，对抗性隐藏状态首先与采样噪声相结合，然后迭代去噪，最后集成以产生鲁棒的文本表示。通过整合对抗性训练、去噪和集成技术，我们表明 DiffuseDef 比现有的不同对抗性防御方法有所改进，并在对抗常见对抗性攻击方面实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.00248</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>从局部概念到普遍概念：评估视觉语言模型的多元文化理解</title>
      <link>https://arxiv.org/abs/2407.00263</link>
      <description><![CDATA[arXiv:2407.00263v1 公告类型：新 
摘要：尽管视觉语言模型最近取得了进展，但由于训练数据集中的代表性不足，它们在非西方文化的图像上的表现仍然不理想。已经提出了各种基准来测试模型的文化包容性，但它们对文化的覆盖范围有限，并且不能充分评估普遍和特定文化的本地概念的文化多样性。为了解决这些限制，我们引入了 GlobalRG 基准，它包括两个具有挑战性的任务：跨普遍性检索和文化视觉基础。前一项任务需要从 50 个国家/地区检索文化多样化的通用概念图像，而后一项任务旨在将特定文化的概念扎根于 15 个国家/地区的图像中。我们对各种模型的评估表明，不同文化之间的性能差异很大——强调了在视觉语言模型中增强多元文化理解的必要性。]]></description>
      <guid>https://arxiv.org/abs/2407.00263</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>LiteSearch：针对法学硕士 (LLM) 的有效树状搜索</title>
      <link>https://arxiv.org/abs/2407.00320</link>
      <description><![CDATA[arXiv:2407.00320v1 公告类型：新
摘要：最近的研究表明，树搜索算法（例如蒙特卡洛树搜索）可以显著提高 LLM 在复杂数学推理任务上的性能。然而，由于浪费的搜索策略，它们通常需要比贪婪解码多 10 倍的计算资源，这使得它们难以在实际应用中部署。本研究引入了一种新的引导树搜索算法，该算法具有动态节点选择和节点级探索预算（最大子节点数）计算来解决此问题。通过考虑朝着最终答案（历史）的搜索进度和在没有任何分步注释的情况下训练的价值网络（未来）的指导，我们的算法在分配的计算预算范围内扩展它之前，迭代地选择最有希望的树节点。在 GSM8K 和 TabMWP 数据集上进行的实验表明，与基线方法相比，我们的方法不仅提供了具有竞争力的性能，而且计算成本也显著降低。]]></description>
      <guid>https://arxiv.org/abs/2407.00320</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>LLM 生成的自然语言符合缩放定律：新的探索和数据增强方法</title>
      <link>https://arxiv.org/abs/2407.00322</link>
      <description><![CDATA[arXiv:2407.00322v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的兴起，自然语言处理得到了增强，例如基于 LLM 的数据增强。然而，先前的研究存在两个主要问题：首先，缺乏对 LLM (LLMNL) 生成的自然语言是否真正与人类自然语言 (HNL) 一致的思考，这是一个关键的基础问题；其次，人们忽视了增强数据是由 LLM 随机生成的，这意味着并非所有数据都具有相同的训练价值，这可能会妨碍分类器的性能。为了应对这些挑战，我们引入了缩放定律来内在计算 LLMNL 和 HNL。通过大量实验，我们发现 LLMNL 与曼德布洛特定律略有偏差（约 0.2 曼德布洛特指数），强调了 HNL 的复杂性优势，并补充了对语言风格的解释性讨论。这为 LLM 的扩展奠定了坚实的基础。此外，我们引入了一种用于小样本文本分类的新型数据增强方法，称为 ZGPTDA，该方法利用符合缩放定律的模糊计算机制来对 GPT-4 增强数据进行决策。在现实场景中进行的大量实验证实了 ZGPTDA 的有效性（将 Bert 和 RoBerta 的 F1 提高了 7-10%）和竞争力（在 DeBerta 上的准确率比最近的 AugGPT 和 GENCO 方法高出约 2%）。此外，我们还揭示了一些有趣的见解，例如希尔伯格定律和泰勒定律可以为文本分类带来更多好处等。]]></description>
      <guid>https://arxiv.org/abs/2407.00322</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:16 GMT</pubDate>
    </item>
    <item>
      <title>生成文本中的句法模板的检测和测量</title>
      <link>https://arxiv.org/abs/2407.00211</link>
      <description><![CDATA[arXiv:2407.00211v1 公告类型：新
摘要：最近对 LLM 生成的文本多样性的评估工作主要集中在单词级特征上。在这里，我们对句法特征进行了分析，以表征模型中的一般重复，而不仅仅是频繁的 n-gram。具体来说，我们定义了句法模板，并表明模型在下游任务中生成模板文本的速率往往高于人类参考文本。我们发现，模型生成文本中的大多数（76%）模板都可以在预训练数据中找到（而人类编写的文本只有 35%），并且在 RLHF 等微调过程中不会被覆盖。这种与预训练数据的联系使我们能够在没有预训练数据的模型中分析句法模板。我们还发现，模板作为特征能够区分模型、任务和领域，并且可用于定性评估常见的模型构造。最后，我们展示了如何使用模板作为分析 LLM 中训练数据风格记忆的有用工具。]]></description>
      <guid>https://arxiv.org/abs/2407.00211</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:15 GMT</pubDate>
    </item>
    <item>
      <title>评估 LLM 理论的人类一致性和模型忠实度</title>
      <link>https://arxiv.org/abs/2407.00219</link>
      <description><![CDATA[arXiv:2407.00219v1 公告类型：新
摘要：我们研究大型语言模型 (LLM) 如何很好地用原理（从输入文本中提取的一组标记，反映了 LLM 的决策过程）解释其生成。我们检查了用两种方法提取的 LLM 原理：1) 使用注意力或梯度来定位重要标记的基于归因的方法，以及 2) 引导 LLM 使用提示提取原理的基于提示的方法。通过大量实验，我们表明基于提示的原理比基于归因的原理与人类注释的原理更一致，并且即使在模型性能较差的情况下也能与人类合理一致。我们还发现，在以前的工作中发现的基于提示的方法的忠诚度限制可能与它们的预测崩溃有关。通过在相应的数据集上微调这些模型，提示和归因方法都表现出更好的忠诚度。我们的研究有助于对法学硕士（LLM）的基本原理（尤其是基于提示的基本原理）进行更严格、更公正的评估。]]></description>
      <guid>https://arxiv.org/abs/2407.00219</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:15 GMT</pubDate>
    </item>
    <item>
      <title>EHRmonize：使用大型语言模型从电子健康记录中进行医学概念抽象的框架</title>
      <link>https://arxiv.org/abs/2407.00242</link>
      <description><![CDATA[arXiv:2407.00242v1 公告类型：新
摘要：电子健康记录 (EHR) 包含大量复杂数据，但协调和处理这些信息仍然是一项具有挑战性且成本高昂的任务，需要大量的临床专业知识。虽然大型语言模型 (LLM) 在各种医疗保健应用中显示出良好的前景，但它们从 EHR 中抽象医学概念的潜力仍未得到充分开发。我们引入了 EHRmonize，这是一个利用 LLM 从 EHR 数据中抽象医学概念的框架。我们的研究使用来自两个真实世界 EHR 数据库的药物数据来评估五个 LLM 在两个自由文本提取和六个二元分类任务中在不同提示策略下的表现。具有 10 次提示的 GPT-4o 在所有任务中都取得了最高的性能，并在部分任务中伴随着 Claude-3.5-Sonnet。GPT-4o 在识别通用路线名称方面的准确率为 97%，在识别通用药物名称方面的准确率为 82%，在执行抗生素二元分类方面的准确率为 100%。尽管 EHRmonize 显著提高了效率，将注释时间缩短了约 60%，但我们强调，临床医生的监督仍然至关重要。我们的框架以 Python 包的形式提供，它提供了一种有前途的工具，可帮助临床医生进行 EHR 数据抽象，从而有可能加速医疗保健研究并改善数据协调流程。]]></description>
      <guid>https://arxiv.org/abs/2407.00242</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:15 GMT</pubDate>
    </item>
    <item>
      <title>Qiyas 基准：衡量 ChatGPT 的阿拉伯语数学和语言理解能力</title>
      <link>https://arxiv.org/abs/2407.00146</link>
      <description><![CDATA[arXiv:2407.00146v1 公告类型：新 
摘要：尽管阿拉伯语作为全球语言的重要性日益增加，但专门针对阿拉伯语数据进行预训练的语言模型却明显不足。这种短缺导致可用于评估阿拉伯语语言模型性能的基准有限。为了解决这一差距，我们引入了两个新颖的基准，旨在评估模型在阿拉伯语中的数学推理和语言理解能力。这些基准源自通用能力倾向测试 (GAT)，即 Qiyas 考试，这是沙特阿拉伯大学录取中广泛使用的标准化测试。为了验证目的，我们在基准上评估了 ChatGPT-3.5-trubo 和 ChatGPT-4 的性能。我们的研究结果表明，这些基准带来了重大挑战，ChatGPT-4 的总体平均准确率为 64%，而 ChatGPT-3.5-trubo 在 Qiyas 基准的各种问题类型中的总体准确率为 49%。我们相信这些基准的发布将为增强针对低资源阿拉伯语的未来模型的数学推理和语言理解能力铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2407.00146</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:14 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4 能帮助检测戒烟意图吗？自动数据注释方法的探索</title>
      <link>https://arxiv.org/abs/2407.00167</link>
      <description><![CDATA[arXiv:2407.00167v1 公告类型：新 
摘要：近年来，美国电子烟或电子烟使用的普及度显著上升，导致电子烟和电子烟使用相关肺损伤 (EVALI) 病例显著增加，在 2019 年 EVALI 爆发期间导致住院和死亡，凸显了了解电子烟行为和制定有效戒烟策略的紧迫性。由于社交媒体平台无处不在，全球超过 47 亿用户使用它们进行连接、通信、新闻和娱乐，其中很大一部分讨论与健康有关，从而确立了社交媒体数据作为公共卫生研究宝贵的有机数据资源的地位。在本研究中，我们从 Reddit 上的一个电子烟子社区中提取了一个样本数据集，以分析用户的戒烟意图。本研究利用 OpenAI 最新的大型语言模型 GPT-4 进行句子级戒烟意图检测，将该模型的结果与外行和临床专家的注释进行了比较。使用不同的提示策略（例如零次提示、一次提示、几次提示和思路链提示），我们开发了 8 个具有不同详细程度的提示来向 GPT-4 解释任务，并评估了这些策略之间的性能。这些初步发现强调了 GPT-4 在社交媒体数据分析中的潜力，尤其是在识别可能逃避人类检测的用户细微意图方面。]]></description>
      <guid>https://arxiv.org/abs/2407.00167</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:14 GMT</pubDate>
    </item>
    <item>
      <title>MetaKP：按需生成关键词</title>
      <link>https://arxiv.org/abs/2407.00191</link>
      <description><![CDATA[arXiv:2407.00191v1 公告类型：新
摘要：传统的关键词预测方法每篇文档只预测一组关键词，无法满足用户和下游应用程序的不同需求。为了弥补这一差距，我们引入了按需关键词生成，这是一种新范式，需要符合特定高级目标或意图的关键词。对于这项任务，我们提出了 MetaKP，这是一个大规模基准，包含四个数据集、7500 份文档和 3760 个目标，涉及新闻和生物医学领域，并带有人工注释的关键词。利用 MetaKP，我们设计了监督和无监督方法，包括多任务微调方法和具有大型语言模型的自洽提示方法。结果突出了监督微调的挑战，其性能对分布变化不具有鲁棒性。相比之下，提出的自洽性提示方法极大地提高了大型语言模型的性能，使 GPT-4o 达到了 0.548 SemF1，超过了完全微调的 BART 基础模型的性能。最后，我们展示了我们的方法作为通用 NLP 基础设施的潜力，并以它在社交媒体流行病事件检测中的应用为例。]]></description>
      <guid>https://arxiv.org/abs/2407.00191</guid>
      <pubDate>Wed, 03 Jul 2024 03:15:14 GMT</pubDate>
    </item>
    </channel>
</rss>