<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 03 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>评估 ChatGPT 在门诊分诊指导中的应用：一项比较研究</title>
      <link>https://arxiv.org/abs/2405.00728</link>
      <description><![CDATA[arXiv:2405.00728v1 公告类型：新
摘要：人工智能（AI）在医疗保健领域的整合为提高运营效率和健康结果带来了变革潜力。 ChatGPT 等大型语言模型 (LLM) 已显示出其支持医疗决策的能力。将法学硕士嵌入医疗系统正在成为医疗保健发展的一个有前景的趋势。 ChatGPT 解决急诊科分诊问题的潜力已经得到检验，但很少有研究探讨其在门诊部的应用。本研究的重点是简化工作流程和提高门诊分诊效率，特别旨在评估 ChatGPT 在门诊指导中提供的响应的一致性，包括版本内响应分析和版本间比较。对于版本内，结果表明 ChatGPT-4.0 的内部响应一致性显着高于 ChatGPT-3.5 (p=0.03)，并且在其最高推荐中均具有中等一致性（4.0 为 71.2%，3.5 为 59.6%） 。然而，版本间一致性相对较低（平均一致性得分=1.43/3，中位数=1），表明两个版本之间很少有推荐匹配。此外，只有 50% 的热门推荐在比较中完全匹配。有趣的是，ChatGPT-3.5 的响应比 ChatGPT-4.0 的响应更有可能完整（p=0.02），这表明两个版本之间的信息处理和响应生成可能存在差异。这些发现提供了对人工智能辅助门诊手术的见解，同时也有助于探索法学硕士在医疗保健利用方面的潜力和局限性。未来的研究可能会侧重于基于人体工程学和人为因素原则，仔细优化法学硕士和人工智能在医疗保健系统中的集成，精确地满足有效门诊分诊的具体需求。]]></description>
      <guid>https://arxiv.org/abs/2405.00728</guid>
      <pubDate>Fri, 03 May 2024 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>LoRA Land：310 个可与 GPT-4 竞争的微调法学硕士，技术报告</title>
      <link>https://arxiv.org/abs/2405.00732</link>
      <description><![CDATA[arXiv:2405.00732v1 公告类型：新
摘要：低秩适应（LoRA）已成为大型语言模型（LLM）参数高效微调（PEFT）最广泛采用的方法之一。 LoRA 减少了可训练参数的数量和内存使用量，同时实现了与完全微调相当的性能。我们的目标是评估在现实应用中使用 LoRA 进行微调的法学硕士培训和服务的可行性。首先，我们测量了在 10 个基本模型和 31 个任务（总共 310 个模型）中使用量化低阶适配器进行微调的 LLM 的质量。我们发现 4 位 LoRA 微调模型平均比基础模型高 34 个点，比 GPT-4 平均高 10 个点。其次，我们研究了最有效的微调基础模型，并评估了任务复杂性启发法在预测微调结果方面的相关性和预测能力。最后，我们评估了 LoRAX 的延迟和并发能力，LoRAX 是一款开源多 LoRA 推理服务器，可使用共享基础模型权重和动态适配器加载，促进在单个 GPU 上部署多个 LoRA 微调模型。 LoRAX 为 LoRA Land 提供支持，LoRA Land 是一个 Web 应用程序，在具有 80GB 内存的单个 NVIDIA A100 GPU 上托管 25 个经过 LoRA 微调的 Mistral-7B LLM。 LoRA Land 强调采用多个专业法学硕士比单一通用法学硕士的质量和成本效益。]]></description>
      <guid>https://arxiv.org/abs/2405.00732</guid>
      <pubDate>Fri, 03 May 2024 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>“有任何问题都可以问我”：康卡斯特如何利用法学硕士实时协助代理商</title>
      <link>https://arxiv.org/abs/2405.00801</link>
      <description><![CDATA[arXiv:2405.00801v1 公告类型：新
摘要：客户服务是企业与客户互动的方式。它可以极大地提高客户的整体满意度。然而，高质量的服务可能会变得昂贵，从而激励人们尽可能提高成本效益，并促使大多数公司使用人工智能助理或“聊天机器人”。另一方面，人与人之间的互动仍然是客户所期望的，尤其是在涉及纠纷等复杂场景以及账单支付等敏感话题时。
  这提高了客户服务代理的门槛。他们需要准确理解客户的问题或疑虑，确定可接受但可行的解决方案（并且在公司政策范围内），同时同时处理多个对话。
  在这项工作中，我们引入了“Ask Me Anything”（AMA）作为面向代理的客户服务界面的附加功能。 AMA 允许客服人员在处理客户对话时按需向大型语言模型 (LLM) 提问 - LLM 可以实时提供准确的响应，从而减少客服人员所需的上下文切换量。在我们的内部实验中，我们发现与传统搜索体验相比，使用 AMA 的代理在每次包含搜索的对话中花费的时间大约减少了 10%，这意味着每年可以节省数百万美元。使用 AMA 功能的客服人员在近 80% 的时间内提供了积极反馈，证明了其作为人工智能辅助客户服务功能的实用性。]]></description>
      <guid>https://arxiv.org/abs/2405.00801</guid>
      <pubDate>Fri, 03 May 2024 06:18:17 GMT</pubDate>
    </item>
    <item>
      <title>不能说不能吗？大型语言模型中暗黑行话的测量和推理</title>
      <link>https://arxiv.org/abs/2405.00718</link>
      <description><![CDATA[arXiv:2405.00718v1 公告类型：新
摘要：确保大型语言模型 (LLM) 抵御恶意利用的弹性至关重要，最近的重点是减轻攻击性响应。然而，对黑话或黑暗行话的理解仍有待探索。本文介绍了特定领域的 Cant 数据集和 CantCounter 评估框架，采用微调、协同调整、数据扩散和数据分析阶段。实验表明，包括 ChatGPT 在内的法学硕士很容易受到无法绕过过滤器的影响，其识别准确度会受到问题类型、设置和提示线索的影响。更新后的模型对盲道查询的接受率更高。此外，法学硕士的反应在不同领域也有所不同，例如，不愿意参与种族主义和 LGBT 话题。这些发现强调了法学硕士对黑话的理解，并反映了培训数据特征和供应商对敏感主题的方法。此外，我们还评估法学硕士展示推理能力的能力。您可以通过 https://github.com/cistineup/CantCounter 访问我们的数据集和代码。]]></description>
      <guid>https://arxiv.org/abs/2405.00718</guid>
      <pubDate>Fri, 03 May 2024 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>用于生成和评估反事实的法学硕士：一项综合研究</title>
      <link>https://arxiv.org/abs/2405.00722</link>
      <description><![CDATA[arXiv:2405.00722v1 公告类型：新
摘要：随着 NLP 模型变得越来越复杂，理解它们的决策变得更加重要。反事实（CF），即输入的最小变化会翻转模型的预测，提供了一种解释这些模型的方法。虽然大型语言模型 (LLM) 在 NLP 任务中表现出了卓越的性能，但它们在生成高质量 CF 方面的功效仍然不确定。这项工作通过研究法学硕士为两个 NLU 任务生成 CF 的效果如何，填补了这一空白。我们对几种常见的法学硕士进行了全面比较，并评估了它们的 CF，评估了内在指标以及这些 CF 对数据增强的影响。此外，我们分析了人类和法学硕士生成的 CF 之间的差异，为未来的研究方向提供了见解。我们的结果表明，法学硕士可以生成流畅的 CF，但很难将引起的变化保持在最低限度。生成用于情感分析 (SA) 的 CF 比 NLI 更具挑战性，其中法学硕士在生成翻转原始标签的 CF 方面表现出弱点。这也反映在数据增强性能上，我们观察到人类 CF 和法学硕士 CF 的增强之间存在很大差距。此外，我们评估了法学硕士在错误标签的数据设置中评估 CF 的能力，并表明他们强烈倾向于同意所提供的标签。 GPT4 对于这种偏差更加稳健，并且其分数与自动指标密切相关。我们的研究结果揭示了一些局限性，并指出了未来潜在的工作方向。]]></description>
      <guid>https://arxiv.org/abs/2405.00722</guid>
      <pubDate>Fri, 03 May 2024 06:18:16 GMT</pubDate>
    </item>
    <item>
      <title>医疗保健中的大型语言模型：综合基准</title>
      <link>https://arxiv.org/abs/2405.00716</link>
      <description><![CDATA[arXiv:2405.00716v1 公告类型：新
摘要：采用大语言模型（LLM）来帮助临床医生引起了人们的广泛关注。现有作品主要采用带有答案选项的封闭式问答任务进行评估。然而，在真实的临床环境中，许多临床决策（例如治疗建议）涉及回答没有预设选项的开放式问题。同时，现有研究主要使用准确性来评估模型性能。在本文中，我们对医疗保健领域的不同法学硕士进行了全面的基准测试，以清楚地了解他们的优势和劣势。我们的基准测试包含涵盖医学语言生成、理解和推理的七个任务和十三个数据集。我们在零样本和少样本（即 1、3、5 样本）学习设置下对医疗保健领域现有的 16 个法学硕士进行了详细评估。我们报告了五个指标（即匹配性、忠实性、全面性、普遍性和稳健性）的结果，这对于获得临床用户的信任至关重要。我们进一步邀请医学专家进行人体评估。]]></description>
      <guid>https://arxiv.org/abs/2405.00716</guid>
      <pubDate>Fri, 03 May 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>探索资源高度稀缺的印度语言的新闻摘要和丰富化：Mizo 案例研究</title>
      <link>https://arxiv.org/abs/2405.00717</link>
      <description><![CDATA[arXiv:2405.00717v1 公告类型：新
摘要：用母语获取足够的信息对于满足用户的信息需求至关重要。虽然资源丰富的语言拥有丰富的在线资源，但资源非常匮乏的语言的情况并不理想。此外，对重大国内和国际事件的报道不足仍然令人担忧，尤其是在资源稀缺的语言中，如 \textbf{Mizo}。在本文中，我们进行了一项研究，以调查一种旨在为米佐新闻文章生成整体摘要的简单方法的有效性，该方法利用英语新闻来补充和增强与相应新闻事件相关的信息。此外，我们提供 500 篇米佐新闻文章和相应的丰富整体摘要。人工评估证实，我们的方法显着增强了米佐新闻文章的信息覆盖范围。米佐数据集和代码可以在 \url{https://github.com/barvin04/mizo_enrichment 访问]]></description>
      <guid>https://arxiv.org/abs/2405.00717</guid>
      <pubDate>Fri, 03 May 2024 06:18:15 GMT</pubDate>
    </item>
    <item>
      <title>虚假人工智能生成内容 (FAIGC)：理论、检测方法和机会的调查</title>
      <link>https://arxiv.org/abs/2405.00711</link>
      <description><![CDATA[arXiv:2405.00711v1 公告类型：新
摘要：近年来，以大语言模型（LLM）和扩散模型（DM）为代表的生成人工智能模型彻底改变了内容生产方式。这些人工智能生成的内容（AIGC）已深深嵌入日常生活和工作的各个方面，涵盖文本、图像、视频和音频。人工智能生成内容的真实性正在逐步增强，接近人类水平的创作标准。然而，这些技术也导致了虚假人工智能生成内容（FAIGC）的出现，给区分真实信息带来了新的挑战。认识到 AIGC 技术就像一把双刃剑至关重要。其强大的生成能力虽然有益，但也给 FAIGC 的创建和传播带来了风险。在本次调查中，我们提出了一种新的分类法，对当今 FAIGC 方法的空间进行了更全面的细分。接下来，我们探讨 FAIGC 的模式和生成技术，分为人工智能生成的虚假信息和人工智能生成的错误信息。然后我们从不同的角度介绍FAIGC检测方法，包括欺骗性FAIGC检测、Deepfake检测和基于幻觉的FAIGC检测。最后，我们讨论了突出的挑战和未来研究的有前景的领域。]]></description>
      <guid>https://arxiv.org/abs/2405.00711</guid>
      <pubDate>Fri, 03 May 2024 06:18:14 GMT</pubDate>
    </item>
    <item>
      <title>致力于采用开源大型语言模型来生成专家级临床记录</title>
      <link>https://arxiv.org/abs/2405.00715</link>
      <description><![CDATA[arXiv:2405.00715v1 公告类型：新
摘要：大型语言模型（LLM）在处理临床文本摘要任务方面表现出了良好的能力。在这项研究中，我们证明了小型开源法学硕士可以经过有效培训，从门诊医患对话中生成高质量的临床记录。我们通过 LLaMA-2 130 亿参数模型的全面的特定领域和特定任务的适应过程来实现这一目标。这个过程包括持续的预训练、监督微调以及来自人工智能和人类反馈的强化学习。我们引入了一种称为 DistillDirect 的增强方法，用于以 Gemini Pro 作为教师模型来执行策略强化学习。我们生成的模型 LLaMA-Clinic 能够生成质量与医生撰写的临床记录相当的临床记录。在一项盲法医师读者研究中，大多数 (90.4%) 的个人评估将 LLaMA-Clinic 生成的笔记在所有三个标准上评为“可接受”或更高：现实世界的准备情况、完整性和准确性。值得注意的是，在更具挑战性的“评估和计划”部分，与医生撰写的笔记 (4.1/5) 相比，LLaMA-Clinic 在现实世界准备度方面得分更高 (4.2/5)。此外，我们还发现了公共临床记录数据集（例如 ACI-BENCH）中的警告。我们强调未来临床记录生成任务的关键考虑因素，强调预先定义最佳实践记录格式的重要性。总体而言，我们的研究证明了培训小型开源法学硕士以协助临床记录、利用医疗机构对患者记录和领域专业知识的访问的潜力和可行性。我们公开了新创建的综合临床对话记录数据集和医生反馈数据集，以促进该领域的未来研究。]]></description>
      <guid>https://arxiv.org/abs/2405.00715</guid>
      <pubDate>Fri, 03 May 2024 06:18:14 GMT</pubDate>
    </item>
    <item>
      <title>使用有意义的反事实对法学硕士进行交互式分析</title>
      <link>https://arxiv.org/abs/2405.00708</link>
      <description><![CDATA[arXiv:2405.00708v1 公告类型：新
摘要：反事实示例对于探索机器学习模型的决策边界和确定特征归因很有用。我们如何应用基于反事实的方法来分析和解释 LLM？我们确定了以下关键挑战。首先，生成的文本反事实应该对用户有意义且可读，从而可以在心理上进行比较以得出结论。其次，为了使解决方案可扩展到长文本，用户应该配备工具来从各种粒度级别的扰动中创建反事实批次并交互式分析结果。在本文中，我们解决了上述挑战并贡献了 1) 一种通过删除和替换不同粒度的文本段来生成完整且有意义的文本反事实批次的新算法，以及 2) LLM Analyzer，一种交互式可视化工具，通过交互式检查和聚合有意义的反事实来帮助用户理解 LLM 的行为。我们使用来自医疗、法律、金融、教育和新闻数据集的 1,000 个样本，通过其生成的反事实的语法正确性来评估所提出的算法。在我们的实验中，97.2% 的反事实在语法上是正确的。通过用例、用户研究和专家反馈，我们展示了所提出的交互式可视化工具的实用性和可用性。]]></description>
      <guid>https://arxiv.org/abs/2405.00708</guid>
      <pubDate>Fri, 03 May 2024 06:18:13 GMT</pubDate>
    </item>
    <item>
      <title>评估遥感平台中的工具增强代理</title>
      <link>https://arxiv.org/abs/2405.00709</link>
      <description><![CDATA[arXiv:2405.00709v1 公告类型：新
摘要：工具增强的大型语言模型（LLM）在遥感（RS）应用中表现出了令人印象深刻的能力。然而，现有的基准测试假设问答输入模板基于预定义的图像文本数据对。这些独立的指令忽略了现实的基于用户的任务的复杂性。考虑一个地理空间分析师：他们放大地图区域，绘制一个用于收集卫星图像的区域，然后简洁地询问“检测此处的所有物体”。如果“这里”没有明确硬编码在图像文本模板中，而是由系统状态（例如实时地图定位）暗示，那么它在哪里？为了弥补这一差距，我们推出了 GeoLLM-QA，这是一个基准测试，旨在捕获真实 UI 平台上的长序列口头、视觉和基于点击的操作。通过对 1,000 项不同任务中最先进的法学硕士进行深入评估，我们为 RS 应用程序提供更强大的代理的见解。]]></description>
      <guid>https://arxiv.org/abs/2405.00709</guid>
      <pubDate>Fri, 03 May 2024 06:18:13 GMT</pubDate>
    </item>
    <item>
      <title>格鲁吉亚语同音词意义消歧</title>
      <link>https://arxiv.org/abs/2405.00710</link>
      <description><![CDATA[arXiv:2405.00710v1 公告类型：新
摘要：本研究提出了一种格鲁吉亚语词义消歧（WSD）任务的新方法，该方法基于对格鲁吉亚通用爬行语料库过滤形成的数据集上预训练的大型语言模型（LLM）进行监督微调。 。该数据集用于训练具有多种含义的单词的分类器。此外，我们还展示了使用 LSTM 进行 WSD 的实验结果。准确消除同音异义词歧义在自然语言处理中至关重要。格鲁吉亚语是一种属于卡特维利语系的粘着语言，在这方面提出了独特的挑战。本文的目的是强调格鲁吉亚语同音异义消歧的具体问题，并提出我们解决这些问题的方法。本文讨论的技术使用包含 7500 多个句子的手工分类数据集来预测同音异义词的词汇含义，准确率达到 95%。]]></description>
      <guid>https://arxiv.org/abs/2405.00710</guid>
      <pubDate>Fri, 03 May 2024 06:18:13 GMT</pubDate>
    </item>
    <item>
      <title>SHED：基于 Shapley 的自动数据集细化，用于指令微调</title>
      <link>https://arxiv.org/abs/2405.00705</link>
      <description><![CDATA[arXiv:2405.00705v1 公告类型：新 
摘要：预先训练的大型语言模型（LLM）可以适应许多下游任务，并通过微调进行定制以符合人类偏好。最近的研究发现，LLM 仅需少量高质量数据即可实现理想的性能，这表明这些大量数据集中的大量数据是多余的甚至是有害的。从海量数据集中识别高质量数据以整理小而有效的数据集已成为一项关键挑战。在本文中，我们介绍了 SHED，这是一种基于 Shapley 值的自动数据集细化框架，用于指令微调。SHED 消除了人工干预或使用商业 LLM 的需要。此外，通过 SHED 整理的数据集表现出可转移性，表明它们可以在不同的 LLM 之间重复使用并具有始终如一的高性能。我们进行了广泛的实验来评估 SHED 整理的数据集。结果表明，SHED 在各种任务和 LLM 中均优于最先进的方法；值得注意的是，SHED 选择的仅包含原始数据 10% 的数据集却实现了与完整数据集相当甚至超越其性能。]]></description>
      <guid>https://arxiv.org/abs/2405.00705</guid>
      <pubDate>Fri, 03 May 2024 06:18:12 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能撰写的科学文章被认为智能程度较低，但比人类撰写的科学文章更可信、更值得信赖</title>
      <link>https://arxiv.org/abs/2405.00706</link>
      <description><![CDATA[arXiv:2405.00706v1 公告类型：新
摘要：本文评估了使用生成式人工智能简化科学传播和增强公众对科学的信任的有效性。通过比较 PNAS 期刊文章的简明摘要与人工智能生成的摘要，这项工作评估了此类摘要和公众看法的语言简单性。研究 1a 分析了 PNAS 摘要（科学摘要）和重要性陈述（非专业摘要）的简单性特征，观察到非专业摘要在语言上确实更简单，但效应大小差异很小。研究 1b 使用 GPT-4 根据论文摘要创建重要性陈述，无需微调，平均效果大小就增加了一倍多。最后，研究 2 通过实验证明，与写得复杂的人类 PNAS 摘要相比，写得简单的 GPT 摘要更能促进公众对科学家的更有利的看法（他们的可信度、可信度）。人工智能有潜力通过简单的语言启发式吸引科学界和公众，倡导将其融入科学传播，打造一个更加知情的社会。]]></description>
      <guid>https://arxiv.org/abs/2405.00706</guid>
      <pubDate>Fri, 03 May 2024 06:18:12 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 真正威力的调查</title>
      <link>https://arxiv.org/abs/2405.00704</link>
      <description><![CDATA[arXiv:2405.00704v1 公告类型：新
摘要：ChatGPT 改变了 AI 社区，一个活跃的研究方向是 ChatGPT 的性能评估。评估的一个关键挑战是 ChatGPT 仍然是闭源的，ChatGPT 可能已使用传统基准数据集作为训练数据。在本文中，（i）我们调查了最近的研究，这些研究揭示了 ChatGPT 在七类 NLP 任务中的真实性能水平，（ii）回顾了 ChatGPT 的社会影响和安全问题，以及（iii）强调了其面临的主要挑战和机遇评估。我们希望我们的调查能够揭示其黑箱方式，以便研究人员不会被其表面生成所误导。]]></description>
      <guid>https://arxiv.org/abs/2405.00704</guid>
      <pubDate>Fri, 03 May 2024 06:18:11 GMT</pubDate>
    </item>
    </channel>
</rss>