<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Fri, 14 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>精炼阳性和有毒样品，以最少的人干预措施对LLM的双重安全自我调整</title>
      <link>https://arxiv.org/abs/2502.08657</link>
      <description><![CDATA[ARXIV：2502.08657V1公告类型：新 
摘要：最近的AI代理，例如Chatgpt和Llama，主要依靠指令调整和强化学习，以人类意图校准大语言模型（LLMS）的输出，以确保输出无害且有用。现有方法在很大程度上取决于高质量阳性样本的手动注释，同时与噪声标签和优先响应数据和分配响应数据之间的最小区分之类的问题竞争。但是，通常会滤除具有明确安全区分的有毒样品，从而消除了有助于LLMS安全对齐的有价值的负面参考。作为回应，我们提出了PT-Align，这是一种新型的安全自我对准方法，可以通过自动提炼正阳性和有毒样品并进行细粒的双重指导调整来最大程度地减少人类的监督。积极样本是无害的反应，而有毒样品故意包含非常有害的内容，作为新的监督信号。具体而言，我们仅通过探索少于50个人的注释来利用LLM本身来迭代生成和完善培训实例。然后，我们采取两种损失，即最大似然估计（MLE）和细粒度的不可能训练（UT），共同学会增强LLM的安全性。 MLE损失鼓励LLM根据阳性样本最大化无害含量的产生。相反，细颗粒的UT损失指导LLM最大程度地减少基于令牌级别的负样本的有害单词的输出产生有用和可靠的内容的可能性。在9个流行的开源LLMS上进行的实验证明了我们的PT-Align在安全对准方面的有效性，同时保持了可比的帮助和实用性水平。]]></description>
      <guid>https://arxiv.org/abs/2502.08657</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语义角色标签：系统调查</title>
      <link>https://arxiv.org/abs/2502.08660</link>
      <description><![CDATA[ARXIV：2502.08660V1公告类型：新 
摘要：语义角色标签（SRL）是一种中心自然语言处理（NLP）任务，旨在了解文本中的语义角色，从而促进了广泛的下游应用程序。尽管SRL获得了广泛而持久的研究，但目前缺乏全面的调查，可以彻底组织和综合该领域。本文旨在回顾过去二十年来SRL社区的整个研究轨迹。我们首先提供SRL的完整定义。为了提供全面的分类法，我们将SRL方法论分为四个关键角度：模型架构，语法功能建模，应用程序方案和多模式扩展。此外，我们讨论了SRL基准，评估指标和范式建模方法，同时还探索了各个领域的实际应用。最后，我们分析了SRL的未来研究方向，以解决SRL在大语言模型（LLMS）（LLMS）及其对更广泛的NLP景观的潜在影响的不断发展的作用。我们维护一个公共存储库，并始终在以下网址更新相关资源]]></description>
      <guid>https://arxiv.org/abs/2502.08660</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>几个shot_llm_synthetic_data_with_distribution_matching</title>
      <link>https://arxiv.org/abs/2502.08661</link>
      <description><![CDATA[ARXIV：2502.08661V1公告类型：新 
摘要：随着大型语言模型（LLMS）的提高，他们执行秘密学习和几乎没有语言的语言的能力得到了显着提高。这刺激了使用LLMS生成高质量的合成数据，以增强较小模型（如在线检索器或弱LLMS）的性能。但是，LLM生成的合成数据通常与关键语言属性的真实数据（例如样式，音调，内容比例等）有所不同。结果，将这些综合数据与实际数据直接混合可能会扭曲原始数据分布，从而可能阻碍性能改善。为了解决这个问题，我们介绍了Synalign：基于关键属性分布匹配的合成数据生成和过滤框架。在生成之前，Synalign采用高斯流程模型替代的不确定性跟踪器，以迭代选择与所选数据的数据簇作为新数据合成的演示，从而促进了真实数据的有效勘探多样性。然后，采用了一种潜在属性推理方法：LLM总结了演示的语言属性，然后根据它们合成新数据。这种方法促进了具有实际数据中出现的语言属性的多种数据的综合数据。生成后，最大平均差异被用作学习每个合成数据的采样权重的目标函数，从而确保分布与真实数据匹配。我们对多个文本预测任务的实验显示了重大的性能改进。我们还对在线检索器进行了在线A/B测试，以证明Synalign的有效性。]]></description>
      <guid>https://arxiv.org/abs/2502.08661</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>转子：对订单不变输入的更可靠的响应</title>
      <link>https://arxiv.org/abs/2502.08662</link>
      <description><![CDATA[ARXIV：2502.08662V1公告类型：新 
摘要：列表输入的语言模型（LMS）的位置偏差是一个众所周知且重要的问题（例如，中间失落）。虽然已经提出了零射击订单不变的LMS来解决此问题，但它们在实际列表问题上的成功受到了限制。在这项工作中，作为第一个贡献，我们确定并克服了两个限制，使零射击不变的LMS更加实用：（1）培训和推理分布不匹配，而不是修改位置ID分配以执行不变性，以及（2）未能适应在实际列表问题中，有序不变和敏感输入的混合物。为了克服，我们提出了（1）转子，用于真正的订单不变的输入的零射击不变的LM，具有最小的位置ID修改，以及（2）选择性路由，一种自适应框架，一种处理订单不变和订单敏感性输入的自适应框架在ListWise任务中。在中间（LITM）的丢失，知识图答录（KGQA）和MMLU基准测试中，我们表明具有选择性路由的转子可以有效地以零拍的方式处理实际列表输入任务。]]></description>
      <guid>https://arxiv.org/abs/2502.08662</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>幻觉检测：使用嵌入式距离分析的概率框架</title>
      <link>https://arxiv.org/abs/2502.08663</link>
      <description><![CDATA[ARXIV：2502.08663V1公告类型：新 
摘要：幻觉是影响LLM的主要问题之一，阻碍了其在生产系统中的广泛采用。尽管目前用于检测幻觉的研究解决方案主要基于启发式方法，但在本文中，我们引入了一种数学上合理的方法来理解幻觉，并利用它来构建一种检测幻觉的工具。据我们所知，我们是第一个表明幻觉内容在正确内容方面存在结构性差异。为了证明这一结果，我们求助于嵌入空间中的Minkowski距离。我们的发现表明，嵌入距离分布的统计学显着差异，这些分布也是免费的 - 无论使用的距离规范和关键字，问题或响应的数量如何，它们都会定性地保持。我们利用这些结构差异来开发一种工具来检测幻觉响应，对于系统参数的特定配置，精度达到66 \％ - 与现场最佳结果相当。总之，建议的方法是有希望的和新颖的，可能为在域中进一步研究铺平了道路，也沿着我们未来的工作中强调的方向铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2502.08663</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>幻觉，单脚手段和错误校准：实证研究</title>
      <link>https://arxiv.org/abs/2502.08666</link>
      <description><![CDATA[ARXIV：2502.08666V1公告类型：新 
摘要：[Kalai和Vempala 2024]的最新理论工作证明，LLMS中特定的幻觉率必须降低训练数据的单声道速率（与经典的良好质量缺失的质量估计器有关）减去模型误解。通过使用N-Gram模型进行系统的实验和使用LLM的文化学习，我们通过检查不同的基础数据分布如何影响单声道速率以及模型幻觉的趋势，从经验研究和验证该理论。然后，我们通过控制训练样品的上升量，同时保持单稳定速率恒定，从而改变模型错误校准，从而使我们能够隔离误解对幻觉的减少效果。这些发现表明，训练数据中事实频率的分布和校准 - 呼吸折衷是概率产生的固有的。我们的结果还表明，可能需要重新考虑目前的培训数据中积极重复数据删除的实践，因为选择性重复可以用作减少幻觉的原则机制。]]></description>
      <guid>https://arxiv.org/abs/2502.08666</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用VAE和并行数据集对文本嵌入的样式提取</title>
      <link>https://arxiv.org/abs/2502.08668</link>
      <description><![CDATA[ARXIV：2502.08668V1公告类型：新 
摘要：这项研究研究了使用变分自动编码器（VAE）模型的各种圣经翻译之间的风格差异。通过将文本数据嵌入高维矢量中，该研究旨在检测和分析翻译之间的风格变化，并具体侧重于将美国标准版本（ASV）与其他翻译区分开。结果表明，每次翻译都表现出独特的风格分布，可以使用VAE模型有效地识别。这些发现表明，VAE模型精通捕获和区分文本样式，尽管它主要是为了区分单一样式而进行了优化。该研究强调了该模型在基于AI的文本生成和风格分析中更广泛应用的潜力，同时也认识到需要进一步改进以解决多维风格关系的复杂性。未来的研究可以将这种方法扩展到其他文本域，从而更深入地了解嵌入各种文本数据中的风格特征。]]></description>
      <guid>https://arxiv.org/abs/2502.08668</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估文本数据质量对功能表示和机器学习模型的影响</title>
      <link>https://arxiv.org/abs/2502.08669</link>
      <description><![CDATA[ARXIV：2502.08669V1公告类型：新 
摘要：背景：在受控设置中收集的数据通常会导致高质量数据集。但是，在实际应用程序中，数据收集的质量通常会受到损害。众所周知，数据集的质量显着影响机器学习模型的性能。
  方法：开发了基本错误率指标，以评估令牌级别的文本数据集质量。混音大语言模型（LLM）用于量化和纠正低质量数据集中的错误。该研究分析了两个医疗保健数据集：高质量的模仿III公立医院数据集和澳大利亚老年护理院的较低质量的私人数据集。系统地以不同的速率将误差系统地引入模拟物中，而使用LLM则提高了ACH数据集质量。
  结果：对于来自模拟物和ACH数据集的35,774和6,336例采样的患者，我们使用Mixtral来引入ACH中的模拟和正确错误中的错误。混音在63％的进度票据中正确检测到了错误，其中17％包含由于医学术语而导致的单个令牌错误分类。 LLMS通过解决各种错误来提高进度注释质量的潜力。在不同的错误率下，特征表示性能耐受性能较低（&lt;10％），但在较高速率下大大下降。
  结论：研究表明，模型在错误率较低的数据集上的性能相对较好（&lt;10％），但随着错误率的增加，它们的性能大大下降（&gt; = 10％）。因此，在将数据集用于机器学习任务之前评估数据集的质量至关重要。对于具有较高错误率的数据集，实施纠正措施对于确保机器学习模型的可靠性和有效性至关重要。]]></description>
      <guid>https://arxiv.org/abs/2502.08669</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>数据增强以改善食品危害和产品检测中的大型语言模型</title>
      <link>https://arxiv.org/abs/2502.08687</link>
      <description><![CDATA[ARXIV：2502.08687V1公告类型：新 
摘要：这项研究的主要目的是证明使用Chatgpt-4O-Mini对食物危害和产品分析的数据扩展的影响。增强数据是使用Chatgpt-4O-Mini生成的，随后用于训练两个大型语言模型：Roberta-Base和Flan-T5-Base。在测试集上评估模型。结果表明，与仅使用提供的数据集相比，使用增强数据有助于提高关键指标的模型性能，包括召回，F1分数，精度和准确性。完整的代码，包括模型培训和增强数据集，可以在此存储库中找到：https：//github.com/areeg94fahad/food-hazard-hazard-prdouct-cls]]></description>
      <guid>https://arxiv.org/abs/2502.08687</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>音乐情绪的表达方式是否相同？</title>
      <link>https://arxiv.org/abs/2502.08744</link>
      <description><![CDATA[ARXIV：2502.08744V1公告类型：新 
摘要：音乐唤起了深刻的情感，但是跨语言的情感描述符的普遍性仍在争论。关于音乐情感的跨文化研究的一个关键挑战是分类法的偏差刺激选择和手动策划，主要依靠西方音乐和语言。为了解决这个问题，我们提出了一个平衡的实验设计，并在巴西，美国和韩国进行了九个在线实验，涉及n = 672名参与者。首先，我们从这些国家采样了一组平衡的流行音乐。然后，我们使用开放式标记管道，收集情感术语以创建特定文化的分类法。最后，使用这些自下而上的分类法，参与者对每首歌的情绪进行评分。这使我们能够绘制文化内部和跨文化的情感相似性。结果表明，高唤醒，高价情绪的一致性，但其他人的变化更大。值得注意的是，机器翻译通常不足以捕获特定于音乐的含义。这些发现共同强调了对域敏感，开放式，自下而上的情感启发方法的需求，以减少情绪研究中的文化偏见。]]></description>
      <guid>https://arxiv.org/abs/2502.08744</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IHEVAL：评估语言模型以遵循指令层次结构</title>
      <link>https://arxiv.org/abs/2502.08745</link>
      <description><![CDATA[ARXIV：2502.08745V1公告类型：新 
摘要：指令层次结构从系统消息到用户消息，对话历史记录和工具输出建立优先顺序，对于确保语言模型（LMS）中的一致和安全行为至关重要。尽管其重要性，但该主题受到了有限的关注，并且缺乏评估模型遵循指令层次结构的能力的全面基准。我们通过引入Iheval（一种新型的基准，包括九个任务中的3,538个例子）来弥合这一差距，涵盖了不同优先级或冲突的指令的情况。我们对流行LMS的评估强调了他们为认识指导重点的努力。与原始的指导跟随性能相比，所有评估的模型在面对冲突的指示时的性能下降。此外，最具竞争力的开源模型在解决此类冲突方面仅能达到48％的准确性。我们的结果强调了LMS未来开发中有针对性优化的需求。]]></description>
      <guid>https://arxiv.org/abs/2502.08745</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自学：您的语言模型秘密地知道相关证据在哪里</title>
      <link>https://arxiv.org/abs/2502.08767</link>
      <description><![CDATA[ARXIV：2502.08767V1公告类型：新 
摘要：在上下文中（通过检索或用户提供的）提供语言模型（LMS）可以显着提高其提供实际正确的接地响应的能力。但是，最近的研究发现，LMS经常难以完全理解和利用背景下的关键证据，尤其是在包含噪声和无关的信息时，这是现实世界中常见的问题。为了解决这个问题，我们提出了自我选择，这是一种推理时间方法，可以通过自我引导的明确突出显示，以帮助LMS专注于关键上下文证据。通过使用更深层的注意力评分利用LMS的固有循证能力，我们的方法自动识别并强调输入环境中的关键证据，从而促进了更准确，实际上扎根的响应，而无需额外的培训或迭代提示。我们证明，自我选择为各个LM家族的多个基于证据的质量检查任务带来一致和显着改善，同时保持计算效率。我们的代码和文档可在https://github.com/zhiningliu1998/selfelicit上获得。]]></description>
      <guid>https://arxiv.org/abs/2502.08767</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>有效LLM推理的通用模型路由</title>
      <link>https://arxiv.org/abs/2502.08773</link>
      <description><![CDATA[ARXIV：2502.08773V1公告类型：新 
摘要：大语言模型在功能方面的重大进展伴随着推理成本的显着增加。模型路由是一种简单的技术，用于降低推理成本，其中一个维护候选LLM的库，并学会将每个提示路由到最小的可行LLM。现有作品着重于学习固定LLM的路由器。在本文中，我们考虑了动态路由的问题，在测试时可以使用新的，以前未观察到的LLM。我们为此问题提出了一种新的方法，该方法依赖于将每个LLM表示为特征向量，该方法是根据一组代表提示的预测得出的。基于此，我们详细介绍了两种有效的策略，分别依靠基于群集的路由和一个学习的群集图。我们证明，这些策略是理论上最佳路由规则的估计，并提供了多余的风险来量化其错误。一系列公共基准的实验表明，拟议策略在30多个看不见的LLMS中的路线方面有效。]]></description>
      <guid>https://arxiv.org/abs/2502.08773</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>零射击信念：LLM的困难问题</title>
      <link>https://arxiv.org/abs/2502.08777</link>
      <description><![CDATA[ARXIV：2502.08777V1公告类型：新 
摘要：我们提出了两种基于LLM的方法，用于对Factbank的零摄影和目标信念预测：一种统一的系统，可以单个通过以单个通行证标识事件，来源和信念标签，以及使用精细调整的混合方法Deberta Tagger进行活动检测。我们表明，多个开源，封闭式和基于推理的LLM在这项任务上挣扎。使用混合方法，我们在FactBank上实现了新的最新结果，并提供了详细的错误分析。然后，我们的方法对意大利信仰语料库进行了测试。]]></description>
      <guid>https://arxiv.org/abs/2502.08777</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>如果多代理辩论是答案，那是什么问题？</title>
      <link>https://arxiv.org/abs/2502.08788</link>
      <description><![CDATA[ARXIV：2502.08788V1公告类型：新 
摘要：多机构辩论（MAD）已成为一种有前途的方法，可以通过使多个代理参与推理期间的迭代讨论来提高大语模型（LLMS）的事实准确性和推理质量。尽管具有潜力，但我们认为当前的MAD研究遭受了评估实践的关键缺点，包括数据集有限的重叠和不一致的基线，引起了人们对概括性的重大关注。相应地，本文使用四个基础模型对九个基准的五种代表性MAD方法进行了系统评估。令人惊讶的是，我们的发现表明，即使消耗额外的推理时间计算，MAD方法也无法可靠地优于简单的单一基准基线，例如思考链和自耐心。从我们的分析中，我们发现模型异质性可以显着改善疯狂框架。我们提出了Heter-Mad，使单个LLM代理可以访问异质基础模型的输出，从而提高了当前的疯狂框架的性能。最后，我们概述了推进疯狂的潜在方向，旨在激发更广泛的对话并激发该领域的未来工作。]]></description>
      <guid>https://arxiv.org/abs/2502.08788</guid>
      <pubDate>Fri, 14 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>