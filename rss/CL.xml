<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 20 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>文章：通过情境学习提高注释者的可靠性</title>
      <link>https://arxiv.org/abs/2409.12218</link>
      <description><![CDATA[arXiv:2409.12218v1 公告类型：新
摘要：确保训练和评估数据中的注释者质量是 NLP 中机器学习的关键部分。情绪分析和攻击性语音检测等任务本质上是主观的，这为传统的质量评估方法带来了挑战，因为很难区分由于工作不力而导致的分歧和由于真诚的注释者之间的意见分歧而导致的分歧。为了在确保一致性的同时增加注释中的多样化视角，我们提出了 \texttt{ARTICLE}，这是一个上下文学习 (ICL) 框架，通过自洽性来估计注释质量。我们使用多个 LLM 在两个攻击性语音数据集上评估该框架，并将其性能与传统方法进行比较。我们的研究结果表明，\texttt{ARTICLE} 可用作识别可靠注释者的稳健方法，从而提高数据质量。]]></description>
      <guid>https://arxiv.org/abs/2409.12218</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MQA-KEAL：面向阿拉伯语的知识编辑下的多跳问答</title>
      <link>https://arxiv.org/abs/2409.12257</link>
      <description><![CDATA[arXiv:2409.12257v1 公告类型：新
摘要：大型语言模型 (LLM) 已在众多应用领域展现出强大的能力。一个关键挑战是让这些模型保持最新可用信息，这限制了这些模型在最终应用中的真正潜力。尽管已经有许多尝试进行 LLM 知识编辑 (KE)，即编辑 LLM 的先验知识并通过多跳问答 (MQA) 对其进行测试，但到目前为止，这些研究主要集中在英语上。为了弥补这一差距，我们在本文中提出：知识编辑下的阿拉伯语多跳问答 (MQA-KEAL)。MQA-KEAL 将知识编辑作为结构化知识单元存储在外部存储器中。为了解决多跳问题，它首先使用任务分解将问题分解为更小的子问题。之后，对于每个子问题，它会迭代查询外部内存和/或目标 LLM，以生成最终响应。此外，我们还贡献了 MQUAKE-AR（英语基准 MQUAKE 的阿拉伯语翻译），以及新的基准 MQA-AEVAL，用于对阿拉伯语 KE 下的 MQA 进行严格的性能评估。实验评估表明，MQA-KEAL 的表现远胜于基线模型。]]></description>
      <guid>https://arxiv.org/abs/2409.12257</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用前提条件和效果知识将大型语言模型转化为世界模型</title>
      <link>https://arxiv.org/abs/2409.12278</link>
      <description><![CDATA[arXiv:2409.12278v1 公告类型：新
摘要：世界模型是智能代理运行的基础，它封装了动作如何影响环境的动态。在这项工作中，我们探索了大型语言模型 (LLM) 作为世界模型运行的潜力。虽然 LLM 本质上不是为模拟现实世界动态而设计的，但我们表明它们可以被诱导执行两个关键的世界模型功能：根据给定的世界状态确定动作的适用性，并预测动作执行后产生的世界状态。这是通过微调两个独立的 LLM（一个用于先决条件预测，另一个用于效果预测）同时利用合成数据生成技术来实现的。通过人类参与者研究，我们验证了我们的模型生成的先决条件和效果知识与人类对世界动态的理解相一致。我们还分析了在我们的合成数据上训练的世界模型在多大程度上产生了一个推断的状态空间，该空间支持创建动作链，这是规划的必要属性。]]></description>
      <guid>https://arxiv.org/abs/2409.12278</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在视听模型中测量声音象征意义</title>
      <link>https://arxiv.org/abs/2409.12306</link>
      <description><![CDATA[arXiv:2409.12306v1 公告类型：新
摘要：视听预训练模型最近引起了广泛关注，并在各种视听任务中表现出色。本研究调查了预训练的视听模型是否表现出声音和视觉表征之间的非任意关联$\unicode{x2013}$，即声音象征$\unicode{x2013}$，这在人类中也有观察到。我们开发了一个包含合成图像和音频样本的专门数据集，并在零样本设置中使用非参数方法评估了这些模型。我们的研究结果揭示了模型的输出与既定的声音象征模式之间存在显着相关性，特别是在语音数据训练的模型中。这些结果表明，此类模型可以捕捉类似于人类语言处理的声音含义联系，从而为认知架构和机器学习策略提供见解。]]></description>
      <guid>https://arxiv.org/abs/2409.12306</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>小型语言模型是方程推理器</title>
      <link>https://arxiv.org/abs/2409.12393</link>
      <description><![CDATA[arXiv:2409.12393v1 公告类型：新
摘要：思维链 (CoT) 推理使大型语言模型 (LLM) 在各种 NLP 任务（包括算术问题解决）中取得了显著的表现。然而，这种成功并不适用于 T5 等小型语言模型 (sLM)，因为它们的容量有限，并且缺乏与大型模型相关的新兴能力。最近通过知识提炼增强 sLM 的工作取得了一些进展，但仍然面临着重大限制，特别是自然语言表达的多变性和大量的计算成本导致的高歧义性。在本文中，我们研究了 sLM 在算术推理任务上表现不佳的原因，并假设自然语言格式的多变性会给这些较小的模型带来高歧义性。基于这一假设，我们对仅方程式格式进行了实验，这是一种将先前以自然语言格式表达的算术推理统一为数学方程式的推理格式。实验结果表明，仅方程格式有效地提高了 sLM 的算术推理能力，尤其是在像 T5-Tiny 这样的非常小的模型中。]]></description>
      <guid>https://arxiv.org/abs/2409.12393</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>偏好对齐改进基于语言模型的 TTS</title>
      <link>https://arxiv.org/abs/2409.12403</link>
      <description><![CDATA[arXiv:2409.12403v1 公告类型：新
摘要：文本转语音 (TTS) 的最新进展表明，基于语言模型 (LM) 的系统比同类系统具有竞争力。可以通过偏好对齐算法实现进一步优化，该算法调整 LM 以与奖励模型的偏好保持一致，从而增强生成内容的可取性。本研究对偏好对齐算法（尤其是直接偏好优化 (DPO)）如何增强基于 LM 的 TTS 进行了全面的实证评估。借助 1.15B 参数的基于 LM 的 TTS 模型，我们证明偏好对齐可以持续提高可理解性、说话者相似性和代理主观评价分数，后两个指标在某些评估中甚至超过了人类语音。我们还表明偏好对齐适用于低资源场景，并可有效推广到域外应用。]]></description>
      <guid>https://arxiv.org/abs/2409.12403</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于相互信息的未对齐多模态语言序列的表征解缠</title>
      <link>https://arxiv.org/abs/2409.12408</link>
      <description><![CDATA[arXiv:2409.12408v1 公告类型：新
摘要：未对齐的多模态语言序列的关键挑战在于有效地整合来自各种模态的信息以获得精细的多模态联合表示。最近，解缠和融合方法通过明确学习模态无关和模态特定表示，然后将它们融合为多模态联合表示，取得了良好的效果。然而，这些方法通常独立学习每种模态的模态无关表示，并利用正交约束来减少模态无关和模态特定表示之间的线性相关性，而忽略了消除它们的非线性相关性。因此，获得的多模态联合表示通常存在信息冗余，导致模型过度拟合和泛化能力差。本文针对未对齐的多模态语言序列，提出了一种基于互信息的表征解缠 (MIRD) 方法，其中设计了一种新颖的解缠框架来联合学习单一模态无关表征。此外，采用互信息最小化约束来确保表征的卓越解缠，从而消除多模态联合表征中的信息冗余。此外，通过引入未标记数据，可以减轻由有限标记数据引起的估计互信息的挑战。同时，未标记数据也有助于表征多模态数据的底层结构，从而进一步防止过度拟合并提高模型的性能。在几个广泛使用的基准数据集上的实验结果验证了我们提出的方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.12408</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多轮 LLM 生成实现复杂任务的文本化代理式推理</title>
      <link>https://arxiv.org/abs/2409.12411</link>
      <description><![CDATA[arXiv:2409.12411v1 公告类型：新
摘要：思路链提示显著提升了大型语言模型的推理能力，但仍然面临三个问题：幻觉问题、可解释性受限和生成不可控。为了应对这些挑战，我们提出了基于 llm 的自主代理框架 AgentCOT，它可以通过多轮 LLM 生成以代理方式解决复杂问题。在每个步骤中，AgentCOT 选择一个动作并执行它以产生具有支持证据的中间结果。此外，我们将步骤的索引集成到推理过程中，以形成复杂推理逻辑的图形结构。我们引入了两种新策略来增强 AgentCOT 的性能。我们进行了广泛的实验来验证我们的方法在六个常见基准上的有效性。结果表明，我们的方法比当前的竞争方法带来了显着的改进。]]></description>
      <guid>https://arxiv.org/abs/2409.12411</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从零到强的泛化：无需金牌标签，以迭代方式激发大型语言模型的强大能力</title>
      <link>https://arxiv.org/abs/2409.12425</link>
      <description><![CDATA[arXiv:2409.12425v1 公告类型：新
摘要：大型语言模型 (LLM) 通过使用黄金标签进行监督微调或上下文学习，表现出色。然而，这种范式受到黄金标签可用性的限制，而在某些情况下，LLM 可能需要执行过于复杂的任务，而人类无法提供此类标签。为了应对这一挑战，本研究探讨了仅使用未标记数据是否可以引发强大的模型能力。我们提出了一种称为零到强泛化的新范式。我们迭代地提示 LLM 注释未标记数据并通过过滤保留高质量标签。令人惊讶的是，我们观察到这个迭代过程逐渐释放了 LLM 在下游任务上的潜力。我们在广泛的分类和推理任务上的实验证实了我们提出的框架的有效性。我们的分析表明，这种范式对于上下文学习和微调以及各种模型大小都有效。]]></description>
      <guid>https://arxiv.org/abs/2409.12425</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言最小对在大型语言模型中引发语言相似性</title>
      <link>https://arxiv.org/abs/2409.12435</link>
      <description><![CDATA[arXiv:2409.12435v1 公告类型：新
摘要：我们引入了一种新颖的分析方法，利用语言最小对来探究大型语言模型 (LLM) 的内部语言表示。通过测量最小对之间 LLM 激活差异的相似性，我们量化并深入了解 LLM 捕获的语言知识。我们的大规模实验涵盖了三种语言的 100 多个 LLM 和 150k 个最小对，从四个关键方面揭示了语言相似性的属性：LLM 之间的一致性、与理论分类的关系、对语义上下文的依赖性以及相关现象的跨语言对齐。我们的研究结果表明 1) 语言相似性受到训练数据暴露的显着影响，导致高资源语言的跨 LLM 一致性更高。2) 语言相似性与细粒度的理论语言类别高度一致，但与更广泛的语言类别的一致性较弱。 3) 语言相似性与语义相似性显示出较弱的相关性，表明其依赖于上下文。4) LLM 在理解相关语言现象方面表现出有限的跨语言一致性。这项研究展示了最小对作为 LLM 中语言神经表征的窗口的潜力，揭示了 LLM 与语言理论之间的关系。]]></description>
      <guid>https://arxiv.org/abs/2409.12435</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过基于图的合成数据增强大型语言模型的逻辑推理</title>
      <link>https://arxiv.org/abs/2409.12437</link>
      <description><![CDATA[arXiv:2409.12437v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 的训练和提示策略最近取得了进展，但这些模型仍然面临着涉及长推理链的复杂逻辑推理任务的挑战。在这项工作中，我们探索了使用基于图的合成推理数据作为训练信号来增强 LLM 推理能力的潜力和局限性。我们对两个已建立的自然语言推理任务——归纳推理和空间推理——进行了广泛的实验，表明使用基于图的合成推理数据进行监督微调 (SFT) 可以有效提高 LLM 的推理性能，而不会影响其在其他标准评估基准上的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.12437</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增量和数据高效的概念形成以支持掩蔽词预测</title>
      <link>https://arxiv.org/abs/2409.12440</link>
      <description><![CDATA[arXiv:2409.12440v1 公告类型：新
摘要：本文介绍了一种支持掩码词预测的高效语言模型学习新方法 Cobweb4L。该方法建立在 Cobweb 的基础上，Cobweb 是一个学习概率概念层次结构的增量系统。每个概念都存储了在标有该概念标签的实例中出现的单词的频率。该系统利用属性值表示将单词及其周围的上下文编码为实例。Cobweb4L 使用类别效用的信息论变体和一种利用多个概念生成预测的新性能机制。我们证明，通过这些扩展，它的性能明显优于以前仅使用单个节点生成预测的 Cobweb 性能机制。此外，我们证明 Cobweb4L 学习速度快，性能可与 Word2Vec 媲美甚至优于 Word2Vec。接下来，我们表明 Cobweb4L 和 Word2Vec 在训练数据较少的相同任务中优于 BERT。最后，我们讨论未来的工作，以使我们的结论更加稳健和包容。]]></description>
      <guid>https://arxiv.org/abs/2409.12440</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CodePlan：通过扩展代码形式规划释放大型语言模型的推理潜力</title>
      <link>https://arxiv.org/abs/2409.12452</link>
      <description><![CDATA[arXiv:2409.12452v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 在传统自然语言处理任务上取得了显著成功，但它们的规划能力仍然是解决复杂多步骤推理任务的关键瓶颈。现有方法主要依赖于提示或特定于任务的微调，通常存在较弱的鲁棒性和跨任务泛化问题。为了解决这一限制，我们引入了 CODEPLAN，这是一种可扩展的范例，它使 LLM 能够生成和遵循代码形式计划伪代码，这些伪代码概述了高级、结构化的推理过程。通过利用代码的结构化和多功能性，CODEPLAN 有效地捕获了复杂推理所固有的丰富语义和控制流。重要的是，CODEPLAN 允许从大量、广泛的文本语料库中自动提取代码形式计划，而无需精心策划的特定于任务的数据集。这使它能够有效地扩展并提高跨不同场景的推理能力。为了训练 CODEPLAN，我们构建了一个包含 200 万个示例的大规模数据集，将代码形式计划与现有语料库中的标准提示-响应对集成在一起。在训练和推理过程中，CODEPLAN 的计算开销都极小，与直接生成响应相比，其相对改进幅度达到 25.1%，这是在 13 个具有挑战性的多步骤推理基准测试中的平均水平，涵盖数学推理、符号推理、指令遵循、多跳问答和决策任务。进一步的分析表明，CODEPLAN 在更复杂的推理任务上的性能提升越来越大，并且得益于其泛化能力，数据效率显著提高。]]></description>
      <guid>https://arxiv.org/abs/2409.12452</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于检索增强生成的熟悉度感知证据压缩</title>
      <link>https://arxiv.org/abs/2409.12468</link>
      <description><![CDATA[arXiv:2409.12468v1 公告类型：新
摘要：检索增强生成 (RAG) 通过从外部来源检索证据来整合非参数知识，从而改进大型语言模型 (LM)。然而，它往往难以过滤掉不一致和不相关的信息，这些信息可能会分散 LM 的任务注意力。虽然使用压缩模型压缩检索到的证据旨在解决这个问题，但压缩证据可能仍然不为用于下游任务的目标模型所熟悉，可能无法有效利用证据。我们提出了 FaviComp（熟悉度感知证据压缩），这是一种新颖的无训练证据压缩技术，它使检索到的证据对目标模型更熟悉，同时无缝集成来自模型的参数知识。具体而言，FaviComp 通过结合压缩模型和目标模型的标记概率来生成目标模型更熟悉的上下文，主动降低压缩证据对目标模型的困惑度。这种方法平衡了参数和非参数知识的集成，这在复杂任务中尤其有用，因为检索到的证据集可能不包含所有必要的信息。实验结果表明，FaviComp 在多个开放域 QA 数据集中始终优于现有基线，实现了高压缩率，并展示了参数和非参数知识的有效集成。]]></description>
      <guid>https://arxiv.org/abs/2409.12468</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AutoMode-ASR：学习选择 ASR 系统以获得更好的质量和成本</title>
      <link>https://arxiv.org/abs/2409.12476</link>
      <description><![CDATA[arXiv:2409.12476v1 公告类型：新
摘要：我们提出了 AutoMode-ASR，这是一种新颖的框架，可有效集成多个 ASR 系统，以提高整体转录质量，同时优化成本。这个想法是在运行系统之前训练一个决策模型，仅根据音频输入为每个片段选择最佳 ASR 系统。我们通过组合二元分类器来确定两个系统之间的偏好来实现这一点。这些分类器配备了各种功能，例如音频嵌入、质量估计和信号属性。此外，我们展示了如何使用质量估计器以最小的成本增加进一步提高性能。实验结果表明，与对所有片段使用单一最佳模型相比，WER 相对降低了 16.2%，成本节省了 65%，速度提高了 75%。我们的框架与商业和开源黑盒 ASR 系统兼容，因为它不需要更改模型代码。]]></description>
      <guid>https://arxiv.org/abs/2409.12476</guid>
      <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>