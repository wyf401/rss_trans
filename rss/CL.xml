<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 28 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>GCoder：改进大型语言模型以解决广义图问题</title>
      <link>https://arxiv.org/abs/2410.19084</link>
      <description><![CDATA[arXiv:2410.19084v1 公告类型：新
摘要：大型语言模型 (LLM) 已展示出强大的推理能力，使其适用于图形计算等复杂任务。图问题的传统推理步骤范式受到不可验证的步骤、有限的长期推理以及对图形变化的较差泛化能力的阻碍。为了克服这些限制，我们引入了 GCoder，这是一种基于代码的 LLM，旨在增强广义图计算问题的解决问题能力。我们的方法涉及构建一个广泛的训练数据集 GraphWild，具有多种图形格式和算法。我们采用多阶段训练过程，包括监督微调 (SFT) 和编译器反馈强化学习 (RLCF)，以改进模型功能。对于看​​不见的任务，使用混合检索技术来增强性能。实验表明，GCoder 优于 GPT-4o，在各种图形计算问题中的平均准确率提高了 16.42%。此外，GCoder 可以高效地管理具有数百万个节点和多种输入格式的大规模图，从而克服了以前专注于推理步骤范式的模型的局限性。这一进步为使用 LLM 更直观、更有效地解决图问题铺平了道路。代码和数据可在此处获取：https://github.com/Bklight999/WWW25-GCoder/tree/master。]]></description>
      <guid>https://arxiv.org/abs/2410.19084</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 树搜索</title>
      <link>https://arxiv.org/abs/2410.19117</link>
      <description><![CDATA[arXiv:2410.19117v1 公告类型：新
摘要：该项目旨在研究一种受 AlphaGo 范式启发的新型序列生成方法，使其适用于大型语言模型 (LLM)。所提出的方法涉及创建不同可能完成的搜索树，并根据模型置信度评估这些完成。通过考虑搜索树中的各种路径并根据模型对每个完成的置信度对其进行评分，我们可以生成多样化且高质量的序列。本研究通过使用置信度作为类似于波束搜索 \citep{vijayakumar2016diverse} 的响应质量代理来探索此范式的实现。本文的主要目标是概述范式并展示其潜力，而不是专注于实现完美的结果。本文将概述我们认为该范式有潜力通过以下方式改进 LLM 的原因：1) 提高输出质量，2) 减少错误，3) 消除或减少复合错误问题，4) 生成多样化和创造性的完成，5) 允许迭代解决问题，6) 自我训练。我们希望这种方法能够产生一组多样化且连贯的序列，为平衡序列生成中的探索和利用提供见解。潜在的应用包括创造性的文本生成任务，例如讲故事和内容创作，以及其他自然语言处理领域，例如机器翻译和自动摘要。目标是使模型更加有效，因为它将能够考虑许多可能的变化，从而找到理想的完成。这项研究旨在帮助理解序列生成中的有效搜索策略及其对生成高质量、多样化文本输出的影响。]]></description>
      <guid>https://arxiv.org/abs/2410.19117</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Read-ME：将 LLM 重构为路由器解耦专家与系统协同设计的混合体</title>
      <link>https://arxiv.org/abs/2410.19123</link>
      <description><![CDATA[arXiv:2410.19123v1 公告类型：新
摘要：大型语言模型 (LLM) 的激增导致了混合专家 (MoE) 架构的采用，该架构动态利用专门的子网络来提高效率和性能。尽管 MoE 模型有诸多好处，但由于模型架构和系统策略之间的设计选择不一致，因此在推理过程中面临着重大挑战，包括内存管理效率低下和批处理不理想。此外，从头开始训练 MoE 的传统方法在成本方面越来越高昂。在本文中，我们提出了一个新颖的框架 Read-ME，它将预先训练的密集 LLM 转换为较小的 MoE 模型（与“升级”通用 MoE 形成对比），从而避免了从头开始训练的高成本。我们的方法采用激活稀疏性来提取专家。为了组成专家，我们研究了广泛采用的分层路由器设计并展示了其冗余性，因此我们引入了与 MoE 主干分离的预门控路由器，以促进系统友好的预计算和前瞻调度，增强专家感知批处理和缓存。因此，我们的协同设计解决了算法和系统方面的关键差距，为资源受限环境中的 LLM 推理建立了可扩展且高效的替代方案。Read-ME 优于其他类似规模的流行开源密集模型，在 MMLU 上实现了高达 10.1% 的改进，并将平均端到端延迟提高了 6.1%。代码可在以下位置获得：https://github.com/VITA-Group/READ-ME。]]></description>
      <guid>https://arxiv.org/abs/2410.19123</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型检索隐性和显性情感事件</title>
      <link>https://arxiv.org/abs/2410.19128</link>
      <description><![CDATA[arXiv:2410.19128v1 公告类型：新
摘要：大型语言模型 (LLM) 近年来因其出色的性能而备受关注。虽然大量研究从各个角度评估了这些模型，但 LLM 执行隐性和显性情绪检索的程度仍未得到充分探索。为了解决这一空白，本研究调查了 LLM 在常识中的情绪检索能力。通过涉及多个模型的大量实验，我们系统地评估了 LLM 在情绪检索方面的能力。具体而言，我们提出了一种监督对比探测方法来验证 LLM 在隐性和显性情绪检索方面的表现，以及它们检索的情绪事件的多样性。结果为 LLM 在处理情绪检索方面的优势和局限性提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2410.19128</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混合偏好：学习路由实例以获得人类与人工智能的反馈</title>
      <link>https://arxiv.org/abs/2410.19133</link>
      <description><![CDATA[arXiv:2410.19133v1 公告类型：新
摘要：从人类反馈中学习使得语言模型 (LM) 与人类偏好保持一致。然而，直接收集人类偏好可能成本高昂、耗时长，并且方差很大。一个有吸引力的替代方案是从 LM 中提取偏好作为合成注释的来源，因为它们比人工注释更一致、更便宜、扩展性更好；然而，它们也容易出现偏差和错误。在这项工作中，我们引入了一个路由框架，该框架结合了来自人类和 LM 的输入，以实现更好的注释质量，同时降低人工注释的总成本。我们方法的关键是识别将从人工注释中受益的偏好实例。我们将其表述为一个优化问题：给定一个偏好数据集和一个评估指标，我们训练一个性能预测模型来预测奖励模型在任意人工和 LM 注释组合上的性能，并采用路由策略来选择最大化预测性能的组合。我们在 MultiPref 上训练性能预测模型，MultiPref 是一个新偏好数据集，包含 10K 个实例，并配有人类和 LM 标签。我们表明，使用我们的路由框架，LM 和直接人类偏好的混合选择比单独使用其中一种偏好可实现更好的奖励模型性能。我们在另外三个数据集上模拟了选择性人类偏好收集，并表明我们的方法可以很好地推广到这三个数据集。我们分析了路由模型中的特征，以确定可以从人类反馈中受益的实例特征，例如具有中等安全问题或中等意图复杂性的提示。我们发布了本研究中使用的数据集、注释平台和源代码，以促进未来更高效、更准确的偏好收集。]]></description>
      <guid>https://arxiv.org/abs/2410.19133</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AlignCap：将语音情感字幕与人类偏好相结合</title>
      <link>https://arxiv.org/abs/2410.19134</link>
      <description><![CDATA[arXiv:2410.19134v1 公告类型：新
摘要：语音情感字幕（SEC）已逐渐成为一项活跃的研究任务。通过人类语音传达的情感内容通常很复杂，将它们归类为固定类别可能不足以完全捕捉语音情感。通过自然语言描述语音情感可能是一种更有效的方法。然而，现有的 SEC 方法经常产生幻觉，并且对看不见的语音失去泛化能力。为了克服这些问题，我们提出了 AlignCap，它基于大型语言模型（LLM）将语音情感字幕与人类偏好对齐，具有两个属性：1）语音文本对齐，使用知识蒸馏（KD）正则化最小化 LLM 对语音和文本输入的响应预测分布之间的差异。2）人类偏好对齐，我们设计偏好优化（PO）正则化来消除事实和忠实幻觉。我们还提取了情感线索，作为在 KD-Regularization 下丰富细粒度信息的提示。实验表明，AlignCap 在 Zero-shot SEC 任务上比其他最先进的方法表现出更强的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.19134</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>未找到生活经验：法学硕士难以与专家就精神药物不良反应达成共识</title>
      <link>https://arxiv.org/abs/2410.19155</link>
      <description><![CDATA[arXiv:2410.19155v1 公告类型：新
摘要：精神药物的不良反应 (ADR) 是精神疾病患者住院的主要原因。由于医疗保健系统和在线社区在解决 ADR 相关问题方面面临限制，大型语言模型 (LLM) 有可能填补这一空白。尽管 LLM 的功能不断增强，但过去的研究尚未探索其在检测与精神药物相关的 ADR 或提供有效的减害策略方面的能力。为了解决这个问题，我们引入了 Psych-ADR 基准和不良药物反应评估 (ADRA) 框架，以系统地评估 LLM 在检测 ADR 表达和提供专家一致的缓解策略方面的表现。我们的分析表明，LLM 难以理解 ADR 的细微差别并区分不同类型的 ADR。虽然 LLM 在表达的情绪和文本语气方面与专家一致，但他们的回答更复杂、更难阅读，并且只有 70.86% 与专家策略一致。此外，他们提供的建议可操作性平均低 12.32%。我们的工作为评估 LLM 在高风险领域中策略驱动任务的表现提供了全面的基准和评估框架。]]></description>
      <guid>https://arxiv.org/abs/2410.19155</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不遗漏任何论点：使用重叠块来更快地处理任意长的法律文本</title>
      <link>https://arxiv.org/abs/2410.19184</link>
      <description><![CDATA[arXiv:2410.19184v1 公告类型：新
摘要：巴西司法系统是世界上最大的司法系统，由于处理数百万起案件的速度缓慢而面临危机，因此开发有效的法律文本分析方法势在必行。我们引入了 uBERT，这是一种结合了 Transformer 和循环神经网络架构的混合模型，可以有效处理长篇法律文本。我们的方法可以处理全文，无论其长度如何，同时保持合理的计算开销。我们的实验表明，在使用重叠输入时，uBERT 比 BERT+LSTM 具有更出色的性能，并且在处理长篇法律文件时比 ULMFiT 快得多。]]></description>
      <guid>https://arxiv.org/abs/2410.19184</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用文本上下文表征丰富 GNN，以检测社交媒体上的虚假信息活动</title>
      <link>https://arxiv.org/abs/2410.19193</link>
      <description><![CDATA[arXiv:2410.19193v1 公告类型：新
摘要：社交媒体上的虚假信息带来了社会和技术挑战。虽然以前的研究已经将文本信息集成到传播网络中，但它们尚未充分利用基于 Transformer 的语言模型的进步来实现高质量的上下文文本表示。这项工作研究了将文本特征纳入图神经网络 (GNN) 对假新闻检测的影响。我们的实验表明，上下文表示在 Macro F1 中比静态表示的性能提高了 9.3%，比没有文本特征的 GNN 的性能提高了 33.8%。然而，嘈杂的数据增强会降低性能并增加不稳定性。我们希望我们的方法能够为进一步的研究开辟道路，并且所有代码都公开可用。]]></description>
      <guid>https://arxiv.org/abs/2410.19193</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过激活分布峰度优化标签集以实现生成模型的零样本分类</title>
      <link>https://arxiv.org/abs/2410.19195</link>
      <description><![CDATA[arXiv:2410.19195v1 公告类型：新
摘要：众所周知，上下文学习 (ICL) 性能对提示设计很敏感，但类别标签选项在零样本分类中的影响却被忽视了。本研究首次全面实证研究了标签选项（例如词汇选择、顺序和详细说明）如何影响零样本 ICL 分类性能。我们的研究结果表明，标签名称的词汇选择（例如，立场分类中的同意与支持）起着重要作用，其影响也与标签顺序有关。对模型内部状态的分析进一步表明，最佳标签名称往往会激活前馈网络中较少的异常神经元。基于这一观察，我们提出了通过激活分布峰度 (LOADS) 进行标签集优化的方案，这是一种不需要梯度传播的事后方法。 LOADS 不仅证明了仅使用 100 个未标记样本在不同模型类型和大小上的有效性，而且还展示了跨语言的可转移性。]]></description>
      <guid>https://arxiv.org/abs/2410.19195</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>故事能帮助法学硕士推理吗？通过叙事策划信息空间</title>
      <link>https://arxiv.org/abs/2410.19221</link>
      <description><![CDATA[arXiv:2410.19221v1 公告类型：新
摘要：叙述被广泛认为是构建信息和促进理解科学传播等各个领域复杂思想的有力工具。本文研究了结合叙事元素是否可以帮助大型语言模型 (LLM) 更有效地解决复杂问题。我们提出了一种新颖的方法，即思想故事 (SoT)，将叙事结构整合到解决问题的提示技术中。这种方法涉及围绕问题陈述构建叙述并创建一个框架来识别和组织相关信息。我们的实验表明，在 GPQA 和 JEEBench 数据集中，在物理、化学、数学和生物学问题上使用各种 LLM 与 SoT 的效果始终优于将它们与其他技术一起使用。SoT 中基于叙述的信息管理过程通过将关键的领域内信息情境化并强调问题空间内的因果关系来增强问题理解。]]></description>
      <guid>https://arxiv.org/abs/2410.19221</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>开发辅导对话数据集以优化 LLM 的教育用途</title>
      <link>https://arxiv.org/abs/2410.19231</link>
      <description><![CDATA[arXiv:2410.19231v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展已显示出可扩展教育应用的前景，但由于需要有效的教学策略以及专家策划的数据集的高成本，它们在基于对话的辅导系统中的使用仍然具有挑战性。我们的研究探讨了在解决阅读理解问题的背景下使用更小、更实惠的 LLM 进行一对一辅导。我们开发了一个由人类教师评估的合成辅导对话数据集，并使用该数据集对较小的 LLM 进行了微调。此外，我们进行了一项交互式实验，比较了微调模型与现实世界辅导场景中较大模型的性能。我们的结果表明，微调模型的性能与较大模型相当，但成本更低，展示了一种在教育环境中实施基于 LLM 的辅导系统的可行、经济高效的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.19231</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>潘多拉魔盒重新开启：分析法学硕士在打击人工智能生成的虚假新闻的斗争中的作用</title>
      <link>https://arxiv.org/abs/2410.19250</link>
      <description><![CDATA[arXiv:2410.19250v1 公告类型：新 
摘要：随着大型语言模型 (LLM) 大规模生成的 AI 生成内容的兴起，人们对虚假新闻传播的真正担忧也愈演愈烈。LLM 能够大规模制作令人信服的虚假新闻，这对人类和自动虚假新闻检测系统都提出了新的挑战。为了解决这一差距，这项工作展示了一项大学级竞赛的结果，该竞赛旨在探索人类如何使用 LLM 来制造虚假新闻，并评估人类注释者和 AI 模型检测虚假新闻的能力。共有 110 名参与者使用 LLM 创建了 252 个独特的虚假新闻故事，84 名注释者参与了检测任务。我们的研究结果表明，LLM 在检测真实新闻方面的效率比人类高出约 68%。然而，对于虚假新闻检测，LLM 和人类的表现仍然相当（准确率约为 60%）。此外，我们还研究了新闻中的视觉元素（例如图片）对检测虚假新闻准确性的影响。最后，我们还研究了虚假新闻创建者用来提高其 AI 生成内容可信度的各种策略。这项研究凸显了检测 AI 生成的虚假新闻的复杂性日益增加，尤其是在人机协作环境中。]]></description>
      <guid>https://arxiv.org/abs/2410.19250</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>并非所有头部都重要：集成检索和推理的头部级 KV 缓存压缩方法</title>
      <link>https://arxiv.org/abs/2410.19258</link>
      <description><![CDATA[arXiv:2410.19258v1 公告类型：新
摘要：键值 (KV) 缓存是一种提高大型语言模型 (LLM) 计算效率的常用技术，但其内存开销会随着输入长度的增加而迅速增长。先前的研究表明，并非所有标记对于文本生成都同样重要，因此提出了层级 KV 缓存压缩以有选择地保留关键信息。认识到注意力头在生成中的不同作用，我们提出了 HeadKV（一种头级 KV 缓存压缩方法）和 HeadKV-R2，它利用一种新颖的上下文推理能力估计进行压缩。我们的方法在单个头部级别运行，估计它们对于需要检索和推理能力的上下文 QA 任务的重要性。针对各种基准（LongBench、LooGLE）、模型架构（例如 Llama-3-8B-Instruct、Mistral-7B-Instruct）和长上下文能力测试的大量实验表明，我们的头部级 KV 缓存压缩明显优于强基线，尤其是在资源匮乏的设置（KV 大小 = 64 和 128）下。值得注意的是，在上下文问答基准上，我们的方法仅保留了 1.5% 的 KV 缓存，却实现了完整 KV 缓存 97% 的性能。]]></description>
      <guid>https://arxiv.org/abs/2410.19258</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>虚构的合成数据可以通过先决条件学习提高法学硕士的真实性</title>
      <link>https://arxiv.org/abs/2410.19290</link>
      <description><![CDATA[arXiv:2410.19290v1 公告类型：新
摘要：最近的研究发现，LLM 幻觉的一个加剧因素是预训练和微调之间的知识不一致，不熟悉的微调数据会误导 LLM 编造合理但错误的输出。在本文中，我们提出了一种称为 Prereq-Tune 的新型微调策略来解决这种知识不一致并减少幻觉。从根本上说，Prereq-Tune 将技能和知识的学习分开，因此模型只学习任务技能，而不会受到知识不一致的影响。为了实现这一点，Prereq-Tune 引入了一个额外的先决条件学习阶段来学习 SFT 所需的知识，使后续的 SFT 只关注任务技能。Prereq-Tune 还可以与虚构的合成数据相结合，以增强 LLM 输出对其内部知识的依据。实验表明，Prereq-Tune 在提高 LLM 在短篇问答和长篇生成任务中的真实性方面优于现有基准。它还为 LLM 中的知识控制生成开辟了新的可能性。我们的代码可在 https://github.com/UCSB-NLP-Chang/Prereq_tune.git 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.19290</guid>
      <pubDate>Mon, 28 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>