<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 26 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>歌词中个人价值观的评估</title>
      <link>https://arxiv.org/abs/2408.12694</link>
      <description><![CDATA[arXiv:2408.12694v1 公告类型：新
摘要：西方国家广泛消费的大多数音乐都包含歌词，美国样本报告称，几乎所有歌曲库都包含歌词。与此同时，社会科学理论表明，个人价值观——指导我们决策和行为的抽象目标——在沟通中发挥着重要作用：我们分享对我们重要的东西，以协调努力、解决问题和应对挑战。因此，歌词中传达的价值观可能与听众的价值观相似或不同，并进而影响听众对歌曲的反应。这表明，努力自动估计歌词中的价值观可能有助于下游的 MIR 任务，特别是个性化。然而，作为高度主观的文本，歌词在采样要注释的歌曲、注释方法和选择聚合方法方面提出了挑战。在这个项目中，我们采用透视主义方法，在社会科学理论的指导下，收集注释、评估其质量并汇总它们。然后，我们通过使用经过验证的值词典，将汇总评级与基于预训练的句子/单词嵌入模型的估计值进行比较。我们讨论了概念上“模糊”的采样和注释挑战解决方案，有望在注释质量和自动估计方面取得初步成果，并指出了未来的发展方向。]]></description>
      <guid>https://arxiv.org/abs/2408.12694</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>宏查询：从高级提示中生成引导图表的探索</title>
      <link>https://arxiv.org/abs/2408.12726</link>
      <description><![CDATA[arXiv:2408.12726v1 公告类型：新
摘要：本文探讨了数据可视化与大型语言模型 (LLM) 的交集。为了使新手用户能够访问更广泛的数据可视化类型，我们提出了一种基于 LLM 的引导式管道，旨在将数据在高级用户问题（称为宏查询）的引导下转换为一组多样化的有用可视化。这种方法利用了各种提示技术、受 Abela 图表分类法启发的微调以及集成的 SQL 工具使用。]]></description>
      <guid>https://arxiv.org/abs/2408.12726</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SLM 与 LLM 相遇：平衡幻觉检测中的延迟、可解释性和一致性</title>
      <link>https://arxiv.org/abs/2408.12748</link>
      <description><![CDATA[arXiv:2408.12748v1 公告类型：新
摘要：大型语言模型 (LLM) 功能强大，但在实时应用中面临延迟挑战，例如进行在线幻觉检测。为了解决这个问题，我们提出了一个新颖的框架，该框架利用小型语言模型 (SLM) 分类器进行初始检测，然后使用 LLM 作为受限推理器为检测到的幻觉内容生成详细解释。本研究通过引入有效的提示技术优化了实时可解释的幻觉检测，这些提示技术将 LLM 生成的解释与 SLM 决策相结合。实证实验结果证明了其有效性，从而提升了整体用户体验。]]></description>
      <guid>https://arxiv.org/abs/2408.12748</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>调查电子商务中的法学硕士应用</title>
      <link>https://arxiv.org/abs/2408.12779</link>
      <description><![CDATA[arXiv:2408.12779v1 公告类型：新
摘要：大型语言模型 (LLM) 的出现彻底改变了各种应用中的自然语言处理，尤其是在电子商务中。在这些领域应用此类 LLM 之前的一个关键步骤是了解和比较此类任务中不同用例的性能。本文探讨了 LLM 在电子商务领域的功效，重点是使用不同大小的公共电子商务数据集对开源 LLM 模型进行指令调整，并将其性能与工业应用中流行的传统模型进行比较。我们在电子商务领域固有的特定任务（即分类、生成、摘要和命名实体识别 (NER)）中对 LLM 和传统的预训练语言模型进行了全面比较。此外，我们还使用上下文学习研究了当前非常大型 LLM 在电子商务特定任务中的小众工业应用的有效性。我们的研究结果表明，使用非常大的 LLM 进行少量推理通常不如微调较小的预训练模型，这凸显了针对特定任务的模型优化的重要性。此外，我们还研究了不同的训练方法，例如单任务训练、混合任务训练和领域/任务内以及不同任务之间的 LoRA 合并。通过严格的实验和分析，本文提供了宝贵的见解，表明 LLM 在电子商务行业中提升自然语言处理能力的潜在有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.12779</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>质量还是数量？关于适应大型语言模型以进行低资源翻译的数据规模和多样性</title>
      <link>https://arxiv.org/abs/2408.12780</link>
      <description><![CDATA[arXiv:2408.12780v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 最近在机器翻译 (MT) 中很受欢迎，但它们在低资源翻译中的表现仍然远远落后于神经机器翻译 (NMT) 模型。在本文中，我们探讨了如何使 LLM 适应低资源环境。特别是，我们重新审视了两个因素的作用：a) 并行数据的重要性和应用，以及 b) 监督微调 (SFT) 中的多样性。最近，研究表明，使用 LLM 进行机器翻译时，并行数据的重要性不如以前的机器翻译研究。同样，SFT 期间的多样性已被证明可以促进 LLM 在语言和任务之间的显著转移。然而，对于低资源 LLM-MT，我们表明这两个考虑因素的情况恰恰相反：a) 并行数据在预训练和 SFT 期间都至关重要，b) 多样性往往会造成干扰，而不是转移。我们针对 2 个资源匮乏的语言群体（美洲土著和东北印第安）的 3 名 LLM 进行了实验，结果显示两种情况下都存在一致的模式，这凸显了我们的研究结果具有普遍性。我们相信这些见解对于扩展到能够有效服务于资源匮乏语言的大规模多语言 LLM-MT 模型将大有裨益。]]></description>
      <guid>https://arxiv.org/abs/2408.12780</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>少即是多：通过自动自我管理训练语料库来增强生成语言模型中的偏好学习</title>
      <link>https://arxiv.org/abs/2408.12799</link>
      <description><![CDATA[arXiv:2408.12799v1 公告类型：新
摘要：语言中的歧义性对开发更强大的语言模型提出了挑战，特别是在偏好学习中，注释者之间的差异导致用于模型对齐的注释数据集不一致。为了解决这个问题，我们引入了一种自我管理方法，该方法利用直接在这些数据集上训练的代理模型来预处理注释数据集。我们的方法通过自动检测和删除数据集中的歧义注释来增强偏好学习。所提出的方法通过大量实验得到验证，表明在各种指令遵循任务中性能显着提高。我们的工作提供了一种直接可靠的方法来克服注释不一致问题，这是开发更高级偏好学习技术的第一步。]]></description>
      <guid>https://arxiv.org/abs/2408.12799</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基础谬误：歪曲科学出版物的证据</title>
      <link>https://arxiv.org/abs/2408.12812</link>
      <description><![CDATA[arXiv:2408.12812v1 公告类型：新
摘要：与健康相关的错误信息声称经常错误地引用可信的生物医学出版物作为证据，表面上似乎支持虚假声明。该出版物实际上并不支持该主张，但由于使用了逻辑谬误，读者可能会相信它。在这里，我们的目标是检测和突出这种谬误，这需要仔细评估被歪曲的出版物的确切内容。为了实现这一点，我们引入了 MissciPlus，这是谬误检测数据集 Missci 的扩展。MissciPlus 以 Missci 为基础，将应用的谬误建立在被歪曲研究的真实段落中。这为在真实输入条件下检测和表达这些谬误创建了一个现实的测试平台，并支持新颖的段落检索任务。MissciPlus 是第一个逻辑谬误数据集，它将现实世界的歪曲证据与不正确的主张配对，与基于证据的事实核查模型的输入相同。使用 MissciPlus，我们 i) 对检索模型进行基准测试，以识别仅在应用谬误时才支持主张的段落，ii) 评估法学硕士如何表达来自歪曲的科学段落的谬误推理，以及 iii) 评估事实核查模型在驳斥歪曲生物医学研究的主张方面的有效性。我们的研究结果表明，当前的事实核查模型很难使用来自歪曲出版物的相关段落来驳斥错误信息。此外，这些段落可能会误导法学硕士将虚假主张视为真实。]]></description>
      <guid>https://arxiv.org/abs/2408.12812</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LIMP：大型语言模型增强意图感知移动性预测</title>
      <link>https://arxiv.org/abs/2408.12832</link>
      <description><![CDATA[arXiv:2408.12832v1 公告类型：新
摘要：人类流动性预测对于城市规划和交通管理等应用至关重要，但由于人类行为背后复杂且通常隐含的意图，它仍然具有挑战性。现有模型主要关注时空模式，较少关注控制运动的根本意图。大型语言模型 (LLM) 的最新进展为将常识推理融入流动性预测提供了一个有前途的替代研究角度。然而，这是一个不平凡的问题，因为 LLM 不是为移动意图推理而构建的，而且它们还面临可扩展性问题和与时空模型的集成困难。为了应对这些挑战，我们提出了一个新颖的 LIMP（用于 Intent-ware Mobility Prediction 的 LLM）框架。具体来说，LIMP 引入了“分析-抽象-推断”（A2I）代理工作流，以释放 LLM 的常识推理能力以进行移动意图推理。此外，我们设计了一种高效的微调方案，将推理能力从商业 LLM 转移到规模较小的开源语言模型，确保 LIMP 能够扩展到数百万条移动记录。此外，我们提出了一种基于 Transformer 的意图感知移动预测模型，以有效利用 LLM 的意图推理能力。在两个真实数据集上进行评估后，LIMP 的表现明显优于基线模型，显示出在下一个位置预测和有效意图推理方面的改进。意图感知移动预测的可解释性凸显了我们的 LIMP 框架在实际应用中的潜力。代码和数据可以在 https://github.com/tsinghua-fib-lab/LIMP 中找到。]]></description>
      <guid>https://arxiv.org/abs/2408.12832</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CLLMFS：一种对比学习增强的用于小样本命名实体识别的大型语言模型框架</title>
      <link>https://arxiv.org/abs/2408.12834</link>
      <description><![CDATA[arXiv:2408.12834v1 公告类型：新 
摘要：少样本命名实体识别 (NER) 是在有限数量的标记数据中识别命名实体的任务，在自然语言处理中具有越来越重要的意义。虽然现有的方法已经显示出一些有效性，例如通过各种提示模式丰富标签语义或采用度量学习技术，但由于其预训练模型缺乏丰富的知识，它们的性能在不同领域表现出有限的鲁棒性。为了解决这个问题，我们提出了 CLLMFS，一种用于少样本命名实体识别的对比学习增强大型语言模型 (LLM) 框架，在有限的训练数据下取得了可喜的结果。考虑到 LLM 的内部表示对下游任务的影响，CLLMFS 集成了专门针对少样本 NER 的低秩自适应 (LoRA) 和对比学习机制。通过增强模型的内部表示，CLLMFS 有效地提高了实体边界感知能力和实体识别准确率。我们的方法在 F1 得分上取得了最先进的性能改进，在多个公认的基准测试中比现有的最佳方法提高了 2.58% 到 97.74%。此外，通过在多个数据集上进行的跨域 NER 实验，我们进一步验证了我们方法的强大泛化能力。我们的代码将在不久的将来发布。]]></description>
      <guid>https://arxiv.org/abs/2408.12834</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对主题领域特异性的多方面问题复杂性估计</title>
      <link>https://arxiv.org/abs/2408.12850</link>
      <description><![CDATA[arXiv:2408.12850v1 公告类型：新
摘要：问题难度估计在教育和评估环境中仍然是一个多方面的挑战。传统方法通常侧重于表面语言特征或学习者的理解水平，而忽略了导致问题复杂性的因素之间的复杂相互作用。本文提出了一种用于特定领域问题难度估计的新框架，利用一套 NLP 技术和知识图谱分析。我们引入了四个关键参数：主题检索成本、主题显着性、主题连贯性和主题肤浅性，每个参数都捕捉了给定主题领域内问题复杂性的不同方面。这些参数通过主题建模、知识图谱分析和信息检索技术进行操作。在这些特征上训练的模型证明了我们的方法在预测问题难度方面的有效性。通过操作这些参数，我们的框架提供了一种新颖的问题复杂性估计方法，为跨不同学科更有效的问题生成、评估设计和自适应学习系统铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2408.12850</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>因果引导主动学习用于消除大型语言模型的偏差</title>
      <link>https://arxiv.org/abs/2408.12942</link>
      <description><![CDATA[arXiv:2408.12942v1 公告类型：新
摘要：尽管取得了令人鼓舞的性能，但最近的分析表明，当前的生成式大型语言模型 (LLM) 仍可能捕获数据集偏差并将其用于生成，从而导致 LLM 的通用性较差且有害。然而，由于数据集偏差的多样性和过度优化问题，以前基于先验知识的去偏方法和基于微调的去偏方法可能不适合当前的 LLM。为了解决这个问题，我们探索将主动学习与因果机制相结合，并提出了一个因果引导的主动学习 (CAL) 框架，该框架利用 LLM 本身自动和自主地识别信息偏差样本并诱导偏差模式。然后采用一种经济高效且基于上下文学习的方法来防止 LLM 在生成过程中利用数据集偏差。实验结果表明，CAL 可以有效识别典型的偏差实例并诱导各种偏差模式来去偏 LLM。]]></description>
      <guid>https://arxiv.org/abs/2408.12942</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态对比语境学习</title>
      <link>https://arxiv.org/abs/2408.12959</link>
      <description><![CDATA[arXiv:2408.12959v1 公告类型：新
摘要：大型语言模型 (LLM) 使用的快速增长凸显了无梯度上下文学习 (ICL) 的重要性。然而，解释它们的内部工作原理仍然具有挑战性。本文介绍了一种新颖的多模态对比上下文学习框架，以增强我们对 LLM 中 ICL 的理解。首先，我们提出了一种基于对比学习的 ICL 在现实世界环境中的解释，将键值表示的距离标记为 ICL 中的区分器。其次，我们开发了一个分析框架来解决现实世界数据集的多模态输入格式偏差。我们证明了 ICL 示例的有效性，即使它们以看不见的格式表示，基线性能也很差。最后，我们提出了一种即时 ICL（文本锚定 ICL）方法，该方法证明了在检测仇恨模因方面的有效性，而典型的 ICL 由于资源限制而难以完成这项任务。在多模态数据集上进行的大量实验表明，我们的方法显著提高了 ICL 在各种场景（例如具有挑战性的任务和资源受限的环境）中的表现。此外，它还为 LLM 中的情境学习机制提供了宝贵的见解。我们的研究结果对于开发更具解释性、更高效和更强大的多模态 AI 系统具有重要意义，尤其是在具有挑战性的任务和资源受限的环境中。]]></description>
      <guid>https://arxiv.org/abs/2408.12959</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>立陶宛语的开放式 Llama2 模型</title>
      <link>https://arxiv.org/abs/2408.12963</link>
      <description><![CDATA[arXiv:2408.12963v1 公告类型：新
摘要：在本文中，我们提出并描述了第一个针对立陶宛语的开放 Llama2 大型语言模型 (LLM)，包括随附的问答 (Q/A) 数据集和流行 LLM 基准的翻译。我们简要回顾了开放的区域 LLM，并详细介绍了所提出的 LLM 及其训练过程。我们还进行了实证评估，将所提出的 LLM 的困惑度与其他现代开放 LLM 的困惑度进行了比较。此外，将所提出的 LLM 与语言理解任务进行基准测试表明，高质量的预训练数据集对于实现在这些基准上表现高效的模型可能至关重要。所述 LLM 的完整实现可在随附的开放存储库~\url{https://huggingface.co/neurotechnology} 中找到。]]></description>
      <guid>https://arxiv.org/abs/2408.12963</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向知识密集型问答的内部和外部知识交互细化框架</title>
      <link>https://arxiv.org/abs/2408.12979</link>
      <description><![CDATA[arXiv:2408.12979v1 公告类型：新
摘要：最近的研究试图将外部知识整合到 LLM 中，以解决 LLM 生成内容的局限性和潜在的事实错误。然而，如何从大量的外部知识中检索正确的知识是一个挑战。为此，我们通过经验观察到 LLM 已经在其预训练参数中编码了丰富的知识，并且在将它们应用于知识密集型任务时，利用这些内部知识可以提高外部知识的检索能力。在本文中，我们提出了一种新的内部和外部知识交互细化范式 IEKR，以利用 LLM 中的内部知识来帮助从外部知识库中检索相关知识，并利用外部知识来细化生成的内部知识的幻觉。通过简单地向 LLM 添加“告诉我一些关于”之类的提示，我们尝试查看相关的显性知识并将它们与查询一起插入到检索器中进行外部检索。利用外部知识补充内部知识，将其作为 LLM 的输入，从而得到答案。我们在知识密集型问答任务的 3 个基准数据集上对不同的 LLM 和领域进行了实验，取得了新的最佳成果。进一步的分析表明了我们方法中不同模块的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.12979</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MedDec：从出院总结中提取医疗决策的数据集</title>
      <link>https://arxiv.org/abs/2408.12980</link>
      <description><![CDATA[arXiv:2408.12980v1 公告类型：新
摘要：医疗决策直接影响个人的健康和福祉。从临床记录中提取决策跨度对于理解医疗决策过程起着至关重要的作用。在本文中，我们开发了一个名为“MedDec”的新数据集，其中包含十种医疗决策注释的十一种不同表型（疾病）的临床记录。我们介绍了医疗决策提取任务，旨在联合提取和分类临床记录中的不同类型的医疗决策。我们对数据集进行了全面的分析，开发了一个跨度检测模型作为此任务的基线，评估了最近的跨度检测方法，并使用了一些指标来衡量数据样本的复杂性。我们的研究结果揭示了临床决策提取固有的复杂性，并为该研究领域的未来工作提供了支持。数据集和代码可通过 https://github.com/CLU-UML/MedDec 获得。]]></description>
      <guid>https://arxiv.org/abs/2408.12980</guid>
      <pubDate>Mon, 26 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>