<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 14 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>探索数学推理中大型语言模型的组合缺陷</title>
      <link>https://arxiv.org/abs/2405.06680</link>
      <description><![CDATA[arXiv:2405.06680v1 公告类型：新
摘要：人类认知表现出系统的组合性，即从有限的学习成分生成无限新颖组合的代数能力，这是理解和推理复杂逻辑的关键。在这项工作中，我们研究了数学推理中大型语言模型（LLM）的组合性。具体来说，我们通过在 MATH 和 GSM8k 的问题描述中引入精心设计的逻辑陷阱来构造一个新的数据集 \textsc{MathTrap}\footnotemark[3]。由于逻辑缺陷问题在现实世界中相当罕见，因此这些对于法学硕士来说代表着“看不见”的案例。解决这些问题需要模型系统地组合（1）原始问题涉及的数学知识和（2）与引入的陷阱相关的知识。我们的实验表明，虽然法学硕士拥有必要知识的两个组成部分，但他们并没有\textbf{自发地}将它们结合起来来处理这些新案例。我们探索了几种方法来弥补这一缺陷，例如自然语言提示、少镜头演示和微调。我们发现法学硕士的表现可以通过上述外部干预得到\textbf{被动}的提高。总体而言，系统组合性对于大型语言模型来说仍然是一个开放的挑战。]]></description>
      <guid>https://arxiv.org/abs/2405.06680</guid>
      <pubDate>Tue, 14 May 2024 06:19:30 GMT</pubDate>
    </item>
    <item>
      <title>利用讲座内容改进反馈：GPT-4 和检索增强生成的探索</title>
      <link>https://arxiv.org/abs/2405.06681</link>
      <description><![CDATA[arXiv:2405.06681v1 公告类型：新
摘要：本文提出了使用检索增强生成（RAG）来改进大型语言模型为编程任务生成的反馈。为此，使用 RAG 转录了相应的讲座录音，并将其作为外部知识源和时间戳作为元信息提供给大型语言模型 GPT-4。这样做的目的是防止产生幻觉并强制使用讲座中的技术术语和短语。在为解决入门编程讲座的编程问题而开发的练习平台中，学生可以请求对 GPT-4 生成的解决方案的反馈。对于此任务，GPT-4 接收学生的代码解决方案、编译器输出、单元测试结果以及通过使用 RAG 作为附加上下文提供的讲义中的相关段落。 GPT-4生成的反馈应该引导学生独立解决问题并链接到讲座内容，使用成绩单的时间戳作为元信息。这样就可以在相应的位置立即观看相应的讲座视频。为了进行评估，学生们在研讨会上使用该工具，并根据每个反馈决定是否应该由 RAG 扩展。基于调查问卷和收集的使用数据的初步结果表明，RAG 的使用可以改善反馈的生成，并且在某些情况下受到学生的青睐。由于反馈生成速度较慢，其好处取决于具体情况。]]></description>
      <guid>https://arxiv.org/abs/2405.06681</guid>
      <pubDate>Tue, 14 May 2024 06:19:30 GMT</pubDate>
    </item>
    <item>
      <title>开放 SQL 框架：增强开源大型语言模型上的文本到 SQL</title>
      <link>https://arxiv.org/abs/2405.06674</link>
      <description><![CDATA[arXiv:2405.06674v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 在文本到 SQL 任务中取得了成功，但开源 LLM 在上下文理解和响应一致性方面遇到了挑战。为了解决这些问题，我们提出了一种针对文本到 SQL 的开源法学硕士量身定制的系统方法。我们的贡献包括对文本到 SQL 任务中开源法学硕士的全面评估、有效问题表示的 \openprompt 策略以及监督微调的新颖策略。我们探索了思想链在逐步推理中的好处，并提出了用于增强小样本学习的 \openexample 方法。此外，我们还引入了令牌高效技术，例如 \textbf{Variable-length Open DB Schema}、\textbf{Target Column Truncation} 和 \textbf{Example Column Truncation}，以解决大型数据库中的挑战。我们的研究结果强调需要进一步调查监督微调对情境学习能力的影响。值得注意的是，我们的方法在 BIRD-Dev 数据集上将 Llama2-7B 从 2.54\% 显着提高到 41.04\%，将 Code Llama-7B 从 14.54\% 显着提高到 48.24\%。值得注意的是，Code Llama-7B 在 BIRD-Dev 数据集上的性能超过了 GPT-4 (46.35%)。]]></description>
      <guid>https://arxiv.org/abs/2405.06674</guid>
      <pubDate>Tue, 14 May 2024 06:19:29 GMT</pubDate>
    </item>
    <item>
      <title>EDA Corpus：用于增强与 OpenROAD 交互的大型语言模型数据集</title>
      <link>https://arxiv.org/abs/2405.06676</link>
      <description><![CDATA[arXiv:2405.06676v1 公告类型：新
摘要：大型语言模型（LLM）是强大的设计工具，提供任务自动化和设计辅助的功能。最近的进展显示了促进法学硕士融入芯片设计流程的巨大潜力；然而，其中许多工作依赖于未公开提供和/或未获得许可用于法学硕士培训和分发的数据。在本文中，我们提出了一种解决方案，旨在通过引入专为 OpenROAD（一种广泛采用的开源 EDA 工具链）量身定制的开源数据集来弥补这一差距。该数据集包含 1000 多个数据点，并采用两种格式构建：(i) 由问题提示和散文答案组成的成对集，以及 (ii) 由代码提示及其相应的 OpenROAD 脚本组成的成对集。通过提供此数据集，我们的目标是促进 EDA 领域内以法学硕士为重点的研究。该数据集可从 https://github.com/OpenROAD-Assistant/EDA-Corpus 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.06676</guid>
      <pubDate>Tue, 14 May 2024 06:19:29 GMT</pubDate>
    </item>
    <item>
      <title>ATG：生成语言模型的自动定理生成基准测试</title>
      <link>https://arxiv.org/abs/2405.06677</link>
      <description><![CDATA[arXiv:2405.06677v1 公告类型：新
摘要：人类可以开发新的定理来探索更广泛、更复杂的数学结果。虽然当前的生成语言模型（LM）在自动证明定理方面取得了显着的进步，但它们生成新的或可重用定理的能力仍有待探索。如果没有新的定理，当前的语言模型很难证明更难的定理，这些定理与指数增长的搜索空间远离给定的假设。因此，本文提出了自动定理生成（ATG）基准，用于评估代理是否可以自动生成有价值的（可能是全新的）定理，这些定理适用于下游定理证明作为可重用知识。具体来说，我们通过将 Metamath 库根据证明深度分为三组来构建 ATG 基准：公理、库和问题。我们进行了大量的实验来研究当前的 LM 是否可以在库中生成定理并有利于问题定理的证明。结果表明，高质量的 ATG 数据有助于模型在下游 ATP 上的表现。然而，当前的 LM 仍有空间开发更好的 ATG 并生成更先进的、类似人类的定理。我们希望新的 ATG 挑战能够为高级复杂定理证明提供一些启发。]]></description>
      <guid>https://arxiv.org/abs/2405.06677</guid>
      <pubDate>Tue, 14 May 2024 06:19:29 GMT</pubDate>
    </item>
    <item>
      <title>针对极端金融数字标签的大型语言模型的参数高效指令调整</title>
      <link>https://arxiv.org/abs/2405.06671</link>
      <description><![CDATA[arXiv:2405.06671v1 公告类型：新
摘要：我们研究了使用相应的 XBRL 标签自动注释财务文档中出现的相关数字（GAAP 指标）的问题。与之前的工作不同，我们研究了通过大型语言模型（LLM）的指令调整使用生成范式解决这个极端分类问题的可行性。为此，我们利用度量元数据信息来构建我们的目标输出，同时为使用 LoRA 的任务提出参数有效的解决方案。我们对两个最近发布的金融数字标签数据集进行了实验。我们提出的模型 FLAN-FinXC 在两个数据集上都实现了新的最先进的性能，优于几个强大的基线。我们通过展示其零样本和最不频繁出现的标签的能力来解释我们提出的模型的更好分数。此外，即使我们无法正确预测 XBRL 标签，在大多数情况下，我们生成的输出也与真实情况有很大重叠。]]></description>
      <guid>https://arxiv.org/abs/2405.06671</guid>
      <pubDate>Tue, 14 May 2024 06:19:28 GMT</pubDate>
    </item>
    <item>
      <title>EHRSQL 2024 电子健康记录可靠文本到 SQL 建模共享任务概述</title>
      <link>https://arxiv.org/abs/2405.06673</link>
      <description><![CDATA[arXiv:2405.06673v1 公告类型：新
摘要：电子健康记录（EHR）是存储医院内患者完整病史的关系数据库。它们记录患者医疗护理的各个方面，从入院和诊断到治疗和出院。虽然 EHR 是临床数据的重要来源，但在预定义的查询集之外探索它们需要 SQL 等查询语言的技能。为了使信息检索更容易访问，一种策略是构建一个问答系统，可能利用文本到 SQL 模型，该模型可以自动将自然语言问题转换为相应的 SQL 查询，并使用这些查询来检索答案。 EHRSQL 2024 共享任务旨在推进和促进使用文本到 SQL 建模的 EHR 问答系统开发研究，该系统能够可靠地向各种医疗保健专业人员提供所需的答案，以改进他们的临床工作流程并满足他们的需求。在申请共享任务的 100 多名参与者中，有 8 个团队完成了整个共享任务流程，并展示了有效解决该任务的多种方法。在本文中，我们描述了可靠的文本到 SQL 建模的任务、数据集以及参与者的方法和结果。我们希望这项共同任务能够激发进一步的研究和见解，为电子病历开发可靠的问答系统。]]></description>
      <guid>https://arxiv.org/abs/2405.06673</guid>
      <pubDate>Tue, 14 May 2024 06:19:28 GMT</pubDate>
    </item>
    <item>
      <title>使用机器和深度学习算法对孟加拉食品评论进行情感极性分析</title>
      <link>https://arxiv.org/abs/2405.06667</link>
      <description><![CDATA[arXiv:2405.06667v1 公告类型：新
【摘要】：互联网已经成为现代社会人们必不可少的工具。人类，像所有生物体一样，有生存的基本要求。其中包括获得大气中的氧气、饮用水、防护住所和食物。世界的不断变化使我们的存在变得不那么复杂。很大一部分人利用在线订餐服务将餐食送到他们的住所。尽管订餐的方法有很多种，但顾客有时会对收到的食物感到失望。我们的努力是建立一个可以确定食品质量好坏的模型。我们收集了来自著名食品订购平台（包括 Food Panda 和 HungryNaki）的超过 1484 条在线评论的广泛数据集。利用收集到的数据，对各种深度学习和机器学习技术进行了严格评估，以确定预测食品质量的最准确方法。在所有评估的算法中，逻辑回归是最准确的，达到了令人印象深刻的 90.91% 的准确率。该评论提供了宝贵的见解，将指导用户决定是否点餐。]]></description>
      <guid>https://arxiv.org/abs/2405.06667</guid>
      <pubDate>Tue, 14 May 2024 06:19:27 GMT</pubDate>
    </item>
    <item>
      <title>即时揭露和解释假新闻</title>
      <link>https://arxiv.org/abs/2405.06668</link>
      <description><![CDATA[arXiv:2405.06668v1 公告类型：新
摘要：社交媒体平台促进了信息的快速传播和消费。然而，无论共享数据的可靠性如何，用户都会立即消费此类内容。因此，后一种众包模式容易受到操纵。这项工作提供了一种可解释的在线分类方法来实时识别假新闻。所提出的方法将无监督和监督机器学习方法与在线创建的词汇相结合。该分析是使用自然语言处理技术使用基于创建者、内容和上下文的特征构建的。可解释的分类机制在仪表板中显示为分类选择的特征和预测置信度。所提出的解决方案的性能已通过 Twitter 的真实数据集进行了验证，结果达到 80% 的准确度和宏观 F 测量。该提案是第一个联合提供数据流处理、分析、分类和可解释性的提案。最终，对假新闻的早期发现、隔离和解释有助于提高社交媒体内容的质量和可信度。]]></description>
      <guid>https://arxiv.org/abs/2405.06668</guid>
      <pubDate>Tue, 14 May 2024 06:19:27 GMT</pubDate>
    </item>
    <item>
      <title>长财务收益电话会议记录的指令引导要点总结</title>
      <link>https://arxiv.org/abs/2405.06669</link>
      <description><![CDATA[arXiv:2405.06669v1 公告类型：新
摘要：虽然自动摘要技术取得了重大进步，但其主要重点是摘要具有清晰结构模式的短新闻文章或文档，例如科学文章或政府报告。对于开发总结财务文件的有效方法还没有进行太多探索，这些文件通常包含复杂的事实和数据。在这里，我们使用最近发布的 ECTSum 数据集研究长盈利通话记录 (ECT) 的要点总结问题。我们利用无监督的基于问题的提取模块，然后是参数高效的指令调整抽象模块来解决此任务。我们提出的模型 FLAN-FinBPS 实现了超越最强基线的新的最先进性能，平均 ROUGE 分数增益为 14.88%，并且能够生成事实上一致的要点摘要，捕获 ECT 中讨论的重要事实。]]></description>
      <guid>https://arxiv.org/abs/2405.06669</guid>
      <pubDate>Tue, 14 May 2024 06:19:27 GMT</pubDate>
    </item>
    <item>
      <title>探索社交媒体帖子以识别抑郁症：Reddit 数据集的研究</title>
      <link>https://arxiv.org/abs/2405.06656</link>
      <description><![CDATA[arXiv:2405.06656v1 公告类型：新
【摘要】：抑郁症是影响个人生活和职业生活的最常见精神障碍之一。在这项工作中，我们研究了利用社交媒体帖子来识别个体抑郁症的可能性。为了实现这一目标，我们进行了一项初步研究，从抑郁症相关论坛中提取并分析了 2022 年 Reddit 热门帖子。使用 UMLS Metathesaurus 将收集的数据标记为抑郁和非抑郁。此外，将预处理的数据输入经典机器学习模型，我们在预测抑郁和非抑郁帖子方面取得了 92.28% 的准确率。]]></description>
      <guid>https://arxiv.org/abs/2405.06656</guid>
      <pubDate>Tue, 14 May 2024 06:19:26 GMT</pubDate>
    </item>
    <item>
      <title>使用命名实体和词性增强财务关系提取的语言模型</title>
      <link>https://arxiv.org/abs/2405.06665</link>
      <description><![CDATA[arXiv:2405.06665v1 公告类型：新
摘要：财务关系提取 (FinRE) 任务涉及在给定一段财务报表/文本的情况下识别实体及其关系。为了解决这个 FinRE 问题，我们提出了一种简单但有效的策略，通过使用命名实体识别 (NER) 和词性 (POS) 以及不同的组合方法来增强预训练语言模型的性能这些信息。金融关系数据集上的实验显示了有希望的结果，并强调了将 NER 和 POS 纳入现有模型的好处。我们的数据集和代码可在 https://github.com/kwanhui/FinRelExtract 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.06665</guid>
      <pubDate>Tue, 14 May 2024 06:19:26 GMT</pubDate>
    </item>
    <item>
      <title>作为规划域生成器的大型语言模型</title>
      <link>https://arxiv.org/abs/2405.06650</link>
      <description><![CDATA[arXiv:2405.06650v1 公告类型：新
摘要：开发领域模型是人工智能规划中为数不多的需要人工参与的领域之一。因此，为了使规划更容易实现，需要自动化领域模型生成的过程。为此，我们研究是否可以使用大型语言模型（LLM）从简单的文本描述生成规划领域模型。具体来说，我们引入了一个框架，通过比较域实例的计划集来自动评估 LLM 生成的域。最后，我们对 7 个大型语言模型进行了实证分析，包括跨 9 个不同规划领域以及三类自然语言领域描述的编码和聊天模型。我们的结果表明，法学硕士，特别是那些具有高参数计数的法学硕士，在从自然语言描述生成正确的规划域方面表现出中等水平的熟练程度。我们的代码可从 https://github.com/IBM/NL2PDDL 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.06650</guid>
      <pubDate>Tue, 14 May 2024 06:19:25 GMT</pubDate>
    </item>
    <item>
      <title>基于Transformer深度学习算法的大语言模型（LLM）AI文本生成检测</title>
      <link>https://arxiv.org/abs/2405.06652</link>
      <description><![CDATA[arXiv:2405.06652v1 公告类型：新
摘要：本文基于 Transformer 模型开发了一种 LLM AI 文本生成检测工具，旨在提高 AI 文本生成检测的准确性，为后续研究提供参考。首先对文本进行 Unicode 规范化，转换为小写形式，通过正则表达式删除非字母字符和标点符号以外的字符，在标点符号周围添加空格，删除第一个和最后一个空格，将连续的省略号替换为单个空格，文本使用指定的分隔符连接。接下来删除非字母字符和多余的空白字符，用一个空格替换多个连续的空白字符，然后再次转换为小写形式。深度学习模型结合了 LSTM、Transformer 和 CNN 等层，用于文本分类或序列标记任务。训练集和验证集显示，模型损失从0.127下降到0.005，准确率从94.96提高到99.8，表明模型对AI生成的文本具有良好的检测和分类能力。测试集混淆矩阵和准确率表明，该模型对AI生成的文本有99%的预测准确率，准确率为0.99，召回率为1，f1分数为0.99，达到了非常高的分类准确率。展望未来，其在AI文本检测领域具有广泛的应用前景。]]></description>
      <guid>https://arxiv.org/abs/2405.06652</guid>
      <pubDate>Tue, 14 May 2024 06:19:25 GMT</pubDate>
    </item>
    <item>
      <title>人工智能代理的级别：从规则到大型语言模型</title>
      <link>https://arxiv.org/abs/2405.06643</link>
      <description><![CDATA[arXiv:2405.06643v1 公告类型：新
摘要：人工智能代理被定义为感知环境、做出决策和采取行动的人工实体。受汽车工程师协会自动驾驶6个级别的启发，AI智能体也根据效用和强度分为以下几个级别：L0，无AI，工具考虑感知加行动； L1，使用基于规则的人工智能； L2，使基于规则的人工智能被基于IL/RL的人工智能取代，并具有额外的推理和决策能力； L3，应用基于LLM的AI而不是基于IL/RL的AI，另外设置记忆和反射； L4，基于L3，促进自主学习和泛化； L5，在L4的基础上，附加了情感、性格的个性以及多智能体的协作行为。]]></description>
      <guid>https://arxiv.org/abs/2405.06643</guid>
      <pubDate>Tue, 14 May 2024 06:19:24 GMT</pubDate>
    </item>
    </channel>
</rss>