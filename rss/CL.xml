<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 18 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用基于网格搜索方法的混合深度学习模型对 COVID-19 Twitter 情绪进行分类</title>
      <link>https://arxiv.org/abs/2406.10266</link>
      <description><![CDATA[arXiv:2406.10266v1 公告类型：新
摘要：在当代，社交媒体平台积累了大量由用户贡献的社交数据。为了及时掌握个人对产品或事件的看法和情感倾向，对用户生成的内容进行情感分析势在必行。微博评论通常包含冗长和简洁的文本条目，呈现出复杂的场景。与较短的文本条目相比，这种复杂性在大量文本内容中尤为明显，因为其内容丰富且单词相互关系复杂。在 Facebook 或 Twitter 等社交网站上分享的舆情的情感分析已经发展并找到了多种应用。然而，这一领域仍有几个挑战有待解决。混合方法已经成为减轻情绪分析错误的有希望的模型，特别是在处理逐渐复杂的训练数据时。在本文中，为了研究 COVID-19 疫苗接种的犹豫不决，我们提出了八种不同的混合深度学习模型进行情绪分类，旨在提高模型的整体准确性。使用嵌入、深度学习模型和网格搜索算法在 Twitter COVID-19 数据集上实现情绪预测。根据这项研究，公众对 COVID-19 免疫接种的情绪似乎随着时间的推移而改善，疫苗不情愿程度的逐渐下降就是明证。通过广泛的评估，提出的模型报告的准确率提高了 98.86%，优于其他模型。具体来说，BERT、CNN 和 GS 的组合产生了最高的准确率，而 GloVe、BiLSTM、CNN 和 GS 的组合紧随其后，准确率为 98.17%。此外，与现有研究相比，提出的模型报告的准确率提高了 2.11% 至 14.46%。]]></description>
      <guid>https://arxiv.org/abs/2406.10266</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:36 GMT</pubDate>
    </item>
    <item>
      <title>生成式 LLM 标记概率分布中未使用的信息：通过计算期望值提高 LLM 阅读理解能力</title>
      <link>https://arxiv.org/abs/2406.10267</link>
      <description><![CDATA[arXiv:2406.10267v1 公告类型：新
摘要：LLM 文本解码是感知 LLM 质量的关键组成部分。我们演示了两个实验，表明可以通过操纵标记概率来改进解码方法。首先，我们在 SummEval 摘要评分数据集上测试了一些 LLM，以衡量阅读理解能力。我们将贪婪解码的分数与下一个标记分布的预期值进行比较。我们通过大温度缩放 logits 以增加分数的熵。这可以大大提高 SummEval 的性能（就与人类判断的相关性而言）。我们看到 7B Mistral 从 6-8% 提高到 13-28%，Mixtral 从 20%-46% 提高到 37%-56%，在两个指标上都超过了 GPT 4 0314 的结果。部分收益似乎与位置偏差有关。其次，我们使用基于概率的树采样算法来检查给定提示的所有最可能的生成。]]></description>
      <guid>https://arxiv.org/abs/2406.10267</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:36 GMT</pubDate>
    </item>
    <item>
      <title>最佳合成嵌入</title>
      <link>https://arxiv.org/abs/2406.10259</link>
      <description><![CDATA[arXiv:2406.10259v1 公告类型：新
摘要：在本文中，我们介绍了一种基于直观想法的词嵌入组合方法，即给定一组词的公平嵌入表示应满足新向量与其每个成分的向量表示的距离相同，并且该距离应最小化。嵌入组合方法可以与静态和上下文化的词表示一起使用，它可以应用于创建句子的表示，也可以学习不一定按序列组织的词集的表示。我们从理论上描述了这种表示存在的条件并得出了解决方案。我们在数据增强和句子分类任务中评估了该方法，研究了嵌入和组合方法的几种设计选择。我们表明，我们的方法在解决旨在捕捉句子简单语言特征的探测任务方面表现出色。]]></description>
      <guid>https://arxiv.org/abs/2406.10259</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:35 GMT</pubDate>
    </item>
    <item>
      <title>Flextron：多合一灵活大型语言模型</title>
      <link>https://arxiv.org/abs/2406.10260</link>
      <description><![CDATA[arXiv:2406.10260v1 公告类型：新
摘要：训练现代 LLM 极其耗费资源，通过重复训练来定制它们以适应以有限的计算和内存资源为特征的各种部署场景是不切实际的。在本文中，我们介绍了 Flextron，这是一种支持灵活模型部署的网络架构和训练后模型优化框架。Flextron 架构利用嵌套弹性结构在推理过程中快速适应特定的用户定义的延迟和准确性目标，而无需进行额外的微调。它还具有输入自适应性，并且可以自动通过其子网络路由令牌以提高性能和效率。我们提出了一种样本高效的训练方法和相关的路由算法，用于系统地将现有的训练过的 LLM 转换为 Flextron 模型。我们在 GPT-3 和 LLama-2 系列 LLM 上对 Flextron 进行了评估，并展示了在多个端到端训练变体和其他最先进的弹性网络上的卓越性能，所有这些都只需一次预训练运行，与原始预训练相比仅消耗 7.63% 的令牌。]]></description>
      <guid>https://arxiv.org/abs/2406.10260</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:35 GMT</pubDate>
    </item>
    <item>
      <title>FoodSky：通过厨师和营养师考试的面向食品的大型语言模型</title>
      <link>https://arxiv.org/abs/2406.10261</link>
      <description><![CDATA[arXiv:2406.10261v1 公告类型：新
摘要：食物是人类生活的基础，不仅是营养来源，也是文化认同和社会互动的基石。随着全球饮食需求和偏好的复杂性日益增加，需要食品智能来实现各种任务的食物感知和推理，从食谱生成和饮食推荐到饮食与疾病相关性的发现和理解。为了实现这一目标，为了在大型语言模型 (LLM) 中实现跨各个领域和任务的强大功能，我们引入了面向食物的 LLM FoodSky，通过感知和推理来理解食物数据。考虑到中国菜的复杂性和典型性，我们首先从各种权威来源构建了一个全面的中国食物语料库 FoodEarth，FoodSky 可以利用该语料库来深入了解与食物相关的数据。然后，我们提出了基于主题的选择性状态空间模型 (TS3M) 和分层主题检索增强生成 (HTRAG) 机制，以分别增强 FoodSky 在捕获细粒度食品语义和生成上下文感知的食品相关文本方面的能力。我们广泛的评估表明，FoodSky 在厨师和营养学考试中的表现明显优于通用 LLM，在中国国家厨师考试和国家营养学考试中的准确率分别为 67.2% 和 66.4%。FoodSky 不仅有望提高烹饪创造力并促进更健康的饮食模式，而且还为解决食品领域复杂现实问题的领域特定 LLM 树立了新标准。FoodSky 的在线演示可在 http://222.92.101.211:8200 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.10261</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:35 GMT</pubDate>
    </item>
    <item>
      <title>改进情感分析的语言模型：来自认知科学的见解</title>
      <link>https://arxiv.org/abs/2406.10265</link>
      <description><![CDATA[arXiv:2406.10265v1 公告类型：新
摘要：我们建议利用认知科学对情感和交流的研究来改进用于情感分析的语言模型。首先，我们介绍心理学和认知科学中的主要情感理论。然后，我们介绍自然语言处理中情感注释的主要方法及其与心理学理论的联系。我们还介绍了认知语用学中情感交流的两种主要分析类型。最后，基于所提出的认知科学研究，我们提出了改进用于情感分析的语言模型的方向。我们认为这些研究工作为构建新的注释方案和情感理解的可能基准铺平了道路，考虑到人类情感和交流的不同方面。]]></description>
      <guid>https://arxiv.org/abs/2406.10265</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:35 GMT</pubDate>
    </item>
    <item>
      <title>语言建模的显式词密度估计</title>
      <link>https://arxiv.org/abs/2406.10256</link>
      <description><![CDATA[arXiv:2406.10256v1 公告类型：新
摘要：语言建模长期以来一直是自然语言处理的核心部分，在过去几年中，基于 LSTM 的语言模型已成为商业语言建模的首选方法。最近，有研究表明，从矩阵分解的角度来看语言建模时，最后的 Softmax 层通过对结果矩阵的秩设置上限来限制模型的表达能力。此外，一种新的基于神经网络的系列称为 NeuralODE，已被引入作为残差网络的连续替代方案。此外，已经证明这些模型与规范化流之间存在联系。在这项工作中，我们提出了一种基于 NeuralODE 和规范化流的连续模拟的新型语言模型系列，并设法改进了一些基线。]]></description>
      <guid>https://arxiv.org/abs/2406.10256</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:34 GMT</pubDate>
    </item>
    <item>
      <title>以全球视角整理扎实的合成数据，实现公平的人工智能</title>
      <link>https://arxiv.org/abs/2406.10258</link>
      <description><![CDATA[arXiv:2406.10258v2 公告类型：新
摘要：稳健的人工智能模型的开发在很大程度上依赖于可用训练数据的质量和多样性。在数据稀缺普遍存在的领域，合成数据生成提供了至关重要的解决方案。在本文中，我们介绍了一种创建合成数据集的新方法，该方法以现实世界的多样性为基础，并通过战略多样化得到丰富。我们使用涵盖 12 种语言和来自 125 个国家的综合新闻文章集合来合成数据，以确保语言和文化表征的广度。通过强制主题多样化、翻译和摘要，生成的数据集准确反映了现实世界的复杂性，并解决了传统数据集中代表性不足的问题。这种方法最初应用于命名实体识别 (NER)，可作为众多人工智能学科的模型，其中数据多样化对于通用性至关重要。初步结果表明，传统 NER 基准测试的性能显著提升，最高提升 7.3%，凸显了我们的合成数据在模仿全球数据源丰富多样的细微差别方面的有效性。本文概述了合成不同数据集所采用的策略，并为 NER 提供了这样一个精选数据集。]]></description>
      <guid>https://arxiv.org/abs/2406.10258</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:34 GMT</pubDate>
    </item>
    <item>
      <title>量化对检索增强生成的影响：对小型 LLM 的分析</title>
      <link>https://arxiv.org/abs/2406.10251</link>
      <description><![CDATA[arXiv:2406.10251v1 公告类型：新
摘要：训练后量化降低了大型语言模型 (LLM) 的计算需求，但可能会削弱其部分功能。由于 LLM 能力随着规模的扩大而出现，较小的 LLM 对量化更敏感。在本文中，我们探讨了量化如何影响较小的 LLM 执行检索增强生成 (RAG) 的能力，特别是在较长的上下文中。我们选择个性化进行评估，因为它是一个使用 RAG 执行的具有挑战性的领域，因为它需要对多个文档进行长上下文推理。我们在两个任务上比较了多个 7B 和 8B LLM 的原始 FP16 和量化 INT4 性能，同时逐步增加检索到的文档数量，以测试量化模型在较长上下文中的表现。为了更好地理解检索的效果，我们在实验中评估了三种检索模型。我们的研究结果表明，如果 7B LLM 能够很好地完成任务，量化不会损害其性能和长上下文推理能力。我们得出结论，可以将 RAG 与量化的较小 LLM 结合使用。]]></description>
      <guid>https://arxiv.org/abs/2406.10251</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:33 GMT</pubDate>
    </item>
    <item>
      <title>新兴概念词典的自动开发：方法论探索</title>
      <link>https://arxiv.org/abs/2406.10253</link>
      <description><![CDATA[arXiv:2406.10253v1 公告类型：新
摘要：本文介绍了以新兴概念为中心的词典的开发，重点关注非技术创新。它介绍了一种四步方法，该方法结合了人类专业知识、统计分析和机器学习技术，以建立一个可以跨多个领域推广的模型。这个过程包括创建主题语料库、开发黄金标准词典、注释和准备训练语料库，最后实施学习模型以识别新术语。结果证明了我们的方法的稳健性和相关性，突出了它对各种环境的适应性及其对词汇研究的贡献。所开发的方法有望应用于概念领域。]]></description>
      <guid>https://arxiv.org/abs/2406.10253</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:33 GMT</pubDate>
    </item>
    <item>
      <title>面向大型语言模型的信号处理</title>
      <link>https://arxiv.org/abs/2406.10254</link>
      <description><![CDATA[arXiv:2406.10254v1 公告类型：新
摘要：本文介绍了在大型语言模型 (LLM) 中应用信号处理的想法。随着最近生成式人工智能的爆炸式增长，我们的工作可以帮助将两个领域联系在一起，即信号处理领域和大型语言模型。我们将经典傅里叶变换和傅里叶变换类可学习时频表示与 LLM 的每个中间激活信号进行比较。一旦我们将每个跨 token 的激活信号分解为时频表示，我们就会学习如何过滤和重建它们，所有组件都是从头开始学习的，以根据先前的上下文预测下一个 token。我们表明，对于类似 GPT 的架构，我们的工作通过添加极少量的额外参数在相同的时期内进行训练，实现了更快的收敛并显着提高了性能。我们希望这项工作为探索 LLM 等神经架构中的信号内部信号处理的算法铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2406.10254</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:33 GMT</pubDate>
    </item>
    <item>
      <title>WarCov——来自社交平台的大型多标签和多模式数据集</title>
      <link>https://arxiv.org/abs/2406.10255</link>
      <description><![CDATA[arXiv:2406.10255v1 公告类型：新
摘要：在分类任务中，从原始数据采集到适合用于评估机器学习模型的数据集的整理，一系列步骤（通常与高成本相关）是必要的。在自然语言处理的情况下，初始清理和转换可以自动执行，但获取标签仍然需要人类专家的合理输入。因此，尽管许多文章经常说“世界充满了数据”，但数据科学家却遭受数据短缺的困扰。这对于自然语言应用至关重要，因为它不断发展，必须适应新的概念或事件。例如，COVID-19 大流行的主题及其相关词汇在 2019 年之前几乎无法识别。因此，创建新的数据集（包括英语以外的语言）仍然至关重要。本研究展示了 2022 年在流行社交媒体平台上发布的关于疫情和乌克兰战争的 3~187~105 条波兰语帖子。该集合不仅包括预处理文本，还包括图像，因此也可以用于多模态识别任务。标签定义帖子的主题，并使用帖子附带的主题标签创建。本研究介绍了从获取到样本模式识别实验的数据集整理过程。]]></description>
      <guid>https://arxiv.org/abs/2406.10255</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:33 GMT</pubDate>
    </item>
    <item>
      <title>早期发现错误信息以进行信息疫情管理：一种领域适应方法</title>
      <link>https://arxiv.org/abs/2406.10238</link>
      <description><![CDATA[arXiv:2406.10238v1 公告类型：新
摘要：信息流行病是指在疾病爆发期间传播的大量真实信息和错误信息。在信息流行病的早期阶段检测错误信息是管理信息流行病和减少其对公众健康危害的关键。早期信息流行病的特点是存在大量与疾病有关的未标记信息。因此，传统的错误信息检测方法不适合这种错误信息检测任务，因为它们依赖信息流行病领域的标记信息来训练模型。为了解决传统方法的局限性，最先进的方法使用其他领域的标记信息来学习模型，以检测信息流行病领域的错误信息。这些方法的有效性取决于它们减轻信息流行病领域和它们利用标记信息的领域之间的协变量转移和概念转移的能力。这些方法侧重于减轻协变量转移，但忽略了概念转移，导致它们在完成任务时效率较低。作为回应，我们从理论上展示了解决协变量转移和概念转移的必要性以及如何实施它们。基于理论分析，我们开发了一种新颖的错误信息检测方法，该方法可以同时解决协变量转移和概念转移问题。使用两个真实世界的数据集，我们进行了广泛的实证评估，以证明我们的方法优于最先进的错误信息检测方法以及可以定制以解决错误信息检测任务的流行领域自适应方法。]]></description>
      <guid>https://arxiv.org/abs/2406.10238</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:32 GMT</pubDate>
    </item>
    <item>
      <title>QCQA：质量和容量感知的分组查询注意</title>
      <link>https://arxiv.org/abs/2406.10247</link>
      <description><![CDATA[arXiv:2406.10247v1 公告类型：新
摘要：键和值特征 (KV-cache) 的过多内存需求给大型语言模型 (LLM) 的自回归推理带来了重大挑战，限制了文本生成的速度和长度。多查询注意 (MQA) 和分组查询注意 (GQA) 等方法通过对查询头进行分组并因此减少相应的键和值头的数量来缓解这些挑战。然而，MQA 和 GQA 以牺牲 LLM 准确性（文本生成质量）为代价降低了 KV-cache 大小要求。由于缺乏对查询头进行质量感知分组，这些方法无法确保 KV-cache 大小和文本生成质量之间的最佳权衡。为了解决这个问题，我们提出了质量和容量感知分组查询注意 (QCQA)，它使用具有计算效率高且成本低的适应度函数的进化算法来识别最佳查询头分组。我们证明，与 GQA 相比，QCQA 在 KV 缓存容量和 LLM 准确度之间实现了更好的平衡。对于 Llama2 $7\,$B 模型，在没有微调的情况下，QCQA 的准确度比 GQA 高 $\mathbf{20}$\%，且 KV 缓存大小要求相似。在对 QCQA 和 GQA 进行微调后，对于相似的 KV 缓存大小，QCQA 的准确度比 GQA 高 $\mathbf{10.55}\,$\%。此外，QCQA 所需的 KV 缓存大小比 GQA 小 $40\,$\%，即可达到相似的准确度。所提出的质量和容量感知查询头分组可以作为自回归 LLM 推理中 KV 缓存优化的新范例。]]></description>
      <guid>https://arxiv.org/abs/2406.10247</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:32 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的最差即时性能</title>
      <link>https://arxiv.org/abs/2406.10248</link>
      <description><![CDATA[arXiv:2406.10248v1 公告类型：新 
摘要：大型语言模型 (LLM) 的性能对提示的措辞极为敏感，这引起了人们对其在现实场景中的可靠性的重大担忧。现有研究通常将提示分为任务级指令和案例级输入，主要侧重于评估和提高对任务级指令变化的鲁棒性。但是，此设置未能完全解决现实世界用户查询的多样性，并假设存在特定于任务的数据集。为了解决这些限制，我们引入了 RobustAlpacaEval，这是一个新的基准，它由语义等效的案例级查询组成，并强调使用最差的提示性能来衡量模型性能下限的重要性。使用 ChatGPT 和来自 Llama、Mistral 和 Gemma 系列的六个开源 LLM 在 RobustAlpacaEval 上进行的大量实验发现模型性能存在很大的差异；例如，Llama-2-70B-chat 模型的最差性能和最佳性能之间的差异为 45.48%，其最差性能下降了 9.38%。我们进一步说明了从与模型无关和与模型相关的角度识别最差提示的难度，强调没有捷径来描述最差提示。我们还尝试使用现有的提示工程和提示一致性方法来增强最差提示的性能，但发现它们的影响有限。这些发现强调需要创建更具弹性的 LLM，以便在不同的提示中保持高性能。]]></description>
      <guid>https://arxiv.org/abs/2406.10248</guid>
      <pubDate>Wed, 19 Jun 2024 03:15:32 GMT</pubDate>
    </item>
    </channel>
</rss>