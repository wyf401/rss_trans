<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 02 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用大型语言模型针对编程中的逻辑错误生成反馈梯形图</title>
      <link>https://arxiv.org/abs/2405.00302</link>
      <description><![CDATA[arXiv:2405.00302v1 公告类型：新
摘要：在编程作业中逻辑错误的反馈生成中，基于大语言模型（LLM）的方法显示出了巨大的前景。这些方法要求法学硕士根据问题陈述和学生（有问题的）提交生成反馈。这些类型的方法存在几个问题。首先，生成的反馈消息通常过于直接地揭示提交中的错误，从而减少了学生学习的宝贵机会。其次，它们没有考虑学生的学习背景，即他们之前提交的内容、当前的知识等。第三，它们不是分层的，因为现有方法对所有学生提交的内容使用单一、共享的提示。在本文中，我们探索使用法学硕士来生成“反馈阶梯”，即同一问题提交对的多个级别的反馈。我们通过与学生、教育工作者和研究人员的用户研究来评估生成的反馈阶梯的质量。在研究中，我们观察到总体上更高级别的反馈和更高分的提交的有效性正在下降。在实践中，我们的方法使教师能够根据学生的个人学习背景选择适当级别的反馈来向学生展示，或者如果更高级别的反馈无法纠正学生的错误，则以渐进的方式提供更详细的信息。]]></description>
      <guid>https://arxiv.org/abs/2405.00302</guid>
      <pubDate>Thu, 02 May 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>我该如何改进？使用 GPT 突出显示开放式响应中所需和不需要的部分</title>
      <link>https://arxiv.org/abs/2405.00291</link>
      <description><![CDATA[arXiv:2405.00291v1 公告类型：新
摘要：自动解释性反馈系统通过提供包含解释的反馈，显着增强学习过程，在促进大量学习者的学习方面发挥着至关重要的作用。然而，实时提供此类解释性反馈会带来挑战，特别是当特定领域的细致入微的响应的高分类精度至关重要时。我们的研究利用大型语言模型，特别是生成式预训练 Transformer (GPT) 的功能，探索一种序列标记方法，重点是识别所需和不太需要的赞美的组成部分，以便在导师训练数据集中提供解释性反馈。我们的目标是在在线培训课程中为导师提供可操作的解释性反馈。为了研究 GPT 模型提供解释性反馈的潜力，我们采用了两种常用的方法：提示和微调。为了量化 GPT 模型识别的突出赞扬成分的质量，我们引入了改进的并集交集 (M-IoU) 分数。我们的研究结果表明：（1）M-IoU 评分与评估序列质量时的人类判断有效相关； (2) 在 GPT-3.5 上使用两次提示在识别基于努力的表扬（M-IoU 为 0.46）和基于结果的表扬（M-IoU 为 0.68）方面取得了不错的表现； (3) 经过优化微调的 GPT-3.5 模型，基于努力的表扬的 M-IoU 分数为 0.64，基于结果的表扬的 M-IoU 分数为 0.84，与人类编码员评估的满意度水平一致。我们的结果显示了使用 GPT 模型提供反馈的前景，这些反馈侧重于开放式响应中需要或需要改进的特定元素。]]></description>
      <guid>https://arxiv.org/abs/2405.00291</guid>
      <pubDate>Thu, 02 May 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>LITO：用于真实性优化的可学习干预</title>
      <link>https://arxiv.org/abs/2405.00301</link>
      <description><![CDATA[arXiv:2405.00301v1 公告类型：新
摘要：大型语言模型 (LLM) 可以生成长篇连贯的文本，但它们仍然经常产生幻觉事实，从而限制了它们的可靠性。为了解决这个问题，已经提出了通过将 LLM 表示转向学习到的“真实方向”来引出真实反应的推理时间方法。然而，以相同的强度应用真实方向无法推广到不同的问题上下文。我们提出了 LITO，一种用于真实性优化的可学习干预方法，可自动识别针对特定上下文的最佳干预强度。LITO 探索了基于不断增加的干预强度的模型生成序列。当预测高度不确定时，它会选择最准确的响应或拒绝回答。在多个 LLM 和问答数据集上的实验表明，LITO 提高了真实性，同时保持了任务准确性。 LITO 的适应性解决了基于一刀切干预的解决方案的问题，通过仅在模型有信心时反映内部知识来最大限度地提高模型的真实性。]]></description>
      <guid>https://arxiv.org/abs/2405.00301</guid>
      <pubDate>Thu, 02 May 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>用于非认知技能学习的社交生活模拟</title>
      <link>https://arxiv.org/abs/2405.00273</link>
      <description><![CDATA[arXiv:2405.00273v1 公告类型：新
摘要：非认知技能对于个人和社会生活的福祉至关重要，这种技能的发展可以通过基于叙事（例如讲故事）的技术来支持。虽然生成式人工智能可以实现交互式和角色扮演的故事讲述，但人们对于用户如何参与和感知人工智能在社交生活模拟中用于非认知技能学习的情况知之甚少。为此，我们推出了 SimuLife++，这是一个由大型语言模型 (LLM) 支持的交互式平台。该系统允许用户扮演主角，在不同的社交场景中与一个或多个人工智能角色一起创作故事。特别是，我们通过引入一个智者代理，将人与人工智能的交互扩展到人与人工智能的协作，智者充当旁观者，为用户的选择和对话提供更有洞察力的观点。通过一项受试者内用户研究，我们发现，根据叙事传输尺度，圣人代理的加入显着增强了叙事沉浸感，从而产生更多消息，尤其是在群聊中。参与者与圣人的互动也与他们的感知动机、自我认知、复原力和应对能力的得分显着提高相关，这表明对非认知技能反思有积极影响。参与者的访谈结果进一步解释了圣人在决策、解决道德困境和解决问题方面的辅助作用；另一方面，他们建议改进用户控制和平衡多个角色的响应。我们提供了生成式人工智能在更广泛的社会背景下非认知技能发展的叙事解决方案中应用的设计启示。]]></description>
      <guid>https://arxiv.org/abs/2405.00273</guid>
      <pubDate>Thu, 02 May 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>对话蕴涵任务的对抗性攻击和防御</title>
      <link>https://arxiv.org/abs/2405.00289</link>
      <description><![CDATA[arXiv:2405.00289v1 公告类型：新
摘要：大型语言模型（LLM）已被证明在不同的NLP任务上非常强大。然而，仍然有很多方法可以以非常低的成本攻击模型。如何防御模型成为一个重要的问题。在我们的工作中，我们将对抗性攻击结果视为模型的一个新（看不见的）领域，并将防御问题框架化为如何提高模型在新领域的鲁棒性。我们专注于对话蕴涵的任务，其中多轮自然语言对话是前提，并且对Transformer模型进行微调以预测关于给定对话的给定假设是真还是假。对手会攻击假设以欺骗模型做出错误的预测。我们采用同义词交换作为攻击方法。为了展示模型的鲁棒性，我们实现了一些微调策略并提出了嵌入扰动损失作为一种提高模型鲁棒性的方法。最后，我们通过讨论现实世界中 NLP 中的对抗性攻击来展示我们工作的重要性。]]></description>
      <guid>https://arxiv.org/abs/2405.00289</guid>
      <pubDate>Thu, 02 May 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>CodeHalu：基于执行的验证驱动法学硕士中的代码幻觉</title>
      <link>https://arxiv.org/abs/2405.00253</link>
      <description><![CDATA[arXiv:2405.00253v1 公告类型：新 
摘要：大型语言模型（LLM）在代码生成领域取得了重大进展，为自动化编程提供了前所未有的支持并协助开发人员。然而，LLM 有时会生成看似合理但未能满足预期要求或执行不正确的代码。编码领域的这种幻觉现象尚未被探索过。为了促进社区对 LLM 中代码幻觉的理解和研究，我们提出了一种基于执行验证的幻觉定义方法，并首次引入了代码幻觉的概念。我们将代码幻觉分为四种主要类型：映射、命名、资源和逻辑幻觉，每种类型进一步分为不同的子类别，以更好地理解和解决 LLM 在代码生成过程中面临的独特挑战。为了系统地评估代码幻觉，我们提出了一种代码幻觉的动态检测算法，并构建了 CodeHalu 基准，该基准包括来自 699 个任务的 8,883 个样本，用于在编程过程中主动检测 LLM 中的幻觉现象。我们在这个基准上测试了 16 个流行的 LLM，以评估它们在代码生成过程中幻觉的频率和性质。研究结果显示，LLM 在生成代码的准确性和可靠性方面存在显著差异，凸显了改进模型和训练方法以确保自动生成代码的功能正确性和安全性的迫切需要。这项研究不仅对代码幻觉进行了分类和量化，还为未来基于 LLM 的代码生成研究的改进提供了见解。CodeHalu 基准和代码已公开发布在 https://github.com/yuchen814/CodeHalu。]]></description>
      <guid>https://arxiv.org/abs/2405.00253</guid>
      <pubDate>Thu, 02 May 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>Clover：具有顺序知识的回归轻量级推测解码</title>
      <link>https://arxiv.org/abs/2405.00263</link>
      <description><![CDATA[arXiv:2405.00263v1 公告类型：新
摘要：由于自回归解码的要求与大多数当代 GPU 的设计不匹配，大型语言模型（LLM）效率低下。具体来说，数十亿到数万亿个参数必须通过其有限的内存带宽加载到GPU缓存中进行计算，但实际上只计算了一小批令牌。因此，GPU 的大部分时间都花在内存传输上，而不是计算上。最近，并行解码（一种推测解码算法）变得越来越流行，并且在生成过程中表现出了令人印象深刻的效率提高。它向大型模型引入了额外的解码头，使它们能够同时预测多个后续标记，并在单个解码步骤中验证这些候选延续。然而，这种方法偏离了预训练期间使用的下一个令牌预测的训练目标，导致候选令牌的命中率较低。在本文中，我们提出了一种新的推测解码算法 Clover，它将顺序知识集成到并行解码过程中。这一增强提高了投机者的命中率，从而提高了整体效率。 Clover 通过回归连接传输预先推测的令牌的顺序知识，然后使用注意力解码器来整合这些推测的令牌。此外，Clover 还包含一个增强块，可以修改隐藏状态，以更好地符合推测生成的目的，而不是下一个代币预测。实验结果表明，Clover 在 Baichuan-Small 上的性能比基线高出 91%，在 Baichuan-Large 上的性能比基线高出 146%，在 Baichuan-Large 上的性能比之前表现最好的方法 Medusa 的性能高出 37%。小号和百川大号分别占 57%。]]></description>
      <guid>https://arxiv.org/abs/2405.00263</guid>
      <pubDate>Thu, 02 May 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformer 的语言模型内部工作原理入门</title>
      <link>https://arxiv.org/abs/2405.00208</link>
      <description><![CDATA[arXiv:2405.00208v1 公告类型：新
摘要：旨在解释高级语言模型内部运作的研究的快速进展突出表明需要将从该领域多年的工作中获得的见解结合起来。本入门书对用于解释基于 Transformer 的语言模型的内部工作原理的当前技术进行了简明的技术介绍，重点关注仅生成解码器的架构。最后，我们对这些模型实现的已知内部机制进行了全面概述，揭示了该领域流行方法和活跃研究方向之间的联系。]]></description>
      <guid>https://arxiv.org/abs/2405.00208</guid>
      <pubDate>Thu, 02 May 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>图解推理：基于LLM的半开放关系抽取</title>
      <link>https://arxiv.org/abs/2405.00216</link>
      <description><![CDATA[arXiv:2405.00216v1 公告类型：新
摘要：本文对利用高级语言模型，特别是思想链（CoT）和图形推理（GRE）技术的关系提取进行了全面的探索。我们演示了如何利用 GPT-3.5 的上下文学习来显着增强提取过程，特别是通过详细的基于示例的推理。此外，我们引入了一种新颖的图形推理方法，将关系提取分解为顺序子任务，提高处理复杂关系数据的精度和适应性。我们在多个数据集（包括手动注释的数据）上进行的实验显示了性能指标的显着改进，强调了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.00216</guid>
      <pubDate>Thu, 02 May 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>SPAFIT：针对预训练大型语言模型的分层渐进适应微调</title>
      <link>https://arxiv.org/abs/2405.00201</link>
      <description><![CDATA[arXiv:2405.00201v1 公告类型：新
摘要：完全微调是一种流行的方法，可以使基于 Transformer 的预训练大语言模型适应特定的下游任务。然而，对计算能力和存储的大量要求阻碍了其广泛使用。此外，越来越多的证据表明 Transformer 架构中存在灾难性遗忘和过度参数化，这促使研究人员寻求更有效的微调（PEFT）方法。 LoRA 和 BitFit 等众所周知的参数高效微调方法通常应用于模型的所有层。我们提出了一种称为分层渐进适应微调（SPAFIT）的 PEFT 方法，该方法基于不同类型的语言知识到模型特定层的本地化。我们对 GLUE 基准测试的九个任务进行的实验表明，我们提出的 SPAFIT 方法优于其他 PEFT 方法，同时仅微调其他方法调整的一小部分参数。]]></description>
      <guid>https://arxiv.org/abs/2405.00201</guid>
      <pubDate>Thu, 02 May 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>思维提示链的通用验证</title>
      <link>https://arxiv.org/abs/2405.00204</link>
      <description><![CDATA[arXiv:2405.00204v1 公告类型：新
摘要：大型语言模型（LLM）最近展示的许多功能主要源于它们利用上下文信息的能力。在本文中，我们通过（1）探索不同的思想链和（2）验证推理过程的各个步骤来探索提高法学硕士推理能力的方法。我们提出模型在推理时应遵循的三个一般原则：(i) 相关性、(ii) 数学准确性和 (iii) 逻辑一致性。我们将这些约束应用于 LLM 生成的推理步骤，以提高最终生成的准确性。约束以验证器的形式应用：要求模型本身验证生成的步骤是否满足每个约束。为了进一步引导几代人走向高质量的解决方案，我们使用推理步骤的复杂性作为额外的验证器。我们在 4 种不同类型的推理任务上评估我们的方法，涵盖总共 9 个不同的数据集。实验表明，我们的方法始终优于普通生成，并且在 9 个数据集中的 6 个数据集中，它优于 N 次最佳采样（对 N 个推理链进行采样并选择最低困惑度的生成）。]]></description>
      <guid>https://arxiv.org/abs/2405.00204</guid>
      <pubDate>Thu, 02 May 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>迈向机器搜索引擎：多种检索增强大型语言模型的统一排名</title>
      <link>https://arxiv.org/abs/2405.00175</link>
      <description><![CDATA[arXiv:2405.00175v1 公告类型：新
摘要：本文介绍了 uRAG——一个具有统一检索引擎的框架，可为多个下游检索增强生成 (RAG) 系统提供服务。每个 RAG 系统都会将检索结果用于独特的目的，例如开放域问答、事实验证、实体链接和关系提取。我们引入了一个通用的训练指南，该指南规范了搜索引擎与参与优化检索模型的下游 RAG 系统之间的通信。这为我们构建一个大规模实验生态系统奠定了基础，该生态系统由 18 个参与训练的 RAG 系统和 18 个使用 uRAG 作为搜索引擎新用户的未知 RAG 系统组成。利用这个实验生态系统，我们回答了许多基础研究问题，这些问题加深了我们对开发机器搜索引擎的前景和挑战的理解。]]></description>
      <guid>https://arxiv.org/abs/2405.00175</guid>
      <pubDate>Thu, 02 May 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>使用长上下文模型的上下文学习：深入探索</title>
      <link>https://arxiv.org/abs/2405.00200</link>
      <description><![CDATA[arXiv:2405.00200v1 公告类型：新
摘要：随着模型上下文长度的不断增加，可以在上下文中提供的演示数量接近整个训练数据集的大小。我们在多个数据集和模型上研究这种极端规模的情境学习（ICL）行为。我们表明，对于许多具有大标签空间的数据集，性能随着数百或数千次演示而持续提高。我们将其与示例检索和微调进行对比：示例检索在较短的上下文长度下表现出出色的性能，但随着演示的增多，效果有所减弱；微调比 ICL 需要更多数据，但有时可以通过额外数据超越长上下文 ICL 性能。我们使用此 ICL 设置作为测试平台来研究上下文学习和长上下文模型的几个属性。我们证明，长上下文 ICL 对随机输入改组的敏感度低于短上下文 ICL，相同标签示例的分组会对性能产生负面影响，并且我们看到的性能提升并不是来自将许多示例编码在一起的累积增益。我们的结论是，虽然长上下文 ICL 可能非常有效，但大部分收益来自于回顾类似的例子而不是任务学习。]]></description>
      <guid>https://arxiv.org/abs/2405.00200</guid>
      <pubDate>Thu, 02 May 2024 06:17:28 GMT</pubDate>
    </item>
    <item>
      <title>变革荷兰语：消除荷兰语非二元代词共指解析系统的偏差</title>
      <link>https://arxiv.org/abs/2405.00134</link>
      <description><![CDATA[arXiv:2405.00134v1 公告类型：新
摘要：西方语言中越来越多地引入中性代词。然而，最近的评估表明，英语 NLP 系统无法正确处理性别中性代词，存在删除和错误性别化非二元个体的风险。本文研究了荷兰共指消解系统在中性代词（特别是 hen 和 die）上的表现。与英语中长期存在的单数they相比，这些代词在荷兰语中直到2016年才被引入。我们还比较了非二元上下文中共指消解系统的两种去偏技术：反事实数据增强（CDA）和去词汇化。此外，由于代词性能很难用 LEA 这样的通用评估指标来解释，因此我们引入了一种创新的评估指标，即代词得分，它直接表示正确处理代词的部分。我们的结果显示，与有性别的代词相比，中性代词的表现有所下降。然而，尽管去词汇化未能带来改进，但 CDA 大大缩小了性别代词和性别中性代词之间的性能差距。我们进一步表明，CDA 在资源匮乏的环境中仍然有效，其中使用了一组有限的去偏文档。这种功效延伸到了以前未见过的新代词，这些新代词目前很少使用，但将来可能会流行起来，强调了以最少的资源和较低的计算成本进行有效去偏的可行性。]]></description>
      <guid>https://arxiv.org/abs/2405.00134</guid>
      <pubDate>Thu, 02 May 2024 06:17:27 GMT</pubDate>
    </item>
    <item>
      <title>HistNERo：罗马尼亚语历史命名实体识别</title>
      <link>https://arxiv.org/abs/2405.00155</link>
      <description><![CDATA[arXiv:2405.00155v1 公告类型：新
摘要：本文介绍了 HistNERo，这是历史报纸中第一个用于命名实体识别（NER）的罗马尼亚语语料库。该数据集包含 323k 个文本标记，涵盖 19 世纪的一半以上（即 1817 年）直到 20 世纪末期（即 1990 年）。八位罗马尼亚语母语人士用五个命名实体对数据集进行了注释。这些样本属于罗马尼亚以下四个历史地区之一，即比萨拉比亚、摩尔达维亚、特兰西瓦尼亚和瓦拉几亚。我们利用这个提出的数据集，使用罗马尼亚语预训练语言模型进行了多项 NER 实验。我们的结果表明，最好的模型达到了 55.69% 的严格 F1 分数。此外，通过一种新颖的领域适应技术减少区域之间的差异，我们将该语料库的性能提高到严格的 F1 分数 66.80%，绝对增益超过 10%。]]></description>
      <guid>https://arxiv.org/abs/2405.00155</guid>
      <pubDate>Thu, 02 May 2024 06:17:27 GMT</pubDate>
    </item>
    </channel>
</rss>