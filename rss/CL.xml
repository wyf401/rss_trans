<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Thu, 09 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>针对印度语言微调预训练命名实体识别模型</title>
      <link>https://arxiv.org/abs/2405.04829</link>
      <description><![CDATA[arXiv:2405.04829v1 公告类型：新
摘要：命名实体识别（NER）是自然语言处理（NLP）应用中的一个有用组件。它用于各种任务，例如机器翻译、摘要、信息检索和问答系统。 NER的研究主要集中在英语和其他一些主要语言，而对印度语言的关注有限。我们分析了挑战并提出了可以为印度语言的多语言命名实体识别量身定​​制的技术。我们提出了一个人工注释的命名实体语料库，其中包含来自印度两个主要语系的 4 种印度语言的 4 万个句子。此外，我们提出了一个在我们的数据集上进行微调的多语言模型，该模型在我们的数据集上的平均 F1 分数为 0.80。我们在完全看不见的印度语言基准数据集上实现了可比较的性能，这证实了我们模型的可用性。]]></description>
      <guid>https://arxiv.org/abs/2405.04829</guid>
      <pubDate>Thu, 09 May 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>基于提示的方法的逻辑否定增强和去偏</title>
      <link>https://arxiv.org/abs/2405.04872</link>
      <description><![CDATA[arXiv:2405.04872v1 公告类型：新
摘要：基于提示的方法在 NLP 领域受到越来越多的关注，并在许多下游任务中显示出有效性。许多工作都集中于挖掘这些方法在知识提取方面的潜力，但很少探讨它们进行逻辑推理的能力。在这项工作中，我们关注基于提示的方法在一阶逻辑推理上的有效性，发现瓶颈在于逻辑否定。根据我们的分析，逻辑否定往往会导致与否定答案的虚假相关，而没有逻辑否定的命题则与肯定答案相关。为了解决这个问题，我们提出了一种简单但有效的方法，否定增强和否定去偏（NAND），它将否定命题引入基于提示的方法而不更新参数。具体来说，这些否定命题可以通过为所有实例提供“not”来抵消虚假相关性，以便模型不能仅根据表达式是否包含逻辑否定来做出决策。在三个数据集上的实验表明，NAND 不仅解决了校准逻辑否定的问题，而且还显着增强了基于提示的逻辑推理方法，而无需模型重新训练。]]></description>
      <guid>https://arxiv.org/abs/2405.04872</guid>
      <pubDate>Thu, 09 May 2024 06:17:45 GMT</pubDate>
    </item>
    <item>
      <title>APrompt4EM：广义实体匹配的增强提示调整</title>
      <link>https://arxiv.org/abs/2405.04820</link>
      <description><![CDATA[arXiv:2405.04820v1 公告类型：新
摘要： 广义实体匹配（GEM）旨在判断以不同格式表示的两条记录是否指向同一现实世界实体，是数据管理中的一项重要任务。预训练语言模型（PLM）的即时调优范例，包括最近的 PromptEM 模型，有效解决了实际应用中资源匮乏的 GEM 挑战，在标记数据稀缺时提供了强大的解决方案。然而，现有的GEM即时调优模型面临着即时设计和信息鸿沟的挑战。本文介绍了针对挑战的增强提示调整框架，其中包括两个主要改进。第一个是基于增强上下文软令牌的提示调整方法，该方法为 PLM 的提示调整提取指导性软令牌优势，第二个是利用大型语言模型 (LLM) 的经济高效的信息增强策略。我们的方法在低资源 GEM 挑战中表现良好。大量实验表明，与基于中等规模 PLM 的现有方法（平均 5.24%+）相比，我们的没有信息增强的基本模型取得了有希望的进步，并且我们的信息增强模型与微调的 LLM 相比，使用了不到 14% 的时间，实现了与微调的 LLM 相当的性能。 API 费用。]]></description>
      <guid>https://arxiv.org/abs/2405.04820</guid>
      <pubDate>Thu, 09 May 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>ChuXin: 1.6B Technical Report</title>
      <link>https://arxiv.org/abs/2405.04828</link>
      <description><![CDATA[arXiv:2405.04828v1 公告类型：新
摘要：在这份报告中，我们提出了 ChuXin，一个完全开源的语言模型，拥有 16 亿个参数。与大多数仅开源模型权重和架构的作品不同，我们已经提供了训练模型所需的一切，包括训练数据、训练过程和评估代码。我们的目标是增强和加强开放研究社区的能力，提高透明度并推动语言建模领域的新一波创新浪潮。此外，我们通过轻量级持续预训练将上下文长度扩展到 1M 个 token，并展示了强大的大海捞针检索性能。两种模型的权重均可在 Hugging Face 上下载和使用。]]></description>
      <guid>https://arxiv.org/abs/2405.04828</guid>
      <pubDate>Thu, 09 May 2024 06:17:44 GMT</pubDate>
    </item>
    <item>
      <title>零样本法学硕士指导的文本反事实生成</title>
      <link>https://arxiv.org/abs/2405.04793</link>
      <description><![CDATA[arXiv:2405.04793v1 公告类型：新
摘要：在许多自然语言处理（NLP）任务中，反事实示例经常用于模型开发和评估。尽管已经探索了自动反事实生成的方法，但此类方法依赖于诸如预先训练的语言模型之类的模型，然后在辅助的、通常特定于任务的数据集上进行微调。收集和注释此类用于反事实生成的数据集是劳动密集型的，因此在实践中不可行。因此，在这项工作中，我们专注于一个新颖的问题设置：\textit{零样本反事实生成}。为此，我们提出了一种利用大型语言模型（LLM）作为通用反事实示例生成器的结构化方法。我们假设，最近法学硕士的指令跟踪和文本理解能力可以有效地利用，以零样本的方式生成高质量的反事实，而不需要任何培训或微调。通过对自然语言处理（NLP）中各种下游任务的综合实验，我们证明了法学硕士作为零样本反事实生成器在评估和解释黑盒 NLP 模型方面的功效。]]></description>
      <guid>https://arxiv.org/abs/2405.04793</guid>
      <pubDate>Thu, 09 May 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>ACORN：按方面常识推理解释评估</title>
      <link>https://arxiv.org/abs/2405.04818</link>
      <description><![CDATA[arXiv:2405.04818v1 公告类型：新
摘要：评估自由文本解释是一项多方面的、主观的、劳动密集型的任务。大型语言模型 (LLM) 因其一致性、可扩展性和成本效益的潜力而成为一种有吸引力的替代方案。在这项工作中，我们提出了 ACORN，一个包含 3,500 个自由文本解释和方面质量评级的新数据集，并使用它来深入了解法学硕士如何评估解释。我们观察到，替换其中一项人工评分有时会维持不变，但更常见的是降低不同设置和质量方面的注释者间一致性，这表明他们的判断并不总是与人工评分者一致。我们通过比较法学硕士生成的评级与不同质量方面的多数投票的人类评级之间的相关性，进一步量化了这种差异。在最好的系统中，Spearman 的等级相关性在 0.53 到 0.95 之间，各个方面的平均值为 0.72，表明一致性较高但不完美。最后，我们考虑了当人类评估员稀缺时使用法学硕士作为额外评估员的替代方案，并与原始黄金标签相比，测量了有限人力库的多数投票标签与法学硕士作为额外评估员之间的相关性。虽然 GPT-4 在只有两名人类评估者时改善了结果，但在所有其他观察到的案例中，当有三名或更多人类评估者时，法学硕士是中性甚至有害的。我们公开发布数据集，以支持 LLM-in-the-loop 评估的未来改进：https://github.com/a-brassard/ACORN。]]></description>
      <guid>https://arxiv.org/abs/2405.04818</guid>
      <pubDate>Thu, 09 May 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>DALK：LLM 和 KG 的动态联合增强，用科学文献回答阿尔茨海默病问题</title>
      <link>https://arxiv.org/abs/2405.04819</link>
      <description><![CDATA[arXiv:2405.04819v1 公告类型：新
摘要：大型语言模型（LLM）的最新进展在各种应用程序中取得了令人鼓舞的性能。尽管如此，整合长尾知识的持续挑战仍然阻碍了法学硕士在专业领域的无缝采用。在这项工作中，我们引入了 DALK（又名 LLM 和 KG 的动态联合增强）来解决这一限制，并展示其研究阿尔茨海默病 (AD) 的能力，阿尔茨海默病是生物医学的一个专业子领域，也是全球健康的优先事项。通过LLM和KG相互增强的协同框架，我们首先利用LLM构建一个源自AD相关科学文献的不断发展的AD特定知识图谱（KG），然后利用从粗到细的采样方法一种新颖的自我意识知识检索方法，用于从 KG 中选择适当的知识来增强 LLM 推理能力。在我们构建的 AD 问答 (ADQA) 基准上进行的实验结果强调了 DALK 的功效。此外，我们还进行了一系列详细的分析，可以为 KG 和 LLM 相互增强的新兴主题提供有价值的见解和指南。我们将在 https://github.com/David-Li0406/DALK 发布代码和数据。]]></description>
      <guid>https://arxiv.org/abs/2405.04819</guid>
      <pubDate>Thu, 09 May 2024 06:17:43 GMT</pubDate>
    </item>
    <item>
      <title>通过对话界面中的多模态实现同理心</title>
      <link>https://arxiv.org/abs/2405.04777</link>
      <description><![CDATA[arXiv:2405.04777v1 公告类型：新
摘要：代理代表了大型语言模型（LLM）和生成人工智能最新兴的应用之一，其有效性取决于导航复杂用户环境的多模式功能。对话健康代理 (CHA) 就是一个典型的例子，它正在通过提供超越文本分析的细致入微的支持来重新定义医疗保健，并将情商纳入其中。本文介绍了一种基于法学硕士的 CHA，旨在实现丰富的多模式对话，尤其是在心理健康支持领域。它通过分析多模式线索，熟练地解释和响应用户的情绪状态，从而提供上下文感知和移情共鸣的口头响应。我们的实现利用了多功能的 openCHA 框架，我们的综合评估涉及以多种情绪语气表达的中性提示：悲伤、愤怒和快乐。我们评估拟议 CHA 规划能力的一致性和可重复性。此外，人类评估者批评 CHA 的移情交付，调查结果显示 CHA 的输出与评估者的评估之间存在惊人的一致性。这些结果证实了声音（即将成为多模式）情感识别在加强 CHA 建立的同理心联系方面发挥着不可或缺的作用，巩固了他们在交互式、富有同情心的数字健康解决方案的前沿地位。]]></description>
      <guid>https://arxiv.org/abs/2405.04777</guid>
      <pubDate>Thu, 09 May 2024 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>CourseGPT-zh：基于知识蒸馏并结合提示优化的教育大语言模型</title>
      <link>https://arxiv.org/abs/2405.04781</link>
      <description><![CDATA[arXiv:2405.04781v1 公告类型：新
摘要：大语言模型（LLM）在自然语言处理（NLP）任务中表现出了惊人的能力，引发了人们对其应用于具有更高专业要求的专业领域的兴趣。然而，通过API访问闭源LLM的限制以及收集海量高质量数据集的困难，给各类课程教育领域的大型语言模型的开发带来了障碍。鉴于这些挑战，我们提出了CourseGPT-zh，这是一种支持定制和低成本部署的面向课程的教育法学硕士。针对课程语料的全面性和多样性要求，我们设计了一个结合即时优化的高质量问答语料蒸馏框架，有效挖掘课本知识并增强其多样性。此外，考虑到LLM响应与用户需求的一致性，引入了一种基于LLM-as-Judge的离散提示优化的新方法。在优化过程中，该框架利用了法学硕士反思和利用错误反馈和模式的能力，允许提供满足用户需求和偏好的提示，同时节省响应长度。最后，我们通过参数高效的微调，获得了基于开源LLM的CourseGPT-zh。实验结果表明，我们的离散提示优化框架有效提高了ChatGPT的响应质量，CourseGPT-zh在专业知识问答方面表现出强大的专业能力，显着优于同类开源模型。]]></description>
      <guid>https://arxiv.org/abs/2405.04781</guid>
      <pubDate>Thu, 09 May 2024 06:17:42 GMT</pubDate>
    </item>
    <item>
      <title>向语言信息提供者学习音位学</title>
      <link>https://arxiv.org/abs/2405.04726</link>
      <description><![CDATA[arXiv:2405.04726v1 公告类型：新
摘要：我们提出了一种交互式语言学习方法，利用信息提供者（有能力的语言使用者）的语言可接受性判断来学习语法。给定语法形式和合成数据的框架，我们的模型根据一系列信息论策略之一迭代地选择或合成数据点，要求信息提供者进行二元判断，并更新自己的参数，为下一个查询。我们证明了我们的模型在音位学领域的有效性，即管理语言中可接受的声音序列类型的规则，并进行了两项实验，一个使用类型学上自然的语言数据，另一个使用一系列程序生成的数据语言。我们发现，我们的模型用于选择项目来查询线人的信息论策略所达到的样本效率与完全监督的方法相当，有时甚至更高。]]></description>
      <guid>https://arxiv.org/abs/2405.04726</guid>
      <pubDate>Thu, 09 May 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>BiasKG：在大型语言模型中引入偏差的对抗性知识图</title>
      <link>https://arxiv.org/abs/2405.04756</link>
      <description><![CDATA[arXiv:2405.04756v1 公告类型：新
摘要：现代大语言模型（LLM）拥有大量的世界知识，如果利用得当，可以在常识推理和知识密集型任务中表现出色。语言模型还可以学习社会偏见，这很有可能造成社会危害。针对法学硕士的安全性，已经提出了许多缓解策略，但尚不清楚它们对于消除社会偏见的效果如何。在这项工作中，我们提出了一种利用知识图增强生成来攻击语言模型的新方法。我们将自然语言刻板印象重构为知识图谱，并使用对抗性攻击策略来诱导几种开源和闭源语言模型的有偏见的反应。我们发现我们的方法增加了所有模型的偏差，甚至是那些接受过安全护栏训练的模型。这表明需要进一步研究人工智能安全，并在这个新的对抗空间中开展进一步的工作。]]></description>
      <guid>https://arxiv.org/abs/2405.04756</guid>
      <pubDate>Thu, 09 May 2024 06:17:41 GMT</pubDate>
    </item>
    <item>
      <title>了解文化常识的大型语言模型的能力和局限性</title>
      <link>https://arxiv.org/abs/2405.04655</link>
      <description><![CDATA[arXiv:2405.04655v1 公告类型：新
摘要：大型语言模型（LLM）通过大量基准评估展示了丰富的常识性理解。然而，他们对文化常识的理解在很大程度上仍未得到检验。在本文中，我们在文化常识任务的背景下对几位最先进的法学硕士的能力和局限性进行了全面检查。使用几个一般和文化常识基准，我们发现（1）法学硕士在对不同文化的特定文化常识知识进行测试时，表现存在显着差异； （2）法学硕士的一般常识能力受文化背景的影响； (3) 用于查询法学硕士的语言会影响其在文化相关任务上的表现。我们的研究指出了法学硕士文化理解中固有的偏见，并提供了有助于开发文化意识语言模型的见解。]]></description>
      <guid>https://arxiv.org/abs/2405.04655</guid>
      <pubDate>Thu, 09 May 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>架起博斯普鲁斯海峡的桥梁：通过低资源语言适应和基准测试策略推进土耳其大语言模型</title>
      <link>https://arxiv.org/abs/2405.04685</link>
      <description><![CDATA[arXiv:2405.04685v1 公告类型：新
摘要：大型语言模型（LLM）在各个领域变得至关重要，这凸显了在代表性不足的语言中建立高质量模型的紧迫性。本研究探讨了低资源语言面临的独特挑战，例如数据稀缺、模型选择、评估和计算限制，特别关注土耳其语。我们进行深入分析，以评估培训策略、模型选择和数据可用性对针对代表性不足的语言设计的法学硕士表现的影响。我们的方法包括两种方法：（i）调整最初用英语预训练的现有法学硕士以理解土耳其语，以及（ii）使用土耳其语预训练数据从头开始开发模型，两者都辅以新颖的土耳其语指令调整的监督微调旨在增强推理能力的数据集。这些方法的相对表现是通过为土耳其法学硕士创建一个新的排行榜来评估的，该排行榜以评估不同推理和知识技能的基准为特色。此外，我们在预训练和微调过程中进行了数据和模型扩展实验，同时强调跨语言知识转移的能力，并解决不同语言微调过程中遇到的灾难性遗忘的挑战。我们的目标是为在资源匮乏的语言环境中推进法学硕士框架提供详细的指南，从而使自然语言处理（NLP）的优势在全球范围内更容易获得。]]></description>
      <guid>https://arxiv.org/abs/2405.04685</guid>
      <pubDate>Thu, 09 May 2024 06:17:40 GMT</pubDate>
    </item>
    <item>
      <title>PoPE：大型语言模型的基于勒让德正交多项式的位置编码</title>
      <link>https://arxiv.org/abs/2405.04585</link>
      <description><![CDATA[arXiv:2405.04585v1 公告类型：新
摘要：相对于原始 Transformer 中使用的基线绝对位置编码（APE）方法，提出了一些改进。在本研究中，我们的目的是研究在更高维度上不充分表示位置编码对注意机制、模型学习相对位置信息的能力以及模型收敛的关键方面的影响，所有这些都源于正弦基函数的选择。通过理论见解和实证分析的结合，我们阐明了这些挑战如何超出 APE 范围，并可能对相对位置编码 (RPE) 方法（例如旋转位置编码 (RoPE)）的性能产生不利影响。
  随后，我们引入了一种称为基于正交多项式的位置编码（PoPE）的创新解决方案，以解决与现有方法相关的一些限制。 PoPE 方法利用正交勒让德多项式对位置信息进行编码。作为基函数的勒让德多项式为位置编码提供了几个理想的属性，包括改进的相关结构、非周期性、正交性以及不同阶多项式之间的不同函数形式。我们的实验结果表明，在 $Multi30k$ 英德翻译任务中，包含 PoPE 的 Transformer 模型优于基线 Transformer 模型，从而建立了新的性能基准。此外，基于 PoPE 的变压器表现出显着加快的收敛速度。
  此外，我们将基于 PoPE 的优越性能提出关于位置编码的新颖理论观点。]]></description>
      <guid>https://arxiv.org/abs/2405.04585</guid>
      <pubDate>Thu, 09 May 2024 06:17:39 GMT</pubDate>
    </item>
    <item>
      <title>使用张量序列进行语言建模</title>
      <link>https://arxiv.org/abs/2405.04590</link>
      <description><![CDATA[arXiv:2405.04590v1 公告类型：新
摘要：我们提出了一种基于最简单张量网络（即张量训练）的新型张量网络语言模型，称为“张量训练语言模型”（TTLM）。TTLM 在由单词的张量积构成的指数空间中表示句子，但以低维方式计算句子的概率。我们证明二阶 RNN、循环算术电路 (RAC) 和乘法积分 RNN 的架构本质上是 TTLM 的特殊情况。对实际语言建模任务的实验评估表明，所提出的 TTLM 变体（即 TTLM-Large 和 TTLM-Tiny）优于具有低规模隐藏单元的普通循环神经网络 (RNN)。（代码可在 https://github.com/shuishen112/tensortrainlm 获得。）]]></description>
      <guid>https://arxiv.org/abs/2405.04590</guid>
      <pubDate>Thu, 09 May 2024 06:17:39 GMT</pubDate>
    </item>
    </channel>
</rss>