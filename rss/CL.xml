<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 15 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>GPT 作为蒙特卡洛语言树：概率视角</title>
      <link>https://arxiv.org/abs/2501.07641</link>
      <description><![CDATA[arXiv:2501.07641v1 公告类型：新 
摘要：大型语言模型（LLM），例如 GPT，被认为可以学习大规模网络爬取数据集中的潜在分布，并通过预测下一个 token 来完成自然语言处理（NLP）任务。然而，这种潜在分布建模机制缺乏定量的理解和分析。在本文中，我们提出了一个新颖的观点，即任何语言数据集都可以用蒙特卡洛语言树（缩写为“Data-Tree”）表示，其中每个节点表示一个 token，每个边表示一个 token 转换概率，每个序列都有唯一的路径。任何类似 GPT 的语言模型也可以展平为另一个蒙特卡洛语言树（缩写为“GPT-Tree”）。我们的实验表明，在同一数据集上训练的不同 GPT 模型在 GPT-Tree 可视化中表现出明显的结构相似性，并且更大的模型更紧密地收敛到数据树。超过 87% 的 GPT 输出标记可以通过 Data-Tree 回忆起来。这些发现可能证实 LLM 的推理过程更可能是概率模式匹配而不是形式推理，因为每个模型推理似乎都能从 Data-Tree 中找到具有最大概率的上下文模式。此外，我们还对 LLM 中的幻觉、思维链 (CoT) 推理和标记偏见等问题提供了更深入的见解。]]></description>
      <guid>https://arxiv.org/abs/2501.07641</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 LLM 微调进行特征提取，增强人才就业洞察力</title>
      <link>https://arxiv.org/abs/2501.07663</link>
      <description><![CDATA[arXiv:2501.07663v1 公告类型：新
摘要：本文探讨了大型语言模型 (LLM) 在从非结构化招聘信息中提取细微而复杂的工作特征方面的应用。使用 AdeptID 提供的 120 万个招聘信息的数据集，我们开发了一个强大的管道来识别和分类变量，例如远程工作可用性、薪酬结构、教育要求和工作经验偏好。我们的方法结合了语义分块、检索增强生成 (RAG) 和微调 DistilBERT 模型，以克服传统解析工具的局限性。通过利用这些技术，我们在识别经常被错误标记或忽视的变量方面取得了显着的进步，例如非基于工资的薪酬和推断的远程工作类别。我们对微调的模型进行了全面评估，并分析了它们的优势、局限性和扩展潜力。这项工作突出了 LLM 在劳动力市场分析中的前景，为更准确和可操作的工作数据洞察奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2501.07663</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>抽象摘要基准测试：挪威新闻文章人工摘要数据集</title>
      <link>https://arxiv.org/abs/2501.07718</link>
      <description><![CDATA[arXiv:2501.07718v1 公告类型：新
摘要：我们引入了一个由挪威语新闻文章组成的高质量人工摘要数据集。该数据集旨在对生成语言模型的抽象摘要能力进行基准测试。数据集中的每个文档都提供了由挪威语母语人士编写的三个不同的候选黄金标准摘要，并且所有摘要都以挪威语的两种书面变体提供——Bokm{\aa}l 和 Nynorsk。本文详细介绍了数据创建工作以及对数据集上现有的挪威语开放 LLM 的评估。我们还提供了人工评估的见解，将人工编写的摘要与模型生成的摘要进行比较。我们的结果表明，该数据集为挪威语摘要能力提供了一个具有挑战性的 LLM 基准]]></description>
      <guid>https://arxiv.org/abs/2501.07718</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>字里行间蕴含：将蕴含纳入 NLI</title>
      <link>https://arxiv.org/abs/2501.07719</link>
      <description><![CDATA[arXiv:2501.07719v1 公告类型：新
摘要：人类交流很大程度上依赖于暗示，传达超越字面意义的含义，以表达更广泛的思想、意图和感受。为了使模型更好地理解和促进人类交流，它们必须响应文本的隐含含义。我们专注于自然语言推理 (NLI)，这是许多语言任务的核心工具，并发现最先进的 NLI 模型和数据集难以识别一系列隐含情况，这些情况是隐含的，而不是文本中明确的。我们将隐含蕴涵形式化为 NLI 任务的扩展，并引入隐含 NLI 数据集 (INLI)，以帮助当今的 LLM 识别更广泛的隐含蕴涵并区分隐含和显含蕴涵。我们展示了在 INLI 上微调的 LLM 如何理解隐含蕴涵，并将这种理解推广到数据集和领域。]]></description>
      <guid>https://arxiv.org/abs/2501.07719</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLMic：罗马尼亚基础语言模型</title>
      <link>https://arxiv.org/abs/2501.07721</link>
      <description><![CDATA[arXiv:2501.07721v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展已在各种任务中展现出卓越的能力，其中商业模型处于领先地位。虽然开放模型通常以较小的规模运行，但它们通过专业化和微调保持竞争力。然而，一个重大挑战仍然存在：由于训练语料库中的代表性有限，开放模型在低资源语言中的表现往往不佳。在本文中，我们介绍了专为罗马尼亚语设计的双语基础语言模型 LLMic。我们记录了为低资源语言预训练基础模型的完整过程，包括语料库构建、架构选择和超参数优化。我们的评估表明，LLMic 可以专门用于目标语言中的任务，实现与其他更大的开放模型相当的结果。我们表明，在初始预训练阶段之后对 LLMic 进行语言翻译微调的效果优于英语到罗马尼亚语翻译任务中的现有解决方案。这为罗马尼亚语社区使用小得多的 LLMic 模型进行高效的大规模处理开辟了道路]]></description>
      <guid>https://arxiv.org/abs/2501.07721</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ESURF：简单有效的 EDU 细分</title>
      <link>https://arxiv.org/abs/2501.07723</link>
      <description><![CDATA[arXiv:2501.07723v1 公告类型：新
摘要：将文本分割成基本话语单元 (EDU) 是话语解析中的一项基本任务。我们提出了一种新的简单方法来识别 EDU 边界，然后根据词汇和字符 n-gram 特征使用随机森林分类对其进行分割。我们表明，尽管该方法很简单，但它在分割和最先进的话语解析器中都优于其他方法。这表明这些特征对于识别基本话语元素的重要性，并指向可能更具训练效率的话语分析方法。]]></description>
      <guid>https://arxiv.org/abs/2501.07723</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索语音生成 CNN 全连接层中的语言表征编码</title>
      <link>https://arxiv.org/abs/2501.07726</link>
      <description><![CDATA[arXiv:2501.07726v1 公告类型：新
摘要：CNN 卷积层的可解释性工作主要集中在计算机视觉上，但一些研究也探索了潜在空间与音频域输出之间的对应关系。然而，尚未彻底研究在连接潜在空间和卷积层的全连接 (FC) 层中如何表示声学和语言信息。本研究首次探索了语音合成 CNN 的 FC 层如何编码语言相关信息。我们提出了两种探索全连接层的技术。在实验 1 中，我们使用权重矩阵作为卷积层的输入。在实验 2 中，我们操纵 FC 层来探索如何在 CNN 中编码类似符号的表示。我们利用 FC 层输出特征图和变量特定权重矩阵在时间上结构化的事实来 (1) 展示学习权重的分布如何以系统的方式在潜在变量之间变化，以及 (2) 展示在保持后续模型参数不变的情况下操纵 FC 层如何影响输出。我们最终提出了一种可以输出单个片段的 FC 操纵。使用这种技术，我们表明生成 CNN（ciwGAN）中词汇特定的潜在代码在 FC 层权重中具有共享词汇不变的亚词汇表示，表明 ciwGAN 以语言学原理的方式编码词汇信息。]]></description>
      <guid>https://arxiv.org/abs/2501.07726</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过自动语法反馈提高学生写作水平</title>
      <link>https://arxiv.org/abs/2501.07740</link>
      <description><![CDATA[arXiv:2501.07740v1 公告类型：新
摘要：本研究强调了句法反馈在提高学生句法能力方面的关键作用。认识到学习者在掌握句法细微差别方面面临的挑战，我们引入了一个名为 Essay-Syntax-Instruct 的专门数据集，旨在提高这些学生对英语句法的理解和应用。利用 GPT3.5-Turbo、Llama-2-7b-chat-hf、Llama-2-13b-chat-hf 和 Mistral-7B-Instruct-v0.2 等大型语言模型 (LLM) 的功能，这项工作开始了针对句法改进任务的全面微调过程。通过细致的评估，我们证明经过微调的 LLM 在解决与语法相关的挑战方面表现出显着的进步，从而成为学生识别和纠正句法错误的有力工具。研究结果不仅凸显了所提出的数据集在提升 LLM 语法增强性能方面的有效性，还阐明了利用高级语言模型支持语言习得努力的有前途的途径。这项研究通过展示 LLM 在促进学生语言发展方面的潜力，为更广泛的语言学习技术领域做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2501.07740</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>知识图谱嵌入技术、方法和挑战的大型语言模型：一项调查</title>
      <link>https://arxiv.org/abs/2501.07766</link>
      <description><![CDATA[arXiv:2501.07766v1 公告类型：新
摘要：大型语言模型（LLM）因其卓越的性能而引起了各个领域的广泛关注，旨在在大量文本数据上训练数亿或更多的参数以理解和生成自然语言。随着LLM的卓越性能逐渐显现，它们越来越多地被应用于知识图谱嵌入（KGE）相关任务以改善处理结果。作为自然语言处理（NLP）领域的深度学习模型，它学习大量文本数据来预测下一个单词或生成与给定文本相关的内容。然而，最近，根据任务特点，LLM在不同类型的KGE相关场景（如多模态KGE和开放KGE）中被不同程度地调用。在本文中，我们研究了在不同类型的KGE场景中执行LLM相关任务的多种方法。为了更好地比较各种方法，我们将每个KGE场景总结为一个分类。除了分类方法之外，我们还以表格形式概述了这些方法及其源代码链接，以便进行更直接的比较。在文章中，我们还讨论了这些方法的主要应用，并为这一新研究领域的发展提出了几个前瞻性的方向。]]></description>
      <guid>https://arxiv.org/abs/2501.07766</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于微调大型语言模型的多编码器冻结解码器方法</title>
      <link>https://arxiv.org/abs/2501.07818</link>
      <description><![CDATA[arXiv:2501.07818v1 公告类型：新
摘要：在参数高效的微调方法中，冻结已成为一种流行的策略，用于加快训练速度、减少灾难性遗忘和提高下游性能。我们研究了在包含各种自然语言任务的多任务设置中冻结解码器的影响，旨在减少部署开销并增强向新任务的可移植性。我们通过在 AlexaTM 模型上微调单个和多任务设置进行的实验表明，冻结解码器对于具有自然语言输出的任务非常有效，并且可以减轻多语言任务中的灾难性遗忘。然而，我们发现将冻结解码器与更大的模型配对可以有效地保持甚至提高结构化和 QA 任务的性能，使其成为更广泛任务类型的可行策略。]]></description>
      <guid>https://arxiv.org/abs/2501.07818</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言模型文本生成的实时验证与细化</title>
      <link>https://arxiv.org/abs/2501.07824</link>
      <description><![CDATA[arXiv:2501.07824v1 公告类型：新
摘要：大型语言模型 (LLM) 在广泛的自然语言任务中表现出色。然而，一个关键的挑战仍然存在，即它们有时会生成事实上不正确的答案。为了解决这个问题，虽然许多以前的工作都集中在识别生成过程中的错误并进一步改进它们，但它们的部署速度很慢，因为它们被设计为仅在整个生成（从第一个到最后一个标记）完成后才验证来自 LLM 的响应。此外，我们观察到，一旦 LLM 在早期生成了错误的标记，后续标记也更有可能在事实上不正确。为此，在这项工作中，我们提出了 Streaming-VR（流式验证和细化），这是一种旨在提高 LLM 输出验证和细化效率的新方法。具体来说，所提出的 Streaming-VR 可以在生成 token 时对其进行实时验证和更正，类似于流式处理，确保在 LLM 构建其响应时，另一个 LLM 实时检查和改进每个 token 子集。通过对多个数据集的全面评估，我们证明了我们的方法不仅提高了 LLM 的事实准确性，而且与之前的改进方法相比，它提供了更有效的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2501.07824</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用图表进行推理：构建隐性知识以增强法学硕士的推理能力</title>
      <link>https://arxiv.org/abs/2501.07845</link>
      <description><![CDATA[arXiv:2501.07845v1 公告类型：新
摘要：大型语言模型 (LLM) 在广泛的任务中取得了显著的成功；然而，它们在推理任务中仍然面临挑战，这些任务需要理解和推断文本序列中不同信息之间的关系。这一挑战在涉及多步骤过程的任务中尤为明显，例如逻辑推理和多跳问答，在这些任务中，理解实体之间的隐式关系和利用给定上下文中的多跳连接至关重要。图作为基本数据结构，明确表示实体之间的成对关系，从而有可能增强 LLM 的推理能力。外部图已被证明可有效支持跨多个任务的 LLM。然而，在许多推理任务中，没有提供预先存在的图结构。我们能否将从上下文中获得的隐式知识构造成图来协助 LLM 进行推理？在本文中，我们提出了图推理 (RwG)，首先从上下文中构建显式图，然后利用这些图来增强 LLM 在推理任务上的推理性能。大量实验证明了所提出的方法在改进逻辑推理和多跳问答任务方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.07845</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优化语言模型以提高语法可接受性：微调技术的比较研究</title>
      <link>https://arxiv.org/abs/2501.07853</link>
      <description><![CDATA[arXiv:2501.07853v1 公告类型：新
摘要：本研究使用 CoLA 数据集探索了开放式预训练 Transformer (OPT-125M) 的微调 (FT)，用于语法可接受性任务。通过比较 Vanilla 微调 (VFT)、基于模式的微调 (PBFT) 和参数高效微调技术 (PEFT)（如低秩自适应 (LoRA)），我们证明了计算效率的显着提高，同时保持了高精度。我们的实验表明，虽然 VFT 实现了最高的准确率 (81.2%)，但 LoRA 通过将内存使用量和迭代时间减少 50% 以上来增强 FT，并在 PBFT 情况下提高了准确率。上下文蒸馏 (CD) 虽然计算效率高，但准确率约为 31%，表现不佳。我们的研究结果有助于通过减少计算障碍来实现对大型语言模型 (LLM) 的民主化访问。]]></description>
      <guid>https://arxiv.org/abs/2501.07853</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ReARTeR：具有可信过程奖励的检索增强推理</title>
      <link>https://arxiv.org/abs/2501.07861</link>
      <description><![CDATA[arXiv:2501.07861v1 公告类型：新
摘要：大型语言模型 (LLM) 的检索增强生成 (RAG) 系统在知识密集型任务中大有可为，但在复杂的多步骤推理中却面临限制。虽然最近的方法已经将 RAG 与使用过程奖励模型 (PRM) 的思路链推理或测试时间搜索相结合，但这些方法面临着诸多挑战，例如缺乏解释、PRM 训练数据存在偏差、PRM 分数存在早期步骤偏差以及推理潜力的训练后优化不足。为了解决这些问题，我们提出了通过可信过程奖励 (ReARTeR) 进行检索增强推理的框架，该框架通过训练后和测试时间扩展来增强 RAG 系统的推理能力。在测试时，ReARTeR 通过过程奖励模型引入了可信过程奖励，以实现准确的标量评分，并通过过程解释模型 (PEM) 生成自然语言解释，从而实现步骤细化。在训练后，它利用可信过程奖励指导的蒙特卡洛树搜索来收集高质量的步骤级偏好数据，并通过迭代偏好优化进行优化。ReARTeR 解决了三个核心挑战：(1) PRM 和 PEM 之间的不一致，通过离线策略偏好学习解决；(2) PRM 训练数据中的偏差，通过平衡的注释方法和针对具有挑战性的示例的更强的注释来缓解；(3) PRM 中的早期步骤偏差，通过基于时间差异的前瞻搜索策略解决。多步推理基准的实验结果显示出显着的改进，凸显了 ReARTeR 提升 RAG 系统推理能力的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.07861</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Whisper 进行嵌入层手术和任务导向搜索的持续学习</title>
      <link>https://arxiv.org/abs/2501.07875</link>
      <description><![CDATA[arXiv:2501.07875v1 公告类型：新 
摘要：当前的多语言 ASR 模型仅支持世界上一小部分语言。持续学习 (CL) 旨在通过向预训练模型添加新语言来解决此问题，同时避免现有语言的性能损失，也称为灾难性遗忘 (CF)。然而，现有的 CL 方法忽略了解码器处标记嵌入查找表的调整，尽管它对 CF 有重大贡献。我们提出了嵌入层手术，其中为每种新语言创建标记嵌入的单独副本，并在转录相应的新语言时选择其中一个副本来替换旧语言嵌入。不幸的是，这种方法意味着 LID 错误也会导致错误的 ASR 嵌入选择。我们的任务式束搜索可以自我纠正此类错误。通过将 Whisper 调整为针对 Common Voice 中 10 种未知语言的每种语言的 10 小时数据，结果表明，与 Experience Replay 相比，我们的方法将预训练语言的平均 WER (AWER) 从 14.2% 降低到 11.9%，同时不影响未知语言的 AWER。]]></description>
      <guid>https://arxiv.org/abs/2501.07875</guid>
      <pubDate>Wed, 15 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>