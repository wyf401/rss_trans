<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 02 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>人类 Wordle 游戏中的语义、正字法和形态偏见</title>
      <link>https://arxiv.org/abs/2411.18634</link>
      <description><![CDATA[arXiv:2411.18634v1 公告类型：新
摘要：我们表明，在 Wordle 游戏中，人类玩家的游戏玩法受到玩家先前猜测的语义、正字法和形态的影响。我们通过将实际人类玩家的猜测与接近最佳的猜测进行比较来证明这种影响，结果表明，人类玩家的猜测在语义、正字法和形态上倾向于与之前的猜测相似。]]></description>
      <guid>https://arxiv.org/abs/2411.18634</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型增量训练的有效性</title>
      <link>https://arxiv.org/abs/2411.18700</link>
      <description><![CDATA[arXiv:2411.18700v1 公告类型：新
摘要：训练大型语言模型是一个计算密集型过程，通常需要大量资源才能获得最先进的结果。增量分层训练已被提出作为一种潜在的策略，通过逐步引入层来优化训练过程，期望这种方法能够加快收敛速度​​并更有效地利用计算资源。在本文中，我们研究了增量训练对 LLM 的有效性，将训练过程分为多个阶段，逐步添加层。我们的实验结果表明，虽然增量方法最初显示出一定的计算效率，但最终需要更大的总体计算成本才能达到与传统全尺寸训练相当的性能。虽然增量训练过程最终可以缩小与基线的性能差距，但只有在经过显着延长的持续训练后才能做到这一点。这些发现表明，增量分层训练可能不是训练大型语言模型的可行替代方案，突出了它的局限性并为这种方法的低效率提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2411.18700</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NewsEdits 2.0：了解更新新闻背后的意图</title>
      <link>https://arxiv.org/abs/2411.18811</link>
      <description><![CDATA[arXiv:2411.18811v1 公告类型：新
摘要：随着事件的发展，新闻文章经常更新新信息：如果我们不谨慎，我们就有可能传播过时的事实。在这项工作中，我们假设语言特征表明事实流动性，并且我们可以仅使用新闻文章的文本（即不是搜索引擎等外部资源）来预测新闻文章中的哪些事实会更新。我们首先通过在大型新闻修订语料库中隔离事实更新来测试这一假设。新闻文章可能出于多种原因而更新（例如事实、风格、叙述）。我们引入了 NewsEdits 2.0 分类法，这是一种编辑意图模式，将新闻写作中的事实更新与风格和叙述更新分开。我们注释了超过 9,200 对句子修订，并训练高分集成模型以应用此模式。然后，通过获取大量银标记对数据集，我们表明我们可以高精度地预测事实何时会在旧文章草稿中更新。最后，为了证明这些发现的实用性，我们构建了一个语言模型问答 (LLM-QA) 弃权任务。我们希望 LLM 在信息可能过时时弃权回答问题。使用我们的预测，我们表明，LLM 缺席达到了接近 Oracle 的准确度水平。]]></description>
      <guid>https://arxiv.org/abs/2411.18811</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>测量生物医学报告中的偏倚风险：RoBBR 基准</title>
      <link>https://arxiv.org/abs/2411.18831</link>
      <description><![CDATA[arXiv:2411.18831v1 公告类型：新
摘要：通过审查科学文献来回答问题的系统正变得越来越可行。为了得出可靠的结论，这些系统应该考虑现有证据的质量，更加重视使用有效方法的研究。我们提出了一个衡量生物医学论文方法论强度的基准，借鉴了系统评价中使用的偏倚风险框架。这四项基准任务来自 500 多篇论文，涵盖了研究方法的分析，然后是对这些研究中的偏倚风险的评估。该基准包含 2000 个专家生成的偏见注释，以及一个经过人工验证的管道，用于与研究论文内容进行细粒度的对齐。我们在基准上评估了一系列大型语言模型，发现这些模型远远达不到专家级的性能。通过提供衡量研究质量判断的标准化工具，基准可以帮助指导执行大规模科学数据聚合的系统。该数据集可在 https://github.com/RoBBR-Benchmark/RoBBR 获得。]]></description>
      <guid>https://arxiv.org/abs/2411.18831</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用树正则化将语法潜入 Transformer 语言模型</title>
      <link>https://arxiv.org/abs/2411.18885</link>
      <description><![CDATA[arXiv:2411.18885v1 公告类型：新
摘要：虽然人类语言理解的组合描述基于分层树状过程，但像 Transformer 这样的神经模型缺乏对这种树结构的直接归纳偏差。引入句法归纳偏差可以解锁 Transformer 语言模型 (LM) 中更稳健、数据效率更高的学习，但现有的整合这种结构的方法极大地限制了模型，要么限制了它们的表达能力，要么增加了推理复杂性。这项工作旨在通过结构化正则化器将句法归纳偏差软注入给定的 Transformer 电路中。我们引入了 TREEREG，这是一种辅助损失函数，它将来自银解析的括号决策转换为一组对向量隐藏状态的可微正交约束。TREEREG 与标准 LM 目标无缝集成，无需进行任何架构更改。使用 TreeReg 在自然语言语料库（例如 WikiText-103）上进行预训练的 LM 在分布外数据上的困惑度降低了 10%，句法泛化能力提高了 9.5 个百分点，仅需不到一半的训练数据就能超越标准 LM。TreeReg 仍能为预训练的 LLM 带来好处：继续使用 TreeReg 对 Sheared Llama 进行预训练可提高句法泛化能力，使用 TreeReg 对 MultiNLI 进行微调可将对抗性 NLI 基准测试上的性能下降降低 41.2 个百分点。]]></description>
      <guid>https://arxiv.org/abs/2411.18885</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>设计一套紧凑且可解释的口语特征用于筛查阿尔茨海默病</title>
      <link>https://arxiv.org/abs/2411.18922</link>
      <description><![CDATA[arXiv:2411.18922v1 公告类型：新
摘要：阿尔茨海默病 (AD) 已成为老龄化社会中最重大的健康挑战之一。基于口语的 AD 检测方法由于其可扩展性而越来越流行。基于 Cookie Theft 图片描述任务，我们设计了一个可解释且有效的特征集，该特征集利用大型语言模型 (LLM) 和词频-逆文档频率 (TF-IDF) 模型的视觉功能。我们的实验结果表明，新提出的特征在两个不同的分类器中始终优于传统语言特征，并且具有较高的维度效率。我们的新功能可以得到很好的解释和逐步解释，从而增强了自动 AD 筛选的可解释性。]]></description>
      <guid>https://arxiv.org/abs/2411.18922</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EzSQL：一种用于改进 SQL 到文本生成的 SQL 中间表示</title>
      <link>https://arxiv.org/abs/2411.18923</link>
      <description><![CDATA[arXiv:2411.18923v1 公告类型：新
摘要：SQL 到文本生成任务传统上使用模板库、Seq2Seq、树到序列和图到序列模型。最近的模型利用 Seq2Seq 框架中预先训练的生成语言模型来完成此任务。但是，将 SQL 视为预训练模型的输入序列并不是最佳选择。在这项工作中，我们提出了一种称为 EzSQL 的新 SQL 中间表示，以使 SQL 与自然语言文本序列对齐。EzSQL 通过修改运算符和关键字来简化 SQL 查询并使其更接近自然语言文本，这些运算符和关键字通常可以用自然语言描述。EzSQL 还消除了对集合运算符的需求。我们提出的 SQL 到文本生成模型使用 EzSQL 作为预训练生成语言模型的输入来生成文本描述。我们证明了我们的模型是一种有效的先进方法，可以从 WikiSQL 和 Spider 数据集上的 SQL 查询生成文本叙述。我们还表明，通过使用我们的 SQL 到文本生成模型生成预训练数据，我们可以提高文本到 SQL 解析器的性能。]]></description>
      <guid>https://arxiv.org/abs/2411.18923</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>少量提示中示例选择对使用 GPT 模型进行自动作文评分的影响</title>
      <link>https://arxiv.org/abs/2411.18924</link>
      <description><![CDATA[arXiv:2411.18924v1 公告类型：新
摘要：本研究使用 GPT 模型研究了示例选择对使用少样本提示的自动作文评分 (AES) 性能的影响。我们评估了少样本提示中示例的选择和顺序对 GPT-3.5 和 GPT-4 模型的几个版本的影响。我们的实验涉及 119 个具有不同示例的提示，我们计算二次加权 kappa (QWK) 来衡量 GPT 和人类评分者分数之间的一致性。回归分析用于定量评估示例选择引入的偏差。结果表明，示例选择对 QWK 的影响因模型而异，GPT-3.5 受示例的影响大于 GPT-4。我们还发现，在 GPT 生成的论文分数和 QWK 中存在多数标签偏见（即倾向于偏向示例中的多数标签）和近因偏见（即倾向于偏向最近示例的标签），这些偏见在 GPT-3.5 中更为明显。值得注意的是，仔细的示例选择使 GPT-3.5 模型能够胜过某些 GPT-4 模型。然而，在 GPT 模型中，2023 年 6 月版的 GPT-4（不是最新模型）表现出最高的稳定性和性能。我们的研究结果深入了解了示例选择在 AES 的小样本提示中的重要性，尤其是在 GPT-3.5 模型中，并强调了对每个模型（即使是小版本）进行单独性能评估的必要性。]]></description>
      <guid>https://arxiv.org/abs/2411.18924</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ScratchEval：GPT-4o 比我的孩子聪明吗？使用可视化编程挑战评估大型多模态模型</title>
      <link>https://arxiv.org/abs/2411.18932</link>
      <description><![CDATA[arXiv:2411.18932v1 公告类型：新
摘要：大型多模态模型 (LMM) 的最新进展展示了令人印象深刻的代码生成能力，主要通过图像到代码的基准进行评估。然而，这些基准仅限于特定的可视化编程场景，其中逻辑推理和多模态理解能力是分开的。为了填补这一空白，我们提出了 ScratchEval，这是一种旨在评估 LMM 的可视化编程推理能力的新型基准。ScratchEval 基于 Scratch，这是一种广泛用于儿童编程教育的基于块的可视化编程语言。通过整合视觉元素和嵌入式编程逻辑，ScratchEval 要求模型同时处理视觉信息和代码结构，从而全面评估其编程意图理解能力。我们的评估方法超越了传统的图像到代码的映射，侧重于统一的逻辑思维和解决问题的能力，为评估 LMM 的可视化编程能力提供了更全面、更具挑战性的框架。 ScratchEval 不仅填补了现有评估方法的空白，还为 LMM 在可视化编程领域的未来发展提供了新的见解。我们的基准测试可在 https://github.com/HKBUNLP/ScratchEval 上访问。]]></description>
      <guid>https://arxiv.org/abs/2411.18932</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新表述电子健康记录以用于预训练临床语言模型</title>
      <link>https://arxiv.org/abs/2411.18940</link>
      <description><![CDATA[arXiv:2411.18940v1 公告类型：新
摘要：临床语言模型对于医疗保健中的许多应用都很重要，但它们的开发依赖于对大量临床文本的访问以进行预训练。然而，由于患者隐私问题，从电子健康记录 (EHR) 中大规模获取临床记录具有挑战性。在这项研究中，我们使用 LLM 重新表述现有的临床记录以生成合成预训练语料库，从以前对重新表述网络数据的研究中获得灵感。我们研究了四种流行的小型 LLM（&lt;10B）来创建合成临床文本，以预训练基于解码器和基于编码器的语言模型。与以前不参考真实临床文本的合成方法相比，该方法在语言建模和下游任务中获得了更好的结果。我们发现，即使在较小的令牌预算下，使用来自不同 LLM 的合成语料库来增强原始临床记录也可以提高性能，这表明该方法有潜力支持机构级别的预训练或扩展以合成大规模临床语料库。]]></description>
      <guid>https://arxiv.org/abs/2411.18940</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对话系统法学硕士时代的零样本槽填充</title>
      <link>https://arxiv.org/abs/2411.18980</link>
      <description><![CDATA[arXiv:2411.18980v1 公告类型：新
摘要：零样本槽填充是自然语言理解 (NLU) 中一个成熟的子任务。然而，大多数现有方法主要关注单轮文本数据，忽略了对话的独特复杂性。对话数据是高度动态的，通常涉及突然的主题转换、中断和隐式引用，这使得直接应用零样本槽填充技术变得困难，即使使用大型语言模型 (LLM) 的卓越功能也是如此。本文通过提出从教师 LLM 到较小模型的槽诱导和黑盒知识提炼 (KD) 自动数据注释策略来解决这些挑战，在内部数据集上的表现优于普通 LLM，F1 分数绝对增加 26%。此外，我们为呼叫中心产品设置引入了一种高效的系统架构，其相对 F1 分数超过现成的提取模型 34%，能够以更高的准确度对对话流进行近乎实时的推理，同时保持低延迟。]]></description>
      <guid>https://arxiv.org/abs/2411.18980</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>USTCCTSU 在 SemEval-2024 任务 1 中的成绩：降低跨语言语义文本相关性任务的各向异性</title>
      <link>https://arxiv.org/abs/2411.18990</link>
      <description><![CDATA[arXiv:2411.18990v1 公告类型：新
摘要：跨语言语义文本相关性任务是一项重要的研究任务，旨在解决跨语言交流和文本理解方面的挑战。它有助于建立不同语言之间的语义联系，这对于机器翻译、多语言信息检索和跨语言文本理解等下游任务至关重要。基于广泛的比较实验，我们选择 XLM-R-base 作为基础模型，并使用基于白化的预训练句子表示来减少各向异性。此外，对于给定的训练数据，我们设计了一种精细的数据过滤方法来缓解多语言的诅咒。通过我们的方法，我们在西班牙语中获得了第二名，在印尼语中获得了第三名，并在比赛的 C 赛道中多次进入前十名。我们进一步进行了全面的分析，以启发未来旨在提高跨语言任务性能的研究。]]></description>
      <guid>https://arxiv.org/abs/2411.18990</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在 CMC 中自言自语：对维基百科讨论页中自我回复的研究</title>
      <link>https://arxiv.org/abs/2411.19007</link>
      <description><![CDATA[arXiv:2411.19007v1 公告类型：新
摘要：本研究提出对维基百科讨论页中的自我回复进行定性分析，更准确地说，当讨论的前两条消息由同一用户撰写时。这种特定模式出现在超过 10% 的包含两条或更多条消息的线程中，可以用多种原因来解释。在对第二条消息的词汇特异性进行初步检查后，我们提出了一个七类类型学，并用它来注释两个参考样本（英语和法语），每个样本有 100 条线程。最后，我们分析和比较了人工注释者（达到合理的全局效率）和指令调整的 LLM（在几个类别中遇到重大困难）的性能。]]></description>
      <guid>https://arxiv.org/abs/2411.19007</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>低资源语言中自动在线仇恨言论检测调查</title>
      <link>https://arxiv.org/abs/2411.19017</link>
      <description><![CDATA[arXiv:2411.19017v1 公告类型：新
摘要：过去十年来，社交媒体平台的影响力不断扩大，影响了人们的交流方式。社交媒体的晦涩程度和互联网的易用性促进了仇恨言论的传播。与仇恨言论相关的术语和表达随着时代的变化而更新，这给政策制定者和研究人员识别仇恨言论带来了障碍。随着越来越多的人使用母语相互交流，这些资源匮乏的语言中的仇恨言论也在增长。尽管人们已经意识到与英语相关的方法，但由于缺乏数据集和在线可用数据，这些资源匮乏的语言并没有受到太多关注。本文对全球资源匮乏的语言中的仇恨言论检测进行了详细调查，并详细介绍了可用的数据集、使用的特征和使用的技术。本调查进一步讨论了现行的调查、与仇恨言论相关的重叠概念、研究挑战和机遇。]]></description>
      <guid>https://arxiv.org/abs/2411.19017</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DIESEL——通过规避 LLM 中的语义嵌入实现动态推理引导</title>
      <link>https://arxiv.org/abs/2411.19038</link>
      <description><![CDATA[arXiv:2411.19038v1 公告类型：新
摘要：近年来，对话式大型语言模型 (LLM) 在诸如随意对话、问答和个性化对话等任务中表现出巨大的成功，在虚拟协助、社交互动和在线客户参与等领域取得了重大进展。然而，它们通常会产生与人类价值观（例如道德标准、安全或社会规范）不一致的反应，从而导致潜在的不安全或不适当的输出。虽然已经提出了几种技术来解决这个问题，但它们是有代价的，需要计算成本高的训练或大大增加推理时间。在本文中，我们提出了 DIESEL，这是一种轻量级的推理指导技术，可以无缝集成到任何自回归 LLM 中，以语义上从响应中过滤掉不需要的概念。DIESEL 既可以作为独立的保护措施，也可以作为额外的防御层，通过根据 LLM 提出的标记与潜在空间中预定义的负面概念的相似性对其进行重新排序来增强响应安全性。这种方法提供了一种高效且有效的解决方案，可与人类价值观保持一致。我们的评估表明，即使在测试响应安全性极限的具有挑战性的越狱场景中，DIESEL 在最先进的对话模型（例如 Llama 3）上也表现出色。我们进一步表明，DIESEL 可以推广到安全以外的用例，从而为通用响应过滤提供了一种通用解决方案，且计算开销最小。]]></description>
      <guid>https://arxiv.org/abs/2411.19038</guid>
      <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>