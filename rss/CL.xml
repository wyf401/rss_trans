<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 14 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过低阶适配器融合增强人工智能安全性</title>
      <link>https://arxiv.org/abs/2501.06208</link>
      <description><![CDATA[arXiv:2501.06208v1 公告类型：新
摘要：大型语言模型 (LLM) 的指令微调是提高特定任务性能的有效方法，但它可能会无意中导致模型在面对恶意提示时产生有害响应的现象。在本文中，我们探索了低秩适配器融合 (LoRA) 作为一种减轻这些风险的方法，同时保留了模型有效处理各种指令的能力。通过使用公认的基准数据集对已建立的基线进行广泛的比较分析，我们证明了通过利用任务适配器和安全适配器之间的 LoRA 融合，有害率降低了 42%，后者专门针对我们的安全数据集进行训练。然而，我们也观察到夸大的安全行为，其中模型拒绝与不安全提示非常相似的安全提示]]></description>
      <guid>https://arxiv.org/abs/2501.06208</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自然语言处理在航空安全中的应用：回顾与定性分析</title>
      <link>https://arxiv.org/abs/2501.06210</link>
      <description><![CDATA[arXiv:2501.06210v1 公告类型：新
摘要：本研究探讨了在航空安全中使用自然语言处理，重点研究机器学习算法以增强安全措施。截至 2024 年 5 月，关键字搜索自然语言处理和航空安全有 34 条 Scopus 结果。分析这些研究使我们能够发现 NLP 在航空领域的方法、发现和影响趋势。定性和定量工具都已用于调查有关航空安全 NLP 的当前文献状态。定性分析总结了研究动机、目标和结果，展示了如何利用 NLP 来帮助识别关键安全问题并提高航空安全。本研究还确定了研究差距并提出了未来探索的领域，为航空业提供了实用建议。我们讨论了在航空安全中实施 NLP 的挑战，例如对大型带注释数据集的需求以及解释复杂模型的难度。我们提出了解决方案，例如用于数据注释的主动学习和用于模型解释的可解释 AI。案例研究证明了 NLP 在提高航空安全方面的成功应用，凸显了其使航空更加安全、更高效的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.06210</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FLAME：金融大语言模型评估与指标评估</title>
      <link>https://arxiv.org/abs/2501.06211</link>
      <description><![CDATA[arXiv:2501.06211v1 公告类型：新
摘要：LLM 彻底改变了 NLP，并在各个领域展现出巨大的潜力。越来越多的金融 LLM 被引入用于特定于金融的任务，但全面评估它们的价值仍然具有挑战性。在本文中，我们介绍了一个全面的中文金融 LLM 评估系统 FLAME，它包括两个核心评估基准：FLAME-Cer 和 FLAME-Sce。FLAME-Cer 涵盖了 CPA、CFA 和 FRM 等 14 种权威金融认证，总共约 16,000 个精心挑选的问题。所有问题都经过人工审查以确保准确性和代表性。FLAME-Sce 包括 10 个主要核心金融业务场景、21 个次要金融业务场景和近 100 个三级金融应用任务的综合评估集。我们评估了 6 个具有代表性的法学硕士，包括 GPT-4o、GLM-4、ERNIE-4.0、Qwen2.5、XuanYuan3 和最新的 Baichuan4-Finance，结果表明 Baichuan4-Finance 在大多数任务中都优于其他法学硕士。通过建立全面而专业的评估体系，FLAME 促进了中国背景下金融法学硕士的进步。参与评估的说明可在 GitHub 上找到：https://github.com/FLAME-ruc/FLAME。]]></description>
      <guid>https://arxiv.org/abs/2501.06211</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>标记化的分区覆盖方法</title>
      <link>https://arxiv.org/abs/2501.06246</link>
      <description><![CDATA[arXiv:2501.06246v1 公告类型：新
摘要：标记化是将字符串从大小为 $k$ 的固定词汇表中编码为标记的过程，广泛应用于自然语言处理应用程序。当今领先的标记化算法是字节对编码 (BPE)，它将标记化问题表述为压缩问题并通过执行合并序列来解决它。在这项工作中，我们将标记化表述为优化目标，通过从顶点覆盖的简单减少表明它是 NP 难的，并提出了多项式时间贪婪算法 GreedTok。我们的公式自然地放松到经过充分研究的加权最大覆盖问题，该问题具有一个简单的 $(1 - 1/e)$ 近似算法 GreedWMC。通过对真实世界语料库的实证评估，我们表明 GreedTok 优于 BPE，同时实现了与 GreedWMC 相当的目标分数（由于放松，GreedWMC 可能会获得更高的分数）。]]></description>
      <guid>https://arxiv.org/abs/2501.06246</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过多义词的表示重新思考稀疏自动编码器的评估</title>
      <link>https://arxiv.org/abs/2501.06254</link>
      <description><![CDATA[arXiv:2501.06254v1 公告类型：新
摘要：稀疏自动编码器 (SAE) 通过将多义神经元的复杂叠加映射到单义特征并组成稀疏词典，作为一种有前途的工具，它引起了广泛关注。然而，传统的性能指标，如均方误差和 L0 稀疏性，忽略了对 SAE 语义表征能力的评估——它们是否能够在保留单词语义关系的同时获得可解释的单义特征。例如，学习到的稀疏特征是否可以区分一个单词中的不同含义并不明显。在本文中，我们提出了一套 SAE 评估方法，通过关注多义词来分析单义特征的质量。我们的研究结果表明，为改进 MSE-L0 帕累托前沿而开发的 SAE 可能会混淆可解释性，这并不一定会增强单义特征的提取。对多义词的 SAE 进行分析也可以了解 LLM 的内部机制；更深的层次和注意力模块有助于区分单词中的多义性。我们的语义重点评估为多义性和现有的 SAE 目标提供了新的见解，并有助于开发更实用的 SAE。]]></description>
      <guid>https://arxiv.org/abs/2501.06254</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>情境学习中最重要的是什么：查找和权重学习之间的平衡</title>
      <link>https://arxiv.org/abs/2501.06256</link>
      <description><![CDATA[arXiv:2501.06256v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种任务中都表现出色，包括上下文学习 (ICL)，其中模型仅根据上下文中提供的示例执行新任务，而不更新模型的权重。虽然先前的研究已经探索了预训练数据和模型架构的作用，但 ICL 背后的关键机制仍不清楚。在这项工作中，我们系统地揭示了 LLM 中支持 ICL 出现的属性。为了消除这些因素的歧义，我们使用深度自回归模型对受控数据集和数据序列进行了研究。我们表明，数据序列中的概念重复对于 ICL 至关重要，比之前指出的训练数据属性（如突发性或长尾分布）更为重要。概念重复可以指文本数据中的 $n$-gram 重复或图像序列数据中的精确图像副本。这种重复还提供了其他以前被忽视的好处，例如减少 ICL 性能的瞬时性。此外，我们表明 ICL 的出现取决于在训练期间平衡权重学习目标和上下文解决能力。]]></description>
      <guid>https://arxiv.org/abs/2501.06256</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AgoraSpeech：通过人类和人工智能的视角进行多注释的政治话语综合数据集</title>
      <link>https://arxiv.org/abs/2501.06265</link>
      <description><![CDATA[arXiv:2501.06265v1 公告类型：新
摘要：政治话语数据集对于获得政治见解、分析传播策略或社会科学现象非常重要。尽管存在大量政治话语语料库，但全面、高质量、带注释的数据集却很少。这主要是因为对修辞策略和意识形态背景的细致注释需要大量的人工、多学科和专业知识。在本文中，我们介绍了 AgoraSpeech，这是一个精心策划的高质量数据集，包含 2023 年希腊全国大选期间来自六个政党的 171 篇政治演讲。该数据集包括六个自然语言处理 (NLP) 任务的注释（每段）：文本分类、主题识别、情绪分析、命名实体识别、两极分化和民粹主义检测。采用了两步注释，首先是 ChatGPT 生成的注释，然后是详尽的人机验证。该数据集最初用于案例研究，以在选举前提供见解。然而，它具有普遍适用性，可以作为政治和社会科学家、记者或数据科学家的丰富信息来源，同时可以用于对 NLP 和大型语言模型 (LLM) 进行基准测试和微调。]]></description>
      <guid>https://arxiv.org/abs/2501.06265</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>环境大型语言模型评估（ELLE）数据集：评估生态环境领域生成式人工智能应用的基准</title>
      <link>https://arxiv.org/abs/2501.06277</link>
      <description><![CDATA[arXiv:2501.06277v1 公告类型：新
摘要：生成式人工智能在生态和环境应用方面具有巨大潜力，例如监测、数据分析、教育和政策支持。然而，由于缺乏统一的评估框架，其有效性受到限制。为了解决这个问题，我们提出了环境大型语言模型评估 (ELLE) 问答 (QA) 数据集，这是第一个旨在评估大型语言模型及其在生态和环境科学中的应用的基准。ELLE 数据集包括 16 个环境主题的 1,130 个问答对，按领域、难度和类型分类。这个全面的数据集标准化了这些领域的绩效评估，从而能够对生成式人工智能的性能进行一致和客观的比较。通过提供专用的评估工具，ELLE 数据集促进了生成式人工智能技术的开发和应用，以实现可持续的环境成果。数据集和代码可在 https://elle.ceeai.net/ 和 https://github.com/CEEAI/elle 上找到。]]></description>
      <guid>https://arxiv.org/abs/2501.06277</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>标点符号在 Brain 和 Transformers 模型之间的语义作用</title>
      <link>https://arxiv.org/abs/2501.06278</link>
      <description><![CDATA[arXiv:2501.06278v1 公告类型：新
摘要：用于自然语言处理 (NLP) 的当代神经网络并非采用特定的语言规则设计。这表明他们可能获得对语言的一般理解。这一属性导致了对破译其内部表征的广泛研究。一种开创性的方法涉及使用人脑数据的实验设置，以探索是否可以建立大脑和神经网络表征之间的转换。自从这项技术出现以来，已经开发出了更复杂的 NLP 模型。在我们的研究中，我们应用这种方法来评估四种新的 NLP 模型，旨在确定与大脑活动最兼容的模型。此外，为了探索大脑如何从语义上理解文本，我们通过四种不同的方式删除标点符号来改变文本，以了解其对人脑语义处理的影响。我们的研究结果表明，RoBERTa 模型与大脑活动最为吻合，根据我们的指标，其准确性优于 BERT。此外，对于 BERT，当排除标点符号时，准确率会更高，并且与原始带有标点符号的结果相比，增加上下文长度并没有显著降低准确率。]]></description>
      <guid>https://arxiv.org/abs/2501.06278</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MinMo：实现无缝语音交互的多模态大型语言模型</title>
      <link>https://arxiv.org/abs/2501.06282</link>
      <description><![CDATA[arXiv:2501.06282v1 公告类型：新
摘要：大型语言模型 (LLM) 和多模态语音文本模型的最新进展为无缝语音交互奠定了基础，实现了实时、自然和类似人类的对话。以前的语音交互模型分为原生和对齐模型。原生模型将语音和文本处理集成在一个框架中，但存在序列长度不同和预训练不足等问题。对齐模型保留了文本 LLM 功能，但通常受到小数据集和对语音任务的狭窄关注的限制。在这项工作中，我们引入了 MinMo，这是一个多模态大型语言模型，具有大约 8B 个参数，可实现无缝语音交互。我们解决了先前对齐的多模态模型的主要局限性。我们通过语音到文本对齐、文本到语音对齐、语音到语音对齐和双工交互对齐的多个阶段对 MinMo 进行训练，使用了 140 万小时的多样化语音数据和广泛的语音任务。经过多阶段训练，MinMo 在语音理解和生成方面在各种基准测试中都取得了最佳表现，同时保持了文本 LLM 的功能，并且还支持全双工对话，即用户和系统之间同时进行双向通信。此外，我们提出了一种新颖而简单的语音解码器，其语音生成性能优于之前的模型。MinMo 增强的指令跟随能力支持根据用户指令控制语音生成，包括情绪、方言和语速等各种细微差别，以及模仿特定的声音。对于 MinMo 来说，语音到文本的延迟约为 100 毫秒，全双工延迟在理论上约为 600 毫秒，在实践中约为 800 毫秒。MinMo 项目网页为 https://funaudiollm.github.io/minmo，代码和模型即将发布。]]></description>
      <guid>https://arxiv.org/abs/2501.06282</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Bactrainus：针对多跳复杂问答任务优化大型语言模型</title>
      <link>https://arxiv.org/abs/2501.06286</link>
      <description><![CDATA[arXiv:2501.06286v1 公告类型：新
摘要：近年来，大型语言模型 (LLM) 的使用显著增加，这些模型在各种通用语言任务中表现出色。然而，对它们在特定领域任务中的表现的评估，特别是那些需要深度自然语言理解的任务，却没有受到太多关注。在本研究中，我们评估了大型语言模型执行特定领域任务的能力，重点关注使用 HotpotQA 数据集的多跳问答 (MHQA) 问题。由于这项任务需要推理和结合来自多个文本源的信息，因此它成为评估这些模型的语言理解能力的具有挑战性的基准。为了解决这个问题，我们设计了一个两阶段的选择器-读取器架构，其中每个阶段都使用一个独立的 LLM。此外，我们还采用了思路链 (CoT) 和问题分解等方法来研究它们对提高模型性能的影响。研究结果表明，大型语言模型与这些技术的结合可使寻找答案的 F1 分数提高高达 4%，证明了模型处理特定领域任务的能力及其对复杂语言的理解。]]></description>
      <guid>https://arxiv.org/abs/2501.06286</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型在类型多样的语言中共享潜在语法概念的表征</title>
      <link>https://arxiv.org/abs/2501.06346</link>
      <description><![CDATA[arXiv:2501.06346v1 公告类型：新
摘要：人类双语者通常使用相似的大脑区域来处理多种语言，这取决于他们学习第二语言的时间和熟练程度。在大型语言模型 (LLM) 中，多种语言是如何学习和编码的？在这项工作中，我们探索了 LLM 在多大程度上共享形态句法概念（例如语法数字、性别和时态）的表示。我们在 Llama-3-8B 和 Aya-23-8B 上训练稀疏自动编码器，并证明抽象语法概念通常以多种语言共享的特征方向进行编码。我们使用因果干预来验证这些表示的多语言性质；具体而言，我们表明仅消除多语言特征会将分类器性能降低到跨语言的近似偶然水平。然后，我们使用这些特征来精确修改机器翻译任务中的模型行为；这证明了这些特征在网络中的作用的通用性和选择性。我们的研究结果表明，即使主要基于英语数据训练的模型也可以开发出强大的跨语言形态句法概念抽象。]]></description>
      <guid>https://arxiv.org/abs/2501.06346</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>面向医学应用的性别中立大型语言模型：减少 PubMed 摘要中的偏见</title>
      <link>https://arxiv.org/abs/2501.06365</link>
      <description><![CDATA[arXiv:2501.06365v1 公告类型：新
摘要：本文介绍了一种通过中和性别职业代词来减轻医学文献中使用的大型语言模型 (LLM) 中的性别偏见的方法。处理了 1965 年至 1980 年的 379,000 篇 PubMed 摘要数据集，以识别和修改与职业相关的代词。我们开发了一个基于 BERT 的模型，即“现代职业偏见消除与精炼训练”或“MOBERT”，对这些中和后的摘要进行了训练，并将其性能与在原始数据集上训练的“1965Bert”进行了比较。MOBERT 实现了 70\% 的包容性替换率，而 1965Bert 仅达到 4\%。对 MOBERT 的进一步分析表明，代词替换准确性与训练数据中职业术语的频率相关。我们建议扩大数据集并改进流程以提高性能并确保在医疗应用中更公平的语言建模。]]></description>
      <guid>https://arxiv.org/abs/2501.06365</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AFRIDOC-MT：非洲语言文档级机器翻译语料库</title>
      <link>https://arxiv.org/abs/2501.06374</link>
      <description><![CDATA[arXiv:2501.06374v1 公告类型：新 
摘要：本文介绍了 AFRIDOC-MT，这是一个文档级多并行翻译数据集，涵盖英语和五种非洲语言：阿姆哈拉语、豪萨语、斯瓦希里语、约鲁巴语和祖鲁语。该数据集包括 334 份健康和 271 份信息技术新闻文档，全部由人工从英语翻译成这些语言。我们通过评估神经机器翻译 (NMT) 模型和大型语言模型 (LLM) 在句子和伪文档级别对英语和这些语言之间的翻译进行文档级翻译基准实验。这些输出被重新调整以形成完整的文档以供评估。我们的结果表明，NLLB-200 在标准 NMT 模型中取得了最佳平均性能，而 GPT-4o 优于通用 LLM。对选定的模型进行微调可以显着提高性能，但对句子进行训练的模型难以有效地推广到较长的文档。此外，我们的分析表明，一些法学硕士存在翻译不足、单词或短语重复以及翻译偏离目标等问题，尤其是对于非洲语言而言。]]></description>
      <guid>https://arxiv.org/abs/2501.06374</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用自注意力机制进行下一个标记预测时“自发”主题变化的动态</title>
      <link>https://arxiv.org/abs/2501.06382</link>
      <description><![CDATA[arXiv:2501.06382v1 公告类型：新
摘要：人类认知可以自发地转移谈话主题，通常是由情感或语境信号触发的。相比之下，基于自注意力的语言模型依赖于输入标记的结构化统计线索来预测下一个标记，缺乏这种自发性。受此区别的启发，我们研究了影响下一个标记预测以改变输入序列主题的因素。我们定义了主题连续性、模糊序列和主题变化的概念，基于将主题定义为一组标记优先级图 (TPG)。使用简化的单层自注意力架构，我们推导出主题变化的分析特征。具体来说，我们证明了 (1) 该模型保持与输入主题相关的标记的优先级顺序，(2) 仅当输入主题中优先级较低的标记数量超过所有优先级较高的标记时，才会发生主题变化，以及 (3) 与人类认知不同，较长的上下文长度和重叠主题会降低自发重定向的可能性。这些见解突出了人类认知和基于自我注意的模型在导航主题变化方面的差异，并强调了设计能够更自然地处理“自发”对话的对话式人工智能的挑战。据我们所知，这是第一项研究如何解决与人类对话和思维如此密切相关的这些问题。]]></description>
      <guid>https://arxiv.org/abs/2501.06382</guid>
      <pubDate>Tue, 14 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>