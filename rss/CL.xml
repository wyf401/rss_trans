<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 02 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>法学硕士 (LLM) 逻辑理论的归纳学习：复杂性分级分析</title>
      <link>https://arxiv.org/abs/2408.16779</link>
      <description><![CDATA[arXiv:2408.16779v1 公告类型：新
摘要：这项工作提出了一种新颖的系统方法来分析大型语言模型 (LLM) 在逻辑理论归纳方面的能力和局限性，这些模型具有来自形式推理引擎的反馈。分析是相对于规则依赖结构的复杂性分级的，可以量化 LLM 性能的特定推理挑战。将 LLM 与形式化方法相结合是自然语言处理领域的一个有前途的前沿，是提高模型推理控制和可解释性的重要途径。特别是，对复杂的事实和规则集进行归纳学习，对当前的自回归模型提出了独特的挑战，因为它们缺乏明确的符号基础。虽然它们可以通过形式系统进行补充，但 LLM 在归纳学习方面提供的属性尚未得到很好的理解和量化。实证结果表明，最大的 LLM 可以取得与 SOTA 归纳逻辑编程 (ILP) 系统基线相媲美的结果，但对于 LLM 来说，跟踪长谓词关系链比理论复杂性更困难。]]></description>
      <guid>https://arxiv.org/abs/2408.16779</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>为 TikTok 建立攻击性内容检测模型</title>
      <link>https://arxiv.org/abs/2408.16857</link>
      <description><![CDATA[arXiv:2408.16857v1 公告类型：新
摘要：社交媒体的出现改变了人际沟通和信息消费过程。这种数字环境适应了用户的意图，也导致了攻击性语言和有害行为的增加。同时，社交媒体平台收集了大量包含用户生成内容和行为信息的数据集。这些数据集对于平台部署机器学习和数据驱动策略、促进客户洞察和针对虚假信息和攻击性内容等社交操纵机制的对策至关重要。然而，对于特定社交媒体平台针对特定事件的研究人员和从业者来说，此类数据集以及各种机器学习技术的应用是有限的。特别是对于提供个性化内容创建和共享独特工具的 TikTok，现有的知识体系将受益于拥有关于攻击性内容的多样化综合数据集和相关数据分析解决方案。虽然社交媒体平台、研究和从业者社区在这方面做出了努力，但此类内容仍在不断激增。这意味着必须公开数据集并构建相应的智能解决方案。为此，本研究对包含攻击性内容的TikTok数据进行了收集和分析，建立了一系列用于攻击性内容检测的机器学习和深度学习模型。这样做的目的是回答以下研究问题：“如何开发一系列计算模型来检测TikTok上的攻击性内容？”。为此，我们考虑了数据科学方法论，收集了120.423条TikTok评论，并在平衡的二元分类方法上获得了0.863的F1得分性能结果。]]></description>
      <guid>https://arxiv.org/abs/2408.16857</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLaVA-Chef：食品食谱的多模式生成模型</title>
      <link>https://arxiv.org/abs/2408.16889</link>
      <description><![CDATA[arXiv:2408.16889v1 公告类型：新 
摘要：在全球化背景下的在线食谱共享领域迅速发展，对理解和生成食物食谱的研究显着增加。 GPT-2 和 LLaVA 等大型语言模型 (LLM) 的最新进展为自然语言处理 (NLP) 方法深入研究与食物相关的任务的各个方面铺平了道路，包括成分识别和全面的食谱生成。 尽管 LLM 具有令人印象深刻的性能和多模态适应性，但特定领域的训练对于其有效应用仍然至关重要。 这项工作评估了现有的用于食谱生成的 LLM，并提出了 LLaVA-Chef，这是一种采用多阶段方法在精选的多样化食谱提示数据集上进行训练的新型模型。 首先，我们改进了视觉食物图像嵌入到语言空间的映射。 其次，我们通过对相关食谱数据进行微调，使 LLaVA 适应食品领域。第三，我们利用不同的提示来增强模型对菜谱的理解。最后，我们通过使用自定义损失函数惩罚模型来提高生成菜谱的语言质量。LLaVA-Chef 比预训练的 LLM 和之前的作品有显著的改进。详细的定性分析表明，与现有方法相比，LLaVA-Chef 可以生成更详细的菜谱，并精确提及配料。]]></description>
      <guid>https://arxiv.org/abs/2408.16889</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索多种策略来提高 CorefUD 中的多语言共指解析</title>
      <link>https://arxiv.org/abs/2408.16893</link>
      <description><![CDATA[arXiv:2408.16893v1 公告类型：新
摘要：共指解析，即识别文本中指代同一实体的表达式的任务，是各种自然语言处理 (NLP) 应用程序中的关键组件。本文介绍了我们的端到端神经共指解析系统，利用 CorefUD 1.1 数据集，该数据集涵盖 12 种语言的 17 个数据集。我们首先建立强大的基线模型，包括单语和跨语言变体，然后提出几个扩展来提高不同语言环境中的性能。这些扩展包括跨语言训练、句法信息的结合、用于优化词头预测的 Span2Head 模型和高级单例建模。我们还通过重叠段尝试了词头跨度表示和长文档建模。提出的扩展，特别是仅使用头部的方法、单例建模和长文档预测，显著提高了大多数数据集的性能。我们还进行了零样本跨语言实验，突出了跨语言迁移在共指解析中的潜力和局限性。我们的研究结果有助于开发用于多语言共指解析的稳健且可扩展的共指系统。最后，我们在 CorefUD 1.1 测试集上评估了我们的模型，并以很大的优势超越了 CRAC 2023 共享任务中同等规模的最佳模型。我们的节点可在 GitHub 上找到：\url{https://github.com/ondfa/coref-multiling}]]></description>
      <guid>https://arxiv.org/abs/2408.16893</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ACE-2005-PT：葡萄牙语事件提取语料库</title>
      <link>https://arxiv.org/abs/2408.16928</link>
      <description><![CDATA[arXiv:2408.16928v1 公告类型：新
摘要：事件提取是一项 NLP 任务，通常涉及识别事件的中心词（触发器）及其在文本中的相关参数。ACE-2005 被广泛认为是该领域的标准语料库。虽然其他语料库（如 PropBank）主要侧重于注释谓词论元结构，但 ACE-2005 提供了有关整个事件结构和语义的全面信息。然而，其有限的语言覆盖范围限制了它的可用性。本文介绍了 ACE-2005-PT，这是一个通过将 ACE-2005 翻译成葡萄牙语创建的语料库，具有欧洲和巴西变体。为了加快获取 ACE-2005-PT 的过程，我们依靠自动翻译器。然而，这带来了一些挑战，与自动识别原文和相应翻译句子中多词注释之间的正确对齐有关。为了实现这一目标，我们开发了一个对齐流程，其中包含多种对齐技术：词形还原、模糊匹配、同义词匹配、多重翻译和基于 BERT 的词对齐器。为了衡量对齐效果，语言专家手动对齐了 ACE-2005-PT 语料库中的注释子集。然后将该子集与我们的流程结果进行比较，结果分别实现了 70.55% 和 87.55% 的精确匹配和宽松匹配分数。最终，我们成功生成了 ACE-2005 语料库的葡萄牙语版本，该版本已被 LDC 接受出版。]]></description>
      <guid>https://arxiv.org/abs/2408.16928</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>葡萄牙语事件提取：使用 ACE-2005 的 QA 驱动方法</title>
      <link>https://arxiv.org/abs/2408.16932</link>
      <description><![CDATA[arXiv:2408.16932v1 公告类型：新
摘要：事件提取是一种信息检索任务，通常包括识别事件（触发器）的中心词和事件的参数。这项任务已在英语中得到广泛研究，但在葡萄牙语中却落后了，部分原因是缺乏特定于任务的注释语料库。本文提出了一个框架，其中对两个独立的基于 BERT 的模型进行了微调，以识别和分类葡萄牙语文档中的事件。我们将这个任务分解为两个子任务。首先，我们使用一个标记分类模型来检测事件触发器。为了提取事件参数，我们训练了一个问答模型，该模型查询触发器相应的事件参数角色。鉴于葡萄牙语中缺乏事件注释语料库，我们将 ACE-2005 数据集（该领域的参考）的原始版本翻译成葡萄牙语，为葡萄牙语事件提取生成了一个新语料库。为此，我们开发了一个自动翻译管道。我们的框架在触发器分类中获得了 64.4 的 F1 分数，在参数分类设置中获得了 46.7 的 F1 分数，因此成为葡萄牙语中这些任务的新的最先进的参考。]]></description>
      <guid>https://arxiv.org/abs/2408.16932</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Plausible-Parrots @ MSP2023：利用实体和事件知识增强语义可信度建模</title>
      <link>https://arxiv.org/abs/2408.16937</link>
      <description><![CDATA[arXiv:2408.16937v1 公告类型：新
摘要：在这项工作中，我们研究了将外部知识注入大型语言模型 (LLM) 以识别简单事件的语义合理性的有效性。具体来说，我们使用从外部知识库中提取的细粒度实体类型、事件类型及其定义来增强 LLM。这些知识通过设计的模板注入我们的系统。我们还扩充数据以平衡标签分布并使任务设置适应现实世界场景，其中事件提及以自然语言句子的形式表达。实验结果表明，注入的知识在建模事件的语义合理性方面是有效的。错误分析进一步强调了识别非平凡实体和事件类型的重要性。]]></description>
      <guid>https://arxiv.org/abs/2408.16937</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型对新冠肺炎疫情期间的恐华情绪进行纵向情绪分析</title>
      <link>https://arxiv.org/abs/2408.16942</link>
      <description><![CDATA[arXiv:2408.16942v1 公告类型：新 
摘要：COVID-19 大流行加剧了仇外心理，尤其是仇华情绪，导致对华裔人士的普遍歧视。大型语言模型 (LLM) 是用于自然语言处理 (NLP) 任务的预训练深度学习模型。LLM 理解和生成类似人类文本的能力使其特别适用于分析社交媒体数据以检测和评估情绪。我们提出了一个情绪分析框架，利用 LLM 对 COVID-19 大流行期间 X（Twitter）中表达的仇华情绪进行纵向情绪分析。结果显示，仇华推文的激增、仇华情绪和 COVID-19 病例激增之间存在显着相关性，表明大流行的发展影响了公众情绪和仇华言论的盛行。此外，情绪分析显示，人们普遍存在负面情绪，例如恼怒和否认，这凸显了政治叙事和错误信息对公众舆论的影响。此前与 COVID-19 相关的研究中也存在缺乏同理心的现象，这凸显了媒体的政治叙事如何看待这场疫情以及如何指责华人社区。我们的研究强调了透明沟通对于缓解全球危机期间的仇外情绪的重要性。]]></description>
      <guid>https://arxiv.org/abs/2408.16942</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MemLong：用于长文本建模的记忆增强检索</title>
      <link>https://arxiv.org/abs/2408.16967</link>
      <description><![CDATA[arXiv:2408.16967v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展在不同领域取得了显著成功。然而，由于注意力机制的二次时间和空间复杂度以及生成过程中键值缓存的不断增长的内存消耗，处理长上下文仍然是 LLM 面临的重大挑战。这项工作介绍了 MemLong：用于长文本生成的内存增强检索，这种方法旨在通过利用外部检索器进行历史信息检索来增强长上下文语言建模的能力。MemLong 将不可微分的“ret-mem”模块与部分可训练的仅解码器语言模型相结合，并引入了一种细粒度、可控的检索注意力机制，该机制利用语义级相关块。对多个长上下文语言建模基准的综合评估表明，MemLong 始终优于其他最先进的 LLM。更重要的是，MemLong 可以将单个 3090 GPU 上的上下文长度从 4k 扩展到 80k。我们的代码可在 https://github.com/Bui1dMySea/MemLong 上找到]]></description>
      <guid>https://arxiv.org/abs/2408.16967</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>工具辅助代理在真实场景中的 SQL 检查和改进</title>
      <link>https://arxiv.org/abs/2408.16991</link>
      <description><![CDATA[arXiv:2408.16991v1 公告类型：新
摘要：最近的文本到 SQL 方法通过结合来自数据库管理系统的反馈来利用大型语言模型 (LLM)。虽然这些方法有效地解决了 SQL 查询中的执行错误，但它们在处理数据库不匹配方面却举步维艰——这些错误不会触发执行异常。数据库不匹配包括条件不匹配和更严格的约束不匹配等问题，这两种问题在现实场景中更为普遍。为了应对这些挑战，我们提出了一个用于 SQL 检查和改进的工具辅助代理框架，为基于 LLM 的代理配备了两个专用工具：检索器和检测器，旨在诊断和纠正具有数据库不匹配的 SQL 查询。这些工具增强了 LLM 更有效地处理实际查询的能力。我们还引入了 Spider-Mismatch，这是一个专门构建的新数据集，用于反映现实场景中遇到的条件不匹配问题。实验结果表明，我们的方法在小样本设置下在 Spider 和 Spider-Realistic 数据集的平均结果上取得了最高的性能，并且在更现实的数据集 Spider-Mismatch 上明显优于基线方法。]]></description>
      <guid>https://arxiv.org/abs/2408.16991</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>动态自洽性：利用推理路径实现高效的 LLM 抽样</title>
      <link>https://arxiv.org/abs/2408.17017</link>
      <description><![CDATA[arXiv:2408.17017v1 公告类型：新
摘要：自一致性 (SC) 是一种广泛使用的方法，通过对 LLM 进行多次采样并输出最常见的解决方案来缓解大型语言模型 (LLM) 中的幻觉。尽管 SC 有很多好处，但它会导致与生成的样本数量成比例的大量计算成本。以前的早期停止方法，例如早期停止自一致性和自适应一致性，旨在通过考虑输出一致性来降低这些成本，但它们并没有分析推理路径 (RP) 本身的质量。为了解决这个问题，我们提出了推理感知自一致性 (RASC)，这是一个创新的早期停止框架，它通过考虑输出答案和来自思路链 (CoT) 提示的 RP 来动态调整样本生成的数量。RASC 按顺序为生成的样本分配置信度分数，在满足某些标准时停止，然后采用加权多数投票来优化样本使用并提高答案可靠性。我们使用多种 LLM 在不同的 QA 数据集上对 RASC 进行了全面测试。与原始 SC 相比，RASC 的表现优于现有方法，并且显著减少了平均 80% 的样本使用量，同时保持或提高了高达 5% 的准确率]]></description>
      <guid>https://arxiv.org/abs/2408.17017</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>InkubaLM：针对资源匮乏的非洲语言的小型语言模型</title>
      <link>https://arxiv.org/abs/2408.17024</link>
      <description><![CDATA[arXiv:2408.17024v1 公告类型：新
摘要：高资源语言模型在非洲背景下往往不够充分，因为非洲迫切需要高效、可访问且与当地相关的模型，即使在计算和数据受到严重限制的情况下也是如此。本文介绍了一个具有 0.4 亿个参数的小型语言模型 InkubaLM，其在机器翻译、问答、AfriMMLU 和 AfriXnli 任务等任务上的性能可与具有明显更大参数数量和更广泛训练数据的模型相媲美。值得注意的是，InkubaLM 在情绪分析方面的表现优于许多大型模型，并且在多种语言中表现出显着的一致性。这项工作代表了挑战有效语言模型必须依赖大量资源的传统范式的关键进步。我们的模型和数据集是公开可用的 \footnote{\url{https://huggingface.co/lelapa}}，以鼓励对低资源语言的研究和开发。]]></description>
      <guid>https://arxiv.org/abs/2408.17024</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从文本到情感：揭秘法学硕士的情感注释能力</title>
      <link>https://arxiv.org/abs/2408.17026</link>
      <description><![CDATA[arXiv:2408.17026v1 公告类型：新
摘要：训练情绪识别模型在很大程度上依赖于人工注释的数据，这些数据带来了多样性、质量和成本方面的挑战。在本文中，我们探讨了大型语言模型 (LLM)，特别是 GPT4，在自动化或协助情绪注释方面的潜力。我们从三个方面将 GPT4 与监督模型和/或人类进行比较：与人类注释的一致性、与人类感知的一致性以及对模型训练的影响。我们发现，使用聚合的人类注释作为基本事实的常用指标可能会低估 GPT-4 的性能，而我们的人类评估实验表明，在多个数据集和评估者中，GPT-4 注释比人类具有一致的偏好。此外，我们研究了使用 GPT-4 作为注释过滤过程对改进模型训练的影响。总之，我们的研究结果凸显了 LLM 在情绪注释任务中的巨大潜力，并强调了改进评估方法的必要性。]]></description>
      <guid>https://arxiv.org/abs/2408.17026</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Novel-WD：使用前缀调整探索法学硕士中新世界知识的获取</title>
      <link>https://arxiv.org/abs/2408.17070</link>
      <description><![CDATA[arXiv:2408.17070v1 公告类型：新
摘要：向预先训练的大型语言模型 (PLM) 教授新信息是一项至关重要但具有挑战性的任务。模型自适应技术（例如微调和参数高效训练）已被证明可以以较慢的速度存储新事实；持续学习是一种选择，但成本高昂且容易发生灾难性遗忘。这项工作研究并量化了 PLM 如何学习和记住其预训练语料库中未出现的新世界知识事实，该语料库仅包含截至某一日期的世界知识。为此，我们首先提出了 Novel-WD，这是一个新的数据集，由包含从最近的 Wikidata 更新中提取的新事实的句子组成，以及因果语言建模和多项选择题 (MCQ) 形式的两个评估任务。我们将这个数据集免费提供给社区，并发布一个程序，以便以后使用最新信息构建类似数据集的新版本。我们还探索了前缀调整在新信息学习中的应用，并分析了给定前缀中可以存储多少信息。我们表明，单个事实可以可靠地编码在单个前缀中，并且前缀容量会随着前缀长度和基础模型大小的增加而增加。]]></description>
      <guid>https://arxiv.org/abs/2408.17070</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MaFeRw：针对检索增强大型语言模型的具有多方面反馈的查询重写</title>
      <link>https://arxiv.org/abs/2408.17072</link>
      <description><![CDATA[arXiv:2408.17072v1 公告类型：新 
摘要：在现实世界的 RAG 系统中，当前查询通常涉及对话上下文中的省略和模糊引用，需要重写查询以更好地描述用户的信息需求。然而，传统的基于上下文的重写对下游生成任务的增强很小，因为从查询重写到响应生成的过程很长。一些研究人员尝试利用带有生成反馈的强化学习来协助重写者，但这些稀疏的奖励在大多数情况下提供的指导很少，导致训练和生成结果不稳定。我们发现用户的需求也反映在黄金文档、检索到的文档和基本事实中。因此，通过将这些多方面的密集奖励反馈到查询重写中，可以获得更稳定和令人满意的响应。在本文中，我们提出了一种新颖的查询重写方法 MaFeRw，通过整合来自检索过程和生成结果的多方面反馈来提高 RAG 性能。具体来说，我们首先使用人工数据训练一个 T5 模型用于重写器初始化。接下来，我们设计三个指标作为强化学习反馈：重写查询与黄金文档的相似度、排名指标以及生成与基本事实之间的 ROUGE。受 RLAIF 的启发，我们针对上述指标训练了三种奖励模型，以实现更高效的训练。最后，我们将这些奖励模型的分数组合作为反馈，并使用 PPO 算法探索最优查询重写策略。在两个对话式 RAG 数据集上的实验结果表明，与基线相比，MaFeRw 实现了更优异的生成指标和更稳定的训练。]]></description>
      <guid>https://arxiv.org/abs/2408.17072</guid>
      <pubDate>Mon, 02 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>