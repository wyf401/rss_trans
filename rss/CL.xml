<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 17 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用感知语用相似性模型精确表征沟通障碍</title>
      <link>https://arxiv.org/abs/2409.09170</link>
      <description><![CDATA[arXiv:2409.09170v1 公告类型：新
摘要：对患有交流障碍的个体的诊断和治疗为语音技术的应用提供了许多机会，但迄今为止的研究尚未充分考虑：条件的多样性、语用缺陷的作用以及有限数据的挑战。本文探讨了感知语用相似性的通用模型如何克服这些限制。它解释了它如何支持临床医生和客户的几个用例，并提供了证据表明一个简单的模型可以提供价值，特别是可以捕捉与自闭症和特定语言障碍诊断相关的话语方面。]]></description>
      <guid>https://arxiv.org/abs/2409.09170</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于热带和传染病分类的大型语言模型的上下文评估</title>
      <link>https://arxiv.org/abs/2409.09201</link>
      <description><![CDATA[arXiv:2409.09201v1 公告类型：新
摘要：虽然大型语言模型 (LLM) 在医学问答方面显示出前景，但专注于热带和传染病特定探索的工作有限。我们以开源热带和传染病 (TRINDs) 数据集为基础，将其扩展为包括人口统计和语义临床和消费者增强，产生 11000 多个提示。我们评估这些 LLM 的表现，将通才和医学 LLM 以及 LLM 结果与人类专家进行比较。我们通过系统实验证明了背景信息（例如人口统计、位置、性别、风险因素）对最佳 LLM 响应的好处。最后，我们开发了 TRINDs-LM 的原型，这是一种研究工具，它提供了一个游乐场来探索背景如何影响 LLM 对健康的输出。]]></description>
      <guid>https://arxiv.org/abs/2409.09201</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自回归 + 思路链 (CoT) $\simeq$ 循环：循环在语言模型中的作用以及对循环 Transformer 的回顾</title>
      <link>https://arxiv.org/abs/2409.09239</link>
      <description><![CDATA[arXiv:2409.09239v1 公告类型：新
摘要：Transformer 架构在各种语言建模任务中表现出色，优于 RNN 和 LSTM 等传统神经架构。这部分是由于它消除了循环连接，从而允许并行训练和更平滑的梯度流动。然而，这种脱离循环结构的举动将 Transformer 模型置于 Chomsky 计算层次的低端，限制了其计算能力。因此，即使是先进的基于 Transformer 的模型在计数、字符串反转、括号配对和乘法等任务中也面临相当大的困难。这些任务虽然看似简单，但需要的计算复杂度超出了 Transformer 架构的能力。同时，“思维链”（CoT）提示的出现使基于 Transformer 的语言模型能够解决以前不可能或执行不力的任务。尽管之前的一些研究主要从心理学的角度解释 CoT，但对 \textit{why} CoT 在推理过程中如此有效的全面理解仍然难以捉摸。在这项工作中，我们彻底研究了语言模型中循环结构对其推理能力的影响，阐明了 CoT 方法如何模拟循环计算并充当自回归和循环之间的桥梁。正是这种近似的循环显著提高了模型的性能和计算能力。此外，我们重新审视了最近基于循环的 Transformer 模型设计，通过我们提出的“循环完备性”概念关注它们的计算能力，并确定了线性 Transformer 和 RWKV 等模型中的关键理论限制。通过这种方式，我们旨在深入了解神经模型架构并促进更好的模型设计。]]></description>
      <guid>https://arxiv.org/abs/2409.09239</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NovAScore：一种用于评估文档级新颖性的新自动化指标</title>
      <link>https://arxiv.org/abs/2409.09249</link>
      <description><![CDATA[arXiv:2409.09249v1 公告类型：新
摘要：在线内容的快速扩展加剧了信息冗余问题，强调需要能够识别真正新信息的解决方案。尽管面临这一挑战，但研究界对新颖性检测的关注度有所下降，尤其是随着大型语言模型 (LLM) 的兴起。此外，以前的方法严重依赖人工注释，这既耗时又昂贵，而且当注释者必须将目标文档与大量历史文档进行比较时尤其具有挑战性。在这项工作中，我们引入了 NovAScore（原子性分数中的新颖性评估），这是一种用于评估文档级新颖性的自动化指标。NovAScore 汇总了原子信息的新颖性和显着性分数，提供了高可解释性和对文档新颖性的详细分析。凭借其动态权重调整方案，NovAScore 提供了增强的灵活性和额外的维度来评估文档中信息的新颖性水平和重要性。我们的实验表明，NovAScore 与人类对新颖性的判断高度相关，在 TAP-DLND 1.0 数据集上实现了 0.626 的 Point-Biserial 相关性，在内部人工注释数据集上实现了 0.920 的 Pearson 相关性。]]></description>
      <guid>https://arxiv.org/abs/2409.09249</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分析静态词嵌入的内在和外在偏差指标之间的相关性，并对齐其测量偏差</title>
      <link>https://arxiv.org/abs/2409.09260</link>
      <description><![CDATA[arXiv:2409.09260v1 公告类型：新
摘要：我们研究了静态词嵌入的内在偏差指标预测自然语言处理 (NLP) 系统是否表现出偏差行为的能力。词嵌入是一种基本的 NLP 技术，它通过真实向量表示单词的含义，但问题是，它还会学习刻板印象等社会偏见。内在偏差指标通过检查向量的特征来衡量偏差，而外在偏差指标则检查使用词嵌入训练的 NLP 系统是否有偏差。先前的研究发现，常见的内在偏差指标通常与外在偏差指标不相关。然而，内在和外在偏差指标在大多数情况下并没有测量到相同的偏差，这让我们质疑这种缺乏相关性是否是真的。在本文中，我们从外在偏差指标的数据集中提取特征词，并分析这些词与内在偏差指标的相关性，以确保两个指标测量到相同的偏差。我们观察到，一些外在偏见指标具有中等到高度的相关性，但与其他指标几乎没有相关性。这一结果表明，内在偏见指标可以预测特定环境下的偏见行为，但不能预测其他环境下的偏见行为。实验代码可在 GitHub 上找到。]]></description>
      <guid>https://arxiv.org/abs/2409.09260</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 ChatGPT 汇总纠纷并推荐类似中文劳动就业案例的实证评估</title>
      <link>https://arxiv.org/abs/2409.09280</link>
      <description><![CDATA[arXiv:2409.09280v1 公告类型：新
摘要：我们提出了一种推荐类似劳动和就业诉讼案件的混合机制。分类器根据法院准备的两个案件的逐项争议来确定相似性。我们对争议进行聚类，计算争议之间的余弦相似度，并将结果用作分类任务的特征。实验结果表明，这种混合方法优于我们之前的系统，后者仅考虑了有关争议聚类的信息。我们用 GPT-3.5 和 GPT-4 生成的逐项争议替换了法院准备的争议，并重复了相同的实验。使用 GPT-4 生成的争议可以获得更好的结果。虽然我们的分类器在使用 ChatGPT 生成的争议时表现不佳，但结果令人满意。因此，我们希望未来的大语言模型能够变得实用。]]></description>
      <guid>https://arxiv.org/abs/2409.09280</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言模型“Grok”可供复制</title>
      <link>https://arxiv.org/abs/2409.09281</link>
      <description><![CDATA[arXiv:2409.09281v1 公告类型：新 
摘要：我们研究了语言模型的预训练动态，重点关注它们从先前上下文复制文本的能力——这是各种 LLM 应用的基本技能，包括上下文学习 (ICL) 和检索增强生成 (RAG)。我们提出了一个新颖的观点，即基于 Transformer 的语言模型开发了类似于 grokking 的复制能力，这指的是模型拟合训练集很久之后在测试集上突然泛化。我们的实验得出了三个论点：（1）预训练损失迅速下降，而模型的上下文复制能力最初滞后，然后突然饱和。（2）开发复制能力的速度与训练的 token 数量无关，类似于只要数据分布保持不变，grokking 速度就不会受到数据集大小的影响。 (3) 诱导头，即负责复制的注意力头，在训练过程中从浅层到深层形成，反映了理解过程中更深层电路的发展。我们认为理解和上下文复制之间的联系可以为更有效的语言模型训练提供有价值的见解，最终提高上下文性能。例如，我们证明了增强理解的技术（例如正则化）可以加速或增强上下文复制的发展。]]></description>
      <guid>https://arxiv.org/abs/2409.09281</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ODE：多模态大型语言模型中幻觉的开放集评估</title>
      <link>https://arxiv.org/abs/2409.09318</link>
      <description><![CDATA[arXiv:2409.09318v1 公告类型：新
摘要：幻觉对多模态大型语言模型 (MLLM) 提出了重大挑战。然而，现有的评估幻觉的基准是静态的，这可能导致潜在的数据污染。本文介绍了 ODE，一种用于评估 MLLM 中对象存在幻觉的开放集动态协议。我们的框架采用图结构来模拟真实词概念之间的关联，并为一般和特定领域的场景生成新样本。概念的动态组合以及各种组合原则确保了广泛的样本分布。实验结果表明，MLLM 使用 ODE 生成的样本表现出更高的幻觉率，有效避免了数据污染。此外，这些样本还可用于微调，以提高 MLLM 在现有基准上的性能。]]></description>
      <guid>https://arxiv.org/abs/2409.09318</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于压缩记忆的事件参数提取检索方法</title>
      <link>https://arxiv.org/abs/2409.09322</link>
      <description><![CDATA[arXiv:2409.09322v1 公告类型：新
摘要：最近的研究已经证明了检索增强在事件参数提取 (EAE) 任务中的有效性。然而，现有的基于检索的 EAE 方法有两个主要限制：(1) 输入长度限制和 (2) 检索器与推理模型之间的差距。这些问题限制了检索信息的多样性和质量。在本文中，我们提出了一种基于压缩记忆的 EAE 检索 (CMR) 机制，该机制解决了上述两个限制。我们的压缩记忆设计为一个动态矩阵，可以有效地缓存检索到的信息并支持持续更新，从而克服了输入长度的限制。此外，在将所有候选演示预加载到压缩记忆中后，该模型会根据输入查询进一步从记忆中检索和过滤相关信息，从而弥合检索器和推理模型之间的差距。大量实验表明，我们的方法在三个公共数据集（RAMS、WikiEvents、ACE05）上取得了新的最佳性能，明显优于现有的基于检索的 EAE 方法。]]></description>
      <guid>https://arxiv.org/abs/2409.09322</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对自动化医疗文档的大型语言模型的有效微调</title>
      <link>https://arxiv.org/abs/2409.09324</link>
      <description><![CDATA[arXiv:2409.09324v1 公告类型：新
摘要：科学研究表明，医生在直接护理患者上花费的每个小时，在行政任务上花费近两个小时，特别是在电子健康记录 (EHR) 和案头工作上。这种过度的行政负担不仅减少了可用于患者护理的时间，还导致医生倦怠和医疗服务效率低下。为了应对这些挑战，本研究引入了 MediGen，这是一种经过微调的大型语言模型 (LLM)，旨在自动从医疗对话中生成医疗报告。通过利用最先进的方法对开源预训练模型（包括 LLaMA3-8B）进行微调，MediGen 在转录和总结临床互动方面实现了高精度。经过微调的 LLaMA3-8B 模型表现出令人鼓舞的结果，实现了 58% 的 ROUGE 得分和 72% 的 BERTScore-F1，表明其在生成准确且具有临床相关性的医疗报告方面的有效性。这些发现表明，MediGen 有可能显著减少医生的行政工作量，提高医疗效率和医生的福祉。]]></description>
      <guid>https://arxiv.org/abs/2409.09324</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过两阶段前缀增强型多模态 LLM 为电影生成面向事件的归因</title>
      <link>https://arxiv.org/abs/2409.09362</link>
      <description><![CDATA[arXiv:2409.09362v1 公告类型：新
摘要：社交媒体平台的繁荣提出了对语义丰富服务的迫切需求，例如事件和故事情节归因。然而，大多数现有研究主要通过基本的字幕任务来关注剪辑级事件理解，而没有分析整部电影中事件的原因。这是一个重大挑战，因为即使是先进的多模态大型语言模型 (MLLM) 也会因上下文长度有限而难以处理大量多模态信息。为了解决这个问题，我们提出了一种两阶段前缀增强 MLLM (TSPE) 方法用于电影视频中的事件归因，即将相关事件与其因果语义联系起来。在本地阶段，我们引入了一个交互感知前缀，引导模型关注单个剪辑中的相关多模态信息，简要总结单个事件。相应地，在全局阶段，我们使用推理知识图谱加强关联事件之间的联系，并设计事件感知前缀，引导模型关注关联事件而不是所有先前的剪辑，从而实现准确的事件归因。对两个真实数据集的综合评估表明，我们的框架优于最先进的方法。]]></description>
      <guid>https://arxiv.org/abs/2409.09362</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过扩散模型实现多样化和高效的音频字幕</title>
      <link>https://arxiv.org/abs/2409.09401</link>
      <description><![CDATA[arXiv:2409.09401v1 公告类型：新
摘要：我们引入了基于扩散的音频字幕 (DAC)，这是一种非自回归扩散模型，专为多样化和高效的音频字幕而设计。虽然现有的依赖语言主干的字幕模型在各种字幕任务中取得了显著的成功，但它们在生成速度和多样性方面的性能不足阻碍了音频理解和多媒体应用的进步。我们基于扩散的框架提供了独特的优势，源于其固有的随机性和字幕中的整体上下文建模。通过严格的评估，我们证明 DAC 不仅在字幕质量方面达到了与现有基准相比的 SOTA 性能水平，而且在生成速度和多样性方面也明显优于它们。DAC 的成功表明，使用扩散主干，文本生成也可以与音频和视觉生成任务无缝集成，为跨不同模态的统一的音频相关生成模型铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2409.09401</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>感质结构与语言出现之间双向因果关系的建设性方法</title>
      <link>https://arxiv.org/abs/2409.09413</link>
      <description><![CDATA[arXiv:2409.09413v1 公告类型：新
摘要：本文提出了一种关于语言出现与主观体验的关系结构（称为感质结构）之间双向因果关系的新视角，并阐述了对两者之间复杂依赖关系的建设性方法。我们假设具有分布式语义（例如句法语义结构）的语言可能是通过协调个体之间的内部表征而出现的，这种内部表征的协调有助于语言更加结构化。这种相互依赖性是由人工智能和符号出现机器人技术的最新进展以及集体预测编码 (CPC) 假设所表明的。计算研究表明，基于神经网络的语言模型形成系统结构化的内部表征，多模态语言模型可以在语言和感知信息之间共享表征。这种观点表明，语言的出现不仅是一种创造交流工具的机制，也是一种让人们实现对定性体验的共同理解的机制。本文讨论了这种双向因果关系在意识研究、语言学和认知科学背景下的含义，并概述了未来建设性的研究方向，以进一步探索语言出现和感质结构之间的动态关系。]]></description>
      <guid>https://arxiv.org/abs/2409.09413</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 REAP 增强 LLM 问题解决能力：反思、明确问题解构和高级提示</title>
      <link>https://arxiv.org/abs/2409.09415</link>
      <description><![CDATA[arXiv:2409.09415v1 公告类型：新
摘要：大型语言模型 (LLM) 已经改变了自然语言处理，但提高其解决问题的能力，特别是对于复杂、推理密集型任务的能力，仍然是一个持续的挑战。本文介绍了 REAP（反思、显式问题解构和高级提示）方法，这是动态上下文生成框架中的一种创新方法。REAP 通过对查询进行反思、将其解构为可管理的组件并生成相关上下文来指导 LLM，以增强解决过程。我们使用旨在揭示 LLM 局限性的数据集对 REAP 进行了评估，在六个最先进的模型中比较了零样本提示和 REAP 增强提示：OpenAI 的 o1-preview、o1-mini、GPT-4o、GPT-4o-mini、Google 的 Gemini 1.5 Pro 和 Claude 3.5 Sonnet。结果显示，性能显著提升，o1-mini 提升了 40.97%，GPT-4o 提升了 66.26%，GPT-4o-mini 提升了 112.93%。尽管 OpenAI 的 o1-preview 的基准性能已经很强大，但仍观察到适度的提升。除了性能改进之外，REAP 还提供了一种经济高效的解决方案；例如，GPT-4o-mini 比 o1-preview 便宜约 100 倍，但提供了具有竞争力的结果。REAP 还提高了模型输出的清晰度，使人们更容易理解结果背后的原因，并简化了识别和解决问题的过程。这些发现表明，REAP 有潜力极大地提高 LLM 的功能，在广泛的应用中提供更好的性能和更高的成本效率。]]></description>
      <guid>https://arxiv.org/abs/2409.09415</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>让人类参与其中：以人为本的生成式人工智能自动注释</title>
      <link>https://arxiv.org/abs/2409.09467</link>
      <description><![CDATA[arXiv:2409.09467v1 公告类型：新
摘要：自动文本注释是社交媒体研究中生成大型语言模型 (LLM) 的一个引人注目的用例。最近的研究表明，LLM 可以在注释任务上取得出色的表现；然而，这些研究在少数任务上评估了 LLM，并且由于依赖公共基准数据集，可能会受到污染。在这里，我们测试了一个以人为本的框架，以负责任地评估自动注释中使用的人工智能工具。我们使用 GPT-4 在 11 个受密码保护的数据集上复制了 27 个注释任务，这些数据集来自最近发表在高影响力期刊上的计算社会科学文章。对于每个任务，我们将 GPT-4 注释与人工注释的真实标签进行比较，并与在人工生成的标签上微调的单独监督分类模型的注释进行比较。虽然 LLM 标签的质量通常很高，但我们发现 LLM 的性能在各个任务之间，甚至在数据集内都存在显着差异。我们的研究结果强调了以人为本的工作流程和谨慎的评估标准的重要性：尽管采用了各种优化策略（例如快速调整），但自动注释在许多情况下仍与人类判断存在很大差异。将自动注释建立在人类生成的验证标签上对于负责任的评估至关重要。]]></description>
      <guid>https://arxiv.org/abs/2409.09467</guid>
      <pubDate>Tue, 17 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>