<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Mon, 24 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>检索调查系统可能是危险的医疗通信者</title>
      <link>https://arxiv.org/abs/2502.14898</link>
      <description><![CDATA[ARXIV：2502.14898V1公告类型：新 
摘要：患者长期以来一直在网上寻求健康信息，并且越来越多，他们正在转向生成的AI来回答与健康相关的查询。鉴于医疗领域的高赌注，诸如检索型生成和引文接地等技术已被广泛促进，作为减少幻觉和提高AI生成反应的准确性的方法，并已被广泛采用到搜索引擎中。本文认为，即使这些方法从幻觉中汲取了从源文档中汲取的字面意义上的内容，它们仍然可能具有很大的误导。患者可能与阅读原始资料相比，患者可以从AI生成的产出明显不同，更不用说咨询知识渊博的临床医生了。通过对包括有争议的诊断和程序安全在内的主题的大规模查询分析，我们通过定量和定性的证据来支持我们的论点，证明了当前系统所产生的次优答案。特别是，我们强调了这些模型如何倾向于将事实降低，忽略关键的相关来源，并加强患者的误解或偏见。我们提出了一系列建议，例如融入沟通语用学和增强对源文件的理解 - 可以帮助减轻这些问题并超越医疗领域。]]></description>
      <guid>https://arxiv.org/abs/2502.14898</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ai可以模仿人类定义新神学主义的能力吗？</title>
      <link>https://arxiv.org/abs/2502.14900</link>
      <description><![CDATA[ARXIV：2502.14900V1公告类型：新 
摘要：语言学中的一项持续辩论是人工智能（AI）是否可以有效地模仿与语言相关的任务中的人类表现。尽管许多研究集中在AI的各种语言能力上，但很少有人关注它如何通过不同的单词形成过程形成的新词。这项研究通过研究人类和AI生成的反应之间在定义三种类型的希腊新系统方面的一致性来解决这一差距：混合，化合物和衍生物。该研究采用了一个在线实验，在该实验中，人类参与者选择了最适合的新博物主义定义，而Chatgpt则收到了相同的提示。结果揭示了人类和人工智能对混合物和衍生物的反应之间的公平协议，但没有对化合物的共识。但是，在考虑人类之间的多数反应时，与AI的共识对于混合和衍生物的同意很高。这些发现突出了人类语言的复杂性，AI在捕捉其细微差别方面仍然面临着挑战。特别是，他们建议需要将更先进的语义网络和上下文学习机制整合到AI模型中，以改善他们对复杂单词形成的解释，尤其是化合物。]]></description>
      <guid>https://arxiv.org/abs/2502.14900</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>读取不可读的：使用图像到文本模型创建19世纪英语报纸的数据集</title>
      <link>https://arxiv.org/abs/2502.14901</link>
      <description><![CDATA[ARXIV：2502.14901V1公告类型：新 
摘要：奥斯卡·王尔德（Oscar Wilde）说：“文学和新闻业之间的差异是新闻业不可读，文学不被阅读。”不幸的是，奥斯卡·王尔德（Oscar Wilde）19世纪的数字存档新闻通常没有质量的光学特征识别（OCR），从而降低了这些档案的可访问性，并使它们在象征和字面上使它们变得不可读。本文通过使用Pixtral 12B（一种预先训练的图像到文本语言模型），通过对19世纪的英语报纸和期刊进行了84K页的19世纪英语报纸和期刊来帮助解决问题。 。将PixTral的OCR能力与其他4种OCR方法进行了比较，其中位字符错误率为1％，比下一个最佳模型低5倍。由此产生的NCSE V2.0数据集具有改进的文章识别，高质量的OCR和文本分类为四种类型和十七个主题。数据集包含140万个条目和3.21亿个单词。示例用例展示了主题相似性，可读性和事件跟踪的分析。 NCSE v2.0可以自由使用，以鼓励历史和社会学研究。结果，21世纪的读者现在可以与19世纪的新闻标准分享奥斯卡·王尔德（Oscar Wilde）的失望，从他们自己的计算机的舒适性中读取了不可读的内容。]]></description>
      <guid>https://arxiv.org/abs/2502.14901</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Pathrag：基于图形的修剪检索增强产生</title>
      <link>https://arxiv.org/abs/2502.14902</link>
      <description><![CDATA[ARXIV：2502.14902V1公告类型：新 
摘要：通过从外部数据库中检索知识，检索增强的生成（RAG）改善了大语言模型（LLMS）的响应质量。典型的破布方法将文本数据库分为块，以平坦的结构组织它们以进行有效的搜索。为了更好地捕获整个文本数据库中固有的依赖关系和结构化关系，研究人员建议将文本信息组织到索引图中，基于Asgraph的抹布。但是，我们认为，当前基于图的抹布方法的局限性在于检索到的信息的冗余，而不是其不足。此外，以前的方法使用平坦的结构在提示中组织检索的信息，从而导致次优性能。为了克服这些局限性，我们提出了PathRag，该Pathrag从索引图中检索了关键的关系路径，并将这些路径转换为文本形式以提示LLM。具体而言，Pathrag通过基于流动的修剪有效地减少了冗余信息，同时指导LLMS通过基于路径的提示产生更合乎逻辑和相干的响应。实验结果表明，Pathrag始终在六个数据集和五个评估维度上胜过最先进的基线。该代码可在以下链接中找到：https：//github.com/bupt-gamma/pathrag]]></description>
      <guid>https://arxiv.org/abs/2502.14902</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>思考JSON内部：严格的LLM模式依从性的强化策略</title>
      <link>https://arxiv.org/abs/2502.14905</link>
      <description><![CDATA[ARXIV：2502.14905V1公告类型：新 
摘要：在本文中，我们通过利用LLM推理能力来解决以大语言模型（LLM）生成严格依从性的挑战。在DeepSeek R1增强学习框架的基础上，我们的方法通过新的管道结合了合成推理数据集构造与小组相对策略优化（GRPO）下的自定义奖励功能的新型管道来训练1.5B参数模型的结构性推理技能。具体来说，我们首先在20K样本中执行R1强化学习，从而反映了原始的DeepSeek R1方法，以建立核心推理能力。随后，我们在单独的10K推理样本数据集上进行了监督的微调，重点是精炼下游任务的模式依从性。尽管训练范围相对较小，需要在8xH100 GPU群集上进行GRPO训练约20小时，而SFT的1XA100需要3小时，但我们的模型在实施模式一致性方面表现出了强劲的性能。我们将思想方法与原始DeepSeek R1（671b），DeepSeek R1（Qwen-1.5b和Qwen-7b）以及Gemini 2.0 Flash（70b）的蒸馏版进行了比较，展示了其在现实世界应用中的有效性。我们的结果强调了用于架构约束文本生成的资源有效框架的实际实用性。]]></description>
      <guid>https://arxiv.org/abs/2502.14905</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越言语：探索多模型模型中的文化价值敏感性</title>
      <link>https://arxiv.org/abs/2502.14906</link>
      <description><![CDATA[ARXIV：2502.14906V1公告类型：新 
摘要：基于文化背景的大语言模型（LLM）中的价值一致性已成为研究的关键领域。但是，在大型视觉模型（VLM）中尚未广泛探索类似的偏见。随着多模式模型的规模不断增长，评估图像是否可以作为文化的可靠代理以及如何通过整合视觉和文本数据来嵌入这些值变得越来越重要。在本文中，我们对不同尺度的多模式模型进行了彻底的评估，重点是它们与文化价值的一致性。我们的发现表明，与LLM一样，VLM对文化价值表现出敏感性，但是它们与这些价值一致性的性能高度依赖于上下文。尽管VLM通过使用图像显示了提高价值理解的潜力，但在多种模型对齐中，这种对齐方式在强调复杂性和毫无创伤的挑战的情况下差异很大。]]></description>
      <guid>https://arxiv.org/abs/2502.14906</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Gneissweb：规模为LLM的高质量数据准备</title>
      <link>https://arxiv.org/abs/2502.14907</link>
      <description><![CDATA[ARXIV：2502.14907V1公告类型：新 
摘要：数据数量和质量在确定大语言模型（LLMS）的性能中起着至关重要的作用。尤其是高质量的数据可以显着提高LLM在广泛的下游任务上概括的能力。领先的LLM的大型培训数据集对于公众来说仍然无法访问，而许多开放数据集的大小很小（少于5万亿代币），从而限制了其适合培训大型型号的能力。
  在本文中，我们介绍了Gneissweb，这是一个大约10万亿代币的大型数据集，可满足培训LLM的数据质量和数量要求。我们的Gneissweb食谱产生了数据集，包括精确的子字符串删除和明智地构建的质量过滤器合奏。 Gneissweb在数据质量和数量之间取得了一个良好的权衡，生产模型优于在最先进的开放大型数据集（5万亿代币）上训练的模型。
  我们表明，使用GneissWeb数据集训练的模型优于在FineWeb-V1.1.0上接受培训的模型，而在一组11个常用的基准测试中计算出的平均得分（零射击和很少射击），用于预先训练数据集评估。当评估集将其扩展到20个基准（零射门和少量射击）时，使用GneissWeb训练的型号仍然比在FineWeb-V1.1.0上训练的模型获得1.75个百分点的优势。]]></description>
      <guid>https://arxiv.org/abs/2502.14907</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>evop：通过进化修剪的强大LLM推论</title>
      <link>https://arxiv.org/abs/2502.14910</link>
      <description><![CDATA[ARXIV：2502.14910V1公告类型：新 
摘要：大型语言模型（LLM）在自然语言处理任务中取得了显着成功，但是它们的庞大规模和计算要求阻碍了它们在资源受限环境中的部署。现有的结构化修剪方法通过从模型中删除冗余结构（例如元素，通道，层）来解决此问题。但是，这些方法采用了启发式修剪策略，从而导致次优性能。此外，在修剪模型时，它们还忽略了数据特征。
  为了克服这些局限性，我们提出了EVOP，这是一个强大的LLM推论的进化修剪框架。 EVOP首先提出了基于群集的校准数据集采样（CCD）策略，以创建更多样化的校准数据集。然后，EVOP引入了一种进化的修剪模式搜索（EPP）方法，以找到最佳的修剪模式。与现有的结构化修剪技术相比，EVOP在保持最佳效率的同时取得了最佳性能。跨不同LLM和不同下游任务的实验验证了提议的EVOP的有效性，使其成为在现实世界应用中部署LLM的实用且可扩展的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.14910</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Batayan：菲律宾NLP邪恶语言模型的基准</title>
      <link>https://arxiv.org/abs/2502.14911</link>
      <description><![CDATA[ARXIV：2502.14911V1公告类型：新 
摘要：大型语言模型（LLMS）的最新进展表现出了广泛基准的高资源语言的显着功能。但是，资源不足的语言的语言细微差别仍未得到探索。我们介绍了Batayan，这是一种整体菲律宾基准测试，旨在系统地评估三种关键自然语言处理（NLP）能力的LLM：理解，推理和产生。 Batayan合并了八项任务，涵盖了他加禄语和代码开关的Taglish usteres。我们严格的言语驱动的注释过程可确保对菲律宾的复杂形态和句法结构的流利性和真实性，从而减轻了现有菲律宾语料库中普遍存在的翻译偏见。我们报告了各种多语言LLM的经验结果，强调了巨大的性能差距，这表明菲律宾人在训练训练中的代表性不足，这是对菲律宾人丰富的形态和构建建模的独特障碍，以及明确的菲律宾语言支持和指导调谐的重要性。此外，我们讨论了数据集构建中遇到的实际挑战，并提出了原则上的解决方案，以在代表性不足的语言上建立文化和语言信仰资源。我们还为菲律宾NLP的迭代，社区驱动的进步提供了公共基准和排行榜，作为明确的基础。]]></description>
      <guid>https://arxiv.org/abs/2502.14911</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于增强材料推理和发现的化学元素的通用语义嵌入</title>
      <link>https://arxiv.org/abs/2502.14912</link>
      <description><![CDATA[ARXIV：2502.14912V1公告类型：新 
摘要：我们提出了一个框架，用于生成化学元素的通用语义嵌入以推进材料推理和发现。该框架利用Elementbert是一种基于域特异性BERT的自然语言处理模型，该模型在12900万种与合金相关的科学论文的摘要中培训，以捕获合金特定的潜在知识和上下文关系。这些语义嵌入是强大的元素描述符，始终优于传统的经验描述符，在多个下游任务之间进行了重大改进。这些包括预测机械和转换特性，对相结构进行分类以及通过贝叶斯优化优化材料特性。对钛合金，高渗透合金和形状的记忆合金的施用表现出高达23％的预测准确性。我们的结果表明，Elementbert通过编码专业合金知识来超过通用BERT变体。通过弥合科学文献的上下文见解，我们的框架加速了高级材料的发现和优化，潜在的应用将超越合金扩展到其他材料类别。]]></description>
      <guid>https://arxiv.org/abs/2502.14912</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenSearch-SQL：通过动态几次和一致性对齐来增强文本到SQL</title>
      <link>https://arxiv.org/abs/2502.14913</link>
      <description><![CDATA[arxiv：2502.14913v1公告类型：新 
摘要：尽管多机构协作大语言模型（LLM）在文本到SQL任务中取得了重大突破，但它们的性能仍然受到各种因素的限制。这些因素包括框架不完整，未能遵循说明和模型幻觉问题。为了解决这些问题，我们提出了OpenSearch-SQL，将文本到SQL任务划分为四个主要模块：预处理，提取，生成和改进，以及基于一致性比对机制的对齐模块。该体系结构通过对齐模块对准代理的输入和输出，从而减少了随后的指令和幻觉的故障。此外，我们设计了一种称为SQL样的中间语言，并基于SQL样的结构化COT进行了优化。同时，我们以自学成才的查询-COT-SQL的形式制定了一种动态的几次策略。这些方法显着改善了文本到SQL任务中LLM的性能。
  在模型选择方面，我们直接应用了基本LLM，而无需任何后培训，从而简化了任务链并增强了框架的可移植性。实验结果表明，OpenSearch-SQL的执行精度（EX）为69.3％，在鸟类开发集中达到72.28％，基于奖励的有效性效率评分（R-VES）为69.36％，这三个为69.36％指标在提交时排名第一。这些结果证明了该方法在有效性和效率方面具有全面的优势。]]></description>
      <guid>https://arxiv.org/abs/2502.14913</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MKE-CODER：中文EMR的ICD编码中具有证据验证的多轴知识</title>
      <link>https://arxiv.org/abs/2502.14916</link>
      <description><![CDATA[ARXIV：2502.14916V1公告类型：新 
摘要：自动编码医学领域的国际疾病分类（ICD）的任务已建立了良好的关注，并受到了很多关注。 ICD在医学领域的自动编码在英语方面已经成功，但是在处理中国电子病历（EMRS）时面临挑战。第一个问题在于很难从中国EMR中提取与疾病代码相关的信息，这主要是由于EMR的简洁写作风格和特定的内部结构。第二个问题是以前的方法未能利用基于疾病的多轴知识，并且与相应的临床证据缺乏关联。本文介绍了一个名为Mke-Coder的新型框架：在ICD编码中国EMR中的证据验证的多轴知识。最初，我们确定了诊断的候选代码，并将它们分类为四个编码轴的知识。随后，我们通过评分模型从EMR的全面内容中检索了相应的临床证据，并从EMR的综合内容中获取了可靠的证据。最后，为了确保候选代码的有效性，我们根据蒙版语言建模策略提出了一个推论模块。该模块验证了与候选代码相关的所有轴心知识均由证据支持，并相应地提供了建议。为了评估框架的性能，我们使用从各个医院收集的大规模中国EMR数据集进行实验。实验结果表明，MKE-Coder在基于中国EMR的自动ICD编码任务中表现出显着优越性。在对我们模拟的真实编码方案中我们方法的实际评估中，已经证明我们的方法可以大大帮助编码者提高其编码准确性和速度。]]></description>
      <guid>https://arxiv.org/abs/2502.14916</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>金丝雀的回声：LLM生成的合成文本的审计隐私风险</title>
      <link>https://arxiv.org/abs/2502.14921</link>
      <description><![CDATA[ARXIV：2502.14921V1公告类型：新 
摘要：从大语言模型（LLM）生成的合成数据中可以收集多少有关培训样本的信息？忽略合成数据生成管道中信息流的微妙之处可能会导致错误的隐私感。在本文中，我们设计了用于微调预训练的LLM的目标数据的成员推理攻击（MIA），然后用于合成数据，尤其是当对手无法访问微型模型，而仅当对手可以访问微型模型时合成数据。我们表明，这种基于数据的MIA比随机猜测要好得多，这意味着合成数据会泄漏有关培训数据的信息。此外，我们发现，在仅释放合成数据时，精心制作的金融旨在最大程度地提高基于模型的MIA的脆弱性，这是对隐私审核的最佳选择。当提示产生有用的，分布的合成数据时，这种分布的金丝雀对模型的输出的影响有限，从而大大降低了它们的脆弱性。为了解决这个问题，我们利用自动回归模型的力学来设计带有分布前缀和高充实后缀的金丝雀，这些后缀将可检测到的痕迹留在合成数据中。这增强了基于数据的MIA的功能，并更好地评估了释放LLMS生成的合成数据的隐私风险。]]></description>
      <guid>https://arxiv.org/abs/2502.14921</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SIFT：通过贴纸在上下文中扎根LLM推理</title>
      <link>https://arxiv.org/abs/2502.14922</link>
      <description><![CDATA[Arxiv：2502.14922V1公告类型：新 
摘要：本文确定了对上下文的误解可能是一个重要的问题，在大型语言模型的推理过程中，从诸如llama3.2-3b-Instruct到诸如deepSeek-r1之类的尖端模型。例如，在“每公斤10美元”一词中，LLMS可能无法认识到每个人的“均”表示“”，导致计算错误。我们介绍了一种小说，训练后的方法，称为**坚持事实（Sift）**解决这个问题。在上下文中，将推理时间计算增加到地面LLM推理。 SIFT的核心是 *贴纸 *，该 *由模型本身生成，以明确强调上下文中的关键信息。鉴于策划的贴纸，SIFT产生了两个预测 - 一个来自原始查询，另一个来自带有贴纸的查询。如果它们有所不同，则贴纸将通过 *正向 *优化（以更好地使提取的事实与查询更好地对齐）和 *逆 *生成（以符合模型的固有趋势），以实现更忠实的推理结果。跨不同模型（从3B到100B+）和基准测试（例如GSM8K，Math-500）的研究揭示了稳定的性能改善。值得注意的是，SIFT将AIME2024上DeepSeek-R1的通行证从78.33％提高到** 85.67 **％，在开源社区中建立了新的最先进。该代码可在https://github.com/zhijie-group/sift上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.14922</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能思考是一个以意义为中心的框架：通过社区代理重新构想语言技术</title>
      <link>https://arxiv.org/abs/2502.14923</link>
      <description><![CDATA[arxiv：2502.14923v1公告类型：新 
摘要：虽然语言技术已经显着发展，但当前的方法无法解决语言保存的复杂社会文化维度。 AI思维提出了一个以意义为中心的框架，该框架将从创建社区的工具转变为与之共同创建解决方案的工具。这种方法认识到，有意义的解决方案通过文化理解，社区代理和技术创新的相互作用而出现。该提案阐明了整体方法和五层技术生态系统，社区保持对他们语言和文化知识代表的控制。社区需求，文化保护和高级能力的系统整合可能会彻底改变我们如何在数字时代的语言多样性来维护。]]></description>
      <guid>https://arxiv.org/abs/2502.14923</guid>
      <pubDate>Mon, 24 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>