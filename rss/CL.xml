<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 05 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于多模式实体链接的最佳传输引导关联分配</title>
      <link>https://arxiv.org/abs/2406.01934</link>
      <description><![CDATA[arXiv:2406.01934v1 公告类型：新 
摘要：多模态实体链接 (MEL) 旨在将多模态上下文中的模糊提及链接到多模态知识图中的实体。一个关键的挑战是充分利用提及和实体之间的多元素相关性来弥合模态差距并实现细粒度语义匹配。现有方法尝试了几种局部相关机制，严重依赖自动学习的注意权重，这可能会过度集中在部分相关性上。为了缓解这个问题，我们将相关性分配问题表述为最优传输 (OT) 问题，并提出了一种新的 MEL 框架，即 OT-MEL，具有 OT 引导的相关性分配。因此，我们利用多模态特征之间的相关性来增强多模态融合，并利用提及和实体之间的相关性来增强细粒度匹配。为了加速模型预测，我们进一步利用知识提炼将 OT 分配知识转移到注意机制。实验结果表明，我们的模型明显优于之前最先进的基线，并证实了 OT 引导的相关分配的有效性。]]></description>
      <guid>https://arxiv.org/abs/2406.01934</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:11 GMT</pubDate>
    </item>
    <item>
      <title>渥太华：用于幻觉和遗漏翻译错误检测的最佳 TransporT 自适应词对齐器</title>
      <link>https://arxiv.org/abs/2406.01919</link>
      <description><![CDATA[arXiv:2406.01919v1 公告类型：新
摘要：最近，人们对机器翻译 (MT) 系统中的幻觉和遗漏检测给予了相当大的关注。解决此任务的两种主要方法涉及分析 MT 系统的内部状态或依赖外部工具的输出，例如句子相似性或 MT 质量估计器。在这项工作中，我们介绍了 OTTAWA，这是一种基于最佳传输 (OT) 的新型单词对齐器，专门用于增强 MT 系统中幻觉和遗漏的检测。我们的方法通过引入“空”向量明确地模拟缺失的对齐，为此我们提出了一种新颖的单侧约束 OT 设置以允许自适应空对齐。与 HalOmi 基准上 18 种语言对的最新方法相比，我们的方法产生了具有竞争力的结果。此外，它还展示了有希望的功能，例如能够区分两种错误类型并执行单词级检测而无需访问 MT 系统的内部状态。]]></description>
      <guid>https://arxiv.org/abs/2406.01919</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:10 GMT</pubDate>
    </item>
    <item>
      <title>有益且无害的不诚实</title>
      <link>https://arxiv.org/abs/2406.01931</link>
      <description><![CDATA[arXiv:2406.01931v1 公告类型：新
摘要：人们在寻求奖励时会撒谎。大型语言模型 (LLM) 通过强化学习与人类价值观保持一致，如果它们满足人类偏好，它们就会获得奖励。我们发现，这也会在有益和无害的对齐中引发不诚实，而 LLM 在生成无害反应时会撒谎。使用最新的解释工具，我们可以检测到不诚实，展示如果 LLM 的诚实度增加，它们会如何有害，并在参数级别分析此类冲突。鉴于这些准备工作和寻求奖励会刺激不诚实的假设，我们从理论上表明，不诚实反过来会降低对齐性能，并通过表示正则化增强寻求奖励的对齐。包括 GPT-4 注释的胜率、困惑度和案例研究在内的大量结果表明，我们可以训练出更诚实、更有益、更无害的 LLM。我们将在本文被接受后将我们的所有代码和结果开源。]]></description>
      <guid>https://arxiv.org/abs/2406.01931</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:10 GMT</pubDate>
    </item>
    <item>
      <title>CR-UTP：经认证的针对通用文本扰动的鲁棒性</title>
      <link>https://arxiv.org/abs/2406.01873</link>
      <description><![CDATA[arXiv:2406.01873v1 公告类型：新
摘要：必须确保语言模型所做的每个预测的稳定性；也就是说，语言的预测应该保持一致，尽管输入有细微变化，比如单词替换。在本文中，我们研究了认证语言模型对通用文本扰动 (UTP) 的鲁棒性问题，UTP 已广泛应用于通用对抗攻击和后门攻击。现有的基于随机平滑的认证鲁棒性在认证输入特定的文本扰动 (ISTP) 方面表现出了相当大的前景，其假设是样本的干净词或对抗词的任何随机改变都会抵消样本扰动的影响。然而，对于 UTP，只屏蔽对抗词就可以消除攻击。一种简单的方法是简单地增加屏蔽率和屏蔽攻击标记的可能性，但由于大量屏蔽导致输入损坏，这会导致认证准确度和认证半径显著降低。为了解决这一挑战，我们引入了一种新方法，即优越提示搜索方法，旨在识别在广泛掩蔽的情况下保持更高认证准确度的优越提示。此外，我们从理论上解释了为什么集合是作为随机平滑的基本提示的特别合适的选择。该方法由优越提示集合技术表示。我们还通过经验证实了这项技术，在多种设置中获得了最先进的结果。这些方法首次实现了针对 UTP 和 ISTP 的高认证准确度。CR-UTP 的源代码可在 https://github.com/UCFML-Research/CR-UTP 获得。]]></description>
      <guid>https://arxiv.org/abs/2406.01873</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:09 GMT</pubDate>
    </item>
    <item>
      <title>Bi-DCSpell：一种用于中文拼写检查的双向检测-校正交互式框架</title>
      <link>https://arxiv.org/abs/2406.01879</link>
      <description><![CDATA[arXiv:2406.01879v1 公告类型：新
摘要：中文拼写检查（CSC）旨在检测和纠正中文句子中可能拼写错误的字符。自然，它涉及检测和纠正子任务，它们动态地相互作用。这种相互作用是双向的，即检测结果有助于降低过度纠正和纠正不足的风险，而从纠正中学习到的知识有助于防止错误检测。当前的 CSC 方法有两种类型：仅纠正或单向检测到纠正交互框架。尽管如此，他们忽略了检测和纠正之间的双向相互作用。本文旨在通过提出一种用于 CSC 的双向检测器-校正器框架（Bi-DCSpell）来填补这一空白。值得注意的是，Bi-DCSpell 包含单独的检测和校正编码器，然后是一个新颖的交互式学习模块，促进检测和校正之间的双向特征交互，以改善彼此的表示学习。大量实验结果表明，Bi-DCSpell 在广泛使用的基准数据集上具有稳健的校正性能，同时具有令人满意的检测能力。]]></description>
      <guid>https://arxiv.org/abs/2406.01879</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:09 GMT</pubDate>
    </item>
    <item>
      <title>迈向有效的时间感知语言表征：探索语言模型中增强的时间理解</title>
      <link>https://arxiv.org/abs/2406.01863</link>
      <description><![CDATA[arXiv:2406.01863v1 公告类型：新
摘要：在不断发展的自然语言处理领域，理解文本的时间背景变得越来越重要。本研究探讨了在预训练期间纳入时间信息的方法，旨在实现有效的时间感知语言表示，以提高与时间相关的任务的性能。与依赖于同步文档集（例如 BookCorpus 和 Wikipedia）的常见预训练模型（如 BERT）相比，我们的研究引入了 BiTimeBERT 2.0，这是一种在时间新闻文章集上进行预训练的新型语言模型。BiTimeBERT 2.0 利用这个时间新闻集合，专注于三个创新的预训练目标：时间感知掩蔽语言建模 (TAMLM)、文档日期 (DD) 和时间敏感实体替换 (TSER)。每个目标都针对时间信息的一个独特方面。 TAMLM 旨在增强对时间背景和关系的理解，DD 将文档时间戳集成为时间标记，而 TSER 则专注于“人”实体的时间动态，认识到其固有的时间意义。实验结果一致表明，BiTimeBERT 2.0 的表现优于 BERT 等模型和其他现有的预训练模型，在时间起着关键作用的各种下游 NLP 任务和应用中取得了显著的进步。]]></description>
      <guid>https://arxiv.org/abs/2406.01863</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:08 GMT</pubDate>
    </item>
    <item>
      <title>#EpiTwitter：COVID-19 疫情期间的公共卫生信息</title>
      <link>https://arxiv.org/abs/2406.01866</link>
      <description><![CDATA[arXiv:2406.01866v1 公告类型：新
摘要：在健康危机期间，有效沟通至关重要，社交媒体是公共卫生专家 (PHE) 与公众互动的重要平台。然而，它也放大了伪专家宣传相反观点的影响力。尽管情感和道德语言在 COVID-19 期间 PHE 沟通中的作用很重要，但仍未得到充分探索。本研究考察了 PHE 和伪专家在疫情期间如何在 Twitter 上交流，重点关注情感和道德语言及其与政治精英的互动。通过分析 2020 年 1 月至 2021 年 1 月期间 489 名 PHE 和 356 名伪专家的推文以及公众的反应，我们确定了关键优先事项和信息传递策略的差异。PHE 优先考虑戴口罩、医疗保健、教育和疫苗，使用乐观等积极的情感语言。相比之下，伪专家更频繁地讨论治疗方法和封锁，使用悲观和厌恶等负面情绪。消极的情感和道德语言往往会推动参与，但 PHE 的积极语言会促进公众的积极反应。PHE 表现出自由党派倾向，对自由派表现出更多积极性，对保守派精英表现出更多消极性，而伪专家则表现出保守党派倾向。这些发现揭示了 COVID-19 话语的两极分化，并强调了专家策略性地使用情感和道德语言对缓解两极分化和增强公众信任的重要性。]]></description>
      <guid>https://arxiv.org/abs/2406.01866</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:08 GMT</pubDate>
    </item>
    <item>
      <title>TruthEval：评估 LLM 真实性和可靠性的数据集</title>
      <link>https://arxiv.org/abs/2406.01855</link>
      <description><![CDATA[arXiv:2406.01855v1 公告类型：新
摘要：大型语言模型 (LLM) 评估是目前最重要的研究领域之一，现有的基准测试被证明是不够的，不能完全代表 LLM 的各种能力。我们为 LLM 基准测试提供了一个精选的敏感主题挑战性陈述集合，称为 TruthEval。这些陈述是手工挑选的，包含已知的真值。选择这些类别是为了区分 LLM 的能力和其随机性。我们使用此数据集进行了一些初步分析，发现几个 LLM 在简单任务中失败的实例表明它们无法理解简单的问题。]]></description>
      <guid>https://arxiv.org/abs/2406.01855</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:07 GMT</pubDate>
    </item>
    <item>
      <title>使用迭代上下文学习获取大型语言模型的先验知识</title>
      <link>https://arxiv.org/abs/2406.01860</link>
      <description><![CDATA[arXiv:2406.01860v1 公告类型：新
摘要：随着大型语言模型 (LLM) 越来越多地部署在现实世界中，了解它们在做出决策时隐含使用的知识至关重要。获取这种知识的一种方法是采用贝叶斯先验分布的形式。我们开发了一个基于提示的工作流程，用于从 LLM 中引出先验分布。我们的方法基于迭代学习，这是一种马尔可夫链蒙特卡罗方法，其中连续推理以支持从先验分布中采样的方式链接在一起。我们在迭代学习以前曾用于估计人类参与者的先验的环境中验证了我们的方法——因果学习、比例估计和预测日常数量。我们发现从 GPT-4 中引出的先验在这些环境中与人类先验在质量上一致。然后，我们使用相同的方法从 GPT-4 中引出各种推测事件的先验，例如超人类人工智能的发展时机。]]></description>
      <guid>https://arxiv.org/abs/2406.01860</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:07 GMT</pubDate>
    </item>
    <item>
      <title>语境化序列似然：增强自然语言生成的置信度分数</title>
      <link>https://arxiv.org/abs/2406.01806</link>
      <description><![CDATA[arXiv:2406.01806v1 公告类型：新
摘要：大型语言模型 (LLM) 的出现极大地推动了众多自然语言生成任务的最新进展。为了可靠地应用 LLM，必须准确衡量其置信度。目前，最常用的置信度得分函数是生成序列的可能性，但它混淆了语义和句法成分。例如，在问答 (QA) 任务中，正确答案的措辞不当可能会导致较低的概率预测。此外，不同的标记应根据上下文赋予不同的权重。在这项工作中，我们建议通过使用从基础 LLM 中引出的注意力值为各种标记分配不同的权重来增强预测的序列概率。通过使用验证集，我们可以识别相关的注意力头，从而显着提高原始序列概率置信度测量的可靠性。我们将这个新分数称为上下文序列似然 (CSL)。 CSL 易于实现，计算速度快，并且通过针对特定任务的提示提供了巨大的进一步改进潜力。在多个 QA 数据集和各种 LLM 中，CSL 在预测生成质量方面表现出比最先进的基线更高的可靠性，这由 AUROC 或 AUARC 测量。]]></description>
      <guid>https://arxiv.org/abs/2406.01806</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:06 GMT</pubDate>
    </item>
    <item>
      <title>用于对维基百科的可读性进行评分的开放式多语言系统</title>
      <link>https://arxiv.org/abs/2406.01835</link>
      <description><![CDATA[arXiv:2406.01835v1 公告类型：新
摘要：维基百科拥有超过 6000 万篇文章，已成为最大的开放和免费知识平台。虽然每月访问量超过 150 亿次，但由于文本可读性不足，许多读者无法访问其内容。然而，之前对维基百科可读性的调查仅限于英语，目前还没有系统支持对维基百科中 300 多种语言的自动可读性评估。为了弥补这一差距，我们开发了一个多语言模型来对维基百科文章的可读性进行评分。为了训练和评估这个模型，我们通过将维基百科中的文章与简化的维基百科和在线儿童百科全书进行匹配，创建了一个涵盖 14 种语言的新型多语言数据集。我们表明，我们的模型在零样本场景中表现良好，在 14 种语言中的排名准确率超过 80%，并且比之前的基准有所提高。这些结果证明了该模型对于没有可用于模型微调的地面实况数据的语言具有大规模适用性。此外，我们首次概述了维基百科除英语以外的可读性状态。]]></description>
      <guid>https://arxiv.org/abs/2406.01835</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:06 GMT</pubDate>
    </item>
    <item>
      <title>超越英语的法学硕士：通过跨语言反馈扩展法学硕士的多语言能力</title>
      <link>https://arxiv.org/abs/2406.01771</link>
      <description><![CDATA[arXiv:2406.01771v1 公告类型：新
摘要：为了将大型语言模型 (LLM) 普及到大多数自然语言，必须使这些模型能够理解和生成多种语言的文本，尤其是资源匮乏的语言。虽然最近的多语言 LLM 在这些功能方面表现出色，但由于缺乏资源匮乏语言的训练数据，这些 LLM 仍然支持有限数量的人类语言。此外，这些 LLM 尚未与人类对下游任务的偏好保持一致，这对于英语 LLM 的成功至关重要。在本文中，我们介绍了 xLLaMA-100 和 xBLOOM-100（统称为 xLLMs-100），它们将 LLaMA 和 BLOOM 的多语言功能扩展到 100 种语言。为此，我们构建了两个数据集：一个包含 100 种语言的多语言教学数据集，代表了迄今为止最大的语言覆盖范围，以及一个包含 30 种语言的跨语言人工反馈数据集。我们对构建的指令数据进行多语言指令调整，并使用跨语言人类反馈数据集上的 DPO 算法进一步将 LLM 与人类反馈对齐。我们在五个多语言基准上评估了 xLLMs-100 的多语言理解和生成能力。实验结果表明，xLLMs-100 在基准测试中始终以相当大的优势领先于同类产品，定义了一种支持 100 种语言的全新最先进的多语言 LLM。]]></description>
      <guid>https://arxiv.org/abs/2406.01771</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:05 GMT</pubDate>
    </item>
    <item>
      <title>OLoRA：大型语言模型的正交低秩自适应</title>
      <link>https://arxiv.org/abs/2406.01775</link>
      <description><![CDATA[arXiv:2406.01775v1 公告类型：新
摘要：大型语言模型 (LLM) 的出现彻底改变了自然语言处理，使理解和生成类似人类的文本具有前所未有的能力。然而，与微调这些模型相关的计算成本和收敛时间仍然是重大挑战。低秩自适应 (LoRA) 已成为一种有前途的方法，通过引入有效的微调技术和减少可训练参数的数量来缓解这些问题。在本文中，我们提出了 OLoRA，这是对 LoRA 方法的增强，它通过 QR 分解利用正交矩阵初始化。OLoRA 显着加快了 LLM 训练的收敛速度，同时保留了 LoRA 的效率优势，例如可训练参数的数量和 GPU 内存占用。我们的实证评估表明，与标准 LoRA 相比，OLoRA 不仅收敛速度更快，而且在各种语言建模任务中表现出更好的性能。这一进步为更高效、更易于访问的 LLM 微调开辟了新途径，有可能实现自然语言应用的更广泛的采用和创新。]]></description>
      <guid>https://arxiv.org/abs/2406.01775</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:05 GMT</pubDate>
    </item>
    <item>
      <title>旋转和排列用于高级异常值管理和 LLM 的有效量化</title>
      <link>https://arxiv.org/abs/2406.01721</link>
      <description><![CDATA[arXiv:2406.01721v1 公告类型：新
摘要：量化大型语言模型 (LLM) 面临重大挑战，主要是由于异常激活会影响低位表示的效率。传统方法主要侧重于解决所有标记中具有一致高幅度的正常异常激活。然而，这些技术在处理大量异常值时会失效，这些异常值的值明显更高，并且经常在低位量化期间造成相当大的性能损失。在本研究中，我们提出了 DuQuant，这是一种创新的量化策略，采用旋转和置换变换来更有效地消除这两种类型的异常值。首先，DuQuant 构建由特定异常值维度通知的旋转矩阵，将这些异常值重新分布在不同旋转块内的相邻通道上。随后，应用锯齿形置换以确保异常值在块之间的平衡分布，从而最大限度地减少块方差。额外的旋转进一步增强了激活景观的平滑度，从而提高了模型性能。 DuQuant 简化了量化过程，并展示了卓越的异常值管理，即使在 4 位权重激活量化下，也能在多种 LLM 架构的多个任务中实现顶级结果。我们的代码可在 https://github.com/Hsu1023/DuQuant 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.01721</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:04 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型理解对话基础</title>
      <link>https://arxiv.org/abs/2406.01749</link>
      <description><![CDATA[arXiv:2406.01749v1 公告类型：新
摘要：对话基础是一种在参与对话的参与者之间建立相互知识的协作机制。这项实验研究分析了寻求信息的对话，以调查大型语言模型在对与显性或隐性基础相关的对话轮次进行分类以及预测基础知识元素方面的能力。我们的实验结果揭示了大型语言模型在这两个任务中遇到的挑战，并讨论了正在进行的研究工作，以通过管道架构和知识库增强基于大型语言模型的对话基础理解。这些举措旨在开发更有效的对话系统，以更好地处理对话中基础知识的复杂性。]]></description>
      <guid>https://arxiv.org/abs/2406.01749</guid>
      <pubDate>Wed, 05 Jun 2024 06:19:04 GMT</pubDate>
    </item>
    </channel>
</rss>