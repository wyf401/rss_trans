<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 23 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>OG-RAG：基于本体的检索增强大型语言模型生成</title>
      <link>https://arxiv.org/abs/2412.15235</link>
      <description><![CDATA[arXiv:2412.15235v1 公告类型：新
摘要：本文介绍了 OG-RAG，这是一种基于本体的检索增强生成方法，旨在通过将检索过程锚定在特定领域的本体中来增强 LLM 生成的响应。虽然 LLM 广泛用于问答和搜索等任务，但它们很难适应专业知识，例如工业工作流程或知识工作，而无需昂贵的微调或次优检索方法。现有的检索增强模型（例如 RAG）提供了改进，但未能考虑结构化领域知识，导致上下文生成不理想。本体通过定义实体及其相互关系来概念化组织领域知识，它提供了一种结构化表示来解决这一差距。OG-RAG 构建了领域文档的超图表示，其中每个超边都封装了使用特定领域本体论的事实知识集群。然后，优化算法会检索最小超边集，从而为 LLM 构建精确的、概念上扎实的上下文。此方法能够在保留实体之间复杂关系的同时实现高效检索。OG-RAG 适用于需要基于事实的推理的领域，特别是需要工作流或决策步骤遵循预定义规则和程序的任务。这些包括医疗保健、法律和农业领域的工业工作流，以及新闻报道、调查研究、咨询等知识驱动的任务。我们的评估表明，OG-RAG 在四个不同的 LLM 中将准确事实的回忆率提高了 55%，并将响应正确率提高了 40%。此外，与基线方法相比，OG-RAG 能够将响应归因于上下文的速度提高 30%，并将基于事实的推理准确性提高 27%。]]></description>
      <guid>https://arxiv.org/abs/2412.15235</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CareBot：开创性的全流程开源医学语言模型</title>
      <link>https://arxiv.org/abs/2412.15236</link>
      <description><![CDATA[arXiv:2412.15236v1 公告类型：新
摘要：最近，闭源 LLM 和开源社区都取得了重大进展，在各个通用领域都超越了人类。然而，由于医学知识的复杂性，它们在医学等特定专业领域的表现仍然不理想，尤其是在开源社区中。在本文中，我们提出了双语医学 LLM CareBot，它利用了一种综合方法，将持续预训练 (CPT)、监督微调 (SFT) 和强化学习与人工反馈 (RLHF) 相结合。我们新颖的两阶段 CPT 方法包括稳定 CPT 和 Boost CPT，有效地弥合了一般数据和领域特定数据之间的差距，促进了从预训练到微调的平稳过渡，并逐步增强领域知识。我们还引入了 DataRater，这是一个旨在评估 CPT 期间数据质量的模型，确保训练数据既准确又相关。对于 SFT，我们开发了一个庞大而多样化的双语数据集，以及 ConFilter（一种提高多轮对话质量的指标），这对于提高模型处理更复杂对话的能力至关重要。高质量数据源和创新技术的结合显著提高了 CareBot 在一系列医疗应用中的性能。我们对中文和英文基准的严格评估证实了 CareBot 在医疗咨询和教育方面的有效性。这些进步不仅解决了医学法学硕士目前存在的局限性，还为在医学领域开发有效可靠的开源模型树立了新标准。我们稍后将开源数据集和模型，为研究界贡献宝贵的资源。]]></description>
      <guid>https://arxiv.org/abs/2412.15236</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Dipper：在推理任务中生成大型语言模型集成的提示多样性</title>
      <link>https://arxiv.org/abs/2412.15238</link>
      <description><![CDATA[arXiv:2412.15238v1 公告类型：新
摘要：大型语言模型在推理任务中仍然面临巨大挑战，尤其是对于较小的模型，许多用户可能由于资源限制（例如 GPU 内存限制）而受到限制。在过去的工作中，提高 LLM 性能的推理时间方法（例如在响应中调用某些推理路径的提示方法）已被证明是有效的，尽管它们在很大程度上依赖于顺序查询。集成方法由并行运行的多个组成模型组成，是一种实现更好推理时间性能的有前途的方法，特别是考虑到最近的发展使 LLM 批量推理的速度显着提高。在这项工作中，我们提出了一个新颖的、无需训练的 LLM 集成框架，其中单个 LLM 模型并行输入一组优化的、多样化的提示，有效地在推理时产生一个集成，以实现推理任务的性能改进。我们通过实证研究证明，我们的方法在数学推理任务上取得了显著的进步，例如在 MATH 上，由几个小模型（例如三个 Qwen2-MATH-1.5B-it 模型）组成的集成模型可以胜过一个更大的模型（例如 Qwen2-MATH-7B-it）。]]></description>
      <guid>https://arxiv.org/abs/2412.15238</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>建立故事期望模型以了解参与度：使用 LLM 的生成框架</title>
      <link>https://arxiv.org/abs/2412.15239</link>
      <description><![CDATA[arXiv:2412.15239v1 公告类型：新
摘要：了解消费者何时以及为何参与故事对于内容创建者和平台至关重要。虽然现有理论表明，观众对即将发生的事情的信念应该在参与决策中发挥重要作用，但实证研究主要集中在开发直接从实际内容中提取特征的技术，而不是捕捉前瞻性信念，因为缺乏在非结构化叙述数据中建模此类信念的原则性方法。为了补充现有的特征提取技术，本文介绍了一个新颖的框架，该框架利用大型语言模型来模拟观众对故事可能如何展开的前瞻性信念。我们的方法为每个故事生成多个潜在的延续，并使用成熟的内容分析技术提取与期望、不确定性和惊喜相关的特征。将我们的方法应用于 Wattpad 的 30,000 多个书籍章节，我们证明我们的框架补充了现有的特征工程技术，通过平均将其边际解释力放大 31%。结果表明，不同类型的参与（继续阅读、评论和投票）是由当前和预期内容特征的不同组合驱动的。我们的框架提供了一种新颖的方法来研究和探索受众的前瞻性信念如何影响他们对叙事媒体的参与，这对以内容为中心的行业的营销策略具有启示意义。]]></description>
      <guid>https://arxiv.org/abs/2412.15239</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ChainStream：基于 LLM 的统一合成感知框架</title>
      <link>https://arxiv.org/abs/2412.15240</link>
      <description><![CDATA[arXiv:2412.15240v1 公告类型：新 
摘要：许多应用程序需要上下文感知来提供个性化和及时的服务。然而，开发感知程序对开发人员来说可能具有挑战性，并且使用它们会危及最终用户的隐私。在本文中，我们建议使用自然语言作为处理个人数据和感知用户上下文的统一接口，这可以有效地简化应用程序开发并使数据管道更加透明。我们的工作受到大型语言模型（LLM）和其他生成模型的启发，而直接应用它们并不能解决问题——让模型直接处理数据无法处理复杂的感知请求，而让模型编写数据处理程序会导致容易出错的代码生成。我们通过 1）使上下文感知程序更简单的统一数据处理框架和 2）使数据查询更具信息的反馈引导查询优化器来解决问题。为了评估基于自然语言的上下文感知的性能，我们创建了一个包含 133 个上下文感知任务的基准。大量评估表明，我们的方法能够高效、准确地自动解决情境感知任务。代码已在 https://github.com/MobileLLM/ChainStream 开源。]]></description>
      <guid>https://arxiv.org/abs/2412.15240</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>量化文本嵌入模型中的位置偏差</title>
      <link>https://arxiv.org/abs/2412.15241</link>
      <description><![CDATA[arXiv:2412.15241v1 公告类型：新
摘要：嵌入模型对于信息检索 (IR) 和语义相似性测量中的任务至关重要，但它们对较长文本和相关位置偏差的处理仍未得到充分探索。在本研究中，我们研究了内容位置和输入大小对文本嵌入的影响。我们的实验表明，无论嵌入模型的位置编码机制如何，它们都会不成比例地优先考虑输入的开头。消融研究表明，在文档开头插入或删除不相关的文本会使改变的嵌入和原始嵌入之间的余弦相似度比在结尾处消融降低高达 12.3%。回归分析进一步证实了这种偏差，即使具有内容不可知性，句子的重要性也会随着位置从开头进一步移动而下降。我们假设这种影响来自预处理策略和选择的位置编码技术。这些发现量化了检索系统的敏感性，并为嵌入模型稳健性提供了新的视角。]]></description>
      <guid>https://arxiv.org/abs/2412.15241</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于脚本的 LLM 对话代理对话策略规划：“AI 治疗师”的基本架构</title>
      <link>https://arxiv.org/abs/2412.15242</link>
      <description><![CDATA[arXiv:2412.15242v1 公告类型：新
摘要：大型语言模型 (LLM) 驱动的对话代理有可能为用户提供规模化的行为医疗支持，甚至可能在未来提供全面的“AI 治疗”。虽然这样的代理已经可以进行流畅和主动的情感支持对话，但它们本质上缺乏以下能力：(a) 始终如一地、可靠地按照预定义的规则采取行动，以使他们的对话与总体治疗概念保持一致，以及 (b) 使他们的决策路径可检查以进行风险管理和临床评估——这两者都是“AI 治疗师”的基本要求。
在这项工作中，我们引入了一种对话代理对话政策规划的新范式，使他们能够 (a) 根据专家编写的概述治疗方法的“脚本”行事，以及 (b) 在对话过程中明确地过渡一组有限的状态。该脚本充当确定性组件，以理想的方式约束 LLM 的行为并为 AI 治疗师建立基本架构。
我们使用不同的提示技术实施了两种基于脚本的对话策略规划变体，并合成了与 LLM 模拟患者的总共 100 次对话。结果证明了这项新技术的可行性，并深入了解了不同实施变体的效率和有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.15242</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MPPO：具有任意负样本的 LLM 的多对偏好优化</title>
      <link>https://arxiv.org/abs/2412.15244</link>
      <description><![CDATA[arXiv:2412.15244v1 公告类型：new 
摘要：将大型语言模型（LLM）与人类反馈对齐对于其发展至关重要。现有的偏好优化方法如DPO和KTO，虽然基于人类反馈强化学习（RLHF）进行了改进，但本质上是从PPO衍生而来的，需要参考模型增加GPU内存资源，并且严重依赖丰富的偏好数据。同时，目前的偏好优化研究主要针对具有两个回复的单问场景，忽略了具有多个回复的优化，这导致应用中的数据浪费。本研究引入了MPPO算法，该算法利用模型响应的平均似然来拟合奖励函数并最大化偏好数据的利用率。通过对Point-wise，Pair-wise和List-wise实现的比较，我们发现Pair-wise方法实现了最佳性能，显着提高了模型响应的质量。实验结果表明MPPO在各种基准测试中均表现出色。在 MT-Bench 上，MPPO 的表现优于 DPO、ORPO 和 SimPO。值得注意的是，在 Arena-Hard 上，MPPO 的表现远超 DPO 和 ORPO。这些成绩凸显了 MPPO 在偏好优化任务中的显著优势。]]></description>
      <guid>https://arxiv.org/abs/2412.15244</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>加速检索增强生成</title>
      <link>https://arxiv.org/abs/2412.15246</link>
      <description><![CDATA[arXiv:2412.15246v1 公告类型：新
摘要：一种解决幻觉并提高大型语言模型 (LLM) 准确性的不断发展的解决方案是检索增强生成 (RAG)，它涉及使用从外部知识源（例如网络）检索的信息来增强 LLM。本文介绍了几个 RAG 执行管道，并揭开了它们检索和生成阶段之间复杂的相互作用。我们证明，虽然精确检索方案成本高昂，但与近似检索变体相比，它们可以减少推理时间，因为精确检索模型可以向生成模型发送更小但更准确的文档列表，同时保持相同的端到端准确性。这一观察结果促使加速 RAG 的精确最近邻搜索。
在这项工作中，我们设计了智能知识存储 (IKS)，这是一种 2 型 CXL 设备，它实现了横向扩展近内存加速架构，在主机 CPU 和近内存加速器之间具有新颖的缓存一致性接口。与在 Intel Sapphire Rapids CPU 上执行搜索相比，IKS 在 512GB 矢量数据库上提供 13.4-27.9 倍的精确最近邻搜索速度。对于代表性 RAG 应用程序，这种更高的搜索性能意味着端到端推理时间缩短了 1.7-26.3 倍。IKS 本质上是一个内存扩展器；其内部 DRAM 可以分解并用于服务器上运行的其他应用程序，以防止 DRAM（当今服务器中最昂贵的组件）被搁置。]]></description>
      <guid>https://arxiv.org/abs/2412.15246</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>简化系统评价：大型语言模型的新应用</title>
      <link>https://arxiv.org/abs/2412.15247</link>
      <description><![CDATA[arXiv:2412.15247v1 公告类型：新
摘要：系统评价 (SR) 对于循证指南至关重要，但通常受到文献筛选耗时的限制。我们提出并评估了一种基于大型语言模型 (LLM) 的内部系统，用于自动进行标题/摘要和全文筛选，以解决文献中的一个关键空白。使用一份关于维生素 D 和跌倒的完整 SR（14,439 篇文章），基于 LLM 的系统采用快速工程进行标题/摘要筛选，采用检索增强生成 (RAG) 进行全文筛选。该系统实现了 99.5% 的文章排除率 (AER)、99.6% 的特异性、0% 的假阴性率 (FNR) 和 100% 的阴性预测值 (NPV)。筛选后，只有 78 篇文章需要人工审查，其中包括通过传统方法确定的所有 20 篇，将人工筛选时间缩短了 95.5%。相比之下，商业标题/摘要筛选工具 Rayyan 在纳入 Rayyan 认为尚未决定或可能纳入的文章时，实现了 72.1% 的 AER 和 5% 的 FNR。降低 Rayyan 的纳入门槛可将 FNR 提高到 0%，但会增加筛选时间。通过解决两个筛选阶段，基于 LLM 的系统明显优于 Rayyan 和传统方法，将总筛选时间缩短至 25.5 小时，同时保持了高准确度。这些发现凸显了 LLM 在 SR 工作流程中的变革潜力，它提供了一种可扩展、高效且准确的解决方案，尤其是对于缺乏自动化工具的全文筛选阶段。]]></description>
      <guid>https://arxiv.org/abs/2412.15247</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RoundTripOCR：一种用于增强低资源梵文语言中 OCR 后纠错的数据生成技术</title>
      <link>https://arxiv.org/abs/2412.15248</link>
      <description><![CDATA[arXiv:2412.15248v1 公告类型：新
摘要：光学字符识别 (OCR) 技术彻底改变了印刷文本的数字化，实现了跨各个领域的高效数据提取和分析。与机器翻译系统一样，OCR 系统也容易出错。在这项工作中，我们解决了数据生成和 OCR 后纠错的挑战，特别是针对资源匮乏的语言。我们提出了一种用于 Devanagari 语言的合成数据生成方法 RoundTripOCR，该方法解决了资源匮乏语言的 OCR 后纠错数据集的稀缺问题。我们发布了印地语、马拉地语、博多语、尼泊尔语、孔卡尼语和梵语的 OCR 后文本校正数据集。我们还提出了一种利用机器翻译技术进行 OCR 纠错的新方法。我们的方法是将 OCR 错误视为平行文本语料库中的错译，将错误的 OCR 输出转换为纠正形式，采用预先训练的变换器模型来学习从错误到正确文本对的映射，从而有效地纠正 OCR 错误。]]></description>
      <guid>https://arxiv.org/abs/2412.15248</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>文学评论法学硕士学位：我们到达了吗？</title>
      <link>https://arxiv.org/abs/2412.15249</link>
      <description><![CDATA[arXiv:2412.15249v1 公告类型：新
摘要：文献综述是科学研究的重要组成部分，但它们仍然耗时且难以撰写，尤其是由于最近大量研究论文的涌入。本文探讨了最近的大型语言模型 (LLM) 在协助基于摘要撰写文献综述方面的零样本能力。我们将任务分解为两个部分：1. 根据查询摘要检索相关作品，2. 根据检索到的结果撰写文献综述。我们分析了 LLM 对这两个组件的有效性。对于检索，我们引入了一种新颖的两步搜索策略，首先使用 LLM 从论文摘要中提取有意义的关键字，然后通过查询外部知识库检索潜在相关的论文。此外，我们研究了一种基于提示的带归因的重新排名机制，并表明与简单的搜索方法相比，重新排名使规范化召回率翻了一番，同时提供了对 LLM 决策过程的洞察。在生成阶段，我们提出了一种两步方法，首先概述评论计划，然后执行计划中的步骤以生成实际评论。为了评估不同的基于 LLM 的文献评论方法，我们使用专为与新发布的 LLM 滚动使用而设计的协议从 arXiv 论文中创建测试集，以避免零样本评估中的测试集污染。我们发布此评估协议以促进这方面的进一步研究和开发。我们的实证结果表明，当任务分解为检索和规划的较小部分时，LLM 在撰写文献评论方面显示出巨大的潜力。此外，我们证明，与现有的更简单的基于 LLM 的生成方法相比，我们的基于规划的方法通过将生成的评论中的幻觉参考最小化 18-26% 来实现更高质量的评论。]]></description>
      <guid>https://arxiv.org/abs/2412.15249</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用基于 Transformer 的语言模型的增强文本压缩方法</title>
      <link>https://arxiv.org/abs/2412.15250</link>
      <description><![CDATA[arXiv:2412.15250v1 公告类型：新
摘要：文本压缩在保留关键信息的同时缩小了文本数据，消除了对存储、带宽和计算效率的限制。尽管通信中英文文本数据量不断增加，但无损压缩技术与基于变压器的文本解压缩的集成却很少受到关注。推进文本压缩和恢复的主要障碍是优化基于变压器的方法并进行有效的预处理和集成无损压缩算法，而这些问题在之前的尝试中仍未得到解决。在这里，我们提出了一种基于变压器的文本解压缩方法，名为 RejuvenateForme，通过利用新的预处理技术和无损压缩方法解决了先前的问题。我们细致的预处理技术结合了 Lempel-Ziv-Welch 算法，在 BookCorpus、EN-DE 和 EN-FR 语料库上实现了 12.57、13.38 和 11.42 的压缩比，与其他深度学习和传统方法相比，展现了最先进的压缩比。此外，RejuvenateForme 在 EN-DE、EN-FR 和 BookCorpus 语料库上实现了 27.31、25.78 和 50.45 的 BLEU 分数，展示了其全面的功效。相比之下，预训练的 T5-Small 比之前最先进的模型表现出更好的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.15250</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AgentPS：通过多轮 QA 实现多模式内容质量保证的代理流程监督</title>
      <link>https://arxiv.org/abs/2412.15251</link>
      <description><![CDATA[arXiv:2412.15251v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 的高级处理和推理能力推动了视觉语言 (VL) 理解任务的重大进展。然而，虽然 MLLM 对于由简单逻辑控制的任务有效，但在推理复杂、相互依赖的逻辑结构时，它们经常会遇到挑战。为了解决这一限制，我们引入了 \textit{AgentPS}，这是一个新颖的框架，它通过微调期间的多轮问答将代理过程监督集成到 MLLM 中。\textit{AgentPS} 由于集成了过程监督和结构化顺序推理，在专有 TikTok 数据集上表现出比基线 MLLM 显着的性能改进。此外，我们表明，用 LLM 生成的标签替换人工注释的标签保留了大部分性能提升，突出了该框架在工业应用中的实际可扩展性。这些结果将 \textit{AgentPS} 定位为多模态分类任务的高效架构。它的适应性和可扩展性，尤其是通过自动注释生成增强时，使其成为处理大规模现实挑战的有力工具。]]></description>
      <guid>https://arxiv.org/abs/2412.15251</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NER- RoBERTa：针对低资源语言中的命名实体识别 (NER) 对 RoBERTa 进行微调</title>
      <link>https://arxiv.org/abs/2412.15252</link>
      <description><![CDATA[arXiv:2412.15252v1 公告类型：新
摘要：如今，自然语言处理 (NLP) 是大多数人日常生活中的重要工具，从理解语音、翻译、命名实体识别 (NER) 和文本分类，到 ChatGPT 等生成文本模型。由于大数据的存在，以及英语、西班牙语、土耳其语、波斯语等广泛使用的语言的大型语料库，这些应用程序已经得到了准确的开发。然而，库尔德语仍然需要更多的语料库和大型数据集才能包含在 NLP 应用程序中。这是因为库尔德语具有丰富的语言结构、多样的方言和有限的数据集，这对库尔德语 NLP (KNLP) 应用程序开发提出了独特的挑战。虽然已经针对各种应用对 KNLP 进行了多项研究，但库尔德语 NER (KNER) 仍然是许多 KNLP 任务的挑战，包括文本分析和分类。在本文中，我们通过提出一种针对 KNER 微调预训练的 RoBERTa 模型的方法来解决这一限制。为此，我们首先创建一个库尔德语语料库，然后设计一个修改后的模型架构并实施训练程序。为了评估训练后的模型，我们进行了一组实验，以使用不同的标记方法和训练模型来展示 KNER 模型的性能。实验结果表明，使用 SentencePiece 标记方法微调的 RoBERTa 显著提高了 KNER 性能，与传统模型相比，F1 分数提高了 12.8%，从而为 KNLP 建立了新的基准。]]></description>
      <guid>https://arxiv.org/abs/2412.15252</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>