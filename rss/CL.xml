<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Thu, 27 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>Mixllm：混合大语模型中的动态路由</title>
      <link>https://arxiv.org/abs/2502.18482</link>
      <description><![CDATA[ARXIV：2502.18482V1公告类型：新 
摘要：大型语言模型（LLMS）最近表现出潜在的人工通用智能，但是它们的用法具有很高的响应延迟。鉴于LLM具有自己的优势和劣势，LLM路由旨在确定流中每个查询的最合适模型，以最大程度地提高响应质量并最大程度地减少成本和延迟。但是，挑战涉及：（1）质量，成本和潜伏期之间的动态权衡； （2）在部署的系统中启用不断学习； （3）随着时间的推移，将导航一组不同的LLM候选者（例如，新的LLM添加或旧LLM删除）。为了弥合这些空白，我们开发了Mixllm，这是一种基于上下文的动态 - 基于Bandit的路由系统，用于查询-LLM分配。具体来说，我们首先利用查询标签来增强路由任务的查询嵌入。接下来，我们设计了轻巧的预测模型，以估计LLM上查询的响应质量和成本。然后，我们设计了一个元决定制造商，以选择查询-LLM分配来最佳折衷响应质量，成本和延迟。最后，该系统受益于持续培训，从而使其适应了随着时间的流逝而不断发展的查询和用户反馈。我们的广泛实验表明，Mixllm在响应质量，成本和潜伏期中实现了最佳的权衡（GPT-4质量的97.25％，占时间限制下成本的24.18％）。]]></description>
      <guid>https://arxiv.org/abs/2502.18482</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FACTROAMINER：大语模型的长期事实评估的概率方法</title>
      <link>https://arxiv.org/abs/2502.18573</link>
      <description><![CDATA[ARXIV：2502.18573V1公告类型：新 
摘要：大型语言模型（LLMS）近年来已经证明了生成任务的巨大功能，但他们在确保生成内容的事实正确性方面努力。这使得这些模型在预期的现实情况下不可靠。在本文中，我们提出了FACTREAMON，这是一种依赖概率推理的新事实评估者，以评估长期产生的响应的事实。具体而言，FACTREAMON将响应分解为原子单元，从外部知识来源检索相关的上下文，并使用逻辑关系（构成，矛盾）在与原子和上下文的逻辑关系（构成，矛盾）之间使用概率编码在原子和上下文上构建了共同的概率分布。然后，FACTROAMIN计算响应中原子单位是否由检索到的上下文支持的后验概率。我们对标记和未标记的基准数据集进行的实验清楚地表明，从事实精确和召回方面，FACTREAMINER在基于最新的及时及时及时的方法上大大改善了。]]></description>
      <guid>https://arxiv.org/abs/2502.18573</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过自我确定性为大语言模型的可扩展最佳选择选​​择</title>
      <link>https://arxiv.org/abs/2502.18581</link>
      <description><![CDATA[ARXIV：2502.18581V1公告类型：新 
摘要：最佳N选择是通过增加测试时间计算来改善大语言模型（LLMS）推理性能的关键技术。当前的最新方法通常采用计算密集型奖励模型进行响应评估和选择。无奖励替代方案，例如自洽和普遍的自遇到，其能力有效地处理开放式生成任务或有效地缩放的能力有限。为了解决这些局限性，我们提出了自我确定性，这是一种新颖有效的度量，利用LLM输出的固有概率分布来估算响应质量而无需外部奖励模型。我们假设较高的分布自我确定性（在多个样本中汇总）与提高的响应精度相关，因为它反映了对生成的输出的更大信心。通过对各种推理任务的广泛实验，我们证明了自我确定性（1）随着样本量$ n $的增加而有效地尺度，类似于奖励模型，但没有计算开销。 （2）补充了思想链，改善了贪婪解码以外的推理绩效； （3）概括到传统自洽方法缺乏的开放式任务。我们的发现将自我确定性确立为提高LLM推理能力的实用和有效方法。该代码可从https://github.com/backprop07/self-clinety获得]]></description>
      <guid>https://arxiv.org/abs/2502.18581</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>后苏联世界的基础模型是什么？</title>
      <link>https://arxiv.org/abs/2502.18583</link>
      <description><![CDATA[ARXIV：2502.18583V1公告类型：新 
摘要：后苏联状态的文化很复杂，它是由不断影响当前事件的动荡历史塑造的。在这项研究中，我们通过构建Borsch来调查基础模型的后文化食品知识，Borsch是俄罗斯和乌克兰语言中涵盖1147和823菜的多模式数据集，以后苏联地区为中心。 We demonstrate that leading models struggle to correctly identify the origins of dishes from Post-Soviet nations in both text-only and multimodal Question Answering (QA), instead over-predicting countries linked to the language the question is asked in. Through analysis of pretraining data, we show that these results can be explained by misleading dish-origin co-occurrences, along with linguistic phenomena such as Russian-Ukrainian code mixing.最后，为了超越基于质量检查的评估，我们测试了模型的能力，以产生对菜肴的准确视觉描述。这项任务与质量检查之间的弱相关性表明，仅质量保证可能不足以评估文化理解。为了促进进一步的研究，我们将在https://github.com/alavrouk/borsch上公开提供Borsch。]]></description>
      <guid>https://arxiv.org/abs/2502.18583</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Neurobiber：快速且可解释的风格特征提取</title>
      <link>https://arxiv.org/abs/2502.18590</link>
      <description><![CDATA[ARXIV：2502.18590V1公告类型：新 
摘要：语言风格是理解文本如何传达意义和实现交流目的的关键，但在大规模提取详细的风格特征仍然具有挑战性。我们提出了神经纤维，这是一种基于变压器的系统，用于基于Biber的多维分析（MDA）建立的快速，可解释的样式分析。 Neurobiber预测我们开源Biberplus库中的96个可轻松风格的功能（一个计算风格特征并提供集成分析的Python工具包，例如PCA和因子分析）。尽管Neurobiber的速度比现有的开源系统快56倍，但在核心语料库上复制了经典的MDA见解，并在PAN 2020的作者资格验证任务上实现了竞争性能，而无需进行广泛的再培训。它的有效且可解释的表示很容易集成到下游NLP管道中，促进了大规模的造型研究，法医分析和实时文本监控。所有组件均可公开使用。]]></description>
      <guid>https://arxiv.org/abs/2502.18590</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>草稿链：通过少写的速度更快地思考</title>
      <link>https://arxiv.org/abs/2502.18600</link>
      <description><![CDATA[ARXIV：2502.18600V1公告类型：新 
摘要：大型语言模型（LLMS）在通过诸如《思想链》（COT）提示之类的机制来解决复杂的推理任务方面表现出色，这强调了冗长的，逐步的推理。但是，人类通常采用更有效的策略：起草简洁的中间思想，只捕获基本信息。在这项工作中，我们提出了草稿链（COD），这是一种受人类认知过程启发的新型范式，在该过程中，LLMS在解决任务时会产生简约但内容丰富的中间推理输出。通过降低详细的洞察力并专注于关键见解，COD匹配或超过COT的准确性，同时仅使用几乎7.6％的令牌，从而大大降低了各种推理任务的成本和潜伏期。]]></description>
      <guid>https://arxiv.org/abs/2502.18600</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人类和机器翻译中情感部署的情境影响</title>
      <link>https://arxiv.org/abs/2502.18642</link>
      <description><![CDATA[ARXIV：2502.18642V1公告类型：新 
摘要：本文说明了文本的整体情感如何在翻译中转移以及对自动情绪分析的影响，尤其是那些利用机器翻译和通过语义相似性指标评估发现的情感分析。尽管人类和机器翻译将产生更多适合目标语言中预期情感频率的引理，但只有机器翻译也会减少文本的总体语义领域，尤其是关于具有认知含量的单词。]]></description>
      <guid>https://arxiv.org/abs/2502.18642</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过梯度下降在稀疏特征上转导一代</title>
      <link>https://arxiv.org/abs/2502.18644</link>
      <description><![CDATA[ARXIV：2502.18644V1公告类型：新 
摘要：大型语言模型（LLMS）在其潜在表示中编码各种语言特征，可以利用这些特征将其输出转向特定的目标特征。在本文中，我们通过训练稀疏的自动编码器来学习查询嵌入的稀疏表示，从而修改LLM的内部结构，从而可以精确控制模型的注意力分布。我们证明，操纵这种稀疏表示形式会有效地将输出转化为不同的风格和认知目标。具体而言，在教育环境中，我们表明可以通过在特定层上修改编码的查询表示形式来系统地调整LLM生成反馈的认知复杂性。为了实现这一目标，我们使用基于梯度的优化在潜在空间中的优化来指导从所需的认知复杂度水平来表示样品的稀疏嵌入。]]></description>
      <guid>https://arxiv.org/abs/2502.18644</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>与LLM的单与双推出对话生成有关人力资源的求职面试</title>
      <link>https://arxiv.org/abs/2502.18650</link>
      <description><![CDATA[ARXIV：2502.18650V1公告类型：新 
摘要：优化在对话代理中使用的语言模型需要大量的示例对话。这些对话越来越多地通过使用强大的大语言模型（LLM）综合生成，尤其是在具有获得真实人类数据的挑战的域中。这样的领域是人力资源（HR）。在这种情况下，我们将两种基于LLM的对话生成方法与生成人力资源求职访谈的用例进行了比较，并评估一种方法是否会产生更高质量的对话，这些对话更具挑战性地与真正的人类话语区分开来。第一个方法使用单个提示来生成完整的面试对话框。第二种方法使用两种相互交谈的代理。为了评估每种方法下的对话质量，我们要求LLM法官使用成对访谈比较来确定AI是否用于采访。我们证明，尽管令牌成本增加了六倍，但双重提示方法产生的访谈的获胜率最高十倍，高于单个prompt方法生成的访谈。不管GPT-4O或Llama 3.3 70B用于采访或判断质量，这种差异仍然保持一致。]]></description>
      <guid>https://arxiv.org/abs/2502.18650</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用新颖的多代理协作框架来增强文本分类，利用伯特</title>
      <link>https://arxiv.org/abs/2502.18653</link>
      <description><![CDATA[arxiv：2502.18653v1公告类型：新 
摘要：我们介绍了一个新型的多代理协作框架，旨在增强文本分类模型的准确性和鲁棒性。我们将BERT作为主要分类器，我们的框架将低信心的预测动态升级到包含词汇，上下文，逻辑，共识和解释性剂的专业多机构系统。这种协作方法可以进行全面的分析和共识驱动的决策，从而大大改善各种文本分类任务的分类绩效。基于基准数据集的经验评估表明，与基于BERT的分类器相比，我们的框架的准确性提高了5.5％，从而强调了其在自然语言处理中推进多机构系统方面的有效性和学术新颖性。]]></description>
      <guid>https://arxiv.org/abs/2502.18653</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>没有奖励模型和偏好数据的生成大语言模型的歧视性填补</title>
      <link>https://arxiv.org/abs/2502.18679</link>
      <description><![CDATA[ARXIV：2502.18679V1公告类型：新 
摘要：监督的微调（SFT），然后是SFT $ \ rightarrow $ PO表示的偏好优化（PO）已成为改善预审计的大语言模型（LLMS）的标准，PO证明了显着的性能提高。但是，PO方法依赖于人体标记的偏好数据或强大的奖励模型来生成偏好数据。我们可以在没有偏好数据或奖励模型的情况下微调LLM，同时在SFT $ \ rightarrow $ po中实现竞争性能？我们通过引入歧视性微调（DFT）来解决这个问题，这是一种新颖的方法，可以消除对偏好数据的需求。与采用生成方法并忽略负面数据的SFT不同，DFT采用了一种歧视性范式，该范式增加了正面答案的概率，同时抑制潜在的负面范式，从而从标记预测转移到数据预测。我们的贡献包括：（i）通过对输入的所有可能输出的所有可能输出中的答案，通过明确建模答案的判别可能性，用于微调LLM的歧视性概率框架； （ii）有效算法优化这种判别可能性； （iii）广泛的实验证明了DFT的有效性，比SFT更好地实现性能，并且与SFT $ \ rightarrow $ PO相当。该代码可以在https://github.com/penguln/dft上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.18679</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MPO：一个有效的后处理框架，用于混合各种偏好对齐</title>
      <link>https://arxiv.org/abs/2502.18699</link>
      <description><![CDATA[ARXIV：2502.18699V1公告类型：新 
摘要：从人类反馈中学习（RLHF）在对齐大语言模型（LLMS）方面表现出了希望。然而，它对单一奖励模型的依赖通常忽略了人类偏好的多样性。最近的方法通过利用多维反馈来解决对相应的奖励模型和使用加强学习训练LLM的限制。但是，该过程是昂贵且不稳定的，尤其是考虑到人类偏好的竞争性和异质性质。在本文中，我们提出了混合偏好优化（MPO），这是一种汇总单目标策略的后处理框架，可作为多目标RLHF（MORLHF）和MAXMIN-RLHF的替代方案。 MPO避免从头开始对齐。取而代之的是，它将现有策略与通过批处理随机镜下降计算的每个策略的重量结合在一起。经验结果表明，MPO在各种偏好之间达到平衡的性能，优于或匹配现有模型的计算成本大大降低。]]></description>
      <guid>https://arxiv.org/abs/2502.18699</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>经过的森林森林：计算社会科学的不确定性感知推理</title>
      <link>https://arxiv.org/abs/2502.18729</link>
      <description><![CDATA[ARXIV：2502.18729V1公告类型：新 
摘要：计算社会科学中的社会调查是由精心制作的领域理论很好地设计的，这些理论可以有效地反映受访者的深层思想，而不会掩盖他们的真实感受。候选问卷选项在很大程度上取决于受访者的先前答案，这导致社会调查分析，时间和所需的专业知识的复杂性。大型语言模型（LLM）执行复杂推理的能力通过促使学习（例如思考链（COT））进行了良好的增强，但仍局限于推理期间的左右决策过程或有限的路径。这意味着他们可能会缺乏需要探索和不确定性搜索的问题。作为回应，提出了一种新型的大型语言模型提示方法，即称为“随机思想森林”（RFOT），以产生不确定性推理以适合计算社会科学领域。 RFOT允许LLM通过产生多样化的思想空间并随机选择构建思想森林来执行故意的决策。它可以扩展整体绩效的探索和预测，从而受益于广泛的响应研究空间。该方法用于在两个数据集上优化计算社会科学分析，涵盖了一系列社会调查分析问题。我们的实验表明，RFOT显着增强了语言模型在两个需要非平凡推理的新型社会调查分析问题上的能力。]]></description>
      <guid>https://arxiv.org/abs/2502.18729</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过启发式搜索自动及时优化：调查</title>
      <link>https://arxiv.org/abs/2502.18746</link>
      <description><![CDATA[ARXIV：2502.18746V1公告类型：新 
摘要：大型语言模型的最新进展导致了各种自然语言处理任务的显着成就，从而使工程越来越重要，越来越重要。尽管手动方法可以有效，但它们通常依赖于直觉，并且不会随着时间的推移自动提示。相比之下，采用基于启发式的搜索算法的自动及时及时优化可以系统地探索和改善人类监督的提示。这项调查提出了对这些方法的全面分类法，将它们分类为优化的位置，优化的内容，哪些标准推动了优化，操作员会生成新提示以及应用哪些迭代搜索算法。我们进一步重点介绍了支持和加速自动及时改进的专业数据集和工具。最后，我们讨论了主要的开放挑战，指出了未来的机会，以实现更健壮和多功能的LLM应用程序。]]></description>
      <guid>https://arxiv.org/abs/2502.18746</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Plutus：低资源希腊金融中的大型语言模型的基准测试</title>
      <link>https://arxiv.org/abs/2502.18772</link>
      <description><![CDATA[ARXIV：2502.18772V1公告类型：新 
摘要：尽管希腊在全球经济中的关键作用，但由于希腊语的语言复杂性和特定领域的数据集的稀缺性，大型语言模型（LLMS）仍未对希腊财务背景感到不安。以前的多语言金融自然语言处理（NLP）已经揭示了相当大的绩效差异，但是到目前为止，还没有开发出专用的希腊金融基准或希腊特定的金融LLM。为了弥合这一差距，我们介绍了希腊第一个金融评估基准Plutus-ben和Plutus-8B，Pioneering Greek Financial LLM，以希腊特定的域名数据进行了微调。 Plutus-ben在希腊语中介绍了五个核心财务NLP任务：数字和文本命名实体识别，问答，抽象性摘要和主题分类，从而促进了系统的和可重复的LLM评估。为了支撑这些任务，我们介绍了三个小说，高质量的希腊财务数据集，并由专家本地希腊人的专家注释，并由两个现有资源增强。我们对22个LLM在冥王星ben上的全面评估表明，由于语言复杂性，特定于领域的术语和财务推理差距，希腊财务NLP仍然具有挑战性。这些发现强调了跨语言转移的局限性，在希腊培训模型中的财务专业知识的必要性以及将财务LLMS适应希腊文本的挑战。我们公开发布Plutus-Ben，Plutus-8B和所有相关数据集，以促进可重复的研究并促进希腊财务NLP，从而促进了财务的更广泛的多语言包容性。]]></description>
      <guid>https://arxiv.org/abs/2502.18772</guid>
      <pubDate>Thu, 27 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>