<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 26 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>扩展零样本语音识别的简单方法</title>
      <link>https://arxiv.org/abs/2407.17852</link>
      <description><![CDATA[arXiv:2407.17852v1 公告类型：新
摘要：尽管在增加自动语音识别的语言覆盖率方面取得了快速进展，但该领域仍远未覆盖所有具有已知书写脚本的语言。最近的研究表明，零样本方法只需要少量文本数据就能取得有希望的结果，然而，准确性在很大程度上取决于所用音素的质量，而音素对于未知语言通常较弱。在本文中，我们提出了 MMS Zero-shot，这是一种概念上更简单的方法，基于罗马化和基于 1,078 种不同语言数据训练的声学模型，比现有技术高出三个数量级。与之前最好的研究相比，MMS Zero-shot 将 100 种未知语言的平均字符错误率降低了 46%。此外，与域内监督基线相比，我们方法的错误率仅高出 2.5 倍，而我们的方法根本不使用任何标记数据来评估语言。]]></description>
      <guid>https://arxiv.org/abs/2407.17852</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:22 GMT</pubDate>
    </item>
    <item>
      <title>探索描述增强无数据意图分类</title>
      <link>https://arxiv.org/abs/2407.17862</link>
      <description><![CDATA[arXiv:2407.17862v1 公告类型：新
摘要：在这项工作中，我们引入了几种方案，利用当前最先进的 (SOTA) 文本嵌入模型，利用描述增强嵌入相似性进行无数据意图分类。我们报告了我们的方法在四个常用的意图分类数据集上的结果，并与以前类似性质的工作进行了比较。我们的工作显示了无数据分类扩展到大量看不见的意图的有希望的结果。我们展示了具有竞争力的结果和显着的改进（+6.12\% 平均）优于强大的零样本基线，所有这些都没有对标记或特定于任务的数据进行训练。此外，我们对该方法的不足之处进行了定性误差分析，以帮助指导该领域的未来研究。]]></description>
      <guid>https://arxiv.org/abs/2407.17862</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:22 GMT</pubDate>
    </item>
    <item>
      <title>Banyan：通过显式结构改进表征学习</title>
      <link>https://arxiv.org/abs/2407.17771</link>
      <description><![CDATA[arXiv:2407.17771v1 公告类型：新
摘要：我们提出了 Banyan，这是一种通过在数据上引入显式结构来学习语义表示的改进模型。与使用跨单个句子的结构的先前方法相比，Banyan 通过将多个组成结构解析为明确包含全局上下文的共享结构来学习。结合受 Griffin 启发的改进的消息传递方案，Banyan 可以学习更好的表示，通过对比学习避免虚假的假阴性，并大大提高此类显式结构模型的记忆效率。使用 Self-StrAE 框架，我们表明 Banyan (a) 在各种设置中均优于使用句子结构的基线 (b) 尽管只有少量（非嵌入）参数，但仍匹配或优于在 1 亿个标记上进行预训练的非结构化基线，如 GloVe（+ 增强）和 RoBERTa 介质（+ simcse），并且 (c) 还在 SemRel 任务上学习了几种低资源（亚洲和非洲）语言的有效表示。]]></description>
      <guid>https://arxiv.org/abs/2407.17771</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:21 GMT</pubDate>
    </item>
    <item>
      <title>揭开大型语言模型中逐字记忆的神秘面纱</title>
      <link>https://arxiv.org/abs/2407.17817</link>
      <description><![CDATA[arXiv:2407.17817v1 公告类型：新
摘要：大型语言模型 (LLM) 经常逐字记忆长序列，这通常会带来严重的法律和隐私问题。许多先前的研究已经使用观察数据研究了这种逐字记忆。为了补充这项工作，我们开发了一个框架，通过继续从注入序列的 Pythia 检查点进行预训练，在受控环境中研究逐字记忆。我们发现 (1) 逐字记忆需要大量的重复；(2) 较晚的（可能更好）检查点更有可能逐字记忆序列，即使对于分布外的序列也是如此；(3) 记忆序列的生成由编码高级特征的分布式模型状态触发，并充分利用了通用语言建模功能。在这些见解的指导下，我们开发了压力测试来评估反学习方法，发现它们通常无法删除逐字记忆的信息，同时还会降低 LM 的质量。总体而言，这些发现挑战了逐字记忆源于特定模型权重或机制的假设。相反，逐字记忆与 LM 的一般功能交织在一起，因此很难在不降低模型质量的情况下将其隔离和抑制。]]></description>
      <guid>https://arxiv.org/abs/2407.17817</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:21 GMT</pubDate>
    </item>
    <item>
      <title>超越实体对齐：通过实体关系协同实现完整的知识图谱对齐</title>
      <link>https://arxiv.org/abs/2407.17745</link>
      <description><![CDATA[arXiv:2407.17745v1 公告类型：新
摘要：知识图谱对齐（KGA）旨在整合来自多个来源的知识，以解决单个知识图谱（KG）在覆盖范围和深度方面的局限性。然而，目前的 KGA 模型在实现“完整”的知识图谱对齐方面还不够。现有模型主要强调跨图实体的链接，但忽略了跨 KG 的关系对齐，因此仅为 KGA 提供了部分解决方案。关系中嵌入的语义相关性在很大程度上被忽视，这可能会限制对跨 KG 信号的全面理解。在本文中，我们建议将关系对齐概念化为一项独立任务，并通过将其分解为两个不同但高度相关的子任务来进行 KGA：实体对齐和关系对齐。为了捕捉这些目标之间相互加强的相关性，我们提出了一种基于期望最大化的新型模型 EREM，该模型迭代优化两个子任务。在真实数据集上的实验结果表明，EREM 在实体对齐和关系对齐任务中始终优于最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2407.17745</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:20 GMT</pubDate>
    </item>
    <item>
      <title>BotEval：促进交互式人工评估</title>
      <link>https://arxiv.org/abs/2407.17770</link>
      <description><![CDATA[arXiv:2407.17770v1 公告类型：新
摘要：随着自然语言处理 (NLP) 模型的快速发展，语言模型被应用于越来越复杂的交互任务，例如谈判和对话审核。让人类评估者直接与这些 NLP 模型交互对于充分评估此类交互任务的性能至关重要。我们开发了 BotEval，这是一个易于定制的开源评估工具包，专注于将人机交互作为评估过程的一部分，而不是人类评估者对静态输入做出判断。BotEval 通过提供涵盖不同复杂程度的常见用例模板和与流行众包平台的内置兼容性，平衡了定制灵活性和用户友好性。我们通过一项评估各种聊天机器人在对话审核有效性方面的性能的研究展示了 BotEval 的众多有用功能，并讨论了 BotEval 与其他注释工具的不同之处。]]></description>
      <guid>https://arxiv.org/abs/2407.17770</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:20 GMT</pubDate>
    </item>
    <item>
      <title>通过注意力头之间的异构上下文分片实现高效的 LLM 训练和服务</title>
      <link>https://arxiv.org/abs/2407.17678</link>
      <description><![CDATA[arXiv:2407.17678v1 公告类型：新
摘要：现有的 LLM 训练和推理框架在提高稀疏性效率的同时，还难以保持上下文和模型架构的完整性。受数据库中分片概念以及注意力在加速器上并行化的事实的启发，我们提出了稀疏分片 (S2) 注意力，这是一种注意力算法，它为不同的注意力头分配异构上下文分区以分而治之。S2-Attention 强制每个注意力头仅关注遵循步幅稀疏模式的上下文分区，而完整上下文则保留为所有分片的并集。由于注意力头在单独的线程块中处理，因此每个头的上下文减少可以产生端到端的加速和内存减少。在推理时，使用 S2-Attention 训练的 LLM 可以将 KV 缓存减少视为免费餐，同时保证模型质量。在实验中，我们表明 S2-Attention 可以提供高达 (1) 25.3 倍的时钟注意力加速，比 FlashAttention-2 快 6 倍，从而将端到端训练时间缩短 6 倍，推理延迟缩短 10 倍，(2) 与默认注意力相比，模型训练质量相当，(3) 在 32K 上下文窗口上具有完美的针检索准确度。在算法的基础上，我们构建了 DKernel，这是一个 LLM 训练和推理内核库，允许用户为自己的模型自定义稀疏模式。我们开源了 DKerne，并使其与 Megatron、Pytorch 和 vLLM 兼容。]]></description>
      <guid>https://arxiv.org/abs/2407.17678</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:19 GMT</pubDate>
    </item>
    <item>
      <title>研究政治偏见对大型语言模型在立场分类中的表现的影响</title>
      <link>https://arxiv.org/abs/2407.17688</link>
      <description><![CDATA[arXiv:2407.17688v1 公告类型：新
摘要：大型语言模型 (LLM) 在执行基于自然语言查询的任务方面表现出了卓越的能力。然而，这些在精选数据集上训练的模型本质上体现了从种族到国家和性别偏见等各种偏见。这些偏见是否会影响 LLM 在某些任务上的表现仍不确定。在本研究中，我们调查了立场分类任务中 LLM 的政治偏见，特别是检查这些模型是否表现出更准确地对政治立场进行分类的倾向。利用三个数据集、七个 LLM 和四种不同的提示方案，我们分析了 LLM 在政治导向的声明和目标上的表现。我们的研究结果显示，在各种政治导向的立场分类任务中，LLM 的表现存在统计学上的显着差异。此外，我们观察到这种差异主要体现在数据集级别，模型和提示方案在不同的立场分类数据集上表现出统计上相似的表现。最后，我们观察到，当陈述所针对的目标存在较大模糊性时，LLM 的立场分类准确性会较差。]]></description>
      <guid>https://arxiv.org/abs/2407.17688</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:19 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是否可以进行认知行为疗法？</title>
      <link>https://arxiv.org/abs/2407.17730</link>
      <description><![CDATA[arXiv:2407.17730v1 Announce Type: new 
摘要：当代社会，心理健康问题日益突出，精神障碍呈现多样化、复杂性、普遍性的特点。认知行为疗法（CBT）是目前最具影响力、临床效果显著、无副作用的心理治疗方法，但在大多数国家覆盖面有限、质量较差。近年来，利用大型语言模型（LLM）识别和干预情绪障碍的研究得到验证，为心理援助治疗提供了新的可能性。然而，LLM真的可以进行认知行为治疗吗？许多心理健康专家对使用LLM进行治疗提出了担忧。为了回答这个问题，我们从在线视频网站收集了真实的CBT语料，设计并进行了有针对性的自动评估框架，涉及对生成文本的情绪倾向、结构化对话模式和主动探究能力的评估。对于情绪倾向，我们计算每个模型生成的CBT对话文本的情绪倾向得分。对于结构化对话模式，我们使用多种自动评估指标来比较不同模型在说话风格、保持话题一致性的能力以及 CBT 中技术的使用情况。对于询问以指导患者，我们使用 PQA (主动提问能力) 指标。我们还在集成 CBT 知识库后评估了 LLM 的 CBT 能力，以探索引入额外知识对增强模型的 CBT 咨询能力的帮助。对四个在自然语言处理上表现优异的 LLM 变体进行了评估，实验结果显示了 LLM 在心理咨询领域的巨大潜力，尤其是与其他技术手段相结合之后。]]></description>
      <guid>https://arxiv.org/abs/2407.17730</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:19 GMT</pubDate>
    </item>
    <item>
      <title>IgnitionInnovators 在“Discharge Me!”活动中：思维链式教学对出院总结的大型语言模型进行微调</title>
      <link>https://arxiv.org/abs/2407.17636</link>
      <description><![CDATA[arXiv:2407.17636v1 公告类型：新
摘要：本文介绍了我们提出的 Discharge Me！共享任务方法，与第 23 届生物医学自然语言处理 (BioNLP) 研讨会同期举行。在这项工作中，我们开发了一个基于 LLM 的框架来解决出院总结文档 (DSD) 任务，即在出院总结中生成两个关键目标部分“简要医院课程”和“出院说明”。通过简化最近对 LLM 的指令微调过程，我们探索了几种提示策略，以使 LLM 最佳地适应 DSD 的特定生成任务。实验结果表明，提供清晰的输出结构，辅以一组全面的思路 (CoT) 问题，可以有效提高模型的推理能力，从而提高生成文本中临床信息的结构正确性和真实性。源代码位于：https：//github.com/antangrocket1312/Discharge_LLM]]></description>
      <guid>https://arxiv.org/abs/2407.17636</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>时间问题：研究时间对生物医学语言模型的影响</title>
      <link>https://arxiv.org/abs/2407.17638</link>
      <description><![CDATA[arXiv:2407.17638v1 公告类型：新
摘要：将语言模型应用于生物医学应用的时间根源：模型是在历史数据上训练的，并将部署用于新数据或未来数据，这可能与训练数据不同。虽然越来越多的生物医学任务采用了最先进的语言模型，但很少有研究检查数据通常在开发和部署过程中发生变化时对生物医学模型的时间影响。这项研究通过统计探究语言模型性能与三个生物医学任务中的数据变化之间的关系来填补这一空白。我们部署了不同的指标来评估模型性能，距离方法来测量数据漂移，以及统计方法来量化对生物医学语言模型的时间影响。我们的研究表明，时间对于部署生物医学语言模型很重要，而性能下降的程度因生物医学任务和统计量化方法而异。我们相信这项研究可以建立一个可靠的基准来评估和评估部署生物医学语言模型的时间影响。]]></description>
      <guid>https://arxiv.org/abs/2407.17638</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>将语音编码器与下游文本模型耦合</title>
      <link>https://arxiv.org/abs/2407.17605</link>
      <description><![CDATA[arXiv:2407.17605v1 公告类型：新
摘要：我们提出了一种模块化方法来构建级联语音翻译 (AST) 模型，该方法可保证生成的模型的性能不差于 1-best 级联基线，同时保留给定任务的最先进的语音识别 (ASR) 和文本翻译 (MT) 性能。我们新颖的贡献是使用在 L2 损失下训练的“导出器”层来确保 ASR 嵌入和 1-best 序列的 MT 标记嵌入之间的强匹配。“导出器”输出嵌入代替 1-best 标记嵌入直接输入到 MT 模型，从而保证生成的模型的性能不差于 1-best 级联基线，同时允许反向传播梯度从 MT 模型流入 ASR 组件。在无法增量训练 MT 模型但我们希望通过利用 AST 任务提供的（语音、转录、翻译转录）数据来提高质量的情况下，匹配嵌入级联架构比其 1-best 对应架构提供了显著的改进。当使用 AST 任务提供的并行文本数据增量训练 MT 模型时，这种改进就会消失。该方法有望用于寻求结合 ASR 编码器和不可变文本模型的其他场景，例如大型语言模型 (LLM)。]]></description>
      <guid>https://arxiv.org/abs/2407.17605</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>DAGPap24 上的 Papilusion：论文还是幻觉？检测人工智能生成的科学论文</title>
      <link>https://arxiv.org/abs/2407.17629</link>
      <description><![CDATA[arXiv:2407.17629v1 公告类型：新
摘要：本文介绍了 Papilusion，这是一种 AI 生成的科学文本检测器，是在 DAGPap24 共享任务中开发的，用于检测自动生成的科学论文。我们提出了一种基于集成的方法，并进行了消融研究，以分析检测器配置对性能的影响。Papilusion 在排行榜上排名第 6，比赛结束后我们的表现有所提高，在官方测试集上获得了 99.46 (+9.63) 的 F1 分数。]]></description>
      <guid>https://arxiv.org/abs/2407.17629</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>#Somos600M 项目：生成代表拉丁美洲、加勒比地区和西班牙语言多样性的 NLP 资源</title>
      <link>https://arxiv.org/abs/2407.17479</link>
      <description><![CDATA[arXiv:2407.17479v1 公告类型：新
摘要：我们有 6 亿西班牙语使用者。我们启动了 #Somos600M 项目，因为拉丁美洲、加勒比地区和西班牙的语言多样性需要在人工智能 (AI) 系统中体现出来。尽管占世界人口的 7.5%，但没有开放数据集来对大型语言模型 (LLM) 进行指令调整，也没有排行榜来评估和比较它们。在本文中，我们介绍了我们作为一个国际开源社区如何创建指令和评估数据集的第一个版本，这是推动我们语言的自然语言处理 (NLP) 不可或缺的资源。]]></description>
      <guid>https://arxiv.org/abs/2407.17479</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>牙科中的生成人工智能：当前方法和未来挑战</title>
      <link>https://arxiv.org/abs/2407.17532</link>
      <description><![CDATA[arXiv:2407.17532v1 公告类型：新 
摘要：由于生成式人工智能 (GenAI) 模型的出现，人工智能 (AI) 已成为人们的商品，该模型通过提供自然语言界面与复杂模型交互来弥合人工智能的可用性差距。这些 GenAI 模型包括文本生成（例如双向聊天系统）到根据用户输入的文本描述生成图像或视频。人工智能的这些进步对牙科产生了多方面的影响。在牙科教育中，学生现在有机会通过仅提示 GenAI 模型来解决大量问题并在几秒钟内得到答案。GenAI 模型可以帮助从业者快速有效地收集知识，从而帮助我们提供更好的患者医疗保健。最后，GenAI 还可以用于牙科研究，其应用范围从新药发现到学术写作协助。在这篇评论中，我们首先定义 GenAI 模型并描述它们的多种生成模式；然后，我们解释并讨论它们在牙科中的当前和潜在应用；最后，我们描述了这些新技术给我们的领域带来的挑战。]]></description>
      <guid>https://arxiv.org/abs/2407.17532</guid>
      <pubDate>Fri, 26 Jul 2024 06:20:16 GMT</pubDate>
    </item>
    </channel>
</rss>