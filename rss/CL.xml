<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 29 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过软对比学习改善多语言对齐</title>
      <link>https://arxiv.org/abs/2405.16155</link>
      <description><![CDATA[arXiv:2405.16155v2 公告类型：新
摘要：制作得体的多语言句子表示对于在跨语言下游任务中实现高性能至关重要。在这项工作中，我们提出了一种基于预训练的单语嵌入模型测量的句子相似度来对齐多语言嵌入的新方法。给定翻译句子对，我们训练一个多语言模型，使跨语言嵌入之间的相似性遵循在单语教师模型中测量的句子相似性。我们的方法可以被认为是对比学习，软标签定义为句子之间的相似性。我们对五种语言的实验结果表明，在双语挖掘任务和 STS 任务的各种基准测试中，我们的软标签对比损失远远优于传统的硬标签对比损失。此外，对于 Tatoeba 数据集，我们的方法优于现有的多语言嵌入，包括 LaBSE。代码可在 https://github.com/YAI12xLinq-B/IMASCL 获得]]></description>
      <guid>https://arxiv.org/abs/2405.16155</guid>
      <pubDate>Wed, 29 May 2024 06:21:23 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行 5W1H 提取</title>
      <link>https://arxiv.org/abs/2405.16150</link>
      <description><![CDATA[arXiv:2405.16150v1 公告类型：新 
摘要：通过 5W1H 框架（\textit{What}、\textit{When}、\textit{Where}、\textit{Why}、\textit{Who} 和 \textit{How}）提取必要的新闻元素对于事件提取和文本摘要至关重要。ChatGPT 等大型语言模型 (LLM) 的出现提供了一个机会，可以通过简单的提示解决与语言相关的任务，而无需花费大量时间微调模型。而 ChatGPT 在处理较长的新闻文本和分析上下文中的特定属性方面遇到了挑战，尤其是回答有关 \textit{What}、\textit{Why} 和 \textit{How} 的问题。提取任务的有效性尤其依赖于高质量的人工注释数据集。然而，5W1H 提取缺乏这样的数据集，增加了基于开源 LLM 微调策略的难度。为了解决这些限制，首先，我们基于四个典型新闻语料库（\textit{CNN/DailyMail}、\textit{XSum}、\textit{NYT}、\textit{RA-MDS}）标注了一个高质量的 5W1H 数据集；其次，我们设计了从零样本/少量样本提示到高效微调的几种策略，以从原始新闻文档中进行 5W1H 方面提取。实验结果表明，微调模型在我们标注的数据集上的性能优于 ChatGPT 的性能。此外，我们还通过在目标领域语料库（例如 CNN/DailyMail）上测试源领域（例如 NYT）模型来探索领域自适应能力，以完成 5W1H 提取任务。]]></description>
      <guid>https://arxiv.org/abs/2405.16150</guid>
      <pubDate>Wed, 29 May 2024 06:21:22 GMT</pubDate>
    </item>
    <item>
      <title>DefSent+：通过将定义句子投影到无限词典条目的准各向同性或各向同性向量空间中来改进语言模型的句子嵌入</title>
      <link>https://arxiv.org/abs/2405.16153</link>
      <description><![CDATA[arXiv:2405.16153v1 公告类型：新
摘要：本文对之前的会议论文 DefSent 进行了重大改进。先前的研究试图通过将定义句子投影到词典条目的向量空间中来改进语言模型的句子嵌入。我们发现，由于使用语言模型的词嵌入来表示词典条目的方法论限制，这种方法尚未得到充分探索。这导致了两个障碍。首先，词典条目受到单词词汇的限制，因此无法充分利用。其次，众所周知，语言模型的语义表示是各向异性的，但不允许对 DefSent 的词嵌入进行预处理，因为它的权重在训练期间被冻结并与预测层绑定。在本文中，我们提出了一种新颖的方法来逐步构建不受限制的条目嵌入。因此，定义句子可以投影到具有无限词典条目的准各向同性或各向同性向量空间中，从而可以获得质量明显更好的句子嵌入。我们将我们的方法简称为 DefSent+（DefSent 的增强版本），其优势如下：1）与 DefSent 相比，测量句子相似度的任务性能有显著提升；2）当使用 DefSent+ 进一步训练数据增强模型（如 SIMCSE 和 SNCSE）时，无需使用手动标记的数据集，就可以在测量句子相似度的方法中实现最佳性能；3）DefSent+ 在基于特征的 NLP 下游任务迁移方面也具有竞争力。]]></description>
      <guid>https://arxiv.org/abs/2405.16153</guid>
      <pubDate>Wed, 29 May 2024 06:21:22 GMT</pubDate>
    </item>
    <item>
      <title>SNOBERT：SNOMED CT 临床术语中临床记录实体链接的基准</title>
      <link>https://arxiv.org/abs/2405.16115</link>
      <description><![CDATA[arXiv:2405.16115v1 公告类型：新
摘要：从医疗数据中提取和分析见解（主要由医护人员以自由文本格式存储）因其非结构化性质而面临重大挑战。医疗编码是医疗保健中的关键过程，由于医学本体的复杂性以及用于训练自然语言处理模型的医学文本的访问受限，因此自动化程度仍然很低。在本文中，我们提出了一种使用基于 BERT 的模型将临床笔记中的文本跨度链接到 SNOMED CT 中的特定概念的方法“SNOBERT”。该方法包括两个阶段：候选选择和候选匹配。这些模型是在最大的公开可用标记临床笔记数据集之一上进行训练的。SNOBERT 优于其他基于深度学习的经典方法，这一点已由应用它的挑战的结果证实。]]></description>
      <guid>https://arxiv.org/abs/2405.16115</guid>
      <pubDate>Wed, 29 May 2024 06:21:21 GMT</pubDate>
    </item>
    <item>
      <title>iREL 在 SemEval-2024 任务 9 中的应用：改进脑筋急转弯的传统提示方法</title>
      <link>https://arxiv.org/abs/2405.16129</link>
      <description><![CDATA[arXiv:2405.16129v1 公告类型：新
摘要：本文介绍了我们针对 SemEval-2024 任务 9：BRAINTEASER：一项违背常识的新任务的方法。BRAINTEASER 任务包括多项选择题问答，旨在评估模型的横向思维能力。它由句子拼图和单词拼图子任务组成，这些子任务要求模型违背默认的常识联想并表现出非常规思维。我们提出了一种独特的策略来提高预训练语言模型（尤其是 Gemini 1.0 Pro 模型）在这两个子任务中的表现。我们采用静态和动态的少量提示技术，并引入了一种模型生成的推理策略，该策略利用 LLM 的推理能力来提高性能。我们的方法表现出显着的改进，表明它的表现比基线模型好很多，但表现不如人类注释者，从而凸显了所提出策略的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.16129</guid>
      <pubDate>Wed, 29 May 2024 06:21:21 GMT</pubDate>
    </item>
    <item>
      <title>基于关键点的法学硕士渐进式思路链提炼</title>
      <link>https://arxiv.org/abs/2405.16064</link>
      <description><![CDATA[arXiv:2405.16064v1 公告类型：新
摘要：思路链提炼是一种将推理能力从大型语言模型 (LLM) 转移到小型学生模型的强大技术。以前的方法通常要求学生模仿 LLM 产生的逐步原理，通常面临以下挑战：(i) 原理中的标记意义各不相同，平等对待它们可能无法准确模仿关键点标记，从而导致推理错误。(ii) 他们通常通过一致地预测原理中的所有步骤来提炼知识，这无法区分步骤生成的学习顺序。这与人类从简单任务开始并推进到更难任务的认知进程不同，导致结果不理想。为此，我们提出了一个统一的框架，称为 KPOD，来解决这些问题。具体来说，我们提出了一个利用掩码学习的标记加权模块，以鼓励学生在提炼过程中准确模仿关键点标记。此外，我们开发了一种推理渐进式蒸馏策略，从训练学生生成最终的推理步骤开始，逐渐扩展到覆盖整个推理。为了实现这一点，提出了一个加权 token 生成损失来评估步骤推理难度，并设计了一个价值函数来安排渐进式蒸馏，同时考虑步骤难度和问题多样性。在四个推理基准上进行的大量实验表明，我们的 KPOD 大大优于以前的方法。]]></description>
      <guid>https://arxiv.org/abs/2405.16064</guid>
      <pubDate>Wed, 29 May 2024 06:21:20 GMT</pubDate>
    </item>
    <item>
      <title>COLT：面向完备性的大型语言模型工具检索</title>
      <link>https://arxiv.org/abs/2405.16089</link>
      <description><![CDATA[arXiv:2405.16089v1 公告类型：新
摘要：最近，将外部工具与大型语言模型 (LLM) 集成已成为一种有前途的方法，可以克服其预训练数据的固有限制。然而，现实世界的应用通常涉及各种各样的工具，由于输入长度和响应时间的限制，将所有工具直接合并到 LLM 中是不可行的。因此，要充分利用工具增强型 LLM 的潜力，开发有效的工具检索系统至关重要。现有的工具检索方法技术主要依赖于用户查询和工具描述之间的语义匹配，这通常会导致选择冗余工具。因此，这些方法无法提供解决 LLM 遇到的多方面问题所需的一整套多样化工具。在本文中，我们提出了一种新颖的与模型无关的基于协同学习的工具检索方法 COLT，该方法不仅可以捕获用户查询和工具描述之间的语义相似性，还可以考虑工具的协同信息。具体来说，我们首先微调基于 PLM 的检索模型，以在语义学习阶段捕获查询和工具之间的语义关系。随后，我们在查询、场景和工具之间构建三个二分图，并引入双视图图协同学习框架，以在协同学习阶段捕获工具之间复杂的协同关系。在开放基准和新推出的 ToolLens 数据集上进行的大量实验表明，COLT 实现了卓越的性能。值得注意的是，采用我们提出的模型框架的 BERT-mini（11M）的性能优于 BERT-large（340M），后者的参数多 30 倍。此外，我们计划公开发布 ToolLens 数据集，以支持工具检索的进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2405.16089</guid>
      <pubDate>Wed, 29 May 2024 06:21:20 GMT</pubDate>
    </item>
    <item>
      <title>SPP：适用于大型语言模型的稀疏性保留参数高效微调</title>
      <link>https://arxiv.org/abs/2405.16057</link>
      <description><![CDATA[arXiv:2405.16057v1 公告类型：新
摘要：大型语言模型 (LLM) 已成为推动人工智能领域发展的关键，但其巨大的规模对微调和部署都带来了重大挑战。当前的训练后剪枝方法虽然可以减小 LLM 的大小，但往往无法保持其原有的性能。为了应对这些挑战，本文介绍了一种保留稀疏度的参数高效微调方法 SPP。与现有的难以保持性能的训练后剪枝方法不同，SPP 提出采用轻量级可学习的列和行矩阵来优化稀疏 LLM 权重，保持剪枝后的预训练模型的结构和稀疏性不变。通过逐元素乘法和残差加法，SPP 确保在训练和权重合并过程中模型稀疏模式和比率的一致性。我们通过将 SPP 应用于 LLaMA 和 LLaMA-2 模型系列并使用最近的训练后剪枝方法证明了 SPP 的有效性。我们的结果表明，SPP 显著提高了具有不同稀疏模式（即非结构化和 N:M 稀疏性）的模型的性能，尤其是对于稀疏率较高的模型（例如 75%），使其成为高效微调稀疏 LLM 的有前途的解决方案。代码将在 https://github.com/Lucky-Lance/SPP 上提供。]]></description>
      <guid>https://arxiv.org/abs/2405.16057</guid>
      <pubDate>Wed, 29 May 2024 06:21:19 GMT</pubDate>
    </item>
    <item>
      <title>评估大型语言模型的基于检索的上下文学习的对抗鲁棒性</title>
      <link>https://arxiv.org/abs/2405.15984</link>
      <description><![CDATA[arXiv:2405.15984v1 公告类型：新
摘要：随着 LLaMA 和 OpenAI GPT-3 等大型语言模型的出现，情境学习 (ICL) 因其有效性和效率而备受关注。然而，ICL 对用于编码提示中演示的选择、顺序和言语化非常敏感。检索增强 ICL 方法试图通过利用检索器提取语义相关的示例作为演示来解决此问题。虽然这种方法可以产生更准确的结果，但它对各种类型的对抗性攻击（包括对测试样本、演示和检索数据的干扰）的鲁棒性仍未得到充分探索。我们的研究表明，检索增强模型可以增强对测试样本攻击的鲁棒性，优于普通 ICL，攻击成功率 (ASR) 降低了 4.87%；然而，它们对演示表现出过度自信，导致演示攻击的 ASR 增加了 2%。对抗性训练有助于提高 ICL 方法对对抗性攻击的鲁棒性；然而，在 LLM 环境中，这种训练方案成本太高。作为替代方案，我们引入了一种有效的无需训练的对抗性防御方法 DARD，该方法利用那些受攻击的样本丰富了示例池。我们表明，DARD 可提高性能和鲁棒性，与基线相比，ASR 降低了 15%。代码和数据已发布，以鼓励进一步研究：https://github.com/simonucl/adv-retreival-icl]]></description>
      <guid>https://arxiv.org/abs/2405.15984</guid>
      <pubDate>Wed, 29 May 2024 06:21:18 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型对花园路径句的增量理解：语义解释、句法重新分析和注意力</title>
      <link>https://arxiv.org/abs/2405.16042</link>
      <description><![CDATA[arXiv:2405.16042v1 公告类型：新 
摘要：阅读暂时模棱两可的花园小径句子时，误解有时会持续到消歧点之后。这种现象传统上是在心理语言学实验中使用在线措施（例如阅读时间）和离线措施（例如理解问题）进行研究的。在这里，我们使用四个大型语言模型（LLM）研究花园小径句子的处理和持续误解的命运：GPT-2、LLaMA-2、Flan-T5 和 RoBERTa。总体目标是评估人类和 LLM 在处理花园小径句子和消除歧义点之后的持续误解方面是否一致，尤其是当存在额外的句法信息（例如，分隔子句边界的逗号）来指导处理时。我们使用 24 个花园小径句子来实现这一目标，这些句子具有可选的及物动词和反身动词，导致暂时的歧义。对于每个句子，都有一对理解问题，分别对应误解和正确解释。在三个实验中，我们 (1) 使用问答任务测量 LLM 的动态语义解释；(2) 跟踪这些模型是否在消歧点（或句子末尾）移动其隐式解析树；(3) 可视化在处理问题探测时关注消歧信息的模型组件。这些实验表明，人类和 LLM 在处理花园小径句子方面表现出良好的一致性，尤其是当有额外的句法信息来指导处理时。]]></description>
      <guid>https://arxiv.org/abs/2405.16042</guid>
      <pubDate>Wed, 29 May 2024 06:21:18 GMT</pubDate>
    </item>
    <item>
      <title>使用预先训练的大型语言模型进行零样本垃圾邮件分类</title>
      <link>https://arxiv.org/abs/2405.15936</link>
      <description><![CDATA[arXiv:2405.15936v1 公告类型：新
摘要：本文研究了使用零样本提示对垃圾邮件进行分类的预训练大型语言模型 (LLM) 的应用。我们在著名的 SpamAssassin 数据集上评估了开源 (Flan-T5) 和专有 LLM (ChatGPT、GPT-4) 的性能。探索了两种分类方法：(1) 从电子邮件主题和正文中截断原始内容，以及 (2) 基于 ChatGPT 生成的摘要进行分类。我们的实证分析利用整个数据集进行评估而无需进一步训练，揭示了有希望的结果。Flan-T5 在截断内容方法上获得了 90% 的 F1 分数，而 GPT-4 使用摘要获得了 95% 的 F1 分数。虽然这些在单一数据集上的初步发现表明 LLM 子任务（例如摘要和分类）的分类流程具有潜力，但还需要在不同的数据集上进行进一步验证。专有模型的高运营成本，加上 LLM 的一般推理成本，可能会严重阻碍垃圾邮件过滤在现实世界中的部署。]]></description>
      <guid>https://arxiv.org/abs/2405.15936</guid>
      <pubDate>Wed, 29 May 2024 06:21:17 GMT</pubDate>
    </item>
    <item>
      <title>句法启动的层次贝叶斯模型</title>
      <link>https://arxiv.org/abs/2405.15964</link>
      <description><![CDATA[arXiv:2405.15964v1 公告类型：新
摘要：句法启动效应表现出三个有据可查的经验特性：词汇增强、逆频率效应和不对称衰减。我们旨在展示如何在通用学习框架即分层贝叶斯模型 (HBM) 中协调这三种经验现象。该模型以句法统计的分层结构表示句法知识，其中较低级别表示句法决策的动词特定偏差，较高级别表示抽象偏差，即动词特定偏差的集合。这些知识会根据贝叶斯推理的经验进行更新。在模拟中，我们表明 HBM 捕捉到了上述句法启动的特性。结果表明，一些通常由残差激活账户解释的启动特性也可以通过隐性学习账户来解释。我们还讨论了该模型对句法启动的词汇基础的影响。]]></description>
      <guid>https://arxiv.org/abs/2405.15964</guid>
      <pubDate>Wed, 29 May 2024 06:21:17 GMT</pubDate>
    </item>
    <item>
      <title>利用卡片预测和色彩语义增强辅助和替代沟通</title>
      <link>https://arxiv.org/abs/2405.15896</link>
      <description><![CDATA[arXiv:2405.15896v1 公告类型：新
摘要：本文介绍了一种增强增强和替代通信 (AAC) 系统的方法，即将彩色语义 (CS) 与专门针对巴西葡萄牙语的基于转换器的语言模型相结合。我们引入了一种改编的 BERT 模型 BERTptCS，该模型结合了 CS 框架来改进通信卡的预测。主要目的是提高通信卡预测的准确性和上下文相关性，这对于具有复杂通信需求 (CCN) 的个人的 AAC 系统至关重要。我们将 BERTptCS 与缺乏 CS 集成的基线模型 BERTptAAC 进行了比较。我们的结果表明，BERTptCS 在各种指标上都明显优于 BERTptAAC，包括 top-k 准确度、平均倒数排名 (MRR) 和 Entropy@K。将 CS 集成到语言模型中可以提高预测准确性，并提供对用户输入的更直观和上下文理解，从而促进更有效的沟通。]]></description>
      <guid>https://arxiv.org/abs/2405.15896</guid>
      <pubDate>Wed, 29 May 2024 06:21:16 GMT</pubDate>
    </item>
    <item>
      <title>幻灯片：集成小型和大型语言模型的开放域对话评估框架</title>
      <link>https://arxiv.org/abs/2405.15924</link>
      <description><![CDATA[arXiv:2405.15924v1 公告类型：新 
摘要：开放域对话系统中黄金标准响应的长期一对多问题对自动评估指标提出了挑战。尽管之前的研究已经通过应用强大的大型语言模型 (LLM) 取得了一些成功，但现有方法仍然难以解决一对多问题，并且在特定领域场景中表现出低于标准的性能。我们假设 LLM 中的常识推理偏差可能会阻碍它们在特定领域评估中的表现。为了解决这两个问题，我们提出了一个新颖的框架 SLIDE（用于对话评估的大小集成），它利用小型专用模型 (SLM) 和 LLM 来评估开放域对话。我们的方法引入了几种技术：（1）对比学习以区分稳健和非稳健的响应嵌入； (2) 一种新的语义敏感度度量，将嵌入余弦距离与通过神经网络学习的相似性相结合，以及 (3) 一种结合 SLM 和 LLM 评估结果的策略。我们的实证结果表明，我们的方法在分类和评估任务中都达到了最先进的性能，此外 SLIDE 评估器与人类判断的相关性更好。我们的代码可在 https://github.com/hegehongcha/SLIDE-ACL2024 上找到。]]></description>
      <guid>https://arxiv.org/abs/2405.15924</guid>
      <pubDate>Wed, 29 May 2024 06:21:16 GMT</pubDate>
    </item>
    <item>
      <title>DuanzAI：俚语增强法学硕士，可帮助理解幽默</title>
      <link>https://arxiv.org/abs/2405.15818</link>
      <description><![CDATA[arXiv:2405.15818v1 公告类型：新
摘要：语言的复杂性在俚语表达的丰富性中显而易见，这些俚语表达通常充满幽默和文化细微差别。这种语言现象越来越普遍，尤其是在数字通信中。然而，现有的人工智能模型，包括 ChatGPT-3.5，在理解这些细微差别方面面临挑战，尤其是在中文俚语中。在本研究中，我们提出了 DuanzAI，这是一种创新方法，可增强大型语言模型 (LLM) 对中文俚语的深度理解。利用精选的数据集和先​​进的技术，DuanzAI 弥合了人类表达和人工智能理解之间的差距，实现了与上下文相关的响应。我们的实验将 LLM 的性能与自定义的 Punchline 实体识别 (PER) 系统进行了对比，该系统集成了语音匹配和拼音 2 汉字技术。应用这些见解，我们开发了先进的聊天机器人 ChatDAI，并在 \url{https://github.com/YesianRohn/DuanzAI} 发布了我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2405.15818</guid>
      <pubDate>Wed, 29 May 2024 06:21:15 GMT</pubDate>
    </item>
    </channel>
</rss>