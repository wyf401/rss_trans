<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Fri, 17 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>TransMI：从多语言预训练语言模型为音译数据创建强大基线的框架</title>
      <link>https://arxiv.org/abs/2405.09913</link>
      <description><![CDATA[arXiv:2405.09913v1 公告类型：新
摘要：将使用不同脚本的相关语言音译为通用脚本在改善下游任务中的跨语言迁移方面显示出有效性。然而，这种方法通常不可避免地需要从头开始预训练模型，因为音译会带来现有多语言预训练语言模型 (mPLM) 中未涵盖的新子词。这是不希望的，因为预训练需要大量的计算预算。一种更有前景的方法是充分利用可用的 mPLM。为此，本文提出了一个简单但有效的框架：音译-合并-初始化（TransMI），它可以创建一个强大的基线，非常适合通过利用 mPLM 及其附带的分词器将数据音译为通用脚本。 TransMI 分为三个阶段： (a) 将 mPLM 的词汇音译为通用脚本； (b) 将新词汇与原始词汇合并； (c) 初始化新子词的嵌入。我们将 TransMI 应用于最近三个强大的 mPLM，我们的实验表明 TransMI 不仅保留了它们处理非音译数据的能力，而且还使模型能够有效地处理音译数据：结果显示持续提高了 3% 到 34% ，因不同模型和任务而异。我们在 \url{https://github.com/cisnlp/TransMI} 公开提供我们的代码和模型。]]></description>
      <guid>https://arxiv.org/abs/2405.09913</guid>
      <pubDate>Fri, 17 May 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>辩论：基于魔鬼代言人的评估和文本评估</title>
      <link>https://arxiv.org/abs/2405.09935</link>
      <description><![CDATA[arXiv:2405.09935v1 公告类型：新
摘要：随着自然语言生成（NLG）模型的流行，系统地评估机器生成文本的质量变得越来越重要。最近的研究引入了基于 LLM 的评估器，这些评估器作为无参考指标运行，展示了它们熟练处理新任务的能力。然而，这些模型通常依赖于单代理方法，我们认为这对其性能带来了固有的限制。这是因为LLM代理人的反应存在偏见，包括对某些文本结构或内容的偏好。在这项工作中，我们提出了 DEBATE，一种基于多智能体评分系统的 NLG 评估框架，并增强了 Devil&#39;s Advocate 的概念。在该框架内，指示一名代理人批评其他代理人的论点，这可能会解决法学硕士代理人答案中的偏见。 DEBATE 在 NLG 评估的两个元评估基准（SummEval 和 TopicalChat）中显着优于之前最先进的方法。我们还表明，代理人之间辩论的广泛性和代理人的角色会影响评估者的表现。]]></description>
      <guid>https://arxiv.org/abs/2405.09935</guid>
      <pubDate>Fri, 17 May 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>通过软负采样增强多模态思想链中的语义</title>
      <link>https://arxiv.org/abs/2405.09848</link>
      <description><![CDATA[arXiv:2405.09848v1 公告类型：新
摘要：思想链（CoT）已被证明对于需要复杂推理的问题很有用。其中许多问题都是文本问题和多模态问题。给定不同模式的输入，模型会生成一个基本原理，然后用它来回答问题。由于幻觉问题，生成的文本质量高但语义不合逻辑的软否定理由并不总是有助于提高答案准确性。本研究提出了一种使用软负采样 (SNSE-CoT) 的基本原理生成方法来减轻多模态 CoT 中的幻觉。应用五种方法来生成软负样本，这些样本共享高度相似的文本，但与原始文本具有不同的语义。应用双向边缘损失（BML）将它们引入仅涉及正样本和负样本的传统​​对比学习框架中。 ScienceQA 数据集上的大量实验证明了该方法的有效性。代码和数据发布于https://github.com/zgMin/SNSE-CoT。]]></description>
      <guid>https://arxiv.org/abs/2405.09848</guid>
      <pubDate>Fri, 17 May 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>前神经方法在自然语言处理教学中的相关性</title>
      <link>https://arxiv.org/abs/2405.09854</link>
      <description><![CDATA[arXiv:2405.09854v1 公告类型：新
摘要：虽然使用深度学习的神经方法是当今自然语言处理 (NLP) 的最先进技术，但前神经算法和方法仍然在近年来的 NLP 教科书和课程中占有一席之地。在本文中，我们比较了澳大利亚和印度教授的两门 NLP 入门课程，并研究了 Transformer 和预神经方法如何在课程的讲座计划和评估中取得平衡。我们还与 CS1 教育中“对象优先”和“对象之后”的争论进行了类比。我们观察到，前神经方法通过建立对 NLP 问题、潜在解决方案甚至基于 Transformer 的模型本身的直观理解，为学生的学习增加了价值。尽管前神经方法并不是最先进的，但该论文还是将其纳入当今的 NLP 课程中。]]></description>
      <guid>https://arxiv.org/abs/2405.09854</guid>
      <pubDate>Fri, 17 May 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>IGOT：域自适应预训练的信息增益优化分词器</title>
      <link>https://arxiv.org/abs/2405.09857</link>
      <description><![CDATA[arXiv:2405.09857v1 公告类型：新
摘要：预训练大型语言模型（LLM）如 ChatGPT、Claude 等在自然语言生成的各个领域都展现了强大的能力。然而，在专门领域特定领域使用LLM时仍然存在许多问题。当使用生成式人工智能处理下游任务时，常见的方法是通过持续训练或微调向预训练模型添加新知识（例如私有领域知识、前沿信息）。然而，领域适应训练是否存在通用范式仍然是一个悬而未决的问题。在本文中，我们提出了信息增益优化分词器（IGOT），它分析下游任务的特殊标记集，使用启发式函数 $\phi$ 和特殊标记及其信息增益构造一个新的子集，以构建新的特定领域tokenizer，并继续对下游任务数据进行预训练。我们探索了该方法的定制分词器对领域自适应预训练的许多积极影响，并验证了该方法可以比仅收集数据和微调的普通方法表现得更好。根据我们的实验，IGOT 使用 LLaMA-7B 的持续预训练过程实现了 11.9% 的 token 节省、12.2% 的训练时间节省和 5.8% 的最大 GPU VRAM 使用节省，结合 T5 模型，我们甚至可以达到节省 31.5% 的训练时间，使得将通用生成式 AI 移植到特定领域比以前更有效。在特定领域的任务中，有监督的 $IGOT_\tau$ 在保持预训练期间在减少收敛半径和收敛点方面表现出了出色的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.09857</guid>
      <pubDate>Fri, 17 May 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>基于LLM的情感分析优化技术（GPT-3）</title>
      <link>https://arxiv.org/abs/2405.09770</link>
      <description><![CDATA[arXiv:2405.09770v1 公告类型：新
摘要： 随着自然语言处理（NLP）技术的快速发展，GPT-3等大规模预训练语言模型已成为NLP领域的热门研究对象。本文旨在探索基于GPT-3等大型预训练语言模型的情感分析优化技术，以提高模型性能和效果，进一步推动自然语言处理（NLP）的发展。通过介绍情感分析的重要性和传统方法的局限性，本文介绍了GPT-3和Fine-tuning技术，并详细解释了它们在情感分析中的应用。实验结果表明Fine-tuning技术可以优化GPT-3模型并在情感分析任务中获得良好的性能。该研究为未来使用大规模语言模型进行情感分析提供了重要参考。]]></description>
      <guid>https://arxiv.org/abs/2405.09770</guid>
      <pubDate>Fri, 17 May 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>SecureLLM：使用组合性为私有、敏感和秘密数据构建可证明安全的语言模型</title>
      <link>https://arxiv.org/abs/2405.09805</link>
      <description><![CDATA[arXiv:2405.09805v1 公告类型：新
摘要：传统的安全机制将资源与不应访问它们的用户隔离开来。我们将此类安全机制的组合性质反映到 LLM 的结构中，以构建可证明安全的 LLM；我们称之为 SecureLLM。其他 LLM 安全方法试图防止不良行为者或不良结果，但只能在一定程度上做到这一点，使其不适合敏感数据。SecureLLM 将访问安全性与微调方法相结合。每个数据孤岛都与其相关联的单独微调，用户只能访问他们有权访问的微调集合。然后，模型必须在这些数据孤岛与这些单个微调的组合的交集上执行组合任务。虽然适用于任何任务，如文档 QA 或进行 API 调用，但在这项工作中，我们关注的是学习新 SQL 数据库布局的模型，以提供自然语言到 SQL 的翻译功能。现有的微调组合方法在这种充满挑战的环境中失败了，因为它们不具备处理组合任务的能力。组合性仍然是 LLM 面临的挑战。我们既贡献了一项困难的新组合自然语言到 SQL 翻译任务，也贡献了 LLM 安全性的新视角，使模型能够部署到当今的安全环境中。]]></description>
      <guid>https://arxiv.org/abs/2405.09805</guid>
      <pubDate>Fri, 17 May 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>Chameleon：混合模态早期融合基础模型</title>
      <link>https://arxiv.org/abs/2405.09818</link>
      <description><![CDATA[arXiv:2405.09818v1 公告类型：新
摘要：我们提出了 Chameleon，这是一系列基于早期融合令牌的混合模式模型，能够理解和生成任意序列的图像和文本。我们从一开始就概述了稳定的训练方法、对齐方法以及为早期融合、基于令牌的混合模式设置量身定制的架构参数化。这些模型在一系列全面的任务上进行评估，包括视觉问答、图像字幕、文本生成、图像生成和长格式混合模态生成。 Chameleon 展示了广泛而通用的功能，包括在图像字幕任务中最先进的性能，在纯文本任务中优于 Llama-2，同时与 Mixtral 8x7B 和 Gemini-Pro 等模型竞争，并执行非平凡的图像一代，全部在一个模型中。根据人类对新的长形式混合模式生成评估的判断，它还匹配或超过了更大模型（包括 Gemini Pro 和 GPT-4V）的性能，其中提示或输出包含图像和文本的混合序列。 Chameleon 标志着完整多模式文档的统一建模向前迈出了重要一步。]]></description>
      <guid>https://arxiv.org/abs/2405.09818</guid>
      <pubDate>Fri, 17 May 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>隐式话语关系预测中的句子邻居分析</title>
      <link>https://arxiv.org/abs/2405.09735</link>
      <description><![CDATA[arXiv:2405.09735v1 公告类型：新
摘要：在没有明确上下文标记的情况下，话语关系分类是一项特别困难的任务\cite{Prasad2008ThePD}。当前隐式关系预测的方法仅依赖于两个相邻的目标句子，忽略了其周围环境的更广泛的上下文\cite{Atwell2021WhereAW}。在这项研究中，我们提出了三种将上下文纳入句子关系预测任务的新方法：（1）直接邻居（DN），（2）扩展窗口邻居（EWN）和（3）部分智能随机邻居（PSRN）。我们的研究结果表明，在话语关系分类任务中包含超出一个话语单元的上下文是有害的。]]></description>
      <guid>https://arxiv.org/abs/2405.09735</guid>
      <pubDate>Fri, 17 May 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>人多力量大：基于模块的专家混合的面向任务的对话系统</title>
      <link>https://arxiv.org/abs/2405.09744</link>
      <description><![CDATA[arXiv:2405.09744v1 公告类型：新
摘要：面向任务的对话系统广泛应用于虚拟助理和其他自动化服务中，提供用户和机器之间的接口以促进特定任务。如今，面向任务的对话系统极大地受益于预训练语言模型（PLM）。然而，它们的任务解决性能受到 PLM 固有能力的限制，并且随着模型尺寸变大，扩展这些模型既昂贵又复杂。为了应对这些挑战，我们提出了面向任务的软专家混合对话系统（SMETOD），该系统利用混合专家（MoE）的集合来擅长解决子问题并为面向任务的对话生成专门的输出。 SMETOD 还以简单性和灵活性扩展了面向任务的对话系统，同时保持了推理效率。我们在三个基准功能上广泛评估我们的模型：意图预测、对话状态跟踪和对话响应生成。实验结果表明，SMETOD 在大多数评估指标上均实现了最先进的性能。此外，与现有强基线的比较表明，SMETOD 在推理成本和解决问题的正确性方面具有很大优势。]]></description>
      <guid>https://arxiv.org/abs/2405.09744</guid>
      <pubDate>Fri, 17 May 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>超维空间中的无监督抽取对话摘要</title>
      <link>https://arxiv.org/abs/2405.09765</link>
      <description><![CDATA[arXiv:2405.09765v1 公告类型：新
摘要：我们提出了 HyperSum，一种提取式摘要框架，它既体现了传统词汇摘要的效率，又体现了当代神经方法的准确性。 HyperSum 利用在极高维度（“维度的祝福”）随机初始化向量时出现的伪正交性来构建有代表性且高效的句子嵌入。简单地对获得的嵌入进行聚类并提取它们的中心点即可产生有竞争力的摘要。 HyperSum 在摘要准确性和忠实度方面通常优于最先进的摘要器，同时速度快 10 到 100 倍。我们开源 HyperSum 作为无监督提取摘要的强大基线。]]></description>
      <guid>https://arxiv.org/abs/2405.09765</guid>
      <pubDate>Fri, 17 May 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>用于大语言模型对齐的激活的频谱编辑</title>
      <link>https://arxiv.org/abs/2405.09719</link>
      <description><![CDATA[arXiv:2405.09719v1 公告类型：新
摘要：大型语言模型 (LLM) 经常表现出不良行为，例如生成不真实或有偏见的内容。事实证明，在现有对齐方法的基础上，编辑其内部表示可以有效缓解此类行为。我们提出了一种新颖的推理时间编辑方法，即激活的频谱编辑 (SEA)，将输入表示投射到与正演示（例如，真实）具有最大协方差的方向，同时最小化与负演示（例如，幻觉）的协方差。我们还将我们的方法扩展到使用特征函数的非线性编辑。我们使用六个不同大小和模型系列的开源 LLM 对有关真实性和偏见的基准进行了广泛的实验。结果证明了 SEA 在有效性、对类似任务的泛化以及推理和数据效率方面的优越性。我们还表明 SEA 编辑对其他模型功能的负面影响有限。]]></description>
      <guid>https://arxiv.org/abs/2405.09719</guid>
      <pubDate>Fri, 17 May 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>SCI 3.0：基于 Web 的图形事件表示模式管理界面</title>
      <link>https://arxiv.org/abs/2405.09733</link>
      <description><![CDATA[arXiv:2405.09733v1 公告类型：新
摘要：为了理解全球事件的复杂性，我们必须浏览一个相互交织的子事件网络，在更大、抽象的宏观事件框架中识别出那些最具影响力的元素。这个概念可以扩展到自然语言处理（NLP）领域：通过将抽象事件表示定义为结构化事件模式。通过创建可以充当这些抽象事件的表示的结构化事件模式。我们方法的核心是 Schema Curation Interface 3.0 (SCI 3.0)，这是一个 Web 应用程序，有助于在生成的图表中实时编辑事件模式属性，例如直接通过以下方式添加、删除或编辑子事件、实体和关系：一个接口。]]></description>
      <guid>https://arxiv.org/abs/2405.09733</guid>
      <pubDate>Fri, 17 May 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>世界知识要素（EWOK）：用于评估语言模型中的基本世界知识的认知启发框架</title>
      <link>https://arxiv.org/abs/2405.09605</link>
      <description><![CDATA[arXiv:2405.09605v1 公告类型：新
摘要：构建和利用世界模型的能力对于通用人工智能代理至关重要。测试这种能力很困难，部分原因是世界模型的构建模块定义不明确。我们提出了世界知识元素（EWOK），这是一个评估语言模型中的世界建模的框架，通过测试语言模型使用概念知识将目标文本与合理/难以置信的上下文进行匹配的能力。 EWOK 针对已知对人类世界建模至关重要的多个知识领域的特定概念。领域范围从社交互动（帮助/阻碍）到空间关系（左/右）。上下文和目标都是最小对。可以灵活地填充项目中的对象、代理和位置，从而轻松生成多个受控数据集。然后我们介绍 EWOK-CORE-1.0，这是一个包含 4,374 个项目的数据集，涵盖 11 个世界知识领域。我们通过一系列评估范式以及包含 12,480 个测量值的人类规范研究来评估 20 个开放权重大型语言模型（1.3B--70B 参数）。所有测试模型的整体性能都比人类性能差，不同领域的结果差异很大。这些数据突出了即使是大型模型也会失败的简单案例，并为 LLM 世界建模能力的有针对性的研究提供了丰富的途径。]]></description>
      <guid>https://arxiv.org/abs/2405.09605</guid>
      <pubDate>Fri, 17 May 2024 06:18:23 GMT</pubDate>
    </item>
    <item>
      <title>模拟政策影响：开发生成情景写作方法来评估监管的感知效果</title>
      <link>https://arxiv.org/abs/2405.09679</link>
      <description><![CDATA[arXiv:2405.09679v1 公告类型：新
摘要：人工智能技术的快速发展对个人和社会产生了许多未来影响。因此，政策制定者的任务是迅速做出反应并制定减轻这些影响的政策。然而，预测政策的有效性是一项艰巨的任务，因为有些影响可能只有在未来才能观察到，相关政策可能不适用于人工智能的未来发展。在这项工作中，我们开发了一种使用大型语言模型（LLM）来评估特定政策在减轻特定负面影响方面的有效性的方法。为此，我们使用 GPT-4 生成政策出台前后的场景，并将这些生动的故事转化为基于人类对影响的感知的指标。我们利用已经建立的生成式人工智能在媒体环境中影响的分类法，生成一组由欧盟人工智能法案第 50 条的透明度立法减轻和未减轻的场景对。然后，我们进行了一项用户研究 (n=234)，从四个风险评估维度评估这些情景：严重性、合理性、严重性和对弱势群体的特异性。我们发现，这种透明度立法被认为可以有效减轻劳工和福祉等领域的危害，但在社会凝聚力和安全等领域基本上无效。通过这个关于生成性人工智能危害的案例研究，我们证明了我们的方法作为工具的有效性，可以迭代减轻各种负面影响的政策的有效性。我们希望这种方法对想要集思广益不同政策或其他缓解策略的潜在效用的研究人员或其他利益相关者有用。]]></description>
      <guid>https://arxiv.org/abs/2405.09679</guid>
      <pubDate>Fri, 17 May 2024 06:18:23 GMT</pubDate>
    </item>
    </channel>
</rss>