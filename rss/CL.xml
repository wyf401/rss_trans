<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 22 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>ArxEval：评估科学文献语言模型中的检索和生成</title>
      <link>https://arxiv.org/abs/2501.10483</link>
      <description><![CDATA[arXiv:2501.10483v1 公告类型：新
摘要：语言模型 [LM] 现在在信息生成和合成中发挥着越来越大的作用；这些系统中科学知识的表示需要高度准确。一个主要的挑战是幻觉；也就是说，产生看似合理但实际上是错误的信息，包括虚构的引文和不存在的研究论文。这种不准确性在所有需要高水平事实正确性的领域都是危险的，例如学术界和教育界。这项工作提出了一种用于评估语言模型在科学文献中生成响应时产生幻觉的频率的流程。我们提出了 ArxEval，这是一个使用 ArXiv 作为存储库的评估流程，包含两个任务：混乱标题和混合标题。我们的评估包括十五种广泛使用的语言模型，并提供了它们在处理科学文献方面的可靠性的比较见解。]]></description>
      <guid>https://arxiv.org/abs/2501.10483</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Tabular-TX：通过情境学习实现基于主题解释结构的表格汇总</title>
      <link>https://arxiv.org/abs/2501.10487</link>
      <description><![CDATA[arXiv:2501.10487v1 公告类型：新
摘要：本文提出了一种基于主题解释结构的表格摘要 (Tabular-TX) 管道，旨在高效处理表格数据。Tabular-TX 通过关注突出显示的单元格对表格数据进行预处理，然后生成摘要句子，该摘要句子由副词短语形式的主题部分和从句形式的解释部分构成。在此过程中，通过考虑表格的结构特征和可比性来执行定制分析。此外，通过利用上下文学习，Tabular-TX 优化了大型语言模型 (LLM) 的分析能力，而无需进行微调，从而有效地处理表格数据的结构复杂性。尽管数据集大小有限，但应用所提出的 Tabular-TX 生成基于表格的摘要的结果与现有的基于微调的方法相比表现出卓越的性能。实验结果证实，Tabular-TX 可以更有效地处理复杂的表格数据，并使其成为基于表格的问答和总结任务的新替代方案，特别是在资源受限的环境中。]]></description>
      <guid>https://arxiv.org/abs/2501.10487</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型内部表示中的标记几何</title>
      <link>https://arxiv.org/abs/2501.10573</link>
      <description><![CDATA[arXiv:2501.10573v1 公告类型：新
摘要：我们研究了 token 嵌入的几何形状与它们在 Transformer 模型中的下一个 token 预测中的作用之间的关系。这种联系的一个重要方面是使用经验测量的概念，它对 Transformer 层中 token 点云的分布进行编码，并推动平均场交互图中 token 表示的演变。我们使用内在维度、邻域重叠和余弦相似度等指标来跨层观察探测这些经验测量。为了验证我们的方法，我们将这些指标与 token 被打乱的数据集进行比较，这会破坏句法和语义结构。我们的研究结果揭示了 token 嵌入的几何属性与下一个 token 预测的交叉熵损失之间的相关性，这意味着损失值较高的提示在更高维空间中表示 token。]]></description>
      <guid>https://arxiv.org/abs/2501.10573</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>调整大型语言模型以实现基于字符的增强和替代交流</title>
      <link>https://arxiv.org/abs/2501.10582</link>
      <description><![CDATA[arXiv:2501.10582v1 公告类型：新
摘要：增强和替代通信 (AAC) 的用户可以通过使用字符语言模型的界面逐个字母地书写。但是，大多数最先进的大型预训练语言模型都会预测可变长度的子词标记。我们研究如何实际使用此类模型进行准确而有效的字符预测。我们使用我们精心策划的大量句子数据集对模型进行微调，其中每个句子都根据其对口头或书面 AAC 通信的有用程度进行评级。我们发现，使用算法从子词大型语言模型生成字符预测比添加分类层或使用字节级模型提供更准确的预测。我们还发现我们的领域适应课程可以有效提高简单对话文本的模型性能。]]></description>
      <guid>https://arxiv.org/abs/2501.10582</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>医学评论家的迭代树分析</title>
      <link>https://arxiv.org/abs/2501.10642</link>
      <description><![CDATA[arXiv:2501.10642v1 公告类型：新
摘要：大型语言模型 (LLM) 已广泛应用于各个领域，但它们在医学领域的应用带来了独特的挑战，特别是在幻觉的产生方面。开放式长篇医学文本中的幻觉表现为误导性的关键主张，由于两个原因，这些主张很难验证。首先，关键主张往往深深纠缠在文本中，不能仅基于表面层次的呈现来提取。其次，验证这些主张具有挑战性，因为基于表面层次的标记检索通常缺乏精确或具体的证据，如果没有更深层次的基于机制的分析，这些主张就无法验证。在本文中，我们为医学批评家介绍了一种称为迭代树分析 (ITA) 的新方法。ITA 旨在从长篇医学文本中提取隐含的主张，并通过迭代和自适应的树状推理过程验证每个主张。此过程结合了自上而下的任务分解和自下而上的证据整合，通过详细的机制级推理实现对复杂医疗索赔的精确验证。我们进行了广泛的实验，结果表明，ITA 在检测复杂医疗文本验证任务中的事实错误方面的表现比以前的方法高出 10%。此外，我们将向公众发布一个全面的测试集，旨在促进该领域研究的进一步发展。]]></description>
      <guid>https://arxiv.org/abs/2501.10642</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DNA 1.0 技术报告</title>
      <link>https://arxiv.org/abs/2501.10648</link>
      <description><![CDATA[arXiv:2501.10648v1 公告类型：新
摘要：在本报告中，我们介绍了 DNA 1.0 8B Instruct，这是一种针对韩语和英语语言任务优化的最先进的双语语言模型。通过对 Llama 3.1 8B 应用高质量韩语数据集的持续预训练 (CPT) 以及随后的监督微调 (SFT)，我们创建了一个具有增强韩语能力的指令跟随模型。然后通过球面线性插值 (SLERP) 将此模型与 Llama 3.1 8B Instruct 合并，并通过直接偏好优化 (DPO) 和知识提炼 (KD) 进行进一步优化。 DNA 1.0 8B Instruct 在韩语特定任务上取得了最先进的成果，包括 KMMLU（53.26%）、KoBEST（83.40%）和 BELEBELE（57.99%），同时在 MMLU（66.64%）、MMLU-Pro（43.05%）和 GSM8K（80.52%）上保持了强大的英语能力。作为一个开放模型，DNA 1.0 8B Instruct 代表了双语语言建模的重大进步。
作为一个开放模型，DNA 1.0 8B Instruct 可通过 https://huggingface.co/dnotitia/Llama-DNA-1.0-8B-Instruct 免费获取。如需商业许可查询或反馈，请通过 https://www.dnotitia.com/contact/post-form 联系我们]]></description>
      <guid>https://arxiv.org/abs/2501.10648</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在现代营销管理中发挥大型语言模型的潜力：应用、未来方向和战略建议</title>
      <link>https://arxiv.org/abs/2501.10685</link>
      <description><![CDATA[arXiv:2501.10685v1 公告类型：新
摘要：大型语言模型 (LLM) 彻底改变了营销管理中的客户参与、活动优化和内容生成过程。在本文中，我们探讨了 LLM 的变革潜力以及当前的应用、未来方向和对营销人员的战略建议。特别是，我们关注 LLM 的主要业务驱动因素，例如个性化、实时交互式客户洞察和内容自动化，以及它们如何实现客户和业务成果。例如，还涵盖了 AI 在数据隐私、透明度和减轻偏见方面的道德方面，目的是通过最佳实践和新技术的使用来促进负责任地使用该技术，企业可以利用 LLM 的潜力，这有助于增长并在数字营销的动荡中保持领先一步。本文旨在通过使用最佳行业实践为营销人员提供必要的指导，将这些强大的 LLM 融入他们的营销策略和创新中，而不会损害其品牌精神。]]></description>
      <guid>https://arxiv.org/abs/2501.10685</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多语言嵌入空间表征翻译对互文性的影响</title>
      <link>https://arxiv.org/abs/2501.10731</link>
      <description><![CDATA[arXiv:2501.10731v1 公告类型：新
摘要：修辞手法很难翻译，但它们对文学文献的翻译至关重要。我们研究了使用多语言嵌入空间来表征互文性（一种常见的修辞手法）在人工翻译和机器翻译中的保存情况。为此，我们使用圣经文本，这些文本既充满了互文性引用，也是高度翻译的作品。我们提供了一个度量标准来在语料库级别表征互文性，并对这种修辞手法在现存的人工翻译和机器生成的对应物中的保存情况进行了定量分析。我们继续对人工翻译过分或过分强调文本中存在的互文性，而机器翻译提供中立基线的案例进行定性分析。这为既定的学术研究提供了支持，该研究提出人工翻译倾向于放大原始手稿的某些文学特征。]]></description>
      <guid>https://arxiv.org/abs/2501.10731</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>古代宗教文本中对句的计算发现</title>
      <link>https://arxiv.org/abs/2501.10739</link>
      <description><![CDATA[arXiv:2501.10739v1 公告类型：新
摘要：对句是圣经文本中一种备受争议的文学手法，它吸引了神秘主义者，同时也引发了持续的学术讨论。在本文中，我们介绍了第一种系统地检测圣经段落中对句的计算方法。我们的方法利用神经嵌入来捕获与对句相关的词汇和语义模式，应用于文本粒度的多个级别（半节、诗句）。我们还让专家注释者来审查检测到的模式的子集。尽管计算效率高，但我们的方法取得了稳健的结果，注释者之间的一致性很高，诗句级别的系统精度@k 为 0.80，半节级别的系统精度@k 为 0.60。我们进一步对检测到的对句的分布进行了定性分析，并选取了一些例子来强调我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.10739</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>开发特定应用的大型语言模型以促进研究伦理审查</title>
      <link>https://arxiv.org/abs/2501.10741</link>
      <description><![CDATA[arXiv:2501.10741v1 公告类型：新
摘要：机构审查委员会 (IRB) 在确保人类受试者研究的道德行为方面发挥着至关重要的作用，但面临着包括不一致、延迟和低效率在内的挑战。我们建议开发和实施特定于应用的大型语言模型 (LLM)，以促进 IRB 审查流程。这些 IRB 特定的 LLM 将根据 IRB 特定的文献和机构数据集进行微调，并配备检索功能以访问最新的上下文相关信息。我们概述了潜在的应用，包括预审筛选、初步分析、一致性检查和决策支持。在解决对准确性、上下文敏感性和人为监督的担忧的同时，我们承认仍然存在一些挑战，例如过度依赖人工智能和对透明度的需求。通过提高伦理审查的效率和质量，同时在关键决策中保持人类判断，IRB 特定的 LLM 提供了一种有前途的工具来改善研究监督。我们呼吁进行试点研究来评估这种方法的可行性和影响。]]></description>
      <guid>https://arxiv.org/abs/2501.10741</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BAP v2：Minecraft 对话中遵循指令的增强任务框架</title>
      <link>https://arxiv.org/abs/2501.10836</link>
      <description><![CDATA[arXiv:2501.10836v1 公告类型：新
摘要：能够理解和执行物理世界中的指令的交互式代理长期以来一直是 AI 研究的核心目标。Minecraft 协作构建任务 (MCBT) 提供了一种实现此目标的设置（Narayan-Chen、Jayannavar 和 Hockenmaier 2019）。这是一款双人游戏，其中建筑师 (A) 指示建造者 (B) 在模拟的积木世界环境中构建目标结构。我们专注于具有挑战性的建造者动作预测 (BAP) 子任务，即在给定的多模态游戏环境中使用有限的训练数据预测正确的动作序列（Jayannavar、Narayan-Chen 和 Hockenmaier 2020）。我们仔细研究了 BAP 任务的评估和数据，发现了关键挑战并在两个方面做出了重大改进，提出了该任务的升级版本 BAP v2。这将使未来的工作取得更高效、更有意义的进展。它包括：（1）增强的评估基准，包括更清晰的测试集和更公平、更有洞察力的指标，以及（2）从模拟 MCBT 的新型 Minecraft 对话和目标结构模拟器生成的额外合成训练数据。我们表明，即使使用相对简单的训练方法，合成数据也可以用于训练性能更高、更稳健的神经模型。展望未来，这些数据对于训练更复杂、数据密集型深度 Transformer 模型以及训练/微调越来越大的 LLM 也至关重要。虽然建模不是这项工作的主要重点，但我们还说明了我们的数据和训练方法对简单的基于 LLM 和 Transformer 的模型的影响，从而验证了我们方法的稳健性，并为未来更先进的架构和 LLM 奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2501.10836</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用遵循指令的法学硕士 (LLM) 进行零样本和少样本学习，用于自动事实核查中的声明匹配</title>
      <link>https://arxiv.org/abs/2501.10860</link>
      <description><![CDATA[arXiv:2501.10860v1 公告类型：新
摘要：声明匹配 (CM) 任务可以通过将可以通过相同事实核查解决的声明放在一起，从而使自动事实核查流程受益。在这项工作中，我们首次探索了零样本和少样本学习方法。我们将 CM 视为二元分类任务，并使用一组遵循指令的大型语言模型 (GPT-3.5-turbo、Gemini-1.5-flash、Mistral-7B-Instruct 和 Llama-3-8B-Instruct) 进行实验，研究提示模板。我们引入了一个新的 CM 数据集 ClaimMatch，它将在接受后发布。我们在 CM 任务中对 LLM 进行了测试，发现可以通过利用更成熟但相似的任务（例如自然语言推理或释义检测）来解决它。我们还提出了一个 CM 流程，我们根据不同长度的文本对其进行了评估。]]></description>
      <guid>https://arxiv.org/abs/2501.10860</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从语言模型生成结构化输出：基准和研究</title>
      <link>https://arxiv.org/abs/2501.10868</link>
      <description><![CDATA[arXiv:2501.10868v1 公告类型：新
摘要：可靠地生成结构化输出已成为现代语言模型 (LM) 应用程序的关键功能。约束解码已成为各个行业在生成过程中强制执行结构化输出的主导技术。尽管它的采用率越来越高，但对约束解码的行为和性能的系统评估却很少。约束解码框架已经围绕 JSON Schema 标准化为结构化数据格式，大多数用途都保证在给定模式的情况下遵守约束。然而，人们对这些方法在实践中的有效性了解甚少。我们提出了一个评估框架，从三个关键维度评估约束解码方法：生成符合约束的输出的效率、各种约束类型的覆盖率以及生成输出的质量。为了促进这一评估，我们引入了 JSONSchemaBench，这是一个约束解码的基准，包含 10K 个现实世界的 JSON 模式，涵盖了各种复杂程度的约束。我们将基准与现有的官方 JSON Schema 测试套件配对，并评估了六个最先进的约束解码框架，包括 Guidance、Outlines、Llamacpp、XGrammar、OpenAI 和 Gemini。通过大量实验，我们深入了解了约束解码在现实世界 JSON 模式的结构化生成方面的能力和局限性。我们的工作为改进约束解码框架和结构化生成任务提供了可行的见解，为评估约束解码和结构化生成树立了新标准。我们在 https://github.com/guidance-ai/jsonschemabench 发布了 JSONSchemaBench]]></description>
      <guid>https://arxiv.org/abs/2501.10868</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于错误严重程度的法国 ASR 系统基准测试</title>
      <link>https://arxiv.org/abs/2501.10879</link>
      <description><![CDATA[arXiv:2501.10879v1 公告类型：新
摘要：自动语音识别 (ASR) 转录错误通常使用将其与参考转录进行比较的指标来评估，例如单词错误率 (WER)，它衡量与参考的拼写偏差，或基于语义分数的指标。然而，这些方法在解释转录错误时往往会忽略人类可以理解的内容。为了解决这一限制，提出了一种新的评估方法，将错误分为四个严重程度级别，进一步细分为子类型，基于客观语言标准、上下文模式和使用内容词作为分析单位。该指标适用于 10 个最先进的法语 ASR 系统的基准测试，包括基于 HMM 和端到端模型。我们的研究结果揭示了每个系统的优点和缺点，确定了那些为用户提供最舒适阅读体验的系统。]]></description>
      <guid>https://arxiv.org/abs/2501.10879</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LegalGuardian：法律实践中大型语言模型安全集成的隐私保护框架</title>
      <link>https://arxiv.org/abs/2501.10915</link>
      <description><![CDATA[arXiv:2501.10915v1 公告类型：新
摘要：大型语言模型 (LLM) 有望通过自动化复杂任务和改善司法途径来推进法律实践。然而，由于对客户机密性的担忧，它们的采用受到限制，尤其是当律师在提示中包含敏感的个人身份信息 (PII) 时，存在未经授权的数据泄露风险。为了缓解这种情况，我们引入了 LegalGuardian，这是一个轻量级的隐私保护框架，专为使用基于 LLM 的工具的律师量身定制。LegalGuardian 采用命名实体识别 (NER) 技术和本地 LLM 来屏蔽和揭露提示中的机密 PII，在任何外部交互之前保护敏感数据。我们详细介绍了它的开发，并使用合成提示库在移民法场景中评估了它的有效性。将传统 NER 模型与一次性提示的本地 LLM 进行比较，我们发现 LegalGuardian 在 PII 检测中使用 GLiNER 可获得 93% 的 F1 分数，使用 Qwen2.5-14B 可获得 97% 的 F1 分数。语义相似性分析证实，该框架在输出中保持了高保真度，确保了基于 LLM 的工具的强大实用性。我们的研究结果表明，法律专业人士可以利用先进的 AI 技术，而不会损害客户机密性或法律文件的质量。]]></description>
      <guid>https://arxiv.org/abs/2501.10915</guid>
      <pubDate>Wed, 22 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>