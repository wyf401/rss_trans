<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 19 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于交叉注意的多模态特征融合的抑郁症检测方法</title>
      <link>https://arxiv.org/abs/2407.12825</link>
      <description><![CDATA[arXiv:2407.12825v1 公告类型：新
摘要：抑郁症是一种普遍而严重的心理健康问题，影响着全球约 3.8% 的人口。尽管存在有效的治疗方法，但中低收入国家超过 75% 的人仍未得到治疗，部分原因是难以在早期准确诊断抑郁症。本文介绍了一种基于交叉注意的多模态特征融合检测抑郁症的新方法。通过使用 MacBERT 作为预训练模型从文本中提取词汇特征，并加入额外的 Transformer 模块来细化特定于任务的上下文理解，该模型对目标任务的适应性得到增强。与以前简单地连接多模态特征的做法不同，该方法利用交叉注意进行特征集成，显着提高抑郁症检测的准确性，并能够更全面、更准确地分析用户的情绪和行为。此外，还构建了基于交叉注意 (MFFNC) 的多模态特征融合网络，在抑郁症识别任务中表现出色。实验结果表明，我们的方法在测试数据集上的准确率达到 0.9495，比现有方法有了显着的改进。此外，它为其他社交媒体平台和涉及多模态处理的任务概述了一种有前途的方法。及时识别和干预抑郁症患者对于挽救生命至关重要，凸显了技术在促进心理健康问题早期干预方面的巨大潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.12825</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:59 GMT</pubDate>
    </item>
    <item>
      <title>评估 GPT-4o 在气候变化证据综合和系统评估中的有效性：初步见解</title>
      <link>https://arxiv.org/abs/2407.12826</link>
      <description><![CDATA[arXiv:2407.12826v1 公告类型：新 
摘要：在这篇简短的研究中，我们研究了使用 GPT-4o（一种最先进的大型语言模型 (LLM)）进行证据综合和系统评估任务的潜力。此类任务的传统工作流程涉及大量领域专家，他们手动审查和综合大量文献。科学文献的迅猛增长和 LLM 的最新进展为用新时代工具补充这些传统工作流程提供了机会。我们评估了 GPT-4o 在全球适应制图倡议 (GAMI) 创建的数据集样本上执行这些任务的有效性，我们检查了从三个专业水平的科学文献中提取气候变化适应相关特征的准确性。我们的结果表明，虽然 GPT-4o 可以在地理位置识别等低专业任务中实现高精度，但它们在利益相关者识别和适应响应深度评估等中级和高专业任务中的表现不太可靠。这些发现促使我们需要设计评估工作流程，利用 GPT-4o 等模型的优势，同时提供改进以提高其在这些任务上的表现。]]></description>
      <guid>https://arxiv.org/abs/2407.12826</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:59 GMT</pubDate>
    </item>
    <item>
      <title>WTU-EVAL：大型语言模型是否使用工具的评估基准</title>
      <link>https://arxiv.org/abs/2407.12823</link>
      <description><![CDATA[arXiv:2407.12823v1 公告类型：新
摘要：虽然大型语言模型（LLM）在 NLP 任务中表现出色，但它们仍然需要外部工具来扩展其能力。当前关于使用 LLM 进行工具学习的研究通常假设强制使用工具，这并不总是与现实世界的情况相符，在现实世界中，工具的必要性是不确定的，不正确或不必要的工具使用会损害 LLM 的一般能力。因此，我们建议探索 LLM 是否能够辨别其能力边界并灵活使用工具。然后，我们引入了是否使用工具评估基准（WTU-Eval）来使用 11 个数据集来评估 LLM，其中 6 个是工具使用数据集，5 个是一般数据集。提示 LLM 根据需要使用工具。八个 LLM 在 WTU-Eval 上的结果表明，LLM 在一般数据集中经常难以确定工具使用情况，而当 LLM 的能力与 ChatGPT 相似时，其在工具使用数据集中的表现会有所提高。在这两个数据集中，错误的工具使用会严重损害 LLM 的性能。为了缓解这种情况，我们还开发了微调数据集来增强工具决策能力。微调 Llama2-7B 可使平均性能提高 14% 并将错误工具使用率降低 16.8%。我们将发布 WTU-Eval 基准。]]></description>
      <guid>https://arxiv.org/abs/2407.12823</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:58 GMT</pubDate>
    </item>
    <item>
      <title>耳语专家：语言模型中减轻毒性的神经干预</title>
      <link>https://arxiv.org/abs/2407.12824</link>
      <description><![CDATA[arXiv:2407.12824v1 公告类型：新
摘要：大型语言模型 (LLM) 的一个重要问题是它们会产生不良的毒性语言。在这项工作中，我们表明，负责毒性的神经元可以通过它们区分有毒句子的能力来确定，并且可以通过按比例降低它们的激活水平来减轻毒性语言。我们提出了 AUROC 适应 (AurA)，这是一种可以应用于任何预先训练的 LLM 以减轻毒性的干预措施。由于干预与每个神经元区分有毒内容的能力成正比，因此它不受任何依赖于模型的超参数的影响。我们表明，AurA 可以将毒性降低高达 $2.2 \times$，而困惑度仅增加 $0.72$。我们还表明，AurA 适用于不同规模的模型（从 1.5B 到 40B 个参数），并且它在缓解有害语言方面的有效性，同时保留了常识性的零样本能力，适用于所有规模。AurA 可以与预提示策略相结合，将其平均缓解潜力从 $1.28\times$ 提高到 $2.35\times$。此外，AurA 可以抵消恶意引发有害内容的对抗性预提示，使其成为部署更安全、毒性更小的模型的有效方法。]]></description>
      <guid>https://arxiv.org/abs/2407.12824</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:58 GMT</pubDate>
    </item>
    <item>
      <title>AutoFlow：大型语言模型代理的自动工作流生成</title>
      <link>https://arxiv.org/abs/2407.12821</link>
      <description><![CDATA[arXiv:2407.12821v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展在理解复杂自然语言方面取得了重大进展。LLM 的一个重要应用是基于 LLM 的 AI 代理，它利用 LLM 以及外部工具的能力来解决复杂任务。为了确保 LLM 代理遵循有效可靠的程序来解决给定的任务，通常使用手动设计的工作流来指导代理的工作机制。然而，手动设计工作流需要大量的努力和领域知识，这使得大规模开发和部署代理变得困难。为了解决这些问题，我们提出了 AutoFlow，这是一个旨在自动生成代理工作流以解决复杂任务的框架。AutoFlow 以自然语言程序作为代理工作流的格式，并采用工作流优化程序来迭代优化工作流质量。此外，这项工作提供了两种工作流生成方法：基于微调和基于上下文的方法，使 AutoFlow 框架适用于开源和闭源 LLM。实验结果表明，我们的框架可以生成稳健可靠的代理工作流。我们认为，用自然语言自动生成和解释工作流是解决复杂任务的一种有前途的范例，尤其是在 LLM 快速发展的情况下。这项工作的源代码可在 https://github.com/agiresearch/AutoFlow 上找到。]]></description>
      <guid>https://arxiv.org/abs/2407.12821</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:57 GMT</pubDate>
    </item>
    <item>
      <title>用于药物咨询的轻量级大型语言模型：Med-Pal</title>
      <link>https://arxiv.org/abs/2407.12822</link>
      <description><![CDATA[arXiv:2407.12822v1 公告类型：新
摘要：大型语言模型 (LLM) 已成为一种潜在的解决方案，可通过患者教育（通常是与药物相关的咨询）协助数字健康发展。我们训练并验证了 Med-Pal，这是一个特定于药物领域的 LLM 聊天机器人，使用细粒度和专家策划的数据集进行了微调，该数据集来自五个轻量级开源 LLM，参数大小较小（70 亿或更少），考虑到计算约束并优先考虑操作效率。一个多学科团队使用 SCORE 标准对 LLM 反应进行了临床评估，重点关注安全性、准确性、偏差、可重复性和易于理解性。表现最佳的轻量级 LLM 被选为 Med-Pal，以便使用对抗性提示进行进一步的工程设计。 Med-Pal 和现有的轻量级 LLM（包括预训练的 Biomistral 和微调的 Meerkat）在独立数据集上针对广泛的药物相关问题（共 231 个）进行了验证，这些问题涉及 14 种不同药物类别的 12 种不同问题类型。Mistral-7b 在选定的轻量级 LLM 中表现最佳，在准确性和安全性领域获得了最高的中位数分数 14 和 71.9% 的高质量响应，因此被选为 Med-Pal 的骨干 LLM。与 Biomistral 相比，Med-pal 在生成适合患者沟通的响应方面表现出色，显著减少了一般 LLM 常见的偏见和错误。将 Med-Pal 与 Meerkat 进行比较时观察到了可比的性能。Med-Pal 展示了开发和使用微调的轻量级 LLM 来增强数字健康通信的可行性。]]></description>
      <guid>https://arxiv.org/abs/2407.12822</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:57 GMT</pubDate>
    </item>
    <item>
      <title>PQCache：基于乘积量化的长上下文 LLM 推理 KVCache</title>
      <link>https://arxiv.org/abs/2407.12820</link>
      <description><![CDATA[arXiv:2407.12820v1 公告类型：新 
摘要：随着大型语言模型 (LLM) 领域的不断发展，推理中的上下文长度正在稳步增长。键值缓存 (KVCache) 是 LLM 推理中的关键组件，由于 GPU 内存有限，现在已成为主要的内存瓶颈。当前的方法选择性地确定适合 LLM 中自注意力计算的键和值来解决此问题。但是，它们要么无法保持模型质量，要么导致高服务延迟。从数据库社区中使用的高级嵌入检索技术中汲取灵感，我们将 KVCache 的存储和搜索视为典型的嵌入检索问题。我们提出了 PQCache，它采用乘积量化 (PQ) 来管理 KVCache，在确保低服务延迟的同时保持模型质量。在预填充阶段，我们将 PQ 应用于每个 LLM 层和头的令牌键。在自回归解码阶段，对于每个新生成的 token，我们首先使用 PQ 代码和质心通过最大内积搜索 (MIPS) 识别重要 token，然后获取相应的键值对进行自注意力计算。通过精心设计重叠和缓存，我们最大限度地减少了两个阶段的任何额外计算和通信开销。大量实验表明，PQCache 兼具有效性和效率。即使只有 1/5 的 token 参与注意力，它也能保持模型质量，同时实现可接受的系统延迟。]]></description>
      <guid>https://arxiv.org/abs/2407.12820</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>通过关注声学和置信度参考进行自动语音识别的错误纠正</title>
      <link>https://arxiv.org/abs/2407.12817</link>
      <description><![CDATA[arXiv:2407.12817v1 公告类型：新
摘要：准确地找到自动语音识别（ASR）假设中的错误单词并有理有据地恢复它们是语音纠错的目标。在本文中，我们提出了一种非自回归语音纠错方法。置信度模块测量 N 个最佳 ASR 假设中每个单词的不确定性，作为查找错误单词位置的参考。此外，来自 ASR 编码器的声学特征也用于提供正确的发音参考。使用编辑路径对齐来自 ASR 的 N 个最佳候选，以相互确认并恢复一些缺失的字符错误。此外，交叉注意机制融合了纠错参考和 ASR 假设之间的信息。实验结果表明，声学和置信度参考都有助于纠错。与 ASR 模型相比，所提出的系统将错误率降低了 21%。]]></description>
      <guid>https://arxiv.org/abs/2407.12817</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:55 GMT</pubDate>
    </item>
    <item>
      <title>“我明白为什么我得到这个分数”：带有反馈的自动简答评分</title>
      <link>https://arxiv.org/abs/2407.12818</link>
      <description><![CDATA[arXiv:2407.12818v1 公告类型：新 
摘要：随着教育系统向数字平台过渡，对高效和准确评估方法的需求日益增加。提供反馈在教育环境中至关重要，不仅仅是传达分数，它还证明了分配的分数是合理的。在此背景下，我们通过引入工程简答反馈 (EngSAF) 展示了自动评分方面的重大进步——这是一个包含 5.8k 个学生答案的数据集，并附有自动简答评分 (ASAG) 任务的参考答案和问题。EngSAF 数据集经过精心策划，涵盖了来自多个工程领域的各种主题、问题和答案模式。我们利用最先进的大型语言模型 (LLM) 的生成功能和我们的标签感知合成反馈生成 (LASFG) 策略将反馈包含在我们的数据集中。本文强调了增强反馈在实际教育环境中的重要性，概述了数据集注释和反馈生成过程，进行了全面的 EngSAF 分析，并提供了不同的基于 LLM 的零样本和微调基线以供将来比较。此外，我们通过在印度理工学院孟买分校 (IITB) 的真实期末考试中部署 ASAG 系统来证明其效率和有效性，展示了其实际可行性和在教育机构中更广泛实施的潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.12818</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:55 GMT</pubDate>
    </item>
    <item>
      <title>自然语言处理中的计算礼貌：一项调查</title>
      <link>https://arxiv.org/abs/2407.12814</link>
      <description><![CDATA[arXiv:2407.12814v1 公告类型：新
摘要：礼貌的计算方法是自动预测和生成文本中的礼貌的任务。鉴于礼貌在互动中的普遍性和挑战性，这是对话分析的一项关键任务。礼貌的计算方法引起了对话分析界的极大兴趣。本文汇编了过去自然语言处理中计算礼貌方面的研究成果。我们认为迄今为止的研究有四个里程碑，即监督和弱监督特征提取以识别和诱导给定文本中的礼貌、结合目标文本之外的上下文、跨不同社会因素研究礼貌以及研究礼貌与各种社会语言线索之间的关系。在本文中，我们描述了计算礼貌研究中的数据集、方法、趋势和问题。我们还讨论了代表性性能值，并提供了未来工作的指针，如先前的工作所示。在了解最新技术的资源方面，本调查提供了几个有价值的例子，最突出的是一个表格，从不同维度总结了过去的论文，例如特征类型、注释技术和使用的数据集。]]></description>
      <guid>https://arxiv.org/abs/2407.12814</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>SMLT-MUGC：小型、中型和大型文本——机器与用户生成内容的检测和比较</title>
      <link>https://arxiv.org/abs/2407.12815</link>
      <description><![CDATA[arXiv:2407.12815v1 公告类型：新
摘要：大型语言模型 (LLM) 因其模仿人类语言的能力而备受关注。识别 LLM 生成的文本对于了解其功能和减轻潜在后果至关重要。本文分析了不同文本长度的数据集：小、中、大。我们比较了机器学习算法在四个数据集上的性能：(1) 小型（来自 Election、FIFA 和权力的游戏的推文），(2) 中型（维基百科介绍和 PubMed 摘要），(3) 大型（OpenAI 网络文本数据集）。我们的结果表明，使用传统机器学习方法更难（74%）检测到具有非常大参数的 LLM（例如具有 1542 百万个参数的 GPT2 的 XL-1542 变体）。但是，使用较小参数（7.62 亿或更少）的 LLM 检测不同长度的文本可以达到高精度（96% 及以上）。我们从多个维度研究人类和机器生成的文本的特征，包括语言学、个性、情感、偏见和道德。我们的研究结果表明，机器生成的文本通常可读性更高，并且与人类的道德判断非常相似，但在性格特征上有所不同。SVM 和投票分类器 (VC) 模型在大多数数据集上始终保持高性能，而决策树 (DT) 模型的性能最低。处理改写的文本时，模型性能会下降，尤其是推文等较短的文本。这项研究强调了检测 LLM 生成的文本的挑战和重要性，并为未来的研究提出了方向，以改进检测方法并了解 LLM 的细微功能。]]></description>
      <guid>https://arxiv.org/abs/2407.12815</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>利用人工智能构建易于理解的政策和证据审查 (BUMPER) 消息传递</title>
      <link>https://arxiv.org/abs/2407.12812</link>
      <description><![CDATA[arXiv:2407.12812v1 公告类型：新
摘要：我们引入了一个使用大型语言模型 (LLM) 构建可理解的政策和证据审查消息 (BUMPER) 的框架。LLM 已被证明能够提供理解和合成各种媒体大型数据库的接口。这为将科学证据转化为政策和行动提供了一个激动人心的机会，从而改善了世界各地的生计。然而，这些模型也带来了与访问、可信度和问责制相关的挑战。BUMPER 框架由同一位科学家（例如个人贡献者、实验室、联盟）在科学知识库（例如文档、代码、调查数据）之上构建。我们专注于通过透明度、范围限制、明确检查和不确定性措施来建立可信度的解决方案。LLM 正在迅速被采用，但其后果却知之甚少。该框架解决了有关 LLM 的可靠性及其在高风险应用中的使用的未决问题。我们为旨在指导麻疹控制计划的模型提供了一个卫生政策实例。我们认为，该框架可以促进决策者获取科学证据并增强其信心，推动研究人员关注政策相关性和可翻译性，并最终增加和加速用于政策决策的科学知识的影响。]]></description>
      <guid>https://arxiv.org/abs/2407.12812</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:53 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行文本分类的数据生成：实证案例研究</title>
      <link>https://arxiv.org/abs/2407.12813</link>
      <description><![CDATA[arXiv:2407.12813v1 公告类型：新
摘要：近年来，使用大型语言模型 (LLM) 生成用于模型训练的合成数据变得越来越流行。虽然 LLM 能够生成真实的训练数据，但数据生成的有效性受到各种因素的影响，包括提示的选择、任务复杂性以及生成数据的质量、数量和多样性。在这项工作中，我们专注于使用合成数据进行文本分类任务。具体来说，我们使用在合成数据上训练的自然语言理解 (NLU) 模型来评估来自不同生成方法的合成数据的质量。这项工作对这些因素的影响进行了实证分析，并为更好的数据生成实践提出了建议。]]></description>
      <guid>https://arxiv.org/abs/2407.12813</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:53 GMT</pubDate>
    </item>
    <item>
      <title>GPT 捷克诗人：使用语言模型生成捷克诗歌节</title>
      <link>https://arxiv.org/abs/2407.12790</link>
      <description><![CDATA[arXiv:2407.12790v1 公告类型：新
摘要：目前，高质量的自动诗歌生成系统仅适用于一小部分语言。我们引入了一种基于微调预训练大型语言模型的捷克语诗歌生成新模型。我们证明，通过在诗歌文本中明确指定诗节参数来指导生成过程可以大大提高模型的有效性。我们还发现适当的标记化至关重要，表明基于音节或单个字符而不是子词的标记化方法在生成诗歌诗节方面表现更佳。我们通过引入 \textit{Forced~generation} 进一步增强了结果，在推理时根据已生成的文本添加韵律和诗节参数的明确规范。我们评估了一系列设置，表明我们提出的方法在生成的诗歌的押韵和韵律方面实现了高精度。]]></description>
      <guid>https://arxiv.org/abs/2407.12790</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:52 GMT</pubDate>
    </item>
    <item>
      <title>TourLLM：通过旅游知识增强法学硕士</title>
      <link>https://arxiv.org/abs/2407.12791</link>
      <description><![CDATA[arXiv:2407.12791v1 公告类型：新
摘要：最近，大型语言模型 (LLM) 已证明其在各种自然语言处理 (NLP) 任务中的有效性。然而，缺乏旅游知识限制了 LLM 在旅游景点介绍和旅行规划方面的表现。为了应对这一挑战，我们为文化和旅游领域构建了一个监督微调数据集，名为 Cultour。该数据集由三部分组成：旅游知识库 QA 数据、旅行日志数据和旅游多样性 QA 数据。此外，我们提出了 TourLLM，这是一个基于 Qwen 的模型，使用 Cultour 进行监督微调，以提高有关景点和旅行计划的信息质量。为了评估 TourLLM 的性能，我们采用了自动和人工评估，并提出了一个名为 CRA（一致性、可读性、可用性）的人工评估标准。实验结果证明了 TourLLM 生成的响应的有效性。我们提出的 Cultour 可在 https://github.com/mrweiqk/Cultour 上访问。]]></description>
      <guid>https://arxiv.org/abs/2407.12791</guid>
      <pubDate>Fri, 19 Jul 2024 06:19:52 GMT</pubDate>
    </item>
    </channel>
</rss>