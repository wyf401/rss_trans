<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 17 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>以圣安东尼奥公共交通系统中使用大型语言模型为例</title>
      <link>https://arxiv.org/abs/2407.11003</link>
      <description><![CDATA[arXiv:2407.11003v1 公告类型：新
摘要：大型语言模型与公共交通系统的整合代表了城市交通管理和乘客体验的重大进步。本研究考察了 LLM 在圣安东尼奥公共交通系统中的影响，利用了它们在自然语言处理、数据分析和实时通信方面的能力。通过利用 GTFS 和其他公共交通信息，该研究强调了 LLM 在增强路线规划、减少等待时间和提供个性化旅行帮助方面的变革潜力。我们的案例研究是圣安东尼奥市，该项目旨在展示 LLM 如何优化资源配置、提高乘客满意度并支持交通管理中的决策过程。我们评估了 LLM 对与信息检索和理解相关的问题的回答。最终，我们相信在公共交通系统中采用 LLM 可以带来更高效、响应更快、用户友好的交通网络，为其他城市提供效仿的典范。]]></description>
      <guid>https://arxiv.org/abs/2407.11003</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:50 GMT</pubDate>
    </item>
    <item>
      <title>ALCHEmist：自动标记比 LLM 数据注释器便宜 500 倍</title>
      <link>https://arxiv.org/abs/2407.11004</link>
      <description><![CDATA[arXiv:2407.11004v1 公告类型：新
摘要：大型预训练模型可用作注释器，帮助替换或增强众包工作者，并将通用模型提炼为较小的专业模型。不幸的是，这是有代价的：使用顶级模型通常需要为 API 调用支付数千美元，而生成的数据集是静态的且难以审核。为了应对这些挑战，我们提出了一个简单的替代方案：我们不是直接从预训练模型中查询标签，而是让模型生成可以生成标签的程序。这些程序可以本地存储和应用、重复使用和扩展，并且成本要低几个数量级。我们的系统 Alchemist 在一系列任务中获得与基于大型语言模型的注释相当或更好的性能，而成本仅为其一小部分：平均而言，改进量提高了 12.9%，而所有数据集的总标记成本降低了约 500 倍。]]></description>
      <guid>https://arxiv.org/abs/2407.11004</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:50 GMT</pubDate>
    </item>
    <item>
      <title>生成式人工智能系统：基于系统的生成式人工智能视角</title>
      <link>https://arxiv.org/abs/2407.11001</link>
      <description><![CDATA[arXiv:2407.11001v1 公告类型：新
摘要：大型语言模型 (LLM) 通过使用自然语言实现与机器的通信，彻底改变了 AI 系统。视觉语言模型 (GPT-4V) 和 Gemini 等生成式 AI (GenAI) 的最新发展已显示出将 LLM 用作多模态系统的巨大前景。这条新的研究路线的成果是构建生成式 AI 系统（简称 GenAISys），该系统能够进行多模态处理和内容创建以及决策。GenAISys 使用自然语言作为通信手段，使用模态编码器作为处理各种数据源的 I/O 接口。它们还配备了数据库和外部专用工具，通过信息检索和存储模块与系统通信。本文旨在探索和陈述生成式人工智能系统的新研究方向，包括如何设计 GenAISys（组合性、可靠性、可验证性）、构建和训练它们，以及从基于系统的视角可以学到什么。需要采用跨学科方法来回答有关 GenAI 系统内部工作原理的未决问题。]]></description>
      <guid>https://arxiv.org/abs/2407.11001</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:49 GMT</pubDate>
    </item>
    <item>
      <title>MoESD：混合专家稳定传播以减轻性别偏见</title>
      <link>https://arxiv.org/abs/2407.11002</link>
      <description><![CDATA[arXiv:2407.11002v1 公告类型：新
摘要：众所周知，文本到图像模型会传播社会偏见。例如，当提示生成某些职业的人的图像时，这些模型倾向于系统地生成特定的性别或种族。在本文中，我们表明这种偏见已经存在于模型的文本编码器中，并通过识别潜在空间中的文本编码偏见然后创建偏见识别门来引入混合专家方法。更具体地说，我们提出了 MoESD（专家稳定扩散混合）和 BiAs（偏见适配器）来减轻性别偏见。我们还证明了在缓解过程中，特殊令牌是必不可少的。通过专注于性别偏见的实验，我们证明了我们的方法成功地减轻了性别偏见，同时保持了图像质量。]]></description>
      <guid>https://arxiv.org/abs/2407.11002</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:49 GMT</pubDate>
    </item>
    <item>
      <title>用于长文本摘要的离散扩散语言模型</title>
      <link>https://arxiv.org/abs/2407.10998</link>
      <description><![CDATA[arXiv:2407.10998v1 公告类型：新
摘要：虽然扩散模型擅长条件生成高质量图像，但离散扩散模型的先前工作并未在条件长文本生成上进行评估。在这项工作中，我们解决了先前离散扩散模型在条件长文本生成方面的局限性，特别是在抽象摘要等长序列到序列任务中。尽管与自回归方法相比解码速度很快，但由于主干架构和随机噪声过程之间的不兼容性，先前的扩散模型在抽象摘要任务上失败了。为了克服这些挑战，我们引入了一种新颖的语义感知噪声过程，使 Transformer 主干能够有效地处理长序列。此外，我们提出了 CrossMamba，这是 Mamba 模型对编码器-解码器范式的改编，它与随机吸收噪声过程无缝集成。我们的方法在三个基准摘要数据集上实现了最先进的性能：Gigaword、CNN/DailyMail 和 Arxiv，在 ROUGE 指标上优于现有的离散扩散模型，并且与自回归模型相比具有更快的推理速度。]]></description>
      <guid>https://arxiv.org/abs/2407.10998</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:48 GMT</pubDate>
    </item>
    <item>
      <title>TALEC：通过标准划分和零样本加少量样本，教你的法学硕士在特定领域使用内部标准进行评估</title>
      <link>https://arxiv.org/abs/2407.10999</link>
      <description><![CDATA[arXiv:2407.10999v1 Announce Type: new 
摘要：随着大型语言模型（LLM）的快速发展，LLM的评估变得越来越重要。衡量摘要和文章创作等文本生成任务非常困难。特别是在特定应用领域（例如，面向企业或面向客户服务），内部评估标准不仅要满足一般标准（正确性、有用性和创造性等），还要同时满足客户的特定需求和业务安全要求，这使得评估更加困难。到目前为止，商业场景中对LLM的评估主要依赖于人工，这既昂贵又耗时。在本文中，我们提出了一种基于模型的评估方法：TALEC，它允许用户灵活地设置自己的评估标准，并使用上下文学习（ICL）来教会判断模型这些内部标准。此外，我们尝试结合零样本和少样本，使判断模型关注更多信息。我们还提出了一个快速范式和工程方法来调整和迭代镜头，帮助判断模型更好地理解复杂的标准。然后我们将微调与 ICL 进行比较，发现微调可以被 ICL 取代。TALEC 表现出很强的准确反映人类偏好的能力，与人类判断的相关性超过 80%，甚至在某些任务中超过了人与人之间的相关性。代码发布在 https://github.com/zlkqz/auto_eval]]></description>
      <guid>https://arxiv.org/abs/2407.10999</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:48 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中的自主提示工程</title>
      <link>https://arxiv.org/abs/2407.11000</link>
      <description><![CDATA[arXiv:2407.11000v1 公告类型：新
摘要：提示工程是一项至关重要但具有挑战性的任务，用于优化大型语言模型 (LLM) 在定制任务上的性能。这项开创性的研究引入了自动提示工程工具箱 (APET)，使 GPT-4 能够自主应用提示工程技术。通过利用专家提示、思维链和思维树等复杂策略，APET 使 GPT-4 能够动态优化提示，从而显著改善单词排序 (增加 4.4%) 和几何形状 (增加 6.8%) 等任务。尽管在诸如 Checkmate in One (-14.8%) 等复杂任务中遇到了挑战，但这些发现证明了 APET 在无需使用外部数据的情况下自动化复杂提示优化过程的变革潜力。总体而言，这项研究代表了人工智能发展的重大飞跃，为自主人工智能系统的未来创新提供了一个强大的框架，并凸显了 GPT-4 将提示工程理论付诸实践的能力。它为提高复杂任务执行的性能以及拓宽这些技术在现实场景中的实际应用奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2407.11000</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:48 GMT</pubDate>
    </item>
    <item>
      <title>LionGuard：构建情境化审核分类器以处理本地化不安全内容</title>
      <link>https://arxiv.org/abs/2407.10995</link>
      <description><![CDATA[arXiv:2407.10995v1 公告类型：新
摘要：随着大型语言模型 (LLM) 在各种应用中越来越普遍，对其输出安全性的担忧也变得越来越重要。当今，大多数安全调整或审核工作都主要以西方为中心的安全观点进行，尤其是针对有毒、仇恨或暴力言论。在本文中，我们描述了 LionGuard，这是一种新加坡语境化的审核分类器，可以作为不安全 LLM 输出的护栏。在对 Singlish 数据进行评估时，LionGuard 的表现优于现有的广泛使用的审核 API（未针对新加坡语境进行微调），高出 14%（二进制）和高达 51%（多标签）。我们的工作强调了本地化对审核分类器的好处，并提出了一种适用于低资源语言的实用且可扩展的方法。]]></description>
      <guid>https://arxiv.org/abs/2407.10995</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:47 GMT</pubDate>
    </item>
    <item>
      <title>多模态大型语言模型的可视化素养：一项比较研究</title>
      <link>https://arxiv.org/abs/2407.10996</link>
      <description><![CDATA[arXiv:2407.10996v1 公告类型：新
摘要：最近引入的多模态大型语言模型 (MLLM) 将大型语言模型 (LLM) 的固有功能与推理多模态上下文的新能力相结合。MLLM 的潜在使用场景远远超过纯文本。可视化领域的许多最新研究已经证明了 MLLM 理解和解释可视化结果以及用自然语言向用户解释可视化内容的能力。在机器学习社区中，MLLM 的一般视觉能力已经通过各种视觉理解基准进行了评估和测试。然而，MLLM 基于视觉感知完成特定可视化任务的能力尚未得到适当的探索和评估，特别是从以可视化为中心的角度。
在这项工作中，我们旨在通过利用可视化素养的概念来评估 MLLM，以填补这一空白。我们在两个流行的可视化素养评估数据集 (VLAT 和 mini-VLAT) 上评估了 MLLM 的性能。在可视化素养框架下，我们开发了一个通用设置来比较不同的多模态大型语言模型（例如 GPT4-o、Claude 3 Opus、Gemini 1.5 Pro）以及现有的人类基线。我们的研究证明了 MLLM 在可视化素养方面的竞争性能，它们在某些任务（例如识别相关性、聚类和层次结构）上的表现优于人类。]]></description>
      <guid>https://arxiv.org/abs/2407.10996</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:47 GMT</pubDate>
    </item>
    <item>
      <title>体现和个性表达对法学硕士教育代理人学习的影响</title>
      <link>https://arxiv.org/abs/2407.10993</link>
      <description><![CDATA[arXiv:2407.10993v1 公告类型：新
摘要：这项工作研究了个性表达和体现如何影响教育对话代理中的个性感知和学习。我们通过集成针对教育应用量身定制的基于 LLM 的对话支持来扩展现有的个性驱动对话代理框架。我们描述了基于此系统的用户研究，以评估两种不同的个性风格：高外向性和亲和性以及低外向性和亲和性。对于每种性格风格，我们评估三种模型：（1）通过对话传达个性的对话模型，（2）仅通过对话表达个性的动画人体模型，以及（3）通过对话和身体和面部动画表达个性的动画人体模型。结果表明，所有模型在个性和学习成果方面都得到了积极的评价。具有高个性特征的模型被认为比具有低个性特征的模型更具吸引力。我们根据参与者对模型类型和性格风格的评分以及用户对开放式问题的回答，对感知的性格特征、学习参数和用户体验进行全面的定量和定性分析。]]></description>
      <guid>https://arxiv.org/abs/2407.10993</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:46 GMT</pubDate>
    </item>
    <item>
      <title>Panza：通过数据回放和本地微调实现的个性化文本写作助手</title>
      <link>https://arxiv.org/abs/2407.10994</link>
      <description><![CDATA[arXiv:2407.10994v1 公告类型：新
摘要：强大的开源大型语言模型 (LLM) 的出现开启了令人兴奋的用例，例如适应用户独特数据和需求的自动化个人助理。此类助理的两个关键要求是个性化（即助理应反映用户自己的风格）和隐私（即用户可能更喜欢始终将个人数据本地存储在自己的计算设备上）。我们为这种自动化助理提供了一种新设计，用于电子邮件生成的个人助理的特定用例，我们称之为 Panza。具体而言，Panza 可以在商用硬件上进行本地训练和推理，并根据用户的写作风格进行个性化设置。Panza 的个性化功能基于一种称为数据回放的新技术，该技术使我们能够使用有限的数据微调 LLM 以更好地反映用户的写作风格。我们表明，通过结合高效的微调和推理方法，Panza 可以使用有限的资源在本地完全执行 - 具体来说，它可以在与免费 Google Colab 实例相同的资源中执行。最后，我们的主要方法论贡献是仔细研究评估指标，以及不同的系统组件选择（例如使用检索增强生成或不同的微调方法）如何影响系统的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.10994</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:46 GMT</pubDate>
    </item>
    <item>
      <title>使用领域自适应大型语言模型对地质钻孔描述进行分类</title>
      <link>https://arxiv.org/abs/2407.10991</link>
      <description><![CDATA[arXiv:2407.10991v1 公告类型：新
摘要：地质钻孔描述包含有关地下成分的详细文本信息。然而，它们的非结构化格式对将相关特征提取为结构化格式提出了重大挑战。本文介绍了 GEOBERTje：一种领域适应的大型语言模型，该模型以荷兰语的佛兰德斯（比利时）地质钻孔描述为训练对象。该模型有效地从钻孔描述中提取相关信息并将其表示为数字向量空间。仅展示 GEOBERTje 的一个潜在应用，我们对有限数量的手动标记观测值微调分类器模型。该分类器将钻孔描述分为主要、第二和第三岩性类。我们表明，我们的分类器优于基于规则的方法和 OpenAI 的 GPT-4。这项研究举例说明了领域适应的大型语言模型如何提高从复杂的非结构化地质描述中提取信息的效率和准确性。这为利用海量数据进行地质分析和建模提供了新的机会。]]></description>
      <guid>https://arxiv.org/abs/2407.10991</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:45 GMT</pubDate>
    </item>
    <item>
      <title>AlleNoise——具有真实世界标签噪声的大规模文本分类基准数据集</title>
      <link>https://arxiv.org/abs/2407.10992</link>
      <description><![CDATA[arXiv:2407.10992v1 公告类型：新
摘要：标签噪声仍然是训练稳健分类模型的挑战。大多数减轻标签噪声的方法都是使用主要具有合成噪声的数据集进行基准测试的。虽然对具有真实噪声分布的数据集的需求已部分由 WebVision 和 Clothing1M 等网络抓取基准测试解决，但这些基准测试仅限于计算机视觉领域。随着基于 Transformer 的模型的重要性日益增加，建立用于学习噪声标签的文本分类基准测试至关重要。在本文中，我们介绍了 AlleNoise，这是一个新的精选文本分类基准数据集，具有真实世界中的实例相关标签噪声，包含大约 5,600 个类别的 500,000 多个示例，并辅以有意义的分层类别分类法。噪声分布来自主要电子商务市场的实际用户，因此它真实地反映了人为错误的语义。除了噪声标签外，我们还提供经过人工验证的干净标签，这有助于更深入地了解噪声分布，这与该领域通常使用的从网络上抓取的数据集不同。我们证明了，使用噪声标签进行学习的既定方法的代表性选择不足以处理这种现实世界的噪声。此外，我们还证明了这些算法不会减轻过度记忆。因此，借助 AlleNoise，我们为开发能够处理文本分类任务中现实世界标签噪声的标签噪声方法设定了高标准。代码和数据集可在 https://github.com/allegro/AlleNoise 下载。]]></description>
      <guid>https://arxiv.org/abs/2407.10992</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:45 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型能理解浪漫吸引力的言语指标吗？</title>
      <link>https://arxiv.org/abs/2407.10989</link>
      <description><![CDATA[arXiv:2407.10989v1 公告类型：新
摘要：是什么让人们在第一次约会时“一拍即合”并相互吸引？虽然理解和预测浪漫互动的动态曾经是人类判断的专属，但我们表明，大型语言模型 (LLM) 可以在短暂的了解互动中检测到浪漫吸引力。通过检查 964 次快速约会的数据，我们发现 ChatGPT（和 Claude 3）可以预测快速约会成功的客观和主观指标（r=0.12-0.23）。ChatGPT 对实际匹配（即联系信息的交换）的预测不仅与能够访问相同信息的人类判断者相当，而且比快速约会者自己的预测有所增加。虽然 ChatGPT 预测中的一些差异可以通过常见的内容维度（例如对话的价位）来解释，但仍然存在相当大比例无法解释的差异这一事实表明 ChatGPT 也注意到了对话动态。此外，ChatGPT 的判断与人类观察者的判断有很大的重叠（平均 r=0.29），突显了它们在浪漫吸引力表现方面的相似性，而这种相似性在一定程度上与准确性无关。]]></description>
      <guid>https://arxiv.org/abs/2407.10989</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:44 GMT</pubDate>
    </item>
    <item>
      <title>MedBench：全面、标准化、可靠的中文医学大型语言模型评估基准测试系统</title>
      <link>https://arxiv.org/abs/2407.10990</link>
      <description><![CDATA[arXiv:2407.10990v1 公告类型：新
摘要：在实际部署之前，确保医学大型语言模型 (LLM) 对人类的普遍有效性和良好性至关重要。然而，医学 LLM 的广泛接受和可访问的评估流程，特别是在中国背景下，仍有待建立。在这项工作中，我们引入了“MedBench”，这是一个全面、标准化和可靠的中国医学 LLM 基准测试系统。首先，MedBench 汇集了目前最大的评估数据集（300,901 个问题），涵盖 43 个临床专业，并对医学 LLM 进行多方面评估。其次，MedBench 提供了一个标准化、全自动的基于云的评估基础设施，将问题和基本事实物理分离。第三，MedBench 实施动态评估机制，以防止捷径学习和答案记忆。将 MedBench 应用于流行的通用和医学 LLM，我们观察到公正、可重复的评估结果，与医学专业人士的观点基本一致。本研究为中国医学法学硕士项目的实际应用奠定了重要基础。MedBench 可在 https://medbench.opencompass.org.cn 上公开访问。]]></description>
      <guid>https://arxiv.org/abs/2407.10990</guid>
      <pubDate>Thu, 18 Jul 2024 03:17:44 GMT</pubDate>
    </item>
    </channel>
</rss>