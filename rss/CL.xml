<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 24 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>字幕胜过图像 (CASLIE)：从高质量多模态教学数据中概括电子商务基础模型</title>
      <link>https://arxiv.org/abs/2410.17337</link>
      <description><![CDATA[arXiv:2410.17337v1 公告类型：新
摘要：利用多模态数据通过多模态基础模型 (MFM) 推动电子商务应用的突破，正受到研究界越来越多的关注。然而，存在一些重大挑战阻碍基础模型对多模态电子商务数据的最佳利用：(1) 大规模、高质量多模态基准数据集的稀缺；(2) 缺乏有效的多模态信息集成方法。为了应对这些挑战，在本文中，我们引入了 MMECInstruct，这是有史以来第一个大规模、高质量的电子商务多模态指令数据集。我们还开发了 CASLIE，这是一个简单、轻量但有效的电子商务多模态信息集成框架。利用 MMECInstruct，我们在 CASLIE 中微调了一系列电子商务 MFM，称为 CASLIE 模型。我们的综合评估表明，CASLIE 模型在域内评估中的表现大大优于 5 类高级基线模型。此外，CASLIE 模型对域外设置表现出很强的通用性。MMECInstruct 和 CASLIE 模型可通过 https://ninglab.github.io/CASLIE/ 公开访问。]]></description>
      <guid>https://arxiv.org/abs/2410.17337</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>并非所有实体都是平等的：检查细粒度实体类型的长尾</title>
      <link>https://arxiv.org/abs/2410.17355</link>
      <description><![CDATA[arXiv:2410.17355v1 公告类型：新
摘要：预训练语言模型 (PLM) 经过大量数据训练，有助于捕捉世界知识和语言能力。因此，它们被广泛用于超精细实体类型化任务，它们提供其参数空间中保存的实体知识。鉴于 PLM 从共现模式中学习，它们可能包含更多或更少的实体知识，这取决于它们在预训练数据中出现的频率。在这项工作中，我们探测 PLM 以引出编码实体概率，并证明它们与大规模互联网数据中的频率高度相关。然后，我们证明依赖 PLM 的实体类型化方法在处理分布长尾实体时会遇到困难。我们的研究结果表明，我们需要超越 PLM 来提供对稀有、新或不常见实体表现良好的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.17355</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AMUSD：用于 LLM 加速的异步多设备推测解码</title>
      <link>https://arxiv.org/abs/2410.17375</link>
      <description><![CDATA[arXiv:2410.17375v1 公告类型：新
摘要：大型语言模型通常以自回归方式生成标记，使用每个标记作为下一个标记的输入。推测解码的最新研究试图通过使用更小、更快的草稿模型来更快地生成候选标记，从而加速这一过程。然后，这些候选者由更大的（原始）验证模型并行验证，与以自回归方式单独使用更大的模型相比，总体速度更快。在这项工作中，我们引入了 AMUSD（异步多设备推测解码），该系统通过将草稿和验证阶段解耦为连续的异步方法，进一步加速生成。与传统的推测解码不同，其中只有一个模型（草稿或验证）一次执行标记生成，AMUSD 允许两个模型在单独的设备（例如 GPU）上独立执行预测。我们在多个数据集上评估了我们的方法，结果表明 AMUSD 比推测解码平均提高了 29%，比传统自回归解码提高了 1.96$\times$ 的速度，同时实现了相同的输出质量。我们的系统是开源的，可在 https://github.com/BradMcDanel/AMUSD/ 上找到。]]></description>
      <guid>https://arxiv.org/abs/2410.17375</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>视觉语言模型是否表征空间？如何表征？评估模糊性下的空间参考框架</title>
      <link>https://arxiv.org/abs/2410.17385</link>
      <description><![CDATA[arXiv:2410.17385v1 公告类型：新
摘要：情境交流中的空间表达可能具有歧义性，因为它们的含义因说话者和听众所采用的参考框架 (FoR) 而异。虽然视觉语言模型 (VLM) 的空间语言理解和推理越来越受到关注，但这些模型中的潜在歧义仍未得到充分探索。为了解决这个问题，我们提出了一致的多语言参考框架测试 (COMFORT)，这是一种评估协议，用于系统地评估 VLM 的空间推理能力。我们使用 COMFORT 评估了九种最先进的 VLM。尽管我们的实验表明 VLM 在解决歧义方面与英语惯例有些一致，但它也暴露了 VLM 的重大缺陷：值得注意的是，这些模型 (1) 表现出较差的稳健性和一致性，(2) 缺乏适应多个 FoR 的灵活性，以及​​ (3) 在跨语言测试中未能遵守特定语言或特定文化的惯例，因为英语往往比其他语言占主导地位。随着越来越多的努力将视觉语言模型与人类的认知直觉相结合，我们呼吁更多地关注空间推理的歧义性和跨文化多样性。]]></description>
      <guid>https://arxiv.org/abs/2410.17385</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型预训练的可扩展影响和事实追踪</title>
      <link>https://arxiv.org/abs/2410.17413</link>
      <description><![CDATA[arXiv:2410.17413v1 公告类型：新
摘要：训练数据归因 (TDA) 方法旨在将模型输出归因于特定的训练示例，将这些方法应用于大型语言模型 (LLM) 输出可以显著提高模型透明度和数据管理。然而，到目前为止，将这些方法应用于 LLM 预训练的全规模仍然具有挑战性。在本文中，我们改进了现有的基于梯度的方法，使其能够有效地进行大规模工作，使我们能够从超过 160B 个标记的预训练语料库中检索 8B 参数语言模型的有影响力的示例，而无需进行子采样或预过滤。我们的方法结合了几种技术，包括优化器状态校正、特定于任务的 Hessian 近似和规范化编码，我们发现这些技术对于大规模性能至关重要。在事实追踪任务的定量评估中，我们的方法在识别影响模型预测的示例方面表现最佳，但经典的、与模型无关的检索方法（如 BM25）在查找明确包含相关事实的段落方面仍然表现更好。这些结果表明事实归因和因果影响之间存在不一致。随着模型大小和训练标记的增加，我们发现影响与归因更加紧密地一致。最后，我们研究了我们的方法确定为有影响的不同类型的示例，发现虽然许多示例直接涉及特定事实，但其他示例通过强化关系类型、常见实体和名称的先验来支持相同的输出。]]></description>
      <guid>https://arxiv.org/abs/2410.17413</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>巴西新闻中的人工智能：混合方法分析</title>
      <link>https://arxiv.org/abs/2410.17423</link>
      <description><![CDATA[arXiv:2410.17423v1 公告类型：新 
摘要：当前人工智能 (AI) 兴趣激增，反映在 2009 年以来媒体报道的增加，引发了关于人工智能对隐私、社会正义、工人权利和民主的影响的重大争论。媒体在塑造公众对人工智能技术的看法和接受度方面发挥着至关重要的作用。然而，对人工智能在媒体中出现方式的研究主要集中在英语环境中，在理解人工智能在全球范围内的表现方式方面存在空白。这项研究通过分析 2023 年 7 月 1 日至 2024 年 2 月 29 日期间来自 13 家热门在线新闻媒体的 3,560 篇巴西媒体新闻文章来解决这一空白。该研究使用计算扎根理论 (CGT)，应用潜在狄利克雷分配 (LDA)、BERTopic 和命名实体识别来调查人工智能报道中的主要主题和所代表的实体。研究结果显示，巴西新闻对人工智能的报道主要集中在与工作场所应用和产品发布相关的主题上，而对社会关注的报道空间有限，社会关注的焦点大多集中在深度伪造和选举诚信上。分析还强调了与行业相关的实体的大量存在，表明企业议程在该国新闻中具有强大的影响力。这项研究强调了巴西媒体需要对人工智能的社会影响进行更批判性和更细致入微的讨论。]]></description>
      <guid>https://arxiv.org/abs/2410.17423</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 GRE 分析性写作评估来评估人工智能生成的论文</title>
      <link>https://arxiv.org/abs/2410.17439</link>
      <description><![CDATA[arXiv:2410.17439v2 公告类型：新
摘要：生成式人工智能的最新革命性进步使得大型语言模型 (LLM) 能够生成逼真且连贯的文本。尽管目前有许多关于生成文本质量的评估指标，但仍然缺乏对 LLM 在复杂且苛刻的写作评估中表现的严格评估。本研究考察了十位领先的 LLM 为研究生入学考试 (GRE) 的分析性写作评估而生成的论文。我们使用人工评分者和 GRE 评分流程中使用的 e-rater 自动评分引擎来评估这些论文。值得注意的是，表现最好的 Gemini 和 GPT-4o 的平均分数分别为 4.78 和 4.67，根据 GRE 评分指南，介于“对问题进行深思熟虑、完善的分析并清晰地传达含义”和“对问题进行胜任的分析并以可接受的清晰度传达含义”之间。我们还评估了这些论文的检测准确性，使用由相同和不同 LLM 生成的论文对检测器进行训练。]]></description>
      <guid>https://arxiv.org/abs/2410.17439</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行上下文学习和符号回归推理</title>
      <link>https://arxiv.org/abs/2410.17448</link>
      <description><![CDATA[arXiv:2410.17448v1 公告类型：新 
摘要：大型语言模型 (LLM) 是基于转换器的机器学习模型，在未经明确训练的任务中表现出色。在这里，我们探索了 LLM 执行符号回归的潜力——这是一种从数据集中查找简单准确方程的机器学习方法。我们提示 GPT-4 从数据中提出表达式，然后使用外部 Python 工具对其进行优化和评估。这些结果被反馈给 GPT-4，GPT-4 在优化复杂性和损失的同时提出改进的表达式。使用思路链提示，我们指示 GPT-4 在生成新表达式之前分析每个问题的数据、先前表达式和科学背景（以自然语言表达）。我们评估了从实验数据中重新发现五个众所周知的科学方程的工作流程，并在没有已知方程的额外数据集上进行了评估。 GPT-4 成功地重新发现了所有五个方程式，并且总体而言，在提示使用便笺簿并考虑科学背景时表现更好。我们还展示了策略提示如何提高模型的性能，以及自然语言界面如何简化理论与数据的集成。虽然这种方法并不比目标方程式更复杂的现有 SR 程序表现更好，但 LLM 仍然可以在遵循指令并在自然语言中融入科学背景的同时迭代以获得更好的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.17448</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器蛇会像电子羊一样做梦吗？研究架构诱导偏差对幻觉的影响</title>
      <link>https://arxiv.org/abs/2410.17477</link>
      <description><![CDATA[arXiv:2410.17477v1 公告类型：新
摘要：大型语言模型 (LLM) 在日常生活中的重要性日益提高，这在很大程度上可以归因于它们的生成能力，但其中一些也归因于使用它们的风险和成本。一方面，它们倾向于产生虚假或误导性信息，从而限制了它们的可靠性。另一方面，人们越来越关注与传统的基于自我注意的 LLM 相关的计算限制，这带来了新的替代方案，特别是旨在克服这些限制的循环模型。然而，同时考虑这两个问题仍然很少见。架构的变化是否会加剧/减轻对幻觉的现有担忧？它们会影响幻觉发生的方式和地点吗？通过广泛的评估，我们研究了这些基于架构的归纳偏差如何影响产生幻觉的倾向。虽然幻觉仍然是一种普遍现象，并不局限于特定的架构，但它们发生的情况以及特定类型幻觉的诱发难易程度可能会因模型架构的不同而有很大差异。这些发现强调了更好地理解这两个问题并相互结合的必要性，并考虑如何设计更通用的幻觉处理技术。]]></description>
      <guid>https://arxiv.org/abs/2410.17477</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能还是智能吗？法学硕士可以推广到新的形容词-名词对，但无法模拟人类的完整分布</title>
      <link>https://arxiv.org/abs/2410.17482</link>
      <description><![CDATA[arXiv:2410.17482v1 公告类型：新
摘要：从形容词-名词组合（如“人工智能仍然是智能吗？”）得出的推论为 LLM 对含义的理解和组合泛化能力提供了良好的测试平台，因为有许多组合对人类和 LLM 来说都是新颖的，但仍然会引发人类的趋同判断。我们研究了一系列 LLM，发现我们测试的最大模型能够在推理由上下文决定时得出类似人类的推论，并且可以推广到未见过的形容词-名词组合。我们还提出了三种方法来评估 LLM 在这些上下文之外的推论，其中存在类似人类的答案分布，而不是单个正确答案。我们发现 LLM 在我们数据集的最多 75% 上显示出类似人类的分布，这是有希望的，但仍有改进的空间。]]></description>
      <guid>https://arxiv.org/abs/2410.17482</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VoiceTextBlender：通过单阶段联合语音文本监督微调增强大型语言模型的语音功能</title>
      <link>https://arxiv.org/abs/2410.17485</link>
      <description><![CDATA[arXiv:2410.17485v1 公告类型：新
摘要：最近的研究已经为大型语言模型 (LLM) 增加了语音功能，从而导致了语音语言模型 (SpeechLM) 的发展。早期的 SpeechLM 专注于单轮语音问答 (QA)，其中用户输入包括语音上下文和文本问题。最近的研究将其扩展到多轮对话，尽管它们通常需要使用各种数据进行复杂的多阶段监督微调 (SFT)。SpeechLM 的另一个关键挑战是灾难性遗忘 - 针对语音任务优化的模型在纯文本性能方面会显著下降。为了缓解这些问题，我们提出了一种新颖的单阶段联合语音文本 SFT 方法，该方法基于 LLM 主干的低秩自适应 (LoRA)。我们的联合 SFT 将纯文本 SFT 数据与三种类型的语音相关数据相结合：语音识别和翻译、基于语音的 QA 和混合模式 SFT。与之前具有 7B 或 13B 参数的 SpeechLM 相比，我们的 3B 模型在各种语音基准测试中均表现出色，同时保留了纯文本任务的原始能力。此外，我们的模型还展示了有效处理以前从未见过的提示和任务（包括多轮混合模式输入）的新兴能力。]]></description>
      <guid>https://arxiv.org/abs/2410.17485</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型在长文本中仍然表现出偏见</title>
      <link>https://arxiv.org/abs/2410.17519</link>
      <description><![CDATA[arXiv:2410.17519v1 公告类型：新 
摘要：现有的大型语言模型 (LLM) 公平性基准主要关注简单任务，例如多项选择题，忽略了在长文本生成等更复杂场景中可能出现的偏见。为了解决这一差距，我们引入了长文本公平性测试 (LTF-TEST)，这是一个通过论文式提示评估 LLM 中偏见的框架。LTF-TEST 涵盖 14 个主题和 10 个人口统计轴，包括性别和种族，共计 11,948 个样本。通过评估模型响应及其背后的原因，LTF-TEST 发现了在简单响应中难以发现的细微偏见。在我们对包括 GPT-4o 和 LLaMa3 在内的五个最近的 LLM 的评估中，我们发现了两种关键的偏见模式。首先，这些模型在响应中经常偏向某些人口群体。其次，它们对传统上处于不利地位的群体表现出过度的敏感性，往往提供过度保护的反应而忽视其他群体。为了减轻这些偏见，我们提出了 FT-REGARD，这是一种将有偏见的提示与中性回答配对的微调方法。FT-REGARD 将性别偏见减少了 34.6%，并在 BBQ 基准上将性能提高了 1.4 个百分点，为解决长文本生成任务中的偏见提供了一种有前途的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.17519</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过几何约束法学硕士 (LLM) 探索复杂的物理世界</title>
      <link>https://arxiv.org/abs/2410.17529</link>
      <description><![CDATA[arXiv:2410.17529v1 公告类型：新
摘要：本研究探讨了大型语言模型（LLM）仅基于文本知识重建和构建物理世界的潜力。它探讨了模型性能对空间理解能力的影响。为了增强对复杂物理世界中几何和空间关系的理解，本研究引入了一组几何约定，并开发了基于多层图和多智能体系统框架的工作流程。它研究了LLM如何在统一的几何约定下使用多层图在空间环境中实现多步骤和多目标几何推理。此外，该研究采用了一种受大规模模型知识启发的遗传算法来解决几何约束问题。总之，这项工作创新性地探索了使用基于文本的LLM作为物理世界构建器的可行性，并设计了一个工作流程来增强其能力。]]></description>
      <guid>https://arxiv.org/abs/2410.17529</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>负责任的多语言大型语言模型：开发、应用和社会影响的调查</title>
      <link>https://arxiv.org/abs/2410.17532</link>
      <description><![CDATA[arXiv:2410.17532v1 公告类型：新
摘要：多语言大型语言模型 (MLLM) 代表了跨语言界限实现人工智能民主化的关键进步。虽然理论基础已经很完善，但实际实施指南仍然很分散。这项工作通过提供一个全面的端到端框架来弥合这一差距，用于在生产环境中开发和部署 MLLM。我们做出了三项独特的贡献：首先，我们展示了从数据预处理到部署的可操作流程，整合了学术研究和工业应用的见解。其次，以 Llama2 为例，我们提供了增强多语言能力的详细优化策略，包括平衡高资源和低资源语言的课程学习方法、标记化策略和有效的采样方法。第三，我们提供跨学科分析，考虑 MLLM 开发中的技术、语言和文化视角。我们的研究结果揭示了支持语言多样性面临的重大挑战，世界上 88.38% 的语言被归类为资源匮乏的语言，影响了超过十亿使用者。我们通过客户服务、搜索引擎和机器翻译中的实际应用来研究实用的解决方案。通过将理论框架与可用于生产的实施策略相结合，本调查为致力于开发更具包容性和有效性的多语言 AI ​​系统的从业者和研究人员提供了必要的指导。]]></description>
      <guid>https://arxiv.org/abs/2410.17532</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过原型学习提高文本分类的可解释性</title>
      <link>https://arxiv.org/abs/2410.17546</link>
      <description><![CDATA[arXiv:2410.17546v2 公告类型：新
摘要：深度神经网络在各种基于文本的任务中取得了显著的表现，但往往缺乏可解释性，这使得它们不太适合透明度至关重要的应用。为了解决这个问题，我们提出了 ProtoLens，这是一种基于原型的新型模型，可为文本分类提供细粒度的子句级可解释性。ProtoLens 使用原型感知跨度提取模块来识别与学习原型相关的相关文本跨度，并使用原型对齐机制来确保原型在整个训练过程中具有语义意义。通过将原型嵌入与人类可理解的示例对齐，ProtoLens 提供了可解释的预测，同时保持了具有竞争力的准确性。大量实验表明，ProtoLens 在多个文本分类基准上的表现均优于基于原型和不可解释的基线。代码和数据可在 \url{https://anonymous.4open.science/r/ProtoLens-CE0B/} 获得。]]></description>
      <guid>https://arxiv.org/abs/2410.17546</guid>
      <pubDate>Thu, 24 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>