<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 10 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>利用预先训练的视听文本转语音模型生成提示语音</title>
      <link>https://arxiv.org/abs/2501.04799</link>
      <description><![CDATA[arXiv:2501.04799v1 公告类型：新
摘要：本文介绍了一种自动生成提示语音 (ACSG) 的新方法，这是一种视觉通信系统，供听力障碍人士使用，以更好地引出口语。我们利用预先训练的视听自回归文本到语音模型 (AVTacotron2) 探索迁移学习策略。该模型被重新编程以从文本输入中推断提示语音 (CS) 手部和嘴唇动作。实验在两个公开可用的数据集上进行，其中一个专门为本研究记录。使用自动 CS 识别系统评估性能。语音级别的解码准确率达到约 77%，结果证明了我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.04799</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>统一极端：开发检测和预测极端主义特征和激进主义的统一模型</title>
      <link>https://arxiv.org/abs/2501.04820</link>
      <description><![CDATA[arXiv:2501.04820v1 公告类型：新
摘要：意识形态运动通过社交媒体扩散到极端派系已成为全球关注的问题。虽然激进化已经在特定意识形态的背景下得到了广泛的研究，但我们以更普遍的术语准确描述极端主义的能力仍然不够发达。在本文中，我们提出了一种新方法，用于提取和分析一系列在线社区论坛中的极端主义话语。通过关注极端主义特征的言语行为特征，我们开发了一个在用户和社区层面量化极端主义的框架。我们的研究确定了 11 个不同的因素，我们将其称为“极端主义十一人”，作为极端主义的广义心理社会模型。将我们的方法应用于各种在线社区，我们展示了在 11 种极端主义特征中描述意识形态多样化社区的能力。我们通过分析来自 incel 社区成员的用户历史记录来证明这种方法的强大功能。我们发现，我们的框架可以准确预测哪些用户在实际加入 incel 社区前 10 个月内加入，AUC 为 $&gt;0.6$，并在事件发生前三到四个月稳步增加到 AUC ~0.9。此外，我们发现，进入极端主义论坛后，用户倾向于在社区内保持极端主义水平，同时仍与一般在线讨论区分开来。我们的研究结果通过引入一种超越传统特征特定模型的更全面、跨意识形态的方法，为极端主义研究做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2501.04820</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>构建历史土耳其语自然语言处理基础：资源和模型</title>
      <link>https://arxiv.org/abs/2501.04828</link>
      <description><![CDATA[arXiv:2501.04828v1 公告类型：新
摘要：本文介绍了历史土耳其语的自然语言处理 (NLP) 的基础资源和模型，该领域在计算语言学中仍未得到充分探索。我们介绍了第一个命名实体识别 (NER) 数据集 HisTR 和第一个通用依赖关系树库 OTA-BOUN，用于土耳其语的历史形式，以及使用这些数据集训练的基于变压器的模型，用于命名实体识别、依赖关系解析和词性标记任务。此外，我们还介绍了奥斯曼文本语料库 (OTC)，这是一个干净的音译历史土耳其语文本语料库，涵盖了广泛的历史时期。我们的实验结果显示，历史土耳其语的计算分析有了显着的改进，在需要理解历史语言结构的任务中取得了有希望的结果。它们还强调了现有的挑战，例如领域适应和跨时期的语言变化。所有展示的资源和模型均可在 https://huggingface.co/bucolin 上获取，以作为历史土耳其 NLP 未来进步的基准。]]></description>
      <guid>https://arxiv.org/abs/2501.04828</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推进波斯语检索增强生成：语言模型的开发、综合基准和优化最佳实践</title>
      <link>https://arxiv.org/abs/2501.04858</link>
      <description><![CDATA[arXiv:2501.04858v1 公告类型：新
摘要：本文研究了在低资源语言中构建检索增强生成 (RAG) 系统的具体障碍，重点关注波斯语的复杂形态和多变语法。该研究旨在通过引入波斯语特定模型，即 MatinaRoberta（一种掩码语言模型）和 MatinaSRoberta（一种微调的 Sentence-BERT），以及一个全面的基准测试框架来提高检索和生成的准确性。在对这些模型进行 731.1 亿个波斯语标记的多样化语料库训练后，使用三个数据集（一般知识 (PQuad)、科学专业文本和组织报告）来评估这些模型。该方法涉及广泛的预训练、使用定制损失函数进行微调，以及使用传统指标和检索增强生成评估框架进行系统评估。结果表明，MatinaSRoberta 的表现优于之前的嵌入，在数据集中实现了卓越的上下文相关性和检索准确性。探索了温度调整、块大小修改和文档摘要索引以增强 RAG 设置。较大的模型（如 Llama-3.1 (70B)）始终表现出最高的生成准确性，而较小的模型则面临着领域特定和形式上下文的挑战。这些发现强调了通过定制的嵌入和检索生成设置在波斯语中开发 RAG 系统的潜力，并强调了搜索引擎和低资源语言中的法律文件分析等 NLP 应用程序的增强。]]></description>
      <guid>https://arxiv.org/abs/2501.04858</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实时无文本对话生成</title>
      <link>https://arxiv.org/abs/2501.04877</link>
      <description><![CDATA[arXiv:2501.04877v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展已导致基于文本的对话系统取得重大进展。这些系统现在可以生成高质量响应，这些响应在广泛的主题和任务中都是准确且连贯的。然而，口语对话系统在自然性方面仍然落后。它们往往会产生机械化的交互，存在响应时间慢、回复过于笼统或谨慎以及缺乏自然节奏和流畅的轮换等问题。这一缺点主要是由于过度依赖传统的级联设计，该设计涉及单独的顺序组件，以及使用文本作为中间表示。本文提出了一种实时、无文本的口语对话生成模型 (RTTL-DG)，旨在克服这些挑战。我们的系统通过直接处理流式口语对话，实现流畅的轮换并以最小的延迟生成响应。此外，我们的模型还结合了反向通道、过滤器、笑声和其他副语言信号，这些信号在级联对话系统中通常不存在，以创建更自然、更像人类的互动。我们的存储库中提供了实现和生成的示例：https://github.com/mailong25/rts2s-dg]]></description>
      <guid>https://arxiv.org/abs/2501.04877</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用语言模型中的对数概率预测未来事件</title>
      <link>https://arxiv.org/abs/2501.04880</link>
      <description><![CDATA[arXiv:2501.04880v1 公告类型：新
摘要：在不断变化的数据驱动决策领域，准确预测未来事件对于各个领域的战略规划至关重要。大型语言模型 (LLM) 的出现标志着该领域的重大进步，提供了利用大量文本数据进行预测的高级工具。在这篇行业论文中，我们介绍了一种使用 LLM 进行 AI 驱动预测的新方法。在先前研究的基础上，我们使用有关当前趋势及其轨迹的数据来生成 15 个不同主题的预测。随后，我们通过基于对数概率的多步骤方法估计它们的概率。我们表明我们获得了 0.186 的 Brier 分数，这意味着比随机机会提高了 +26%，比广泛使用的 AI 系统提高了 +19%。]]></description>
      <guid>https://arxiv.org/abs/2501.04880</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SUGAR：利用上下文信心实现更智能的检索</title>
      <link>https://arxiv.org/abs/2501.04899</link>
      <description><![CDATA[arXiv:2501.04899v1 公告类型：新
摘要：考虑到大型语言模型 (LLM) 的参数知识有限，检索增强生成 (RAG) 为其提供相关的外部知识，在一定程度上缓解了幻觉问题。然而，统一检索支持上下文会使响应生成源效率低下，因为当模型被嘈杂的检索内容分散注意力并产生无用的答案时，触发检索器并不总是必要的，甚至是不准确的。受这些问题的启发，我们引入了语义不确定性引导的自适应检索 (SUGAR)，我们利用基于上下文的熵来主动决定是否检索，并进一步确定单步和多步检索。我们的实证结果表明，以语义不确定性估计为指导的选择性检索可以提高各种问答任务的性能，并实现更有效的推理。]]></description>
      <guid>https://arxiv.org/abs/2501.04899</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>JELLY：使用 LLM 进行情感识别和语境推理，实现对话语音合成</title>
      <link>https://arxiv.org/abs/2501.04904</link>
      <description><![CDATA[arXiv:2501.04904v1 公告类型：新 
摘要：最近，对对话语音合成 (CSS) 的需求日益增长，它通过考虑对话上下文来生成更自然的语音。为了解决这个问题，我们引入了 JELLY，这是一个新颖的 CSS 框架，它集成了情感识别和上下文推理，通过对具有多个部分 LoRA 模块的大型语言模型 (LLM) 进行微调来生成对话中的适当语音。我们提出了一种情感感知 Q-former 编码器，使 LLM 能够感知语音中的情感。编码器经过训练，利用情感语音数据集将语音情感与文本对齐。然后使用对话语音数据对整个模型进行微调，以推断情感背景，从而在对话中生成情感适当的语音。我们的实验结果表明，JELLY 在情感背景建模方面表现出色，可以合成与对话自然一致的语音，同时缓解情感对话语音数据集的稀缺性。]]></description>
      <guid>https://arxiv.org/abs/2501.04904</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型研究数字翻译</title>
      <link>https://arxiv.org/abs/2501.04927</link>
      <description><![CDATA[arXiv:2501.04927v1 公告类型：新
摘要：数字翻译不准确会导致严重的安全问题，从财务损失到医疗不准确。虽然大型语言模型（LLM）在机器翻译方面取得了重大进展，但它们的数字翻译能力尚未得到彻底探索。本研究重点评估基于LLM的机器翻译系统在处理数字数据时的可靠性。为了系统地测试当前开源LLM的数字翻译能力，我们基于真实业务数据构建了一个中英文数字翻译数据集，涵盖了十种类型的数字翻译。在数据集上的实验表明，数字翻译中的错误是一个常见问题，大多数开源LLM在我们的测试场景中都表现不佳。特别是当涉及到“百万”、“十亿”和“一”等大单位的数字类型时，即使是最新的llama3.1 8b模型的错误率也高达20％。最后，我们介绍了三种潜在策略来减轻大单位的数字误译。]]></description>
      <guid>https://arxiv.org/abs/2501.04927</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>循序渐进：提升大型语言模型的软约束遵循能力</title>
      <link>https://arxiv.org/abs/2501.04945</link>
      <description><![CDATA[arXiv:2501.04945v1 公告类型：新
摘要：对于大型语言模型 (LLM) 来说，遵循涉及多个约束的指令至关重要。然而，软约束在语义上是相关的，很难通过自动化方法进行验证。这些约束仍然是 LLM 面临的重大挑战。为了增强 LLM 遵循软约束的能力，我们最初设计了一个管道来自动获得高质量的输出。此外，为了充分利用获取的数据，我们引入了一种基于课程学习的训练范式。我们通过实验评估了我们的方法在提高 LLM 的软约束遵循能力方面的有效性，并分析了推动改进的因素。数据集和代码可在 https://github.com/Rainier-rq/FollowSoftConstraints 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2501.04945</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>揭秘金融法学硕士领域自适应后训练</title>
      <link>https://arxiv.org/abs/2501.04961</link>
      <description><![CDATA[arXiv:2501.04961v1 公告类型：新
摘要：大型语言模型 (LLM) 的领域自适应后训练已成为医学和金融等专业领域的一种有前途的方法。然而，在确定不同数据和模型配置的最佳适应标准和训练策略方面仍然存在重大挑战。为了应对这些挑战，我们引入了 FINDAP，这是一项针对金融领域 LLM 领域自适应后训练的系统和细粒度调查。我们的方法首先确定目标领域所需的核心能力，并设计一个符合这些需求的综合评估套件。然后，我们分析关键的后训练阶段的有效性，包括持续的预训练、指令调整和偏好调整。基于这些见解，我们提出了一种有效的训练方法，该方法以新颖的偏好数据提炼方法为中心，利用生成奖励模型的过程信号。由此产生的模型 Llama-Fin 在广泛的金融任务中实现了最先进的性能。我们的分析还强调了每个培训后阶段如何促进不同的能力，揭示特定的挑战和有效的解决方案，为 LLM 的领域适应提供宝贵的见解。项目页面：https://github.com/SalesforceAIResearch/FinDap]]></description>
      <guid>https://arxiv.org/abs/2501.04961</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VoxEval：对端到端口语语言模型的知识理解能力进行基准测试</title>
      <link>https://arxiv.org/abs/2501.04962</link>
      <description><![CDATA[arXiv:2501.04962v1 公告类型：新
摘要：随着对开发基于语音的交互模型的需求不断增长，端到端口语语言模型 (SLM) 已成为一种有前途的解决方案。在与人类交谈时，这些模型必须理解广泛的世界知识。在本文中，我们介绍了 VoxEval，这是一种新颖的语音问答基准，专门用于通过纯语音交互来评估 SLM 的知识理解。与现有的 AudioQA 基准不同，VoxEval 保持问题和答案的语音格式，评估模型在不同音频条件下的稳健性（不同的音色、音频质量和说话风格），并开创了对具有挑战性的领域的评估，例如口语形式的数学问题解决。我们使用 VoxEval 对最近的 SLM 进行了全面评估，揭示了当前模型在性能上的重大限制，突出了未来改进的关键领域。]]></description>
      <guid>https://arxiv.org/abs/2501.04962</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SensorQA：日常生活监测问答基准</title>
      <link>https://arxiv.org/abs/2501.04974</link>
      <description><![CDATA[arXiv:2501.04974v1 公告类型：新
摘要：随着传感器数据的快速增长，以人类可理解的方式有效地解释和处理这些数据变得至关重要。虽然现有研究主要侧重于学习分类模型，但很少有研究探讨最终用户如何主动从传感器数据中提取有用的见解，而这往往因缺乏适当的数据集而受阻。为了解决这一差距，我们引入了 \Dataset，这是第一个由人类创建的用于日常生活监测的长期时间序列传感器数据的问答 (QA) 数据集。 \Dataset 由人类工作者创建，包括 5.6K 个反映真正人类兴趣的多样化和实用查询，以及从传感器数据中得出的准确答案。我们进一步在此数据集上为最先进的 AI 模型建立了基准，并评估了它们在典型边缘设备上的性能。我们的结果揭示了当前模型与最佳 QA 性能和效率之间的差距，凸显了对新贡献的需求。数据集和代码可从以下网址获取：\url{https://github.com/benjamin-reichman/SensorQA}。]]></description>
      <guid>https://arxiv.org/abs/2501.04974</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TreeKV：使用树结构实现平滑的键值缓存压缩</title>
      <link>https://arxiv.org/abs/2501.04987</link>
      <description><![CDATA[arXiv:2501.04987v1 公告类型：新
摘要：高效的键值 (KV) 缓存压缩对于在长序列和资源有限的环境中扩展基于 Transformer 的大型语言模型 (LLM) 至关重要。现有方法根据标记的位置或重要性分数逐出标记，但基于位置的策略可能会错过预定义区域之外的关键信息，而那些依赖于全局重要性分数的策略会导致强烈的区域偏差，限制 KV 缓存的整体上下文保留并可能损害 LLM 在复杂任务上的性能。我们的小波分析表明，随着标记接近序列的末尾，它们对生成的贡献逐渐增加并且倾向于与相邻标记产生更大的分歧，这表明从远处到近处的上下文的过渡平稳，复杂性和多变性不断增加。受此观察的启发，我们提出了 TreeKV，这是一种直观的、无需训练的方法，它采用树结构实现平滑的缓存压缩。TreeKV 保持固定的缓存大小，即使在长文本场景中也能让 LLM 提供高质量的输出。与大多数压缩方法不同，TreeKV 适用于生成和预填充阶段。它在 PG19 和 OpenWebText2 上的语言建模任务中始终超越所有基线模型，允许使用短上下文窗口训练的 LLM 推广到较长的窗口，同时将缓存减少 16 倍。在 Longbench 基准测试中，TreeKV 以最佳效率仅使用 6% 的预算实现了最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2501.04987</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强大型语言模型中的类人反应</title>
      <link>https://arxiv.org/abs/2501.05032</link>
      <description><![CDATA[arXiv:2501.05032v1 公告类型：新
摘要：本文探讨了使大型语言模型 (LLM) 更像人类的进步。我们专注于增强人工智能系统中的自然语言理解、对话连贯性和情商的技术。该研究评估了各种方法，包括使用不同的数据集进行微调、结合心理学原理以及设计更好地模仿人类推理模式的模型。我们的研究结果表明，这些增强功能不仅可以改善用户交互，还可以为不同领域的人工智能应用开辟新的可能性。未来的工作将解决这些类似人类的属性所带来的道德影响和潜在偏见。]]></description>
      <guid>https://arxiv.org/abs/2501.05032</guid>
      <pubDate>Fri, 10 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>