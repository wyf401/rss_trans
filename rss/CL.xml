<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 01 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>复仇之战？循环模型在预测人类语言理解指标方面与 Transformers 相匹配</title>
      <link>https://arxiv.org/abs/2404.19178</link>
      <description><![CDATA[arXiv:2404.19178v1 公告类型：新
摘要：Transformers 已经取代循环神经网络，成为自然语言处理任务的主导架构，尽管有人批评认知不可信，但它也用于建模可预测性对在线人类语言理解的影响。然而，最近开发的两种循环神经网络架构 RWKV 和 Mamba 在执行自然语言任务方面似乎与同等规模的 Transformer 相当或更好。在本文中，我们表明，当代的循环模型现在也能够在在线人类语言理解建模方面与同等大小的变压器相匹配，甚至在某些情况下超过性能。这表明 Transformer 语言模型并不是唯一适合这项任务，并且为关于语言模型的架构特征在多大程度上使其成为更好或更差的人类语言理解模型的争论开辟了新的方向。]]></description>
      <guid>https://arxiv.org/abs/2404.19178</guid>
      <pubDate>Wed, 01 May 2024 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>是什么推动了多语言语言模型的性能？</title>
      <link>https://arxiv.org/abs/2404.19159</link>
      <description><![CDATA[arXiv:2404.19159v1 公告类型：新
摘要：本研究调查了影响不同语言的多语言大语言模型（MLLM）性能的因素。我们在 SIB-200 数据集（包含 204 种语言的主题分类数据集）上研究了 6 个 MLLM，包括屏蔽语言模型、自回归模型和指令调整的 LLM。我们的分析考虑了三种场景：所有语言、SEEN 语言（存在于模型的预训练数据中）和 UNSEEN 语言（不以任何有意义的方式存在或记录在模型的预训练数据中）。我们研究了预训练数据大小、一般资源可用性、语言族和脚本类型等因素对模型性能的影响。决策树分析表明，预训练数据大小是对 SEEN 语言影响最大的因素。然而，有趣的是，脚本类型和语言家族对于 UNSEEN 语言至关重要，凸显了跨语言迁移学习的重要性。值得注意的是，模型大小和架构不会显着改变已识别的最重要特征。我们的研究结果为当前 MLLM 的优势和局限性提供了宝贵的见解，并希望指导更有效、更公平的多语言 NLP 系统的开发。]]></description>
      <guid>https://arxiv.org/abs/2404.19159</guid>
      <pubDate>Wed, 01 May 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>Game-MUG：面向多模态的游戏情境理解和评论生成数据集</title>
      <link>https://arxiv.org/abs/2404.19175</link>
      <description><![CDATA[arXiv:2404.19175v1 公告类型：新
摘要：电子竞技的动态特性使得普通观众的情况相对复杂。电竞转播涉及游戏专家解说，但依赖解说的比赛解说不足以全面了解比赛情况。通过包含多样化的多模态电子竞技信息，包括观众的谈话/情绪、比赛音频和比赛赛事信息，它将变得更加丰富。本文介绍了 GAME-MUG，一种新的多模式游戏情境理解和观众参与的评论生成数据集及其强大的基线。我们的数据集收集自 YouTube 和 Twitch 的 2020-2022 年 LOL 游戏直播，包括多模式电子竞技游戏信息，包括文本、音频和时间序列事件日志，用于检测游戏情况。此外，我们还通过涵盖游戏情境和观众对话理解，并引入鲁棒的联合多模态双重学习模型作为基线，提出了一个新的观众对话增强评论数据集。我们检查模型的游戏情境/事件理解能力和评论生成能力，以显示多模态方面覆盖和联合集成学习方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.19175</guid>
      <pubDate>Wed, 01 May 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>健康信息音频传输中增加强调和暂停的效果</title>
      <link>https://arxiv.org/abs/2404.19119</link>
      <description><![CDATA[arXiv:2404.19119v1 公告类型：新
摘要：健康素养对于支持身体健康至关重要，是国家的一项重大目标。音频信息传递对于自我通知变得越来越流行。在这项研究中，我们以不同难度的健康文本的信息强调和暂停的形式评估音频增强的效果，并测量健康信息的理解和保留。我们从困难和简单的文本中制作了音频片段，并在 Amazon Mechanical Turk (AMT) 上进行了研究。我们的研究结果表明，重点对于信息理解和记忆都很重要。当没有额外的停顿时，强调重要信息可以降低对困难和简单文本的感知难度。与不添加强调 (50%) 相比，正确强调困难文本的理解更高 (54%)。添加停顿可以降低感知难度并可以提高记忆力，但会对信息理解产生不利影响。]]></description>
      <guid>https://arxiv.org/abs/2404.19119</guid>
      <pubDate>Wed, 01 May 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>结合代币/嵌入投机者加速生产法学硕士</title>
      <link>https://arxiv.org/abs/2404.19124</link>
      <description><![CDATA[arXiv:2404.19124v1 公告类型：新
摘要：本技术报告描述了新型推测解码草稿模型的设计和训练，以加快生产环境中大型语言模型的推理速度。通过根据上下文向量和采样标记调整草稿预测，我们可以训练我们的投机者有效地预测高质量的 n 元语法，然后基础模型会接受或拒绝。这使我们能够有效地预测每次推理前向传递的多个标记，将高度优化的基本模型实现的挂钟推理速度加快 2-3 倍。我们探索这些初步结果并描述进一步改进的后续步骤。]]></description>
      <guid>https://arxiv.org/abs/2404.19124</guid>
      <pubDate>Wed, 01 May 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>RTF：用于关系三元组提取的基于区域的表格填充方法</title>
      <link>https://arxiv.org/abs/2404.19154</link>
      <description><![CDATA[arXiv:2404.19154v1 公告类型：新
摘要：关系三元组提取是知识图谱自动构建的关键工作。现有方法仅从令牌或令牌对级别构造浅层表示。然而，先前的工作忽略了关系三元组的局部空间依赖性，导致实体对边界检测的弱点。为了解决这个问题，我们提出了一种新的基于区域的表格填充方法（RTF）。我们设计了一种新颖的基于区域的标记方案和双向解码策略，它将每个关系三元组视为特定关系表上的一个区域，并通过确定每个区域的两个端点来识别三元组。我们还引入卷积从空间角度构建区域级表表示，这使得三元组更容易被捕获。此外，我们在不同关系之间共享部分标记分数，以提高关系分类器的学习效率。实验结果表明，我们的方法在两个广泛使用的基准数据集的三个变体上实现了最先进的技术，具有更好的泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2404.19154</guid>
      <pubDate>Wed, 01 May 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>SuperCLUE-Fin：中国法学硕士对各种金融任务和应用的分级细粒度分析</title>
      <link>https://arxiv.org/abs/2404.19063</link>
      <description><![CDATA[arXiv:2404.19063v1 公告类型：新
摘要：SuperCLUE-Fin（SC-Fin）基准测试是专为中国本土金融大语言模型（FLM）量身定制的开创性评估框架。它评估六个金融应用领域和二十五个专业任务的 FLM，涵盖理论知识和实际应用，例如合规性、风险管理和投资分析。 SC-Fin 使用模仿现实生活场景的多回合、开放式对话，根据一系列标准来衡量模型，包括准确的财务理解、逻辑推理、清晰度、计算效率、商业头脑、风险感知以及对中文的遵守情况法规。
  在涉及一千多个问题的严格评估中，SC-Fin 确定了一个性能等级，其中 GLM-4 和 MoonShot-v1-128k 等国产模型的表现优于其他模型，获得 A 级，凸显了在将理论知识转化为实用知识方面进一步发展的潜力金融解决方案。该基准是在中国背景下完善 FLM、指导金融知识数据库的改进、标准化金融解释以及推广优先考虑合规性、风险管理和安全实践的模型的关键工具。
  我们创建了一个切合实际的综合基准，推动人工智能在中国金融领域的发展。 SC-Fin 促进 FLM 的进步和负责任的部署，为中国市场的个人和机构用户提高模型性能和可用性提供宝贵的见解..~\footnote{我们的基准可以在 \url{https:// www.CLUEbenchmarks.com}}。]]></description>
      <guid>https://arxiv.org/abs/2404.19063</guid>
      <pubDate>Wed, 01 May 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>上下文符号回归：利用语言模型进行函数发现</title>
      <link>https://arxiv.org/abs/2404.19094</link>
      <description><![CDATA[arXiv:2404.19094v1 公告类型：新
摘要：符号回归（SR）是一项旨在提取一组经验观察结果背后的数学表达式的任务。在 SR 数据集上训练的基于 Transformer 的方法保留了该任务中当前最先进的技术，而大型语言模型 (LLM) 在 SR 中的应用仍未得到探索。这项工作研究了将预训练的 LLM 集成到 SR 管道中，利用一种方法，根据在观察集上实现的预测误差迭代地细化函数形式，直到达到收敛。我们的方法利用法学硕士根据观察结果提出一组初始可能的函数，利用其强大的预训练先验。然后，这些函数由模型本身和外部优化器对其系数进行迭代细化。重复该过程直到结果令人满意。然后，我们在此背景下分析视觉语言模型，探索将绘图作为视觉输入以帮助优化过程。我们的研究结果表明，法学硕士能够成功恢复适合给定数据的良好符号方程，优于基于遗传编程的 SR 基线，并且在输入中添加图像，显示出最复杂基准的有希望的结果。]]></description>
      <guid>https://arxiv.org/abs/2404.19094</guid>
      <pubDate>Wed, 01 May 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>实时保障大语言文本生成的框架</title>
      <link>https://arxiv.org/abs/2404.19048</link>
      <description><![CDATA[arXiv:2404.19048v1 公告类型：新
摘要：大型语言模型 (LLM) 具有显着先进的自然语言处理 (NLP) 任务，但由于其生成有害内容的倾向，也带来道德和社会风险。为了解决这个问题，人们开发了各种方法来保护法学硕士免于产生不安全的内容。然而，现有方法存在局限性，包括需要训练特定的控制模型和在文本生成过程中主动干预，从而导致质量下降和计算开销增加。为了缓解这些限制，我们提出了 LLMSafeGuard，这是一个轻量级框架，用于实时保护 LLM 文本生成。 LLMSafeGuard 在解码过程中将外部验证器集成到波束搜索算法中，拒绝违反安全约束的候选者，同时允许有效的候选者继续进行。我们引入了基于相似性的验证方法，简化了约束引入并消除了控制模型训练的需要。此外，LLMSafeGuard 采用上下文相关的时序选择策略，仅在必要时干预 LLM。我们在解毒和版权保护这两项任务上评估了 LLMSafe-Guard，并展示了其相对于 SOTA 基线的卓越性能。例如，LLMSafeGuard 降低了平均毒性分数。与最佳基线相比，LLM 输出提高了 29.7%，同时在解毒任务中保持与自然输出相似的语言质量。同样，在版权任务中，LLMSafeGuard 与基线相比，最长公共子序列 (LCS) 减少了 56.2%。此外，我们的上下文明智的时序选择策略将推理时间减少了至少 24%，同时保持了与验证每个时间步骤相当的有效性。 LLMSafeGuard 还提供可调参数来平衡其有效性和效率。]]></description>
      <guid>https://arxiv.org/abs/2404.19048</guid>
      <pubDate>Wed, 01 May 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>思路计划：使用大型语言模型启发式引导问题解决</title>
      <link>https://arxiv.org/abs/2404.19055</link>
      <description><![CDATA[arXiv:2404.19055v1 公告类型：新
摘要：虽然语言模型 (LM) 在广泛领域的零样本推理任务中提供了显著的能力，但它们在需要多步骤推理的问题中表现并不令人满意。以前缓解这种情况的方法包括将较大的多步骤任务分解为子任务，并要求语言模型为每个子任务生成建议（“想法”），并使用详尽的规划方法（如 DFS）来组成解决方案。在这项工作中，我们利用这个想法引入了两个新的贡献：首先，我们形式化了一种基于规划的方法，通过部分可观察马尔可夫决策过程 (POMDP) 使用 LM 执行多步骤问题求解，其中 LM 自身对状态值的思考用作搜索启发式方法；其次，利用在线 POMDP 求解器 POMCP，我们在 24 点游戏任务上实现了比现有方法更高的 89.4% 的成功率，同时还提供了比以前使用的固定树搜索更好的随时性能特征。总而言之，这些贡献使现代 LM 能够更有效地分解和解决更大规模的推理任务。]]></description>
      <guid>https://arxiv.org/abs/2404.19055</guid>
      <pubDate>Wed, 01 May 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>使用自然语言处理进行计算就业市场分析</title>
      <link>https://arxiv.org/abs/2404.18977</link>
      <description><![CDATA[arXiv:2404.18977v1 公告类型：新
摘要：[摘要摘要]
  最近的技术进步凸显了劳动力市场的动态，对就业前景产生重大影响，并增加了跨平台和语言的职位空缺数据。汇总这些数据可以为劳动力市场需求、新技能的出现以及促进各个利益相关者的工作匹配提供有价值的见解。然而，尽管私营部门普遍存在见解，但该领域缺乏透明的语言技术系统和数据。本论文研究了从职位描述中提取相关信息的自然语言处理（NLP）技术，识别了培训数据稀缺、缺乏标准化注释指南以及缺乏有效的职位描述提取方法等挑战。我们构建问题，获取带注释的数据，并引入提取方法。我们的贡献包括职位描述数据集、去识别数据集和用于高效模型训练的新型主动学习算法。我们提出使用弱监督进行技能提取、使多语言语言模型适应就业市场领域的分类感知预训练方法以及利用多个技能提取数据集来提高整体性能的检索增强模型。最后，我们将提取的信息归入指定的分类法中。]]></description>
      <guid>https://arxiv.org/abs/2404.18977</guid>
      <pubDate>Wed, 01 May 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>用于真实语言建模的马尔可夫代理</title>
      <link>https://arxiv.org/abs/2404.18988</link>
      <description><![CDATA[arXiv:2404.18988v1 公告类型：新
摘要：思想链（CoT）推理原则上可以使人们更深入地理解语言模型（LM）的内部推理。然而，之前的工作表明，尽管 CoT 发生了变化，一些 LM 仍会回答类似的问题，这表明这些模型并未真正使用 CoT。我们提出了一种训练方法来生成 CoT，该 CoT 足以独立于其他上下文来预测未来文本。这种方法保证了如果 LM 可以预测未来的代币，那么它一定使用 CoT 来理解其上下文。我们形式化了这样的想法：发送者对接收者 LM 的真实性是发送者帮助接收者预测他们未来观察的程度。然后，我们将“马尔可夫”LM 定义为仅在 CoT 作为上下文的情况下预测未来文本的LM。我们通过将真实性定义应用于马尔可夫 LM 并通过策略梯度和近端策略优化 (PPO) 进行优化，得出“马尔可夫训练”程序。我们证明了我们的训练算法在长上下文算术问题上的有效性，表明该模型利用了 CoT，并验证生成的 CoT 是否有意义且可供其他模型使用。]]></description>
      <guid>https://arxiv.org/abs/2404.18988</guid>
      <pubDate>Wed, 01 May 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>我们是怎么来到这里的？总结对话动态</title>
      <link>https://arxiv.org/abs/2404.19007</link>
      <description><![CDATA[arXiv:2404.19007v1 公告类型：新
摘要：在整个对话过程中，参与者彼此互动的方式不断变化：他们的语气可能会改变，他们可能会采取不同的策略来传达他们的观点，或者他们可能会改变他们的互动模式。对这些动态的理解可以补充所讨论的实际事实和观点，从而提供对对话轨迹的更全面的看法：它是如何达到当前状态的以及它可能走向何方。
  在这项工作中，我们介绍了通过构建人类编写的摘要数据集并探索几个自动基线来总结对话动态的任务。我们评估这样的摘要是否可以通过已建立的下游任务来捕获对话的轨迹：预测正在进行的对话是否最终会脱轨而导致有毒行为。我们证明它们可以帮助人类和自动化系统完成这项预测任务。人类在阅读摘要时做出预测的速度比阅读文字记录时快三倍，而且更有信心。此外，与直接根据文字记录进行预测相比，自动预测系统在构建对话动态摘要并根据其进行预测时更加准确。]]></description>
      <guid>https://arxiv.org/abs/2404.19007</guid>
      <pubDate>Wed, 01 May 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>GuideWalk——用于增强学习的异构数据融合——多类文档分类案例</title>
      <link>https://arxiv.org/abs/2404.18942</link>
      <description><![CDATA[arXiv:2404.18942v1 公告类型：新
摘要：计算机科学和机器学习的主要问题之一是从大规模异构数据中有效地提取信息。文本数据以其语法、语义甚至隐藏的信息内容，在所关注的数据类型中占有特殊的地位。文本数据的处理需要嵌入，这是一种将文本内容转换为数字向量的方法。正确的嵌入算法是获取文本数据完整信息内容的起点。在这项工作中，提出了一种基于有意义句子的图结构的新嵌入方法。算法的设计旨在构建一个嵌入向量，该嵌入向量构成文本数据的句法和语义元素以及隐藏内容。所提出的嵌入方法的成功性在分类问题中进行了测试。在广泛的应用领域中，文本分类是嵌入方法最好的实验室；该方法的分类能力可以使用降维来测试，无需任何进一步的处理。此外，该方法可以与不同的嵌入算法和机器学习方法进行比较。所提出的方法使用真实世界的数据集和八种众所周知且成功的嵌入算法进行了测试。与众所周知的算法相比，所提出的嵌入方法对二进制和多类数据集显示出明显更好的分类。]]></description>
      <guid>https://arxiv.org/abs/2404.18942</guid>
      <pubDate>Wed, 01 May 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>可信、不可靠还是泄露？：增强自动事实核查的证据验证</title>
      <link>https://arxiv.org/abs/2404.18971</link>
      <description><![CDATA[arXiv:2404.18971v1 公告类型：新
摘要：自动事实核查（AFC）越来越受到研究人员的关注，旨在帮助事实核查人员对抗网上日益传播的错误信息。虽然许多现有的 AFC 方法结合了来自网络的外部信息来帮助检查索赔的真实性，但它们常常忽视验证所收集“证据”的来源和质量的重要性。一个被忽视的挑战涉及对“泄露证据”的依赖，即直接从事实核查网站收集并用于训练亚足联系统的信息，导致早期错误信息检测的环境不切实际。同样，包含来自不可靠来源的信息可能会破坏 AFC 系统的有效性。为了应对这些挑战，我们提出了一种全面的证据验证和过滤方法。我们创建了“CREDible、Unreliable 或 LEaked”(CREDULE) 数据集，其中包含 91,632 篇分类为 Credible、Unreliable 和事实已检查（Leaked）的文章。此外，我们还引入了证据验证网络（EVVER-Net），该网络在 CREDULE 上进行训练，以检测短文本和长文本中泄露和不可靠的证据。 EVVER-Net 可用于过滤从网络收集的证据，从而增强端到端 AFC 系统的稳健性。我们对各种语言模型进行了实验，结果表明，EVVER-Net 可以展示高达 91.5% 和 94.4% 准确率的令人印象深刻的性能，同时分别利用域可信度分数以及短文本或长文本。最后，我们评估了广泛使用的事实核查数据集提供的证据，包括 LIAR-PLUS、MOCHEG、FACTIFY、NewsCLIPpings+ 和 VERITE，其中一些数据显示出有关泄露和不可靠证据的比率。]]></description>
      <guid>https://arxiv.org/abs/2404.18971</guid>
      <pubDate>Wed, 01 May 2024 06:18:24 GMT</pubDate>
    </item>
    </channel>
</rss>