<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 03 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>GAMedX：使用大型语言模型的基于生成 AI 的医疗实体数据提取器</title>
      <link>https://arxiv.org/abs/2405.20585</link>
      <description><![CDATA[arXiv:2405.20585v1 公告类型：新
摘要：在快速发展的医疗保健及其他领域，生成式人工智能与电子健康记录 (EHR) 的整合代表着一项关键进步，解决了当前信息提取技术中的一个关键差距。本文介绍了 GAMedX，这是一种命名实体识别 (NER) 方法，利用大型语言模型 (LLM) 有效地从患者就诊各个阶段生成的医学叙述和非结构化文本中提取实体。通过解决处理非结构化医学文本的重大挑战，GAMedX 利用生成式人工智能和 LLM 的功能来改进数据提取。该方法采用统一的方法，集成了用于 NER 的开源 LLM，利用链式提示和 Pydantic 模式进行结构化输出，以应对专业医学术语的复杂性。研究结果显示，其中一个评估数据集的 ROUGE F1 得分显著，准确率为 98%。这项创新增强了实体提取功能，为从非结构化数据自动填写表格提供了一种可扩展且经济高效的解决方案。因此，GAMedX 简化了非结构化叙述的处理，并在 NER 应用中树立了新标准，为医疗技术领域以外的理论和实践进步做出了重大贡献。]]></description>
      <guid>https://arxiv.org/abs/2405.20585</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:13 GMT</pubDate>
    </item>
    <item>
      <title>DAFNet：用于大型语言模型中顺序模型编辑的动态辅助融合</title>
      <link>https://arxiv.org/abs/2405.20588</link>
      <description><![CDATA[arXiv:2405.20588v1 公告类型：新
摘要：最近，虽然大型语言模型 (LLM) 已经展示了令人印象深刻的结果，但它们仍然存在幻觉，即产生虚假信息。模型编辑是修复 LLM 中的事实错误的任务；然而，大多数以前的工作都将其视为一次性任务，很少关注 LLM 产生的不断出现的错误。我们解决了顺序模型编辑 (SME) 的任务，旨在连续纠正错误。动态辅助融合网络 (DAFNet) 旨在增强整个序列中事实知识之间的语义交互，防止在编辑多个知识三元组的过程中发生灾难性遗忘。具体而言，(1) 对于关系三元组中的语义融合，我们将内部编辑注意力流聚合到 LLM 中具有标记级粒度的自回归自注意力中。我们进一步利用多层对角线编辑间注意流来更新整个序列级粒度的加权表示。（2）考虑到需要辅助参数来存储顺序编辑的知识，我们构建了一个名为 \textbf{DAFSet} 的新数据集，该数据集满足近期、流行、长尾和鲁棒性等属性，以增强顺序编辑的通用性。实验表明，DAFNet 在单转和顺序编辑方面的表现明显优于强基线。DAFSet 的使用还在各种场景中持续提高了其他基于辅助网络的方法的性能]]></description>
      <guid>https://arxiv.org/abs/2405.20588</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:13 GMT</pubDate>
    </item>
    <item>
      <title>开放 Ko-LLM 排行榜：使用 Ko-H5 基准测试评估韩语大型语言模型</title>
      <link>https://arxiv.org/abs/2405.20574</link>
      <description><![CDATA[arXiv:2405.20574v1 公告类型：新
摘要：本文介绍了 Open Ko-LLM 排行榜和 Ko-H5 基准，它们是评估韩语大型语言模型 (LLM) 的重要工具。结合私人测试集，同时模仿英语 Open LLM 排行榜，我们建立了一个强大的评估框架，该框架已很好地融入韩国 LLM 社区。我们进行数据泄漏分析，显示私人测试集的好处，以及 Ko-H5 基准内的相关性研究和 Ko-H5 分数的时间分析。此外，我们为扩展设定基准的必要性提供了实证支持。我们希望 Open Ko-LLM 排行榜为扩大 LLM 评估以促进更多语言多样性树立先例。]]></description>
      <guid>https://arxiv.org/abs/2405.20574</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:12 GMT</pubDate>
    </item>
    <item>
      <title>情绪的观点：精神病学笔记中的临床医生偏见检测</title>
      <link>https://arxiv.org/abs/2405.20582</link>
      <description><![CDATA[arXiv:2405.20582v1 公告类型：新 
摘要：在精神病学中，负面的患者描述和污名化语言会通过两种方式造成医疗保健差异：（1）患者阅读时可能会损害他们对医疗中心的信任和参与度；（2）未来的提供者阅读时可能会对患者的未来观点产生负面影响。通过利用大型语言模型，这项工作旨在根据读者的观点识别精神病临床笔记中表达的情绪。从西奈山医疗系统大量且多样化的临床笔记中提取句子，我们使用提示和上下文学习来调整三个大型语言模型（GPT-3.5、Llama 2、Mistral）以根据提供者或非提供者的观点对句子传达的情绪进行分类。结果表明，GPT-3.5 最符合提供者的观点，而 Mistral 最符合非提供者的观点。]]></description>
      <guid>https://arxiv.org/abs/2405.20582</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:12 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型针对翻译进行了多少种语言的微调？</title>
      <link>https://arxiv.org/abs/2405.20512</link>
      <description><![CDATA[arXiv:2405.20512v1 公告类型：新摘要：最近出现了一种新的机器翻译范式：对并行文本进行微调的大型语言模型 (LLM) 已被证明优于在大量并行数据上以监督方式训练的专用翻译系统 (Xu et al., 2024a; Alves et al., 2024)。然而，目前尚不清楚这种范式是否可以实现大规模多语言机器翻译，或者是否需要对少数语言对的专用模型进行微调。翻译微调如何影响 LLM 对于零样本语言、零样本语言对和不涉及英语的翻译任务的 MT 能力？为了解决这些问题，我们对来自多并行 FLORES-200 数据的 132 个翻译任务的 TOWER 系列语言模型 (Alves et al., 2024) 的翻译质量进行了广泛的实证评估。我们发现，即使对于零样本语言，翻译微调也能提高翻译质量，但影响并不均匀，具体取决于所涉及的语言对。这些结果需要进一步研究，以便有效地使用 LLM 实现大规模多语言翻译。]]></description>
      <guid>https://arxiv.org/abs/2405.20512</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>面向大型语言模型的本体增强表示学习</title>
      <link>https://arxiv.org/abs/2405.20527</link>
      <description><![CDATA[arXiv:2405.20527v1 公告类型：新
摘要：利用本体在组织和协调多个不同领域的知识方面的广泛应用，本文提出了一种新方法，通过注入由参考本体形式化的知识来改进感兴趣的嵌入大型语言模型 (embedding-LLM)：本体知识注入旨在提高所考虑的 LLM 有效建模注入本体所描述的知识领域的能力。在强大的生成 LLM（即 GPT-3.5-turbo）的帮助下，利用本体形式化的语言信息（即概念同义词和描述）和结构信息（即 is-a 关系）来编译一套全面的概念定义。然后使用这些概念定义通过对比学习框架对目标嵌入 LLM 进行微调。为了演示和评估所提出的方法，我们利用了生物医学疾病本体 MONDO。结果表明，通过本体疾病知识增强的嵌入 LLM 表现出更好的能力，可以有效评估提及疾病的生物医学文献中的域内句子的相似性，同时不会影响其域外性能。]]></description>
      <guid>https://arxiv.org/abs/2405.20527</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>转学Q星：LLM对齐的原则解码</title>
      <link>https://arxiv.org/abs/2405.20495</link>
      <description><![CDATA[arXiv:2405.20495v1 公告类型：新
摘要：对齐基础模型对于其安全和可靠的部署至关重要。然而，传统的微调方法计算量大，需要更新数十亿个模型参数。一种有前途的替代方法是通过解码进行对齐，它直接调整响应分布而无需模型更新以最大化目标奖励 $r$，从而为对齐提供了一个轻量级且适应性强的框架。然而，原则性解码方法依赖于对最优 Q 函数 ($Q^*$) 的 oracle 访问，这在实践中通常是不可用的。因此，先前的 SoTA 方法要么使用 $Q^{\pi_{\texttt{sft}}}$（源自参考 $\texttt{SFT}$ 模型）来近似这个 $Q^*$，要么依赖短期奖励，导致解码性能不佳。在本研究中，我们提出了 Transfer $Q^*$，它通过与基线奖励 $\rho_{\texttt{BL}}$（可能与目标奖励 $r$ 不同）对齐的基线模型 $\rho_{\texttt{BL}}$ 隐式估计目标奖励 $r$ 的最佳值函数。Transfer $Q^*$ 的理论分析对其最优性进行了严格的表征，推导出次优差距的上限，并根据用户需求确定超参数以控制与预训练参考 $\texttt{SFT}$ 模型的偏差。我们的方法显著减少了先前 SoTA 方法中观察到的次优差距，并在对多个合成和真实数据集的广泛测试中展示了关键指标（如连贯性、多样性和质量）的卓越经验性能。]]></description>
      <guid>https://arxiv.org/abs/2405.20495</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:10 GMT</pubDate>
    </item>
    <item>
      <title>SPOT：通过原创性分数阈值进行文本来源预测</title>
      <link>https://arxiv.org/abs/2405.20505</link>
      <description><![CDATA[arXiv:2405.20505v1 公告类型：新
摘要：大型语言模型 (LLM) 的广泛接受开启了新的应用和社会风险。流行的对策旨在检测错误信息，通常涉及训练以识别任何信息相关性的特定领域模型。我们建议从信任的角度研究 LLM 生成的文本，而不是评估信息的有效性。在本研究中，我们将信任定义为知道输入文本是由 LLM 还是人生成的能力。为此，我们设计了一种有效的方法 SPOT，它根据原创性分数对任何独立文本输入的来源进行分类。该分数来自给定 LLM 检测其他 LLM 的预测。我们通过经验证明了该方法对现代 LLM 的架构、训练数据、评估数据、任务和压缩的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2405.20505</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:10 GMT</pubDate>
    </item>
    <item>
      <title>将海量文本嵌入基准扩展到法语</title>
      <link>https://arxiv.org/abs/2405.20468</link>
      <description><![CDATA[arXiv:2405.20468v1 公告类型：新
摘要：近年来，已经出现了许多嵌入模型，并广泛用于各种 NLP 任务。海量文本嵌入基准 (MTEB) 大大简化了选择一个在英语中表现良好的模型，但扩展到其他语言仍然具有挑战性。这就是为什么我们扩展 MTEB 以提出第一个针对法语的大规模句子嵌入基准的原因。我们不仅在易于使用的界面中收集了 22 个现有数据集，而且还创建了三个新的法语数据集，用于对 8 个不同任务进行全局评估。我们对 46 个精心挑选的嵌入模型进行了大规模比较，进行了全面的统计测试，并分析了模型性能与许多特征之间的相关性。我们发现，即使没有一个模型在所有任务上都是最好的，在句子相似性上预先训练的大型多语言模型表现特别好。我们的工作附带开源代码、新数据集和公共排行榜。]]></description>
      <guid>https://arxiv.org/abs/2405.20468</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:09 GMT</pubDate>
    </item>
    <item>
      <title>自动生成重点反馈以协助科学写作</title>
      <link>https://arxiv.org/abs/2405.20477</link>
      <description><![CDATA[arXiv:2405.20477v1 公告类型：新
摘要：科学写作是一项具有挑战性的任务，尤其是对于经常依赖经验丰富的同行反馈的新手研究人员而言。最近的工作主要集中在改进表面形式和风格而不是手稿内容。在本文中，我们提出了一项新颖的任务：自动生成重点反馈以协助科学写作。我们介绍了 SWIF$^{2}$T：一种科学写作重点反馈工具。它旨在生成具体、可操作且连贯的评论，以识别科学论文中的弱点和/或提出修改意见。我们的方法包括四个部分 - 规划者、调查员、审阅者和控制者 - 利用多个大型语言模型 (LLM) 来实现它们。我们汇编了一个包含 300 篇同行评审的数据集，其中引用了科学论文中的弱点并进行人工评估。结果表明，与其他方法相比，SWIF$^{2}$T 的反馈在特异性、阅读理解和整体帮助方面具有优势。在我们的分析中，我们还发现了自动生成的评论比人工评论更好的案例，这表明在科学写作中整合人工智能生成的反馈的机会。]]></description>
      <guid>https://arxiv.org/abs/2405.20477</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:09 GMT</pubDate>
    </item>
    <item>
      <title>新闻文章中显著实体的可扩展检测</title>
      <link>https://arxiv.org/abs/2405.20461</link>
      <description><![CDATA[arXiv:2405.20461v1 公告类型：新
摘要：新闻文章通常会提到许多实体，其中很大一部分与故事无关。因此，检测文章中实体的显着性对于新闻搜索、分析和摘要等应用非常重要。在这项工作中，我们通过微调预训练的 Transformer 模型来探索有效且有效的显着实体检测的新方法，这些模型具有直接使用实体标签或上下文实体表示的分类头。实验表明，这些简单的技术在具有不同大小和显着性定义的数据集上的表现大大优于以前的工作。我们还研究知识蒸馏技术，以有效降低这些模型的计算成本而不影响其准确性。最后，我们进行了广泛的分析和消融实验来表征所提出模型的行为。]]></description>
      <guid>https://arxiv.org/abs/2405.20461</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:08 GMT</pubDate>
    </item>
    <item>
      <title>XPrompt：通过联合提示归因解释大型语言模型的生成</title>
      <link>https://arxiv.org/abs/2405.20404</link>
      <description><![CDATA[arXiv:2405.20404v1 公告类型：新
摘要：大型语言模型 (LLM) 在复杂的文本生成任务中表现出色。然而，输入提示对生成内容的贡献对人类来说仍然模糊不清，这强调了阐明和解释输入和输出对之间因果关系的必要性。现有的提供提示特定解释的工作通常将模型输出限制为分类或下一个单词预测。最初试图解释整个语言生成的一些尝试通常将输入提示文本独立处理，而忽略了它们对后续生成的组合影响。在本研究中，我们引入了一个基于联合提示归因的反事实解释框架 XPrompt，旨在解释一些提示文本如何协同影响 LLM 的完整生成。具体而言，我们将生成解释的提示归因任务表述为组合优化问题，并引入一种概率算法来搜索离散空间中的因果输入组合。我们定义并使用多个指标来评估所产生的解释，证明了我们框架的真实性和效率。]]></description>
      <guid>https://arxiv.org/abs/2405.20404</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:07 GMT</pubDate>
    </item>
    <item>
      <title>SeamlessExpressiveLM：具有思路链的富有表现力的语音到语音翻译的语音语言模型</title>
      <link>https://arxiv.org/abs/2405.20410</link>
      <description><![CDATA[arXiv:2405.20410v1 公告类型：新
摘要：富有表现力的语音到语音翻译 (S2ST) 是无缝通信中的一个关键研究课题，其重点是翻译语音中语义和说话者声音风格的保留。早期的工作合成说话者风格对齐的语音，以便直接学习从语音到目标语音频谱图的映射。最近的研究不依赖于风格对齐的数据，而是利用语言建模 (LM) 的进步，并在语义和声学标记上构建级联 LM。这项工作提出了 SeamlessExpressiveLM，一种用于富有表现力的 S2ST 的单一语音语言模型。我们将复杂的源到目标语音映射分解为具有思路链提示的中间生成步骤。首先引导该模型翻译目标语义内容，然后将说话者风格转移到多流声学单元。经对西班牙语到英语和匈牙利语到英语的翻译进行评估，SeamlessExpressiveLM 在语义质量和风格转换方面均优于级联 LM，同时实现了更好的参数效率。]]></description>
      <guid>https://arxiv.org/abs/2405.20410</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:07 GMT</pubDate>
    </item>
    <item>
      <title>应用程序交互的小型语言模型：案例研究</title>
      <link>https://arxiv.org/abs/2405.20347</link>
      <description><![CDATA[arXiv:2405.20347v1 公告类型：新
摘要：我们研究小型语言模型 (SLM) 通过自然语言交互促进应用程序使用的有效性。我们重点关注 Microsoft 用于云供应链履行的特定内部应用程序。我们的实验表明，即使在小型数据集上进行微调，小型模型在准确性和运行时间方面也可以胜过大型模型。除了这些结果之外，我们还强调了基于 SLM 的系统设计注意事项。]]></description>
      <guid>https://arxiv.org/abs/2405.20347</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:06 GMT</pubDate>
    </item>
    <item>
      <title>不会产生幻觉？评估领先的人工智能法律研究工具的可靠性</title>
      <link>https://arxiv.org/abs/2405.20362</link>
      <description><![CDATA[arXiv:2405.20362v1 公告类型：新
摘要：法律实践见证了人工智能 (AI) 产品数量的急剧增长。此类工具旨在协助完成广泛的核心法律任务，从搜索和总结案例到文件起草。但这些工具中使用的大型语言模型容易“产生幻觉”，即编造虚假信息，这使得它们在高风险领域的使用存在风险。最近，某些法律研究提供商吹捧诸如检索增强生成 (RAG) 之类的方法可以“消除”(Casetext, 2023) 或“避免”幻觉 (Thomson Reuters, 2023)，或保证“无幻觉”的法律引用 (LexisNexis, 2023)。由于这些系统的封闭性，系统地评估这些说法具有挑战性。在本文中，我们设计并报告了对人工智能驱动的法律研究工具的首次预注册实证评估。我们证明提供商的说法是夸大其词。虽然与通用聊天机器人 (GPT-4) 相比，幻觉有所减少，但我们发现 LexisNexis (Lexis+ AI) 和 Thomson Reuters (Westlaw AI-Assisted Research 和 Ask Practical Law AI) 制作的 AI 研究工具分别有 17% 至 33% 的时间会出现幻觉。我们还记录了系统在响应性和准确性方面的巨大差异。我们的文章做出了四个关键贡献。这是第一篇评估和报告基于 RAG 的专有法律 AI 工具性能的文章。其次，它引入了一个全面的、预先注册的数据集，用于识别和了解这些系统中的漏洞。第三，它提出了一种区分幻觉和准确法律反应的清晰类型学。最后，它提供了证据来告知法律专业人员在监督和验证 AI 输出方面的责任，这仍然是 AI 负责任地融入法律的一个核心悬而未决的问题。]]></description>
      <guid>https://arxiv.org/abs/2405.20362</guid>
      <pubDate>Tue, 04 Jun 2024 03:16:06 GMT</pubDate>
    </item>
    </channel>
</rss>