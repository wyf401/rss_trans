<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 28 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>改进从复杂的医患对话中生成临床记录</title>
      <link>https://arxiv.org/abs/2408.14568</link>
      <description><![CDATA[arXiv:2408.14568v1 公告类型：新
摘要：撰写临床笔记和记录医学检查是医疗保健专业人员的一项关键任务，是患者护理文档的重要组成部分。但是，手动编写这些笔记非常耗时，并且会影响临床医生花在直接患者互动和其他任务上的时间。因此，自动临床记录生成系统的开发已成为医疗人工智能领域具有临床意义的研究领域。在本文中，我们介绍了使用大型语言模型 (LLM) 对临床记录生成领域的三个关键贡献。首先，我们介绍了 CliniKnote，这是一个全面的数据集，包含 1,200 个复杂的医患对话及其完整的临床记录。该数据集由医学专家在现代神经网络的帮助下创建和整理，为临床记录生成任务中的模型训练和评估提供了宝贵的资源。其次，我们提出了 K-SOAP（关键词、主观、客观、评估和计划）笔记格式，通过在顶部添加关键词部分增强了传统的 SOAP~\cite{podder2023soap}（主观、客观、评估和计划）笔记，从而可以快速识别重要信息。第三，我们开发了一个自动流程，从医患对话中生成 K-SOAP 笔记，并使用各种指标对各种现代 LLM 进行基准测试。与标准 LLM 微调方法相比，我们的结果表明效率和性能有显著提高。]]></description>
      <guid>https://arxiv.org/abs/2408.14568</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>令人惊讶的脆弱：评估和解决多模式基础模型中的即时不稳定性</title>
      <link>https://arxiv.org/abs/2408.14595</link>
      <description><![CDATA[arXiv:2408.14595v1 公告类型：新
摘要：OFASys 等多模态基础模型 (MFM) 显示出仅通过文本提示即可解锁对图像、视频和音频数据等复杂数据的分析的潜力。然而，当文本输入与其训练分布略有不同时，它们的性能可能会受到影响，考虑到使用特定于模态的数据来“接地”文本输入，这是令人惊讶的。这项研究表明，提示不稳定性是 MFM 的主要问题，导致所有模态的性能持续下降，但这种不稳定性可以通过使用增强数据进行额外训练来缓解。我们评估了几种接地提示扰动的方法，其中我们生成扰动并根据与文本和/或模态数据的相似性进行过滤。在增强数据上重新训练模型后，我们发现无论扰动条件如何，扰动测试数据的准确性都有所提高，性能也更稳定，这表明数据增强策略有助于模型更有效地处理域转移。在错误分析中，我们发现跨领域的性能改进存在一致的模式，这表明对提示扰动进行重新训练往往有助于提高 MFM 中的一般推理能力。]]></description>
      <guid>https://arxiv.org/abs/2408.14595</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>什么构成了一个好故事？我们如何衡量它？故事评价综合调查</title>
      <link>https://arxiv.org/abs/2408.14622</link>
      <description><![CDATA[arXiv:2408.14622v1 公告类型：新
摘要：随着人工智能的发展，特别是大型语言模型 (LLM) 的成功，自动生成的故事的数量和质量显著提高。这导致需要自动故事评估来评估计算系统的生成能力并分析自动生成和人工编写的故事的质量。评估故事可能比其他生成评估任务更具挑战性。虽然机器翻译等任务主要侧重于评估流畅性和准确性方面，但故事评估需要复杂的额外措施，例如整体连贯性、角色发展、趣味性等。这需要对相关研究进行彻底的审查。在本次调查中，我们首先总结了现有的讲故事任务，包括文本到文本、视觉到文本和文本到视觉。我们强调了它们的评估挑战，确定了衡量故事的各种人类标准，并展示了现有的基准数据集。然后，我们提出了一个分类法来组织已经开发的或可以用于故事评估的评估指标。我们还对这些指标进行了描述，并讨论了它们的优点和局限性。之后，我们讨论了人机协作进行故事评估和生成。最后，我们提出了未来的潜在研究方向，从故事评估扩展到一般评估。]]></description>
      <guid>https://arxiv.org/abs/2408.14622</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中的无训练激活稀疏性</title>
      <link>https://arxiv.org/abs/2408.14690</link>
      <description><![CDATA[arXiv:2408.14690v1 公告类型：新
摘要：激活稀疏性可以通过减少前向传递期间矩阵乘法所需的计算和内存移动来实现大型语言模型 (LLM) 中的实际推理加速。然而，现有方法面临着阻碍广泛采用的限制。一些方法是针对具有基于 ReLU 的稀疏性的旧模型量身定制的，而另一些方法则需要对多达数千亿个标记进行大量持续的预训练。本文介绍了 TEAL，这是一种简单的免训练方法，它将基于幅度的激活稀疏性应用于整个模型的隐藏状态。TEAL 在 Llama-2、Llama-3 和 Mistral 系列中实现了 40-50% 的模型范围稀疏性，性能下降最小，大小从 7B 到 70B 不等。我们改进了现有的稀疏核，并展示了在 40% 和 50% 模型范围稀疏度下高达 1.53$\times$ 和 1.8$\times$ 的时钟解码速度提升。TEAL 与权重量化兼容，从而进一步提高效率。]]></description>
      <guid>https://arxiv.org/abs/2408.14690</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LyCon：使用大型语言模型从词袋中重建歌词</title>
      <link>https://arxiv.org/abs/2408.14750</link>
      <description><![CDATA[arXiv:2408.14750v1 公告类型：新
摘要：本文解决了歌词研究中的独特挑战，其中歌词的直接使用通常由于版权问题而受到限制。与典型数据不同，互联网来源的歌词经常受到版权法的保护，因此需要采用替代方法。我们的研究介绍了一种从公开的词袋 (BoW) 数据集生成无版权歌词的新方法，该数据集包含歌词的词汇表但不包含歌词本身。利用与 BoW 数据集和大型语言模型相关的元数据，我们成功重建了歌词。我们已经编制并提供了一个重建歌词数据集 LyCon，该数据集与来自知名来源的元数据保持一致，包括百万歌曲数据集、Deezer 情绪检测数据集和 AllMusic 流派数据集，可供公众访问。我们相信，情绪注释或流派等元数据的整合使得对歌词进行各种学术实验成为可能，例如有条件的歌词生成。]]></description>
      <guid>https://arxiv.org/abs/2408.14750</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>全球人工智能社区需要多种语言的出版</title>
      <link>https://arxiv.org/abs/2408.14772</link>
      <description><![CDATA[arXiv:2408.14772v1 公告类型：新
摘要：在这次挑衅中，我们讨论了英语在人工智能研究界的主导地位，认为英语出版的要求维护并加强了人工智能中更广泛的提取制度。虽然大型语言模型和机器翻译被认为是打破障碍的一种方式，但我们认为它们的使用是语言排斥科学家和潜在读者的一种表现。我们提出了更健康的出版文化的替代未来，围绕三个主题：以会议举办国的语言管理会议，指示同行评审员不要评判论文的语言适宜性，并提供以多种语言出版和展示的机会。我们欢迎这篇文章的新翻译。如果您想贡献一个，请联系作者。]]></description>
      <guid>https://arxiv.org/abs/2408.14772</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GSIFN：一种基于图结构和交错掩蔽多模态变换器的融合网络，用于多模态情绪分析</title>
      <link>https://arxiv.org/abs/2408.14809</link>
      <description><![CDATA[arXiv:2408.14809v1 公告类型：新 
摘要：多模态情绪分析（MSA）利用多种模态来分析情绪。通常，高级融合方法和基于表示学习的方法旨在解决该问题。我们提出的 GSIFN 解决了​​ MSA 中需要解决的两个关键问题：（i）在多模态融合中，现有融合方法中模态组合的解耦和巨大的参数冗余导致融合性能和效率低下。（ii）单模态特征提取器和增强器的表示能力和计算开销之间的权衡。GSIFN 包含两个主要组件来解决这些问题：（i）图结构和交错掩码多模态 Transformer。它采用交错掩码机制构建鲁棒的多模态图嵌入，实现基于 Transformer 的全模态融合，大大降低了计算开销。 (ii) 一种具有低计算开销和高性能的自监督学习框架，它利用具有矩阵内存的并行化 LSTM 来增强非语言模态特征以生成单峰标签。在 MSA 数据集 CMU-MOSI、CMU-MOSEI 和 CH-SIMS 上进行评估，与最先进的方法相比，GSIFN 表现出卓越的性能，并且计算开销明显更低。]]></description>
      <guid>https://arxiv.org/abs/2408.14809</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AAVENUE：通过新颖的基准测试检测 AAVE 中 NLU 任务的 LLM 偏差</title>
      <link>https://arxiv.org/abs/2408.14845</link>
      <description><![CDATA[arXiv:2408.14845v1 公告类型：新
摘要：检测非裔美国本土英语 (AAVE) 的自然语言理解 (NLU) 中的偏见对于开发包容性的自然语言处理 (NLP) 系统至关重要。为了解决方言引起的性能差异，我们引入了 AAVENUE ({AAVE} {N}atural Language {U}nderstanding {E}valuation)，这是评估大型语言模型 (LLM) 在 AAVE 和标准美式英语 (SAE) 的 NLU 任务上的表现的基准。AAVENUE 建立在现有基准（如 VALUE）的基础上并加以扩展，用更灵活的方法取代确定性的句法和形态转换，利用基于 LLM 的翻译和少量提示，在翻译 GLUE 和 SuperGLUE 基准的关键任务时提高我们评估指标的性能。我们使用五种流行的 LLM 和一套全面的指标（包括流利度、BARTScore、质量、连贯性和可理解性）比较 AAVENUE 和 VALUE 翻译。此外，我们还招募了流利的 AAVE 使用者来验证我们的翻译的真实性。我们的评估表明，LLM 在 SAE 任务上的表现始终优于 AAVE 翻译版本，这突显了固有的偏见，并强调了对更具包容性的 NLP 模型的需求。我们已经在 GitHub 上开源了我们的源代码，并创建了一个网站来展示我们的工作，网址为 https://aavenue.live。]]></description>
      <guid>https://arxiv.org/abs/2408.14845</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SHADOW 项目：使用 LM 探测在 Wikidata 上进行符号高阶联想演绎推理</title>
      <link>https://arxiv.org/abs/2408.14849</link>
      <description><![CDATA[arXiv:2408.14849v1 公告类型：新
摘要：我们引入了 SHADOW，这是一种使用联想演绎推理在中间任务上训练的微调语言模型，并使用 Wikidata 三重完成来测量其在知识库构建任务上的性能。我们在 LM-KBC 2024 挑战赛上对 SHADOW 进行了评估，结果表明它的表现比基线解决方案高出 20%，F1 得分为 68.72%。]]></description>
      <guid>https://arxiv.org/abs/2408.14849</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>检测人工智能缺陷：针对语言模型内部故障的目标驱动攻击</title>
      <link>https://arxiv.org/abs/2408.14853</link>
      <description><![CDATA[arXiv:2408.14853v1 公告类型：新 
摘要：大型语言模型 (LLM) 已成为快速发展的人工智能领域的焦点。然而，一个关键问题是这些模型的预训练语料库中存在有毒内容，这可能导致产生不适当的输出。研究检测 LLM 内部故障的方法可以帮助我们了解它们的局限性并提高其安全性。现有方法主要侧重于越狱攻击，这涉及手动或自动构建对抗性内容以提示目标 LLM 生成意外响应。这些方法严重依赖于提示工程，这非常耗时并且通常需要专门设计的问题。为了应对这些挑战，本文提出了一种目标驱动的攻击范式，该范式专注于直接引出目标响应而不是优化提示。我们引入了另一个 LLM 作为有毒内容检测器的使用，称为 ToxDet。给定一个目标毒性反应，ToxDet 可以生成一个可能的问题和一个初步答案，以激发目标模型产生具有与所提供反应等同含义的期望毒性反应。ToxDet 通过与目标 LLM 交互并从其接收奖励信号进行训练，利用强化学习进行优化过程。虽然目标模型的主要重点是开源 LLM，但经过微调的 ToxDet 也可以转移到攻击黑盒模型（例如 GPT-4o），从而取得显著成果。在 AdvBench 和 HH-Harmless 数据集上的实验结果证明了我们的方法在检测目标 LLM 产生有害反应的趋势方面的有效性。该算法不仅暴露了漏洞，还为研究人员提供了宝贵的资源来加强他们的模型以抵御此类攻击。]]></description>
      <guid>https://arxiv.org/abs/2408.14853</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在对齐的大型语言模型上推进对抗性后缀迁移学习</title>
      <link>https://arxiv.org/abs/2408.14866</link>
      <description><![CDATA[arXiv:2408.14866v1 公告类型：新
摘要：语言模型 (LLM) 面临安全问题，因为恶意用户可能会滥用。最近的红队工作已经确定了能够使用基于梯度的搜索算法贪婪坐标梯度 (GCG) 越狱 LLM 的对抗性后缀。然而，GCG 面临着计算效率低下的问题，限制了对后缀在模型和数据之间的可转移性和可扩展性的进一步研究。在这项工作中，我们在搜索效率和后缀可转移性之间架起了桥梁。我们提出了一个两阶段的迁移学习框架 DeGCG，它将搜索过程分解为行为无关的预搜索和行为相关的后搜索。具体来说，我们在预搜索中采用直接第一个目标标记优化来促进搜索过程。我们将我们的方法应用于跨模型、跨数据和自转移场景。此外，我们引入了我们方法的交错变体 i-DeGCG，它迭代地利用自迁移能力来加速搜索过程。在 HarmBench 上的实验证明了我们的方法在各种模型和领域中的有效性。值得注意的是，我们的 i-DeGCG 在 Llama2-chat-7b 上的表现优于基线，有效集和测试集上的 ASR 分别为 $43.9$ ($+22.2$) 和 $39.0$ ($+19.5$)。对跨模型迁移的进一步分析表明，第一个目标标记优化在利用后缀迁移能力实现高效搜索方面发挥着关键作用。]]></description>
      <guid>https://arxiv.org/abs/2408.14866</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Inverse-Q*：用于对齐大型语言模型（无需偏好数据）的标记级强化学习</title>
      <link>https://arxiv.org/abs/2408.14874</link>
      <description><![CDATA[arXiv:2408.14874v1 公告类型：新
摘要：人类反馈强化学习 (RLHF) 已被证明可有效将大型语言模型与人类意图相结合，但它通常依赖于复杂的方法，如近端策略优化 (PPO)，这些方法需要大量的超参数调整，并且在样本效率和稳定性方面存在挑战。在本文中，我们介绍了 Inverse-Q*，这是一个创新框架，它通过优化 token 级强化学习而超越了传统的 RL 方法，而无需额外的奖励或价值模型。Inverse-Q* 利用直接偏好优化技术，但通过直接从模型的响应中估计条件最优策略来扩展它们，从而促进更细粒度和更灵活的策略制定。我们的方法减少了对人工注释和外部监督的依赖，使其特别适合资源匮乏的环境。我们展示了大量的实验结果，证明 Inverse-Q* 不仅在收敛速度和模型响应与人类偏好的一致性方面与 PPO 相匹配，而且可能超过 PPO 的有效性。我们的研究结果表明，Inverse-Q* 为传统的 RLHF 方法提供了一种实用且强大的替代方案，为更高效、适应性更强的模型训练方法铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2408.14874</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>表达讽刺时韵律和语义线索之间的功能权衡</title>
      <link>https://arxiv.org/abs/2408.14892</link>
      <description><![CDATA[arXiv:2408.14892v1 公告类型：新
摘要：本研究调查了讽刺的声学特征，并理清了讽刺话语的倾向与讽刺韵律线索的存在之间的相互作用。使用从电视节目中汇编的讽刺话语数据集，我们分析了属于三个不同讽刺类别（嵌入、命题和言外之意）的话语和关键短语中的韵律特征，这些类别的语义线索存在程度不同，并将它们与中性表达进行比较。结果表明，在讽刺意义从语义中突出的短语中，韵律线索的相关性低于讽刺意义从语义中不明显时的相关性，这表明在短语层面上，讽刺的韵律和语义线索之间存在权衡。这些发现强调了在语义密集的讽刺表达中对韵律调节的依赖减少，以及塑造讽刺意图交流的细微互动。]]></description>
      <guid>https://arxiv.org/abs/2408.14892</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在空白处书写：长上下文检索的更好推理模式</title>
      <link>https://arxiv.org/abs/2408.14906</link>
      <description><![CDATA[arXiv:2408.14906v1 公告类型：新
摘要：在本文中，我们介绍了“边缘写作”（WiM），这是一种用于大型语言模型的新推理模式，旨在优化检索导向任务中长输入序列的处理。这种方法利用键值缓存的分块预填充来执行分段推理，从而能够高效处理广泛的上下文以及引导模型完成特定任务的中间信息（“边缘”）的生成和分类。这种方法略微增加了计算开销，同时显着提高了现成模型的性能，而无需进行微调。具体来说，我们观察到 WiM 为推理技能（HotpotQA、MultiHop-RAG）的准确率平均提高了 7.5%，为聚合任务（CWE）的 F1 分数提高了 30.0% 以上。此外，我们还展示了所提出的模式如何融入交互式检索设计，该设计为最终用户提供有关上下文处理进度的持续更新，并精确定位相关信息与最终响应的集成。我们在 https://github.com/writer/writing-in-the-margins 上发布了使用 Hugging Face Transformers 库的 WiM 实现。]]></description>
      <guid>https://arxiv.org/abs/2408.14906</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SpikingSSM：使用稀疏和并行脉冲状态空间模型学习长序列</title>
      <link>https://arxiv.org/abs/2408.14909</link>
      <description><![CDATA[arXiv:2408.14909v1 公告类型：新
摘要：脉冲神经网络（SNN）被称为低能耗网络，在过去几十年中引起了广泛关注。虽然 SNN 在视觉任务方面与人工神经网络（ANN）的竞争力越来越强，但尽管它们具有内在的时间动态性，但它们很少用于长序列任务。在这项工作中，我们利用状态空间模型（SSM）的序列学习能力，开发了用于长序列学习的脉冲状态空间模型（SpikingSSM）。受树突神经元结构的启发，我们将神经元动力学与原始 SSM 块分层集成，同时实现稀疏突触计算。此外，为了解决事件驱动的神经元动力学与并行计算的冲突，我们提出了一种轻量级的替代动态网络，它可以准确预测重置后的膜电位并与可学习阈值兼容，与传统迭代方法相比，训练速度可以提高几个数量级。在长距离竞技场基准测试任务中，SpikingSSM 实现了与最先进的 SSM 相媲美的性能，同时实现了平均 90% 的网络稀疏性。在语言建模方面，我们的网络在 WikiText-103 数据集上显著超越了现有的脉冲大型语言模型 (spikingLLM)，而模型大小仅为其三分之一，证明了其作为低计算成本 LLM 主干架构的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.14909</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>