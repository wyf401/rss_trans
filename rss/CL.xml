<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 01 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>代词逻辑</title>
      <link>https://arxiv.org/abs/2409.18978</link>
      <description><![CDATA[arXiv:2409.18978v1 公告类型：新
摘要：特别是在跨性别和非二元性别 (TGNB) 社区中，公开分享个人代词的做法越来越普遍，这样我们才能在别人的讲话中被正确地区分性别。我们中的许多人对我们的性别有着微妙的渴望，这导致我们使用更复杂的描述来描述我们的愿望；例如，描述符“她/他们”。我们观察到，这些对我们的愿望的描述具有他们自己的小语言结构。因此，我们提出形式逻辑作为表达个人代词和潜在的性别其他方面的工具。我们探索了三种潜在的逻辑基础（线性逻辑、时间逻辑和具有明确描述的自由逻辑）及其权衡。我们提出这一建议的首要动机是游戏，肯定一个人可以同时成为逻辑学家和 TGNB。我们将形式化描述为可以随着社会对性别的理解而不断发展的东西。这意味着外展是一项重要的潜在应用：我们可以向 TGNB 青年展示他们属于逻辑，并能做出独特的贡献。评估一个人的代词是否受到尊重的工具也是一种应用。]]></description>
      <guid>https://arxiv.org/abs/2409.18978</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IW-Bench：评估用于将图像转换为 Web 的大型多模式模型</title>
      <link>https://arxiv.org/abs/2409.18980</link>
      <description><![CDATA[arXiv:2409.18980v1 公告类型：新
摘要：最近，大型多模态模型的进步导致了图像理解能力的重大进步。尽管取得了这些进步，但仍然缺乏专门用于评估这些大型模型的图像到 Web 转换能力的强大基准。首先，必须确保生成的 Web 元素的完整性。这些元素包括可见和不可见类别。以前的评估方法（例如 BLEU）由于 Web 中存在不可见元素而特别容易受到重大改变的影响。此外，测量网页的布局信息至关重要，参考元素之间的位置关系，这是以前的工作所忽略的。为了应对挑战，我们策划并调整了图像和相应 Web 代码的基准（IW-Bench）。具体来说，我们提出了元素准确度，它通过解析文档对象模型 (DOM) 树来测试元素的完整性。我们还提出了布局准确性，通过将 DOM 树转换为公共子序列来分析元素的位置关系。此外，为了获得更好的性能，我们设计了一个五跳多模态思维链提示，它包含五个跳：1）SoM 提示注入。2）推断元素。3）推断布局。4）推断 Web 代码。5）反射。我们的基准测试包括 1200 对难度各异的图像和 Web 代码。我们对现有的大型多模态模型进行了广泛的实验，深入了解了它们在图像到 Web 领域的性能和改进领域。]]></description>
      <guid>https://arxiv.org/abs/2409.18980</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型：经过微调的 BERT 以检测自然语言中的魅力型领导策略</title>
      <link>https://arxiv.org/abs/2409.18984</link>
      <description><![CDATA[arXiv:2409.18984v1 公告类型：新
摘要：这项工作使用经过微调的 Transformers 双向编码器表示 (BERT) 模型研究了在自然语言中识别魅力型领导策略 (CLT)。基于为此任务生成和策划的大量 CLT 语料库，我们的方法包括训练一个机器学习模型，该模型能够准确识别自然语言中这些策略的存在。进行了性能评估以评估我们的模型在检测 CLT 方面的有效性。我们发现，对所有 CLT 的检测总准确率为 98.96% 本研究的结果对心理学和管理学的研究具有重要意义，为简化目前对文本中魅力的复杂评估提供了潜在的方法。]]></description>
      <guid>https://arxiv.org/abs/2409.18984</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Lab-AI——用于临床医学个性化实验室测试解释的检索增强语言模型</title>
      <link>https://arxiv.org/abs/2409.18986</link>
      <description><![CDATA[arXiv:2409.18986v1 公告类型：新 
摘要：准确解释实验室结果对临床医学至关重要，但大多数患者门户网站使用通用正常范围，忽略了年龄和性别等因素。本研究介绍了 Lab-AI，这是一个交互式系统，它使用来自可靠健康来源的检索增强生成 (RAG) 提供个性化的正常范围。Lab-AI 有两个模块：因子检索和正常范围检索。我们在 68 个实验室测试中测试了这些 - 30 个有条件因素，38 个没有。对于有因素的测试，正常范围取决于患者特定信息。我们的结果表明，带有 RAG 的 GPT-4-turbo 在因子检索中获得了 0.95 的 F1 分数，在正常范围检索中获得了 0.993 的准确率。带有 RAG 的 GPT-4-turbo 在因子检索方面的表现比最好的非 RAG 系统高出 29.1%，在问题级和实验室级正常范围检索方面分别显示出 60.9% 和 52.9% 的改进。这些发现凸显了 Lab-AI 在增强患者对实验室结果理解方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.18986</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过小型语言模型实现高效、个性化的移动健康事件预测</title>
      <link>https://arxiv.org/abs/2409.18987</link>
      <description><![CDATA[arXiv:2409.18987v1 公告类型：新
摘要：医疗监测对于早期发现、及时干预和持续管理健康状况至关重要，最终可改善个人的生活质量。最近的研究表明，大型语言模型 (LLM) 在支持医疗保健任务方面表现出色。然而，现有的基于 LLM 的医疗保健解决方案通常依赖于基于云的系统，这引发了隐私问题并增加了个人信息泄露的风险。因此，人们越来越有兴趣在手机和可穿戴设备等设备上本地运行这些模型以保护用户的隐私。小型语言模型 (SLM) 是解决隐私和计算问题的潜在候选者，因为它们更高效，更适合本地部署。然而，SLM 在医疗保健领域的表现尚未得到研究。本文研究了 SLM 准确分析健康数据（例如步数、卡路里、睡眠时间和其他重要统计数据）以评估个人健康状况的能力。我们的结果表明，TinyLlama 拥有 11 亿个参数，使用 4.31 GB 内存，延迟时间为 0.48 秒，与其他四种最先进的 (SOTA) SLM 相比，在各种医疗应用上表现出最佳性能。我们的结果表明，SLM 可以部署在可穿戴或移动设备上进行实时健康监测，为高效且保护隐私的医疗保健提供实用的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2409.18987</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过大型语言模型将商业活动划分为循环经济国际标准行业分类的统一框架</title>
      <link>https://arxiv.org/abs/2409.18988</link>
      <description><![CDATA[arXiv:2409.18988v1 公告类型：新
摘要：有效的信息收集和知识编码对于开发促进循环经济实践的推荐系统至关重要。一种有前途的方法是创建一个集中的知识库，对历史废物转化为资源的交易进行分类，随后根据过去的成功生成建议。然而，构建这样一个知识库的一个重大障碍是缺乏一个通用的标准化框架来表示不同地理区域的商业活动。为了应对这一挑战，本文利用大型语言模型 (LLM) 将描述经济活动的文本数据分类到国际标准行业分类 (ISIC)，这是一个全球公认的经济活动分类框架。这种方法使全球企业提供的任何经济活动描述都能归类到统一的 ISIC 标准中，从而促进了集中知识库的创建。我们的方法在经过微调的 GPT-2 模型上在 182 个标签的测试数据集上实现了 95% 的准确率。该研究为跨地区部署的知识编码和推荐系统提供了标准化基础，为全球促进可持续循环经济实践的努力做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2409.18988</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SC-Phi2：针对星际争霸 II 宏观管理任务的微调小型语言模型</title>
      <link>https://arxiv.org/abs/2409.18989</link>
      <description><![CDATA[arXiv:2409.18989v1 公告类型：新
摘要：本文介绍了 SC-Phi2，这是一种针对宏观管理任务进行微调的星际争霸 II 小型语言模型。小型语言模型（如 Phi2、Gemma 和 DistilBERT）是大型语言模型 (LLM) 的精简版本，具有更少的参数，运行时需要更少的功率和内存。为了教授微软的 Phi2 模型有关星际争霸的知识，我们创建了一个新的 SC2 文本数据集，其中包含有关星际争霸种族、角色和动作的信息，并使用它通过自监督学习对 Phi-2 进行微调。我们将此语言模型与来自预训练的 BLIP-2（引导语言图像预训练）模型的视觉转换器 (ViT) 配对，并在 MSC 重放数据集上对其进行微调。这使我们能够构建包含视觉游戏状态信息的动态提示。与星际争霸 LLM 中使用的大型模型（例如 GPT-3.5）不同，Phi2 主要基于教科书数据进行训练，除了我们的训练过程提供的内容外，几乎没有包含星际争霸 II 的固有知识。通过使用 LoRA（低秩自适应）和量化，我们的模型可以在单个 GPU 上进行训练。我们证明了我们的模型在微观管理任务（例如构建顺序和全局状态预测）方面表现良好，并且参数数量较少。]]></description>
      <guid>https://arxiv.org/abs/2409.18989</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>调查 MLLM 概况：当前调查的元评论</title>
      <link>https://arxiv.org/abs/2409.18991</link>
      <description><![CDATA[arXiv:2409.18991v1 公告类型：新
摘要：多模态大型语言模型 (MLLM) 的兴起已成为人工智能领域的变革力量，使机器能够处理和生成跨多种模态的内容，例如文本、图像、音频和视频。这些模型代表了传统单模态系统的重大进步，为从自主代理到医学诊断等各种应用开辟了新领域。通过整合多种模态，MLLM 可以更全面地理解信息，紧密模仿人类感知。随着 MLLM 功能的扩展，对全面准确的性能评估的需求变得越来越重要。本调查旨在对 MLLM 的基准测试和评估方法进行系统回顾，涵盖基础概念、应用、评估方法、道德问题、安全性、效率和特定领域的应用等关键主题。通过对现有文献的分类和分析，我们总结了各种调查的主要贡献和方法，进行了详细的比较分析，并研究了它们在学术界的影响。此外，我们还确定了 MLLM 研究中的新趋势和尚未充分探索的领域，并提出了未来研究的潜在方向。本调查旨在让研究人员和从业者全面了解 MLLM 评估的现状，从而促进这一快速发展的领域的进一步发展。]]></description>
      <guid>https://arxiv.org/abs/2409.18991</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>事件理解的机械模型回顾</title>
      <link>https://arxiv.org/abs/2409.18992</link>
      <description><![CDATA[arXiv:2409.18992v1 公告类型：新
摘要：本综述考察了事件理解的理论假设和计算模型，追溯了从话语理解理论到当代事件认知框架的演变。本综述涵盖了关键的话语理解理论，包括建构-整合、事件索引、因果网络和共振模型，重点介绍了它们对理解理解中的认知过程的贡献。然后，我讨论了事件理解的当代理论框架，包括事件分割理论（Zacks 等人，2007 年）、事件视界模型（Radvansky &amp; Zacks，2014 年）和分层生成框架（Kuperberg，2021 年），这些框架强调事件理解中的预测、因果关系和多层次表示。基于这些理论，我评估了五种事件理解的计算模型：REPRISE（Butz 等人，2019 年）、结构化事件记忆 (SEM；Franklin 等人，2020 年）、Lu 模型（Lu 等人，2022 年）、Gumbsch 模型（Gumbsch 等人，2022 年）以及 Elman 和 McRae 模型（2019 年）。分析重点关注它们的分层处理、预测机制和表征学习方法。出现的关键主题包括使用分层结构作为归纳偏差、预测在理解中的重要性以及学习事件动态的多种策略。该评论确定了未来研究的关键领域，包括需要更复杂的方法来学习结构化表征、整合情景记忆机制以及为工作事件模型开发自适应更新算法。通过综合理论框架和计算实现的见解，本评论旨在增进我们对人类事件理解的理解，并指导未来认知科学的建模工作。]]></description>
      <guid>https://arxiv.org/abs/2409.18992</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中对齐对分类决策有效性的系统表征</title>
      <link>https://arxiv.org/abs/2409.18995</link>
      <description><![CDATA[arXiv:2409.18995v1 公告类型：新
摘要：随着大型语言模型 (LLM) 被部署到医疗保健等高风险领域，了解它们的决策与人类偏好和价值观的契合程度变得至关重要，尤其是当我们认识到这些偏好没有单一的黄金标准时。本文采用系统方法评估 LLM 在分类决策中的偏好对齐，以医疗分诊作为特定领域的用例。它还衡量对齐过程将如何有效地改变特定模型的对齐。这种方法的关键是一种新颖的简单测量方法，即对齐合规指数 (ACI)，它量化了 LLM 与给定偏好函数或黄金标准的对齐效果。由于 ACI 衡量的是对齐效果而不是对齐过程，因此它适用于本研究中使用的上下文学习之外的对齐方法。
使用模拟患者对的数据集，对三个前沿 LLM（GPT4o、Claude 3.5 Sonnet 和 Gemini Advanced）做出符合专家临床医生偏好的分诊决策的能力进行了评估。使用各种提示策略评估了模型在对齐尝试之前和之后的性能。结果显示，不同模型和对齐方法之间的对齐效果存在显著差异。值得注意的是，根据 ACI 的衡量，表现良好的模型，对齐前有时会在对齐后降级，目标偏好函数的微小变化会导致模型排名发生巨大变化。还通过有针对性的提问探讨了 LLM 决策背后隐含的道德原则（人类理解的）。
这项研究促使在短期内使用一套实用的方法和 ACI，以了解分类决策（例如分诊）中各种人类和 LLM 决策价值观之间的对应关系。]]></description>
      <guid>https://arxiv.org/abs/2409.18995</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从语言巨人到感官大师：大型语言模型跨模态推理调查</title>
      <link>https://arxiv.org/abs/2409.18996</link>
      <description><![CDATA[arXiv:2409.18996v1 公告类型：新
摘要：跨模态推理 (CMR) 是一种跨不同感官模态进行综合和推理的复杂过程，它越来越被认为是向更复杂和拟人化的人工智能系统发展的关键能力。大型语言模型 (LLM) 代表一类专门设计用于大规模解析、生成和处理人类语言的 AI 算法。最近部署 LLM 来处理 CMR 任务的趋势标志着提高其有效性的方法的新主流。本调查对使用 LLM 应用于 CMR 的当前方法进行了细致的阐述，将这些方法分为详细的三层分类法。此外，该调查深入研究了该领域内原型模型的主要设计策略和操作技术。此外，它阐明了与将 LLM 集成到 CMR 相关的当前挑战，并确定了未来的研究方向。总而言之，本综述致力于通过为学者提供全面而详细的视野，展示当前研究的前沿，同时指出潜在的进步途径，从而加速这一新兴领域的进步。收集相关论文的相关 GitHub 存储库可在 https://github.com/ZuyiZhou/Awesome-Cross-modal-Reasoning-with-LLMs 找到]]></description>
      <guid>https://arxiv.org/abs/2409.18996</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PropaInsight：从技巧、诉求和意图的角度更深入地理解宣传</title>
      <link>https://arxiv.org/abs/2409.18997</link>
      <description><![CDATA[arXiv:2409.18997v1 公告类型：新
摘要：宣传在塑造公众舆论和助长虚假信息方面发挥着关键作用。虽然现有研究主要侧重于识别宣传技巧，但缺乏捕捉此类内容的更广泛动机和影响的能力。为了应对这些挑战，我们引入了 propainsight，这是一个基于基础社会科学研究的概念框架，它系统地将宣传分解为技巧、唤醒诉求和潜在意图。propainsight 提供了对宣传如何在不同背景下运作的更细致的理解。此外，我们提出了 propagaze，这是一个新颖的数据集，它将人工注释的数据与通过精心设计的管道生成的高质量合成数据相结合。我们的实验表明，现成的 LLM 在宣传分析方面举步维艰，但使用 propagaze 进行训练可以显着提高性能。与 1-shot GPT-4-Turbo 相比，经过微调的 Llama-7B-Chat 在技术识别中的文本跨度 IoU 提高了 203.4%，在吸引力分析中的 BertScore 提高了 66.2%。此外，propagaze 在数据稀疏和跨域场景中补充了有限的人工注释数据，显示出其在全面和可推广的宣传分析方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.18997</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 的临床试验检索控制推理</title>
      <link>https://arxiv.org/abs/2409.18998</link>
      <description><![CDATA[arXiv:2409.18998v1 公告类型：新
摘要：将患者与临床试验进行匹配需要对文件进行系统且合理的解释，这需要大量专家级背景知识，并且需要一套复杂的明确定义的资格标准。此外，此解释过程需要在庞大的试验知识库上大规模运行。在本文中，我们提出了一种可扩展的方法，该方法扩展了 LLM 的功能，使其能够系统化对一系列医疗资格标准的推理，并在现实案例的背景下对其进行评估。所提出的方法覆盖了 LLM 的集合引导推理方法。所提出的框架在 TREC 2022 临床试验中进行了评估，取得了优于最先进技术的结果：NDCG@10 为 0.693，Precision@10 为 0.73。]]></description>
      <guid>https://arxiv.org/abs/2409.18998</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 GPT 增强型 FinBERT 蒸馏技术增强 TinyBERT 的金融情绪分析能力</title>
      <link>https://arxiv.org/abs/2409.18999</link>
      <description><![CDATA[arXiv:2409.18999v1 公告类型：新
摘要：在快速发展的金融情绪分析领域，预测模型的效率和准确性至关重要，因为它们对金融市场有重大影响。基于 Transformer 的模型（如 BERT）和大型语言模型（LLM）（如 GPT-4）大大推进了 NLP 任务。尽管基于 BERT 的模型具有优势，但它们在边缘计算环境中面临着计算强度的挑战，而 LLM 的庞大规模和计算要求限制了它们的实际部署。本研究建议利用 LLM（如 GPT-4 Omni）的生成能力来创建合成的、特定领域的训练数据。这种方法解决了数据稀缺的挑战，并通过使小型模型与大型模型竞争来提高小型模型的性能。该研究特别旨在增强 FinBERT（一种针对金融情绪分析进行微调的 BERT 模型），并通过结构化的两层知识提炼策略开发紧凑型 Transformer 模型 TinyFinBERT。使用 GPT-4 Omni 增强的数据（包括生成新的训练示例和转换现有数据），我们显著提高了 FinBERT 的准确性，使其可以作为教师模型使用。然后，增强后的 FinBERT 使用 GPT-4 Omni 和 GPT-3.5 Turbo 增强数据将知识提炼到 TinyFinBERT。提炼策略结合了对数和中间层提炼。TinyFinBERT 的训练和评估使用了 PhraseBank 数据集和 FiQA 2018 Task1 数据集，实现了与 FinBERT 相当的性能，同时规模更小、效率更高。这项研究展示了 LLM 如何通过创新的数据增强和提炼技术增强更小、更高效的模型的能力，从而有效地促进金融情绪分析的进步。]]></description>
      <guid>https://arxiv.org/abs/2409.18999</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关注重要的事情</title>
      <link>https://arxiv.org/abs/2409.19001</link>
      <description><![CDATA[arXiv:2409.19001v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 取得了显著的成功，但它们在将其输出与用户指令对齐方面仍然表现出有限的能力。在这项工作中，我们介绍了一种简单有效的方法，我们将其命名为 GUIDE，它可以机械地提高指令标记中的注意力分数。为了支持此操作，我们提出了影响力，这是一种新颖的指标，它突出显示了用户的指令如何通过转换器层传播并影响 LLM 输出。我们的结果表明，GUIDE 将遵循指令的准确率提高了 29.4% 至 60.4%，优于自然提示替代方案和多达 1M 个标记的监督微调。]]></description>
      <guid>https://arxiv.org/abs/2409.19001</guid>
      <pubDate>Tue, 01 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>