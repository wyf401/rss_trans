<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 02 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过相似性搜索进行上下文示例选择可改善低资源机器翻译</title>
      <link>https://arxiv.org/abs/2408.00397</link>
      <description><![CDATA[arXiv:2408.00397v1 公告类型：新
摘要：生成式大型语言模型 (LLM) 执行上下文学习的能力引发了大量研究，以探讨如何最好地为各种自然语言处理任务提示模型。在本文中，我们重点关注机器翻译 (MT)，这项任务已被证明可以从上下文翻译示例中受益。然而，尚未发表关于如何最好地选择示例的系统研究，并且关于基于相似性的选择相对于随机选择的有用性，已经报告了混合结果。我们提供了一项涵盖多个 LLM 和多个上下文示例检索策略的研究，比较了多语言句子嵌入。我们涵盖了几个语言方向，代表了不同级别的语言资源（英语到法语、德语、斯瓦希里语和沃洛夫语）。与之前发表的结果相反，我们发现句子嵌入相似性可以改善 MT，尤其是对于资源较少的语言方向，并讨论了选择池多样性和质量之间的平衡。我们还强调了基于 LLM 的 MT 评估中可能存在的问题，并提出了更合适的评估协议，将 COMET 指标调整为 LLM 评估。代码和输出可在 https://github.com/ArmelRandy/ICL-MT 免费获取。]]></description>
      <guid>https://arxiv.org/abs/2408.00397</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:15 GMT</pubDate>
    </item>
    <item>
      <title>GalleryGPT：使用大型多模态模型分析绘画</title>
      <link>https://arxiv.org/abs/2408.00491</link>
      <description><![CDATA[arXiv:2408.00491v1 公告类型：新
摘要：艺术品分析是艺术欣赏的重要基本技能，可以丰富个人的审美感受力并促进批判性思维能力。理解艺术品具有挑战性，因为它具有主观性、多样化的解释和复杂的视觉元素，需要艺术史、文化背景和美学理论方面的专业知识。然而，受限于数据收集和模型能力，以前的自动分析艺术品的工作主要集中在分类、检索和其他简单任务上，这与人工智能的目标相去甚远。为了促进研究进展，在本文中，我们进一步进行了综合分析，灵感来自大型多模态模型的卓越感知和生成能力。具体来说，我们首先提出了一项针对艺术品（本文中的绘画）撰写段落分析的任务，仅关注视觉特征以形成对艺术品的更全面的理解。为了支持形式分析的研究，我们收集了一个大型数据集 PaintingForm，其中包含约 19k 幅绘画图像和 50k 个分析段落。我们进一步介绍了一种用于绘画分析创作的卓越大型多模态模型 GalleryGPT，该模型基于 LLaVA 架构进行了少许修改和微调，并利用了我们收集的数据。我们在多个数据集上进行了正式分析生成和零样本实验，以评估模型的容量。结果显示，与强大的基线 LMM 相比，性能有了显著提升，展示了其出色的艺术分析和泛化能力。\textcolor{blue}{代码和模型可在以下网址获取：https://github.com/steven640pixel/GalleryGPT。]]></description>
      <guid>https://arxiv.org/abs/2408.00491</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:15 GMT</pubDate>
    </item>
    <item>
      <title>Bailing-TTS：面向类人自发表达的汉语方言语音合成</title>
      <link>https://arxiv.org/abs/2408.00284</link>
      <description><![CDATA[arXiv:2408.00284v1 公告类型：新
摘要：大规模文本转语音 (TTS) 模型最近取得了重大进展。然而，它们在生成汉语方言语音方面仍然存在不足。为了解决这个问题，我们提出了 Bailing-TTS，这是一组能够生成高质量汉语方言语音的大规模 TTS 模型。Bailing-TTS 是汉语方言语音生成的基础模型。首先，提出了持续半监督学习以促进文本标记和语音标记的对齐。其次，使用特定的转换器架构和多阶段训练过程开发了汉语方言表示学习。通过提出的新颖网络架构设计和相应策略，Bailing-TTS 能够有效、高效地从文本生成汉语方言语音。实验表明，Bailing-TTS 生成的汉语方言语音接近人类的自发表征。鼓励读者在 \url{https://c9412600.github.io/bltts_tech_report/index.html} 上收听演示。]]></description>
      <guid>https://arxiv.org/abs/2408.00284</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:14 GMT</pubDate>
    </item>
    <item>
      <title>DeliLaw：基于大型语言模型的中文法律咨询系统</title>
      <link>https://arxiv.org/abs/2408.00357</link>
      <description><![CDATA[arXiv:2408.00357v1 公告类型：新
摘要：传统的法律检索系统旨在检索法律文件、法规、判例和其他法律信息，由于缺乏对特定问题的语义理解，无法给出令人满意的答案。大型语言模型（LLM）在各种自然语言处理任务中取得了优异的效果，这启发我们在法律领域训练一个LLM来帮助法律检索。然而，在中文法律领域，由于法律问题的复杂性和法律文章的严谨性，目前还没有一个具有令人满意的实际应用的法律大模型。在本文中，我们提出了一个基于大型语言模型的中文法律咨询系统DeliLaw。DeliLaw集成了法律检索模块和案例检索模块，以克服模型幻觉。用户可以在DeliLaw系统上以对话模式咨询专业法律问题、搜索法律文章和相关裁判案例等。此外，DeliLaw支持使用英语进行咨询。我们提供系统的地址：https://data.delilegal.com/lawQuestion。]]></description>
      <guid>https://arxiv.org/abs/2408.00357</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:14 GMT</pubDate>
    </item>
    <item>
      <title>QUITO：通过查询引导上下文压缩加速长上下文推理</title>
      <link>https://arxiv.org/abs/2408.00274</link>
      <description><![CDATA[arXiv:2408.00274v1 公告类型：新
摘要：上下文学习 (ICL) 功能是大型语言模型 (LLM) 成功的基础。最近，上下文压缩引起了越来越多的关注，因为它可以大大降低 LLM 的推理复杂性和计算成本。在本文中，我们介绍了一种新颖的查询引导注意力压缩 (QUITO) 方法，该方法利用问题对上下文的注意力来过滤无用信息。具体来说，我们采用触发标记来计算响应问题的上下文注意力分布。基于分布，我们提出了三种不同的过滤方法来满足上下文长度的预算约束。我们使用两个广泛使用的数据集（即 NaturalQuestions 和 ASQA）评估 QUITO。实验结果表明，QUITO 在各种数据集和下游 LLM 中的表现明显优于既定基线，凸显了其有效性。我们的代码可在 https://github.com/Wenshansilvia/attention_compressor 上找到。]]></description>
      <guid>https://arxiv.org/abs/2408.00274</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:13 GMT</pubDate>
    </item>
    <item>
      <title>探索印度语中文本到图像的生成偏差</title>
      <link>https://arxiv.org/abs/2408.00283</link>
      <description><![CDATA[arXiv:2408.00283v1 公告类型：新
摘要：本研究调查了印度广泛使用的印度语文本到图像 (TTI) 模型中的偏见。它评估并比较了这些语言中领先的 TTI 模型的生成性能和文化相关性与它们在英语中的表现。使用提出的 IndicTTI 基准，我们全面评估了 30 种印度语的性能，包括两个开源传播模型和两个商业生成 API。该基准的主要目标是评估这些模型对印度语的支持并确定需要改进的领域。鉴于超过 14 亿人使用的 30 种语言的语言多样性，该基准旨在提供对 TTI 模型在印度语领域有效性的详细而有见地的分析。IndicTTI 基准的数据和代码可以在 https://iab-rubric.org/resources/other-databases/indictti 上访问。]]></description>
      <guid>https://arxiv.org/abs/2408.00283</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:13 GMT</pubDate>
    </item>
    <item>
      <title>句子式语音摘要：基于 LM 知识提炼的任务、数据集和端到端建模</title>
      <link>https://arxiv.org/abs/2408.00205</link>
      <description><![CDATA[arXiv:2408.00205v1 公告类型：新
摘要：本文介绍了一种称为逐句语音摘要（Sen-SSum）的新方法，该方法以逐句的方式从口语文档生成文本摘要。Sen-SSum 将自动语音识别（ASR）的实时处理与语音摘要的简洁性相结合。为了探索这种方法，我们为 Sen-SSum 提供了两个数据集：Mega-SSum 和 CSJ-SSum。使用这些数据集，我们的研究评估了两种基于 Transformer 的模型：1）结合 ASR 和强文本摘要模型的级联模型，以及 2）将语音直接转换为文本摘要的端到端 (E2E) 模型。虽然 E2E 模型对于开发计算效率高的模型很有吸引力，但它们的性能不如级联模型。因此，我们提出使用级联模型生成的伪摘要对 E2E 模型进行知识提炼。我们的实验表明，提出的知识提炼有效地提高了两个数据集上 E2E 模型的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.00205</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:12 GMT</pubDate>
    </item>
    <item>
      <title>通过分组 FIR 滤波和注意力机制增强结构化状态空间模型</title>
      <link>https://arxiv.org/abs/2408.00244</link>
      <description><![CDATA[arXiv:2408.00244v1 公告类型：新
摘要：结构化状态空间模型 (SSM) 已成为 Transformer 架构的有力替代品，在各种序列建模任务中提供线性时间复杂度和卓越性能。尽管 SSM 具有优势，但由于扩展的一系列递归矩阵乘法引入的敏感性，像原始 Mamba-2 这样的 SSM 面临着训练困难。在本文中，我们提出了一种先进的架构，通过将 A 乘法分解为多个组并通过分组有限脉冲响应 (FIR) 滤波优化位置编码来缓解这些挑战。这种新结构称为分组 FIR 增强型 SSM (GFSSM)，采用半可分矩阵进行高效计算。此外，受流式语言模型中发现的“注意力下沉”现象的启发，我们采用了类似的机制来增强我们的模型在扩展序列上的稳定性和性能。我们的方法进一步弥合了 SSM 和 Transformer 架构之间的差距，为可扩展和高性能序列建模提供了一条可行的前进道路。]]></description>
      <guid>https://arxiv.org/abs/2408.00244</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:12 GMT</pubDate>
    </item>
    <item>
      <title>Clover-2：回归轻量级推测解码的精确推理</title>
      <link>https://arxiv.org/abs/2408.00264</link>
      <description><![CDATA[arXiv:2408.00264v1 公告类型：新
摘要：大型语言模型 (LLM) 经常出现效率低下的问题，这主要归因于自回归解码的要求与当代 GPU 的架构之间的不一致。最近，回归轻量级推测解码因其在文本生成任务中的显著效率改进而备受关注。这种方法利用轻量级回归草稿模型，如循环神经网络 (RNN) 或单个转换器解码器层，利用顺序信息迭代预测潜在标记。具体而言，RNN 草稿模型在计算上经济实惠，但往往提供较低的准确性，而注意力解码器层模型则表现出相反的特征。本文介绍了 Clover-2，这是 Clover 的高级迭代，Clover 是一种基于 RNN 的草稿模型，旨在实现与注意力解码器层模型相当的准确性，同时保持最小的计算开销。Clover-2 增强了模型架构并结合知识提炼来提高 Clover 的准确性并提高整体效率。我们使用开源的 Vicuna 7B 和 LLaMA3-Instruct 8B 模型进行了实验。结果表明，Clover-2 在各种模型架构中都超越了现有方法，展现了其有效性和稳健性。]]></description>
      <guid>https://arxiv.org/abs/2408.00264</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:12 GMT</pubDate>
    </item>
    <item>
      <title>客户端间非独立同分布上下文内学习</title>
      <link>https://arxiv.org/abs/2408.00144</link>
      <description><![CDATA[arXiv:2408.00144v1 公告类型：新
摘要：大型语言模型 (LLM) 的进步已在多个复杂的自然语言推理任务中显示出其有效性。一个关键挑战仍然是如何有效地将这些模型适应新的或不熟悉的任务。上下文学习 (ICL) 通过从训练数据集中检索与查询相关的一组数据点（称为上下文示例 (ICE)）并在推理过程中将它们作为上下文提供，为少样本适应提供了一种有前途的解决方案。大多数现有研究使用集中式训练数据集，但许多现实世界的数据集可能分布在多个客户端之间，并且远程数据检索可能与成本相关。特别是当客户端数据是非同一独立分布 (non-IID) 时，从客户端检索测试查询所需的一组适当的 ICE 提出了严峻的挑战。在本文中，我们首先表明，在这种具有挑战性的环境中，由于非 IID 性，测试查询在客户端之间会有不同的偏好，而同等的贡献通常会导致性能不佳。然后，我们介绍了一种新方法来解决存在数据使用预算时的分布式非 IID ICL 问题。其原则是，每个客户的适当贡献（预算）应根据该客户的每个查询的偏好来设计。我们的方法使用数据驱动的方式为每个客户分配预算，并针对每个测试查询进行量身定制。通过对各种数据集进行广泛的实证研究，我们的框架相对于竞争基线表现出卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.00144</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:11 GMT</pubDate>
    </item>
    <item>
      <title>使用聚类和提示自动生成自然语言处理的行为测试用例</title>
      <link>https://arxiv.org/abs/2408.00161</link>
      <description><![CDATA[arXiv:2408.00161v1 公告类型：新
摘要：最近针对自然语言处理 (NLP) 模型（例如 Checklist）的行为测试的工作受到软件工程测试中相关范例的启发。它们允许评估一般语言能力和领域理解，因此可以帮助评估概念健全性并识别模型弱点。然而，一个主要的挑战是测试用例的创建。当前的软件包依赖于使用手动开发的半自动化方法，这需要领域专业知识并且可能很耗时。本文介绍了一种通过利用大型语言模型和统计技术的强大功能来开发测试用例的自动化方法。它对文本表示进行聚类以仔细构建有意义的组，然后应用提示技术自动生成最小功能测试 (MFT)。著名的 Amazon Reviews 语料库用于演示我们的方法。我们分析了四种不同分类算法的行为测试配置文件，并讨论了这些模型的局限性和优势。]]></description>
      <guid>https://arxiv.org/abs/2408.00161</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:11 GMT</pubDate>
    </item>
    <item>
      <title>评估法学硕士临床问题成果的课程共享任务</title>
      <link>https://arxiv.org/abs/2408.00122</link>
      <description><![CDATA[arXiv:2408.00122v1 公告类型：新
摘要：本文介绍了我们在达姆施塔特工业大学 2023/2024 年语言技术基础 (FoLT) 课程中组织的一项共享任务，该任务侧重于评估大型语言模型 (LLM) 在生成与健康相关的临床问题的有害答案方面的输出。我们描述了任务设计注意事项并报告了我们从学生那里收到的反馈。我们希望本文中报告的任务和发现与教授自然语言处理 (NLP) 和设计课程作业的教师相关。]]></description>
      <guid>https://arxiv.org/abs/2408.00122</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:10 GMT</pubDate>
    </item>
    <item>
      <title>通过负面注意力分数对齐来纠正大型语言模型中的负面偏见</title>
      <link>https://arxiv.org/abs/2408.00137</link>
      <description><![CDATA[arXiv:2408.00137v1 公告类型：新
摘要：二元决策任务，例如是非问题或答案验证，反映了现实世界中的一个重要场景，例如用户寻求确认他们在特定问题上的决策是否正确。在这项工作中，我们观察到语言模型在复杂推理任务的二元决策中表现出负面偏见。根据我们的观察和基于注意力的模型动力学原理，我们提出了一个负注意力分数（NAS）来系统和定量地制定负面偏见。基于 NAS，我们识别出关注指令中提供的负面标记的注意力头作为二元决策的答案候选，而不管提示中的问题是什么，并验证它们与负面偏见的关联。此外，我们提出了负注意力分数对齐（NASA）方法，这是一种参数高效的微调技术，用于解决提取的负偏差注意力头。来自各种推理任务领域和大型模型搜索空间的实验结果表明，NAS 显着减少了由负偏差引起的精度和召回率之间的差距，同时保留了它们的泛化能力。我们的代码可在 \url{https://github.com/ysw1021/NASA} 上找到。]]></description>
      <guid>https://arxiv.org/abs/2408.00137</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:10 GMT</pubDate>
    </item>
    <item>
      <title>ReLiK：检索和链接，在学术预算内快速准确地进行实体链接和关系提取</title>
      <link>https://arxiv.org/abs/2408.00103</link>
      <description><![CDATA[arXiv:2408.00103v1 公告类型：新
摘要：实体链接 (EL) 和关系提取 (RE) 是自然语言处理中的基本任务，是广泛应用中的关键组件。在本文中，我们提出了 ReLiK，一种用于 EL 和 RE 的检索器-阅读器架构，其中，给定输入文本，检索器模块负责识别可能出现在文本中的候选实体或关系。随后，阅读器模块负责辨别相关的检索到的实体或关系，并建立它们与相应文本跨度的对齐。值得注意的是，我们提出了一种创新的输入表示，将候选实体或关系与文本结合在一起，从而可以在一次前向传递中链接实体或提取关系，并充分利用预训练语言模型的语境化功能，这与以前基于检索器-阅读器的方法不同，后者需要对每个候选进行前向传递。我们对 EL 和 RE 的制定在使用学术预算训练的情况下，在域内和域外基准测试中均实现了最佳性能，并且推理速度比竞争对手快 40 倍。最后，我们展示了我们的架构如何无缝用于信息提取 (cIE)，即 EL + RE，并通过使用同时提取实体和关系的共享读取器来创造新的最佳状态。]]></description>
      <guid>https://arxiv.org/abs/2408.00103</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:09 GMT</pubDate>
    </item>
    <item>
      <title>Gemma 2：以实用规模改进开放语言模型</title>
      <link>https://arxiv.org/abs/2408.00118</link>
      <description><![CDATA[arXiv:2408.00118v1 公告类型：新
摘要：在这项工作中，我们引入了 Gemma 2，这是 Gemma 系列轻量级、最先进的开放模型的新成员，其规模从 20 亿到 270 亿个参数不等。在这个新版本中，我们对 Transformer 架构应用了几项已知的技术修改，例如交错局部全局注意力（Beltagy 等人，2020a）和组查询注意力（Ainslie 等人，2023）。我们还使用知识蒸馏（Hinton 等人，2015）而不是下一个标记预测来训练 2B 和 9B 模型。生成的模型提供了与其规模相称的最佳性能，甚至可以提供比大 2-3 倍的模型更具竞争力的替代方案。我们向社区发布了所有模型。]]></description>
      <guid>https://arxiv.org/abs/2408.00118</guid>
      <pubDate>Fri, 02 Aug 2024 06:21:09 GMT</pubDate>
    </item>
    </channel>
</rss>