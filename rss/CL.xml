<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 14 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过综合偏好强化学习增加自动生成问题的难度</title>
      <link>https://arxiv.org/abs/2410.08289</link>
      <description><![CDATA[arXiv:2410.08289v1 公告类型：新
摘要：随着文化遗产部门越来越多地采用检索增强生成 (RAG) 等技术来提供更加个性化的搜索体验并实现与收藏数据的对话，对专门评估数据集的需求也在增长。虽然端到端系统测试至关重要，但评估各个组件也同样重要。我们的目标是最终的回答任务，这非常适合机器阅读理解 (MRC)。虽然现有的 MRC 数据集涉及一般领域，但它们缺乏文化遗产信息所需的特异性。不幸的是，对于大多数遗产机构来说，手动创建此类数据集的成本过高。本文介绍了一种经济高效的方法，用于使用从合成偏好数据中进行的强化学习（RLHF）来生成难度更大的特定领​​域的 MRC 数据集。我们的方法利用现有问答模型在 SQuAD 子集上的性能来创建难度指标，假设更具挑战性的问题得到正确回答的频率较低。这项研究的贡献包括：（1）一种使用 PPO 和合成数据增加问题难度的方法；（2）该方法有效性的经验证据，包括人工评估；（3）对突发现象进行深入的错误分析和研究；（4）一个开源代码库和一组三个 llama-2-chat 适配器，用于可重复性和适应性。]]></description>
      <guid>https://arxiv.org/abs/2410.08289</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MELO：职业多语言实体链接评估基准</title>
      <link>https://arxiv.org/abs/2410.08319</link>
      <description><![CDATA[arXiv:2410.08319v1 公告类型：新
摘要：我们提出了职业多语言实体链接 (MELO) 基准，这是一个新的 48 个数据集集合，用于评估 21 种语言的实体提及与 ESCO 职业多语言分类法的链接。MELO 是使用高质量、预先存在的人工注释构建的。我们使用简单的词汇模型和通用句子编码器进行实验，在零样本设置中将其作为双编码器进行评估，以建立未来研究的基线。标准化评估的数据集和源代码可在 https://github.com/Avature/melo-benchmark 上公开获取]]></description>
      <guid>https://arxiv.org/abs/2410.08319</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>你知道你在说什么吗？表征查询知识相关性以实现可靠的检索增强生成</title>
      <link>https://arxiv.org/abs/2410.08320</link>
      <description><![CDATA[arXiv:2410.08320v1 公告类型：新
摘要：众所周知，语言模型 (LM) 容易产生幻觉和错误信息。检索增强生成 (RAG) 从外部知识语料库中检索可验证信息以补充 LM 中的参数知识，为这些问题提供了切实可行的解决方案。但是，RAG 的生成质量高度依赖于用户查询与检索到的文档之间的相关性。当查询超出外部知识语料库所代表的知识范围或语料库中的信息过时时，可能会生成不准确的响应。在这项工作中，我们建立了一个统计框架，通过捕获知识的相关性来评估 RAG 系统对查询的回答程度。我们引入了一种在线测试程序，该程序采用拟合优度 (GoF) 测试来检查每个用户查询的相关性，以检测知识相关性低的知识外查询。此外，我们还开发了一个离线测试框架，用于检查一系列用户查询，旨在检测查询分布中的重大变化，这表明知识库不再能够充分支持用户的兴趣。我们通过对八个问答 (QA) 数据集进行系统评估来展示这些策略的能力，结果表明，新的测试框架是提高现有 RAG 系统可靠性的有效解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.08320</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>声音搜索的语言：检查音频搜索引擎中的用户查询</title>
      <link>https://arxiv.org/abs/2410.08324</link>
      <description><![CDATA[arXiv:2410.08324v1 公告类型：新
摘要：本研究在声音搜索引擎的背景下研究了文本、用户编写的搜索查询，涵盖了各种应用，例如拟音、音效和一般音频检索。当前的研究在设计基于文本的音频检索系统时，没有充分解决现实世界用户的需求和行为。为了弥补这一差距，我们分析了来自两个来源的搜索查询：自定义调查和 Freesound 网站查询日志。该调查旨在收集不受限制的假设声音搜索引擎的查询，从而生成一个数据集，该数据集可以在不受现有系统限制的情况下捕获用户意图。该数据集也可以与研究社区共享。相比之下，Freesound 查询日志包含大约 900 万个搜索请求，提供了现实世界使用模式的全面视图。我们的研究结果表明，调查查询通常比 Freesound 查询更长，这表明用户在不受系统限制的情况下更喜欢详细的查询。这两个数据集主要包含基于关键字的查询，很少有调查参与者使用完整的句子。影响调查查询的关键因素包括主要声源、预期用途、感知位置和声源数量。这些见解对于开发以用户为中心、有效的基于文本的音频检索系统至关重要，可增强我们对声音搜索环境中用户行为的理解。]]></description>
      <guid>https://arxiv.org/abs/2410.08324</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估高风险领域中的差异隐私合成数据生成</title>
      <link>https://arxiv.org/abs/2410.08327</link>
      <description><![CDATA[arXiv:2410.08327v1 公告类型：新
摘要：文本数据匿名化的困难阻碍了 NLP 在涉及私人数据的高风险领域（例如医疗保健和社会服务）的开发和部署。匿名性较差的敏感数据不能轻易与注释者或外部研究人员共享，也不能用于训练公共模型。在这项工作中，我们探索了使用差异隐私语言模型生成的合成数据代替真实数据的可行性，以促进这些领域的 NLP 开发而不损害隐私。与之前的工作相比，我们为真实的高风险领域生成合成数据，并提出并进行使用启发式评估来评估数据质量。我们的结果表明，之前的简单评估未能突出合成数据中的效用、隐私和公平性问题。总的来说，我们的工作强调需要进一步改进合成数据生成，以使其成为实现隐私保护数据共享的可行方法。]]></description>
      <guid>https://arxiv.org/abs/2410.08327</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过强化学习探索基于自然语言的儿童高效数字学习策略</title>
      <link>https://arxiv.org/abs/2410.08334</link>
      <description><![CDATA[arXiv:2410.08334v1 公告类型：新
摘要：本文研究了儿童如何使用强化学习 (RL) 框架学习数字，重点关注语言指导的影响。使用强化学习的动机源于其与受控环境中的心理学习理论的相似之处。通过使用最先进的深度强化学习模型，我们模拟和分析了各种形式的语言指导对数字习得的影响。我们的研究结果表明，某些语言结构更有效地提高了 RL 代理的数字理解能力。此外，我们的模型预测了向 RL 代理呈现数字的最佳序列，从而提高了他们的学习速度。这项研究为语言和数字认知之间的相互作用提供了宝贵的见解，对教育策略和旨在支持早期儿童学习的人工智能系统的开发都有影响。]]></description>
      <guid>https://arxiv.org/abs/2410.08334</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非线性二阶动力学描述跨语言和语境的唇部收缩轨迹</title>
      <link>https://arxiv.org/abs/2410.08351</link>
      <description><![CDATA[arXiv:2410.08351v1 公告类型：新
摘要：我们研究了英语和普通话中 /b/ 和 /m/ 发音过程中唇音收缩轨迹的动态。我们发现，在不同的语言和语境中，瞬时位移与瞬时速度的比率从运动开始到运动结束通常遵循指数衰减曲线。我们将这一经验发现形式化为微分方程，并结合点吸引子动力学假设，推导出一个描述唇音收缩轨迹的非线性二阶动力学系统。该方程只有两个参数，T 和 r。T 对应于目标状态，r 对应于运动速度。因此，每个参数都对应于语音相关的控制维度。非线性回归表明该模型可以很好地拟合单个运动轨迹。此外，从模型中模拟的轨迹在质量上与经验轨迹相匹配，并捕捉关键的运动变量，如持续时间、峰值速度和达到峰值速度的时间。该模型构成了对单个发音运动动态的提议，从而为理解对发音运动学的其他影响（如韵律、运动间协调和随机噪声）提供了一个新的基础。]]></description>
      <guid>https://arxiv.org/abs/2410.08351</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>揭示新冠肺炎的社会动态：推特上疫苗和症状话语的历时语义分析</title>
      <link>https://arxiv.org/abs/2410.08352</link>
      <description><![CDATA[arXiv:2410.08352v1 公告类型：新
摘要：社交媒体被认为是了解舆情动态和社会影响的重要来源，因为社交媒体每天产生大量文本数据，人们在这些平台上互动的行为“不受约束”。然而，由于语义转移现象，即词义随时间演变，这种分析具有挑战性。本文提出了一种无监督动态词嵌入方法，用于在没有预定义锚词的情况下捕捉社交媒体数据中的纵向语义变化。该方法利用词共现统计和动态更新来随时间调整嵌入，解决了数据稀疏、分布不平衡和协同语义效应的挑战。在大型 COVID-19 Twitter 数据集上进行评估后，该方法揭示了不同大流行阶段疫苗和症状相关实体的语义演变模式，以及它们与现实世界统计数据的潜在相关性。我们的主要贡献包括动态嵌入技术、COVID-19 语义转变的实证分析，以及关于增强计算社会科学研究的语义转变建模的讨论。这项研究能够捕捉社交媒体上的纵向语义动态，以了解公共话语和集体现象。]]></description>
      <guid>https://arxiv.org/abs/2410.08352</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>瓶中合并：可微分自适应合并 (DAM) 以及从平均到自动化的路径</title>
      <link>https://arxiv.org/abs/2410.08371</link>
      <description><![CDATA[arXiv:2410.08371v1 公告类型：新
摘要：通过合并模型，AI 系统可以结合不同语言模型的不同优势，实现多种能力之间的平衡，而无需进行大量的再训练。然而，由于训练方法和微调的差异，集成过程可能很复杂，通常需要专业知识和反复改进。本文探讨了各种复杂程度的模型合并技术，研究了自动化方法（如进化策略）与超参数驱动方法（如 DARE、TIES-Merging）和更简单的方法（如 Model Soups）相比的优势。此外，我们引入了可微分自适应合并 (DAM)，这是一种高效的自适应合并方法，可替代进化合并，通过缩放系数优化模型集成，最大限度地减少计算需求。我们的研究结果表明，即使是简单的平均方法（如 Model Soups），在模型相似性较高时也能表现出色，这突显了每种技术独特的优势和局限性。我们在 GitHub 上开源了 DAM，包括实现代码和实验流程：https://github.com/arcee-ai/DAM。]]></description>
      <guid>https://arxiv.org/abs/2410.08371</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估社交媒体自杀风险检测的 Transformer 模型</title>
      <link>https://arxiv.org/abs/2410.08375</link>
      <description><![CDATA[arXiv:2410.08375v1 公告类型：新
摘要：检测社交媒体中的自杀风险是一项关键任务，具有潜在的挽救生命的意义。本文介绍了一项利用最先进的自然语言处理解决方案识别社交媒体帖子中自杀风险的研究，作为 kubapok 团队开展的“IEEE BigData 2024 Cup：检测社交媒体上的自杀风险”的提交。我们尝试了以下基于 Transformer 的模型配置：微调的 DeBERTa、具有 CoT 和少样本提示的 GPT-4o 以及微调的 GPT-4o。任务设置是将社交媒体帖子分为四类：指标、想法、行为和尝试。我们的研究结果表明，微调的 GPT-4o 模型优于其他两种配置，在识别自杀风险方面实现了高精度。值得注意的是，我们的模型在比赛中获得了第二名。通过证明简单的通用模型可以获得最先进的结果，我们认为这些模型加上最少的调整，有可能成为社交媒体上自动自杀风险检测的有效解决方案。]]></description>
      <guid>https://arxiv.org/abs/2410.08375</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GUS-Net：具有概括、不公平和刻板印象的文本中的社会偏见分类</title>
      <link>https://arxiv.org/abs/2410.08388</link>
      <description><![CDATA[arXiv:2410.08388v1 公告类型：新
摘要：自然语言处理 (NLP) 中的偏见检测是一项关键挑战，尤其是随着大型语言模型 (LLM) 在各个领域的使用越来越多。本文介绍了 GUS-Net，这是一种创新的偏见检测方法，侧重于三种主要类型的偏见：（G）概括、（U）不公平和（S）刻板印象。GUS-Net 利用生成式 AI 和自动化代理来创建全面的合成数据集，从而实现强大的多标签标记分类。我们的方法通过结合预训练模型的上下文编码来增强传统的偏见检测方法，从而提高了识别有偏见实体的准确性和深度。通过大量实验，我们证明 GUS-Net 优于最先进的技术，在准确性、F1 分数和汉明损失方面取得了卓越的表现。研究结果凸显了 GUS-Net 在捕捉不同背景下的各种偏见方面的有效性，使其成为检测文本中社会偏见的宝贵工具。这项研究有助于 NLP 领域持续努力解决隐性偏见，为未来各个领域的研究和应用提供了途径。用于创建数据集和模型的 Jupyter 笔记本可在以下位置获取：https://github.com/Ethical-Spectacle/fair-ly/tree/main/resources。
警告：本文包含有害语言的示例，建议读者谨慎阅读。]]></description>
      <guid>https://arxiv.org/abs/2410.08388</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 KV 预测缩短首次标记时间</title>
      <link>https://arxiv.org/abs/2410.08391</link>
      <description><![CDATA[arXiv:2410.08391v1 公告类型：新
摘要：使用基于转换器的语言模型进行推理始于提示处理步骤。在此步骤中，模型生成第一个输出标记并存储未来生成步骤所需的 KV 缓存。此提示处理步骤在计算上可能很昂贵，当提示长度或批次大小增加时，边缘设备上的十亿参数模型需要 10 秒或更长时间。这会通过在模型的输出中引入显着的延迟来降低用户体验。为了减少生成预训练模型的第一个输出（称为“第一个标记时间”或 TTFT）所花费的时间，我们引入了一种称为 KV 预测的新方法。在我们的方法中，一个小的辅助模型用于处理提示并生成基础模型使用的 KV 缓存的近似值。然后将此近似的 KV 缓存与基础模型一起用于自回归生成，而无需再次查询辅助模型。我们证明，与基线相比，我们的方法产生了帕累托最优的效率-准确度权衡。在 TriviaQA 上，我们展示了在一系列 TTFT FLOPs 预算范围内相对准确度的提高，范围在 $15\%-50\%$ 之间。我们还展示了在固定 TTFT FLOPs 预算下，HumanEval Python 代码完成的准确度提高高达 $30\%$。此外，我们在 Apple M2 Pro CPU 上对模型进行了基准测试，并证明了我们在 FLOPs 方面的改进转化为硬件上的 TTFT 加速。我们在 https://github.com/apple/corenet/tree/main/projects/kv-prediction 上发布了我们的代码。]]></description>
      <guid>https://arxiv.org/abs/2410.08391</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>幻觉对关系提取合成训练数据的影响</title>
      <link>https://arxiv.org/abs/2410.08393</link>
      <description><![CDATA[arXiv:2410.08393v1 公告类型：新
摘要：关系提取对于构建知识图谱至关重要，大量高质量数据集是训练、微调和评估模型的基础。生成数据增强 (GDA) 是扩展此类数据集的常用方法。然而，这种方法通常会引入幻觉，例如虚假事实，其对关系提取的影响仍未得到充分探索。在本文中，我们研究了幻觉对文档和句子级别关系提取性能的影响。我们的实证研究表明，幻觉大大损害了模型从文本中提取关系的能力，召回率降低了 19.1% 到 39.2%。我们发现相关的幻觉会损害模型的性能，而不相关的幻觉的影响微乎其微。此外，我们还开发了检测幻觉的方法，以提高数据质量和模型性能。我们的方法成功地将文本分类为“幻觉”或“干净”，实现了 83.8% 和 92.2% 的高 F1 分数。这些方法不仅有助于消除幻觉，还有助于估计其在数据集中的普遍性，这对于选择高质量数据至关重要。总的来说，我们的工作证实了相关幻觉对关系提取模型有效性的深远影响。]]></description>
      <guid>https://arxiv.org/abs/2410.08393</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>理解大型语言模型的参数和上下文知识之间的相互作用</title>
      <link>https://arxiv.org/abs/2410.08414</link>
      <description><![CDATA[arXiv:2410.08414v1 公告类型：新
摘要：大型语言模型 (LLM) 在预训练期间编码大量知识（参数知识或 PK），并且可以通过合并上下文知识 (CK) 进一步增强。LLM 能否有效地将其内部 PK 与外部 CK 相结合以解决复杂问题？在本文中，我们研究了 PK 和 CK 之间的动态交互，将它们的关系分为四种类型：支持性、互补性、冲突性和无关性。为了支持这项调查，我们引入了 ECHOQA，这是一个涵盖科学、事实和常识知识的基准。我们的结果表明，当上下文信息可用时，LLM 倾向于抑制其 PK，即使它是互补的或不相关的。虽然量身定制的说明可以鼓励 LLM 更多地依赖他们的 PK，但他们仍然难以充分利用它。这些发现揭示了 LLM 的一个关键弱点，引发了人们对它们在知识密集型任务中的可靠性的担忧。资源可在https://github.com/sitaocheng/Knowledge Interplay获取。]]></description>
      <guid>https://arxiv.org/abs/2410.08414</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>o10 个大型语言模型的检索增强生成及其在评估医疗健康方面的普遍性</title>
      <link>https://arxiv.org/abs/2410.08431</link>
      <description><![CDATA[arXiv:2410.08431v1 公告类型：新
摘要：大型语言模型 (LLM) 显示出医疗应用的潜力，但通常缺乏专业的临床知识。检索增强生成 (RAG) 允许使用特定领域的信息进行定制，使其适用于医疗保健。本研究评估了 RAG 模型在确定手术适应性和提供术前指导方面的准确性、一致性和安全性。我们使用 35 个本地和 23 个国际术前指南开发了 LLM-RAG 模型，并根据人工生成的响应对其进行了测试。总共评估了 3,682 个回复。使用 Llamaindex 处理临床文件，并评估了 10 个 LLM，包括 GPT3.5、GPT4 和 Claude-3。分析了 14 种临床场景，重点关注术前指导的七个方面。使用既定的指南和专家判断来确定正确的反应，并以人工生成的答案作为比较。 LLM-RAG 模型在 20 秒内生成响应，明显快于临床医生（10 分钟）。GPT4 LLM-RAG 模型实现了最高的准确度（96.4% vs. 86.6%，p=0.016），没有幻觉，并能产生与临床医生相当的正确指令。结果与当地和国际指南一致。这项研究展示了 LLM-RAG 模型在术前医疗保健任务中的潜力，突出了它们的效率、可扩展性和可靠性。]]></description>
      <guid>https://arxiv.org/abs/2410.08431</guid>
      <pubDate>Mon, 14 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>