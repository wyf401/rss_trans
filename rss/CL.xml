<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 25 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>EM 回归：用于 QA 评估的实体驱动答案集扩展</title>
      <link>https://arxiv.org/abs/2404.15650</link>
      <description><![CDATA[arXiv:2404.15650v1 公告类型：新
摘要：最近，直接使用大型语言模型（LLM）已被证明是评估 QA 模型最可靠的方法。然而，它的可解释性有限、成本高和环境危害。为了解决这些问题，我们建议使用软 EM 和实体驱动的答案集扩展。基于表面形式通常根据实体类型遵循特定模式的观察，我们的方法扩展了黄金答案集以包括不同的表面形式。实验结果表明，我们的方法大大优于传统的评估方法。此外，我们的评估方法的可靠性与基于法学硕士的评估方法相当，同时具有高可解释性和减少环境危害的优点。]]></description>
      <guid>https://arxiv.org/abs/2404.15650</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:58 GMT</pubDate>
    </item>
    <item>
      <title>KS-LLM：带有问答证据文档的大型语言模型的知识选择</title>
      <link>https://arxiv.org/abs/2404.15660</link>
      <description><![CDATA[arXiv:2404.15660v1 公告类型：新
摘要：大型语言模型（LLM）存在幻觉问题，在应用于知识密集型任务时面临重大挑战。一种有前景的方法是利用证据文档作为额外的支持知识，这些知识可以通过检索或生成来获得。然而，现有的方法直接利用证据文档的全部内容，这可能会引入噪声信息并损害大型语言模型的性能。为了解决这个问题，我们提出了一种新颖的大型语言模型知识选择（KS-LLM）方法，旨在从证据文档中识别有价值的信息。 KS-LLM方法利用三元组从证据文档中有效地选择有利于回答问题的知识片段。具体来说，我们首先根据输入问题生成三元组，然后从证据文档中选择与三元组最相似的证据句子，最后将证据句子和三元组结合起来辅助大型语言模型生成答案。在 TriviaQA、WebQ 和 NQ 等多个问答数据集上的实验比较表明，所提出的方法超越了基线并取得了最佳结果。]]></description>
      <guid>https://arxiv.org/abs/2404.15660</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:58 GMT</pubDate>
    </item>
    <item>
      <title>用于索赔验证的最小证据组识别</title>
      <link>https://arxiv.org/abs/2404.15588</link>
      <description><![CDATA[arXiv:2404.15588v1 公告类型：新
摘要：现实世界中的声明验证（例如，针对从网络检索到的大量候选证据）通常需要识别和聚合一组完整的证据，这些证据共同为声明提供全面支持。当存在可用于从不同角度验证主张的不同证据集时，问题变得尤其具有挑战性。在本文中，我们正式定义并研究了识别此类最小证据组（MEG）以进行声明验证的问题。我们证明，基于给定证据组是否为主张提供全部/部分支持的蕴涵推断，可以从 Set Cover 问题中减少 MEG 识别。与 LLM 提示相比，我们提出的方法在 WiCE 和 SciFact 数据集上实现了 18.4% 和 34.8% 的绝对改进。最后，我们展示了 MEG 在索赔生成等下游应用中的优势。]]></description>
      <guid>https://arxiv.org/abs/2404.15588</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:57 GMT</pubDate>
    </item>
    <item>
      <title>从结构化数据生成业务洞察的法学硕士/基于规则的混合方法</title>
      <link>https://arxiv.org/abs/2404.15604</link>
      <description><![CDATA[arXiv:2404.15604v1 公告类型：新
摘要：在业务数据分析领域，从庞大且多样化的数据集中提取可行见解的能力对于做出明智的决策和保持竞争优势至关重要。传统的基于规则的系统虽然可靠，但在面对现代业务数据的复杂性和动态性时往往表现不佳。相反，人工智能 (AI) 模型，特别是大型语言模型 (LLM)，在模式识别和预测分析方面具有巨大潜力，但可能缺乏特定业务应用所需的精度。本文探讨了混合方法的功效，该方法将基于规则的系统的稳健性与法学硕士的自适应能力相结合，以生成可操作的业务见解。]]></description>
      <guid>https://arxiv.org/abs/2404.15604</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:57 GMT</pubDate>
    </item>
    <item>
      <title>CodeIP：用于大型代码语言模型的语法引导多位水印</title>
      <link>https://arxiv.org/abs/2404.15639</link>
      <description><![CDATA[arXiv:2404.15639v1 公告类型：新
摘要：随着大型语言模型（LLM）越来越多地用于自动化代码生成，人们通常希望知道代码是否是人工智能生成的以及由哪个模型生成的，特别是出于保护工业知识产权（IP）和防止学术界使用的目的。教育中的不当行为。将水印合并到机器生成的内容中是提供代码来源的一种方法，但现有的解决方案仅限于单个位或缺乏灵活性。我们推出了 CodeIP，这是一种用于基于 LLM 的代码生成的新水印技术。 CodeIP 能够插入多位信息，同时保留生成代码的语义，从而提高插入水印的强度和多样性。这是通过训练类型预测器来预测下一个标记的后续语法类型以增强生成代码的语法和语义正确性来实现的。对五种编程语言的真实数据集进行的实验展示了 CodeIP 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.15639</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:57 GMT</pubDate>
    </item>
    <item>
      <title>检索头机械地解释长上下文事实</title>
      <link>https://arxiv.org/abs/2404.15574</link>
      <description><![CDATA[arXiv:2404.15574v1 公告类型：新
摘要：尽管长上下文语言模型最近取得了进展，但基于 Transformer 的模型如何表现出从长上下文中的任意位置检索相关信息的能力仍然难以捉摸。本文旨在解决这个问题。我们对各种模型的系统调查表明，一种特殊类型的注意力头主要负责检索信息，我们将其称为检索头。我们确定了检索头的有趣属性：（1）通用性：所有具有长上下文能力的探索模型都有一组检索头； （2）稀疏：只有一小部分（小于5%）的注意力头被检索。 (3) 内在的：检索头已经存在于用短上下文预训练的模型中。当通过持续预训练来扩展上下文长度时，执行信息检索的仍然是同一组头。 (4)动态激活：以Llama-2 7B为例，无论上下文如何变化，12个检索头始终关注所需的信息。其余的检索头在不同的上下文中被激活。 （5）因果性：完全剪枝检索头会导致无法检索到相关信息并产生幻觉，而随机剪枝非检索头不会影响模型的检索能力。我们进一步表明，检索头强烈影响思想链（CoT）推理，其中模型需要经常引用问题和先前生成的上下文。相反，模型使用其内在知识直接生成答案的任务受屏蔽检索头的影响较小。这些观察结果共同解释了模型的哪个内部部分从输入标记中寻求信息。我们相信我们的见解将促进未来关于减少幻觉、改进推理和压缩 KV 缓存的研究。]]></description>
      <guid>https://arxiv.org/abs/2404.15574</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:56 GMT</pubDate>
    </item>
    <item>
      <title>基础大型语言模型可以协助进行药品制造调查吗？</title>
      <link>https://arxiv.org/abs/2404.15578</link>
      <description><![CDATA[arXiv:2404.15578v1 公告类型：新
摘要：通用大型语言模型（LLM）如生成预训练变压器（GPT）和大型语言模型元人工智能（LLaMA）近年来引起了广泛关注。有强有力的证据表明这些模型可以在各种自然语言处理任务中表现出色。然而，如何利用它们来处理特定领域的用例并驱动价值仍然是一个悬而未决的问题。在这项工作中，我们专注于特定的用例，即药品制造调查，并建议利用组织中制造事件和偏差的历史记录有助于解决和结束新案例，或降低新制造活动的风险。使用从不同产品线中选择的小型但多样化的实际制造偏差数据集，我们评估和量化了三个通用 LLM（GPT-3.5、GPT-4 和 Claude-2）在执行与上述目标相关的任务时的能力。特别是，（1）法学硕士能够自动从非结构化数据中提取特定信息（例如案例的根本原因）的过程，以及（2）通过在数据库上执行语义搜索来识别相似或相关偏差的可能性的历史记录进行审查。虽然我们的结果表明 GPT-4 和 Claude-2 在信息提取任务中具有很高的准确性，但我们讨论了 LLM 的明显推理和幻觉行为之间复杂相互作用的情况作为风险因素。此外，我们还表明，偏差描述向量嵌入的语义搜索可用于高度准确地识别相似记录，例如具有相似类型缺陷的记录。我们讨论进一步的改进，以提高类似记录识别的准确性。]]></description>
      <guid>https://arxiv.org/abs/2404.15578</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:56 GMT</pubDate>
    </item>
    <item>
      <title>走向大型语言模型逻辑推理能力的系统评估</title>
      <link>https://arxiv.org/abs/2404.15522</link>
      <description><![CDATA[arXiv:2404.15522v1 公告类型：新
摘要：最近开发的大型语言模型（LLM）已被证明在广泛的语言理解任务中表现出色。但是，他们真的能对自然语言进行“推理”吗？这个问题一直受到广泛的研究关注，并且许多推理技能（例如常识、数字和定性）都得到了研究。然而，与“逻辑推理”相关的关键技能仍未得到充分探索。现有研究法学硕士推理能力的工作仅关注命题逻辑和一阶逻辑的几个推理规则（例如肯定前件和托伦斯）。针对上述限制，我们综合评估了法学硕士在命题逻辑、一阶逻辑和非单调逻辑的 25 种不同推理模式上的逻辑推理能力。为了实现系统评估，我们引入了 LogicBench，这是一个专注于单个推理规则的使用的自然语言问答数据集。我们使用思维链提示对 GPT-4、ChatGPT、Gemini、Llama-2 和 Mistral 等一系列法学硕士进行了详细分析。实验结果表明，现有的法学硕士在 LogicBench 上表现不佳；尤其是，他们在处理涉及复杂推理和否定的情况时遇到困难。此外，他们有时会忽略推理得出正确结论所必需的上下文信息。我们相信，我们的工作和发现有助于未来评估和增强法学硕士逻辑推理能力的研究。数据和代码可在 https://github.com/Mihir3009/LogicBench 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.15522</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:55 GMT</pubDate>
    </item>
    <item>
      <title>PRISM：使用大型语言模型进行语义临床试验匹配的患者记录解释</title>
      <link>https://arxiv.org/abs/2404.15549</link>
      <description><![CDATA[arXiv:2404.15549v1 公告类型：新
摘要：临床试验匹配是确定患者可能符合条件的试验的任务。通常，这项任务是劳动密集型的，需要根据临床试验严格的纳入和排除标准对患者电子健康记录 (EHR) 进行详细验证。这个过程是手动的、耗时的，而且难以扩大规模，导致许多患者错过了潜在的治疗选择。大型语言模型 (LLM) 的最新进展使得自动化患者试验匹配成为可能，正如多项并发研究显示的那样。然而，目前的方法仅限于受限的、通常是合成的数据集，这些数据集不能充分反映现实世界医疗数据中遇到的复杂性。在这项研究中，我们首次使用现实世界的 EHR 对临床试验匹配进行了端到端的大规模实证评估。我们的研究展示了 LLM 能够准确地将患者与合适的临床试验进行匹配的能力。我们使用专有的 LLM（包括 GPT-4 和 GPT-3.5）以及我们自定义的微调模型 OncoLLM 进行了实验，结果表明，尽管 OncoLLM 的规模明显较小，但它不仅表现优于 GPT-3.5，而且与合格医生的表现相当。所有实验均在现实世界的 EHR 上进行，其中包括来自美国一家癌症中心的临床记录和可用的临床试验。]]></description>
      <guid>https://arxiv.org/abs/2404.15549</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:55 GMT</pubDate>
    </item>
    <item>
      <title>CASPR：对比总结的自动评估指标</title>
      <link>https://arxiv.org/abs/2404.15565</link>
      <description><![CDATA[arXiv:2404.15565v1 公告类型：新
摘要：从一组来源评论中总结有关实体（例如酒店、电话）的比较意见（通常称为对比总结）可以极大地帮助用户做出决策。然而，在不依赖人类评估的情况下可靠地测量输出摘要的对比度仍然是一个悬而未决的问题。先前的工作提出了基于标记重叠的指标，即独特性得分，来衡量对比度，但没有考虑对保留意义的词汇变化的敏感性。在这项工作中，我们提出了一种自动评估指标 CASPR，以更好地衡量一对摘要之间的对比度。我们的指标基于一种简单且轻量级的方法，该方法利用自然语言推理 (NLI) 任务来测量对比度，方法是将评论分段为单个声明句子，并仔细聚合它们之间的 NLI 分数以得出摘要级别的分数。我们将 CASPR 与独特性评分以及基于 BERTScore 的简单但强大的基线进行比较。我们在先前数据集 CoCoTRIP 上的结果表明，与基线相比，CASPR 可以更可靠地捕获摘要对的对比性。]]></description>
      <guid>https://arxiv.org/abs/2404.15565</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:55 GMT</pubDate>
    </item>
    <item>
      <title>Killkan：带有形态句法信息的克丘亚语自动语音识别数据集</title>
      <link>https://arxiv.org/abs/2404.15501</link>
      <description><![CDATA[arXiv:2404.15501v1 公告类型：新
摘要：本文介绍了 Killkan，这是厄瓜多尔本土语言 Kichwa 语言的第一个自动语音识别（ASR）数据集。 Kichwa 是一种资源极少的濒危语言，在 Killkan 之前还没有任何资源可以将 Kichwa 纳入自然语言处理的应用中。该数据集包含大约 4 小时的音频，包括转录、西班牙语翻译以及通用依赖关系格式的形态句法注释。音频数据取自 Kichwa 的一个公开广播节目。本文还提供了数据集的语料库语言分析，特别关注 Kichwa 的凝集形态以及与西班牙语的频繁语码转换。实验表明，尽管数据集规模较小，但该数据集使得为 Kichwa 开发第一个质量可靠的 ASR 系统成为可能。该数据集、ASR 模型以及用于开发它们的代码将公开可用。因此，我们的研究积极展示了资源建设及其在低资源语言及其社区中的应用。]]></description>
      <guid>https://arxiv.org/abs/2404.15501</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:54 GMT</pubDate>
    </item>
    <item>
      <title>ToM-LM：将心理理论推理委托给大型语言模型中的外部符号执行器</title>
      <link>https://arxiv.org/abs/2404.15515</link>
      <description><![CDATA[arXiv:2404.15515v1 公告类型：新
摘要：心理理论（ToM）是指个体将心理状态归因于他人的能力。虽然大型语言模型 (LLM) 在 ToM 能力方面表现出了一些希望，但它们仍然难以应对复杂的 ToM 推理。我们的方法利用外部符号执行器，特别是 SMCDEL 模型检查器，并进行微调以提高法学硕士的 ToM 推理能力。在我们的方法中，法学硕士首先通过成对的自然语言和 ToM 问题的符号表述表示进行微调，然后指示使用一次性上下文示例生成符号表述。然后生成的符号公式由 SMCDEL 模型检查器执行，以进行透明且可验证的 ToM 推理并给出最终结果。我们证明，我们的方法 ToM-LM 比所有构建的基线都有显着改进。我们的研究提出了一种关于外化 ToM 推理的特定组成部分（主要是关于信念的推理）的新颖观点，并建议将其推广到 ToM 推理的其他方面。]]></description>
      <guid>https://arxiv.org/abs/2404.15515</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:54 GMT</pubDate>
    </item>
    <item>
      <title>XC-Cache：交叉参与缓存上下文以实现高效的 LLM 推理</title>
      <link>https://arxiv.org/abs/2404.15420</link>
      <description><![CDATA[arXiv:2404.15420v1 公告类型：新
摘要：上下文学习（ICL）方法通常利用提示来根据参考信息生成仅解码器的语言模型。由于自注意力操作的二次成本，上下文的即时处理效率低下，因此需要缓存。然而，缓存变压器状态很容易需要几乎与模型参数一样多的空间。当事先不知道正确的上下文时，缓存 ICL 可能会很困难。这项工作通过引入模型来解决这些限制，这些模型受编码器-解码器架构的启发，使用交叉注意力来在没有提示的情况下对参考文本进行条件生成。更准确地说，我们利用预训练的仅解码器模型，并且仅训练少量的添加层。我们使用问答（QA）作为测试平台来评估我们的模型执行条件生成的能力，并观察到它们的性能优于 ICL，与微调提示的 LLM 相当，并且相对于标准 KV 缓存大幅减少了空间占用：两个数量级。]]></description>
      <guid>https://arxiv.org/abs/2404.15420</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:53 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型以惊人的准确度识别网络钓鱼电子邮件：性能比较分析</title>
      <link>https://arxiv.org/abs/2404.15485</link>
      <description><![CDATA[arXiv:2404.15485v1 公告类型：新
摘要：网络钓鱼是几十年来流行的网络犯罪策略，仍然是当今数字世界的重大威胁。通过利用巧妙的社会工程元素和现代技术，网络犯罪以许多个人、企业和组织为目标，以利用信任和安全。这些网络攻击者通常以许多值得信赖的形式伪装成合法来源。通过巧妙地利用紧迫感、恐惧、社会认同等心理因素和其他操纵策略，网络钓鱼者可以引诱个人泄露敏感和个性化的信息。基于现代技术中这一普遍存在的问题，本文旨在分析 15 种大型语言模型 (LLM) 在检测网络钓鱼尝试方面的有效性，特别关注一组随机的“419 诈骗”电子邮件。目标是根据预定义的标准分析包含电子邮件元数据的文本文件，确定哪些法学硕士可以准确检测网络钓鱼电子邮件。实验得出结论，以下模型 ChatGPT 3.5、GPT-3.5-Turbo-Instruct 和 ChatGPT 在检测网络钓鱼电子邮件方面最有效。]]></description>
      <guid>https://arxiv.org/abs/2404.15485</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:53 GMT</pubDate>
    </item>
    <item>
      <title>MEDIQA-CORR 2024 上的 IryoNLP：解决医疗机构肩上的医疗错误检测和纠正任务</title>
      <link>https://arxiv.org/abs/2404.15488</link>
      <description><![CDATA[arXiv:2404.15488v1 公告类型：新
摘要：在应用于临床领域的自然语言处理中，利用大型语言模型已成为临床笔记错误检测和纠正的有前途的途径，这是一项知识密集型任务，注释数据稀缺。本文介绍了 MedReAct&#39;N&#39;MedReFlex，它利用了一套由四种基于 LLM 的医疗代理组成的套件。 MedReAct 代理通过观察、分析和采取行动来启动该过程，生成轨迹来指导搜索以瞄准临床记录中的潜在错误。随后，MedEval 代理雇用五名评估员来评估目标错误和建议的纠正。如果 MedReAct 的行动证明不够，MedReFlex 代理会进行干预，进行反思分析并提出替代策略。最后，MedFinalParser 代理格式化最终输出，保留原始样式，同时确保纠错过程的完整性。我们方法的核心组成部分是基于 ClinicalCorp 语料库的 RAG 管道。在包含临床指南和信息的其他知名来源中，我们预处理并发布了用于临床 RAG 应用的开源 MedWiki 数据集。我们的结果证明了我们通过 MedReAct&#39;N&#39;MedReFlex 框架与 ClinicalCorp 合作的 RAG 方法的核心作用。它在 MEDIQA-CORR 2024 年最终排行榜上排名第九。]]></description>
      <guid>https://arxiv.org/abs/2404.15488</guid>
      <pubDate>Thu, 25 Apr 2024 21:14:53 GMT</pubDate>
    </item>
    </channel>
</rss>