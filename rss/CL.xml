<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 05 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>大型语言模型在模拟人类专家对社交媒体上加热烟草产品公众情绪评价方面的准确性</title>
      <link>https://arxiv.org/abs/2502.01658</link>
      <description><![CDATA[arXiv:2502.01658v1 公告类型：新
摘要：社交媒体上替代烟草产品的情绪分析对于烟草控制研究非常重要。大型语言模型 (LLM) 可以帮助简化劳动密集型的人类情绪分析过程。本研究考察了 LLM 在复制有关加热烟草产品 (HTP) 的社交媒体消息的人类情绪评估方面的准确性。
该研究使用 GPT-3.5 和 GPT-4 Turbo 对 500 条 Facebook 和 500 条 Twitter 消息进行分类，包括反 HTP、支持 HTP 和中性消息。这些模型对每条消息进行最多 20 次评估，并将其大多数标签与人类评估者进行比较。
结果表明，GPT-3.5 准确复制了 Facebook 消息的人类情绪 61.2%，Twitter 消息的准确率为 57.0%。GPT-4 Turbo 表现更好，Facebook 的准确率为 81.7%，Twitter 的准确率为 77.0%。使用三个响应实例，GPT-4 Turbo 实现了二十个实例中 99% 的准确率。与中性消息相比，GPT-4 Turbo 对反对和支持 HTP 消息的准确率也更高。GPT-3.5 的错误分类通常涉及将反对或支持 HTP 消息标记为中性或不相关，而 GPT-4 Turbo 在所有类别中都表现出改进。
总之，LLM 可用于 HTP 相关社交媒体消息的情绪分析，与人类专家相比，GPT-4 Turbo 的准确率达到 80% 左右。然而，由于不同情绪类别的准确率存在差异，因此存在歪曲整体情绪的风险。]]></description>
      <guid>https://arxiv.org/abs/2502.01658</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推测集成：通过推测实现快速大型语言模型集成</title>
      <link>https://arxiv.org/abs/2502.01662</link>
      <description><![CDATA[arXiv:2502.01662v1 公告类型：新
摘要：集成方法通过组合多个模型来增强大型语言模型 (LLM)，但计算成本高昂。在本文中，我们介绍了 Speculative Ensemble，这是一种在不牺牲性能的情况下加速 LLM 集成的新框架，其灵感来自 Speculative Decoding - 其中小型提议模型按顺序生成标记，而较大的目标模型并行验证它们。我们的方法建立在两个关键见解之上：（1）验证分布可以是提议模型和目标模型的集成分布，（2）交替使用每个模型作为提议者和验证者可以进一步提高效率。我们将这种方法推广到具有 n 个模型的集成，并从理论上证明 SE 永远不会比标准集成慢，通常可以实现更快的速度。大量实验表明，与标准集成技术相比，速度提高了 1.11 倍至 2.23 倍，而不会影响生成质量。我们的代码可以在 https://github.com/Kamichanw/Speculative-Ensemble/ 上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.01662</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 XLNet 对人类亚肺病毒 (HMPV) 进行情绪分析的可解释 AI</title>
      <link>https://arxiv.org/abs/2502.01663</link>
      <description><![CDATA[arXiv:2502.01663v1 公告类型：新
摘要：2024 年，中国爆发人类偏肺病毒 (HMPV)，随后蔓延至英国和其他国家，引起了公众的极大关注。虽然 HMPV 通常会引起轻微症状，但它对脆弱人群的影响促使卫生当局强调预防措施。本文探讨了情绪分析如何通过分析社交媒体数据来增强我们对公众对 HMPV 的反应的理解。我们应用了 Transformer 模型，特别是 XLNet，在情绪分类中实现了 93.50% 的准确率。此外，我们通过 SHAP 使用可解释的 AI (XAI) 来提高模型透明度。]]></description>
      <guid>https://arxiv.org/abs/2502.01663</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于印度语结构化问答的多语言状态空间模型</title>
      <link>https://arxiv.org/abs/2502.01673</link>
      <description><![CDATA[arXiv:2502.01673v1 公告类型：新
摘要：印度语的多样性和复杂性对自然语言处理 (NLP) 任务提出了独特的挑战，特别是在问答 (QA) 领域。为了应对这些挑战，本文探讨了状态空间模型 (SSM) 的应用，以构建针对印度语的高效且具有上下文感知的 QA 系统。SSM 特别适合这项任务，因为它们能够对序列数据中的长期和短期依赖关系进行建模，使其能够很好地处理印度语言特有的丰富形态、复杂语法和上下文复杂性。我们在代表各种印度语的不同数据集中评估了多个 SSM 架构，并对它们的性能进行了比较分析。我们的结果表明，这些模型有效地捕捉了语言的细微差别，从而显著改善了问题解释、上下文对齐和答案生成。这项工作代表了 SSM 首次应用于印度语问答任务，为该领域的未来研究奠定了基础基准。我们建议对现有的 SSM 框架进行增强，以优化其在印度语中普遍存在的低资源环境和多语言场景中的适用性。]]></description>
      <guid>https://arxiv.org/abs/2502.01673</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>同行评审毒性检测基准：使用新数据集的一项具有挑战性的任务</title>
      <link>https://arxiv.org/abs/2502.01676</link>
      <description><![CDATA[arXiv:2502.01676v1 公告类型：新 
摘要：同行评审对于通过建设性批评推动和改进科学至关重要。然而，有害的反馈会打击作者的积极性并阻碍科学进步。这项工作探索了一个重要但尚未得到充分探索的领域：检测同行评审中的毒性。我们首先在四个不同的类别中定义同行评审中的毒性，并从 OpenReview 平台上整理一个同行评审数据集，并由人类专家根据这些定义进行注释。利用这个数据集，我们对各种模型进行了基准测试，包括一个专用的毒性检测模型、一个情绪分析模型、几个开源大型语言模型 (LLM) 和两个闭源 LLM。我们的实验探索了不同提示粒度（从粗粒度到细粒度指令）对模型性能的影响。值得注意的是，像 GPT-4 这样的最先进的 LLM 在简单提示下与人类判断的一致性较低，但在详细指令下实现了更好的一致性。此外，模型的置信度得分是与人类判断更好地一致的良好指标。例如，GPT-4 在人类判断中获得了 0.56 的 Cohen&#39;s Kappa 得分，当仅使用置信度得分高于 95% 的预测时，该得分将增加到 0.63。总体而言，我们的数据集和基准强调需要继续研究以增强 LLM 的毒性检测能力。通过解决这个问题，我们的工作旨在为建设性的学术讨论和科学合作营造一个健康、负责任的环境。]]></description>
      <guid>https://arxiv.org/abs/2502.01676</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>幽默的例外：图像性、音素惊喜、记忆回忆和情感联想</title>
      <link>https://arxiv.org/abs/2502.01682</link>
      <description><![CDATA[arXiv:2502.01682v1 公告类型：新
摘要：这项元研究探讨了幽默、音素二元组惊讶、情感价和记忆回忆之间的关系。先前的研究表明，音素惊讶程度较高的单词更容易被记住，这表明不可预测的音素序列促进了长期记忆回忆。情感价是另一个影响记忆的已知因素，负面经历和刺激通常比正面经历和刺激更容易被记住。基于现有发现，这项研究强调，具有负面关联的单词通常会表现出更大的惊讶，更容易被回忆。然而，幽默却是一个例外：虽然与积极情绪相关，但幽默的单词也会表现出更高的惊讶度和增强的记忆力。]]></description>
      <guid>https://arxiv.org/abs/2502.01682</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>由 LLM 提供支持的 Benchmark Factory：可靠、通用且高效</title>
      <link>https://arxiv.org/abs/2502.01683</link>
      <description><![CDATA[arXiv:2502.01683v1 公告类型：新
摘要：大型语言模型（LLM）的快速发展导致模型供应和应用需求激增。为了促进它们之间的有效匹配，广泛需要可靠、通用和高效的基准生成器。然而，人工注释者受到效率低下的制约，当前的LLM基准生成器不仅缺乏通用性，而且由于缺乏用于验证和优化的全面评估框架，可靠性也有限。为了填补这一空白，我们首先提出了一个自动化和无偏的评估框架，该框架围绕四个维度和十个标准构建。在这个框架下，我们仔细分析了直接提示LLM作为通用基准生成器的优点和缺点。为了提高可靠性，我们引入了一系列方法来解决已发现的弱点并将它们集成为BenchMaker。跨多个LLM和任务的实验证实，BenchMaker在所有指标上都实现了优于或可与人工注释基准相当的性能，突出了其通用性和可靠性。更重要的是，它在 12 个 LLM 中提供了高度一致的评估结果（与 MMLU-Pro 的 Pearson 相关性为 0.967），同时每个样本仅需 0.005 美元和 0.38 分钟。]]></description>
      <guid>https://arxiv.org/abs/2502.01683</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于代理的不确定性意识利用开源大型语言模型改进自动放射学报告标记</title>
      <link>https://arxiv.org/abs/2502.01691</link>
      <description><![CDATA[arXiv:2502.01691v1 公告类型：新
摘要：使用大型语言模型 (LLM) 从放射学报告中可靠地提取结构化数据仍然具有挑战性，尤其是对于希伯来语等复杂的非英语文本。本研究引入了一种基于代理的不确定性感知方法来提高 LLM 预测在医学应用中的可信度。我们分析了三个医疗中心克罗恩病患者的 9,683 份希伯来语放射学报告（从 2010 年到 2023 年）。512 份报告的子集针对六个胃肠道器官和 15 个病理发现进行了手动注释，而其余报告则使用 HSMP-BERT 自动注释。使用 Llama 3.1（Llama 3-8b-instruct）和贝叶斯提示集成（BayesPE）执行结构化数据提取，它使用六个语义等效的提示来估计不确定性。基于代理的决策模型将多个提示输出整合为五个校准不确定性的置信度水平，并与三个基于熵的模型进行了比较。在过滤高不确定性案例之前和之后，使用准确度、F1 得分、精确度、召回率和科恩的 Kappa 来评估性能。基于代理的模型在所有指标上都优于基线，F1 得分为 0.3967，召回率为 0.6437，科恩的 Kappa 为 0.3006。在过滤高不确定性案例（大于或等于 0.5）后，F1 得分提高到 0.4787，Kappa 提高到 0.4258。不确定性直方图显示正确预测和错误预测之间有明显的区分，其中基于代理的模型提供了最精确的不确定性估计。通过结合不确定性感知提示集成和基于代理的决策模型，该方法提高了 LLM 从放射学报告中提取结构化数据的性能和可靠性，为高风险医疗应用提供了更易于解释和更值得信赖的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2502.01691</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BARE：结合基础语言模型和指令调整语言模型，实现更好的合成数据生成</title>
      <link>https://arxiv.org/abs/2502.01697</link>
      <description><![CDATA[arXiv:2502.01697v1 公告类型：新
摘要：随着模型训练对高质量数据的需求不断增长，研究人员和开发人员越来越多地生成合成数据来调整和训练 LLM。关于合成数据的一个普遍假设是从指令调整模型中采样就足够了；然而，这些模型难以产生多样化的输出——这是泛化的关键要求。尽管有各种提示方法，但在这项工作中，我们表明从指令调整模型中实现有意义的多样性仍然具有挑战性。相比之下，我们发现没有后训练的基础模型表现出更大的多样性，但在指令跟随方面的能力较差，因此质量较低。利用这一见解，我们提出了 Base-Refine (BARE)，这是一种合成数据生成方法，它通过两阶段过程将基础模型的多样性与指令调整模型的质量相结合。通过最少的少量样本和策展，BARE 生成多样化和高质量的数据集，从而提高下游任务的性能。我们表明，使用少至 1,000 个 BARE 生成的样本进行微调即可达到与 LiveCodeBench 任务上最佳类似大小模型相当的性能。此外，使用 BARE 生成的数据进行微调在 GSM8K 上比仅指令数据提高了 101%，在 RAFT 上比 SOTA 方法提高了 18.4%。]]></description>
      <guid>https://arxiv.org/abs/2502.01697</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Comply：受果蝇嗅觉启发，学习具有复杂权重的句子</title>
      <link>https://arxiv.org/abs/2502.01706</link>
      <description><![CDATA[arXiv:2502.01706v1 公告类型：新
摘要：受生物启发的神经网络为建模数据分布提供了替代途径。FlyVec 是一个最近的例子，它从果蝇的嗅觉回路中汲取灵感来解决学习词向量的任务。令人惊讶的是，即使与专门设计用于编码文本的深度学习方法相比，该模型的表现也具有竞争力，并且计算效率最高。我们提出了一个问题，即这种性能是否可以进一步提高。为此，我们引入了 Comply。通过复杂权重合并位置信息，我们使单层神经网络能够学习序列表示。我们的实验表明，Comply 不仅取代了 FlyVec，而且性能与明显更大的最先进模型相当。我们无需额外的参数即可实现这一点。Comply 产生可以从神经元权重中明确解释的句子的稀疏上下文表示。]]></description>
      <guid>https://arxiv.org/abs/2502.01706</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过耦合标记生成评估大型语言模型</title>
      <link>https://arxiv.org/abs/2502.01754</link>
      <description><![CDATA[arXiv:2502.01754v1 公告类型：新
摘要：最先进的大型语言模型依靠随机化来响应提示。直接的后果是，如果多次询问，模型可能会对同一提示做出不同的响应。在这项工作中，我们认为大型语言模型的评估和排名应该控制其运作所依赖的随机化。我们的出发点是开发耦合自回归生成的因果模型，该模型允许不同的大型语言模型使用相同的随机源对响应进行采样。基于我们的因果模型，我们首先表明，在基于基准数据集的评估中，耦合自回归生成得出的结论与普通自回归生成相同，但使用的样本更少。然而，我们进一步表明，在基于（人工）成对比较的评估中，耦合和普通自回归生成在比较两个以上的模型时会得出不同的排名，即使样本数量无限。这表明，现有评估协议中某个模型相对于其他模型的明显优势可能并非真实存在，而是被生成过程固有的随机性所混淆。为了说明和补充我们的理论结果，我们使用 Llama 家族的几种大型语言模型进行了实验。我们发现，在流行的 MMLU 基准数据集的多个知识领域中，耦合自回归生成所需的样本量最多比普通自回归生成少 40%，即可得出相同的结论。此外，使用来自 LMSYS Chatbot Arena 平台的数据，我们发现，在耦合和普通自回归生成下，强大的大型语言模型与提示的成对比较得出的胜率有所不同。]]></description>
      <guid>https://arxiv.org/abs/2502.01754</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>关于鲍勃·迪伦：计算视角</title>
      <link>https://arxiv.org/abs/2502.01772</link>
      <description><![CDATA[arXiv:2502.01772v1 公告类型：新
摘要：卡斯·桑斯坦 (Cass Sunstein) 的文章《论鲍勃·迪伦》描述了迪伦的“去习惯化”风格——不断拒绝顺应期望，并倾向于重塑他的音乐和抒情身份。在本文中，我通过对 1962 年至 2012 年迪伦歌词的大规模计算分析扩展了桑斯坦的观察结果。使用 o3-mini-high（大型语言模型），我从歌词中提取了概念到概念的关系，并构建了有向知识图来捕捉迪伦的主题结构。然后，我量化了情绪、隐喻表达、主题多样性和网络复杂性随时间的变化。结果表明，迪伦的歌词越来越依赖隐喻，显示出不断变化的情绪特征，并表现出高度的去习惯化——在这里以关键概念网络中心性不断增加的方差来衡量。我还发现，对运动、抗议和神话意象的引用与迪伦职业生涯中众所周知的阶段一致，反映了他艺术的动态和不可预测性。这些发现不仅加深了我们对桑斯坦论点的实证理解，还引入了一种分析艺术家演变的新型计算方法，为文化和创造性变化的研究提供了更广泛的适用性。]]></description>
      <guid>https://arxiv.org/abs/2502.01772</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SelfCheckAgent：生成大型语言模型中的零资源幻觉检测</title>
      <link>https://arxiv.org/abs/2502.01812</link>
      <description><![CDATA[arXiv:2502.01812v1 公告类型：新
摘要：在大型语言模型 (LLM) 中检测幻觉仍然是其在实际应用中可靠部署的关键挑战。为了解决这个问题，我们引入了 SelfCheckAgent，这是一个集成了三个不同代理的新框架：符号代理、专用检测代理和上下文一致性代理。这些代理为幻觉检测提供了一种强大的多维方法。值得注意的结果包括上下文一致性代理利用 Llama 3.1 和思维链 (CoT) 在 WikiBio 数据集上取得了出色的表现，非事实幻觉检测得分分别为 93.64%、事实 70.26% 和排名 78.48%。在 AIME 数据集上，具有 CoT 的 GPT-4o 在非事实检测方面表现出色，准确率为 94.89%，但在事实检测方面则表现不佳，准确率为 30.58%，排名检测方面则为 30.68%，这凸显了在复杂数学领域中检测幻觉的复杂性。该框架还采用了三角测量策略，增强了 SelfCheckAgent 的强度，从而显著提高了现实世界中幻觉的识别能力。比较分析证明了 SelfCheckAgent 在不同领域的适用性，使其成为值得信赖的 LLM 的关键进步。这些发现凸显了一致性驱动方法在检测 LLM 中的幻觉方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.01812</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中的潜在词汇投射：一种隐式表征细化的新方法</title>
      <link>https://arxiv.org/abs/2502.01882</link>
      <description><![CDATA[arXiv:2502.01882v1 公告类型：新
摘要：生成语义连贯的文本需要对语言结构进行强大的内部表示，而传统的嵌入技术通常无法充分捕捉到这一点。引入了一种新方法，即潜在词汇投影 (LLP)，通过结构化转换为潜在空间来细化词汇表示，从而增强输入嵌入与其上下文含义之间的一致性。该方法在现有语言模型架构中集成了优化的投影机制，从而能够在保持句法完整性的同时更准确地选择标记。跨多个基准的评估表明困惑度降低，BLEU 分数增加，表明预测准确性和流畅度有所提高。词汇多样性的分析揭示了生成的文本中词汇的多样性，解决了冗余和重复短语结构的常见问题。对熵分布的进一步评估表明解码过程中的不确定性有所下降，反映了对单词选择的信心增强。此外，长距离依赖性保留也表现出可观的收益，在扩展的标记距离下分类准确率有所提高。尽管增加了投影机制，但计算效率仍在可控的约束范围内，凸显了 LLP 集成到现有架构中的实用性。]]></description>
      <guid>https://arxiv.org/abs/2502.01882</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>概念隐喻理论作为大型语言模型的提示范式</title>
      <link>https://arxiv.org/abs/2502.01901</link>
      <description><![CDATA[arXiv:2502.01901v1 公告类型：新
摘要：我们引入概念隐喻理论 (CMT) 作为通过复杂推理任务中的认知提示来增强大型语言模型 (LLM) 的框架。CMT 利用隐喻映射来构建抽象推理，提高模型处理和解释复杂概念的能力。通过结合基于 CMT 的提示，我们引导 LLM 走向更结构化和更像人类的推理模式。为了评估这种方法，我们在涵盖领域特定推理、创造性洞察力和隐喻解释的基准任务上将四个原生模型（Llama3.2、Phi3、Gemma2 和 Mistral）与 CMT 增强模型进行比较。使用 Llama3.3 70B 模型自动评估响应。实验结果表明，CMT 提示显着提高了推理准确性、清晰度和隐喻连贯性，在所有评估任务中均优于基线模型。]]></description>
      <guid>https://arxiv.org/abs/2502.01901</guid>
      <pubDate>Wed, 05 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>