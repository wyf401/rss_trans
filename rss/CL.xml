<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 27 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>检索增强生成与数据驱动的 Tabula Rasa 方法相结合，实现时间知识图谱预测</title>
      <link>https://arxiv.org/abs/2408.13273</link>
      <description><![CDATA[arXiv:2408.13273v1 公告类型：新
摘要：OpenAI ChatGPT 和 Google Gemini 等预训练大型语言模型 (PLLM) 面临着时间知识图谱 (tKG) 预测中事实回忆不准确、幻觉、偏见和未来数据泄露等挑战。为了解决这些问题，我们引入了 sLA-tKGF（用于 tKG 预测的小型语言助手），它利用检索增强生成 (RAG) 辅助、定制训练的小型语言模型，通过从头开始的白板方法进行有效的 tKG 预测。我们的框架使用来自 tKG、网络搜索结果和 PLLM 生成的文本描述的相关历史数据构建知识注入提示，以了解目标时间之前的历史实体关系。它利用这些外部知识注入的提示来更深入地理解和推理特定于上下文的语义和时间信息，以零样本提示小规模语言模型来更准确地预测 tKG 中的未来事件。它通过理解随时间变化的趋势来减少幻觉并缓解分布转移挑战。因此，它可以更准确地、基于上下文地预测未来事件，同时最大限度地减少计算需求。严格的实证研究表明，我们的框架在基准数据集上具有可解释和值得信赖的 tKG 预测的稳健性、可扩展性和最先进 (SOTA) 性能。]]></description>
      <guid>https://arxiv.org/abs/2408.13273</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的桥梁设计规范问答系统</title>
      <link>https://arxiv.org/abs/2408.13282</link>
      <description><![CDATA[arXiv:2408.13282v1 Announce Type: new 
摘要：本文构建了基于大型语言模型的桥梁设计规范问答系统，尝试了三种实现方案：完全微调Bert预训练模型、参数高效微调Bert预训练模型、从头开始自建语言模型。通过自建问答任务数据集，基于tensorflow和keras深度学习平台框架构建并训练模型，预测用户给出的桥梁设计规范中答案的起始位置和终止位置。实验结果表明，完全微调Bert预训练模型在训练集、验证集和测试集上均达到100%准确率，系统可以从用户给出的桥梁设计规范中提取答案，回答用户的各种问题；虽然参数高效的Bert预训练模型和自建语言模型在训练集上都有很好的表现，但在测试集上的泛化能力还有待提高。本文的研究为专业领域问答系统的开发提供了有益的参考。]]></description>
      <guid>https://arxiv.org/abs/2408.13282</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Power Scheduler：与批次大小和令牌数量无关的学习率调度器</title>
      <link>https://arxiv.org/abs/2408.13359</link>
      <description><![CDATA[arXiv:2408.13359v1 公告类型：新
摘要：寻找语言模型预训练的最佳学习率是一项具有挑战性的任务。这不仅是因为学习率、批量大小、训练标记数量、模型大小和其他超参数之间存在复杂的相关性，而且因为对具有数十亿或数万亿个参数的大型语言模型进行超参数搜索的成本过高。最近的研究建议使用小型代理模型和小型语料库进行超参数搜索，并将最佳参数转置到大型模型和大型语料库。虽然零样本可迁移性在理论和经验上已经证明适用于与模型大小相关的超参数，如深度和宽度，但从小语料库到大语料库的零样本迁移尚未得到充分探索。在本文中，我们研究了最近提出的 WSD 调度程序的最佳学习率、批量大小和训练标记数量之间的相关性。经过数千次小实验，我们发现变量之间存在幂律关系，并证明了其跨模型大小的可迁移性。根据观察，我们提出了一种新的学习率调度程序 Power 调度程序，它与训练标记的数量和批处理大小无关。实验表明，将 Power 调度程序与最大更新参数化 (muP) 相结合，无论训练标记的数量、批处理大小、模型大小甚至模型架构如何，都可以使用一组超参数始终如一地实现令人印象深刻的性能。使用 Power 调度程序训练的 3B 密集和 MoE 模型实现了与最先进的小型语言模型相当的性能。我们在 https://ibm.biz/BdKhLa 开源了这些预训练模型。]]></description>
      <guid>https://arxiv.org/abs/2408.13359</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CodeRefine：用于增强 LLM 生成的研究论文代码实现的管道</title>
      <link>https://arxiv.org/abs/2408.13366</link>
      <description><![CDATA[arXiv:2408.13366v1 公告类型：新
摘要：本文介绍了 CodeRefine，这是一种使用大型语言模型 (LLM) 自动将研究论文方法转换为功能代码的新框架。我们的多步骤方法首先从论文中提取和总结关键文本块，分析它们的代码相关性，并使用预定义的本体创建知识图。然后从这种结构化表示生成代码，并通过提出的回顾性检索增强生成方法进行增强。CodeRefine 解决了连接理论研究和实际实施的挑战，为 LLM 零样本提示提供了更准确的替代方案。对各种科学论文的评估​​表明，CodeRefine 能够改进论文中的代码实现，从而有可能加速尖端算法在实际应用中的采用。]]></description>
      <guid>https://arxiv.org/abs/2408.13366</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将多头卷积编码器与交叉注意相结合以改进 SPARQL 查询翻译</title>
      <link>https://arxiv.org/abs/2408.13432</link>
      <description><![CDATA[arXiv:2408.13432v1 Announce Type: new 
摘要：KGQA系统（知识图谱问答系统）的主要任务是将用户输入的问题转换成查询语法（如SPARQL）。随着Transformer、ConvS2S等现代流行编码器和解码器的兴起，不少学者将SPARQL生成的研究方向转向神经机器翻译（NMT）架构或Text-to-SPARQL的生成式AI领域。在基于NMT的问答系统中，系统将知识库查询语法视为一种语言，利用基于NMT的翻译模型将自然语言问题翻译成查询语法。学者们利用流行的配备交叉注意力的架构，如Transformer、ConvS2S、BiLSTM等，来训练查询语法的翻译模型。为了达到更好的查询效果，本文改进了ConvS2S编码器，并从Transformer中加入了多头注意力机制，提出了一种基于n-gram语言模型的多头Conv编码器（MHC编码器）。其原理是利用卷积层捕获输入序列中具有不同感受野的局部隐藏特征，利用多头注意力机制计算它们之间的依赖关系。最终我们发现基于多头Conv编码器的翻译模型取得了优于其他编码器的性能，在QALD-9和LC-QuAD-1.0数据集上分别获得了76.52%和83.37%的BLEU-1（BiLingual Evaluation Understudy）。此外，在QALD-9和LC-QuAD-1.0数据集上的端到端系统实验中，我们取得了领先于其他KGQA系统的结果，Macro F1-measures分别达到了52%和66%。此外，实验结果表明，在有限的计算资源下，如果拥有优秀的编码器-解码器架构和交叉注意力，专家学者可以仅使用一般的嵌入就实现与大型预训练模型相当的出色性能。]]></description>
      <guid>https://arxiv.org/abs/2408.13432</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用图卷积网络进行知识感知对话脱轨预测</title>
      <link>https://arxiv.org/abs/2408.13440</link>
      <description><![CDATA[arXiv:2408.13440v1 公告类型：新
摘要：在线对话特别容易脱轨，脱轨可能表现为有害的沟通模式，包括不尊重的评论和辱骂。预测对话脱轨可以提前预测脱轨的迹象，从而实现对话的主动调节。对话脱轨预测的最先进的方法是按顺序编码对话并使用图神经网络来模拟对话用户动态。然而，现有的图模型无法捕捉复杂的对话特征，如上下文传播和情绪变化。使用常识知识可以使模型捕捉到这些特征，从而提高性能。按照这种方法，我们从对话上下文信息知识库中得出常识性陈述，以丰富图神经网络分类架构。我们将话语的多源信息融合到胶囊中，这些胶囊被基于变压器的预测器用来预测对话脱轨。我们的模型捕捉了对话动态和上下文传播，在 CGA 和 CMV 基准数据集上的表现优于最先进的模型]]></description>
      <guid>https://arxiv.org/abs/2408.13440</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>让每一分钱都物有所值：实现成本效益推理的难度自适应自洽性</title>
      <link>https://arxiv.org/abs/2408.13457</link>
      <description><![CDATA[arXiv:2408.13457v1 公告类型：新
摘要：自洽（SC）是一种广泛用于思路链推理的解码策略，它在各种多步骤推理任务中表现出显著的收益，但由于预设大小的多次采样而导致成本高昂。它的变体，自适应自洽（ASC）和早期停止自洽（ESC），根据一组预样本的后验分布动态调整样本数量，降低 SC 的成本，同时对性能的影响最小。然而，这两种方法都没有利用关于问题难度的先验信息。它通常会导致不必要的重复抽样，而这些简单的问题只需一次尝试就可以准确回答，从而浪费资源。为了解决这个问题，我们提出了难度自适应自洽（DSC），它利用先验和后验角度的难度信息来自适应地分配推理资源，进一步降低 SC 的成本。为了证明 DSC 的有效性，我们在六个基准上对三种常见的推理任务类别（算术、常识和符号推理）进行了广泛的实验。实证结果表明，DSC 在成本方面始终远远超过强大的基准 ASC 和 ESC，同时实现了相当的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.13457</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>为什么要反对工作：基于 RoBERTa 的工作相关压力识别和主要因素分析系统</title>
      <link>https://arxiv.org/abs/2408.13473</link>
      <description><![CDATA[arXiv:2408.13473v1 公告类型：新
摘要：众所周知，恶劣的工作环境和工作压力会导致焦虑、抑郁和自杀意念等心理健康问题。因此，创建既能检测员工不快乐又能找到问题根源的解决方案至关重要。虽然之前的研究已经使用机器学习研究了心理健康的原因，但它们通常侧重于一般的心理健康分析，很少有研究关注可解释的解决方案或研究特定工作场所的环境。r/antiwork 是反工作运动的 subreddit，反工作运动代表着完全停止工作的愿望。使用这个 subreddit 作为工作环境不满的代理，我们创建了一个用于反工作情绪检测的新数据集，随后训练了一个突出显示反工作情绪的模型。在此之后，我们进行了定性和定量分析，以揭示一些关键见解，了解反工作运动的心态以及他们的工作环境如何影响他们。我们发现，不赋予员工权力或责任的工作环境、令人沮丧的招聘经历以及不公平的薪酬是导致员工厌恶工作情绪的主要原因，从而导致员工缺乏自信和动力。]]></description>
      <guid>https://arxiv.org/abs/2408.13473</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型进行中医命名实体识别与 COVID-19 文献对比研究</title>
      <link>https://arxiv.org/abs/2408.13501</link>
      <description><![CDATA[arXiv:2408.13501v1 公告类型：新 
摘要：目的：探索和比较 ChatGPT 和其他最先进的 LLM 在中医抗击 COVID-19 文献中涵盖不同实体类型和领域的特定领域 NER 任务上的性能。方法：我们建立了一个包含 389 篇中医抗击 COVID-19 文章的数据集，并以属于 3 个领域的 6 种实体类型作为基本事实，手动注释了其中 48 篇，以此来评估 LLM 的 NER 性能。然后，我们使用 ChatGPT（GPT-3.5 和 GPT-4）和 4 个最先进的基于 BERT 的问答 (QA) 模型（RoBERTa、MiniLM、PubMedBERT 和 SciBERT）对 6 种实体类型执行 NER 任务，而无需事先对特定任务进行训练。还应用了领域微调模型 (GSAP-NER) 进行全面比较。结果：在精确匹配和模糊匹配上，LLM 的整体性能存在明显差异。在模糊匹配中，ChatGPT 在 6 项任务中的 5 项上超越了基于 BERT 的 QA 模型；而在精确匹配中，基于 BERT 的 QA 模型在 6 项任务中的 5 项上优于 ChatGPT，但 F-1 差异较小。GPT-4 在模糊匹配中表现出显著优势，尤其是在中药配方实体类型和中成药 (TFD) 和成分 (IG) 上。虽然 GPT-4 在草药实体类型、目标和研究方法上优于基于 BERT 的模型，但 F-1 得分均未超过 0.5。GSAP-NER 在 F-1 方面略胜于 GPT-4，RM 略胜一筹。ChatGPT 的召回率远高于准确率，尤其是在模糊匹配中。结论：LLM 的 NER 性能高度依赖于实体类型，并且其性能因应用场景而异。对于需要高召回率的场景，ChatGPT 可能是一个不错的选择。但是，对于严格场景下的知识获取，ChatGPT 和基于 BERT 的 QA 模型都不是专业从业者的现成工具。]]></description>
      <guid>https://arxiv.org/abs/2408.13501</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过 Token 级奖励函数估计进行选择性偏好优化</title>
      <link>https://arxiv.org/abs/2408.13518</link>
      <description><![CDATA[arXiv:2408.13518v1 公告类型：新
摘要：大型语言模型对齐的最新进展利用 token 级监督来执行细粒度的偏好优化。然而，现有的 token 级对齐方法要么对所有可用的 token 进行优化，这可能会很嘈杂且效率低下，要么使用复杂且昂贵的关键 token 选择策略进行选择性训练。在这项工作中，我们提出了选择性偏好优化 (SePO)，这是一种以高效关键 token 选择为中心的新型选择性对齐策略。SePO 提出了第一种基于直接偏好优化 (DPO) 的 token 选择方法，该方法训练一个 oracle 模型来估计目标数据的 token 级奖励函数。此方法适用于任何具有响应级注释的现有对齐数据集，并能够使用小规模 oracle 模型和训练数据进行经济高效的 token 选择。然后利用估计的奖励函数对目标数据集内的所有 token 进行评分，其中仅选择关键 token 来使用无参考模型的对比目标函数来监督目标策略模型。在三个公开评估基准上进行的大量实验表明，SePO 仅通过优化目标数据集上的 30% 关键标记，就显著优于竞争性基线方法。SePO 在弱到强泛化方面的应用表明，弱预言机模型有效地监督了参数多 16.8 倍的强策略模型。SePO 还可以有效地从分布外的数据中选择关键标记，以增强强策略模型并缓解过度优化问题。]]></description>
      <guid>https://arxiv.org/abs/2408.13518</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HRGraph：利用 LLM 构建人力资源数据知识图谱，并基于信息传播进行职位推荐</title>
      <link>https://arxiv.org/abs/2408.13521</link>
      <description><![CDATA[arXiv:2408.13521v1 公告类型：新
摘要：知识图谱 (KG) 作为语义网络，通过提供统一、情境化和结构化的表示形式，并具有灵活性，可以轻松适应不断发展的知识，在管理不同领域的复杂互连数据方面被证明是非常有效的。通过处理复杂的人力资源 (HR) 数据，KG 可以帮助完成不同的人力资源职能，如招聘、工作匹配、识别学习差距和提高员工保留率。尽管它们具有潜力，但在实施实用的人力资源知识图谱方面所做的努力有限。本研究通过提出一个使用大型语言模型从文档中有效开发人力资源知识图谱的框架来解决这一差距。由此产生的 KG 可用于各种下游任务，包括工作匹配、识别员工技能差距等等。在这项工作中，我们展示了人力资源 KG 在精确工作匹配方面发挥重要作用的案例，为雇主和雇员带来了优势。知识图谱和图神经网络中的信息传播实验以及案例研究的经验证据强调了知识图谱在工作和员工推荐以及工作领域分类等任务中的有效性。代码和数据可在以下位置获取：https://github.com/azminewasi/HRGraph]]></description>
      <guid>https://arxiv.org/abs/2408.13521</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>潘多拉魔盒还是阿拉丁神灯：全面分析揭示 RAG 噪声在大型语言模型中的作用</title>
      <link>https://arxiv.org/abs/2408.13533</link>
      <description><![CDATA[arXiv:2408.13533v1 公告类型：新
摘要：检索增强生成 (RAG) 已成为解决大型语言模型 (LLM) 中幻觉的重要方法。虽然最近的研究已将 RAG 模型扩展到复杂的噪声场景，但这些探索通常局限于有限的噪声类型，并假设噪声本质上对 LLM 有害，可能偏离现实世界的检索环境并限制实际适用性。在本文中，我们从语言学的角度定义了七种不同的噪声类型，并建立了噪声 RAG 基准 (NoiserBench)，这是一个涵盖多个数据集和推理任务的综合评估框架。通过对具有不同架构和规模的八个代表性 LLM 进行实证评估，我们发现这些噪声可以进一步分为两类实际组：对 LLM 有益的噪声（又名有益噪声）和对 LLM 有害的噪声（又名有害噪声）。虽然有害噪音通常会损害性能，但有益噪音可能会增强模型能力和整体性能的多个方面。我们的分析为开发更强大、适应性更强的 RAG 解决方案和减轻各种检索场景中的幻觉提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2408.13533</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>菜单的文化适应性：一种细致入微的方法</title>
      <link>https://arxiv.org/abs/2408.13534</link>
      <description><![CDATA[arXiv:2408.13534v1 公告类型：新
摘要：文化特定项目 (CSI) 的机器翻译带来了重大挑战。CSI 翻译的最新研究表明，使用大型语言模型 (LLM) 可以适应不同的语言和文化，取得了一些成功；然而，需要进行更深入的分析来研究每种方法的优点和缺点。在本文中，我们介绍了 ChineseMenuCSI 数据集，这是最大的中英文菜单语料库，带有 CSI 与非 CSI 标签和细粒度测试集。我们定义了三个级别的 CSI 形象性以进行更细致的分析，并开发了一种新颖的自动 CSI 识别方法，该方法在大多数类别中都优于基于 GPT 的提示。重要的是，我们是第一个将人工翻译理论融入 LLM 驱动的翻译过程的人，显著提高了翻译准确性，COMET 分数提高了 7 分。]]></description>
      <guid>https://arxiv.org/abs/2408.13534</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IQA-EVAL：人模交互式问答的自动评估</title>
      <link>https://arxiv.org/abs/2408.13545</link>
      <description><![CDATA[arXiv:2408.13545v1 公告类型：新 
摘要：为了评估用于问答 (QA) 的大型语言模型 (LLM)，传统方法通常侧重于直接评估模型根据给定的问题和上下文生成的即时响应。在人类寻求人工智能助手帮助查找信息的常见用例中，这些非交互式评估没有考虑到人机模型对话的动态性质，而交互感知评估表明，人类更喜欢准确的 QA 模型 (Lee et al., 2023)。人机交互 (HCI) 领域的最新研究已经聘请了人类评估员进行交互和评估，但它们通常成本高昂且耗时长。在这项工作中，我们引入了一个自动评估框架 IQA-EVAL 来进行交互式问答评估。更具体地说，我们引入了基于 LLM 的评估代理 (LEA)，它可以：(1) 模拟人类行为以与 IQA 模型生成交互；(2) 自动评估生成的交互。此外，我们建议将角色分配给 LEA，以更好地模拟真实的人类评估者群体。我们表明：（1）我们的评估框架以 GPT-4（或 Claude）作为骨干模型，在 IQA 任务上与人类评估实现了高度相关性；（2）将角色分配给 LEA 以更好地代表人群，进一步显著提高了相关性。最后，我们使用我们的自动指标来评估最近五个具有代表性的 LLM，其中包含来自复杂和模糊问答任务的 1000 多个问题，如果由人工评估，则需要花费 5,000 美元。]]></description>
      <guid>https://arxiv.org/abs/2408.13545</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FLEURS-ASL：将美国手语纳入大规模多语言多任务评估</title>
      <link>https://arxiv.org/abs/2408.13585</link>
      <description><![CDATA[arXiv:2408.13585v1 公告类型：新
摘要：手语翻译历来是主流机器翻译研究的边缘领域。为了帮助融合这些领域，我们引入了 FLEURS-ASL，这是多路并行基准 FLORES（用于文本）和 FLEURS（用于语音）的扩展，以支持他们的第一种手语（作为视频），美国手语，由 5 名认证聋人翻译。FLEURS-ASL 可用于评估各种任务——主要是句子和话语级别的翻译——在 ASL 和 200 种其他语言作为文本或 102 种语言作为语音之间。我们使用统一的建模方法为从 ASL 到英语文本的任务提供基线，该方法在 34 秒的上下文窗口中结合了时间戳标记和以前的文本标记，并在 YouTube-ASL 的随机视频片段上进行训练。该模型达到或超过了短语级基线的性能，同时支持大量新任务。我们还使用 FLEURS-ASL 来表明多模式前沿模型实际上不了解 ASL，这强调了将手语纳入标准评估套件的重要性。]]></description>
      <guid>https://arxiv.org/abs/2408.13585</guid>
      <pubDate>Tue, 27 Aug 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>