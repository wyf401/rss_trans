<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 12 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>使用增强排名数据集进行多响应偏好优化</title>
      <link>https://arxiv.org/abs/2412.07812</link>
      <description><![CDATA[arXiv:2412.07812v1 公告类型：新 
摘要：大型语言模型 (LLM) 的最新进展令人瞩目，新模型不断超越其前辈。这些进步的基础是对各种训练机制的广泛研究。其中，偏好优化通过将人类偏好纳入训练过程，在提高 LLM 性能方面发挥了重要作用。然而，构建偏好优化数据集具有挑战性，优化过程对数据集质量高度敏感。在本研究中，我们提出了一种增强偏好优化数据集的新方法。此外，我们引入了一种基于多响应的偏好优化训练方法，可以同时学习多个响应。]]></description>
      <guid>https://arxiv.org/abs/2412.07812</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>重新思考大型语言模型时代的情感标注</title>
      <link>https://arxiv.org/abs/2412.07906</link>
      <description><![CDATA[arXiv:2412.07906v1 公告类型：新
摘要：现代情感计算系统在训练和评估方面严重依赖带有人工注释情感标签的数据集。然而，由于情绪的主观性，人工注释的成本高昂、对研究设计敏感且难以质量控制。同时，大型语言模型 (LLM) 在许多自然语言理解任务中表现出色，成为一种有前途的文本注释工具。在这项工作中，我们分析了 LLM 背景下情感注释的复杂性，重点关注 GPT-4 作为领先模型。在我们的实验中，GPT-4 在一项人工评估研究中获得了高分，比以前的工作描绘了更为积极的画面，其中人工标签是唯一的基本事实。另一方面，我们观察到人类和 GPT-4 情绪感知之间的差异，强调了人类输入在注释研究中的重要性。为了充分利用 GPT-4 的优势并保留人类视角，我们探索了将 GPT-4 集成到情感注释流程中的两种方法，展示了其标记低质量标签、减少人工注释者的工作量以及提高下游模型学习性能和效率的潜力。总之，我们的研究结果突出了新的情感标记实践的机会，并建议使用 LLM 作为辅助人工注释的有前途的工具。]]></description>
      <guid>https://arxiv.org/abs/2412.07906</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不断提问：探索法学硕士 (LLM) 对重复问题的稳健性</title>
      <link>https://arxiv.org/abs/2412.07923</link>
      <description><![CDATA[arXiv:2412.07923v1 公告类型：新
摘要：本研究考察大型语言模型 (LLM)（例如 ChatGPT，特别是最新的 GPT-4o-mini）是否对重复提示表现出敏感性，以及重复问题是否可以提高响应准确性。我们假设在单个提示中重复问题可能会增强模型对查询关键元素的关注。为了测试这一点，我们在开卷和闭卷设置下对两个阅读理解数据集的大样本评估了 ChatGPT 的表现，每个问题的重复次数为每个提示 1、3 或 5 次。我们的研究结果表明，该模型对重复问题不敏感，凸显了其在这种情况下的稳健性和一致性。]]></description>
      <guid>https://arxiv.org/abs/2412.07923</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用多个参考转录本对 ASR 进行风格无关评估</title>
      <link>https://arxiv.org/abs/2412.07937</link>
      <description><![CDATA[arXiv:2412.07937v1 公告类型：新
摘要：词错误率 (WER) 作为一种指标具有多种局限性，这些局限性一直困扰着语音识别领域。评估数据集受到转录任务的不同风格、形式和固有歧义的影响。在这项工作中，我们尝试通过使用在相反风格参数下转录的多个参考对 ASR 系统进行风格无关的评估来缓解其中一些差异。结果，我们发现现有的 WER 报告可能显著高估了最先进的 ASR 系统所犯的内容错误的数量。此外，我们发现我们的多参考方法是一种有用的机制，可用于比较在训练数据和目标任务的风格构成上不同的 ASR 模型的质量。]]></description>
      <guid>https://arxiv.org/abs/2412.07937</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经文本生成中的分叉路径</title>
      <link>https://arxiv.org/abs/2412.07961</link>
      <description><![CDATA[arXiv:2412.07961v1 公告类型：新
摘要：估计大型语言模型 (LLM) 中的不确定性对于正确评估 LLM 和确保用户安全非常重要。然而，以前的不确定性估计方法侧重于生成文本中的最终答案，而忽略了可能对结果产生巨大影响的中间步骤。我们假设存在关键的分叉标记，因此在这些特定标记（而不是其他标记）上重新采样系统会导致非常不同的结果。为了通过实证检验这一点，我们开发了一种新颖的方法来表示文本生成各个标记之间的不确定性动态，并应用统计模型来检验我们的假设。我们的方法非常灵活：它可以应用于任何数据集和任何 LLM，而无需微调或访问模型权重。我们使用我们的方法分析了 4 个领域中 7 个不同任务的 LLM 响应，涵盖了广泛的典型用例。我们发现了许多分叉标记的例子，包括标点符号等令人惊讶的标记，这表明 LLM 通常只需要一个标记就能表达出截然不同的意思。]]></description>
      <guid>https://arxiv.org/abs/2412.07961</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HalluCana：使用 Canary Lookahead 修复 LLM 幻觉</title>
      <link>https://arxiv.org/abs/2412.07965</link>
      <description><![CDATA[arXiv:2412.07965v1 公告类型：新
摘要：在本文中，我们介绍了 HalluCana，这是一种金丝雀前瞻技术，用于检测和纠正长篇生成中大型语言模型 (LLM) 的事实幻觉。HalluCana 会在生成过程中甚至生成之前，在出现幻觉迹象时立即检测并干预。为了支持及时检测，我们利用 LLM 隐藏空间中的内部事实性表示，在其中我们研究了 LLM 事实性自我评估的各种代理，并讨论了它与模型在预训练中的上下文熟悉度的关系。在传记生成方面，我们的方法将生成质量提高了 2.5 倍，同时计算量减少了 6 倍以上。]]></description>
      <guid>https://arxiv.org/abs/2412.07965</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>概念瓶颈大型语言模型</title>
      <link>https://arxiv.org/abs/2412.07992</link>
      <description><![CDATA[arXiv:2412.07992v1 公告类型：新
摘要：我们引入了概念瓶颈大型语言模型 (CB-LLM)，这是一种创建固有可解释大型语言模型 (LLM) 的开创性方法。与依赖事后解释方法且神经元功能洞察力有限的传统黑盒 LLM 不同，CB-LLM 以其内置的可解释性、可扩展性和提供清晰、准确解释的能力树立了新标准。我们研究了 NLP 领域的两个基本任务：文本分类和文本生成。在文本分类中，CB-LLM 缩小了与传统黑盒模型的性能差距并提供了清晰的可解释性。在文本生成中，我们展示了如何使用 CB-LLM 中的可解释神经元进行概念检测和引导文本生成。我们的 CB-LLM 使人类和 LLM 在各种任务中实现更大的交互——这是现有 LLM 中明显缺乏的功能。我们的代码可以在https://github.com/Trustworthy-ML-Lab/CB-LLMs上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.07992</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TinyThinker：通过自我反思，从粗到细的知识内化提炼推理</title>
      <link>https://arxiv.org/abs/2412.08024</link>
      <description><![CDATA[arXiv:2412.08024v1 公告类型：新
摘要：大型语言模型在不同任务中表现出令人印象深刻的推理能力，这促使人们努力通过生成的推理数据将这些能力提炼成更小的模型。然而，直接对这种合成的推理数据进行训练可能会导致对推理过程的表面模仿，而不是促进推理能力与底层知识的真正结合。为了解决这个问题，我们提出了 TinyThinker，这是一个引入两种新方法的框架。首先，我们引入了一个三阶段过程，逐步引导学生模型完成推理过程，逐步将知识从粗粒度细化到细粒度。其次，我们开发了一个两阶段训练框架，包括一个初始推理获取阶段，然后是一个利用自生成数据的自我反思阶段。在常识推理基准上的实验表明，TinyThinker 与基线相比取得了卓越的性能。消融研究进一步验证了我们框架中每个组件的有效性。 TinyThinker 可扩展到其他知识密集型推理任务，为在较小的语言模型中开发有效的推理能力提供了另一种策略。代码可在 https://github.com/shengminp/TinyThinker 上找到]]></description>
      <guid>https://arxiv.org/abs/2412.08024</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>M2SE：一种用于统一情绪和情感分析的多阶段多任务指令调整策略</title>
      <link>https://arxiv.org/abs/2412.08049</link>
      <description><![CDATA[arXiv:2412.08049v1 公告类型：新
摘要：情绪分析和情绪识别对于人机交互和抑郁症检测等应用至关重要。传统的单峰方法通常无法捕捉情绪表达的复杂性，因为来自不同模态的信号相互冲突。当前的多模态大型语言模型 (MLLM) 在检测细微面部表情和处理各种与情绪相关的任务方面也面临挑战。为了解决这些问题，我们提出了 M2SE，一种用于通用 MLLM 的多阶段多任务情绪和情绪指令调整策略。它采用组合方法来训练模型完成多模态情绪分析、情绪识别、面部表情识别、情绪原因推理和情绪原因对提取等任务。我们还介绍了情绪多任务数据集 (EMT)，这是一个支持这五个任务的自定义数据集。我们的模型情绪宇宙 (EmoVerse) 建立在基本的 MLLM 框架上，没有修改，但在使用 M2SE 策略进行训练时，它在这些任务上取得了显着的改进。大量实验表明，EmoVerse 的表现优于现有方法，在情绪和情感任务中取得了最先进的成果。这些结果凸显了 M2SE 在增强多模态情感感知方面的有效性。数据集和代码可在 https://github.com/xiaoyaoxinyi/M2SE 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.08049</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多语言法学硕士 (LLM) 本质上奖励资源匮乏语言的语言内时间敏感语义对齐</title>
      <link>https://arxiv.org/abs/2412.08090</link>
      <description><![CDATA[arXiv:2412.08090v1 公告类型：新
摘要：资源丰富的语言和资源匮乏的语言之间标记资源的持续差异仍然是大型语言模型 (LLM) 的重大障碍。跨语言上下文学习 (X-ICL) 的最新进展，主要是通过从多语言预训练转换器中检索语义对齐的示例，已显示出缓解这一问题的希望。然而，我们的调查显示，LLM 本质上奖励语言内语义对齐的跨语言实例，而不是直接跨语言语义对齐，在 X-ICL 设置中处理时间敏感查询时存在明显差异。这样的查询需要 LLM 具有良好的时间推理能力，但进步主要集中在英语上。本研究旨在通过提高低资源语言的时间推理能力来弥合这一差距。为此，我们引入了 mTEMPREASON，这是一个针对不同程度的低资源语言的时间推理数据集，并提出了跨语言时间敏感语义对齐 (CLiTSSA)，这是一种在这些情况下改进时间推理的新方法。为了实现这一点，我们构建了 mTEMPREASON 的扩展，其中包含成对的并行跨语言时间查询及其预期的语言内语义相似性分数。我们的实证证据强调了 CLiTSSA 与三种语言（罗马尼亚语、德语和法语）的既定基线相比具有优异的性能，涵盖三个时间任务并包括一组四个不同的同时期 LLM。这标志着在解决跨语言时间推理背景下的资源差异方面迈出了重要一步。]]></description>
      <guid>https://arxiv.org/abs/2412.08090</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>邪恶双胞胎并没有那么邪恶：对机器生成提示的定性洞察</title>
      <link>https://arxiv.org/abs/2412.08127</link>
      <description><![CDATA[arXiv:2412.08127v1 公告类型：新
摘要：人们普遍观察到，语言模型 (LM) 以可预测的方式响应看似难以理解的算法生成的提示。这既表明我们缺乏对 LM 工作原理的全面了解，也是一种实际挑战，因为不透明性可能会被用于 LM 的有害用途，例如越狱。我们首次对不透明的机器生成提示或自动提示进行了彻底分析，涉及 3 个不同大小和系列的 LM。我们发现机器生成的提示的特点是最后一个标记通常是可理解的并且对生成有很强的影响。前面的标记中有一小部分但一致的比例是填充符，它们可能出现在提示中，这是优化过程固定标记数量的副产品。剩余的标记往往与生成至少具有松散的语义关系，尽管它们与生成没有良好的句法关系。此外，我们发现，我们对机器生成的提示应用的某些消融也可以应用于自然语言序列，从而导致类似的行为，这表明自动提示是 LM 处理语言输入方式的直接结果。]]></description>
      <guid>https://arxiv.org/abs/2412.08127</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NLPineers@ 天城文脚本语言的 NLU 2025：使用基于 BERT 的模型集成进行仇恨言论检测</title>
      <link>https://arxiv.org/abs/2412.08163</link>
      <description><![CDATA[arXiv:2412.08163v1 公告类型：新
摘要：本文探讨了针对 CHIPSAL@COLING 2025 共享任务子任务 B 的 Devanagari 脚本语言中的仇恨言论检测，重点关注印地语和尼泊尔语。使用一系列基于 Transformer 的模型，例如 XLM-RoBERTa、MURIL 和 IndicBERT，我们检查了它们在处理仇恨言论和自由表达之间细微界限方面的有效性。我们表现最佳的模型，作为多语言 BERT 模型的集合实现，实现了 0.7762 的召回率（召回率排名 3/31）和 0.6914 的 F1 分数（排名 17/31）。为了解决类别不平衡问题，我们使用反向翻译进行数据增强，并使用余弦相似度来保持增强后的标签一致性。这项工作强调了在 Devanagari 脚本语言中进行仇恨言论检测的必要性，并为进一步的研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2412.08163</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从社区到可解释网络和词嵌入：一种统一的方法</title>
      <link>https://arxiv.org/abs/2412.08187</link>
      <description><![CDATA[arXiv:2412.08187v1 公告类型：新
摘要：对复杂系统（例如人类社交互动或语言中的词语共现）中的信息进行建模，有助于理解这些系统的组织和功能。此类系统可以通过网络建模，网络理论提供了一套有用的方法来分析它们。在这些方法中，图嵌入是一种强大的工具，可以在矢量化特征空间中总结网络的交互和拓扑结构。当用于机器学习算法的输入时，嵌入向量有助于解决常见的图形问题，例如链接预测、图形匹配等。词嵌入的目标是表示词义，从大型文本语料库中提取它。尽管嵌入算法输入的信息结构存在差异，但许多图嵌入方法都是从 NLP 中的方法改编和启发而来的。在这两个领域都观察到了这些方法的局限性。这些方法中的大多数都需要长时间且耗费资源的训练。大多数方法的另一个缺点是它们是黑盒的，从中了解信息的结构相当复杂。模型的可解释性允许理解向量空间的结构，而无需外部信息，因此可以更轻松地进行审核。考虑到这两个限制，我们提出了一个新颖的框架，以有效地将网络顶点嵌入可解释的向量空间中。我们的低维二分框架 (LDBGF) 利用网络的二分投影，使用团伙来降低维数。除了 LDBGF，我们还介绍了该框架的两个实现，它们依赖于社区而不是团伙：SINr-NR 和 SINr-MF。我们表明 SINr-MF 可以在经典图上表现良好，而 SINr-NR 可以生成高质量的图和词嵌入，这些图和词嵌入在运行过程中都是可解释且稳定的。]]></description>
      <guid>https://arxiv.org/abs/2412.08187</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DocSum：用于文档抽象摘要的领域自适应预训练</title>
      <link>https://arxiv.org/abs/2412.08196</link>
      <description><![CDATA[arXiv:2412.08196v1 公告类型：新
摘要：抽象摘要在将大量文本压缩和改写为连贯摘要方面取得了重大进展。然而，由于领域特定术语、OCR 生成的错误以及模型微调所需的带注释数据集稀缺，总结行政文件带来了独特的挑战。现有模型通常难以适应此类文档的复杂结构和专业内容。为了解决这些限制，我们引入了 DocSum，这是一个针对行政文件量身定制的领域自适应抽象摘要框架。DocSum 利用对 OCR 转录文本的预训练和通过创新的问答对集成进行微调，提高了摘要的准确性和相关性。这种方法解决了管理内容固有的复杂性，确保输出符合实际业务需求。为了评估其功能，我们定义了一种新颖的下游任务设置——文档抽象摘要——它反映了业务和组织设置的实际要求。全面的实验证明了 DocSum 在生成高质量摘要方面的有效性，展示了其在改善公共和私营部门的决策和运营工作流程方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2412.08196</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过专门的 NLP 模型实现准确的医学命名实体识别</title>
      <link>https://arxiv.org/abs/2412.08255</link>
      <description><![CDATA[arXiv:2412.08255v1 Announce Type: new 
摘要：本研究针对医学命名实体识别任务，评估了BioBERT在医学文本处理中的效果。通过与BERT、ClinicalBERT、SciBERT、BlueBERT等模型的对比实验，结果表明BioBERT在准确率和F1值上均取得了最优表现，验证了其在医学领域的适用性和优越性。BioBERT通过在生物医学数据上进行预训练，增强了对专业术语和复杂医学文本的理解能力，为医学信息提取和临床决策支持提供了有力的工具。研究还探讨了BioBERT在处理医学数据时面临的隐私和合规性挑战，并提出了未来结合其他医学专用模型提高泛化性和鲁棒性的研究方向。随着深度学习技术的发展，BioBERT在智能医疗、个性化治疗、疾病预测等应用领域的潜力将进一步拓展，未来研究可重点关注模型的实时性和可解释性，推动其在医学领域的广泛应用。]]></description>
      <guid>https://arxiv.org/abs/2412.08255</guid>
      <pubDate>Thu, 12 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>