<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 21 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用 LLM 实现空间配置和运动动力学的高效手语翻译</title>
      <link>https://arxiv.org/abs/2408.10593</link>
      <description><![CDATA[arXiv:2408.10593v1 公告类型：新
摘要：无注释手语翻译 (SLT) 将手语视频直接转换为口语句子，而无需依赖注释。最近，大型语言模型 (LLM) 利用其强大的自然语言生成功能，在无注释方法中表现出色。然而，这些方法通常依赖于特定领域的视觉编码器微调来实现最佳结果。相比之下，本文强调了捕捉手语固有的空间配置和运动动态的重要性。考虑到这一点，我们介绍了基于空间和运动的手语翻译 (SpaMo)，这是一种基于 LLM 的新型 SLT 框架。SpaMo 的核心思想简单而有效。我们首先使用现成的视觉编码器提取空间和运动特征，然后将这些特征输入带有语言提示的 LLM。此外，我们在 SLT 监督之前采用视觉文本对齐过程作为热身。我们的实验表明，SpaMo 在两个流行的数据集 PHOENIX14T 和 How2Sign 上实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2408.10593</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:58 GMT</pubDate>
    </item>
    <item>
      <title>重新审视语音表征学习：单独可学习参数和稳健数据增强的必要性</title>
      <link>https://arxiv.org/abs/2408.10557</link>
      <description><![CDATA[arXiv:2408.10557v1 公告类型：新
摘要：语音建模方法学习一个固定语音片段的嵌入，通常在 10-25 毫秒之间。语音中存在的信息可以分为两类：“所说的内容”（内容）和“如何表达”（其他），这两者本质上是正交的，如果强制一起优化，优化算法会找到次优解决方案。这导致一项或所有下游任务的性能不佳，如先前的研究表明。当前的自监督学习 (SSL) 方法（例如 HuBERT）非常擅长对语音中存在的内容信息进行建模。数据增强提高了需要有效建模其他信息的任务的性能，但这会导致模型容量分散。在这项工作中，我们进行了一项初步研究，以了解使用单独的可学习参数对其他信息进行建模的重要性。我们提出了一个修改版的 HuBERT，称为 Other HuBERT (O-HuBERT)，以检验我们的假设。我们的发现有两个方面：首先，O-HuBERT 方法能够利用所有层来构建复杂的特征来编码其他信息；其次，强大的数据增强策略对于学习依赖于其他信息的任务所需的信息以及使用类似大小的模型（1 亿个参数）和预训练数据（960 小时）在 SUPERB 基准上实现最先进 (SOTA) 性能至关重要。]]></description>
      <guid>https://arxiv.org/abs/2408.10557</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:57 GMT</pubDate>
    </item>
    <item>
      <title>站在法学硕士的角度思考：通过问题重写器生成更好的答案</title>
      <link>https://arxiv.org/abs/2408.10573</link>
      <description><![CDATA[arXiv:2408.10573v1 公告类型：新
摘要：大型语言模型 (LLM) 已展示出显著的能力，特别是在问答 (QA) 领域。然而，它们在问答中的有效性往往因用户问题的模糊性而受到削弱。为了解决这个问题，我们引入了单轮实例级提示优化，称为问题重写器。通过增强黑盒 LLM 中人类问题的可理解性，我们的问题重写器提高了生成答案的质量。重写器使用直接偏好优化进行优化，该优化基于从评估生成答案的自动标准收集的反馈；因此，它的训练不需要昂贵的人工注释。在多个黑盒 LLM 和长格式问答 (LFQA) 数据集上的实验证明了我们方法的有效性。本文为训练问题重写器提供了一个实用的框架，并为未来在 LFQA 任务中探索提示优化树立了先例。代码可在 \url{https://github.com/3244we/Question-Rewriter} 获得。]]></description>
      <guid>https://arxiv.org/abs/2408.10573</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:57 GMT</pubDate>
    </item>
    <item>
      <title>NoMatterXAI：生成“无论如何”另类事实示例，用于解释黑盒文本分类模型</title>
      <link>https://arxiv.org/abs/2408.10528</link>
      <description><![CDATA[arXiv:2408.10528v1 公告类型：新
摘要：在可解释人工智能 (XAI) 中，反事实解释 (CE) 是一种经过深入研究的方法，它通过“假设”的对比推理来传达特征相关性，以解释人工智能模型的预测。然而，它们只关注重要（即相关）的特征，而在很大程度上忽略了不太重要（即不相关）的特征。这些不相关的特征在许多应用中都至关重要，尤其是当用户需要确保人工智能模型的决策不会受到性别、种族、宗教或政治派别等特定属性的影响或偏见时。为了解决这一差距，提出了另类事实解释 (AE) 的概念。 AE 探索“无论如何”的另一种现实，其中不相关的特征被替换为同一属性（例如“政治”）中的替代特征（例如“共和党人”-&gt;“民主党人”），同时保持相似的预测输出。这可以验证 AI 模型预测是否受指定属性的影响。尽管 AE 前景光明，但缺乏系统地生成它们的计算方法，特别是在文本领域，为 AI 文本分类器创建 AE 提出了独特的挑战。本文通过将 AE 生成公式化为优化问题并引入 MoMatterXAI（一种为文本分类任务生成 AE 的新算法）来解决这一挑战。我们的方法实现了高达 95% 的高保真度，同时在多个模型和数据集中保持超过 90% 的上下文相似度。一项人工研究进一步验证了 AE 在向最终用户解释 AI 文本分类器方面的有效性。所有代码都将公开提供。]]></description>
      <guid>https://arxiv.org/abs/2408.10528</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>表格数据的语言建模：基础、技术和发展的调查</title>
      <link>https://arxiv.org/abs/2408.10548</link>
      <description><![CDATA[arXiv:2408.10548v1 公告类型：新
摘要：表格数据是各个领域中流行的数据类型，由于其异构性和复杂的结构关系，它带来了独特的挑战。在表格数据分析中实现高预测性能和稳健性对众多应用具有重要意义。受自然语言处理（特别是转换器架构）最新进展的影响，出现了用于表格数据建模的新方法。早期技术集中于从头开始对转换器进行预训练，经常遇到可扩展性问题。随后，开发了利用 BERT 等预训练语言模型的方法，这些方法需要的数据更少，性能更高。最近出现的大型语言模型（如 GPT 和 LLaMA）进一步彻底改变了该领域，以最少的微调促进了更先进和多样化的应用。尽管人们的兴趣日益浓厚，但仍然缺乏对表格数据语言建模技术的全面调查。本文填补了这一空白，系统回顾了表格数据语言建模的发展，内容包括：（1）不同表格数据结构和数据类型的分类；（2）回顾模型训练中使用的关键数据集和用于评估的任务；（3）总结建模技术，包括广泛采用的数据处理方法、流行的架构和训练目标；（4）从采用传统的预训练/预训练语言模型到使用大型语言模型的演变；（5）确定表格数据分析语言建模中持续存在的挑战和未来潜在的研究方向。与此调查相关的 GitHub 页面位于：https://github.com/lanxiang1017/Language-Modeling-on-Tabular-Data-Survey.git。]]></description>
      <guid>https://arxiv.org/abs/2408.10548</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:56 GMT</pubDate>
    </item>
    <item>
      <title>数据增强整合对话流程和风格，使口语对话系统适应低资源用户群体</title>
      <link>https://arxiv.org/abs/2408.10516</link>
      <description><![CDATA[arXiv:2408.10516v1 公告类型：新
摘要：本研究解决了口语对话系统 (SDS) 在数据稀缺的情况下与表现出不同对话行为的用户（尤其是未成年人）互动时遇到的交互挑战。我们提出了一种新颖的数据增强框架，以增强资源有限的用户组的 SDS 性能。我们的方法利用大型语言模型 (LLM) 来提取说话者风格，并利用预训练语言模型 (PLM) 来模拟对话行为历史。该方法生成丰富且个性化的对话数据，从而促进与独特用户群体的更好互动。大量实验验证了我们方法的有效性，凸显了其促进更具适应性和包容性的对话系统发展的潜力。]]></description>
      <guid>https://arxiv.org/abs/2408.10516</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:55 GMT</pubDate>
    </item>
    <item>
      <title>XCB：一种有效的语境偏见方法，用于语音识别中的跨语言短语偏见</title>
      <link>https://arxiv.org/abs/2408.10524</link>
      <description><![CDATA[arXiv:2408.10524v1 公告类型：新
摘要：当有预定义的短语列表时，语境化 ASR 模型已被证明可以有效提高不常见短语的识别准确率。然而，这些模型往往难以适应双语设置，而双​​语设置是代码转换语音识别中普遍存在的。在本研究中，我们通过引入跨语言语境偏差 (XCB) 模块，首次尝试解决这一挑战。具体来说，我们通过集成辅助语言偏差模块和补充语言特定损失来增强针对主要语言的预训练 ASR 模型，旨在增强对第二语言中短语的识别。在我们内部的代码转换数据集上进行的实验结果验证了我们方法的有效性，证明了第二语言中偏差短语的识别有了显着改善，即使没有任何额外的推理开销。此外，当应用于未见的 ASRU-2019 测试集时，我们提出的系统表现出效率和泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2408.10524</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:55 GMT</pubDate>
    </item>
    <item>
      <title>基于计划的文本生成检索分析</title>
      <link>https://arxiv.org/abs/2408.10490</link>
      <description><![CDATA[arXiv:2408.10490v1 公告类型：新
摘要：在文本生成中，幻觉是指生成看似连贯但与既定知识相矛盾的文本。一个令人信服的假设是，当语言模型被赋予其参数知识之外的生成任务时（由于稀有性、新近性、领域等），就会出现幻觉。解决这一限制的常见策略是将检索机制注入语言模型，为模型提供与任务相关的知识。在本文中，我们利用指令调整的 LLM 的规划功能，并分析如何使用规划来指导检索以进一步降低幻觉的频率。我们在长文本生成任务上对我们提出的方法的几种变体进行了实证评估。通过提高相关事实的覆盖率，计划引导的检索和生成可以产生更具信息量的响应，同时提供更高的源文档归因率。]]></description>
      <guid>https://arxiv.org/abs/2408.10490</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>QUITO-X：一种基于信息瓶颈的交叉注意压缩算法</title>
      <link>https://arxiv.org/abs/2408.10497</link>
      <description><![CDATA[arXiv:2408.10497v1 公告类型：新
摘要：生成式 LLM 在各种工业任务中取得了显著的成功，并且可以通过 ICL 有效地适应垂直领域和下游任务。然而，随着任务变得越来越复杂，ICL 所需的上下文长度也越来越长，并且出现了两个重大问题：（i）过长的上下文导致高成本和推理延迟。（ii）长上下文引入的大量与任务无关的信息加剧了“迷失在中间”的问题。
最近，根据从某些因果语言模型（例如 llama-7b）获得的某些度量标准删除标记来压缩提示已成为缓解这些问题的有效方法。然而，先前方法使用的度量标准（例如自信息或 PPL）与在查询条件化时区分最重要的标记的目标并不完全一致。在这项工作中，我们引入了信息瓶颈理论来仔细检查度量标准所需的属性。受此启发，我们在编码器-解码器架构中使用交叉注意作为新指标。我们的简单方法在较小的模型中以较低的延迟显著提高了性能。
我们在四个数据集上评估了我们的方法：DROP、CoQA、SQuAD 和 Quoref。实验结果表明，在保持相同性能的同时，我们的压缩率可以比之前的 SOTA 提高近 25%。值得注意的是，在删除 25% 的标记的实验中，我们模型的答案 EM 分数有时甚至超过使用未压缩文本作为上下文的对照组。]]></description>
      <guid>https://arxiv.org/abs/2408.10497</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:54 GMT</pubDate>
    </item>
    <item>
      <title>Goldfish：350 种语言的单语语言模型</title>
      <link>https://arxiv.org/abs/2408.10441</link>
      <description><![CDATA[arXiv:2408.10441v1 公告类型：新
摘要：对于许多资源匮乏的语言，唯一可用的语言模型是同时对多种语言进行训练的大型多语言模型。然而，使用 FLORES 困惑度作为指标，我们发现这些模型对许多语言的表现都比二元语法差（例如，XGLM 4.5B 中 24% 的语言；BLOOM 7.1B 中 43%）。为了促进针对资源匮乏语言的研究，我们预先训练并发布了 Goldfish，这是一套单语自回归 Transformer 语言模型，最多有 1.25 亿个参数，适用于 350 种语言。尽管每个 Goldfish 模型都小 10 倍以上，但在 204 种 FLORES 语言中的 98 种语言中，Goldfish 的 FLORES 困惑度低于 BLOOM、XGLM 和 MaLA-500。然而，在推理基准测试中，Goldfish 模型的表现明显不如大型多语言模型，这表明对于资源匮乏的语言，多语言性主要提高的是一般推理能力，而不是基本的文本生成能力。我们发布了在 5MB（350 种语言）、10MB（288 种语言）、100MB（166 种语言）和 1GB（83 种语言）文本数据上训练的模型（如果有）。Goldfish 模型可用作资源匮乏的 NLP 研究中现有模型的基线、微调源或增强模型，并且它们对于需要跨语言最大程度可比的模型的跨语言研究也非常有用。]]></description>
      <guid>https://arxiv.org/abs/2408.10441</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:53 GMT</pubDate>
    </item>
    <item>
      <title>通过稀疏-密集-稀疏机制增强一次性剪枝预训练语言模型</title>
      <link>https://arxiv.org/abs/2408.10473</link>
      <description><![CDATA[arXiv:2408.10473v1 公告类型：新
摘要：预训练语言模型 (PLM) 被设计为在上下文理解方面具有鲁棒性，并在各种自然语言处理任务中表现出色。然而，它们相当大的规模会产生大量的计算和存储成本。现代修剪策略采用一次性技术来压缩 PLM，而无需对特定于任务或其他一般数据进行重新训练；然而，这些方法往往会导致性能不可避免地下降。在本文中，我们提出了 SDS，这是一个稀疏-密集-稀疏修剪框架，从权重分布优化的角度增强修剪后的 PLM 的性能。我们分三个步骤概述了修剪过程。首先，我们使用传统的一次性修剪方法修剪模型中不太重要的连接。接下来，我们通过使用稀疏正则化重新激活修剪后的连接来重建一个具有修剪友好权重分布的密集模型。最后，我们进行第二轮修剪，与初始修剪相比，修剪后的模型更胜一筹。实验结果表明，在相同的稀疏度配置下，SDS 的表现优于最先进的修剪技术 SparseGPT 和 Wanda。例如，在 2:4 稀疏度的 OPT-125M 的多个零样本基准测试中，SDS 将 Raw-Wikitext2 上的困惑度降低了 9.13，并将准确率平均提高了 2.05%。]]></description>
      <guid>https://arxiv.org/abs/2408.10473</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:53 GMT</pubDate>
    </item>
    <item>
      <title>非结构化文本的价值对齐</title>
      <link>https://arxiv.org/abs/2408.10392</link>
      <description><![CDATA[arXiv:2408.10392v1 公告类型：新
摘要：将大型语言模型 (LLM) 与价值体系对齐已成为 AI 和 NLP 领域的一个重要研究领域。目前，这种对齐过程依赖于高质量监督和偏好数据的可用性，而这些数据的整理或注释既耗时又昂贵。在本文中，我们介绍了一种系统的端到端方法，用于将 LLM 与非结构化文本数据中表示的隐式和显式值对齐。我们提出的方法利用可扩展的合成数据生成技术来有效地将模型与非结构化数据中存在的值对齐。通过两个不同的用例，我们展示了我们的方法在 Mistral-7B-Instruct 模型上的效率。我们的方法可靠地将 LLM 与文档中嵌入的值对齐，并且通过使用自动指标和胜率来量化，与其他方法相比，其性能有所提高。]]></description>
      <guid>https://arxiv.org/abs/2408.10392</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:52 GMT</pubDate>
    </item>
    <item>
      <title>使用投影仪编辑器网络解决编辑范围中的词汇偏见</title>
      <link>https://arxiv.org/abs/2408.10411</link>
      <description><![CDATA[arXiv:2408.10411v1 公告类型：新
摘要：权重保留模型编辑技术严重依赖于决定何时对基础模型应用编辑的范围机制。这些范围机制利用表示空间中的距离函数来确定编辑的范围。在这项工作中，我们表明基于距离的范围函数可以解决词汇偏见问题，从而导致诸如具有相似词汇特征的无关提示失败等问题。为了解决这个问题，我们引入了用于模型编辑的投影仪编辑器网络 (PENME)，这是一种模型编辑方法，它采用紧凑适配器和通过对比学习目标训练的投影网络。我们证明了 PENME 在实现卓越结果方面的有效性，同时具有计算效率和灵活性，可以适应各种模型架构。]]></description>
      <guid>https://arxiv.org/abs/2408.10411</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:52 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的符号知识提炼综述</title>
      <link>https://arxiv.org/abs/2408.10210</link>
      <description><![CDATA[arXiv:2408.10210v1 公告类型：新
摘要：这篇调查论文深入探讨了大型语言模型 (LLM) 中符号知识提炼这一新兴且关键的领域。随着生成式预训练 Transformer-3 (GPT-3) 和 Transformer 的双向编码器表示 (BERT) 等 LLM 在规模和复杂性上不断扩大，有效利用其广泛知识的挑战变得至关重要。本调查集中于将这些模型中包含的复杂、通常隐含的知识提炼成更具符号性、更明确的形式的过程。这种转变对于增强 LLM 的可解释性、效率和适用性至关重要。我们根据方法和应用对现有研究进行分类，重点关注如何使用符号知识提炼来提高更小、更高效的人工智能 (AI) 模型的透明度和功能性。本调查讨论了核心挑战，包括以易于理解的形式保持知识深度，并探讨了该领域开发的各种方法和技术。我们确定了当前研究中的差距和未来发展的潜在机会。本调查旨在全面概述法学硕士中的符号知识提炼，强调其在向更易于访问和更高效的人工智能系统发展中的重要性。]]></description>
      <guid>https://arxiv.org/abs/2408.10210</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:51 GMT</pubDate>
    </item>
    <item>
      <title>超越相关文档：使用大型语言模型进行以查询为中心的摘要的知识密集型方法</title>
      <link>https://arxiv.org/abs/2408.10357</link>
      <description><![CDATA[arXiv:2408.10357v1 公告类型：新
摘要：以查询为中心的摘要 (QFS) 是自然语言处理中的一项基本任务，具有广泛的应用，包括搜索引擎和报告生成。然而，传统方法假设相关文档可用，但在实际场景中，尤其是在高度专业化的主题中，这可能并不总是成立。为了解决这一限制，我们提出了一种新颖的知识密集型方法，将 QFS 重新定义为知识密集型任务设置。该方法包括两个主要组件：检索模块和摘要控制器。检索模块根据给定的文本查询从大规模知识语料库中有效地检索潜在相关文档，消除了对预先存在的文档集的依赖。摘要控制器无缝集成了强大的基于大型语言模型 (LLM) 的摘要器和精心定制的提示，确保生成的摘要全面且与查询相关。为了评估我们方法的有效性，我们创建了一个新数据集以及人工注释的相关性标签，以便对检索和摘要性能进行全面评估。大量实验证明了我们方法的卓越性能，特别是它能够在不依赖相关文档可用性的情况下生成准确的摘要。这强调了我们的方法在各种查询场景中的多功能性和实用性。]]></description>
      <guid>https://arxiv.org/abs/2408.10357</guid>
      <pubDate>Wed, 21 Aug 2024 06:19:51 GMT</pubDate>
    </item>
    </channel>
</rss>