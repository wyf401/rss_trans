<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Wed, 19 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>文本和代码生成中大型语言模型的合奏学习：调查</title>
      <link>https://arxiv.org/abs/2503.13505</link>
      <description><![CDATA[ARXIV：2503.13505V1公告类型：新 
摘要：生成验证的变压器（GPT）是用于从自然语言输入中生成文本的常见大语模型（LLMS）。但是，单个LLMS中语言参数的固定属性可能导致生成的输出中的不一致。该限制还限制了模型由于固有的偏见而代表各种语言模式的能力。此外，许多强大的LLM都是封闭的。这样可以防止组织将其数据集成到这些系统中，从而引起人们对数据隐私和限制行业应用程序的担忧。受LLM集成模型在文本生成中的成功应用的启发，最近的文献还研究了它们在代码生成中的潜力。本文回顾了这些新兴的LLM合奏方法。我们的目标是增强读者对现有技术的理解，并鼓励进一步的研究和实际实施，旨在扩大文本和代码生成中LLM集成模型的现实应用。我们将这些方法分为七种主要方法：重量合并，知识融合，专家的混合，奖励合奏，输出合奏，路由和级联。从此列表中，我们专注于四种方法和模型，这些方法和模型表现出强大的性能和更广泛的应用的潜力。我们分析了他们的建模步骤，培训方法和输出功能，以清楚地了解其功能。我们的发现突出了LLM合奏技术的好处。这些包括更好地表示多样性，提高的产出质量以及应用程序的灵活性。该信息为选择涉及文本和代码生成的各种现实世界任务的模型提供了宝贵的见解，并可能将方法应用于多模式LLMS。]]></description>
      <guid>https://arxiv.org/abs/2503.13505</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经2023 LLM效率微调竞赛</title>
      <link>https://arxiv.org/abs/2503.13507</link>
      <description><![CDATA[ARXIV：2503.13507V1公告类型：新 
摘要：我们对神经2023大语言模型（LLM）微调竞赛的分析揭示了以下趋势：表现最好的模型在基准数据集中表现出明显的过度拟合，反映了更广泛的基准过度对受欢迎的排行榜的问题，并且该数据策划对于获得高表现LLM至关重要。该竞赛由两个阶段组成 - 一个开放评估阶段，具有公开可用的任务，并具有看不见的任务的封闭式评估阶段 - 使我们能够评估微调LLMS的普遍性。我们的结果突出了当前基于基准的评估方案对生成模型的局限性，并证明了需要更强大的评估方法。值得注意的是，获奖提交的提交利用了标准的开源库，主要集中在数据策划上。为了促进进一步的研究和促进可重复性，我们发布了所有竞争条目，Docker文件和评估基础架构，为社区提供了探索LLM中微调，过度拟合和可重复性的宝贵资源。]]></description>
      <guid>https://arxiv.org/abs/2503.13507</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>这是太多的选择：生成AI和医学教育中多项选择问题的陷阱</title>
      <link>https://arxiv.org/abs/2503.13508</link>
      <description><![CDATA[ARXIV：2503.13508V1公告类型：新 
摘要：大语模型（LLM）在多项选择问题（MCQ）基准测试中的性能经常被认为是其医疗功能的证明。我们假设LLM在医疗MCQ上的表现可能部分是虚幻的，并且是由医学内容知识和推理能力以外的因素驱动的。为了评估这一点，我们通过配对MCQ（FreemedQA）创建了一个新颖的自由响应问题的基准。使用此基准，我们评估了三个最先进的LLM（GPT-4O，GPT-3.5和Llama-3-70b-Instruct），并发现相对于多个选择的自由回答问题的平均绝对恶化为39.43％，而自由回应问题的平均绝对恶化（p = 1.3 * 10-5）（P = 1.3 * 10-5），这比人类绩效降低了22.29％的降低。为了隔离MCQ格式在性能中的作用，我们进行了一项掩盖研究，迭代地掩盖了问题的一部分。在100％掩盖时，平均LLM多项选择性性能比随机机会（p = 0.002）高6.70％（p = 0.002），一个LLM（GPT-4O）的准确性为37.34％。值得注意的是，对于所有LLM，自由响应性能接近零。我们的结果强调了医学MCQ基准的缺点，即高估了LLM在医学中的能力，并且从广义上讲，使用LLM评估的自由回答问题来改善人类和机器评估的潜力。]]></description>
      <guid>https://arxiv.org/abs/2503.13508</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>及时的情绪：LLM更改的催化剂</title>
      <link>https://arxiv.org/abs/2503.13510</link>
      <description><![CDATA[ARXIV：2503.13510V1公告类型：新 
摘要：大语言模型（LLM）的兴起已经彻底改变了自然语言处理（NLP），但是迅速情感的影响是输入文本的潜在情感特征，仍然没有得到充实的态度。这项研究系统地研究了提示中的情感变化如何影响LLM生成的产出，从而在相干，事实和偏见方面影响。利用基于词典和基于变压器的情感分析方法，我们对提示进行了分类并评估五个领先的LLM的响应：Claude，DeepSeek，GPT-4，Gemini和Llama。我们的分析涵盖了六个AI驱动的应用程序，包括内容生成，对话AI，法律和财务分析，医疗保健AI，创意写作和技术文档。通过转换提示，我们评估它们对产出质量的影响。我们的发现表明，迅速情绪会显着影响模型的反应，负面提示通常会降低事实准确性和放大偏见，而正提示则倾向于增加详细的和情感的传播。这些结果强调了情感意识及时工程的重要性，以确保公平可靠的AI生成的内容。]]></description>
      <guid>https://arxiv.org/abs/2503.13510</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>rag-kg-il：通过抹布和增量知识图表学习整合的多代理混合框架，用于减少幻觉和增强LLM推理</title>
      <link>https://arxiv.org/abs/2503.13514</link>
      <description><![CDATA[ARXIV：2503.13514V1公告类型：新 
摘要：本文介绍了RAG-KG-IL，这是一种新型的多代理混合框架，旨在通过将检索功能增强的生成（RAG）和知识图（kgs）与增量学习（IL）方法集成，以增强大语言模型（LLMS）的推理能力。尽管有最近的进步，但LLMS在结构化数据，处理动态知识演变以及缓解幻觉的推理方面仍然面临重大挑战，尤其是在关键任务领域。我们提出的RAG-KG-IL框架通过采用一个多代理体系结构来解决这些局限性，该架构可以实现持续的知识更新，整合结构化知识，并结合了自主的代理，以增强解释性和推理。该框架利用抹布来确保生成的响应基于可验证的信息，而KG则提供结构化的域知识，以提高一致性和理解深度。增量学习方法允许在不完全重新培训的情况下对知识库进行动态更新，从而大大降低计算开销并改善模型的适应性。我们使用涉及与健康相关的查询的现实案例研究评估了框架，将其与GPT-4O和仅使用抹布的基线等最新模型进行了比较。实验结果表明，我们的方法大大降低了幻觉率，并提高了答案的完整性和推理准确性。结果强调了组合抹布，千克和多代理系统的潜力，以创建能够在复杂域中实时知识集成和推理的智能，适应性的系统。]]></description>
      <guid>https://arxiv.org/abs/2503.13514</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>居里：评估多任务科学长篇小说理解和推理上的LLM</title>
      <link>https://arxiv.org/abs/2503.13517</link>
      <description><![CDATA[ARXIV：2503.13517V1公告类型：新 
摘要：解决问题的科学问题涉及在应用专家知识的同时综合信息。我们介绍了Curie，这是一种科学的长篇文化理解，推理和信息提取基准，以衡量大语模型（LLM）在科学问题解决和协助科学家进行现实工作流程中的潜力。该基准介绍了十项具有挑战性的任务，共有580个问题，解决方案对由六个学科的专家组成 - 材料科学，凝结物理学，量子计算，地理空间分析，生物多样性和蛋白质 - 涵盖了科学领域的实验性工作和理论工作。我们在Curie的任务上评估了一系列封闭式和开放的LLM，这些任务需要域专业知识，对长篇文章信息的理解以及多步推理。尽管Gemini Flash 2.0和Claude-3在跨域中表现出一致的高度理解，但流行的GPT-4O和Command-R+在蛋白质测序任务上急剧失败。在32％的最佳性能中，所有型号都有很大的改进空间。我们希望从居里获得的见解可以指导科学中LLM的未来发展。评估代码和数据在https://github.com/google/curie中]]></description>
      <guid>https://arxiv.org/abs/2503.13517</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>示例作为提示：电子商务中有效LLM改编的可扩展方法</title>
      <link>https://arxiv.org/abs/2503.13518</link>
      <description><![CDATA[ARXIV：2503.13518V1公告类型：新 
摘要：提示LLMS提供了一种有效的方法来指导产量生成而无需明确的模型培训。在电子商务领域中，基于促进的应用程序广泛用于诸如查询了解，推荐系统和客户支持之类的任务。但是，将LLM适应不同的任务通常需要域专家的广泛及时工程，以及频繁的更新以与不断发展的业务需求保持一致。此外，制定完全公正的自然语言提示仍然是人类的挑战。为了应对这些挑战，我们提出了一个新颖的框架，例如提示（EAP），该提示（EAP）利用标记数据来增强提示。具体而言，EAP会自动选择最具代表性的示例，以最大程度地提高LLM的少量功能。由于其无监督的示例选择并适应潜在的数据分布变化，因此这是有效的。我们验证了四个现实世界中生产用例的EAP，表明它与域专家设计的手工制作的提示相比，它可以达到可比甚至出色的性能。此外，我们介绍了EAP_LITE，它完全用标记的示例替换了提示的自然语言组成部分。 EAP_LITE将LLM推理速度提高了高达70％，而不会损害性能。最新的在线A/B测试表明，使用EAP和EAP_LITE进行数据标记可以带来大量的综合收入增长0.06％。]]></description>
      <guid>https://arxiv.org/abs/2503.13518</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估大语言模型的过程建模能力 - 初步基础和结果</title>
      <link>https://arxiv.org/abs/2503.13520</link>
      <description><![CDATA[ARXIV：2503.13520V1公告类型：新 
摘要：大型语言模型（LLM）已彻底改变了自然语言的处理。尽管LLM的过程建模能力的第一个基准是有希望的，但目前正在争论LLM在多大程度上可以生成良好的过程模型。在这项贡献中，我们认为对LLM的过程建模能力的评估远非微不足道。因此，必须仔细采取可用的评估结果。例如，即使在简单的情况下，不仅应考虑模型的质量，而且还应考虑生成所需的成本和时间。因此，LLM不会生成一个最佳解决方案，而是一组帕累托最佳变体。此外，还必须考虑到一些其他挑战，例如质量概念化，结果验证，可推广性和数据泄漏。我们详细讨论了这些挑战，并讨论了未来的实验，以科学地应对这些挑战。]]></description>
      <guid>https://arxiv.org/abs/2503.13520</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>代理增强的大型语言模型用于研究政治机构</title>
      <link>https://arxiv.org/abs/2503.13524</link>
      <description><![CDATA[ARXIV：2503.13524V1公告类型：新 
摘要：大语言模型（LLM）在政治学中的应用正在迅速扩展。本文演示了LLM在使用预定义的功能和专业工具增强时如何用作能够简化数据收集，预处理和分析等任务的动态代理。这种方法的核心是代理检索增强的生成（Agentic rag），它使LLMS具有与外部知识基础相互作用的动作呼叫功能。除了信息检索之外，LLM代理还可以合并用于文档摘要，成绩单编码，定性可变分类和统计建模等任务的模块化工具。为了证明这种方法的潜力，我们介绍了旨在支持研究美国国会的学者Congressra。通过此示例，我们强调了LLM代理如何使用驱动政治机构研究的特定领域数据来降低复制，测试和扩展实证研究的成本。]]></description>
      <guid>https://arxiv.org/abs/2503.13524</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向层次的多步奖励模型，以增强大语模型的推理</title>
      <link>https://arxiv.org/abs/2503.13551</link>
      <description><![CDATA[ARXIV：2503.13551V2公告类型：新 
摘要：最近的研究表明，大型语言模型（LLMS）通过监督的微调或加强学习来实现强大的推理能力。但是，一种关键方法，即过程奖励模型（PRM），遭受了奖励黑客攻击，使其无法确定最佳的中间步骤。在本文中，我们提出了一种新型的奖励模型方法，即分层奖励模型（HRM），该模型评估了从细粒度和粗粒水平的个人和连续推理步骤。 HRM在评估推理连贯性和自我反射方面的表现更好，尤其是在上一步不正确的情况下。此外，为了通过Monte Carlo Tree搜索（MCT）解决自主生成PRM培训数据的效率低下，我们引入了基于节点合并（将两个连续的推理步骤组合为一个连续的推理步骤）中的轻巧有效的数据增强策略，称为层次结构节点压缩（HNC）。这种方法通过可忽略不计的计算开销来使HRM的MCTS结果多样化，从而通过引入噪声来增强标签的鲁棒性。 PRM800K数据集的经验结果表明，与PRM相比，HRM与HNC结合使用，在评估中实现了卓越的稳定性和可靠性。此外，对MATH500和GSM8K的跨域评估证实了HRM在各种推理任务中的出色概括和鲁棒性。所有实验的代码将在https：//github.com/tengwang0318/hierarchial_reward_model上发布。]]></description>
      <guid>https://arxiv.org/abs/2503.13551</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Mes-rag：将多模式，实体存储和安全增强带来抹布</title>
      <link>https://arxiv.org/abs/2503.13563</link>
      <description><![CDATA[ARXIV：2503.13563V1公告类型：新 
摘要：检索功能的生成（RAG）通过使用外部知识来改善大语言模型（LLMS），但它与精确的实体信息检索斗争。在本文中，我们提出了Mes-rag框架，该框架可以增强特定于实体的查询处理，并提供准确，安全和一致的响应。 Mes-rag引入了主动的安全措施，通过在数据访问之前应用保护来确保系统完整性。此外，该系统支持实时多模式输出，包括文本，图像，音频和视频，无缝集成到现有的抹布架构中。实验结果表明，MES-rag显着提高了准确性和召回率，突出了其在提高问题驱动器的安全性和实用性方面的有效性，将准确性提高到目标任务的0.83（+0.25）。我们的代码和数据可从https://github.com/wpydcr/mes-rag获得。]]></description>
      <guid>https://arxiv.org/abs/2503.13563</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ML-SpecQD：使用量化的草稿进行多级投机解码</title>
      <link>https://arxiv.org/abs/2503.13565</link>
      <description><![CDATA[ARXIV：2503.13565V1公告类型：新 
摘要：投机解码（SD）已成为一种加速LLM推断的方法，而无需牺牲16位模型推断的任何准确性。在典型的SD设置中，这个想法是使用完整的，小的，快速的模型作为“草稿”来生成接下来的几个令牌，并使用“ Target”大型模型来验证草稿生成的令牌。这种方法的功效在很大程度上取决于草稿生成的令牌的接受率以及草稿与目标模型的相对令牌吞吐量。然而，有效的SD管道需要预先培训并将草案模型与目标模型保持一致，这使得对LLM推断以插件方式不切实际。在这项工作中，我们建议以插件方式使用MXFP4型号作为草稿，因为MXFP4仅重量量化（WOQ）仅将BF16目标模型权重与MXFP4进行直接铸造。在实践中，我们的插件解决方案在BF16基线上可提供高达2倍的加速度。然后，我们寻求进一步加速的机会：通过使用另一个较小的草稿，可以通过投机解码来加速MXFP4的标记生成本身。我们称我们的方法ML-SpecQD：使用量化的草稿进行多级投机解码，因为它递归地采用了推测来加速草稿一代。将多级投机解码与MXFP4量化的草稿相结合，我们胜过最先进的投机解码，在BF16基线上产生高达2.72倍的速度。]]></description>
      <guid>https://arxiv.org/abs/2503.13565</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PENSEZ：较少的数据，更好的推理 - 重新思考法国法学学士学位</title>
      <link>https://arxiv.org/abs/2503.13661</link>
      <description><![CDATA[arxiv：2503.13661v1公告类型：新 
摘要：大型语言模型（LLM）在各种自然语言处理任务中表现出了显着的功能。但是，在数学推理和非英语语言等专业领域中实现强大的性能通常需要在大规模数据集上进行广泛的培训。本文研究了一种对比方法：对小型，高质量的双语（英语）数据集进行战略性微调，以增强大语言模型的推理能力和法语能力。我们不依赖规模，而是探讨了针对的数据策展和优化培训可以实现竞争性甚至优越的表现的假设。我们通过仅针对2,000个精心选择的样本进行了有针对性的监督微调（SFT）来证明，数学推理的显着改善。具体而言，Pensez 7b的基础模型的准确性提高了AIME25的20％，而法国数学5级基准的精度则提高了12％。这些结果挑战了主要的假设，即大规模数据集是LLM中强大推理性能的基本条件，突出了战略数据策展的潜力，并优化了对增强专业技能和多语言功能的微调。我们的发现对高性能，多语言LLM的有效发展具有影响，尤其是在资源约束的情况下。]]></description>
      <guid>https://arxiv.org/abs/2503.13661</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GPT生成的文本的特征提取和分析</title>
      <link>https://arxiv.org/abs/2503.13687</link>
      <description><![CDATA[ARXIV：2503.13687V1公告类型：新 
摘要：随着GPT等先进的自然语言模型的兴起，在包括学术界在内的各个领域中，人体写作和GPT生成的文本之间的兴起变得越来越具有挑战性和至关重要。长期以来的窃问题变得越来越紧迫，现在对信息的真实性的担忧更加复杂，因为并不总是清楚提出的事实是真实的还是捏造的。在本文中，我们介绍了一项针对特征提取和分析的全面研究，以区分人文和GPT生成的文本。通过将机器学习分类器应用于这些提取的特征，我们评估了每个功能在检测中的重要性。我们的结果表明，人类和GPT生成的文本表现出独特的写作风格，这可以被我们的特征有效地捕获。给定足够长的文本，两者可以以很高的精度进行区分。]]></description>
      <guid>https://arxiv.org/abs/2503.13687</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Atyaephyra在Semeval-2025任务4：低排名NPO</title>
      <link>https://arxiv.org/abs/2503.13690</link>
      <description><![CDATA[ARXIV：2503.13690V1公告类型：新 
摘要：我们提出了有关Semeval 2025共享任务的提交，内容涉及从LLMS学习敏感内容。我们的方法采用低排名适应性的负偏好优化。我们表明，我们可以利用这种组合来廉价计算其他正则化术语，这有助于稳定。我们方法的结果大大超过了共享的任务基准。]]></description>
      <guid>https://arxiv.org/abs/2503.13690</guid>
      <pubDate>Wed, 19 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>