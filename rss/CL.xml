<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Wed, 05 Mar 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>巴斯克地区的自动首次C1评估器</title>
      <link>https://arxiv.org/abs/2503.01851</link>
      <description><![CDATA[ARXIV：2503.01851V1公告类型：新 
摘要：在整个项目中，我们都有一个自动评估，一个自动评估者，该评估者确定构成符合C1水平。为了实现我们的目标，我们通过Habe和Talk训练我们的系统获得了10,000种转录的作品。我们有不同的不同技术，以避免数据稀缺和系统过度拟合：EDA，SCL和调节；我们还对其行为进行了不同语言模型的测试。最后，我们对不同系统行为进行了分析，以测量模型校准和伪影的影响。
   - 
  在此项目中，我们试图开发一个自动评估者，该评估员确定他们是否具有C1水平。我们已经通过梁与一词协议之间的协议获得了10,000篇转录的著作，以完成我们的目标。我们已经研究了不同的技术，以避免数据短缺和系统过度进行：EDA，SCL和监管；我们还通过不同的语言模型测试了行为。最后，我们还进行了不同系统的行为分析，以测量模型的校准和人工制品的影响。]]></description>
      <guid>https://arxiv.org/abs/2503.01851</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对大语言模型的机器学习技术的全面调查</title>
      <link>https://arxiv.org/abs/2503.01854</link>
      <description><![CDATA[ARXIV：2503.01854V1公告类型：新 
摘要：本研究研究了在大语言模型（LLMS）的上下文中的机器学习技术，称为\ textit {llm uncorning}。 LLM Uncorning提供了一种原则性的方法，可以从LLMS中删除不良数据（例如敏感或非法信息）的影响，同时保留其整体实用程序而无需进行全面重新培训。尽管研究的兴趣日益增加，但没有系统地组织现有工作并提炼关键见解的全面调查。在这里，我们的目标是弥合这一差距。我们首先介绍LLM学习的定义和范例，然后是现有未学习研究的全面分类法。接下来，我们将当前的学习方法分类，总结其优势和局限性。此外，我们回顾了评估指标和基准，提供了当前评估方法的结构化概述。最后，我们概述了未来研究的有希望的方向，强调了该领域的主要挑战和机遇。]]></description>
      <guid>https://arxiv.org/abs/2503.01854</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>优化检索效果的医学内容，以进行间隔重复学习</title>
      <link>https://arxiv.org/abs/2503.01859</link>
      <description><![CDATA[ARXIV：2503.01859V1公告类型：新 
摘要：大语模型的进步通过实现可扩展有效的学习解决方案彻底改变了医学教育。本文提出了一条采用检索功能的生成系统（RAG）系统的管道，根据经过验证的资源为波兰州专业化考试（PES）准备评论生成。该系统将这些生成的注释和源文档与间隔重复学习算法集成在一起，以增强知识的保留，同时最大程度地减少认知过载。通过采用精致的检索系统，查询改造器和高级读取器，我们修改的抹布解决方案比效率促进了准确性。医学注释者进行严格的评估表明，关键指标的改进，例如文档相关性，可信度和逻辑连贯性，这是通过本文中提出的一系列实验证明的。这项研究强调了抹布系统提供可扩展，高质量和个性化的教育资源的潜力，从而解决了非英语用户。]]></description>
      <guid>https://arxiv.org/abs/2503.01859</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从小型语言模型：重新审视联邦主义论文</title>
      <link>https://arxiv.org/abs/2503.01869</link>
      <description><![CDATA[ARXIV：2503.01869V1公告类型：新 
摘要：很长一段时间以来，联邦主义论文的作者身份一直是询问和辩论的主题，不仅是语言学家和历史学家，而且是统计学家。在可以说是第一个贝叶斯案例研究的情况下，Mosteller and Wallace（1963）提供了将所有有争议的论文归因于麦迪逊的第一个统计证据。我们的论文重新审视了这个历史数据集，但从大小的现代语言模型中。我们回顾一些更流行的大型语言模型（LLM）工具，并在文本分类的背景下从统计的角度检查它们。我们调查是否没有尝试进行任何尝试，一般嵌入构建体可用于风格和归因。我们解释了各种单词/短语嵌入之间的差异，并讨论了如何在文档中汇总它们。与我们的期望相反，我们说明了用单词嵌入的维度扩展可能并不总是有益于归因于降低主题嵌入的尺寸。我们的实验表明，默认的LLM嵌入（即使在手动微调之后）也可能无法始终提高作者身份归因精度。取而代之的是，对``功能单词&#39;&#39;训练的主题嵌入的贝叶斯分析产生了卓越的样本外分类性能。这表明，传统（小）统计语言模型具有可解释性和稳固的理论基础，可以在作者身份归因任务中具有很大的优势。此分析可在GITHUB.COM/sowithub.com/sowonjeong-comlm to llmm llmm llmm llmm llmm llmm。]]></description>
      <guid>https://arxiv.org/abs/2503.01869</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型可以提取客户需求以及专业分析师吗？</title>
      <link>https://arxiv.org/abs/2503.01870</link>
      <description><![CDATA[ARXIV：2503.01870V1公告类型：新 
摘要：确定客户需求（CNS）对于产品管理，产品开发和营销非常重要。应用程序依靠专业分析师解释文本数据（例如，面试成绩单，在线评论）来了解客户体验的细微差别，并简单地提出“工作要做”。该任务在认知上复杂且耗时。当前的实践通过关键字搜索和机器学习促进了该过程，但依靠人类的判断来制定CNS。我们检查大型语言模型（LLMS）是否可以自动提取CNS。由于评估CNS需要专业判断，因此我们与一家营销咨询公司合作，对提取的CNS进行了盲目研究：（1）具有及时工程（基本LLM）的基础LLM（基本LLM），（2）使用专业识别的CNS（SFT LLM）和（3）专业分析师进行专业识别的LLM。提取CNS时，SFT LLM的性能比专业分析师的性能和更好。提取的中枢神经系统已良好，足以确定机会，并通过源含量（无幻觉）证明。 SFT LLM是有效的，并提供了CNS的更完整覆盖范围。基础LLM不够精确或具体。组织可以依靠SFT LLM来减少手动努力，提高CN发音的精度，并为创新和营销策略提供改进的见解。]]></description>
      <guid>https://arxiv.org/abs/2503.01870</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Time-MQA：时间序列多任务询问通过上下文增强</title>
      <link>https://arxiv.org/abs/2503.01875</link>
      <description><![CDATA[ARXIV：2503.01875V1公告类型：新 
摘要：时间序列数据是金融，医疗保健和能源领域的基础。但是，大多数现有的方法和数据集仍集中在狭窄的任务范围上，例如预测或异常检测。为了弥合这一差距，我们介绍了时间序列多任务问题回答（Time-MQA），这是一个统一的框架，可以在多个时间序列任务中进行自然语言查询 - 数值分析任务和通过推理回答的开放式问题。 Time-MQA的核心是TSQA数据集，TSQA数据集是一个大规模数据集，其中包含$ \ sim $ \ sim $ 200K的问题 - 答案对，源自不同的时间序列跨度环境，流量等。这种综合资源涵盖了各种时间序列的长度，并促进了强大的模型开发。我们进一步展示了TSQA数据集增强时间序列推理能力，超越单纯的数字任务并促进与时间数据更高级和直觉的交互作用，如何在TSQA数据集增强时间序列推理功能上不断预训练大型语言模型（Mistral 7b，Llama-3 8b和Qwen-2.5 7b）。完整的TSQA数据集，模型，可执行的代码，用于评估的用户研究问卷以及结果都是开源的。]]></description>
      <guid>https://arxiv.org/abs/2503.01875</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>超越词是您所需要的：基于代理生成AI的社交媒体主题提取器</title>
      <link>https://arxiv.org/abs/2503.01880</link>
      <description><![CDATA[ARXIV：2503.01880V1公告类型：新 
摘要：社交媒体帖子的主题分析提供了对公共话语的主要理解，但是传统方法通常难以捕获非结构化的大规模文本数据的复杂性和细微差别。这项研究介绍了一种新型的主题分析方法，该方法将来自预训练的语言模型的推文嵌入，使用和基质分解降低维度，以及生成的AI，以识别和完善潜在主题。我们的方法群集压缩了推文表示，并采用生成的AI通过代理思想链（COT）提示提取和阐明主题，并具有辅助LLM以进行质量保证。该方法应用于自闭症社区的推文，该小组越来越多地利用社交媒体讨论他们的经验和挑战。通过自动化主题提取过程，目的是在保持原始话语的丰富性的同时发现关键的见解。这项自闭症案例研究证明了拟议方法在改善社交媒体数据的主题分析方面的实用性，提供了可扩展和适应性的框架，可应用于不同的环境。结果突出了将机器学习和生成AI结合起来的潜力，以增强在线社区中主题识别的深度和准确性。]]></description>
      <guid>https://arxiv.org/abs/2503.01880</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于分析收入销售记录的高级深度学习技术：方法和应用程序</title>
      <link>https://arxiv.org/abs/2503.01886</link>
      <description><![CDATA[ARXIV：2503.01886V1公告类型：新 
摘要：本研究对伯特，芬伯特和Ulmfit等深度学习方法进行了比较分析，以分析收入呼叫笔录的情感分析。目的是调查如何利用自然语言处理（NLP）从大规模的财务成绩单中提取情感，从而有助于采用更明智的投资决策和风险管理策略。我们在财务情感分析的背景下检查了每个模型的优势和局限性，重点是数据预处理要求，计算效率和模型优化。通过严格的实验，我们使用关键指标（包括准确性，精度，召回和F1得分）评估其性能。此外，我们讨论了潜在的增强功能，以提高这些模型在财务文本分析中的有效性，从而提供了对其对现实世界财务决策的适用性的见解。]]></description>
      <guid>https://arxiv.org/abs/2503.01886</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM的经验分析以反驳错误信息</title>
      <link>https://arxiv.org/abs/2503.01902</link>
      <description><![CDATA[ARXIV：2503.01902V1公告类型：新 
摘要：虽然大语言模型（LLMS）可以扩大在线错误信息，但它们也显示出解决错误信息的希望。在本文中，我们从经验上研究了三个LLM的能力 -  Chatgpt，Gemini和Claude-反对政治错误信息。我们实施了两步，经过深思熟虑的提示方法，模型首先确定了给定索赔的可靠来源，然后产生有说服力的响应。我们的发现表明，模型努力在真实新闻来源中对他们的回应进行基础，并且倾向于引用左倾来源。我们还观察到模型之间不同程度的响应多样性。我们的发现强调了仅通过及时工程来使用LLM进行事实检查的担忧，强调需要更强大的护栏。我们的结果对研究人员和非技术用户都有影响。]]></description>
      <guid>https://arxiv.org/abs/2503.01902</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>心理板：评估LLM辅助精神病临床实践表现的全面和专业基准</title>
      <link>https://arxiv.org/abs/2503.01903</link>
      <description><![CDATA[ARXIV：2503.01903V1公告类型：新 
摘要：大语言模型（LLMS）的出现提供了潜在的解决方案，以解决诸如医疗资源短缺和精神病临床实践中诊断一致性较低的问题。尽管存在这一潜力，但仍不存在一个稳健而全面的基准测试框架，以评估LLM在正宗的精神病临床环境中的功效。这阻碍了针对精神病应用量身定制的专业LLMS的进步。为了应对这一差距，通过将临床需求纳入精神病学和临床数据中，我们提出了一个基准测试系统Psych Bench，以评估LLM在精神病临床环境中的实际表现。我们使用Psychbench对16个LLM进行了全面的定量评估，并研究了及时设计，经过思考推理，输入文本长度和特定领域的知识对模型性能的影响。通过详细的错误分析，我们确定了现有模型的优势和潜在局限性以及改进的建议指示。随后，进行了一项涉及60位不同资历的精神科医生的临床读者研究，以进一步探索现有LLMS作为不同资历的精神病医生的支持工具的实际好处。通过定量和读者的评估，我们表明，尽管现有模型具有巨大的潜力，但它们在精神病临床实践中尚未足够作为决策工具。读者的研究进一步表明，作为一种辅助工具，LLM可以为初级精神科医生提供特别值得注意的支持，从而有效提高其工作效率和整体临床质量。为了促进该领域的研究，我们将公开提供数据集和评估框架，希望推进LLM在精神病临床环境中的应用。]]></description>
      <guid>https://arxiv.org/abs/2503.01903</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>文本和视觉语言检索中的概念对比编辑</title>
      <link>https://arxiv.org/abs/2503.01914</link>
      <description><![CDATA[ARXIV：2503.01914V1公告类型：新 
摘要：随着深度学习模型的复杂性的增长，实现模型敏捷的解释性变得越来越重要。在这项工作中，我们采用事后的概念对比编辑来揭示在检索模型表示中刻有值得注意的模式和偏见。我们系统地设计针对语音各个部分的最佳和可控制的对比干预措施，并有效地应用它们以黑盒方式解释语言和粘膜语言学预培训模型。此外，我们引入了一个新颖的指标，以评估对比度干预对模型结果的每个单词影响，从而对每种干预措施的有效性进行全面评估。]]></description>
      <guid>https://arxiv.org/abs/2503.01914</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>NCL-UOR在SEMEVAL-2025任务3：检测多语言幻觉和相关可观察的过度文本跨度跨越改进和修改的seflcheckgpt</title>
      <link>https://arxiv.org/abs/2503.01921</link>
      <description><![CDATA[ARXIV：2503.01921V1公告类型：新 
摘要：Semeval-2025 Task 3（MU Shroum）重点是检测多种语言各种大型语言模型（LLM）产生的内容中的幻觉。这项任务不仅涉及确定幻觉的存在，还涉及指出其特定事件。为了应对这一挑战，这项研究介绍了两种方法：修改后的refchecker和修改后的自我检查。修改后的Refchecker将基于及时的事实验证集成到参考文献中，将其构成基于索赔的测试，而不是单个外部知识源。修改后的自我检查符合外部知识，以克服其对内部知识的依赖。此外，两种方法的原始提示设计都得到了增强，以识别LLM生成的文本中的幻觉单词。实验结果证明了该方法的有效性，在检测各种语言的幻觉方面在测试数据集上取得了很高的排名，平均IOU为0.5310，平均COR为0.5669。]]></description>
      <guid>https://arxiv.org/abs/2503.01921</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对DeepSeek-R1在强迫思维中的安全性的输出长度影响</title>
      <link>https://arxiv.org/abs/2503.01923</link>
      <description><![CDATA[ARXIV：2503.01923V1公告类型：新 
摘要：大型语言模型（LLM）表现出强大的推理能力，但是它们在对抗条件下的安全仍然是一个挑战。这项研究研究了输出长度对DeepSeek-R1稳健性的影响，尤其是在强迫思维方案中。我们分析了各种对抗性提示中的响应，发现较长的输出可以通过自我纠正来提高安全性，但某些攻击类型利用了延长的世代。我们的发现表明，应动态控制输出长度，以平衡推理有效性和安全性。我们建议基于学习的政策调整和适应性令牌长度调节，以提高LLM安全性。]]></description>
      <guid>https://arxiv.org/abs/2503.01923</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不自然的语言不是错误，而是LLM的功能</title>
      <link>https://arxiv.org/abs/2503.01926</link>
      <description><![CDATA[ARXIV：2503.01926V1公告类型：新 
摘要：已经观察到大型语言模型（LLM）处理非人类可读的文本序列（例如越狱提示），通常被视为对齐LLM的错误。在这项工作中，我们提出了一项系统的调查，挑战了这种看法，表明不自然的语言 - 人类似乎无法理解的字符串，但要维持LLMS的语义含义 - 包含模型可用的潜在特征。值得注意的是，不自然的语言具有潜在特征，可以在推理过程中跨越不同的模型和任务。此外，在不自然版本的指令数据集上进行了微调的模型与接受自然语言培训的模型在PAR上执行了PAR，在各种基础模型中平均达到了长度控制的Alpacaeval 2.0的49.71获胜率。此外，通过全面的分析，我们通过过滤噪声并从过滤单词中推断上下文含义来证明LLMS来处理不自然的语言。]]></description>
      <guid>https://arxiv.org/abs/2503.01926</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>询问：通过自我校正澄清增强LLMS工具使用</title>
      <link>https://arxiv.org/abs/2503.01940</link>
      <description><![CDATA[ARXIV：2503.01940V1公告类型：新 
摘要：大型语言模型（LLMS）在工具学习中表现出了显着的功能。在实际情况下，用户查询通常是模棱两可和不完整的，需要有效的澄清。但是，现有的交互式澄清方法面临两个关键局限性：依赖手动构造的数据集以及在多转移澄清过程中缺乏误差校正机制。我们提出asktoact，它通过利用查询及其工具调用解决方案之间的结构映射来解决这些挑战。我们的关键见解是工具参数自然代表明确的用户意图。通过系统地从查询中删除关键参数，同时将其保留为地面真理，我们可以自动构造高质量的培训数据。我们通过使用选择性掩蔽机制对错误校正增强数据进行微调来进一步增强模型鲁棒性，从而在澄清相互作用期间实现动态误差检测。全面的实验表明，Ask施用明显胜过现有方法，在恢复关键的未指定意图并平均提高澄清效率48.34％的同时，同时保持高精度的工具调用准确性。我们的框架在不同的复杂性水平上表现出良好的性能，并成功地概括为完全看不见的API，而无需额外的培训，从而达到了与GPT-4相当的计算资源的性能。]]></description>
      <guid>https://arxiv.org/abs/2503.01940</guid>
      <pubDate>Wed, 05 Mar 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>