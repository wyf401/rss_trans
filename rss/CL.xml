<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 29 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过情绪跨模态融合和类间对比学习增强对话中的情绪识别</title>
      <link>https://arxiv.org/abs/2405.17900</link>
      <description><![CDATA[arXiv:2405.17900v1 Announce Type: new 
摘要：对话中的情绪识别（ERC）的目的是根据上下文信息识别话语的情绪类别。以前的ERC方法依赖于简单的连接进行跨模态融合，忽略了模态之间的信息差异，导致模型无法关注特定模态的情绪信息。同时，没有处理模态之间共享的信息来产生情绪。信息冗余问题。为了克服这些限制，我们提出了一种基于向量连接的跨模态融合情绪预测网络。该网络主要包括两个阶段：基于连接向量的多模态特征融合阶段和基于融合特征的情绪分类阶段。此外，我们设计了一个基于情绪标签的监督类间对比学习模块。实验结果证实了所提方法的有效性，在IEMOCAP和MELD数据集上表现出优异的性能。]]></description>
      <guid>https://arxiv.org/abs/2405.17900</guid>
      <pubDate>Thu, 30 May 2024 03:15:00 GMT</pubDate>
    </item>
    <item>
      <title>不仅仅是灾难性遗忘：为特定领域的法学硕士 (LLM) 整合通用能力</title>
      <link>https://arxiv.org/abs/2405.17830</link>
      <description><![CDATA[arXiv:2405.17830v1 公告类型：新
摘要：大型语言模型（LLM）在特定领域任务上进行微调后，在一般任务上的表现会下降，这种现象被称为灾难性遗忘（CF）。然而，本文提出了超越CF的领域特定LLM实际应用的另一个挑战，称为一般能力集成（GCI），这需要在单个实例中集成一般能力和领域知识。GCI的目标不仅仅是保留以前获得的一般能力和新的领域知识，而是以有凝聚力的方式协调和利用这两组技能来提高领域特定任务的表现。以法律领域为例，我们精心设计了三组不缺乏实用性的训练和测试任务，并构建了相应的数据集。为了更好地将一般能力融入特定领域场景，我们引入了ALoRA，它在LoRA上使用多头注意力模块，促进从前一个token到当前token的直接信息传递。这种增强允许表示根据注意力在特定领域知识和一般能力之间动态切换。对提出的任务进行了广泛的实验。结果展示了我们的设置的重要性以及我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.17830</guid>
      <pubDate>Thu, 30 May 2024 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>基准低估了多语言对话代理的准备程度</title>
      <link>https://arxiv.org/abs/2405.17840</link>
      <description><![CDATA[arXiv:2405.17840v1 公告类型：新
摘要：由于训练数据获取成本高昂，创建多语言任务导向对话 (TOD) 代理具有挑战性。遵循提高训练数据效率的研究趋势，我们首次表明，上下文学习足以解决多语言 TOD。
为了处理具有挑战性的对话状态跟踪 (DST) 子任务，我们将其分解为更简单的步骤，这些步骤更适合上下文学习，其中仅使用少量样本。我们在多语言 TOD 数据集 X-RiSAWOZ 上测试了我们的方法，该数据集有 12 个域，包括中文、英语、法语、韩语、印地语和混合代码的印地语-英语。我们对这 6 种语言的逐向 DST 准确率范围为 55.6% 到 80.3%，似乎比微调模型实现的 SOTA 结果更差，后者的准确率从 60.7% 到 82.8%；我们在响应生成 (RG) 子任务中的 BLEU 分数也明显低于 SOTA。
然而，在对验证集进行手动评估后，我们发现通过纠正金标签错误和改进数据集注释模式，使用我们的提示的 GPT-4 可以实现 (1) DST 中 89.6%-96.8% 的准确率，以及 (2) 跨不同语言的 99% 以上的正确响应生成。这让我们得出结论，当前的自动指标严重低估了上下文学习的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.17840</guid>
      <pubDate>Thu, 30 May 2024 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 进行算术推理：Prolog 生成和排列</title>
      <link>https://arxiv.org/abs/2405.17893</link>
      <description><![CDATA[arXiv:2405.17893v1 公告类型：新
摘要：使用思想链 (CoT) 指导大型语言模型 (LLM) 解决小学数学问题已取得巨大成功。然而，CoT 方法依赖于 LLM 来生成一系列算术计算，这很容易出现级联计算错误。我们假设 LLM 应该专注于从数学问题描述中提取谓词并生成符号公式，以便可以通过外部代码解释器完成底层计算。我们研究使用 LLM 生成 Prolog 程序来解决数学问题。实验结果表明，在三个不同的 LLM 中，我们基于 Prolog 的算术问题求解在 GSM8K 基准测试中优于 CoT 生成。此外，考虑到 Prolog 中谓词和符号公式的不敏感顺序，我们建议通过数据增强对基本事实谓词进行排列，以实现更稳健的 LLM 训练。]]></description>
      <guid>https://arxiv.org/abs/2405.17893</guid>
      <pubDate>Thu, 30 May 2024 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>通过通用语言模型实现语法错误纠正的检测-纠正结构</title>
      <link>https://arxiv.org/abs/2405.17804</link>
      <description><![CDATA[arXiv:2405.17804v1 公告类型：新
摘要：语法错误校正 (GEC) 是一项致力于以最少的编辑纠正文本的任务，可以将其分解为两个部分：检测和校正。然而，以前的工作主要集中在直接校正上，之前没有将两者整合到单个模型中的努力。此外，大型语言模型 (LLM) 对检测-校正范式的探索仍未得到充分开发。本文介绍了一种基于通用语言模型 (GLM) 的集成检测-校正结构 DeCoGLM。检测阶段采用容错检测模板，而校正阶段利用自回归掩码填充进行局部错误校正。通过对输入标记进行战略组织和对注意掩码进行修改，我们促进了单个模型内的多任务学习。我们的模型在英语和中文 GEC 数据集上表现出与最先进模型相媲美的性能。进一步的实验证明了 LLM 中检测-校正结构的有效性，为 GEC 指明了一个有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2405.17804</guid>
      <pubDate>Thu, 30 May 2024 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>TransVIP：具有语音和等时保存功能的语音到语音翻译系统</title>
      <link>https://arxiv.org/abs/2405.17809</link>
      <description><![CDATA[arXiv:2405.17809v1 公告类型：新
摘要：人们对将语音从一种语言直接翻译成另一种语言（称为端到端语音到语音翻译）的研究兴趣和趋势日益增长。然而，大多数端到端模型都难以超越级联模型，即通过连接语音识别、机器翻译和文本到语音模型而形成的管道框架。主要挑战源于直接翻译任务固有的复杂性和数据稀缺性。在本研究中，我们引入了一种新颖的模型框架 TransVIP，它以级联方式利用不同的数据集，但通过联合概率促进端到端推理。此外，我们提出了两个独立的编码器，以在翻译过程中保留说话者的语音特征和与源语音的等时性，使其非常适合视频配音等场景。我们对法语-英语语言对的实验表明，我们的模型优于当前最先进的语音到语音翻译模型。]]></description>
      <guid>https://arxiv.org/abs/2405.17809</guid>
      <pubDate>Thu, 30 May 2024 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>Conv-CoA：通过对话链改进大型语言模型中的开放域问答</title>
      <link>https://arxiv.org/abs/2405.17822</link>
      <description><![CDATA[arXiv:2405.17822v1 公告类型：新
摘要：我们提出了一种用于开放域对话式问答 (OCQA) 的对话式行动链 (Conv-CoA) 框架。与文献相比，Conv-CoA 解决了三个主要挑战：(i) 与实时或领域事实不一致的不真实幻觉，(ii) 对话场景中的推理性能较弱，以及 (iii) 对话信息检索中的表现不令人满意。我们的主要贡献是一种动态推理检索机制，它提取问题的意图并将其分解为一个推理链，通过系统提示、预先设计的动作、更新上下文知识集 (CKS) 和一种新颖的基于 Hopfield 的检索器来解决。从方法论上讲，我们提出了一种资源效率高的 Hopfield 检索器，以提高我们行动中对话信息检索的效率和准确性。此外，我们提出了一个对话多参考信念分数 (Conv-MRFS) 来验证和解决对话中检索到的知识和答案之间的冲突。从实证上讲，我们在五个不同的研究方向和两个公共基准上对我们的框架和 23 种最先进的方法进行了比较。这些比较表明，我们的 Conv-CoA 在准确性和效率方面都优于其他方法。]]></description>
      <guid>https://arxiv.org/abs/2405.17822</guid>
      <pubDate>Thu, 30 May 2024 03:14:58 GMT</pubDate>
    </item>
    <item>
      <title>ORLM：为优化建模训练大型语言模型</title>
      <link>https://arxiv.org/abs/2405.17743</link>
      <description><![CDATA[arXiv:2405.17743v1 公告类型：新
摘要：大型语言模型 (LLM) 已成为复杂运筹学 (OR) 自动化优化建模的强大工具。然而，当前的方法严重依赖于专有 LLM 的即时工程（例如，多智能体合作），从而引发了数据隐私问题，这可能会阻碍行业应用。为了解决这个问题，我们建议训练开源 LLM 进行优化建模。我们确定了 OR LLM 训练数据集的四个关键要求，设计并实现了 OR-Instruct，这是一种根据特定要求定制的半自动化合成数据创建过程。我们还介绍了 IndustryOR 基准，这是第一个用于测试 LLM 解决现实世界 OR 问题的工业基准。我们将来自 OR-Instruct 的数据应用于各种 7b 大小的开源 LLM（称为 ORLM），从而显着提高了优化建模的能力。我们性能最佳的 ORLM 在 NL4OPT、MAMO 和 IndustryOR 基准测试中实现了最先进的性能。我们的代码和数据将在 \url{https://github.com/Cardinal-Operations/ORLM} 上提供。]]></description>
      <guid>https://arxiv.org/abs/2405.17743</guid>
      <pubDate>Thu, 30 May 2024 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>XL3M：基于分段推理的无需训练的 LLM 长度扩展框架</title>
      <link>https://arxiv.org/abs/2405.17755</link>
      <description><![CDATA[arXiv:2405.17755v1 公告类型：新
摘要：长度泛化失败问题，即大型语言模型 (LLM) 无法推广到长度超过其最大训练长度的文本，极大地限制了 LLM 在流式长输入场景中的应用。为了解决这个问题，现有的方法要么需要大量成本，要么引入精度损失。在本文中，我们通过经验发现 LLM 预测的准确性与其确定性高度相关。基于此，我们提出了一个高效的免训练框架，称为 XL3M（意为超长大型语言模型），它使在短序列上训练的 LLM 能够推理极长的序列而无需任何进一步的训练或微调。在 XL3M 框架下，输入上下文首先会被分解为多个短子上下文，其中每个子上下文包含一个独立的段和一个公共“问题”，该问题距离原始上下文的末尾有几个标记。然后XL3M给出了一种衡量每个片段与“问题”之间相关性的方法，并通过按时间顺序拼接所有相关片段来构建一个简洁的关键上下文。进一步使用关键上下文代替原始上下文完成推理任务。综合基准测试的评估显示了XL3M的优越性。使用我们的框架，Llama2-7B模型能够在8卡华为Ascend 910B NPU机器上推理20M长的序列，每卡64GB内存。]]></description>
      <guid>https://arxiv.org/abs/2405.17755</guid>
      <pubDate>Thu, 30 May 2024 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>基于随机过程的序列评价</title>
      <link>https://arxiv.org/abs/2405.17764</link>
      <description><![CDATA[arXiv:2405.17764v1 公告类型：新
摘要：对长文本序列进行建模和分析是自然语言处理的一项基本任务。使用神经语言模型成功捕捉长文本动态将促进许多下游任务，如连贯性评估、文本生成、机器翻译等。本文提出了一种通过随机过程对序列进行建模的新方法。我们为文本编码器引入了一个基于可能性的训练目标，并设计了一个比以前的方法更彻底的长文本评估测量（分数）。提出的训练目标有效地保持了序列的连贯性，而新的分数全面捕捉了时间和空间依赖性。我们的新分数的理论特性显示了它在序列评估中的优势。实验结果显示，它在各种序列评估任务中都表现出色，包括不同长度的文档内和文档之间的全局和局部区分。我们还证明了编码器在区分人类和人工智能书面文本方面取得了有竞争力的结果。]]></description>
      <guid>https://arxiv.org/abs/2405.17764</guid>
      <pubDate>Thu, 30 May 2024 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>获取你的数据：利用上下文大型语言模型提高归纳准确性</title>
      <link>https://arxiv.org/abs/2405.17712</link>
      <description><![CDATA[arXiv:2405.17712v1 公告类型：新
摘要：本文介绍了用于准确插补方法的上下文语言模型 (CLAIM)，这是一种新颖的策略，它利用预先训练的大型语言模型 (LLM) 的广泛知识和推理能力来解决表格数据集中的缺失数据挑战。与主要依赖数值估计的传统插补方法不同，CLAIM 使用上下文相关的自然语言描述符来填充缺失值。这种方法将数据集转换为自然语言上下文格式，本质上更符合 LLM 的功能，从而促进 LLM 的双重用途：首先，生成缺失值描述符，然后在丰富的数据集上微调 LLM，以提高下游任务的性能。我们对不同数据集和缺失模式的评估表明，CLAIM 的性能优于现有的插补技术。此外，我们对上下文特定描述符与通用描述符对缺失数据的有效性的研究突出了上下文准确性在提高 LLM 数据插补性能方面的重要性。结果强调了 CLAIM 显著提高数据分析和机器学习模型的可靠性和质量的潜力，为处理缺失数据提供了更细致、更有效的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2405.17712</guid>
      <pubDate>Thu, 30 May 2024 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>C$^{3}$Bench：大型语言模型的全面古典汉语理解基准</title>
      <link>https://arxiv.org/abs/2405.17732</link>
      <description><![CDATA[arXiv:2405.17732v1 公告类型：新
摘要：古典汉语理解（CCU）在保护和探索优秀中国传统文化方面具有重要价值。最近，研究人员试图利用大型语言模型（LLM）出色的理解和语义能力来发挥 CCU 的潜力。然而，没有全面的基准来评估 LLM 的 CCU 能力。为了填补这一空白，本文引入了 C$^{3}$bench，这是一个全面的古典汉语理解基准，它包含 50,000 个文本对，用于五个主要 CCU 任务，包括分类、检索、命名实体识别、标点符号和翻译。此外，C$^{3}$bench 中的数据来自十个不同的领域，涵盖了古典汉语的大多数类别。利用提出的 C$^{3}$bench，我们广泛评估了 15 个代表性 LLM 在所有五个 CCU 任务上的定量性能。我们的研究结果不仅建立了 LLM 的 CCU 能力的公共排行榜，而且还获得了一些发现。具体而言，现有的 LLM 在 CCU 任务上表现不佳，并且仍然不如监督模型。此外，结果表明 CCU 是一项需要特别关注的任务。我们相信这项研究可以为基于 LLM 的 CCU 研究的未来发展提供标准基准、全面基线和宝贵见解。评估流程和数据集可在 \url{https://github.com/SCUT-DLVCLab/C3bench} 获得。]]></description>
      <guid>https://arxiv.org/abs/2405.17732</guid>
      <pubDate>Thu, 30 May 2024 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>MobileConvRec：用于移动应用推荐的对话数据集</title>
      <link>https://arxiv.org/abs/2405.17740</link>
      <description><![CDATA[arXiv:2405.17740v1 公告类型：新
摘要：现有的推荐系统主要集中在两种范式上：1-基于历史用户-项目交互的推荐和2-对话式推荐。对话式推荐系统促进用户与系统之间的自然语言对话，使系统能够征求用户的明确需求，同时使用户能够查询推荐并提供反馈。由于自然语言处理的重大进步，对话式推荐系统已获得重视。现有的对话式推荐数据集极大地促进了各自领域的研究。尽管近年来移动用户和应用程序呈指数级增长，但对话式移动应用推荐系统的研究仍面临巨大的限制。这种限制主要归因于缺乏专门针对移动应用的高质量基准数据集。为了促进对话式移动应用推荐的研究，我们引入了 MobileConvRec。MobileConvRec 通过利用 Google Play 商店中的真实用户与移动应用的交互来模拟对话，这些交互最初是在大型移动应用推荐数据集 MobileRec 中捕获的。所提出的对话式推荐数据集将反映隐性用户偏好的连续用户-项目交互与全面的多轮对话相结合，以有效掌握明确的用户需求。MobileConvRec 包含 12K 多个多轮推荐相关对话，涵盖 45 个应用类别。此外，MobileConvRec 为每个应用提供丰富的元数据，例如权限数据、安全和隐私相关信息以及应用的二进制可执行文件等。我们通过对几个预先训练的大型语言模型的比较研究，证明了 MobileConvRec 可以作为对话式移动应用推荐的绝佳试验台。]]></description>
      <guid>https://arxiv.org/abs/2405.17740</guid>
      <pubDate>Thu, 30 May 2024 03:14:56 GMT</pubDate>
    </item>
    <item>
      <title>可解释的机器学习西班牙法律判决的多标签分类</title>
      <link>https://arxiv.org/abs/2405.17610</link>
      <description><![CDATA[arXiv:2405.17610v1 公告类型：新
摘要：机器学习 (ML) 等人工智能技术尚未在法律领域发挥最大潜力。这部分是由于他们对自己的决定提供的解释不足。当法律从业者搜索法理学以收集案件的背景知识时，具有解释能力的自动专家系统特别有用。因此，我们提出了一个混合系统，该系统将 ML 用于判决（句子）的多标签分类，并将视觉和自然语言描述用于解释目的，并通过自然语言处理技术和深度法律推理来识别所涉及的实体，例如当事人。我们不知道有任何关于法律判决的自动多标签分类的先前工作，同时也为最终用户提供具有可比整体质量的自然语言解释。我们的解决方案在由法律专家注释的标记数据集上实现了超过 85% 的微精度。这证明了它的兴趣在于将人类专家从单调的劳动密集型法律分类任务中解放出来。]]></description>
      <guid>https://arxiv.org/abs/2405.17610</guid>
      <pubDate>Thu, 30 May 2024 03:14:55 GMT</pubDate>
    </item>
    <item>
      <title>发自内心的叙述：通过法学硕士课程追踪个人故事中的同理心和叙述风格</title>
      <link>https://arxiv.org/abs/2405.17633</link>
      <description><![CDATA[arXiv:2405.17633v1 公告类型：新
摘要：同理心是实现亲社会行为的基石，可以通过在故事中分享个人经历来唤起。虽然同理心受到叙事内容的影响，但直觉上，人们也会通过叙事风格对故事的讲述方式做出反应。然而，同理心和叙事风格之间的关系尚未完全了解。在这项工作中，我们使用 LLM 和大规模众包研究对风格和同理心之间的关系进行了实证检验和量化。我们引入了一种新颖的基于理论的分类法 HEART（人类同理心和叙事分类法），它描述了可以引起对故事叙述者同理心的叙事风格元素。我们确定了 LLM 在从 HEART 中提取叙事元素方面的表现，表明使用我们的分类法进行提示可以产生合理的、人类级别的注释，超出了以前基于词典的方法所能做到的。为了展示我们分类法的实证应用，我们通过一项大规模众包研究收集了故事共情判断数据集，参与者人数为 N=2,624。我们表明，通过 LLM 提取的叙事元素（尤其是情感生动性和情节量）可以阐明叙事风格培养对个人故事的共情的途径。我们的工作表明，此类模型可用于叙事分析，从而获得以人为本的社会和行为洞察。]]></description>
      <guid>https://arxiv.org/abs/2405.17633</guid>
      <pubDate>Thu, 30 May 2024 03:14:55 GMT</pubDate>
    </item>
    </channel>
</rss>