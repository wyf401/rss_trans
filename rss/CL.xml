<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 21 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>探索量化对 StarCoder2 能耗和推理时间的影响</title>
      <link>https://arxiv.org/abs/2411.12758</link>
      <description><![CDATA[arXiv:2411.12758v1 公告类型：新
摘要：本研究考察了量化和修剪策略，以减少代码大型语言模型 (LLM) 推理中的能耗。使用 StarCoder2，我们观察到由于吞吐量较低和一些准确性损失，量化带来的能源需求增加。相反，修剪减少了能源使用，但损害了性能。结果突出了 LLM 模型压缩中的挑战和权衡。我们建议未来研究硬件优化量化，以提高效率，同时将准确性损失降至最低。]]></description>
      <guid>https://arxiv.org/abs/2411.12758</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型辅助因果发现中消除幻觉的新方法</title>
      <link>https://arxiv.org/abs/2411.12759</link>
      <description><![CDATA[arXiv:2411.12759v1 公告类型：新
摘要：大型语言模型 (LLM) 在因果发现中越来越多地被用来替代人类领域专家，这凸显了对最佳模型选择的需求。本文首次对流行的因果发现 LLM 进行了幻觉调查。我们表明，在因果发现中使用 LLM 时会出现幻觉，因此 LLM 的选择很重要。我们建议在有高质量数据可用时使用检索增强生成 (RAG) 来减少幻觉。此外，我们介绍了一种新方法，在辩论中使用多个 LLM 和一个仲裁者来审核因果图中的边缘，从而实现与 RAG 相当的幻觉减少。]]></description>
      <guid>https://arxiv.org/abs/2411.12759</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用法学硕士玩语言游戏导致越狱</title>
      <link>https://arxiv.org/abs/2411.12762</link>
      <description><![CDATA[arXiv:2411.12762v1 公告类型：新 
摘要：大型语言模型 (LLM) 的出现刺激了众多越狱技术的发展，旨在绕过其针对恶意攻击的安全防御。一种有效的越狱方法是确定安全泛化失败的领域，这种现象称为不匹配泛化。在本文中，我们介绍了两种基于不匹配泛化的新型越狱方法：自然语言游戏和自定义语言游戏，这两种方法都能有效绕过 LLM 的安全机制，种类繁多，变体各异，使其难以防御并导致高攻击率。自然语言游戏涉及使用合成语言结构以及与这些结构交织在一起的动作，例如 Ubbi Dubbi 语言。基于这一现象，我们提出了自定义语言游戏方法：通过使用各种自定义规则与 LLM 互动，我们成功地在多个 LLM 平台上执行越狱攻击。大量实验证明了我们方法的有效性，在 GPT-4o 上的成功率为 93%，在 GPT-4o-mini 上的成功率为 89%，在 Claude-3.5-Sonnet 上的成功率为 83%。此外，为了研究安全对齐的可推广性，我们使用自定义语言游戏对 Llama-3.1-70B 进行了微调，以在我们的数据集中实现安全对齐，并发现当通过其他语言游戏进行交互时，微调后的模型仍然无法识别有害内容。这一发现表明，LLM 中嵌入的安全对齐知识无法推广到不同的语言格式，从而为该领域的未来研究开辟了新的途径。]]></description>
      <guid>https://arxiv.org/abs/2411.12762</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SEFD：用于检测 LLM 生成文本的语义增强框架</title>
      <link>https://arxiv.org/abs/2411.12764</link>
      <description><![CDATA[arXiv:2411.12764v1 公告类型：新
摘要：大型语言模型 (LLM) 的广泛采用迫切需要强大的工具来检测 LLM 生成的文本，尤其是考虑到 \textit{释义} 技术通常会逃避现有的检测方法。为了应对这一挑战，我们提出了一种用于检测 LLM 生成的文本 (SEFD) 的新型语义增强框架，该框架利用基于检索的机制来充分利用文本语义。我们的框架通过系统地将基于检索的技术与传统检测器相结合，改进了现有的检测方法，采用了精心策划的检索机制，在全面覆盖和计算效率之间取得了平衡。我们展示了我们的方法在现实世界应用中常见的顺序文本场景中的有效性，例如在线论坛和问答平台。通过对各种 LLM 生成的文本和检测方法进行全面的实验，我们证明我们的框架在解释场景中显著提高了检测准确性，同时保持了标准 LLM 生成内容的稳健性。]]></description>
      <guid>https://arxiv.org/abs/2411.12764</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用半监督学习进行社交媒体上的自杀风险评估</title>
      <link>https://arxiv.org/abs/2411.12767</link>
      <description><![CDATA[arXiv:2411.12767v1 公告类型：新
摘要：随着社交媒体社区日益成为有自杀倾向者发帖和聚集的地方，自然语言处理为开发自动自杀风险评估系统提供了一条令人兴奋的途径。然而，过去的努力受到标记数据缺乏和可用标记数据中的类别不平衡的影响。为了适应这项任务不完善的数据环境，我们提出了一个半监督框架，该框架利用标记（n=500）和未标记（n=1,500）数据，并通过一种旨在处理不平衡数据集的新型伪标签获取过程扩展了自训练算法。为了进一步确保伪标签质量，我们手动验证了伪标签数据的一个子集，该子集在多次伪标签生成试验中未一致预测。我们测试了各种模型作为该框架的骨干，最终决定 RoBERTa 表现最佳。最终，通过利用部分验证的伪标记数据以及真实标记数据，我们大大提高了模型评估社交媒体帖子自杀风险的能力。]]></description>
      <guid>https://arxiv.org/abs/2411.12767</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CROW：通过内部一致性正则化消除大型语言模型中的后门</title>
      <link>https://arxiv.org/abs/2411.12768</link>
      <description><![CDATA[arXiv:2411.12768v1 公告类型：新
摘要：最近的研究表明，大型语言模型 (LLM) 容易受到后门攻击，攻击者会嵌入隐藏的触发器来操纵模型响应。现有的后门防御方法主要针对视觉或分类任务而设计，因此对文本生成任务无效，从而使 LLM 容易受到攻击。我们引入了内部一致性正则化 (CROW)，这是一种使用一致性正则化微调来解决后门触发器导致的逐层不一致问题的新防御方法。CROW 利用了以下直觉：干净的模型在各层隐藏表示中表现出平滑、一致的过渡，而后门模型在触发时会表现出明显的波动。通过对抗性扰动和正则化来强制内部一致性，CROW 可以消除后门效应，而无需干净的参考模型或先前的触发器知识，仅依赖一小组干净的数据。这使得它可以在各种 LLM 架构中部署。实验结果表明，在 Llama-2 (7B, 13B)、CodeLlama (7B, 13B) 和 Mistral-7B 等模型上，CROW 能够持续显著降低各种后门策略和任务（包括负面情绪、有针对性的拒绝和代码注入）的攻击成功率，同时保留模型的生成能力。]]></description>
      <guid>https://arxiv.org/abs/2411.12768</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索语言模型代理在注意力分散的情况下操作不同体验语境的能力</title>
      <link>https://arxiv.org/abs/2411.12828</link>
      <description><![CDATA[arXiv:2411.12828v1 公告类型：新
摘要：大型语言模型 (LLM) 代理在越来越多的领域中显示出前景。在许多提议的应用中，预计代理会根据输入提示中呈现的累积经验进行推理。我们提出了 OEDD（Operationalize Experience despite Distraction）语料库，这是一组经过人工注释验证的场景，具有预先编写的代理历史，其中代理必须在存在干扰的情况下根据不同的经验信息做出决策。我们使用最小的思路链提示策略评估了三款最先进的 LLM（GPT-3.5 Turbo、GPT-4o 和 Gemini 1.5 Pro），并观察到当 (1) 输入上下文包含超过 1,615 个历史交互标记、(2) 一个至关重要的决策前提是两个不同环境前提的正确结论、以及 (3) 一个微不足道但分散注意力的干扰事实随之而来时，所有 LLM 在选择两个动作中更好的一个方面的表现都比随机选择差。我们的代码和测试语料库可公开获取：https://github.com/sonnygeorge/OEDD 。]]></description>
      <guid>https://arxiv.org/abs/2411.12828</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AzSLD：使用 Baseline Software 进行手指拼写、单词和句子翻译的阿塞拜疆手语数据集</title>
      <link>https://arxiv.org/abs/2411.12865</link>
      <description><![CDATA[arXiv:2411.12865v1 公告类型：新
摘要：手语处理技术的发展依赖于广泛而可靠的数据集、说明和道德准则。我们提供了一个全面的阿塞拜疆手语数据集 (AzSLD)，该数据集收集自不同的手语用户和语言参数，以促进手语识别和翻译系统的进步并支持当地手语社区。该数据集是在基于视觉的 AzSL 翻译项目的框架内创建的。本研究将数据集作为手指拼写字母和句子和单词级手语数据集的摘要。该数据集是从不同年龄、性别和手语风格的手语者那里收集的，视频从两个摄像机角度录制，以完整捕捉每个手势的细节。这种方法确保了手势识别模型的稳健训练和评估。AzSLD 包含 30,000 个视频，每个视频都经过精心注释，带有准确的手势标签和相应的语言翻译。该数据集附有技术文档和源代码，以方便其在训练和测试中的使用。该数据集为从事手语识别、翻译或合成的研究人员和开发人员提供了宝贵的标记数据资源。整个项目都严格遵守道德准则，所有参与者都对收集、发布和使用数据提供了知情同意。]]></description>
      <guid>https://arxiv.org/abs/2411.12865</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>您所需要的只是 Signformer：面向手语的边缘 AI</title>
      <link>https://arxiv.org/abs/2411.12901</link>
      <description><![CDATA[arXiv:2411.12901v1 公告类型：新
摘要：由于资源密集型方法的增加，手语翻译，尤其是无注释范式中的手语翻译，正面临不切实际和不可持续的困境。当代最先进技术 (SOTA) 在很大程度上依赖于预训练的复杂主干，例如大型语言模型 (LLM)、嵌​​入源或大量数据集，导致在现实世界场景中可持续使用的参数和计算效率相当低下。尽管他们取得了成功，但遵循这一研究方向会破坏该领域的总体使命，即为听力障碍人群和普通人群创造巨大的价值。我们致力于 LLM 和自然语言处理 (NLP) 研究的主流趋势，追求架构的深刻根本变革，以实现从头开始的改进，而无需预训练模型、先验知识转移或任何非从头开始的 NLP 策略的外部帮助。
介绍 Signformer，这是一个从头开始的 Feather-Giant，它将该领域转变为边缘 AI，它以 LLM 能力和可部署的紧凑性重新定义性能和效率的极限。在本文中，我们展示了手语的性质分析，以指导我们的算法设计，并提供具有卷积和注意新颖性的可扩展转换器管道。截至 2024 年，我们在排行榜上取得了新的第二名，与最优秀的方法相比，参数减少了 467-1807 倍，并且在 57 万个参数的更轻配置中胜过几乎所有其他方法。]]></description>
      <guid>https://arxiv.org/abs/2411.12901</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一种灵活的大型语言模型护栏开发方法，适用于离题提示检测</title>
      <link>https://arxiv.org/abs/2411.12946</link>
      <description><![CDATA[arXiv:2411.12946v1 公告类型：新
摘要：大型语言模型容易出现离题滥用，用户可能会提示这些模型执行超出其预期范围的任务。当前的护栏通常依赖于精选示例或自定义分类器，存在高假阳性率、有限的适应性以及需要预生产中不可用的真实数据不切实际的问题。在本文中，我们介绍了一种灵活的、无数据的护栏开发方法来应对这些挑战。通过彻底定性地定义问题空间并将其传递给 LLM 以生成不同的提示，我们构建了一个合成数据集来对优于启发式方法的离题护栏进行基准测试和训练。此外，通过将任务定义为对用户提示是否与系统提示相关进行分类，我们的护栏可以有效地推广到其他滥用类别，包括越狱和有害提示。最后，我们通过开源合成数据集和非主题护栏模型进一步为该领域做出贡献，为在预生产环境中开发护栏提供宝贵的资源并支持未来 LLM 安全的研究和开发。]]></description>
      <guid>https://arxiv.org/abs/2411.12946</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用目标语言的数据约束来训练双语 LM</title>
      <link>https://arxiv.org/abs/2411.12986</link>
      <description><![CDATA[arXiv:2411.12986v1 公告类型：新
摘要：大型语言模型是根据当前的扩展定律要求在网络上的大量数据上进行训练的。由于英语拥有丰富的高质量预训练数据，因此取得了大部分进展。然而，对于大多数其他语言来说，这种高质量的预训练数据是无法获得的。在这项工作中，我们研究如何通过从具有高质量数据的辅助语言中获取数据来提高数据受限目标语言中预训练模型的性能。我们通过量化使用数据丰富的辅助语言数据进行训练与使用目标语言进行训练之间的性能差距、探索翻译系统的好处、研究数据受限语言的模型扩展的局限性以及提出从辅助语言中上采样数据的新方法来研究这一点。我们的结果表明，更强大的辅助数据集可以在不修改模型或训练目标的情况下提高相近语言的性能，特别是，由于开发了信息更丰富的英语预训练数据集而获得的性能提升可以扩展到数据有限的目标语言设置。]]></description>
      <guid>https://arxiv.org/abs/2411.12986</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MemoryFormer：通过移除全连接层来最小化 Transformer 计算</title>
      <link>https://arxiv.org/abs/2411.12992</link>
      <description><![CDATA[arXiv:2411.12992v1 公告类型：新
摘要：为了降低大型语言模型的计算复杂度，人们付出了巨大的努力来提高线性注意和 flash-attention 等 Transformer 模型的效率。然而，为了追求更高的性能，模型大小和相应的计算复杂度也在不断扩大。在这项工作中，我们提出了 MemoryFormer，一种新颖的 Transformer 架构，它从新的角度显着降低了计算复杂度 (FLOP)。我们消除了 Transformer 模型的几乎所有计算，除了多头注意操作所需的必要计算。这是通过使用一种替代特征转换方法来取代全连接层的线性投影来实现的。具体而言，我们首先构建一组内存查找表，这些查找表存储大量离散向量以替换线性投影中使用的权重矩阵。然后我们使用哈希算法根据输入嵌入动态检索相关的向量子集。检索到的向量组合在一起将形成输出嵌入，它提供了全连接层中矩阵乘法运算结果的估计。与进行矩阵乘法相比，从内存中检索数据块是一种更便宜的操作，只需要很少的计算。我们从头开始训练 MemoryFormer，并在各种基准上进行大量实验，以证明所提模型的有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.12992</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>耐心是大型语言模型推理的关键</title>
      <link>https://arxiv.org/abs/2411.13082</link>
      <description><![CDATA[arXiv:2411.13082v1 公告类型：新
摘要：大型语言模型领域的最新进展，特别是通过思维链 (CoT) 方法，已在解决复杂问题方面取得了显着进步。然而，现有模型要么由于用户偏好而倾向于牺牲详细推理以求简洁，要么需要大量且昂贵的训练数据来学习复杂的推理能力，从而限制了它们解决复杂任务的潜力。为了弥补这一差距，遵循扩展测试时间的概念，我们提出了一种简单的方法，鼓励模型采用更耐心的推理方式，而无需引入新知识或技能。为了采用偏好优化方法，我们生成详细的推理过程作为正例，生成简单的答案作为反例，从而训练模型以支持其响应的彻底性。我们的结果表明，仅在轻量级数据集上进行训练，GSM8k 的性能就提高了 6.7%。]]></description>
      <guid>https://arxiv.org/abs/2411.13082</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有多级粒度音节数控制的歌曲形式感知全歌曲文本到歌词生成</title>
      <link>https://arxiv.org/abs/2411.13100</link>
      <description><![CDATA[arXiv:2411.13100v1 公告类型：新
摘要：歌词生成面临着独特的挑战，特别是在实现精确的音节控制的同时还要遵守歌曲形式结构，例如诗句和合唱。传统的逐行方法往往会导致不自然的措辞，这凸显了对更细粒度的音节管理的需求。我们提出了一个歌词生成框架，该框架可以在单词、短语、行和段落级别实现多级音节控制，并了解歌曲形式。我们的方法根据输入文本和歌曲形式生成完整的歌词，确保与指定的音节约束保持一致。生成的歌词样本可在以下网址获取：https://tinyurl.com/lyrics9999]]></description>
      <guid>https://arxiv.org/abs/2411.13100</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>深入研究有效推理方法：推测解码综述</title>
      <link>https://arxiv.org/abs/2411.13157</link>
      <description><![CDATA[arXiv:2411.13157v1 公告类型：新
摘要：随着大型语言模型 (LLM) 的规模和复杂性不断增长，其高效推理已成为关注的焦点。传统的自回归解码虽然有效，但由于其顺序标记生成过程而存在计算效率低下的问题。推测解码通过引入一个两阶段框架解决了这一瓶颈：起草和验证。较小、高效的模型会生成初步草稿，然后由更大、更复杂的模型对其进行完善。本文对推测解码方法进行了全面的概述，将其分为以草稿为中心和以模型为中心的方法。我们讨论了与每种方法相关的关键思想，强调了它们扩展 LLM 推理的潜力。本概述旨在指导未来优化推测解码及其与现实世界 LLM 应用中集成的研究。]]></description>
      <guid>https://arxiv.org/abs/2411.13157</guid>
      <pubDate>Thu, 21 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>