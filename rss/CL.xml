<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 10 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用多语言编码器和知识提炼增强低资源 NMT：案例研究</title>
      <link>https://arxiv.org/abs/2407.06538</link>
      <description><![CDATA[arXiv:2407.06538v1 公告类型：新
摘要：神经机器翻译 (NMT) 仍然是一项艰巨的挑战，尤其是在处理低资源语言时。预训练的序列到序列 (seq2seq) 多语言模型（例如 mBART-50）在各种低资源 NMT 任务中表现出色。然而，他们的预训练仅限于 50 种语言，而不支持许多低资源语言，尤其是印度次大陆使用的语言。扩展 mBART-50 的语言支持需要复杂的预训练，可能会因灾难性的遗忘而导致性能下降。考虑到这些不断扩大的挑战，本文探讨了一个框架，该框架利用预训练语言模型的优势以及 seq2seq 架构中的知识提炼来促进低资源语言的翻译，包括 mBART-50 未涵盖的语言。所提出的框架采用基于多语言编码器的 seq2seq 模型作为基础架构，随后使用互补的知识提炼技术来减轻不平衡训练的影响。我们的框架在三种资源匮乏的印度语上进行了评估，在四个印度语到印度语方向上取得了显著的 BLEU-4 和 chrF 改进。此外，我们进行了人工评估以确认我们方法的有效性。我们的代码可在 https://github.com/raypretam/Two-step-low-res-NMT 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2407.06538</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:50 GMT</pubDate>
    </item>
    <item>
      <title>MUSE：机器学习语言模型的六向评估</title>
      <link>https://arxiv.org/abs/2407.06460</link>
      <description><![CDATA[arXiv:2407.06460v1 公告类型：新
摘要：语言模型 (LM) 是在大量文本数据上进行训练的，其中可能包括私人和受版权保护的内容。出于隐私或版权方面的考虑，数据所有者可能会要求从经过训练的模型中删除他们的数据。然而，在现代模型中，准确地取消学习这些数据点（即使用删除的数据进行重新训练）是难以实现的。这导致了许多近似取消学习算法的发展。对这些算法的有效性的评估传统上范围很窄，无法从模型部署者和数据所有者的角度准确量化算法的成功和实用性。我们通过提出 MUSE 来解决这个问题，MUSE 是一个全面的机器反学习评估基准，它列举了反学习模型的六个不同的理想属性：（1）无逐字记忆，（2）无知识记忆，（3）无隐私泄露，（4）对不打算删除的数据的效用保留，（5）相对于删除请求大小的可扩展性，以及（6）对连续反学习请求的可持续性。使用这些标准，我们对 7B 参数 LM 上的八种流行反学习算法反学习哈利波特书籍和新闻文章的有效性进行了基准测试。我们的结果表明，大多数算法都可以在不同程度上防止逐字记忆和知识记忆，但只有一种算法不会导致严重的隐私泄露。此外，现有算法未能满足部署者的期望，因为它们通常会降低一般模型效用，也无法持续适应连续的反学习请求或大规模内容删除。我们的研究结果确定了语言模型上现有反学习算法实用性的关键问题，我们发布了基准以促进进一步评估：muse-bench.github.io]]></description>
      <guid>https://arxiv.org/abs/2407.06460</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:49 GMT</pubDate>
    </item>
    <item>
      <title>互动很重要：英语第二语言会话互动对话评估框架</title>
      <link>https://arxiv.org/abs/2407.06479</link>
      <description><![CDATA[arXiv:2407.06479v1 公告类型：新
摘要：我们提出了一个以英语为第二语言 (ESL) 的使用者为对象的交互式对话评估框架。我们的框架收集对话级交互性标签（例如，主题管理；总共 4 个标签）和微观跨度特征（例如，反向通道；总共 17 个特征）。根据我们的注释数据，我们通过构建各种基于机器学习的模型来研究微观特征如何影响 ESL 对话的（更高级别）交互性质量。我们的结果表明，某些微观特征与交互性质量密切相关，例如参考词（例如，她、她、他），揭示了关于高级对话质量和低级语言信号之间相互作用的新见解。我们的框架还提供了一种评估 ESL 交流的方法，这对语言评估很有用。]]></description>
      <guid>https://arxiv.org/abs/2407.06479</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:49 GMT</pubDate>
    </item>
    <item>
      <title>通过检测和探索特定任务的神经元来理解 LLM 的多任务学习（泛化）</title>
      <link>https://arxiv.org/abs/2407.06488</link>
      <description><![CDATA[arXiv:2407.06488v1 公告类型：新
摘要：虽然大型语言模型（LLM）已经展示了卓越的多任务能力，但理解其背后的学习机制仍然是一个具有挑战性的问题。在本文中，我们尝试从神经元的角度来理解这种机制。具体来说，我们通过对任务特定数据的梯度归因来检测LLM中的任务敏感神经元。通过大量的失活和微调实验，我们证明检测到的神经元与给定的任务高度相关，我们将其称为任务特定神经元。利用这些已识别的任务特定神经元，我们深入研究了多任务学习和持续学习中的两个常见问题：泛化和灾难性遗忘。我们发现任务特定神经元的重叠与跨任务的泛化和特化密切相关。有趣的是，在LLM的某些层，不同任务特定神经元的参数具有很高的相似性，并且这种相似性与泛化性能高度相关。受这些发现的启发，我们提出了一种神经元级连续微调方法，该方法在连续学习过程中仅对当前任务特定的神经元进行微调，大量实验证明了该方法的有效性。我们的研究为 LLM 在多任务学习中的可解释性提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2407.06488</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:49 GMT</pubDate>
    </item>
    <item>
      <title>基于 sLLM 的 DPO 高效准确的记忆对话模型</title>
      <link>https://arxiv.org/abs/2407.06537</link>
      <description><![CDATA[arXiv:2407.06537v1 公告类型：新
摘要：在多会话对话系统中，随着会话的进行不断更新记忆至关重要。由于输入句子大小有限，单​​纯积累记忆会使人们难以专注于对话内容进行推理。因此，需要一种能够管理记忆以持续反映对话历史的高效、准确的对话模型。本文提出了一种随着会话的进展而有效管理记忆的对话模型，并将其纳入模型中，以使用 3 种方法准确反映对话历史：SFT、DPO 和带有 SFT 模型的 DPO。我们使用 DPO 算法的模型显示记忆准确度提高了约 0.0591 的 BERTScore，反映记忆的响应率也增加了。此外，响应生成性能在流畅度上提高了约 4.292，在连贯性上提高了 3.935，在一致性上提高了 2.896。本文介绍了一种训练方法，即使模型规模较小，其性能也比参数规模大两倍以上的模型更好。因此，我们的模型不仅在准确率方面表现出色，而且在资源利用率方面也表现出色。]]></description>
      <guid>https://arxiv.org/abs/2407.06537</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:49 GMT</pubDate>
    </item>
    <item>
      <title>CharSS：用于梵语分词的字符级变换模型</title>
      <link>https://arxiv.org/abs/2407.06331</link>
      <description><![CDATA[arXiv:2407.06331v1 公告类型：新
摘要：印度语言中的子词标记本身就具有意义，分离它们可以增强 NLP 任务，因此子词分割是一个至关重要的过程。将梵语和其他印度语言分割成子标记并不是一件容易的事，因为它可能包括连词，这可能会导致词边界的变化。我们提出了一种利用字符级 Transformer 模型进行梵语词分割 (CharSS) 的新方法。我们在三个基准数据集上进行了实验，以比较我们的方法与现有方法的性能。在 UoH+SandhiKosh 数据集上，我们的方法在分割预测准确度方面比目前最先进的系统高出 6.72 个百分点。在 hackathon 数据集上，我们的方法在完美匹配指标方面比当前的 SOTA 系统高出 2.27 个百分点。我们还提出了一个基于梵语的片段用例，用于将技术术语翻译成词汇相似的资源匮乏的印度语言。在这项任务的两个独立实验中，我们分别实现了 8.46 和 6.79 chrF++ 分数的平均提升。]]></description>
      <guid>https://arxiv.org/abs/2407.06331</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:48 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型回忆不确定性受到扇形效应的调节</title>
      <link>https://arxiv.org/abs/2407.06349</link>
      <description><![CDATA[arXiv:2407.06349v1 公告类型：新
摘要：本文评估大型语言模型 (LLM) 在对人类文本数据进行预训练后是否表现出类似于 Anderson 在人类身上发现的认知粉丝效应。我们进行了两组旨在引发粉丝效应的上下文回忆实验。与人类结果一致，我们发现通过标记概率测量的 LLM 回忆不确定性受到粉丝效应的影响。我们的结果表明，消除不确定性会破坏观察到的效果。实验表明，无论粉丝值是在上下文中还是在预训练数据中诱导的，粉丝效应都是一致的。最后，这些发现提供了计算机证据，表明粉丝效应和典型性是同一现象的表达。]]></description>
      <guid>https://arxiv.org/abs/2407.06349</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:48 GMT</pubDate>
    </item>
    <item>
      <title>数据无处不在：预训练数据集构建指南</title>
      <link>https://arxiv.org/abs/2407.06380</link>
      <description><![CDATA[arXiv:2407.06380v1 公告类型：新
摘要：最近的语言模型的令人印象深刻的功能在很大程度上可以归因于它们所训练的数万亿个标记预训练数据集。然而，模型开发人员未能披露他们的构建方法，这导致缺乏关于如何开发有效预训练集的公开信息。为了解决这个问题，我们对整个预训练集构建流程进行了首次系统研究。首先，我们对现有的预训练集开发技术进行消融，以确定哪些方法可以在下游评估中转化为模型准确率的最大提升。然后，我们对最广泛使用的数据源、网络爬虫快照进行分类，涵盖毒性、质量、语音类型和领域等属性。最后，我们展示了如何使用此类属性信息进一步完善和提高预训练集的质量。这些发现构成了一套可行的步骤，从业者可以使用这些步骤来开发高质量的预训练集。]]></description>
      <guid>https://arxiv.org/abs/2407.06380</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:48 GMT</pubDate>
    </item>
    <item>
      <title>DebUnc：通过不确定性估计减轻大型语言模型代理通信中的幻觉</title>
      <link>https://arxiv.org/abs/2407.06426</link>
      <description><![CDATA[arXiv:2407.06426v1 公告类型：新
摘要：为了增强大型语言模型 (LLM) 的功能，引入了多智能体辩论，其中多个 LLM 在几轮辩论中讨论问题的解决方案。然而，LLM 经常产生看似自信的错误反应，这可能会误导其他智能体。部分原因是智能体在标准辩论期间不会表达他们的信心水平。为了解决这个问题，我们引入了 DebUnc，这是一个多智能体辩论框架，它使用不确定性指标来评估智能体的信心水平。我们调整了 LLM 注意力机制，根据置信度调整标记权重，并探索使用文本提示来传达信心。我们在各种基准上的评估表明，基于注意力的方法特别有效，并且随着不确定性指标的发展，性能将继续提高。代码可在 https://github.com/lukeyoffe/debunc 获得]]></description>
      <guid>https://arxiv.org/abs/2407.06426</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:48 GMT</pubDate>
    </item>
    <item>
      <title>多语言大型语言模型中孟加拉语情感属性性别刻板印象的实证研究</title>
      <link>https://arxiv.org/abs/2407.06432</link>
      <description><![CDATA[arXiv:2407.06432v1 公告类型：新
摘要：大型语言模型 (LLM) 的影响力正在迅速增长，随着时间的推移，更多的工作将实现自动化。由于 LLM 的影响力不断扩大，评估其公平性至关重要。研究表明，LLM 反映了社会规范和偏见，这有可能在下游任务中传播社会刻板印象。许多关于 LLM 偏见的研究都集中在各种 NLP 应用中的性别偏见。然而，尽管情感与性别之间存在密切的社会联系，但在情感属性偏见研究方面仍存在差距。对于孟加拉语等资源匮乏的语言来说，这种差距甚至更大。从历史上看，女性与同情、恐惧和内疚等情绪有关，而男性则与愤怒、虚张声势和权威有关。这种模式反映了孟加拉语地区的社会规范。在本文中，我们首次对孟加拉语中封闭源和开源 LLM 中的性别情感归因进行了彻底调查。我们的目标是阐明孟加拉语背景下的性别和情感之间错综复杂的社会关系。我们成功地通过分析方法证明了孟加拉语中情感背景下的性别偏见的存在，并展示了 LLM 中情感归因如何根据性别角色选择而发生变化。我们所有的资源（包括代码和数据）都是公开的，以支持未来对孟加拉语 NLP 的研究。
警告：本文包含许多人可能会觉得冒犯的明确陈词滥调。]]></description>
      <guid>https://arxiv.org/abs/2407.06432</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:48 GMT</pubDate>
    </item>
    <item>
      <title>CodeUpdateArena：对 API 更新的知识编辑进行基准测试</title>
      <link>https://arxiv.org/abs/2407.06249</link>
      <description><![CDATA[arXiv:2407.06249v1 公告类型：新
摘要：大型语言模型 (LLM) 越来越多地用于合成和推理源代码。然而，这些模型知识的静态性质并没有反映出它们调用的库和 API 函数不断发展的事实，功能不断增加或变化。虽然许多基准测试评估了 LLM 如何生成代码，但之前没有研究过如何更新 LLM 关于代码 API 函数的知识。为了填补这一空白，我们提出了 CodeUpdateArena，这是一个用于代码领域知识编辑的基准测试。我们的基准测试中的一个实例由一个合成 API 函数更新与一个使用更新功能的程序合成示例配对而成；我们的目标是更新 LLM 以能够解决这个程序合成示例，而无需在推理时提供更新的文档。与对文本中编码的事实进行知识编辑相比，这里的成功更具挑战性：代码 LLM 必须正确推理修改后的函数的语义，而不仅仅是重现其语法。我们的数据集是通过首先提示 GPT-4 生成原子和可执行函数更新来构建的。然后，对于每个更新，我们都会生成程序综合示例，其代码解决方案易于使用该更新。我们的基准涵盖了来自七个不同 Python 包的 54 个函数的各种类型的更新，总共有 670 个程序综合示例。我们的实验表明，在开源代码 LLM（即 DeepSeek、CodeLlama）之前添加更新文档无法让它们纳入用于解决问题的更改，现有的知识编辑技术也有很大改进空间。我们希望我们的基准能够激发代码 LLM 中知识更新的新方法。]]></description>
      <guid>https://arxiv.org/abs/2407.06249</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:47 GMT</pubDate>
    </item>
    <item>
      <title>混合 X-Linker：用于生物医学实体链接的自动数据生成和极端多标签排名</title>
      <link>https://arxiv.org/abs/2407.06292</link>
      <description><![CDATA[arXiv:2407.06292v1 公告类型：新
摘要：最先进的深度学习实体链接方法依赖于大量人工标记的数据，而这些数据的获取成本很高。当前数据集的大小有限，导致生物医​​学概念覆盖范围不足，应用于新数据时性能下降。在这项工作中，我们建议自动生成数据以创建大规模训练数据集，这允许探索最初为生物医学实体链接任务中的极端多标签排名任务开发的方法。我们提出了混合 X-Linker 管道，其中包括不同的模块，分别将疾病和化学实体提及链接到 MEDIC 和 CTD-Chemical 词汇表中的概念。 X-Linker 在多个生物医学数据集上进行了评估：BC5CDR-Disease、BioRED-Disease、NCBI-Disease、BC5CDR-Chemical、BioRED-Chemical 和 NLM-Chem，分别实现了 0.8307、0.7969、0.8271、0.9511、0.9248 和 0.7895 的 top-1 准确率。X-Linker 在三个数据集中表现出色：BC5CDR-Disease、NCBI-Disease 和 BioRED-Chemical。相比之下，SapBERT 在其余三个数据集中的表现优于 X-Linker。这两个模型都仅依赖于提及字符串进行操作。X-Linker 的源代码及其相关数据是公开的，可用于执行生物医学实体链接，而无需使用来自特定知识组织系统的标识符预先标记实体。]]></description>
      <guid>https://arxiv.org/abs/2407.06292</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:47 GMT</pubDate>
    </item>
    <item>
      <title>使用阿拉伯语的社交媒体用户的性格分析及其对情绪分析的影响</title>
      <link>https://arxiv.org/abs/2407.06314</link>
      <description><![CDATA[arXiv:2407.06314v1 公告类型：新
摘要：社交媒体越来越走向个性化，个人会透露自己的信仰、兴趣、习惯和活动，从而让人们一窥他们的性格特征。本研究探讨了推特上使用阿拉伯语与性格特征及其对情绪分析的影响之间的相关性。我们根据从用户的个人资料活动和推文内容中提取的信息来表明用户的性格特征。我们的分析结合了语言特征、个人资料统计数据（包括性别、年龄、个人简介等）以及表情符号等附加功能。为了获得个性数据，我们在 16personalities.com 上抓取了参加 16personalities 阿拉伯语测试的用户的时间线和个人资料。我们的数据集包括在推特上分享其性格结果的 3,250 名用户。我们实施了各种机器学习技术来揭示人格特质，并为此开发了一个专用模型，使用 BERT 实现了 74.86% 的准确率，对该数据集的分析证明语言特征、个人资料特征和派生模型可用于区分不同的人格特质。此外，我们的研究结果表明，性格会影响社交媒体中的情绪。这项研究有助于持续努力，以深入了解社交媒体上的人类行为与性格特征之间的关系，并将其应用于政治话语分析和舆论追踪等现实世界的应用。]]></description>
      <guid>https://arxiv.org/abs/2407.06314</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:47 GMT</pubDate>
    </item>
    <item>
      <title>如有疑问，请立即行动：迈向构建高效、有力的护栏</title>
      <link>https://arxiv.org/abs/2407.06323</link>
      <description><![CDATA[arXiv:2407.06323v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种下游任务中具有令人信服的性能。然而，这些系统容易产生不良输出，例如有害和有偏见的文本。为了纠正这种情况，护栏（或检测器）模型的开发已经获得了关注。受开发社会偏见检测器的发现的启发，我们采用了使用-提及区别的概念 - 我们将其确定为我们社会偏见检测器初步版本中表现不佳的主要原因。利用这些信息，我们描述了一个完全可扩展和可重复的合成数据生成管道，该管道利用分类驱动的指令来创建有针对性和标记的数据。使用此管道，我们生成了超过 300K 个独特的对比样本，并提供了大量实验来系统地评估一套开源数据集上的性能。我们表明，我们的方法以极低的计算成本实现了具有竞争力的性能，并提供了迭代开发高效且功能强大的护栏模型的见解。
警告：本文包含有毒、有偏见且可能有害的文本示例。]]></description>
      <guid>https://arxiv.org/abs/2407.06323</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:47 GMT</pubDate>
    </item>
    <item>
      <title>使用参考翻译机器预测上下文中的词语相似度</title>
      <link>https://arxiv.org/abs/2407.06230</link>
      <description><![CDATA[arXiv:2407.06230v1 公告类型：新
摘要：我们通过将任务转换为给定上下文的单词之间的机器翻译性能预测 (MTPP) 以及它们的相似性之间的距离来识别英语中两个单词之间的相似性。我们使用参考翻译机器 (RTM)，它允许训练和测试集以及堆叠机器学习模型的通用表示。RTM 可以在上下文中的分级单词相似性 (GWSC) 任务中取得最佳结果。]]></description>
      <guid>https://arxiv.org/abs/2407.06230</guid>
      <pubDate>Thu, 11 Jul 2024 03:17:46 GMT</pubDate>
    </item>
    </channel>
</rss>