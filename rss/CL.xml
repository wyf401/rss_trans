<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 22 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于多模态情感分析的协作情感代理</title>
      <link>https://arxiv.org/abs/2404.12642</link>
      <description><![CDATA[arXiv:2404.12642v1 公告类型：新
摘要：在本文中，我们提出了一种用于多模态情感分析（MSA）的新多模态表示学习（MRL）方法，该方法通过协作情感代理促进模态之间的自适应交互，称为 Co-SA。 Co-SA 包含两个关键组成部分：情感代理建立 (SAE) 阶段和情感代理合作 (SAC) 阶段。在 SAE 阶段，每个情感代理处理单模态信号，并通过模态情感解缠 (MSD) 和深度相空间重建 (DPSR) 模块突出显示模态内的显式动态情感变化。随后，在SAC阶段，Co-SA精心设计了情感代理的特定任务交互机制，以便协调多模态信号来学习联合表示。具体来说，Co-SA 为每个情绪代理配备了一个独立的策略模型，该模型捕获了模式中的重要属性。这些策略通过适应下游任务的统一奖励相互优化。受益于奖励机制，Co-SA 超越了预定义融合模式的限制，在多模态交互设置中自适应地捕获 MRL 的单峰特性。为了证明 Co-SA 的有效性，我们将其应用于多模态情感分析 (MSA) 和多模态情绪识别 (MER) 任务。我们全面的实验结果表明，Co-SA 擅长发现多种跨模式特征，涵盖共同和互补的方面。该代码可在 https://github.com/smwanghhh/Co-SA 获取。]]></description>
      <guid>https://arxiv.org/abs/2404.12642</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:35 GMT</pubDate>
    </item>
    <item>
      <title>CORI：具有罗马化集成的 CJKV 基准——迈向超越文本脚本的跨语言传输的一步</title>
      <link>https://arxiv.org/abs/2404.12618</link>
      <description><![CDATA[arXiv:2404.12618v1 公告类型：新
摘要：天真地将英语视为源语言可能会因为没有考虑语言接触的重要性而阻碍许多语言的跨语言迁移。有些语言比其他语言联系更紧密，目标语言可以从密切相关的语言的迁移中受益；对于许多语言来说，密切相关的语言集不包括英语。在这项工作中，我们研究了源语言对跨语言迁移的影响，证明了选择与目标语言有高度接触的源语言的重要性。我们还为密切接触的中日韩越（CJKV）语言构建了一个新颖的基准数据集，以进一步鼓励对语言接触的深入研究。为了全面捕捉这些语言之间的联系，我们建议通过对比学习目标将罗马化转录整合到文本脚本之外，从而增强跨语言表示和有效的零样本跨语言迁移。]]></description>
      <guid>https://arxiv.org/abs/2404.12618</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>自动语音识别中自我监督表示的有效注入</title>
      <link>https://arxiv.org/abs/2404.12628</link>
      <description><![CDATA[arXiv:2404.12628v1 公告类型：新
摘要：Wav2vec 和 HuBERT 等自监督学习 (SSL) 模型在语音相关任务上产生了最先进的结果。鉴于此类模型的有效性，在传统的 ASR 系统中使用它们是有利的。虽然一些方法建议将这些模型合并为可训练的编码器或可学习的前端，但训练此类系统的速度非常慢，并且需要大量的计算周期。在这项工作中，我们提出了两种简单的方法，使用（1）逐帧加法和（2）交叉注意机制来有效地将 SSL 模型的表示合并到 ASR 架构中，从而产生大小与 ASR 相当的模型标准编码器-解码器一致性系统，同时还避免在训练期间使用 SSL 模型。与基线相比，我们的方法可以加快训练速度，并在 Librispeech 和 Tedlium 数据集上产生显着的性能提升。我们进一步提供详细的分析和消融研究，证明我们方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2404.12628</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:34 GMT</pubDate>
    </item>
    <item>
      <title>iTBLS：表格信息交互式对话数据集</title>
      <link>https://arxiv.org/abs/2404.12580</link>
      <description><![CDATA[arXiv:2404.12580v1 公告类型：新
摘要：本文介绍了交互式表（iTBLS），这是一个位于科学文章表格中的交互式对话数据集。该数据集旨在通过人工智能驱动的多任务表格功能促进人类与人工智能协作解决问题。与之前将交互建模为事实问答或程序合成的工作相比，iTBLS 拓宽了交互的范围，包括数学推理、自然语言操作以及通过将交互描述为以下三个任务之一来扩展自然语言对话中的现有表格：解释、修改或生成。此外，本文还提出了一套 iTBLS 基线方法，针对不同的计算情况利用零样本提示和参数高效的微调。我们还介绍了一种新颖的多步骤方法，并展示了如何将其与参数高效的微调结合起来，以实现 iTBLS 的最新技术；在解释方面优于标准参数效率微调高达 15%，在修改方面优于 18%，在生成方面优于 38%。]]></description>
      <guid>https://arxiv.org/abs/2404.12580</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>使用序列级知识蒸馏的参数高效多样化释义生成</title>
      <link>https://arxiv.org/abs/2404.12596</link>
      <description><![CDATA[arXiv:2404.12596v1 公告类型：新
摘要：在过去的一年里，自然语言生成（NLG）领域经历了指数级的增长，这很大程度上归功于大型语言模型（LLM）的引入。这些模型在自然语言处理和生成领域的一系列领域中表现出了最有效的性能。然而，它们在特定领域任务（例如释义）中的应用提出了重大挑战。大量的参数使得它们难以在商业硬件上运行，并且需要大量时间进行推理，导致生产环境中的成本很高。在这项研究中，我们通过利用法学硕士为释义领域开发三种不同的模型，并应用一种称为序列级知识蒸馏的方法来解决这些障碍。这些精炼模型能够保持法学硕士生成的释义的质量。它们表现出更快的推理时间和生成具有相当质量的各种释义的能力。这些模型的一个显着特征是它们能够展现句法多样性，同时保留词汇多样性，由于数据集中现有的数据质量问题，这些特征以前并不常见，并且在基于神经的方法中通常不会观察到。对我们模型的人工评估表明，与蒸馏过程中使用的 LLM 教师模型相比，尽管尺寸小了 1000 倍，但性能仅下降了 4%。这项研究为 NLG 领域做出了重大贡献，为释义任务提供了更高效、更具成本效益的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2404.12596</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:33 GMT</pubDate>
    </item>
    <item>
      <title>NLP 模型的基于潜在概念的解释</title>
      <link>https://arxiv.org/abs/2404.12545</link>
      <description><![CDATA[arXiv:2404.12545v1 公告类型：新
摘要：由于深度学习模型固有的不透明性，解释和理解深度学习模型的预测带来了巨大的挑战。之前许多旨在解释这些预测的努力都依赖于输入特征，特别是 NLP 模型中的单词。然而，由于这些单词的离散性以及缺乏上下文的冗长性，此类解释通常信息量较少。为了解决这个限制，我们引入了潜在概念归因方法（LACOAT），该方法根据潜在概念生成预测解释。我们的直觉是，一个词可以表现出多个方面，具体取决于它的使用上下文。因此，给定上下文中的单词，从我们的训练过程中得出的潜在空间反映了该单词的特定方面。 LACOAT 通过将显着输入单词的表示映射到训练潜在空间中来发挥作用，使其能够在该潜在空间内提供具有基于上下文的解释的预测。]]></description>
      <guid>https://arxiv.org/abs/2404.12545</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>Dubo-SQL：文本转 SQL 的多样化检索增强生成和微调</title>
      <link>https://arxiv.org/abs/2404.12560</link>
      <description><![CDATA[arXiv:2404.12560v1 公告类型：新
摘要：根据 BIRD-SQL 基准测试的执行准确性 (EX) 衡量，当前自动文本到 SQL 的最先进技术 (SOTA) 仍远远低于人类专家的表现。最准确的方法也是缓慢且昂贵的。为了推进文本到 SQL 的 SOTA，同时降低成本和提高速度，我们探索了低成本微调、多样化检索增强生成 (RAG) 的新颖方法以及有助于大型语言模型的新输入和输出格式的组合（法学硕士）取得更高的 EX。我们引入了两种新方法：Dubo-SQL v1 和 v2。 Dubo-SQL v1 在 BIRD-SQL 的保留测试集上为 EX 创造了新记录。 Dubo-SQL v2 在 BIRD-SQL 开发集上实现了更高的性能。 Dubo-SQL v1 依赖于 OpenAI 的 LLM，但使用低成本的 GPT-3.5 Turbo，同时超过了使用 OpenAI 的次优模型的性能，后者使用了更昂贵的 GPT-4。 Dubo-SQL v1 的性能超过使用 GPT-3.5 的次优模型 20% 以上。 Dubo-SQL v2 使用 GPT-4 Turbo 和 RAG 代替微调来推动 EX 更高。]]></description>
      <guid>https://arxiv.org/abs/2404.12560</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:32 GMT</pubDate>
    </item>
    <item>
      <title>GraphER：用于实体和关系提取的结构感知文本到图形模型</title>
      <link>https://arxiv.org/abs/2404.12491</link>
      <description><![CDATA[arXiv:2404.12491v1 公告类型：新
摘要：信息提取（IE）是自然语言处理（NLP）中的一项重要任务，涉及从非结构化文本中提取命名实体及其关系。在本文中，我们提出了一种解决此任务的新方法，将其表述为图结构学习（GSL）。通过将 IE 制定为 GSL，我们增强了模型在提取过程中动态细化和优化图结构的能力。与之前对这些任务进行单独或不相关预测的模型相比，这种公式可以为实体和关系预测提供更好的交互和基于结构的决策。与联合实体和关系提取基准的最先进基线进行比较时，我们的模型 GraphER 取得了有竞争力的结果。]]></description>
      <guid>https://arxiv.org/abs/2404.12491</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>EnriCo：实体和关系提取的丰富表示和全局约束推理</title>
      <link>https://arxiv.org/abs/2404.12493</link>
      <description><![CDATA[arXiv:2404.12493v1 公告类型：新
摘要：联合实体和关系提取在各种应用中发挥着关键作用，特别是在知识图谱的构建中。尽管最近取得了进展，但现有方法往往在两个关键方面存在不足：代表性的丰富性和产出结构的连贯性。这些模型通常依赖于手工启发式方法来计算实体和关系表示，这可能会导致关键信息的丢失。此外，他们忽视任务和/或数据集特定的约束，导致输出结构缺乏一致性。在我们的工作中，我们引入了 EnriCo，它可以缓解这些缺点。首先，为了培养丰富且富有表现力的表示，我们的模型利用注意力机制，允许实体和关系动态确定准确提取所需的相关信息。其次，我们引入了一系列解码算法，旨在推断最高得分的解决方案，同时遵守任务和数据集特定的约束，从而促进结构化和连贯的输出。在联合 IE 数据集上进行评估时，我们的模型表现出了与基线相比的竞争性能。]]></description>
      <guid>https://arxiv.org/abs/2404.12493</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>BIRD：适用于大型语言模型的值得信赖的贝叶斯推理框架</title>
      <link>https://arxiv.org/abs/2404.12494</link>
      <description><![CDATA[arXiv:2404.12494v1 公告类型：新
摘要：大型语言模型主要依靠归纳推理来进行决策。当应用于通常呈现不完整的上下文和条件的现实世界任务时，这会导致不可靠的决策。因此，需要准确的概率估计和适当的解释来提高决策的可靠性。在本文中，我们提出了一种用于大型语言模型的贝叶斯推理框架，称为 BIRD。 BIRD 基于溯因因素、LLM 蕴涵以及可学习的演绎贝叶斯模型，为模型决策提供可控且可解释的概率估计。实验表明，BIRD 使用开源 Llama 模型生成的概率估计在超过 65% 的情况下与人类判断一致，比最先进的 GPT-4 性能高出 35%。我们还表明，BIRD 可以直接用于在许多实际应用中做出值得信赖的决策。]]></description>
      <guid>https://arxiv.org/abs/2404.12494</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:31 GMT</pubDate>
    </item>
    <item>
      <title>NORMAD：衡量大型语言模型文化适应性的基准</title>
      <link>https://arxiv.org/abs/2404.12464</link>
      <description><![CDATA[arXiv:2404.12464v1 公告类型：新
摘要：大型语言模型（LLM）融入各种全球文化从根本上提出了文化挑战：LLM 必须引导互动、尊重社会规范并避免跨越文化界限。然而，目前尚不清楚法学硕士是否可以使他们的成果适应不同的文化规范。我们的研究主要集中在这方面。我们引入了 NormAd，这是一个新颖的数据集，其中包括代表来自 75 个国家的社会和文化规范的 2,600 个故事，用于评估法学硕士适应不同粒度级别的社会文化背景的能力，例如原籍国、其相关文化价值观和普遍的社会规范。我们的研究表明，法学硕士在所有背景粒度的文化推理上都遇到了困难，与来自南半球国家的文化相比，他们对以英语为中心的文化表现出了更强的适应能力。即使有明确的社会规范，表现最好的模型 Mistral-7b-Instruct 也只能达到 81.8% 的准确率，落后于人类达到的 95.6% 的准确率。对 NormAd 的评估进一步表明，法学硕士很难适应涉及跨文化送礼的故事。由于固有的共识或阿谀偏见，法学硕士发现评估符合文化规范的故事的社会可接受性比评估那些偏离文化规范的故事要容易得多。我们的基准衡量法学硕士的文化适应性（或缺乏文化适应性），强调使这些技术对全球受众更加公平和有用的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.12464</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>英语学习者对语码转换句子的语法错误纠正</title>
      <link>https://arxiv.org/abs/2404.12489</link>
      <description><![CDATA[arXiv:2404.12489v1 公告类型：新
摘要： 语码转换（CSW）是多语言使用者中的常见现象，即在单一话语或话语中使用多种语言。然而，混合语言话语可能仍然包含语法错误，但大多数现有的语法错误纠正 (GEC) 系统都是在单语言数据上进行训练的，而不是在开发时考虑到 CSW。在这项工作中，我们首次探索了 GEC 系统在 CSW 文本上的使用。通过这一探索，我们提出了一种通过翻译现有 GEC 语料库中不同文本范围来生成合成 CSW GEC 数据集的新方法。然后，我们研究了基于 CSW 比率、切换点因子和语言约束来选择这些跨度的不同方法，并确定它们如何影响 GEC 系统在 CSW 文本上的性能。我们的最佳模型在 3 个 CSW 测试集（英汉、英韩和英日）上实现了 1.57 $F_{0.5}$ 的平均增长，且不影响模型在单语言数据集上的性能。我们还发现，在一种 CSW 语言上训练的模型对于其他类型相似的 CSW 语言具有相对较好的泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2404.12489</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>AmbigDocs：同名下不同实体的跨文档推理</title>
      <link>https://arxiv.org/abs/2404.12447</link>
      <description><![CDATA[arXiv:2404.12447v1 公告类型：新
摘要：具有相同名称的不同实体可能难以区分。处理令人困惑的实体提及是语言模型 (LM) 的一项关键技能。例如，考虑到“迈克尔·乔丹在哪里接受的教育？”这个问题。以及一组讨论名为 Michael Jordan 的不同人的文档，LM 能否区分实体提及以生成问题的一致答案？为了测试这种能力，我们引入了一个新的基准测试 AmbigDocs。通过利用维基百科的消歧页面，我们识别了一组文档，这些文档属于共享一个模糊名称的不同实体。从这些文档中，我们生成包含不明确名称的问题及其相应的答案集。我们的分析表明，当前最先进的模型经常会产生模糊的答案或错误地合并属于不同实体的信息。我们建立了一个本体论，对四种不完整答案进行分类，并建立自动评估指标来识别此类类别。我们为未来跨多个具有不明确实体的文档进行推理的工作奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2404.12447</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>用情境扰动描述科学 QA 中法学硕士的弃权行为</title>
      <link>https://arxiv.org/abs/2404.12452</link>
      <description><![CDATA[arXiv:2404.12452v1 公告类型：新
摘要：面对不确定性，正确的模型反应是不回答问题，以免误导用户。在这项工作中，我们研究了法学硕士在提供不充分或不正确的背景时避免回答与背景相关的科学问题的能力。我们在多种设置中探讨模型的敏感性：删除黄金上下文，用不相关的上下文替换黄金上下文，以及提供超出给定内容的附加上下文。在四个法学硕士的四个 QA 数据集上进行的实验中，我们表明，不同模型、所提供的上下文类型以及问题类型的性能差异很大；特别是，许多法学硕士似乎无法避免使用标准 QA 提示来回答布尔问题。我们的分析还强调了弃权表现对 QA 任务准确性的意外影响。与直觉相反，在某些设置中，用不相关上下文替换黄金上下文或将不相关上下文添加到黄金上下文可以提高弃权性能，从而提高任务性能。我们的结果表明，需要对 QA 数据集设计和评估进行更改，以更有效地评估模型弃权的正确性和下游影响。]]></description>
      <guid>https://arxiv.org/abs/2404.12452</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>mOthello：跨语言表示对齐和跨语言迁移何时出现在多语言模型中？</title>
      <link>https://arxiv.org/abs/2404.12444</link>
      <description><![CDATA[arXiv:2404.12444v1 公告类型：新
摘要：许多预训练的多语言模型表现出跨语言迁移能力，这通常归因于预训练期间学习到的语言中性表示。然而，目前尚不清楚哪些因素有助于语言中性表征的学习，以及学习到的语言中性表征是否足以促进跨语言迁移。我们提出了一个综合任务，多语言黑白棋（mOthello），作为深入研究这两个问题的测试平台。我们发现：（1）使用朴素的多语言预训练训练的模型无法学习所有输入语言的语言中性表示； （2）引入“锚标记”（即跨语言相同的词汇项）有助于跨语言表示对齐； （3）仅学习语言中立的表征不足以促进跨语言迁移。根据我们的发现，我们提出了一种新颖的方法 - 具有统一输出空间的多语言预训练 - 既可以诱导语言中性表示的学习，又可以促进跨语言迁移。]]></description>
      <guid>https://arxiv.org/abs/2404.12444</guid>
      <pubDate>Mon, 22 Apr 2024 06:17:28 GMT</pubDate>
    </item>
    </channel>
</rss>