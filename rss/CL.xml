<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 17 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>自我知识提炼以学习模糊性</title>
      <link>https://arxiv.org/abs/2406.09719</link>
      <description><![CDATA[arXiv:2406.09719v1 公告类型：新
摘要：最近的语言模型在自然语言理解 (NLU) 任务上表现出色。然而，当面对可以以多种方式解释的模糊样本时，它们通常不是最优的，过于自信地预测单个标签而不考虑其正确性。为了解决这个问题，我们提出了一种新颖的自我知识蒸馏方法，使模型能够利用从其较低层提炼的知识更准确地学习标签分布。这种方法还包括一个学习阶段，该阶段根据提炼的分布知识重新校准被判断为极其模糊的训练样本的不必要的增强置信度。我们在不同的 NLU 基准数据集上验证了我们的方法，实验结果证明了它在产生更好的标签分布方面的有效性。特别是，通过重新校准高度模糊样本的置信度的过程，当对未见样本的预测与其真实标签不匹配时过度自信的问题得到了显着缓解。事实证明，这有助于生成比现有最先进方法更好的分布。此外，与现有方法相比，我们的方法在训练模型方面效率更高，因为它不涉及额外的训练过程来优化标签分布。]]></description>
      <guid>https://arxiv.org/abs/2406.09719</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>检测不需要事实判断的响应生成</title>
      <link>https://arxiv.org/abs/2406.09702</link>
      <description><![CDATA[arXiv:2406.09702v1 公告类型：新
摘要：随着大型语言模型（LLM）的显著发展，确保输出的真实性已成为一项挑战。然而，在对话中，用给定的知识或事实来提供回复的所有内容并不一定是件好事。这项研究旨在实现对话回复中的吸引力和真实性，为此设定了一个任务来预测不需要事实正确性判断的句子，例如同意或个人意见/感受。我们通过众包为这项任务创建了一个数据集，即带有事实核查标签（DDFC）注释的对话数据集，并使用该数据集在多个模型上执行分类任务。分类准确率最高的模型可以产生大约 88% 的准确分类结果。]]></description>
      <guid>https://arxiv.org/abs/2406.09702</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>UniBridge：针对低资源语言的跨语言迁移学习的统一方法</title>
      <link>https://arxiv.org/abs/2406.09717</link>
      <description><![CDATA[arXiv:2406.09717v1 公告类型：新
摘要：在本文中，我们介绍了 UniBridge（具有优化嵌入和词汇的跨语言迁移学习），这是一种全面的方法，旨在提高跨语言迁移学习的有效性，特别是在资源有限的语言中。我们的方法解决了语言模型的两个基本要素：嵌入的初始化和最佳词汇量。具体来说，我们提出了一种新颖的嵌入初始化方法，该方法利用语言的词汇和语义对齐。此外，我们提出了一种系统地搜索最佳词汇量的方法，确保模型复杂性和语言覆盖率之间的平衡。我们在多语言数据集上的实验表明，我们的方法极大地提高了几种语言的 F1 分数。UniBridge 是一种适用于各种语言的跨语言系统的强大且适应性强的解决方案，突出了在跨语言环境中初始化嵌入和选择正确词汇量的重要性。]]></description>
      <guid>https://arxiv.org/abs/2406.09717</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>通过基础学习语言结构</title>
      <link>https://arxiv.org/abs/2406.09662</link>
      <description><![CDATA[arXiv:2406.09662v1 公告类型：新
摘要：语言是高度结构化的，其句法和语义结构在某种程度上为同一语言的使用者所认同。通过隐性或显性地了解这些结构，人类可以有效地学习和使用语言，并推广到包含未见过的单词的句子。受人类语言学习的启发，在这篇论文中，我们考虑了一系列机器学习任务，旨在通过基础来学习语言结构。我们寻求来自其他数据源（即基础）的远程监督，包括但不限于其他模态（例如视觉）、程序的执行结果和其他语言。
我们展示了这一任务制定的潜力，并通过三种方案提倡采用它。在第一部分中，我们考虑通过视觉基础来学习句法解析。我们提出了基于视觉的语法归纳任务，提出了第一个从基于视觉的文本和语音中归纳句法结构的模型，并发现视觉基础信号有助于提高纯语言模型的解析质量。作为一项附带贡献，我们提出了一种新颖的评估指标，可以评估不涉及文本或自动语音识别系统的语音解析。在第二部分中，我们提出了两种执行感知方法，将句子映射到相应的语义结构（即程序），显著提高了组合泛化和少样本程序合成。在第三部分中，我们提出了一种从其他语言的注释中学习语言结构的方法。具体来说，我们提出了一种在跨语言词对齐方面树立新纪录的方法。然后，我们利用学习到的词对齐来提高零样本跨语言依存关系解析的性能，方法是提出一种基于子结构的新颖投影方法，该方法保留了从源语言学习到的结构知识。]]></description>
      <guid>https://arxiv.org/abs/2406.09662</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:15 GMT</pubDate>
    </item>
    <item>
      <title>FreeCtrl：使用前馈层构建控制中心，实现无需学习的可控文本生成</title>
      <link>https://arxiv.org/abs/2406.09688</link>
      <description><![CDATA[arXiv:2406.09688v1 公告类型：新
摘要：可控文本生成 (CTG) 旨在制作符合特定属性的文本，传统上采用基于学习的技术，例如使用特定于属性的数据集进行训练、微调或前缀调整。这些方法虽然有效，但需要大量的计算和数据资源。相比之下，一些提出的无学习替代方案绕过了学习，但往往产生较差的结果，体现了计算成本和模型功效之间的基本机器学习权衡。为了克服这些限制，我们提出了 FreeCtrl，这是一种无学习方法，可动态调整所选前馈神经网络 (FFN) 向量的权重以控制大型语言模型 (LLM) 的输出。FreeCtrl 取决于不同 FFN 向量的权重影响不同标记出现在输出中的可能性的原理。通过识别和自适应调整与属​​性相关的 FFN 向量的权重，FreeCtrl 可以控制生成内容中属性关键字的输出可能性。在单属性和多属性控制上进行的大量实验表明，无需学习的 FreeCtrl 优于其他无需学习和基于学习的方法，成功解决了学习成本和模型性能之间的困境。]]></description>
      <guid>https://arxiv.org/abs/2406.09688</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:15 GMT</pubDate>
    </item>
    <item>
      <title>用于设备导向语音检测的融合低秩自适应多模态大型语言模型</title>
      <link>https://arxiv.org/abs/2406.09617</link>
      <description><![CDATA[arXiv:2406.09617v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 已显示出实现类人对话的潜力，但它们主要在文本数据上进行预训练。加入音频或视频可以提高性能，但收集大规模多模态数据和预训练多模态 LLM 具有挑战性。为此，我们提出了一种融合低秩自适应 (FLoRA) 技术，该技术可以有效地调整预训练的单模态 LLM，以通过低秩自适应使用新的、以前未见过的模态。对于设备导向的语音检测，使用 FLoRA，多模态 LLM 相对于纯文本方法实现了 22% 的等错误率 (EER) 相对降低，并且与完全微调 (FFT) 对应方法相比实现了性能对等，而只需调整其一小部分参数。此外，借助新引入的适配器 dropout，FLoRA 对缺失数据具有很强的鲁棒性，与 FFT 相比，EER 降低了 20%，错误接受率降低了 56%。所提出的方法可以很好地扩展到从 16M 到 3B 参数的模型大小。]]></description>
      <guid>https://arxiv.org/abs/2406.09617</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:14 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的语音识别多模态检索</title>
      <link>https://arxiv.org/abs/2406.09618</link>
      <description><![CDATA[arXiv:2406.09618v1 公告类型：新
摘要：检索是一种广泛采用的利用外部信息改进语言模型的方法。随着该领域向多模态大型语言模型发展，扩展纯文本方法以将其他模态纳入检索中以及应用于广泛的机器学习任务和数据类型非常重要。在这项工作中，我们提出了两种方法的多模态检索：kNN-LM 和交叉注意技术。我们通过将我们的检索方法应用于可访问外部信息的自动语音识别任务，从经验上证明了其有效性。在这种设置下，我们表明基于语音的多模态检索优于基于文本的检索，并且与多模态语言模型基线相比，单词错误率提高了 50%。此外，我们在 Spoken-Squad 问答数据集上取得了最先进的识别结果。]]></description>
      <guid>https://arxiv.org/abs/2406.09618</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:14 GMT</pubDate>
    </item>
    <item>
      <title>使用 BERT 分析社交媒体短文本中的性别极性：表情符号和表情符号的作用</title>
      <link>https://arxiv.org/abs/2406.09573</link>
      <description><![CDATA[arXiv:2406.09573v1 公告类型：新
摘要：在这项工作中，我们基于 BERT 对不同的模型进行了微调，以检测 Twitter 账户的性别极性。我们特别关注分析使用表情符号和表情符号对我们的模型在分类任务中的表现的影响。我们能够证明，使用这些非单词输入以及在短文本格式（如推文）中提及其他账户会对检测账户持有人的性别产生影响。]]></description>
      <guid>https://arxiv.org/abs/2406.09573</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:13 GMT</pubDate>
    </item>
    <item>
      <title>解读多样性：印度人工智能研究概况回顾</title>
      <link>https://arxiv.org/abs/2406.09559</link>
      <description><![CDATA[arXiv:2406.09559v1 公告类型：新
摘要：这篇评论论文全面概述了印度语中的大型语言模型 (LLM) 研究方向。印度语是印度次大陆使用的语言，包括印度、巴基斯坦、孟加拉国、斯里兰卡、尼泊尔和不丹等。这些语言具有丰富的文化和语言遗产，全球有超过 15 亿人使用。由于市场潜力巨大，并且对各种语言中基于自然语言处理 (NLP) 的应用程序的需求不断增长，印度语的生成应用为研究带来了独特的挑战和机遇。我们的论文深入探讨了印度生成模型的最新进展，并提供了研究方向的分类，汇总了 84 篇最新出版物。本文调查的研究方向包括 LLM 开发、微调现有 LLM、语料库开发、基准测试和评估，以及围绕特定技术、工具和应用的出版物。我们发现，各出版物中的研究人员都强调了数据可用性有限、缺乏标准化以及印度语特殊的语言复杂性所带来的挑战。这项工作旨在为 NLP 领域的研究人员和从业人员（尤其是专注于印度语的研究人员和从业人员）提供宝贵的资源，并有助于为这些语言开发更准确、更高效的 LLM 应用程序。]]></description>
      <guid>https://arxiv.org/abs/2406.09559</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:12 GMT</pubDate>
    </item>
    <item>
      <title>Speech ReaLLM——通过教授时间流，利用多模式 LLM 实现实时流式语音识别</title>
      <link>https://arxiv.org/abs/2406.09569</link>
      <description><![CDATA[arXiv:2406.09569v1 公告类型：新
摘要：我们引入了 Speech ReaLLM，这是一种新的 ASR 架构，它将“仅解码器”ASR 与 RNN-T 结合在一起，使多模态 LLM 架构能够进行实时流式传输。这是第一个设计用于处理连续音频而无需明确端点指向的“仅解码器”ASR 架构。Speech ReaLLM 是更通用的 ReaLLM（“实时 LLM”）方法的一个特例，也是首次在此介绍。这个想法受到 RNN-T 的启发：不是仅在用户提示结束时生成响应，而是在实时收到每个输入标记后生成响应（它通常是空的）。在 Librispeech“测试”中，80M Speech ReaLLM 实时实现 3.0% 和 7.4% 的 WER（没有外部 LM 或辅助损失）。这仅略高于 3 倍大的 Attention-Encoder-Decoder 基线。我们还表明，通过这种方式，LLM 架构可以学习表示和重现时间的流动；并且经过预先训练的 7B LLM 可以进行微调，以便相当好地完成这项任务。]]></description>
      <guid>https://arxiv.org/abs/2406.09569</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:12 GMT</pubDate>
    </item>
    <item>
      <title>Talking Heads：理解 Transformer 语言模型中的层间通信</title>
      <link>https://arxiv.org/abs/2406.09519</link>
      <description><![CDATA[arXiv:2406.09519v1 公告类型：新
摘要：虽然众所周知，Transformer 语言模型 (LM) 将特征从早期层传递到后期层，但人们对模型如何表示和路由这些信息还不太了解。通过分析 LM 用于实现此目的的特定机制，我们发现它也用于从列表中调用项目，并表明这种机制可以解释模型对提示中项目顺序的看似任意的敏感性。具体而言，我们发现模型写入残差流的低秩子空间以表示特征，然后由特定的后续层读出，从而形成层之间的低秩通信通道。通过使用奇异值分解 (SVD) 分解注意力头权重矩阵，我们发现可以通过分析它们的权重矩阵来预测先前描述的由一个或多个层分隔的头部之间的相互作用。我们表明，我们可以根据发现的机制操纵内部模型表示以及编辑模型权重，从而显著提高我们的合成洗衣清单任务的性能，该任务需要从列表中回忆，通常可将任务准确率提高 20% 以上。我们的分析揭示了从语言模型预训练中学习到的令人惊讶的复杂可解释结构，并帮助我们理解为什么复杂的 LM 有时在简单领域会失败，从而促进未来对更复杂行为的分析。]]></description>
      <guid>https://arxiv.org/abs/2406.09519</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:11 GMT</pubDate>
    </item>
    <item>
      <title>探索乌尔都语的句法模式：深入研究依存关系分析</title>
      <link>https://arxiv.org/abs/2406.09549</link>
      <description><![CDATA[arXiv:2406.09549v1 公告类型：新
摘要：解析是将句子分解为语法成分并识别句子的句法结构的过程。通过使用词典和句法规则为其成分分配语法标签，可以实现句法正确的句子结构。在语言学中，解析器非常有用，因为它有许多不同的应用，例如名称实体识别、问答系统和信息提取等。用于解析的两种最常用技术是短语结构和依存结构。由于乌尔都语是一种资源匮乏的语言，因此在构建乌尔都语解析器方面进展甚微。对几种解析器的比较表明，依存解析方法更适合乌尔都语等无序语言。我们在解析乌尔都语（一种具有复杂形态的南亚语言）方面取得了重大进展。对于乌尔都语依存解析，采用由词位置、词头和依存关系组成的基本特征模型作为起点，然后采用更复杂的特征模型。依赖性标记集的设计充分考虑了乌尔都语的复杂形态结构、词序变化和词汇歧义，包含 22 个标记。我们的数据集由新闻文章中的句子组成，我们尝试包含不同复杂度的句子（这非常具有挑战性），以获得可靠的结果。所有实验均使用 MaltParser 进行，探索所有 9 种算法和分类器。使用 Nivreeager 算法，我们实现了 70% 的整体最佳标记准确率 (LA) 以及 84% 的整体最佳未标记附着分数 (UAS)。然后将输出数据与手动解析的树库测试数据进行比较，以进行错误评估并识别解析器产生的错误。]]></description>
      <guid>https://arxiv.org/abs/2406.09549</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:11 GMT</pubDate>
    </item>
    <item>
      <title>新闻专线：百年历史新闻的大型结构化数据库</title>
      <link>https://arxiv.org/abs/2406.09490</link>
      <description><![CDATA[arXiv:2406.09490v1 公告类型：新
摘要：从历史上看，美国地方报纸的内容主要来自美联社等新闻通讯社。历史学家认为，新闻通讯社在创造国家认同和对世界的共同理解方面发挥了关键作用，但没有通过新闻通讯社发送的内容的综合档案。我们通过将定制的深度学习管道应用于来自数千家地方报纸的数百 TB 的原始图像扫描来重建这样的档案。由此产生的数据集包含 270 万篇独特的公共领域美国新闻通讯文章，撰写于 1878 年至 1977 年之间。这些文章中的位置是地理参考的，主题使用定制的神经主题分类进行标记，命名实体被识别，个人使用新颖的实体消歧模型在维基百科上消歧。为了构建新闻通讯数据集，我们首先识别报纸布局并从原始图像扫描中转录大约 1.38 亿个结构化文章文本。然后，我们使用定制的神经双编码器模型对复制的文章进行去重，在存在大量删节和噪音的情况下，量化每篇文章的复制范围。使用文本分类器来确保我们只包括历史上属于公共领域的新闻通讯文章。文本附带的结构化数据提供了丰富的信息，包括数百万美国人在一个世纪中阅读的新闻的人物（消除歧义的个人）、内容（主题）和地点（地理参考）。我们还包括国会图书馆关于在头版刊登文章的报纸的元数据信息。新闻通讯数据集既可用于大型语言建模 - 将训练数据扩展到现代网络文本之外 - 也可用于研究计算语言学、社会科学和数字人文学科的各种问题。]]></description>
      <guid>https://arxiv.org/abs/2406.09490</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:10 GMT</pubDate>
    </item>
    <item>
      <title>使用文本挖掘分析探索约旦的交通事故叙述</title>
      <link>https://arxiv.org/abs/2406.09438</link>
      <description><![CDATA[arXiv:2406.09438v1 公告类型：新
摘要：本研究探讨了交通事故叙述，试图通过文本挖掘分析来指导和加强有效的交通安全政策。文本挖掘技术用于解开叙述中的关键主题和趋势，旨在更深入地了解导致交通事故的因素。本研究收集了约旦五条主要高速公路的事故数据，涵盖了 2018 年至 2022 年的 7,587 条记录。采用无监督学习方法从碰撞数据中学习模式。还使用了各种文本挖掘技术，例如主题建模、关键字提取和词共现网络，以揭示碰撞模式的共现。结果表明，文本挖掘分析是一种有前途的方法，并强调了交通事故的多因素性质，包括交织在一起的人为决策和车辆状况。所有分析中反复出现的主题都强调了需要采取平衡的道路安全方法，将主动和被动措施相结合。强调对驾驶员的教育以及对与动物相关的事件的认识至关重要。]]></description>
      <guid>https://arxiv.org/abs/2406.09438</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:09 GMT</pubDate>
    </item>
    <item>
      <title>推进生物医学领域的高分辨率视觉语言模型</title>
      <link>https://arxiv.org/abs/2406.09454</link>
      <description><![CDATA[arXiv:2406.09454v1 公告类型：新
摘要：多模态学习显著推动了生成式人工智能的发展，尤其是在视觉语言建模方面。GPT-4V 等创新和 LLaVA 等开源项目已经实现了能够完成零样本任务的强大对话代理。然而，将这些技术应用于生物医学领域面临着独特的挑战。最近的举措，如 LLaVA-Med，已经开始使用 PMC-15M 等大型数据集来调整生物医学环境中的指令调整。我们的研究有三个主要贡献：（i）我们提出了一个新的指令数据集，其中包含来自 Claude3-Opus 和 LLaMA3 70B 的医学图像-文本对；（ii）我们提出了一种使用分层表示的新型图像编码策略来改善细粒度的生物医学视觉理解；（iii）我们开发了 Llama3-Med 模型，该模型在生物医学视觉问答基准上实现了最先进的零样本性能，与以前的方法相比，平均性能提高了 10% 以上。这些进步为医疗专业人员提供了更准确、更可靠的工具，弥补了当前多模式对话助手的差距，并促进了医疗 AI 的进一步创新。]]></description>
      <guid>https://arxiv.org/abs/2406.09454</guid>
      <pubDate>Mon, 17 Jun 2024 06:20:09 GMT</pubDate>
    </item>
    </channel>
</rss>