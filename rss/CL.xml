<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 09 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>对大型语言模型的调查及其功能和局限性的一些见解</title>
      <link>https://arxiv.org/abs/2501.04040</link>
      <description><![CDATA[arXiv:2501.04040v1 公告类型：新
摘要：人工智能的快速发展，尤其是基于 Transformer 架构的大型语言模型 (LLM) 的发展，重新定义了自然语言处理的能力。这些模型现在在各种与语言相关的任务中表现出色，例如文本生成、问答、翻译和总结，通常可与人类的理解力相媲美。更有趣的是，LLM 已经展示了超越其核心功能的新兴能力，在常识推理、代码生成和算术等任务中表现出色。这篇调查论文探讨了驱动这些功能的基础组件、扩展机制和架构策略。我们强调 GPT 和 LLaMA 等模型，分析了指数数据和计算增长对 LLM 性能的影响，同时还解决了与扩展相关的权衡。我们还研究了 LLM 在医疗保健、金融、教育和法律等行业中的应用，强调了它们的适应性和解决特定领域挑战的潜力。这项工作的核心问题是 LLM 如何在不同的任务中推广、展示规划和推理能力，以及这些新兴能力是否可以系统地引出或增强。特别是，我们对 LLM 中的 CoT（思维链）和 PoT（思维计划）能力提供了一些见解，重点关注预训练数据如何影响它们的出现。此外，我们研究了集成外部系统的 LLM 模数框架，使 LLM 能够处理复杂的动态任务。通过分析这些因素，本文旨在促进对 LLM 能力和局限性的持续讨论，促进其在新的、日益复杂的环境中负责任地开发和应用。]]></description>
      <guid>https://arxiv.org/abs/2501.04040</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>“是的！”——法学硕士 (LLM) 是否表现出多模式特征转移？</title>
      <link>https://arxiv.org/abs/2501.04138</link>
      <description><![CDATA[arXiv:2501.04138v1 公告类型：新
摘要：人类交流是一种多方面和多模式的技能。交流需要理解交流的表面文本内容和内涵意图。对于人类来说，学习超越表面层次首先要学习言语中的交流意图。一旦人类掌握了口头交流的这些技能，他们就会将这些技能转移到书面交流中。在本文中，我们评估了语音+文本模型和特别强调人与人对话训练的文本模型进行这种多模式技能转移的能力。我们专门测试了这些模型检测隐蔽欺骗性通信的能力。我们发现，在没有特殊提示的情况下，语音+文本 LLM 在执行此任务方面比单模式 LLM 更有优势。同样，我们发现人与人对话训练的 LLM 也具有这项技能的优势。]]></description>
      <guid>https://arxiv.org/abs/2501.04138</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MIA 共享任务上的多语言开放式 QA</title>
      <link>https://arxiv.org/abs/2501.04153</link>
      <description><![CDATA[arXiv:2501.04153v1 公告类型：新
摘要：跨语言信息检索 (CLIR) ~\cite{shi2021cross, asai2021one, jiang2020cross} 例如，可以找到任何语言的相关文本，例如英语（高资源）或泰卢固语（低资源），即使查询是用不同的、可能资源较少的语言提出的。在这项工作中，我们旨在为这种受限但重要的设置开发有用的 CLIR 模型，在这种设置中，我们不需要任何类型的额外监督或标记数据来进行检索任务，因此可以有效地用于资源较少的语言。
\par 我们提出了一种简单有效的重新排名方法来改进开放式问答中的段落检索。重新排序器使用零样本多语言问题生成模型（一种预先训练的语言模型）对检索到的段落重新评分，以计算在检索到的段落（可能是另一种语言）条件下输入问题为目标语言的概率。我们在完全零样本设置下评估我们的方法，不需要任何训练。因此，我们方法的主要优势在于，我们的方法可用于对任何稀疏检索方法（如 BM-25）获得的结果进行重新排序。这消除了获取检索任务所需的昂贵标记语料库的需要，因此可以用于资源匮乏的语言。]]></description>
      <guid>https://arxiv.org/abs/2501.04153</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推理增强型自我训练，用于长篇个性化文本生成</title>
      <link>https://arxiv.org/abs/2501.04167</link>
      <description><![CDATA[arXiv:2501.04167v1 公告类型：新
摘要：个性化文本生成需要大型语言模型 (LLM) 具有从其标准训练中经常不会遇到的上下文中学习的独特能力。鼓励 LLM 更好地使用个性化上下文来生成更符合用户期望的输出的一种方法是指示它们推理用户过去的偏好、背景知识或写作风格。为了实现这一点，我们提出了个性化文本生成的推理增强自训练 (REST-PG)，这是一个训练 LLM 在响应生成过程中推理个人数据的框架。REST-PG 首先生成推理路径来训练 LLM 的推理能力，然后采用期望最大化强化自训练根据其自身的高奖励输出迭代训练 LLM。我们在 LongLaMP 基准上评估 REST-PG，该基准由四个不同的个性化长篇文本生成任务组成。我们的实验表明，REST-PG 比最先进的基线取得了显著的改进，基准测试中平均相对性能提升了 14.5%。]]></description>
      <guid>https://arxiv.org/abs/2501.04167</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于网络问答的多模态多跳源检索</title>
      <link>https://arxiv.org/abs/2501.04173</link>
      <description><![CDATA[arXiv:2501.04173v1 公告类型：新
摘要：这项工作解决了多模态多跳问答 (QA) 的学习和推理挑战。我们提出了一个基于句子语义结构的图形推理网络，以学习多源推理路径并在图像和文本模态中找到回答问题的支持事实。在本文中，我们研究了图形结构对于多模态多跳问答的重要性。我们的分析以 WebQA 为中心。我们构建了一个强大的基线模型，该模型使用成对分类任务查找相关来源。我们确定，通过正确使用来自预训练模型的特征表示，图形结构有助于改进多模态多跳问答。我们指出，图形结构和邻接矩阵都是与任务相关的先验知识，可以利用图形结构来提高任务的检索性能。实验和可视化分析表明，通过图网络或整个图结构进行消息传播可以用 token-wise 交叉注意取代大规模多模态转换器。我们证明了我们的方法的适用性，尽管是一个非常轻量的模型，但与转换器基线相比，检索 F1score 的性能提升为 \textbf{4.6$\%$}。我们进一步证明了我们的模型对大规模检索设置的适用性。]]></description>
      <guid>https://arxiv.org/abs/2501.04173</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IOLBENCH：语言推理法学硕士基准测试</title>
      <link>https://arxiv.org/abs/2501.04249</link>
      <description><![CDATA[arXiv:2501.04249v1 公告类型：新
摘要：尽管深度神经网络取得了显著的进步并得到了广泛的应用，但它们执行推理任务的能力仍然有限，特别是在需要结构化、抽象思维的领域。在本文中，我们通过引入 IOLBENCH（一种源自国际语言学奥林匹克 (IOL) 问题的新基准）来研究最先进的大型语言模型 (LLM) 的语言推理能力。该数据集包含测试语法、形态、音系和语义的各种问题，所有这些都经过精心设计，以使其自成体系并独立于外部知识。这些任务挑战模型进行元认知语言推理，需要从最少的例子中推断出语言规则和模式。通过对领先的 LLM 进行广泛的基准测试，我们发现即使是最先进的模型也难以处理语言复杂性的复杂性，特别是在需要组合概括和规则抽象的领域。我们的分析突出了当前语言问题解决模型的优势和持续存在的局限性，为其推理能力提供了宝贵的见解。通过引入 IOLBENCH，我们旨在促进进一步研究开发能够进行类似人类推理的模型，这对计算语言学和人工智能领域具有更广泛的影响。]]></description>
      <guid>https://arxiv.org/abs/2501.04249</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多模态图形对比学习和 ChartQA 提示</title>
      <link>https://arxiv.org/abs/2501.04303</link>
      <description><![CDATA[arXiv:2501.04303v1 公告类型：新
摘要：ChartQA 面临着巨大的挑战，因为图表元素的分布很复杂，底层数据中隐含着隐含的模式。在本章中，我们为图表开发了一个联合多模态场景图，明确表示图表元素与其相关模式之间的关系。
我们提出的多模态场景图由两个部分组成：一个视觉图和一个文本图，每个部分都旨在捕获图表中的结构和语义信息。为了统一这些不同模态的表示，我们引入了一种多模态图对比学习方法，该方法通过最大化多模态图中表示同一对象的节点之间的相似性来学习统一的表示。学习到的图形表示可以无缝地合并到 Transformer 解码器中作为软提示。
此外，鉴于零样本场景中对多模态大型语言模型 (MLLM) 的需求日益增长，我们为 MLLM 设计了思路链 (CoT) 提示以减少幻觉。我们在 ChartQA、OpenCQA 和 ChartX 等公共基准上测试了这两种方法，证明了性能的提升并验证了我们提出的方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2501.04303</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM4SR：针对科学研究的大型语言模型的调查</title>
      <link>https://arxiv.org/abs/2501.04306</link>
      <description><![CDATA[arXiv:2501.04306v1 公告类型：新
摘要：近年来，大型语言模型 (LLM) 的快速发展改变了科学研究的格局，为研究周期的各个阶段提供了前所未有的支持。本文首次系统地探讨了 LLM 如何彻底改变科学研究过程。我们分析了 LLM 在研究的四个关键阶段所发挥的独特作用：假设发现、实验规划和实施、科学写作和同行评审。我们的评论全面展示了特定于任务的方法和评估基准。通过确定当前的挑战并提出未来的研究方向，本调查不仅突出了 LLM 的变革潜力，而且旨在激励和指导研究人员和从业者利用 LLM 推进科学研究。资源可在以下存储库中找到：https://github.com/du-nlp-lab/LLM4SR]]></description>
      <guid>https://arxiv.org/abs/2501.04306</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>巨型数字堆最像谁：分析招聘环境中的公平性</title>
      <link>https://arxiv.org/abs/2501.04316</link>
      <description><![CDATA[arXiv:2501.04316v1 公告类型：新
摘要：大型语言模型 (LLM) 越来越多地被部署在招聘等高风险应用中，但它们在不公平决策和结果方面的可能性仍未得到充分研究，特别是在生成环境中。在这项工作中，我们通过两个现实任务来检查基于 LLM 的招聘系统的公平性：简历摘要和检索。通过构建合成简历数据集和整理招聘信息，我们调查模型行为是否因人口统计学群体而异，并且是否对人口统计学扰动敏感。我们的研究结果表明，大约 10% 的生成摘要中出现了基于种族的差异，而基于性别的差异仅占 1%。在检索设置中，所有评估的模型都显示出跨人口统计学群体的非均匀选择模式，并且对基于性别和种族的扰动都表现出高度敏感性。令人惊讶的是，检索模型对非人口变化表现出了类似的敏感性，这表明公平性问题可能部分源于一般的脆弱性问题。总体而言，我们的结果表明，基于 LLM 的招聘系统（尤其是在检索阶段）可能会表现出明显的偏见，从而导致现实世界中出现歧视性结果。]]></description>
      <guid>https://arxiv.org/abs/2501.04316</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>先理解后推理：通过迭代总结预提示增强思路链</title>
      <link>https://arxiv.org/abs/2501.04341</link>
      <description><![CDATA[arXiv:2501.04341v1 公告类型：新 
摘要：思路链 (CoT) 提示是大型语言模型 (LLM) 中增强复杂推理的主要范式。它指导 LLM 呈现多步骤推理，而不是直接生成最终答案。然而，当推理所需的关键信息隐含或缺失时，CoT 会遇到困难。发生这种情况的原因是 CoT 强调推理步骤的顺序，而忽略了基本信息的早期提取。我们提出了一种称为迭代总结预提示 (ISP^2) 的预提示方法，用于在未明确提供关键信息时改进 LLM 推理。首先，提取实体及其相应的描述以形成潜在的关键信息对。接下来，我们使用可靠性评级来评估这些对，然后将排名最低的两个对合并为新的实体描述。重复此过程，直到获得唯一的关键信息对。最后，该对与原始问题一起输入到 LLM 中以产生答案。大量实验表明，与现有方法相比，该方法的效率提高了 7.1%。与传统提示不同，ISP^2 采用预提示归纳法，可灵活集成到各种推理框架中。代码可在 https://github.com/zdhgreat/ISP-2 上找到。]]></description>
      <guid>https://arxiv.org/abs/2501.04341</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SEO：大型语言模型的随机经验优化</title>
      <link>https://arxiv.org/abs/2501.04393</link>
      <description><![CDATA[arXiv:2501.04393v1 公告类型：新 
摘要：大型语言模型（LLM）可以从有用的经验中受益，以提高其在特定任务上的性能。然而，为不同的LLM找到有用的经验并不明显，因为不清楚什么经验适合特定的LLM。以前的研究旨在使用LLM自动查找有用的经验，但很难确保获得的经验的有效性。在本文中，我们提出了随机经验优化（SEO），这是一种迭代方法，它通过自然语言中的经验更新来找到优化的模型特定经验，而无需修改模型参数。在SEO中，我们提出了一种随机验证方法来确保经验的更新方向，避免无效的更新。三个LLM在三个任务上的实验结果表明，通过SEO优化的经验可以实现持续的性能提升。进一步的分析表明，SEO优化的经验可以推广到分布外的数据，从而提高LLM在类似任务上的性能。]]></description>
      <guid>https://arxiv.org/abs/2501.04393</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于解决数学奥林匹克问题基准的端到端孟加拉语 AI：利用集成方法利用大型语言模型</title>
      <link>https://arxiv.org/abs/2501.04425</link>
      <description><![CDATA[arXiv:2501.04425v1 公告类型：新
摘要：这项工作介绍了一种增强大型语言模型 (LLM) 以解决孟加拉 AI 数学挑战的系统方法。通过评估不同的 LLM 配置、使用特定数据集进行微调以及实施检索增强生成 (RAG)，我们提高了模型在多语言环境中的推理精度。关键发现表明，定制提示、数据集增强和迭代推理提高了模型在奥林匹克级数学挑战方面的效率。]]></description>
      <guid>https://arxiv.org/abs/2501.04425</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用大型语言模型实现 GitHub 的隐藏实体检测</title>
      <link>https://arxiv.org/abs/2501.04455</link>
      <description><![CDATA[arXiv:2501.04455v1 公告类型：新
摘要：命名实体识别是从非结构化数据源构建知识库时的重要任务。虽然实体检测方法主要依赖于大量训练数据，但大型语言模型 (LLM) 利用预训练期间获得的功能，为依赖零样本学习 (ZSL) 或少样本学习 (FSL) 的方法铺平了道路。具体而言，在没有大规模训练数据的非常特殊的场景中，ZSL/FSL 开辟了新的机会。本文遵循这一最新趋势，并研究在这种情况下利用大型语言模型 (LLM) 自动检测来自 GitHub 存储库的文本内容中的数据集和软件的潜力。虽然现有方法仅关注命名实体，但本研究旨在通过整合存储库和在线中心等资源来扩大范围，其中实体也由 URL 表示。本研究探索了不同的 FSL 提示学习方法，以提高 LLM 识别存储库文本中数据集和软件提及的能力。通过分析 LLM 的有效性和学习策略，本文深入了解了高级语言模型在自动实体检测方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.04455</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>当法学硕士遇到困难时：针对资源匮乏的语言的无参考翻译评估</title>
      <link>https://arxiv.org/abs/2501.04473</link>
      <description><![CDATA[arXiv:2501.04473v1 公告类型：新
摘要：本文研究了针对低资源语言对的机器翻译的无参考评估，即质量评估 (QE)。段级 QE 是一项具有挑战性的跨语言理解任务，它为翻译输出提供质量分数 (0-100)。我们全面评估零/少样本场景中的大型语言模型 (LLM)，并使用基于注释指南的新提示执行指令微调。我们的结果表明，基于提示的方法优于基于编码器的微调 QE 模型。我们的错误分析揭示了标记化问题，以及由于音译和命名实体导致的错误，并主张改进跨语言任务的 LLM 预训练。我们发布了数据和公开训练的模型以供进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2501.04473</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PolInterviews——德国政治家公共广播采访数据集</title>
      <link>https://arxiv.org/abs/2501.04484</link>
      <description><![CDATA[arXiv:2501.04484v1 公告类型：新
摘要：本文介绍了一个新颖的公共广播采访数据集，采访对象是德国高级政客。采访内容来自 YouTube，经过转录、说话人识别处理，并以整洁开放的格式存储。该数据集包括对 33 位不同德国政客的 99 次采访，涵盖五种主要采访形式，共包含 28,146 个句子。作为同类数据集中的第一个，该数据集为研究（德国）政治背景下的政治传播的各个方面提供了宝贵的机会，例如议程设置、采访者动态或政客的自我表现。]]></description>
      <guid>https://arxiv.org/abs/2501.04484</guid>
      <pubDate>Thu, 09 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>