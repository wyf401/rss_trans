<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 26 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>DeepScore：一种测量 AI 生成的临床文档质量的综合方法</title>
      <link>https://arxiv.org/abs/2409.16307</link>
      <description><![CDATA[arXiv:2409.16307v1 公告类型：新
摘要：医疗从业者正在迅速采用生成式 AI 解决方案进行临床文档处理，从而节省大量时间并减轻压力。然而，评估 AI 生成的文档的质量是一项复杂且持续的挑战。本文概述了 DeepScribe 评估和管理笔记质量的方法，重点关注各种指标和综合“DeepScore”，即质量和准确性的总体指数。这些方法旨在通过问责制和持续改进来提高患者护理文档的质量。]]></description>
      <guid>https://arxiv.org/abs/2409.16307</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索聊天翻译中的传统 NMT 模型和大型语言模型</title>
      <link>https://arxiv.org/abs/2409.16331</link>
      <description><![CDATA[arXiv:2409.16331v1 公告类型：新
摘要：本文介绍了华为翻译服务中心（HW-TSC）在英语和德语（en-de）双向 WMT24 聊天翻译共享任务中的提交情况。实验涉及使用聊天数据微调模型并探索各种策略，包括最小贝叶斯风险（MBR）解码和自训练。结果显示在某些方向上有显着的性能改进，其中 MBR 自训练方法取得了最佳效果。大型语言模型还讨论了聊天翻译领域面临的挑战和进一步研究的潜在途径。]]></description>
      <guid>https://arxiv.org/abs/2409.16331</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>做正确的事，消除偏见！使用 LLM 缓解多类别偏见</title>
      <link>https://arxiv.org/abs/2409.16371</link>
      <description><![CDATA[arXiv:2409.16371v1 公告类型：新
摘要：本文解决了为语言构建稳健且可推广的偏见缓解模型的挑战。认识到现有数据集的局限性，我们引入了 ANUBIS，这是一个新数据集，包含 1507 个精心策划的句子对，涵盖九个社会偏见类别。我们评估了 T5 等最先进的模型，利用监督微调 (SFT)、强化学习 (PPO、DPO) 和上下文学习 (ICL) 来有效缓解偏见。我们的分析侧重于多类社会偏见减少、跨数据集通用性和训练模型的环境影响。ANUBIS 和我们的研究结果为构建更公平的人工智能系统提供了宝贵的资源，并有助于开发具有广泛社会影响的负责任和无偏见的技术。]]></description>
      <guid>https://arxiv.org/abs/2409.16371</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RISCORE：通过上下文重建示例增强语言模型中的上下文谜语解决能力</title>
      <link>https://arxiv.org/abs/2409.16383</link>
      <description><![CDATA[arXiv:2409.16383v1 公告类型：新
摘要：解谜需要高级推理技能，迫使法学硕士进行抽象思维和创造性解决问题，这通常会揭示他们认知能力的局限性。在本文中，我们使用多项选择题形式检查法学硕士的解谜能力，探索不同的提示技术如何影响需要不同推理技能的谜语的表现。为了提高结果，我们引入了 RISCORE（使用上下文重构的谜题解决）一种新颖的全自动提示方法，该方法生成并利用上下文重构的基于句子的谜题与原始示例结合以创建少样本样本。我们的实验表明，RISCORE 显着提高了语言模型在垂直和横向思维任务中的表现，超越了各种少样本设置中的传统样本选择策略。]]></description>
      <guid>https://arxiv.org/abs/2409.16383</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士偏见综合调查：现状与未来方向</title>
      <link>https://arxiv.org/abs/2409.16430</link>
      <description><![CDATA[arXiv:2409.16430v1 公告类型：新
摘要：大型语言模型 (LLM) 通过提供前所未有的文本生成、翻译和理解功能，彻底改变了自然语言处理 (NLP) 中的各种应用。然而，它们的广泛部署揭示了人们对这些模型中嵌入的偏见的重大担忧。本文对 LLM 中的偏见进行了全面的调查，旨在对这些偏见的类型、来源、影响和缓解策略进行广泛的回顾。我们系统地将偏见分为几个维度。我们的调查综合了当前的研究结果，并讨论了偏见在实际应用中的影响。此外，我们批判性地评估了现有的偏见缓解技术，并提出了未来的研究方向，以提高 LLM 的公平性和公正性。这项调查是研究人员、从业者和政策制定者解决和理解 LLM 中偏见的基础资源。]]></description>
      <guid>https://arxiv.org/abs/2409.16430</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FMDLlama：基于大型语言模型的金融虚假信息检测</title>
      <link>https://arxiv.org/abs/2409.16452</link>
      <description><![CDATA[arXiv:2409.16452v1 公告类型：新
摘要：社交媒体的出现使得虚假信息的传播更加容易。在金融领域，信息的准确性对金融市场的各个方面都至关重要，这使得金融虚假信息检测（FMD）成为亟待解决的问题。大型语言模型（LLM）在各个领域都表现出色。然而，当前的研究大多依赖于传统方法，尚未探索LLM在FMD领域的应用。主要原因是缺乏FMD指令调整数据集和评估基准。在本文中，我们提出了FMDLlama，这是第一个基于使用指令数据微调Llama3.1的用于FMD任务的开源指令跟踪LLM，第一个支持LLM指令调整的多任务FMD指令数据集（FMDID），以及一个具有分类和解释生成任务的综合FMD评估基准（FMD-B）以测试LLM的FMD能力。我们将我们的模型与 FMD-B 上的各种 LLM 进行比较，我们的模型优于所有其他开源 LLM 以及 ChatGPT。]]></description>
      <guid>https://arxiv.org/abs/2409.16452</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 改进 NL-to-FOL 翻译的策略：数据生成、增量微调和验证</title>
      <link>https://arxiv.org/abs/2409.16461</link>
      <description><![CDATA[arXiv:2409.16461v1 公告类型：新 
摘要：逻辑推理是自然语言处理中的一项基本任务，对大型语言模型 (LLM) 提出了重大挑战。逻辑推理的固有特性使其非常适合符号表示，例如一阶逻辑 (FOL)。符号逻辑推理研究探索了使用最先进的 LLM（即 GPT-4）生成自然语言 (NL) 语句的 FOL 翻译，但翻译中的错误通常不是重点。我们通过对 LLM 生成的 FOL 语句中的翻译错误进行分类来解决这个问题。为了在提高 LLaMA-2 13B 和 Mistral 7B 等较小语言模型的 FOL 翻译质量方面取得进展，我们使用 GPT-4o 创建了 ProofFOL，这是 ProofWriter 数据集的高质量 FOL 注释子集。与 LLaMA-2 70B 等大型语言模型相比，基于此银标准数据进行微调的模型在性能上取得了显著提升。除了使用大数据改进模型之外，我们还解决了数据稀缺问题，并引入了一个包含数据增强和验证步骤的增量框架。在增强过程中，一对（前提，结论）根据谓词和 FOL 被拆分为多个新实例。此数据用于微调，并且此模型上的推理会生成比在原始数据上训练的模型错误更少的 FOL。我们对翻译错误的调查导致生成扰动数据集，该数据集用于训练验证器以纠正潜在的句法和语义 FOL 翻译错误。我们展示了一种充分利用现有有限的人工注释数据集的有效方法。我们的结果显示，使用 LLaMA-2 和 Mistral 模型上的 ProofFOL，ProofWriter 和 ProntoQA 数据集的性能达到最佳水平。]]></description>
      <guid>https://arxiv.org/abs/2409.16461</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过重写非自回归 ASR 格进行拼写纠正</title>
      <link>https://arxiv.org/abs/2409.16469</link>
      <description><![CDATA[arXiv:2409.16469v1 公告类型：新
摘要：对于端到端自动语音识别 (ASR) 模型，识别个人或罕见短语可能很困难。提高准确性的一个有希望的方法是通过拼写纠正（或重写）ASR 格，其中可能被误识别的短语被替换为声学相似且上下文相关的替代短语。然而，由于非自回归、上下文无关的波束搜索产生的噪声假设，重写对于使用联结时间分类 (CTC) 训练的 ASR 模型来说具有挑战性。
我们提出了一种有限状态转换器 (FST) 技术来重写由基于 Transformer 的 CTC 模型生成的字片格。我们的算法直接将字素到音素 (G2P) 转换为音素，避免了明确的单词表示并利用了 CTC 格的丰富性。我们的方法不需要重新训练或修改 ASR 模型。我们在具有上下文相关实体的测试集上将句子错误率 (SER) 相对降低了 15.2%。]]></description>
      <guid>https://arxiv.org/abs/2409.16469</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索导师与学生对话中的知识追踪</title>
      <link>https://arxiv.org/abs/2409.16490</link>
      <description><![CDATA[arXiv:2409.16490v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展导致了人工智能 (AI) 驱动的辅导聊天机器人的发展，有望为人们提供广泛的高质量个性化教育。现有的研究主要研究如何让 LLM 遵循辅导原则，而不是如何在对话中模拟学生行为。然而，分析学生对话轮次可以作为一种形成性评估，因为开放式的学生话语可能表明他们的知识水平并揭示特定的误解。在这项工作中，我们首次尝试在导师与学生的对话中进行知识追踪 (KT)。我们提出了 LLM 提示方法来识别每个对话轮次中涉及的知识成分/技能，并诊断学生是否正确回应导师，并通过专家人工评估验证 LLM 的有效性。然后，我们对得到的标记数据应用一系列 KT 方法来跟踪整个对话中学生的知识水平。我们对两个辅导对话数据集进行了实验，并表明一种新颖而简单的基于 LLM 的方法 LLMKT 在预测对话中学生回答正确性方面明显优于现有的 KT 方法。我们进行了广泛的定性分析，以突出对话 KT 中的挑战并概述了未来工作的多种途径。]]></description>
      <guid>https://arxiv.org/abs/2409.16490</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>理解产品图像引发的语言认知复杂性</title>
      <link>https://arxiv.org/abs/2409.16521</link>
      <description><![CDATA[arXiv:2409.16521v1 公告类型：新
摘要：产品图像（例如手机）可用于引出通过语言表达的多种消费者报告特征，包括表面感知属性（例如“白色”）和更复杂的属性，如感知效用（例如“电池”）。引出语言的认知复杂性揭示了认知过程的性质以及理解它们所需的背景；认知复杂性还可以预测消费者随后的选择。这项工作提供了一种测量和验证产品图像引发的人类语言认知复杂性的方法，提供了一种理解人类认知过程的工具以及由大型语言模型 (LLM) 模拟的虚拟受访者。我们还引入了一个大型数据集，其中包括产品图像的各种描述性标签，包括人类评定的复杂性。我们证明，可以使用一组自然语言模型来近似人类评定的认知复杂性，这些模型结合起来可以粗略地捕捉复杂性构造。此外，即使在人类对复杂性的评估有限的用例中，这种方法也是最低限度监督和可扩展的。]]></description>
      <guid>https://arxiv.org/abs/2409.16521</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将问题从查询生成中分离出来以实现任务自适应检索</title>
      <link>https://arxiv.org/abs/2409.16570</link>
      <description><![CDATA[arXiv:2409.16570v1 公告类型：新
摘要：本文研究信息检索问题，以适应看不见的任务。现有工作从特定领域的文档生成合成查询以联合训练检索器。但是，传统的查询生成器将查询视为问题，因此无法适应一般的搜索意图。更宽松的方法结合了任务自适应元素，例如使用 137B LLM 进行少量学习。在本文中，我们挑战了将查询和问题等同起来的趋势，而是将查询生成任务概念化为将高级意图“编译”为任务自适应查询。具体来说，我们提出了 EGG，这是一种查询生成器，可以更好地适应 BeIR 基准中表达的广泛搜索意图。我们的方法在四个意图未被充分探索的任务上优于基线和现有模型，同时使用的查询生成器比以前最先进的方法小 47 倍。我们的研究结果表明，用明确的搜索意图指导 LM 是建模有效查询生成器的一个关键方面。]]></description>
      <guid>https://arxiv.org/abs/2409.16570</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>第一个临床文本生成共享任务概述：RRG24 和“Discharge Me！”</title>
      <link>https://arxiv.org/abs/2409.16603</link>
      <description><![CDATA[arXiv:2409.16603v1 公告类型：新
摘要：自然语言生成的最新发展对医疗保健有着巨大的影响。例如，最先进的系统可以自动生成临床报告中的各个部分，以减轻医生的工作量并简化医院文档。为了探索这些应用，我们提出了一个由两个子任务组成的共享任务：（1）放射学报告生成（RRG24）和（2）出院总结生成（“出院！”）。RRG24 涉及根据胸部 X 光片生成放射学报告的“发现”和“印象”部分。“出院！”涉及为通过急诊科入院的患者生成出院总结的“简要医院病程”和“出院说明”部分。“出院！”提交的内容随后由一组临床医生审查。这两项任务都强调通过生成文档来减少临床医生倦怠和重复性工作量的目标。我们收到了来自 8 个团队的 201 份 RRG24 作品提交，以及来自 16 个团队的 211 份“Discharge Me!”作品提交。]]></description>
      <guid>https://arxiv.org/abs/2409.16603</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估和增强大型语言模型以评估学术出版物的新颖性</title>
      <link>https://arxiv.org/abs/2409.16605</link>
      <description><![CDATA[arXiv:2409.16605v1 公告类型：新
摘要：最近的研究主要从语义角度评估了大型语言模型 (LLM) 的创造力/新颖性，使用了认知科学的基准。然而，在评估 LLM 时，评估学术出版物的新颖性是一个尚未探索的领域。在本文中，我们引入了一个学术新颖性基准 (SchNovel) 来评估 LLM 评估学术论文新颖性的能力。SchNovel 由从 arXiv 数据集中抽样的六个领域的 15000 对论文组成，出版日期相隔 2 至 10 年。在每一对中，最近发表的论文被认为更新颖。此外，我们提出了 RAG-Novelty，它通过利用检索类似论文来评估新颖性，从而模拟人类审阅者的审阅过程。大量实验深入了解了不同 LLM 评估新颖性的能力，并证明 RAG-Novelty 优于最近的基线模型。]]></description>
      <guid>https://arxiv.org/abs/2409.16605</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>针对实际应用的声明引导文本后门攻击</title>
      <link>https://arxiv.org/abs/2409.16618</link>
      <description><![CDATA[arXiv:2409.16618v1 公告类型：新
摘要：自然语言处理的最新进展和大型语言模型的广泛使用暴露了新的安全漏洞，例如后门攻击。以前的后门攻击需要在模型分发后进行输入操作才能激活后门，这在现实世界的适用性方面造成了限制。为了解决这一问题，我们引入了一种新颖的声明引导后门攻击 (CGBA)，它利用固有的文本声明作为触发器，消除了对此类操作的需求。CGBA 利用声明提取、聚类和有针对性的训练来诱使模型对有针对性的声明做出不当行为，而不会影响其在干净数据上的性能。CGBA 在各种数据集和模型中展示了其有效性和隐蔽性，大大增强了实际后门攻击的可行性。我们的代码和数据将在 https://github.com/PaperCGBA/CGBA 上提供。]]></description>
      <guid>https://arxiv.org/abs/2409.16618</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过自我对弈训练语言模型赢得辩论可提高评判准确性</title>
      <link>https://arxiv.org/abs/2409.16636</link>
      <description><![CDATA[arXiv:2409.16636v1 公告类型：新
摘要：我们通过训练模型进行辩论，使用通过自我游戏生成的数据进行辩论，以测试辩论作为一种可扩展监督方法的稳健性。在一项长语境阅读理解任务中，我们发现基于语言模型的评估者在评判为赢得辩论而优化的模型时，能够更准确地回答问题。相比之下，我们发现，在没有对方辩手在场的情况下，经过训练以说服法官的咨询模型不存在这种关系。在我们的辩论模型和新颖的咨询基线的定量和定性比较中，我们发现有证据表明，辩论训练鼓励更强大、更具信息量的论据，表明它有望为难以直接评估的任务提供高质量的监督。]]></description>
      <guid>https://arxiv.org/abs/2409.16636</guid>
      <pubDate>Thu, 26 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>