<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 03 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>安全服务：调整指令调整模型以实现安全性和帮助性</title>
      <link>https://arxiv.org/abs/2412.00074</link>
      <description><![CDATA[arXiv:2412.00074v1 公告类型：新
摘要：大型语言模型 (LLM) 在复杂推理和文本生成方面表现出了卓越的能力。然而，当提示有问题的输入时，这些模型可能会无意中生成不安全或有偏见的反应，从而对实际部署提出了重大的道德和实际问题。这项研究解决了开发语言模型的关键挑战，这些模型可以生成有用和无害的内容，在模型性能和安全性之间找到微妙的平衡。我们证明，在预训练模型的指令调整过程中加入与安全相关的指令可以显著减少对不安全提示的毒性反应，而不会影响有用性数据集的性能。我们发现直接偏好优化 (DPO) 特别有效，通过利用选择和拒绝的响应进行学习，其表现优于 SIT 和 RAFT。我们的方法将各种有害性基准中的安全响应从 40% 提高到 90% 以上。此外，我们讨论了一个严格的评估框架，该框架涵盖了安全性和有用性任务的专门指标和多样化数据集，确保对模型的功能进行全面的评估。]]></description>
      <guid>https://arxiv.org/abs/2412.00074</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于科学文本分类的微调大型语言模型：一项比较研究</title>
      <link>https://arxiv.org/abs/2412.00098</link>
      <description><![CDATA[arXiv:2412.00098v1 公告类型：新 
摘要：跨不同领域的在线文本内容呈指数级增长，需要先进的自动文本分类方法。基于 Transformer 架构的大型语言模型 (LLM) 已在此领域取得显著成功，尤其是在自然语言处理 (NLP) 任务中。然而，由于专业词汇和数据不平衡等独特挑战，通用 LLM 通常在处理领域特定内容（例如科学文本）时遇到困难。在本研究中，我们在来自 WoS-46985 数据集的三个数据集上对四个最先进的 LLM BERT、SciBERT、BioBERT 和 BlueBERT 进行了微调，以评估它们在科学文本分类中的表现。我们的实验表明，领域特定模型，尤其是 SciBERT，在基于摘要和基于关键字的分类任务中始终优于通用模型。此外，我们将我们取得的成果与文献中报道的深度学习模型成果进行了比较，进一步突出了 LLM 的优势，尤其是在特定领域使用时。研究结果强调了 LLM 领域特定适应性的重要性，以提高其在专业文本分类任务中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.00098</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过知识注入实现高效的学习内容检索</title>
      <link>https://arxiv.org/abs/2412.00125</link>
      <description><![CDATA[arXiv:2412.00125v1 公告类型：新
摘要：随着在线教育平台的兴起，各个领域的教育内容日益丰富。在众多可用资源中找到最合适的培训可能很困难，尤其是在包含许多相互关联的领域，例如 ICT。在本研究中，我们提出了一个领域特定的聊天机器人应用程序，它需要有限的资源，利用 Phi 语言模型的版本来帮助学习者提供教育内容。在提出的方法中，使用 QLoRA 对 Phi-2 和 Phi-3 模型进行了微调。微调所需的数据来自华为人才平台，该平台提供计算机科学领域不同专业水平的课程。RAG 系统用于支持该模型，该模型通过 500 个问答对进行了微调。此外，从 JSON、PPT 和 DOC 等不同格式中提取了总共 420 个问答对内容，以创建用于 RAG 系统的矢量数据库。通过将微调模型与 RAG 方法结合使用，我们得到了具有不同能力的聊天机器人。向生成的聊天机器人提出的问题和答案分别保存，并使用 ROUGE、BERTScore、METEOR 和 BLEU 指标进行评估。RAG 支持的 Phi-2 模型的精度值为 0.84，F1 分数为 0.82。除了 4 个不同类别中总共 13 个不同的评估指标外，还将每个模型的答案与创建的内容进行比较，并选择最合适的方法用于实际应用。]]></description>
      <guid>https://arxiv.org/abs/2412.00125</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>是否集成：评估使用大型语言模型进行网络钓鱼检测的多数投票策略</title>
      <link>https://arxiv.org/abs/2412.00166</link>
      <description><![CDATA[arXiv:2412.00166v1 公告类型：新
摘要：大型语言模型 (LLM) 的有效性在很大程度上取决于它们收到的提示的质量。但是，即使在处理相同的提示时，由于训练过程的差异，LLM 也会产生不同的结果。为了利用多个 LLM 的集体智慧并提高其性能，本研究调查了三种用于文本分类的多数投票策略，重点是网络钓鱼 URL 检测。这些策略是：(1) 基于提示的集成，它利用单个 LLM 对各种提示生成的响应的多数投票；(2) 基于模型的集成，这需要将来自多个 LLM 的响应聚合到一个提示；(3) 混合集成，通过将不同的提示发送到多个 LLM 然后聚合它们的响应来结合这两种方法。我们的分析表明，集成策略最适合单个组件表现出同等性能水平的情况。然而，当个人表现存在显著差异时，集成方法的有效性可能不会超过表现最好的单个 LLM 或提示。在这种情况下，不建议选择集成技术。]]></description>
      <guid>https://arxiv.org/abs/2412.00166</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>一次训练，彻底解决情感方面三元组提取问题</title>
      <link>https://arxiv.org/abs/2412.00208</link>
      <description><![CDATA[arXiv:2412.00208v1 公告类型：新
摘要：方面-意见对提取 (AOPE) 和方面情绪三元组提取 (ASTE) 在自然语言处理中引起了广泛关注。然而，大多数现有方法都是流水线框架，它提取方面/意见并分别识别它们的关系，导致错误传播和高时间复杂度的缺点。针对这个问题，我们提出了一种基于转换的管道来减轻标记级偏差并捕获位置感知的方面-意见关系。通过使用融合数据集和对比学习优化，我们的模型可以学习稳健的动作模式，并且可以联合优化单独的子任务，通常具有线性时间复杂度。结果表明，我们的模型在 ASTE 和 AOPE 任务上都取得了最佳性能，在 F1 测量中比最先进的方法至少高出 6.98%。代码可在 https://github.com/Paparare/trans_aste 获得。]]></description>
      <guid>https://arxiv.org/abs/2412.00208</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>N\"ushuRescue：利用人工智能振兴濒临灭绝的 N\"ushu 语言</title>
      <link>https://arxiv.org/abs/2412.00218</link>
      <description><![CDATA[arXiv:2412.00218v1 公告类型：新
摘要：保护和振兴濒危和灭绝语言是一项有意义的事业，既能保护文化遗产，又能丰富语言学和人类学等领域。然而，这些语言通常资源匮乏，因此重建起来既费力又费钱。女书就是这一挑战的典型例子，女书是一种罕见的文字，历史上中国瑶族妇女用它来在父权社会中表达自我。为了应对这一挑战，我们引入了 N\&quot;ushuRescue，这是一个人工智能驱动的框架，旨在用最少的数据训练濒危语言的大型语言模型 (LLM)。N\&quot;ushuRescue 可自动评估并扩展目标语料库，以加速语言复兴。作为基础组件，我们开发了 NCGold，这是一个 500 句的女书-中文平行语料库，这是同类中第一个公开可用的数据集。利用 GPT-4-Turbo，在之前没有接触过 N\&quot;ushu 并且只有来自 NCGold 的 35 个简短示例的情况下，N\&quot;ushuRescue 在 50 个保留句子上实现了 48.69% 的翻译准确率，并生成了 NCSilver，这是一组 98 个新翻译的现代汉语句子，长度不一。补充材料中包含了 NCGold 和 NCSilver 的样本。此外，我们开发了基于 FastText 和 Seq2Seq 模型，以进一步支持对 N\&quot;ushu 的研究。N\&quot;ushuRescue 为濒危语言的振兴提供了一种多功能且可扩展的工具，最大限度地减少了对大量人工输入的需求。]]></description>
      <guid>https://arxiv.org/abs/2412.00218</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>临床文档语料库和各种领域代理：语料库设计多样性调查，重点关注德语文本数据</title>
      <link>https://arxiv.org/abs/2412.00230</link>
      <description><![CDATA[arXiv:2412.00230v1 公告类型：新
摘要：我们调查了临床文档语料库，重点关注德国文本数据。由于德国严格的数据隐私立法，这些资源（只有少数例外）都存储在安全的临床数据空间中，并对临床外部研究人员锁定。这种情况与自然语言处理领域的既定工作流程形成鲜明对比，在自然语言处理领域，易于访问和重复使用数据集合是常见的做法。因此，已经研究了替代语料库设计以摆脱这种数据贫乏。除了英语临床数据集的机器翻译和具有虚构临床内容的合成语料库的生成外，其他几种类型的领域代理也已出现，以替代真实的临床文档。近距离代理的常见实例是医学期刊出版物、临床治疗指南、药品标签等，更远距离代理包括在线百科全书医学文章或来自社交媒体渠道的医学内容。在对来自四个书目系统的 359 个结果进行符合 PRISM 标准的筛选后，最终选择了 75 篇相关文献进行本次审查，并确定了 59 个不同的语料库。我们确定了 24 个真实的临床语料库（来自 40 个出版物），其中只有 5 个可以公开分发。2 个真实语料库的翻译和 3 个合成的翻译补充了临床语料库集。14 个语料库被归类为近域代理，16 个被归类为远域代理。大量不可访问的真实德语临床语料库与其可公开访问的替代品之间存在明显的分界：翻译的或合成的、近域或远域的代理。因此乍一看，数据瓶颈似乎已经突破。但直观地看，在这个类型空间中，特定类型的写作风格、措辞和医学领域专业知识的差异也是显而易见的。这就引发了一个问题：替代语料库设计的有效性到底有多高。]]></description>
      <guid>https://arxiv.org/abs/2412.00230</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中的认知偏差：调查和缓解实验</title>
      <link>https://arxiv.org/abs/2412.00323</link>
      <description><![CDATA[arXiv:2412.00323v1 公告类型：新
摘要：大型语言模型 (LLM) 在人类编写的大型语料库上进行训练，并在各种任务上表现出色。然而，由于人类容易受到认知偏见的影响，从而导致非理性判断，LLM 也会受到这些偏见的影响，导致非理性决策。例如，由于顺序偏差，改变多项选择题中选项的顺序会影响 LLM 的性能。在我们的研究中，我们首先对现有的研究进行了广泛的调查，研究了 LLM 的认知偏见及其缓解措施。LLM 中的缓解技术的缺点是它们可以应用的偏见类型有限，或者需要冗长的输入或输出。然后，我们研究了两种缓解方法 SoPro 和 AwaRe 在应用于 LLM 时的有效性，这受到了众包研究的启发。为了测试这些方法的有效性，我们在 GPT-3.5 和 GPT-4 上进行了实验，以评估应用这些方法之前和之后六种偏见对输出的影响。结果表明，虽然 SoPro 影响不大，但 AwaRe 使 LLM 能够减轻这些偏见的影响并做出更合理的反应。]]></description>
      <guid>https://arxiv.org/abs/2412.00323</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过不确定性引导的策略选择增强零样本思维链提示</title>
      <link>https://arxiv.org/abs/2412.00353</link>
      <description><![CDATA[arXiv:2412.00353v1 公告类型：新
摘要：思维链 (CoT) 提示通过构建大型语言模型 (LLM) 的推理过程，显著增强了其能力。然而，现有方法面临着严重的限制：手工制作的演示需要大量的人类专业知识，而触发短语容易出现不准确的情况。在本文中，我们提出了零样本不确定性选择 (ZEUS) 方法，这是一种新方法，它利用不确定性估计来选择有效的演示，而无需访问模型参数，从而改进了 CoT 提示。与传统方法不同，ZEUS 在区分有用和无效问题方面具有很高的灵敏度，从而确保了更精确和可靠的选择。我们广泛的评估表明，ZEUS 在四个具有挑战性的推理基准上始终优于现有的 CoT 策略，证明了其稳健性和可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2412.00353</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在 Transformer 中，自注意力机制是否需要单独的权重？</title>
      <link>https://arxiv.org/abs/2412.00359</link>
      <description><![CDATA[arXiv:2412.00359v1 公告类型：新
摘要：自注意力的成功在于它能够捕捉长距离依赖关系并增强上下文理解，但它受到计算复杂性和处理具有固有方向性的顺序数据的挑战的限制。这项工作引入了一种基于共享权重自注意力的 BERT 模型，该模型只为（键、值和查询）表示学习一个权重矩阵，而不是为每个表示学习三个单独的矩阵。我们的共享权重注意力将训练参数大小减少了一半以上，训练时间减少了约十分之一。此外，我们在 GLUE 的小任务上展示了比 BERT 基线更高的预测精度，特别是在噪声和域外数据上的泛化能力。实验结果表明，我们的共享自注意力方法在注意力模块中实现了 66.53% 的参数大小减少。在 GLUE 数据集中，基于共享权重自注意力的 BERT 模型比标准、对称和基于成对注意力的 BERT 模型分别提高了 0.38%、5.81% 和 1.06% 的准确率。该模型和源代码可在 Anonymous 上找到。]]></description>
      <guid>https://arxiv.org/abs/2412.00359</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>那是讽刺吗？：讽刺检测的文献综述</title>
      <link>https://arxiv.org/abs/2412.00425</link>
      <description><![CDATA[arXiv:2412.00425v1 公告类型：新
摘要：讽刺很难被人类解读。鉴于讽刺的复杂性，能够解读讽刺通常被称为智慧的标志。因此，这是一个自然语言处理领域，对于计算机来说仍然很难解读。本文献综述深入探讨了讽刺检测的不同方面，以了解检测过程中面临的潜在问题、解决此问题的方法以及可用于讽刺检测的不同形式的数据集。]]></description>
      <guid>https://arxiv.org/abs/2412.00425</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过联合约束 k 均值和子空间选择进行命名实体识别的少样本域自适应</title>
      <link>https://arxiv.org/abs/2412.00426</link>
      <description><![CDATA[arXiv:2412.00426v1 公告类型：新
摘要：命名实体识别 (NER) 是一项通常需要大量带注释数据集的任务，这限制了其在具有不同实体定义的领域中的适用性。本文讨论了少样本 NER，旨在以最少的监督将知识转移到新领域。与以前仅依赖有限带注释数据的方法不同，我们提出了一种弱监督算法，该算法将小型带标记数据集与大量未标记数据相结合。我们的方法通过标签监督、聚类大小约束和特定领域的判别子空间选择扩展了 k-means 算法。这个统一的框架在几个英语数据集上实现了少样本 NER 的最先进的结果。]]></description>
      <guid>https://arxiv.org/abs/2412.00426</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>非英语母语人士或 ChatGPT：谁的思维更佳？</title>
      <link>https://arxiv.org/abs/2412.00457</link>
      <description><![CDATA[arXiv:2412.00457v1 公告类型：新 
摘要：本研究旨在回答一个主要问题：非英语母语人士和 ChatGPT 谁的思维更好？通过处理和解释中心嵌入的英语结构提供证据表明，人类大脑超越了 ChatGPT，并且 ChatGPT 不能被视为一种语言理论。 15 名非英语母语人士被招募为研究参与者。 向研究参与者和 ChatGPT 展示了一个中心嵌入的英语句子。 研究结果表明，即使对于非 L2（这里是英语）母语人士来说，人类大脑仍然远远领先于大型语言模型，特别是 ChatGPT。 研究得出结论，人类大脑处理和解释自然语言数据的能力是独一无二的，而 ChatGPT 仍然落后于人类的这种独特能力。]]></description>
      <guid>https://arxiv.org/abs/2412.00457</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GloCOM：基于全局聚类上下文的短文本神经主题模型</title>
      <link>https://arxiv.org/abs/2412.00525</link>
      <description><![CDATA[arXiv:2412.00525v1 公告类型：新
摘要：由于数据稀疏性限制了单词共现模式，而标签稀疏性则源于不完整的重建目标，因此从短文本中发现隐藏主题对于传统和神经模型来说具有挑战性。尽管数据聚合提供了一种潜在的解决方案，但现有的神经主题模型往往会忽略它，因为时间复杂度、聚合质量差以及难以推断单个文档的主题比例。在本文中，我们提出了一个新模型 GloCOM（主题模型的全局聚类上下文），该模型通过构建短文档的聚合全局聚类上下文来解决这些挑战，利用来自预训练语言模型的文本嵌入。GloCOM 可以推断聚类上下文的全局主题分布和单个短文本的局部分布。此外，该模型结合了这些全局上下文来增加重建损失，从而有效地处理了标签稀疏性问题。在短文本数据集上进行的大量实验表明，我们的方法在主题质量和文档表示方面都优于其他最先进的模型。]]></description>
      <guid>https://arxiv.org/abs/2412.00525</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ChemTEB：化学文本嵌入基准，特定领域的嵌入模型性能和效率概述</title>
      <link>https://arxiv.org/abs/2412.00532</link>
      <description><![CDATA[arXiv:2412.00532v1 公告类型：新 
摘要：语言模型的最新进展开启了卓越信息检索和内容生成的新时代，嵌入模型在优化数据表示效率和性能方面发挥着重要作用。虽然海量文本嵌入基准 (MTEB) 等基准已经标准化了通用领域嵌入模型的评估，但在化学等专业领域仍然存在差距，由于特定领域的挑战，这些领域需要量身定制的方法。本文介绍了一种专为化学科学设计的新基准——化学文本嵌入基准 (ChemTEB)。ChemTEB 解决了化学文献和数据独特的语言和语义复杂性，提供了一套全面的化学领域数据任务。通过使用此基准对 34 个开源和专有模型进行评估，我们阐明了当前方法在处理和理解化学信息方面的优缺点。我们的工作旨在为研究界提供标准化、特定领域的评估框架，促进为化学相关应用开发更精确、更高效的 NLP 模型。此外，它还提供了对通用模型在特定领域环境中的性能的洞察。ChemTEB 附带开源代码和数据，进一步提高了其可访问性和实用性。]]></description>
      <guid>https://arxiv.org/abs/2412.00532</guid>
      <pubDate>Tue, 03 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>