<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 31 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>Docling：一款高效的人工智能驱动文档转换开源工具包</title>
      <link>https://arxiv.org/abs/2501.17887</link>
      <description><![CDATA[arXiv:2501.17887v1 公告类型：新
摘要：我们介绍了 Docling，这是一种易于使用、自包含、MIT 许可的开源文档转换工具包，它可以将几种流行的文档格式解析为统一、结构丰富的表示形式。它由最先进的专门用于布局分析 (DocLayNet) 和表格结构识别 (TableFormer) 的 AI 模型提供支持，并且可以在少量资源预算下在商用硬件上高效运行。Docling 作为 Python 包发布，可以用作 Python API 或 CLI 工具。Docling 的模块化架构和高效的文档表示使实现扩展、新功能、模型和自定义变得容易。Docling 已经集成到其他流行的开源框架中（例如 LangChain、LlamaIndex、spaCy），使其成为处理文档和开发高端应用程序的天然选择。开源社区全力投入了 Docling 的使用、推广和开发，不到一个月的时间，Docling 在 GitHub 上就收获了 10,000 颗星，据报道，2024 年 11 月，Docling 成为 GitHub 全球第一大热门存储库。]]></description>
      <guid>https://arxiv.org/abs/2501.17887</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>InnerThoughts：解开大型语言模型中的表征和预测</title>
      <link>https://arxiv.org/abs/2501.17994</link>
      <description><![CDATA[arXiv:2501.17994v1 公告类型：新
摘要：大型语言模型 (LLM) 包含大量事实知识，这些知识通常由多项选择问答提示引出。在内部，此类模型通过多个转换器层处理提示，在其隐藏状态中构建问题的不同表示。但最终，只有与最后一层和标记位置相对应的隐藏状态才用于预测答案标签。在这项工作中，我们建议在一组训练问题上学习一个小型的独立神经网络预测器模块，该模块将最后一个时间位置的所有层的隐藏状态作为输入并输出预测。实际上，这样的框架将 LLM 的表示能力与其预测能力区分开来。在一系列硬基准上，我们的方法在性能上取得了显着的改进，有时可与监督微调程序相媲美，但计算成本仅为其一小部分。]]></description>
      <guid>https://arxiv.org/abs/2501.17994</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>灵丹妙药：通过微调后扰动减轻大型语言模型的有害微调</title>
      <link>https://arxiv.org/abs/2501.18100</link>
      <description><![CDATA[arXiv:2501.18100v1 公告类型：新
摘要：有害的微调攻击给微调服务带来了重大的安全风险。主流防御措施旨在对模型进行免疫，使后续有害的微调攻击效果降低。然而，我们的评估结果表明，这种防御措施很脆弱——只需几个微调步骤，模型仍然可以学习有害的知识。为此，我们做了进一步的实验，发现一个非常简单的解决方案——在微调模型中添加纯随机扰动，可以使模型从有害行为中恢复，尽管这会导致模型微调性能的下降。为了解决微调性能下降的问题，我们进一步提出了 Panacea，它优化了微调后将应用于模型的自适应扰动。Panacea 在不影响下游微调性能的情况下保持了模型的安全对齐性能。对不同的有害率、微调任务和主流 LLM 进行了全面的实验，平均有害分数降低了 21.5%，同时保持了微调性能。作为副产品，我们分析了优化后的扰动，并表明不同 LLM 中的不同层具有不同的安全系数。源代码可在 https://github.com/w-yibo/Panacea 获得]]></description>
      <guid>https://arxiv.org/abs/2501.18100</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多样化偏好优化</title>
      <link>https://arxiv.org/abs/2501.18101</link>
      <description><![CDATA[arXiv:2501.18101v1 公告类型：新
摘要：语言模型的后期训练，无论是通过强化学习、偏好优化还是监督微调，都倾向于锐化输出概率分布并减少生成响应的多样性。这对于需要不同响应的创造性生成任务来说尤其成问题。%这会影响生成高质量合成数据的能力，而这些数据正成为模型训练的重要组成部分。在这项工作中，我们引入了多样化偏好优化 (DivPO)，这是一种在线优化方法，它学习生成比标准管道更加多样化的响应，同时保持生成的质量。在 DivPO 中，选择偏好对首先考虑一组响应及其多样性度量，并选择更稀有但质量更高的选定示例，而拒绝的示例更常见但质量较低。DivPO 可生成 45.6% 的多样化角色属性，故事多样性增加 74.6%，同时保持与标准基线相似的胜率。]]></description>
      <guid>https://arxiv.org/abs/2501.18101</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自监督量化表征，用于无缝集成知识图谱与大型语言模型</title>
      <link>https://arxiv.org/abs/2501.18119</link>
      <description><![CDATA[arXiv:2501.18119v1 公告类型：新
摘要：由于知识图谱（KG）结构与自然语言之间存在天然差距，KG 的整体结构信息与大型语言模型（LLM）的有效集成已成为一个重要问题。为此，我们提出了一个两阶段框架来学习和应用每个实体的量化代码，旨在实现 KG 与 LLM 的无缝集成。首先，提出一种自监督量化表示（SSQR）方法，将 KG 结构和语义知识压缩为与语言句子格式一致的离散代码（即 token）。我们进一步设计 KG 指令跟踪数据，将这些学习到的代码视为特征直接输入到 LLM，从而实现无缝集成。实验结果表明，SSQR 优于现有的无监督量化方法，可以产生更多可区分的代码。此外，经过微调的 LLaMA2 和 LLaMA3.1 在 KG 链接预测和三重分类任务上也具有出色的性能，每个实体仅使用 16 个 token，而不是传统提示方法中的数千个 token。]]></description>
      <guid>https://arxiv.org/abs/2501.18119</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>揭示语言模型在新闻摘要中的作用</title>
      <link>https://arxiv.org/abs/2501.18128</link>
      <description><![CDATA[arXiv:2501.18128v1 公告类型：新
摘要：鉴于最近引入了多种语言模型，以及对改进自然语言处理任务（尤其是摘要）的持续需求，这项工作对 20 种最近的语言模型进行了全面的基准测试，重点关注新闻摘要任务的较小模型。在这项工作中，我们系统地测试了这些模型在总结以不同风格编写并在三个不同数据集中呈现的新闻文章文本方面的能力和有效性。具体来说，我们在本研究中关注零样本和少样本学习设置，并应用了一种结合不同评估概念的稳健评估方法，包括自动指标、人工评估和 LLM-as-a-judge。有趣的是，在少样本学习设置中包含演示示例并没有提高模型的性能，在某些情况下，甚至导致生成的摘要质量更差。这个问题主要是由于用作参考摘要的黄金摘要质量差，这对模型的性能产生了负面影响。此外，我们的研究结果突出了 GPT-3.5-Turbo 和 GPT-4 的卓越性能，它们通常因其先进的功能而占据主导地位。然而，在评估的公共模型中，某些模型（例如 Qwen1.5-7B、SOLAR-10.7B-Instruct-v1.0、Meta-Llama-3-8B 和 Zephyr-7B-Beta）表现出了令人鼓舞的结果。这些模型显示出巨大的潜力，使它们成为新闻摘要任务中大型模型的有竞争力的替代品。]]></description>
      <guid>https://arxiv.org/abs/2501.18128</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>适用于低位大型语言模型的混合精度图神经量化</title>
      <link>https://arxiv.org/abs/2501.18154</link>
      <description><![CDATA[arXiv:2501.18154v1 公告类型：新
摘要：训练后量化 (PTQ) 对于在资源有限的环境中部署大型语言模型 (LLM) 至关重要，因为它可以显著减少资源需求。然而，由于量化权重和原始权重之间存在显著差异，现有的 PTQ 策略在低位水平 (&lt; 3 位) 下表现不佳。为了提高低位宽下的量化性能，我们引入了一种混合精度图神经 PTQ (MG-PTQ) 方法，采用图神经网络 (GNN) 模块来捕获权重之间的依赖关系并自适应地分配量化位宽。通过 GNN 模块的信息传播，我们的方法可以更有效地捕获目标权重之间的依赖关系，从而更准确地评估权重重要性并优化量化策略的分配。在 WikiText2 和 C4 数据集上进行的大量实验表明，我们的 MG-PTQ 方法优于之前最先进的 PTQ 方法 GPTQ，为低位条件下的量化性能设定了新的基准。]]></description>
      <guid>https://arxiv.org/abs/2501.18154</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的上下文结构化标记依赖性编码</title>
      <link>https://arxiv.org/abs/2501.18205</link>
      <description><![CDATA[arXiv:2501.18205v1 公告类型：新
摘要：大规模神经架构中的标记表示策略通常依赖于上下文细化的嵌入，但传统方法很少在标记交互中明确编码结构化关系。自注意力机制有效地捕获了动态上下文依赖关系，但它们对学习到的权重分布的依赖限制了生成序列中长距离层次结构的保存。依赖感知标记编码引入了一种结构化的嵌入初始化方法，确保关系约束嵌入在标记表示中，而不是仅通过注意力动态推断出来。所提出的编码机制通过依赖加权注意力计算来细化标记交互，确保句法和语义依赖关系在多个处理层中得到保留。实证评估表明，不同语言基准的困惑度有所降低，表明自回归文本生成中的上下文连贯性和预测一致性有所改善。计算效率评估显示，内存消耗和训练时间略有增加，这归因于编码模块中的额外矩阵计算，但在传统的 Transformer 架构中仍然可以实现可扩展性。结构化编码增强了词汇变化和依赖性保留，增强了语言连贯性，而无需外部句法注释或辅助训练目标。统计比较突出了依赖性对齐的改进，特别是在较长的序列中，传统的自注意模型表现出层次一致性的下降。句子长度分布表明突然的短语转换减少，进一步支持了显式依赖性编码有助于更结构化的短语生成的假设。]]></description>
      <guid>https://arxiv.org/abs/2501.18205</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>如何选择数据点来对 NLG 模型进行有效的人工评估？</title>
      <link>https://arxiv.org/abs/2501.18251</link>
      <description><![CDATA[arXiv:2501.18251v1 公告类型：新
摘要：人工评估是评估文本生成模型的黄金标准。它也很昂贵，并且为了符合预算限制，在实践中通常会选择测试数据的随机子集。随机选择的数据可能无法准确代表测试性能，因此这种方法在模型比较方面在经济上效率低下。因此，在这项工作中，我们开发了一套选择器，以便在考虑评估成本的同时获得最具信息量的数据点以供人工评估。我们表明，基于自动度量分数的方差、模型输出的多样性或项目反应理论的选择器优于随机选择。我们进一步开发了一种方法，将这些选择器提炼到模型输出尚不可用的场景。特别是，我们引入了基于源的估计器，它仅基于源文本预测项目对人工评估的有用性。我们在两项常见的 NLG 任务（机器翻译和摘要）中展示了我们的选择器的有效性，并表明仅需约 50% 的测试数据即可产生与整个数据相同的评估结果。我们的实现已在 subset2evaluate 包中发布。]]></description>
      <guid>https://arxiv.org/abs/2501.18251</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用文本嵌入模型的通用魔法词来破解 LLM 的安全措施</title>
      <link>https://arxiv.org/abs/2501.18280</link>
      <description><![CDATA[arXiv:2501.18280v1 公告类型：新
摘要：大型语言模型（LLM）的安全问题最近引起了广泛关注，各种防御机制被开发出来以防止有害输出，其中基于文本嵌入模型的保护措施是根本防御措施。通过测试，我们发现文本嵌入模型输出的分布明显偏向，平均值较大。受此观察的启发，我们提出了新颖有效的方法来搜索可以攻击文本嵌入模型的通用魔法词。作为后缀的通用魔法词可以将任何文本的嵌入移向偏差方向，从而操纵任何文本对的相似性并误导保护措施。通过在用户提示后附加魔法词并要求 LLM 以魔法词结尾答案，攻击者可以越狱保护措施。为了消除这种安全风险，我们还提出了针对此类攻击的防御机制，可以以无训练的方式纠正文本嵌入的偏差分布。]]></description>
      <guid>https://arxiv.org/abs/2501.18280</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从入侵生物学科学论文中挖掘物种、地点、栖息地和生态系统：一项使用大型语言模型的大规模探索性研究</title>
      <link>https://arxiv.org/abs/2501.18287</link>
      <description><![CDATA[arXiv:2501.18287v1 公告类型：新
摘要：本文介绍了一项探索性研究，利用大型语言模型 (LLM) 的功能从入侵生物学文献中挖掘关键生态实体。具体来说，我们专注于提取物种名称、它们的位置、相关栖息地和生态系统，这些信息对于理解物种传播、预测未来入侵和指导保护工作至关重要。传统的文本挖掘方法通常难以应对生态术语的复杂性以及这些文本中发现的微妙语言模式。通过应用没有领域特定微调的通用 LLM，我们发现了使用这些模型进行生态实体提取的前景和局限性。通过这样做，这项研究为更先进的自动化知识提取工具奠定了基础，这些工具可以帮助研究人员和从业者理解和管理生物入侵。]]></description>
      <guid>https://arxiv.org/abs/2501.18287</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RbFT：针对检索缺陷的检索增强生成的稳健微调</title>
      <link>https://arxiv.org/abs/2501.18365</link>
      <description><![CDATA[arXiv:2501.18365v1 公告类型：新
摘要：检索增强生成 (RAG) 通过集成从知识库中检索到的外部知识来增强大型语言模型 (LLM)。然而，它的有效性从根本上受到检索器和知识库可靠性的限制。在现实世界中，这些组件的缺陷往往会导致检索到嘈杂、不相关或误导性的反事实信息，最终破坏 RAG 系统的可信度。为了应对这一挑战，我们提出了稳健微调 (RbFT)，这种方法旨在通过两个有针对性的微调任务增强 LLM 对检索缺陷的弹性。实验结果表明，RbFT 显著提高了 RAG 系统在不同检索条件下的稳健性，超越了现有方法，同时保持了高推理效率和与其他稳健性技术的兼容性。]]></description>
      <guid>https://arxiv.org/abs/2501.18365</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GENIE：用于构建 EHR 数据的生成注释信息提取模型</title>
      <link>https://arxiv.org/abs/2501.18435</link>
      <description><![CDATA[arXiv:2501.18435v1 公告类型：新
摘要：电子健康记录 (EHR) 在推动医疗保健方面具有巨大潜力，它提供丰富的纵向数据，将结构化信息与非结构化临床笔记中的宝贵见解相结合。然而，临床文本的非结构化性质对二次应用提出了重大挑战。传统的构建 EHR 自由文本数据的方法，例如基于规则的系统和多阶段管道，通常受到其耗时的配置和无法适应来自不同医疗环境的临床笔记的限制。很少有系统提供术语的全面属性提取。虽然像 GPT-4 和 LLaMA 405B 这样的大型语言模型 (LLM) 在结构化任务方面表现出色，但它们速度慢、成本高且不适合大规模使用。为了克服这些限制，我们引入了 GENIE，这是一个生成注释信息提取系统，它利用 LLM 将非结构化临床文本的结构简化为具有标准化格式的可用数据。 GENIE 一次性处理整个段落，以高精度提取实体、断言状态、位置、修饰符、值和目的。其统一的端到端方法简化了工作流程，减少了错误，并消除了大量人工干预的需要。使用强大的数据准备管道和经过微调的小规模 LLM，GENIE 在多个信息提取任务中实现了具有竞争力的性能，优于 cTAKES 和 MetaMap 等传统工具，并且可以处理要提取的额外属性。GENIE 大大增强了医疗保健系统的实际适用性和可扩展性。通过开源模型和测试数据，我们旨在鼓励协作并推动 EHR 结构化的进一步发展。]]></description>
      <guid>https://arxiv.org/abs/2501.18435</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CALM：释放语言模型问答的跨语言自对齐能力</title>
      <link>https://arxiv.org/abs/2501.18457</link>
      <description><![CDATA[arXiv:2501.18457v1 公告类型：新
摘要：大型语言模型 (LLM) 在广泛的多语言语料库上进行预训练，以获取特定于语言的文化知识和一般知识。理想情况下，虽然 LLM 应该对跨语言的文化无关问题提供一致的答案，但我们观察到显著的性能差异。为了解决这个问题，我们探索了语言模型 (CALM) 的跨语言自对齐能力，以跨语言对齐知识。具体来说，对于给定的问题，我们对不同语言的多个响应进行采样，并选择最自洽的响应作为目标，其余响应作为反面例子。然后，我们采用直接偏好优化 (DPO) 来对齐不同语言之间的模型知识。对 MEDQA 和 X-CSQA 数据集的评估证明了 CALM 在增强跨语言知识问答方面的有效性，无论是在零样本还是检索增强设置中。我们还发现，增加 CALM 训练中涉及的语言数量可以提高准确性和一致性。我们对跨语言一致性如何增强知识对齐进行了定性分析，并探索了该方法的通用性。本文的源代码和数据可在 GitHub 上找到。]]></description>
      <guid>https://arxiv.org/abs/2501.18457</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有重叠通信的流式 DiLoCo：迈向分布式免费午餐</title>
      <link>https://arxiv.org/abs/2501.18512</link>
      <description><![CDATA[arXiv:2501.18512v1 公告类型：新
摘要：大型语言模型 (LLM) 的训练通常分布在大量加速器上，以减少训练时间。由于内部状态和参数梯度需要在每个梯度步骤中交换，因此所有设备都需要使用低延迟高带宽通信链路共置，以支持所需的大量交换位。最近，像 DiLoCo 这样的分布式算法放宽了这种共置限制：加速器可以分组为“工作者”，其中工作者之间的同步很少发生。这反过来意味着工作者可以通过较低带宽的通信链路连接而不会影响学习质量。然而，在这些方法中，工作者之间的通信仍然需要与以前相同的峰值带宽，因为同步需要所有工作者之间交换所有参数。在本文中，我们从三个方面改进了 DiLoCo。首先，我们只按顺序同步参数子集，而不是一次同步所有参数，这大大降低了峰值带宽。其次，我们允许工作器在同步的同时继续训练，从而减少挂钟时间。第三，我们量化工作器交换的数据，从而进一步减少工作器之间的带宽。通过适当组合这些修改，我们通过实验证明，我们可以分布训练十亿级参数，并达到与以前类似的质量，但所需带宽减少了两个数量级。]]></description>
      <guid>https://arxiv.org/abs/2501.18512</guid>
      <pubDate>Fri, 31 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>