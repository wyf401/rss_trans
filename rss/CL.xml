<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 22 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>定量评论总结的提示性方面关键点分析</title>
      <link>https://arxiv.org/abs/2407.14049</link>
      <description><![CDATA[arXiv:2407.14049v1 公告类型：新
摘要：关键点分析 (KPA) 旨在进行定量总结，提供关键点 (KP) 作为简洁的文本摘要和衡量其流行程度的数量。文献中已经报道了针对论证和评论的 KPA 研究。大多数针对评论的 KPA 研究采用监督学习来提取短句作为 KP，然后将 KP 与评论评论进行匹配以量化 KP 流行程度。最近的抽象方法仍然基于句子生成 KP，这通常会导致 KP 具有重叠和幻觉意见，并且量化不准确。在本文中，我们提出了用于定量评论总结的提示方面关键点分析 (PAKPA)。 PAKPA 利用方面情感分析和大型语言模型 (LLM) 的上下文学习来为业务实体生成和量化基于方面的 KP，从而实现忠实的 KP 和准确的量化，并且无需大量带注释的数据进行监督训练。在流行评论数据集 Yelp 和面向方面的评论摘要数据集 SPACE 上的实验表明，我们的框架实现了最先进的性能。源代码和数据可在以下位置获取：https://github.com/antangrocket1312/PAKPA]]></description>
      <guid>https://arxiv.org/abs/2407.14049</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:22 GMT</pubDate>
    </item>
    <item>
      <title>BERTer：高效之选</title>
      <link>https://arxiv.org/abs/2407.14039</link>
      <description><![CDATA[arXiv:2407.14039v1 公告类型：新
摘要：我们探索先进的微调技术，以提高 BERT 在情绪分析、释义检测和语义文本相似性方面的表现。我们的方法利用 SMART 正则化来对抗过度拟合，改进超参数选择，采用交叉嵌入 Siamese 架构来改进句子嵌入，并引入创新的早期退出方法。我们的微调结果目前表明，在结合多个微调架构时，模型效率和有效性有显着提高，在测试集上实现了最先进的性能得分，超越了当前的基准，并突出了 BERT 在多方面语言任务中的适应性。]]></description>
      <guid>https://arxiv.org/abs/2407.14039</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:21 GMT</pubDate>
    </item>
    <item>
      <title>ECCO：我们能否在不牺牲功能正确性的情况下提高模型生成代码的效率？</title>
      <link>https://arxiv.org/abs/2407.14044</link>
      <description><![CDATA[arXiv:2407.14044v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 在生成功能正确的程序方面取得了很大成功，但调节模型以产生有效的解决方案同时确保正确性仍然是一个挑战。此外，对于流行的解释语言（如 Python），在不同的硬件规格下，对代码效率进行基准测试的不可靠性是一个障碍。在本文中，我们提出了 ECCO，这是一个可重复的基准，用于通过两种范式评估程序效率：基于自然语言 (NL) 的代码生成和基于历史的代码编辑。在 ECCO 上，我们调整并彻底研究了三种最有前途的现有基于 LLM 的方法：上下文学习、使用执行或 NL 反馈的迭代细化以及以执行和编辑历史为条件的微调。虽然大多数方法会降低功能正确性并适度提高程序效率，但我们发现添加执行信息通常有助于保持功能正确性，而 NL 反馈可以更多地提高效率。我们发布了基准以支持未来基于 LLM 生成高效代码的工作。]]></description>
      <guid>https://arxiv.org/abs/2407.14044</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:21 GMT</pubDate>
    </item>
    <item>
      <title>NeLLCom-X：用于模拟语言学习和群组交流的综合神经代理框架</title>
      <link>https://arxiv.org/abs/2407.13999</link>
      <description><![CDATA[arXiv:2407.13999v1 公告类型：新
摘要：计算语言学的最新进展包括使用交互神经网络代理模拟类人语言的出现，从随机符号集开始。最近推出的 NeLLCom 框架 (Lian et al., 2023) 允许代理首先学习一种人工语言，然后使用它进行交流，目的是研究特定语言学属性的出现。我们通过引入更现实的角色交替代理和群组通信来扩展这个框架 (NeLLCom-X)，以研究语言可学习性、沟通压力和群体规模效应之间的相互作用。我们通过复制先前研究的关键发现来验证 NeLLCom-X，模拟词序/案例标记权衡的出现。接下来，我们研究交互如何影响语言融合和权衡的出现。该新框架有利于未来对多种语言方面的模拟，强调了互动和群体动力在语言进化中的重要性。]]></description>
      <guid>https://arxiv.org/abs/2407.13999</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:20 GMT</pubDate>
    </item>
    <item>
      <title>HeCiX：集成知识图谱和大型语言模型用于生物医学研究</title>
      <link>https://arxiv.org/abs/2407.14030</link>
      <description><![CDATA[arXiv:2407.14030v1 公告类型：新
摘要：尽管药物开发策略取得了进步，但 90% 的临床试验都失败了。这表明在靶标验证和药物优化方面被忽视了。为了解决这个问题，我们引入了 HeCiX-KG，Hetionet-Clinicaltrials neXus 知识图谱，这是来自 ClinicalTrials.gov 和 Hetionet 的数据在单个知识图中的新融合。HeCiX-KG 结合了来自 ClinicalTrials.gov 的先前进行的临床试验的数据以及来自 Hetionet 的疾病和基因领域的专业知识。这为临床研究人员提供了全面的资源。此外，我们引入了 HeCiX，这是一个使用 LangChain 将 HeCiX-KG 与 GPT-4 集成并提高其可用性的系统。HeCiX 在针对一系列临床相关问题的评估中表现出色，证明该模型有望提高临床研究的有效性。因此，这种方法提供了对临床试验和现有生物数据的更全面的了解。]]></description>
      <guid>https://arxiv.org/abs/2407.14030</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:20 GMT</pubDate>
    </item>
    <item>
      <title>重新审视自动语音识别性能中的种族差异：来源混淆的作用</title>
      <link>https://arxiv.org/abs/2407.13982</link>
      <description><![CDATA[arXiv:2407.13982v1 公告类型：新
摘要：在大量音频数据上训练的自动语音识别 (ASR) 模型现在被广泛用于将语音转换为书面文本，应用范围广泛，从视频字幕到医疗保健和其他领域使用的自动助手。因此，ASR 模型及其使用公平公正非常重要。之前研究了商业 ASR 系统在区域非洲裔美国人语言语料库 (CORAAL) 上的性能，结果表明，ASR 在非洲裔美国人英语 (AAE) 上的性能明显较差。本研究旨在通过检查当前最先进的基于神经网络的 ASR 系统 (Whisper、OpenAI) 在 CORAAL 数据集上的性能来了解造成这种差异的因素。本研究确定了两个关键发现。第一个发现证实了之前的发现，即即使在邻近社区之间也存在显著的方言差异，并且 AAE 上的 ASR 性能较差，可以通过对 ASR 模型进行微调来在一定程度上改善。第二个是 CORAAL 先前研究中未讨论过的新发现：数据集内音频录制实践的差异对 ASR 准确性有显著影响，导致“来源混淆”效应，其中语言使用和录制质量因研究地点而异。这些发现强调，在检查神经 ASR 模型中存在的公平性和偏见时，需要进一步进行系统研究以理清录音质量和固有语言多样性的影响，因为 ASR 准确性的任何偏见都可能对使用 ASR 技术的各个生活领域的差异产生负面的下游影响。]]></description>
      <guid>https://arxiv.org/abs/2407.13982</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:19 GMT</pubDate>
    </item>
    <item>
      <title>RAG-QA Arena：评估长格式检索增强问答的领域稳健性</title>
      <link>https://arxiv.org/abs/2407.13998</link>
      <description><![CDATA[arXiv:2407.13998v1 公告类型：新
摘要：基于检索增强生成 (RAG-QA) 的问答是 NLP 中的一个重要研究课题，具有广泛的实际应用。然而，目前用于此任务的大多数数据集要么使用单一源语料库构建，要么由简短的提取答案组成，这不足以评估基于大型语言模型 (LLM) 的 RAG-QA 系统的跨域泛化能力。为了解决这些限制，我们创建了 Long-form RobustQA (LFRQA)，这是一个新的数据集，包含人工编写的长格式答案，将来自多个文档的简短提取答案整合成一个连贯的叙述，涵盖七个不同领域的 26K 个查询和大型语料库。我们进一步提出了 RAG-QA Arena，通过使用 LLM 作为评估器直接比较模型生成的答案与 LFRQA 的答案。我们通过大量实验表明，RAG-QA Arena 与人类对答案质量的判断高度相关。此外，只有 41.3% 最具竞争力的 LLM 答案优于 LFRQA 的答案，这表明 RAG-QA Arena 是未来研究具有挑战性的评估平台。]]></description>
      <guid>https://arxiv.org/abs/2407.13998</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:19 GMT</pubDate>
    </item>
    <item>
      <title>狼人竞技场：通过社会推理进行法学硕士评估的案例研究</title>
      <link>https://arxiv.org/abs/2407.13943</link>
      <description><![CDATA[arXiv:2407.13943v1 公告类型：新
摘要：本文介绍了狼人竞技场，这是一种通过经典社交推理游戏狼人的视角来评估大型语言模型 (LLM) 的新框架。在狼人竞技场中，LLM 相互竞争，驾驭游戏中复杂的欺骗、推理和说服动态。该框架引入了一种基于竞标的动态轮流系统，反映了现实世界中的讨论，个人可以策略性地选择何时发言。我们通过以 Gemini 和 GPT 模型为特色的竞技场式锦标赛展示了该框架的实用性。我们的结果揭示了模型在战略推理和沟通方面的明显优势和劣势。这些发现凸显了狼人竞技场作为具有挑战性和可扩展性的 LLM 基准的潜力。]]></description>
      <guid>https://arxiv.org/abs/2407.13943</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>奇妙的序列及其所在位置：通过状态跟踪约束解码和重新排序实现忠实高效的 API 调用生成</title>
      <link>https://arxiv.org/abs/2407.13945</link>
      <description><![CDATA[arXiv:2407.13945v1 公告类型：新
摘要：API 调用生成是大型语言模型工具使用能力的基石，可提供对更广阔世界的访问。然而，现有的监督和上下文学习方法存在训练成本高、数据效率差以及生成的 API 调用可能不符合 API 文档和用户请求的问题。为了解决这些限制，我们提出了一种称为 FANTASE 的输出端优化方法。FANTASE 的两个独特贡献是其状态跟踪约束解码 (SCD) 和重新排名组件。SCD 以 Token Search Trie 的形式动态地合并适当的 API 约束，以实现高效且保证的生成忠实于 API 文档。重新排名组件通过利用轻量级模型作为鉴别器对大型语言模型的波束搜索候选生成进行重新排名，从而有效地引入监督信号。我们通过 DSTC8 和 API Bank 数据集展示了 FANTASE 在 API 调用生成准确性、推理效率和上下文效率方面的卓越性能。]]></description>
      <guid>https://arxiv.org/abs/2407.13945</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:18 GMT</pubDate>
    </item>
    <item>
      <title>揭示情绪推理模型中的政治偏见：对社会科学研究中情绪分析的启示</title>
      <link>https://arxiv.org/abs/2407.13891</link>
      <description><![CDATA[arXiv:2407.13891v1 公告类型：新
摘要：本文探讨了社会科学研究中用于情绪分析 (SA) 的情感推理模型中是否存在政治偏见。机器学习模型通常会反映其训练数据中的偏见，从而影响其结果的有效性。虽然之前的研究强调了性别和种族偏见，但我们的研究重点是政治偏见——这是一个尚未充分探索但普遍存在的问题，可能会扭曲广泛研究中对文本数据的解释。我们对实验室开发的波兰情绪分析模型进行了偏见审计。通过分析涉及波兰政客的姓名和句子的价态预测，我们发现了受政治派别影响的系统性差异。我们的研究结果表明，人类评分者的注释会将政治偏见传播到模型的预测中。为了缓解这种情况，我们修剪了提到这些政客的文本的训练数据集，并观察到偏见有所减少，但并未完全消除。鉴于政治偏见在 SA 中具有重大影响，我们的研究强调在将这些模型用于社会科学研究时要谨慎。我们建议对 SA 结果进行严格审查，并建议使用基于词典的系统作为意识形态上更中立的替代方案。本文强调了持续审查和方法调整的必要性，以确保在学术和应用环境中使用机器学习的可靠性和公正性。]]></description>
      <guid>https://arxiv.org/abs/2407.13891</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>为大型语言模型制定有效的微调策略</title>
      <link>https://arxiv.org/abs/2407.13906</link>
      <description><![CDATA[arXiv:2407.13906v1 公告类型：新
摘要：本文通过探索数据效率和超参数优化来解决有效微调大型语言模型 (LLM) 的挑战。我们研究了有效微调所需的最少数据，并提出了一种利用早期模型性能的新型超参数优化方法。我们的实验表明，在产品属性提取任务中，仅使用 200 个样本进行微调就可以将模型准确率从 70% 提高到 88%。我们确定了大约 6,500 个样本的饱和点，超过此饱和点，额外的数据会产生递减的收益。我们提出的贝叶斯超参数优化方法以总训练时间的 20% 来评估模型，与最终模型性能密切相关，5 个顶级早期模型中有 4 个在完成时仍保持在前 5 名。在独立测试集上进行评估时，这种方法的准确率比基线模型提高了 2%。这些发现为从业者提供了可行的见解，有可能减少计算负荷和对大量数据集的依赖，同时提高微调 LLM 的整体性能。]]></description>
      <guid>https://arxiv.org/abs/2407.13906</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>BiasDPO：通过直接偏好优化减轻语言模型中的偏见</title>
      <link>https://arxiv.org/abs/2407.13928</link>
      <description><![CDATA[arXiv:2407.13928v1 公告类型：新
摘要：大型语言模型 (LLM) 已成为推动自然语言处理的关键，但它们延续偏见的可能性引起了重大担忧。本文介绍了一种采用直接偏好优化 (DPO) 的新框架，以减轻 LLM 生成的英文文本中的性别、种族和宗教偏见。通过开发一种有利于较少偏见而不是有偏见的完成的损失函数，我们的方法培养了 LLM 中对尊重和非歧视性语言的偏好。我们还提供了一个手动设计的数据集，用于训练 LLM 识别和纠正偏见。该数据集包含与有偏见和无偏见完成配对的各种提示。在 Microsoft Phi-2 模型上实施这种方法，我们展示了有偏见输出的显着减少，因为我们的模型在几乎所有偏见基准上都优于基线模型。与其他开源模型相比，我们的模型在大多数基准上也实现了更好的性能。通过减少模型生成的语言中的偏见，我们的研究标志着朝着开发更符合道德和社会责任的法学硕士迈出了重要一步。我们在 HuggingFace 上公开发布了 BiasDPO 数据集。]]></description>
      <guid>https://arxiv.org/abs/2407.13928</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:17 GMT</pubDate>
    </item>
    <item>
      <title>Phi-3 安全后训练：将语言模型与“中断-修复”循环相结合</title>
      <link>https://arxiv.org/abs/2407.13833</link>
      <description><![CDATA[arXiv:2407.13833v1 公告类型：新
摘要：语言模型训练的最新创新表明，可以创建足够小以在智能手机上运行的高性能模型。随着这些模型部署在越来越多的领域，确保它们符合人类偏好和安全考虑至关重要。在本报告中，我们介绍了安全对齐 Phi-3 系列语言模型的方法。我们利用了“故障修复”循环，执行多轮数据集管理、安全后训练、基准测试、红队和漏洞识别，以覆盖单轮和多轮场景中的各种危害区域。我们的结果表明，这种方法在广泛的负责任 AI 基准测试中迭代地提高了 Phi-3 模型的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.13833</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>学习语言奖励模型的目标条件表征</title>
      <link>https://arxiv.org/abs/2407.13887</link>
      <description><![CDATA[arXiv:2407.13887v1 公告类型：新
摘要：通过离线数据或自我监督目标学习改进的表示的技术在传统强化学习 (RL) 中显示出令人印象深刻的结果。然而，尚不清楚改进的表示学习如何使语言模型 (LM) 上的人类反馈 (RLHF) 的强化学习受益。在这项工作中，我们提出以对比的 $\textit{goal-conditioned}$ 方式训练奖励模型 (RM)，通过增加沿采样的首选轨迹的未来状态的表示相似性并降低沿随机采样的非首选轨迹的相似性。此目标在 MATH 和 GSM8k 等具有挑战性的基准上显着提高了 RM 性能高达 0.09 AUROC。这些发现也扩展到一般对齐 - 在 Helpful-Harmless 数据集上，我们观察到准确度提高了 $2.3\%$。除了提高奖励模型性能之外，我们还表明，这种训练 RM 表示的方式可以提高可操纵性，因为它使我们能够评估某个动作实现特定目标状态的可能性（例如，某个解决方案是否正确或有用）。利用这一见解，我们发现，通过丢弃可能最终处于“不正确”状态的轨迹，我们可以在多数投票期间过滤高达 $55\%$ 的生成标记，从而节省大量成本。我们还发现，这些表示可以通过调节所需的未来目标状态来执行细粒度控制。例如，我们表明，使用我们的方法将 Llama 3 模型转向有用的代数，与监督微调训练基线相比，有用性提高了 $9.6\%$。同样，将模型转向复杂的代数，与基线相比，复杂性提高了 $21.6\%$。总体而言，我们发现以这种对比的、目标调节的方式训练 RM 可以显著提高性能并实现模型可操纵性。]]></description>
      <guid>https://arxiv.org/abs/2407.13887</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:16 GMT</pubDate>
    </item>
    <item>
      <title>RDBE：基于推理提炼的评估增强了自动论文评分</title>
      <link>https://arxiv.org/abs/2407.13781</link>
      <description><![CDATA[arXiv:2407.13781v1 公告类型：新
摘要：最近，各种仅编码器和编码器解码器预训练模型（如 BERT 和 T5）已作为小型语言模型应用于自动论文评分 (AES)。然而，现有的研究主要将此任务视为类似于分类问题，仅关注在目标文本中输出分数，而不提供对生成分数的解释。与这些方法不同，我们引入了基于推理蒸馏的评估 (RDBE)，它集成了可解释性以阐明模型分数背后的原理，同时通过初始推理提高性能。这种解释能力是在训练过程中通过利用大型语言模型 (LLM) 生成的推理来提炼小型语言模型 (SLM) 获得的。我们的实验结果证明了 RDBE 在数据集中考虑的所有评分标准中的有效性。RDBE 的表现优于零样本 LLM 生成和基线微调模型的生成，在相应的数据集中确立了其最新水平。这凸显了其实用的解释输出和增强的性能。]]></description>
      <guid>https://arxiv.org/abs/2407.13781</guid>
      <pubDate>Mon, 22 Jul 2024 06:20:15 GMT</pubDate>
    </item>
    </channel>
</rss>