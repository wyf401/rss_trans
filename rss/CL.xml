<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 03 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>南亚语言文本处理、语音处理和多模态研究的广度优先目录</title>
      <link>https://arxiv.org/abs/2501.00029</link>
      <description><![CDATA[arXiv:2501.00029v1 公告类型：新 
摘要：我们回顾了南亚语言中关于基于文本的语言处理、多模态模型和语音处理的最新文献（2022 年 1 月 - 2024 年 10 月），并重点分析了 21 种资源匮乏的南亚语言，即西莱基语、阿萨姆语、俾路支语、博杰普尔语、博多语、缅甸语、恰蒂斯加尔语、迪维希语、古吉拉特语、卡纳达语、克什米尔语、孔卡尼语、卡西语、马拉雅拉姆语、梅泰语、尼泊尔语、奥里亚语、普什图语、拉贾斯坦语、信德语和泰卢固语。我们使用基于大型语言模型 (LLM) 的相关性分类和聚类的分步方法来确定趋势、挑战和未来的研究方向。我们的目标是向有兴趣研究南亚语言的 NLP 研究人员提供南亚语言技术最新发展的广度优先概述。]]></description>
      <guid>https://arxiv.org/abs/2501.00029</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>中国英语学习者在理解英语句子时未充分利用句法加工，基于改编的花园路径歧义实验的证据</title>
      <link>https://arxiv.org/abs/2501.00030</link>
      <description><![CDATA[arXiv:2501.00030v1 Announce Type: new 
摘要：许多研究表明，句子理解更多地依赖于语义加工而非句法加工。然而，先前的研究主要强调对语义加工的偏好，侧重于语义视角。相比之下，本研究从句法角度强调句法加工的利用不足。本研究的实证实验基于传统的花园小径实验（涉及局部歧义但整体明确的句子），创新地制作了一个改编版本，以语义歧义但句法明确的句子为实验对象，以满足其特定的研究目的。本实验涉及140名受试者，通过使用SPSS、Graph Pad Prism和Cursor的描述性和推理性统计分析表明，中国英语学习者在理解英语句子时倾向于未充分利用句法加工。研究确定了两种类型的解析未充分利用：部分和完全。进一步探究发现，句法加工中的试错过程对句子理解和句法加工均有贡献，因此本研究为开发一种新的解析方法奠定了基础，旨在将句法加工充分融入句子理解中，从而提高中国英语学习者的英语句子理解水平。]]></description>
      <guid>https://arxiv.org/abs/2501.00030</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提炼大型语言模型以实现高效的临床信息提取</title>
      <link>https://arxiv.org/abs/2501.00031</link>
      <description><![CDATA[arXiv:2501.00031v1 公告类型：新
摘要：大型语言模型 (LLM) 擅长临床信息提取，但其计算需求限制了实际部署。知识蒸馏——将知识从较大模型转移到较小模型的过程——提供了一种潜在的解决方案。我们评估了蒸馏后的 BERT 模型在临床命名实体识别 (NER) 任务中的性能，这些模型比现代 LLM 小约 1,000 倍。我们利用最先进的 LLM（Gemini 和 OpenAI 模型）和医学本体（RxNorm 和 SNOMED）作为药物、疾病和症状提取的教师标签器。我们将我们的方法应用于五个公开可用的数据集中的 3,300 多份临床笔记，将蒸馏后的 BERT 模型与其教师标签器和在人工标签上微调的 BERT 模型进行比较。使用来自 MedAlign 数据集的临床笔记进行了外部验证。对于疾病提取，F1 得分分别为 0.82（教师模型）、0.89（在人类标签上训练的 BioBERT）和 0.84（BioBERT-distilled）。对于药物，F1 得分分别为 0.84（教师模型）、0.91（BioBERT-human）和 0.87（BioBERT-distilled）。对于症状：F1 得分为 0.73（教师模型）和 0.68（BioBERT-distilled）。蒸馏后的 BERT 模型具有更快的推理速度（分别比 GPT-4o、o1-mini 和 Gemini Flash 快 12 倍、4 倍、8 倍），成本更低（分别比 GPT-4o、o1-mini 和 Gemini Flash 便宜 85 倍、101 倍、2 倍）。在外部验证数据集上，蒸馏后的 BERT 模型的 F1 得分为 0.883（药物）、0.726（疾病）和 0.699（症状）。蒸馏后的 BERT 模型比最先进的 LLM 便宜 101 倍，速度快 12 倍，同时在 NER 任务上实现类似的性能。蒸馏为临床信息提取提供了一种计算效率高且可扩展的大型 LLM 替代方案。]]></description>
      <guid>https://arxiv.org/abs/2501.00031</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器翻译迁移学习的跨语言检验</title>
      <link>https://arxiv.org/abs/2501.00045</link>
      <description><![CDATA[arXiv:2501.00045v1 公告类型：新
摘要：本研究通过评估五种不同的语言对，研究了迁移学习在不同语言家族中机器翻译的有效性。利用在高资源语言上预先训练的模型，这些模型在低资源语言上进行了微调，检查了学习率、批量大小、时期数和权重衰减等超参数的变化。该研究涵盖了来自不同语言背景的语言对：闪米特语（现代标准阿拉伯语 - 黎凡特阿拉伯语）、班图语（豪萨语 - 祖鲁语）、罗曼语（西班牙语 - 加泰罗尼亚语）、斯拉夫语（斯洛伐克语 - 马其顿语）和语言孤立语（东亚美尼亚语 - 西亚美尼亚语）。结果表明，迁移学习在不同语言家族中都是有效的，尽管超参数的影响各不相同。中等批量大小（例如 32）通常更有效，而非常高的学习率可能会破坏模型训练。该研究强调了迁移学习在多语言环境中的普遍性，并表明一致的超参数设置可以简化和提高多语言模型训练的效率。]]></description>
      <guid>https://arxiv.org/abs/2501.00045</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 Seq2Seq 模型的聊天机器人，具有 LSTM 和注意力机制，可增强用户交互</title>
      <link>https://arxiv.org/abs/2501.00049</link>
      <description><![CDATA[arXiv:2501.00049v1 公告类型：新
摘要：聊天机器人是一种智能软件应用程序，可通过消息传递平台自动进行对话并以自然语言吸引用户。利用人工智能 (AI)，聊天机器人可以发挥各种功能，包括客户服务、信息收集和随意交谈。现有的虚拟助手聊天机器人，如 ChatGPT 和 Gemini，展示了人工智能在自然语言处理 (NLP) 中的潜力。然而，许多当前解决方案依赖于预定义的 API，这可能导致供应商锁定和高成本。为了应对这些挑战，这项工作提出了一种使用序列到序列 (Seq2Seq) 模型开发的聊天机器人，该模型具有编码器-解码器架构，该架构结合了注意力机制和长短期记忆 (LSTM) 单元。通过避免使用预定义的 API，这种方法可确保灵活性和成本效益。聊天机器人在专门为摩洛哥 Draa-Tafilalet 旅游业策划的数据集上进行训练、验证和测试。主要评估结果表明，所提出的基于 Seq2Seq 模型的聊天机器人实现了高准确率：训练准确率约为 99.58%，验证准确率约为 98.03%，测试准确率约为 94.12%。这些结果证明了聊天机器人在旅游领域提供相关且连贯的响应方面的有效性，凸显了专业 AI 应用程序在提升小众市场用户体验和满意度方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.00049</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于数学分析的大型语言模型</title>
      <link>https://arxiv.org/abs/2501.00059</link>
      <description><![CDATA[arXiv:2501.00059v1 公告类型：新
摘要：数学问题解决是人工智能 (AI) 的一个关键领域，也是评估大型语言模型 (LLM) 能力的关键基准。虽然大量研究集中在数学问题解决上，但大多数现有工作和数据集都集中在计算任务上，在数学分析等领域留下了空白，数学分析需要严格的证明和形式推理。我们开发了 DEMI-MathAnalysis 数据集，其中包括来自数学分析主题（例如序列和极限、无穷级数和凸函数）的基于证明的问题。我们还设计了一个指导框架，以严格提高 LLM 解决这些问题的能力。通过在这个数据集上微调 LLM 并使用我们的框架，我们观察到它们生成逻辑、完整和优雅证明的能力有了显着提高。这项工作解决了数学推理中的关键差距，并有助于推进能够处理形式化数学语言的可信 AI。该代码可在 LLM for Mathematical Analysis 上公开访问。]]></description>
      <guid>https://arxiv.org/abs/2501.00059</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ELECTRA 和 GPT-4o：情绪分析的经济高效合作伙伴</title>
      <link>https://arxiv.org/abs/2501.00062</link>
      <description><![CDATA[arXiv:2501.00062v1 公告类型：新
摘要：双向转换器擅长情绪分析，大型语言模型 (LLM) 是有效的零样本学习器。他们作为一个团队会表现得更好吗？本文探讨了 ELECTRA 和 GPT-4o 在三向情绪分类方面的协作方法。我们使用来自斯坦福情绪树库 (SST) 和 DynaSent 的混合评论对四个模型 (ELECTRA Base/Large、GPT-4o/4o-mini) 进行了微调 (FT)。我们将 ELECTRA 的输入提供给 GPT：预测标签、概率和检索到的示例。与单独使用任一模型相比，将 ELECTRA Base FT 预测与 GPT-4o-mini 共享可显著提高性能（82.74 宏 F1 vs. 79.29 ELECTRA Base FT、79.52 GPT-4o-mini），并实现最低成本/性能比（\$0.12/F1 点）。但是，当对 GPT 模型进行微调时，包括预测会降低性能。GPT-4o FT-M 表现最佳（86.99），GPT-4o-mini FT 紧随其后（86.77），但成本低得多（\$0.38 vs. \$1.59/F1 点）。我们的结果表明，使用经过微调的编码器的预测来增强提示是提高性能的有效方法，经过微调的 GPT-4o-mini 几乎与 GPT-4o FT 一样好，但成本降低了 76%。对于资源有限的项目来说，两者都是经济实惠的选择。]]></description>
      <guid>https://arxiv.org/abs/2501.00062</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迁移学习中语言模型的对抗鲁棒性</title>
      <link>https://arxiv.org/abs/2501.00066</link>
      <description><![CDATA[arXiv:2501.00066v1 公告类型：新 
摘要：我们研究了 LLM 在迁移学习场景中的对抗鲁棒性。通过对多个数据集（MBIB 仇恨言论、MBIB 政治偏见、MBIB 性别偏见）和各种模型架构（BERT、RoBERTa、GPT-2、Gemma、Phi）进行全面实验，我们发现迁移学习虽然可以提高标准性能指标，但往往会导致对抗攻击的脆弱性增加。我们的研究结果表明，较大的模型对这种现象表现出更大的弹性，这表明模型大小、架构和适应方法之间存在复杂的相互作用。我们的工作强调了在迁移学习场景中考虑对抗鲁棒性的迫切需要，并提供了在不影响性能的情况下保持模型安全性的见解。这些发现对于在性能和鲁棒性都至关重要的实际应用中开发和部署 LLM 具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2501.00066</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>生成语言模型中的对抗性谈判动态</title>
      <link>https://arxiv.org/abs/2501.00069</link>
      <description><![CDATA[arXiv:2501.00069v1 公告类型：新
摘要：生成语言模型越来越多地用于合同起草和增强，从而产生了竞争方部署不同语言模型的场景。这不仅带来了博弈论挑战，还带来了与人工智能安全和保障相关的重大担忧，因为对方使用的语言模型可能是未知的。这些竞争互动可以看作是对抗性试验场，模型被有效地红队化以暴露漏洞，例如生成有偏见、有害或法律上有问题的文本。尽管这些挑战非常重要，但这些模型在对抗环境中的竞争稳健性和安全性仍然知之甚少。在这项小型研究中，我们通过评估主要开源语言模型在面对面竞争中的表现和漏洞来解决这个问题，模拟现实世界的合同谈判。我们进一步探讨了这些对抗性互动如何揭示潜在风险，为开发更安全、更可靠的模型提供信息。我们的研究结果为日益增长的人工智能安全研究做出了贡献，为竞争性法律背景下的模型选择和优化提供了见解，并提供了降低风险的可行策略。]]></description>
      <guid>https://arxiv.org/abs/2501.00069</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ICLR：表征的上下文学习</title>
      <link>https://arxiv.org/abs/2501.00070</link>
      <description><![CDATA[arXiv:2501.00070v1 公告类型：新
摘要：最近的研究表明，预训练数据指定的语义会影响大型语言模型 (LLM) 中不同概念的表示的组织方式。然而，考虑到 LLM 的开放性，例如它们在上下文中学习的能力，我们可以问模型是否会改变这些预训练语义以采用替代的、上下文指定的语义。具体来说，如果我们提供上下文示例，其中一个概念扮演的角色与预训练数据所暗示的角色不同，模型是否会根据这些新颖的语义重新组织它们的表示？为了回答这个问题，我们从概念角色语义理论中获得灵感，并定义了一个玩具“图形跟踪”任务，其中图形的节点通过训练期间看到的概念来引用（例如，苹果、鸟等），并且图形的连接性通过一些预定义的结构（例如，方形网格）来定义。给定表示图上随机游走痕迹的样本，我们分析了模型的中间表示，发现随着上下文数量的缩放，预训练的语义表示会突然重新组织为与图结构一致的上下文表示。此外，我们发现，当参考概念的语义具有相关性（例如星期一、星期二等）时，上下文指定的图结构仍然存在于表示中，但无法主导预训练的结构。为了解释这些结果，我们将我们的任务类比为预定义图拓扑的能量最小化，为推断上下文指定语义的隐式优化过程提供了证据。总体而言，我们的研究结果表明，缩放上下文大小可以灵活地重新组织模型表示，可能释放新功能。]]></description>
      <guid>https://arxiv.org/abs/2501.00070</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>无需位置编码，因果变换器中的位置信息便可通过邻近嵌入的相似性获得</title>
      <link>https://arxiv.org/abs/2501.00073</link>
      <description><![CDATA[arXiv:2501.00073v1 公告类型：新
摘要：具有因果注意的 Transformer 可以解决需要位置信息的任务，而无需使用位置编码。在这项工作中，我们提出并研究了一个关于如何在不使用显式位置编码的情况下存储位置信息的新假设。我们观察到，附近的嵌入比远处的嵌入更相似，这使得 Transformer 可以潜在地重建标记的位置。我们表明，这种模式可以出现在训练过的和随机初始化的 Transformer 模型中，这些模型具有因果注意，并且在常见的超参数范围内没有位置编码。]]></description>
      <guid>https://arxiv.org/abs/2501.00073</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CaseSumm：美国最高法院判决的大型长篇背景摘要数据集</title>
      <link>https://arxiv.org/abs/2501.00097</link>
      <description><![CDATA[arXiv:2501.00097v1 公告类型：新
摘要：本文介绍了 CaseSumm，这是一种用于法律领域长上下文摘要的新型数据集，它解决了摘要评估对更长、更复杂的数据集的需求。我们收集了 25.6K 美国最高法院 (SCOTUS) 意见及其官方摘要，称为“大纲”。我们的数据集是最大的开放法律案例摘要数据集，也是第一个包含可追溯到 1815 年的 SCOTUS 判决摘要的数据集。
我们还使用自动指标和专家人工评估对 LLM 生成的摘要进行了全面评估，揭示了这些评估方法之间的差异。我们的评估显示，较小的开源模型 Mistral 7b 在大多数自动指标上都优于较大的模型，并成功生成了类似大纲的摘要。相比之下，人类专家注释者表示 Mistral 摘要包含幻觉。注释者一致认为 GPT-4 摘要更清晰，并且具有更高的敏感性和特异性。此外，我们发现基于 LLM 的评估与人工评估的相关性并不比传统的自动指标更高。此外，我们的分析还确定了生成的摘要中的特定幻觉，包括先例引用错误和对案件事实的歪曲陈述。这些发现证明了当前法律摘要自动评估方法的局限性，并强调了人工评估在评估摘要质量方面的关键作用，特别是在复杂、高风险领域。
CaseSumm 可在 https://huggingface.co/datasets/ChicagoHAI/CaseSumm 上找到]]></description>
      <guid>https://arxiv.org/abs/2501.00097</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>以数据为中心的方法检测和减轻儿童心理健康文本中的人口统计学偏见：焦虑检测案例研究</title>
      <link>https://arxiv.org/abs/2501.00129</link>
      <description><![CDATA[arXiv:2501.00129v1 公告类型：新
摘要：简介：医疗保健 AI 模型通常会从其训练数据中继承偏见。虽然努力主要针对结构化数据中的偏见，但心理健康在很大程度上取决于非结构化数据。本研究旨在检测和减轻与旨在协助儿科心理健康筛查的 AI 模型的训练数据中的非生物学差异相关的语言差异。我们的目标是：（1）通过评估不同性别亚组的结果均等性来评估偏见的存在，（2）通过文本分布分析识别偏见来源，以及（3）开发一种针对心理健康文本数据的去偏见方法。方法：我们检查了不同人口群体的分类均等性，并评估了性别语言如何影响模型预测。应用了一种以数据为中心的去偏见方法，重点是消除有偏见的术语，同时保留显着的临床信息。该方法在儿科患者自动焦虑检测模型上进行了测试。结果：我们的研究结果显示，女性青少年患者存在系统性漏诊，与男性患者相比，其准确率低 4%，假阴性率 (FNR) 高 9%，这可能是由于患者笔记中的信息密度和语言差异造成的。男性患者的笔记平均长 500 个字，语言相似性指标表明不同性别的词汇分布不同。实施我们的去偏方法可将诊断偏差降低多达 27%，证明了其在提高人口群体公平性方面的有效性。讨论：我们开发了一个以数据为中心的去偏框架来解决临床文本中基于性别的内容差异。通过消除偏见语言并加强对临床基本信息的关注，我们的方法展示了一种有效的策略，可以减轻在文本上训练的 AI 医疗模型中的偏见。]]></description>
      <guid>https://arxiv.org/abs/2501.00129</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>社交媒体中时间线摘要的时间推理</title>
      <link>https://arxiv.org/abs/2501.00152</link>
      <description><![CDATA[arXiv:2501.00152v1 公告类型：新
摘要：本文探讨了增强大型语言模型 (LLM) 中的时间推理能力是否可以提高时间线摘要的质量，时间线摘要是总结包含事件序列（尤其是社交媒体线程）的长文本的任务。我们引入了 \textit{NarrativeReason}，这是一个新的数据集，专注于叙述中连续事件之间的时间关系，将其与主要解决成对事件关系的现有时间推理数据集区分开来。然后，我们的方法通过知识提炼框架将时间推理与时间线摘要相结合，我们首先在时间推理任务上微调教师模型，然后将这些知识提炼到学生模型中，同时对其进行时间线摘要任务的训练。实验结果表明，我们的模型在心理健康相关的时间线摘要任务上取得了优异的表现，这些任务涉及长社交媒体线程，事件重复且情绪混合，凸显了利用时间推理改进时间线摘要的重要性。]]></description>
      <guid>https://arxiv.org/abs/2501.00152</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>测量大型语言模型对新闻报道进行注释的能力</title>
      <link>https://arxiv.org/abs/2501.00164</link>
      <description><![CDATA[arXiv:2501.00164v1 公告类型：新 
摘要：自 2022 年底推出 ChatGPT 以来，大型语言模型及其评估的能力一直在学术研究和行业中不断讨论和评估。在法律、医学和数学等多个领域已经开发了场景和基准（Bommasani 等人，2023 年），并且模型变体正在不断评估。一个尚未得到足够场景开发关注的领域是新闻业，特别是新闻采购和道德。新闻业是民主中至关重要的真相确定功能（Vincent，2023 年），采购是所有原创新闻产出的重要支柱。评估 LLM 为不同来源信号注释故事的能力以及记者如何证明它们是一个需要基准方法的关键场景。它提供了建立自动化系统的潜力，以将更透明和更道德的新闻形式与日常新闻进行对比。在本文中，我们提出了一个场景来评估 LLM 在新闻报道中识别和注释来源方面的表现，该场景基于受新闻研究启发的五类模式（Gans，2004）。我们提供用例、数据集和指标，作为系统基准测试的第一步。我们的准确性结果表明，基于 LLM 的方法在识别故事中的所有来源陈述方面以及在匹配来源类型方面有更大的作用。更艰巨的任务是发现来源依据。]]></description>
      <guid>https://arxiv.org/abs/2501.00164</guid>
      <pubDate>Fri, 03 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>