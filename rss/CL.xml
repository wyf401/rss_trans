<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 10 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>文本并非唯一需要：多模式提示可帮助法学硕士理解幽默</title>
      <link>https://arxiv.org/abs/2412.05315</link>
      <description><![CDATA[arXiv:2412.05315v1 公告类型：新
摘要：虽然大型语言模型 (LLM) 在各种基于文本的任务中都表现出了令人印象深刻的自然语言理解能力，但理解幽默仍然是一个持续的挑战。幽默通常是多模态的，依靠语音歧义、节奏和时间来传达意义。在本研究中，我们探索了一种简单的多模态提示方法来理解和解释幽默。我们展示了一个 LLM，其中包含笑话的文本和口头形式，使用现成的文本转语音 (TTS) 系统生成。与所有测试数据集中的文本提示相比，使用多模态提示可以改善对幽默的解释。]]></description>
      <guid>https://arxiv.org/abs/2412.05315</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于多方对话生成的多方监督语言模型微调</title>
      <link>https://arxiv.org/abs/2412.05342</link>
      <description><![CDATA[arXiv:2412.05342v1 公告类型：新
摘要：大型语言模型（LLM）通常经过微调以参与二元或两方对话，不能很好地适应多方对话（MPD），这阻碍了它们在多人会议、讨论和日常交流等场景中的应用。以前的基于LLM的研究主要集中在多代理框架上，而它们的基础LLM仍然是成对微调的。在本文中，我们在多方对话数据集上为LLM设计了一个多方微调框架（MuPaS），并证明了这种简单的框架可以让LLM高效地与多方对话风格保持一致。我们还设计了两种可以将MuPaS转换为MPD模拟器的训练策略。大量实验表明，MuPaS 可以实现最先进的多方响应，更高的下一位说话人预测准确率，更高的人工和自动评估话语质量，甚至可以合理地生成分布外的场景、主题和角色描述。MuPaS 框架将 LLM 训练与更复杂的多方应用（如对话生成、虚拟排练或元宇宙）连接起来。]]></description>
      <guid>https://arxiv.org/abs/2412.05342</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>自回归 Transformer 语言模型中的增量句子处理机制</title>
      <link>https://arxiv.org/abs/2412.05353</link>
      <description><![CDATA[arXiv:2412.05353v1 公告类型：新 
摘要：自回归变换语言模型 (LM) 具有强大的句法能力，通常可以成功处理从协议到 NPI 许可的现象。但是，它们用于逐步处理语言输入的功能尚不清楚。在本文中，我们通过研究 LM 中花园小径句子处理的潜在机制来填补这一空白。我们问：(1) LM 是使用句法特征还是浅层启发式方法来执行增量句子处理？(2) LM 只代表一种潜在解释，还是多种？(3) LM 是否会重新分析或修复其最初的错误表示？为了解决这些问题，我们使用稀疏自动编码器来识别可解释的特征，这些特征决定了 LM 更喜欢花园小径句子的哪种延续（以及哪种解读）。我们发现，虽然许多重要特征与句法结构有关，但有些反映了句法上不相关的启发式方法。此外，虽然大多数活跃特征对应于句子的一种解读，但有些特征对应于另一种解读，这表明 LM 同时为两种可能性分配权重。最后，LM 不会重复使用花园小径句子处理中的特征来回答后续问题。]]></description>
      <guid>https://arxiv.org/abs/2412.05353</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CALICO：通过合成数据生成实现对话代理定位</title>
      <link>https://arxiv.org/abs/2412.05388</link>
      <description><![CDATA[arXiv:2412.05388v1 公告类型：新
摘要：我们提出了 CALICO，这是一种微调大型语言模型 (LLM) 的方法，用于将对话代理训练数据从一种语言本地化为另一种语言。对于插槽（命名实体），CALICO 支持三种操作：逐字复制、直译和本地化，即生成更适合目标语言的插槽值，例如位于使用该语言的国家/地区的城市和机场名称。此外，我们设计了一种迭代过滤机制来丢弃嘈杂的生成样本，我们表明这可以提高下游对话代理的性能。为了证明 CALICO 的有效性，我们构建并发布了 8 种语言的 MultiATIS++ 旅行信息测试集的新人工本地化 (HL) 版本。与测试集的原始人工翻译 (HT) 版本相比，我们表明我们的新 HL 版本更具挑战性。我们还表明，CALICO 在 HT 情况下和 HL 情况下的表现均优于最先进的 LINGUIST（依赖于脱离上下文的字面槽翻译），其中 CALICO 生成更准确的槽翻译，其中 CALICO 生成更接近 HL 测试集的本地化槽。]]></description>
      <guid>https://arxiv.org/abs/2412.05388</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多样性胜过数量：从小样本关系分类中得到的教训</title>
      <link>https://arxiv.org/abs/2412.05434</link>
      <description><![CDATA[arXiv:2412.05434v1 公告类型：新
摘要：在少样本关系分类 (FSRC) 中，模型必须仅使用少量标记示例推广到新关系。虽然 NLP 的最新进展主要集中在扩展数据大小上，但我们认为关系类型的多样性对于 FSRC 性能更为重要。在这项工作中，我们证明，即使整体数据集大小保持不变，对多样化关系集进行训练也会显著增强模型推广到看不见的关系的能力。
我们引入了 REBEL-FS，这是一种新的 FSRC 基准，它包含的关系类型比现有数据集多一个数量级。通过系统实验，我们表明，增加训练数据中关系类型的多样性会在各种少样本学习场景（包括高负面设置）中带来持续的性能提升。我们的研究结果挑战了通常的假设，即仅凭更多数据就能带来更好的性能，并表明以多样性为重点的有针对性的数据管理可以大大减少 FSRC 对大规模数据集的需求。]]></description>
      <guid>https://arxiv.org/abs/2412.05434</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实现有效的 GenAI 多智能体协作：企业应用程序的设计和评估</title>
      <link>https://arxiv.org/abs/2412.05449</link>
      <description><![CDATA[arXiv:2412.05449v1 公告类型：新
摘要：由大型语言模型 (LLM) 驱动的 AI 代理在解决问题方面表现出强大的能力。通过结合许多智能代理，多代理协作已成为一种有前途的方法，可以解决超出单个 AI 代理能力的复杂、多方面问题。然而，设计协作协议和评估这些系统的有效性仍然是一项重大挑战，尤其是对于企业应用而言。本报告通过对新型多代理协作框架中的协调和路由能力进行全面评估来解决这些挑战。我们评估了两种关键的操作模式：(1) 通过并行通信和有效载荷引用实现复杂任务完成的协调模式，以及 (2) 用于代理之间高效消息转发的路由模式。我们对来自三个企业领域的一组手工制作的场景进行了基准测试，这些场景与报告一起公开发布。对于协调能力，我们展示了代理间通信和有效载荷引用机制的有效性，实现了 90% 的端到端目标成功率。我们的分析得出了几个关键发现：在我们的基准测试中，与单代理方法相比，多代理协作可将目标成功率提高高达 70%；有效载荷引用可将代码密集型任务的性能提高 23%；使用选择性绕过代理编排的路由机制可以大幅降低延迟。这些发现为多代理系统的企业部署提供了宝贵的指导，并推动了可扩展、高效的多代理协作框架的开发。]]></description>
      <guid>https://arxiv.org/abs/2412.05449</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>知识图谱就是你所需要的：在物理问答中利用知识图谱</title>
      <link>https://arxiv.org/abs/2412.05453</link>
      <description><![CDATA[arXiv:2412.05453v1 公告类型：新
摘要：本研究探讨了使用大型语言模型生成的知识图谱将高中物理问题分解为子问题的有效性。我们引入了一个旨在提高问答任务模型响应质量的流程。通过使用 LLM 构建知识图谱来捕捉问题的内部逻辑，这些图谱随后指导子问题的生成。我们假设与传统的分解技术相比，这种方法产生的子问题在逻辑上与原始问题更加一致。我们的结果表明，从知识图谱中得出的子问题对原始问题逻辑的保真度显著提高。这种方法不仅通过提供更清晰、更符合语境的子问题来增强学习体验，而且还凸显了 LLM 改变教育方法的潜力。研究结果表明，应用人工智能来提高教育内容质量和有效性是一个有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2412.05453</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SplaXBERT：利用混合精度训练和上下文分割进行问答</title>
      <link>https://arxiv.org/abs/2412.05499</link>
      <description><![CDATA[arXiv:2412.05499v1 公告类型：新
摘要：SplaXBERT 基于 ALBERT-xlarge 构建，采用上下文分割和混合精度训练，在长文本问答任务中取得了很高的效率。在 SQuAD v1.1 上测试，其精确匹配率为 85.95%，F1 得分为 92.97%，在准确率和资源效率方面均优于传统的基于 BERT 的模型。]]></description>
      <guid>https://arxiv.org/abs/2412.05499</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型不确定性量化调查：分类、开放研究挑战和未来方向</title>
      <link>https://arxiv.org/abs/2412.05563</link>
      <description><![CDATA[arXiv:2412.05563v1 公告类型：新
摘要：大型语言模型 (LLM) 在内容生成、编码和常识推理方面的出色表现促使其广泛融入社会的各个方面。然而，鉴于 LLM 容易产生幻觉，因此其整合引发了对其可靠性和可信度的质疑：这些幻觉是看似合理的、事实不正确的反应，并且表达得非常自信。先前的研究表明，可以通过检查 LLM 对相关提示的响应的不确定性来检测由 LLM 产生的幻觉和其他非事实反应，从而推动了致力于量化 LLM 不确定性的大量研究工作。本调查旨在对现有的 LLM 不确定性量化方法进行广泛的回顾，确定它们的显着特征以及优缺点。我们在相关分类法中介绍现有方法，统一表面上不同的方法以帮助理解最新技术。此外，我们重点介绍了法学硕士 (LLM) 不确定性量化方法的应用，涵盖聊天机器人和文本应用以及机器人技术中的具身人工智能应用。最后，我们总结了法学硕士 (LLM) 不确定性量化方面的开放性研究挑战，以期激发未来的研究。]]></description>
      <guid>https://arxiv.org/abs/2412.05563</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>极坐标系表示大型语言模型中的语法</title>
      <link>https://arxiv.org/abs/2412.05571</link>
      <description><![CDATA[arXiv:2412.05571v1 公告类型：新
摘要：句法树最初是用符号表示形式化的，也可以在大型语言模型 (LLM) 的激活中有效表示。事实上，“结构探针”可以找到神经激活的子空间，其中句法相关的单词彼此相对较近。然而，这种句法代码仍然不完整：结构探针词嵌入之间的距离可以表示句法关系的存在，但不能表示句法关系的类型和方向。在这里，我们假设句法关系实际上是由附近嵌入之间的相对方向编码的。为了检验这一假设，我们引入了一个“极地探针”，它经过训练可以从词嵌入之间的距离和方向读取句法关系。我们的方法揭示了三个主要发现。首先，我们的极坐标探测器成功恢复了句法关系的类型和方向，并且比结构探测器的性能高出近两倍。其次，我们确认这个极坐标系统存在于许多 LLM 中间层的低维子空间中，并且在最新的前沿模型中变得越来越精确。第三，我们用一个新的基准证明，相似的句法关系在嵌套的句法树层级上以类似的方式编码。总体而言，这项工作表明 LLM 自发地学习了一种神经激活的几何结构，它明确地代表了语言理论的主要符号结构。]]></description>
      <guid>https://arxiv.org/abs/2412.05571</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士作为法官：基于法学硕士的评估方法综合调查</title>
      <link>https://arxiv.org/abs/2412.05579</link>
      <description><![CDATA[arXiv:2412.05579v2 公告类型：新
摘要：大型语言模型（LLM）的快速发展推动了其在各个领域的应用不断扩大。最有前途的应用之一是它们作为基于自然语言响应的评估者的角色，称为“LLMs-as-judges”。由于其出色的有效性、跨任务泛化能力以及自然语言形式的可解释性，该框架引起了学术界和工业界越来越多的关注。本文从功能、方法、应用、元评估和局限性五个关键角度全面概述了 LLMs-as-judges 范式。我们首先对 LLMs-as-judges 进行系统定义并介绍其功能（为什么使用 LLM 法官？）。然后我们讨论使用 LLM 构建评估系统的方法（如何使用 LLM 法官？）。此外，我们研究了其应用的潜在领域（在哪里使用 LLM 法官？）并讨论了在各种情况下评估它们的方法（如何评估 LLM 法官？）。最后，我们详细分析了 LLM 法官的局限性并讨论了未来的潜在方向。通过结构化和全面的分析，我们旨在为 LLMs-as-judges 在研究和实践中的开发和应用提供见解。我们将继续在 https://github.com/CSHaitao/Awesome-LLMs-as-Judges 维护相关资源列表。]]></description>
      <guid>https://arxiv.org/abs/2412.05579</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BERTCaps：用于波斯语多领域情感分析的 BERT Capsule</title>
      <link>https://arxiv.org/abs/2412.05591</link>
      <description><![CDATA[arXiv:2412.05591v1 公告类型：新 
摘要：多领域情绪分析涉及通过利用特定于领域的信息来估计非结构化文本的极性。文献中讨论的方法共同的主要问题之一是它们对不同于构建意见模型的领域的适用性较差。本文旨在提出一种使用深度学习方法进行波斯语多领域 SA 分析的新方法。提出的 BERTCapsules 方法由 BERT 和 Capsule 模型的组合组成。在这种方法中，BERT 用于实例表示，Capsule Structure 用于学习提取的图。Digikala 数据集（包括具有正极性和负极性的十个域）用于评估这种方法。对 BERTCaps 模型的评估在情绪分类二元分类中实现了 0.9712 的准确率，在领域分类中实现了 0.8509 的准确率。]]></description>
      <guid>https://arxiv.org/abs/2412.05591</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CharacterBox：评估法学硕士在基于文本的虚拟世界中的角色扮演能力</title>
      <link>https://arxiv.org/abs/2412.05631</link>
      <description><![CDATA[arXiv:2412.05631v1 公告类型：新 
摘要：角色扮演是大型语言模型 (LLM) 的一项关键功能，可实现广泛的实际应用，包括智能非玩家角色、数字孪生和情感伴侣。评估 LLM 中的这种能力具有挑战性，因为角色扮演涉及复杂的动态，例如在整个故事情节中保持角色保真度以及在没有明确基本事实的情况下浏览开放式叙述。当前的评估方法主要侧重于问答或对话快照，无法充分捕捉真实角色扮演所必需的细微角色特征和行为。在本文中，我们提出了 CharacterBox，这是一个模拟沙箱，旨在生成情境细粒度角色行为轨迹。这些行为轨迹可以更全面、更深入地评估角色扮演能力。CharacterBox 由两个主要组件组成：角色代理和叙述者代理。角色代理基于心理和行为科学，表现出类似人类的行为，而叙述者代理则协调角色代理与环境变化之间的交互。此外，我们还引入了两种基于轨迹的方法，利用 CharacterBox 来增强 LLM 性能。为了降低成本并促进公共社区采用 CharacterBox，我们对两个较小的模型 CharacterNR 和 CharacterRM 进行了微调，以替代 GPT API 调用，并展示了它们与高级 GPT API 相比的竞争性能。]]></description>
      <guid>https://arxiv.org/abs/2412.05631</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>混合隐维 Transformer</title>
      <link>https://arxiv.org/abs/2412.05644</link>
      <description><![CDATA[arXiv:2412.05644v2 公告类型：新
摘要：Transformer 模型在有效扩展隐藏维度方面遇到挑战，因为均匀增加它们会增加计算和内存成本，同时无法强调每个 token 最相关的功能。为了进一步理解，我们研究了隐藏维度的稀疏性，并观察到经过训练的 Transformer 仅利用了一小部分 token 维度，从而揭示了“激活流”模式。值得注意的是，存在跨多个连续 token 持续激活的共享子维度和针对每个 token 唯一激活的专用子维度。为了更好地对 token 相关子维度进行建模，我们提出了 MoHD（隐藏维度混合），这是一种稀疏条件激活架构。具体而言，MoHD 对常见 token 特征采用共享子维度，并采用路由机制来动态激活专用子维度。为了减轻稀疏性造成的潜在信息丢失，我们设计了激活缩放和组融合机制来保留激活流。通过这种方式，MoHD 在几乎不增加计算或参数的情况下扩展了隐藏维度，在保持性能的同时实现了高效的训练和推理。在 10 个 NLP 任务中的评估表明，MoHD 在参数效率和任务性能方面超越了 Vanilla Transformers。它在激活参数减少 50% 的情况下实现了 1.7% 的性能提升，在激活成本不变的情况下将参数扩展 3 倍，实现了 3.7% 的性能提升。MOHD 为扩展模型提供了一个新的视角，展示了隐藏维度稀疏性提高效率的潜力]]></description>
      <guid>https://arxiv.org/abs/2412.05644</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将 NER 推向高潮：Auto-AdvER 方法</title>
      <link>https://arxiv.org/abs/2412.05655</link>
      <description><![CDATA[arXiv:2412.05655v1 公告类型：新
摘要：本文介绍了 Auto-AdvER 开发的案例研究，Auto-AdvER 是一种专门用于汽车广告类型文本的命名实体识别模式和数据集。Auto-AdvER 的开发考虑到了行业需求，旨在增强该领域的文本挖掘分析，并贡献了语言上独特的 NER 数据集。我们提出了一个由三个标签组成的模式：“条件”、“历史”和“销售选项”。我们概述了注释的指导原则，描述了模式开发的方法，并展示了注释研究的结果，该研究证明了注释者之间的 F1 分数一致性为 92%。此外，我们使用仅编码器模型：BERT、DeBERTaV3 和仅解码器的开源和闭源大型语言模型 (LLM)：Llama、Qwen、GPT-4 和 Gemini 来比较性能。我们的结果表明，LLM 类优于较小的仅编码器模型。然而，法学硕士成本高昂，远非完美地完成这项任务。我们将这项工作作为更精细分析的垫脚石，并讨论 Auto-AdvER 对广告分析和客户洞察的潜在影响，包括市场动态分析和数据驱动的预测性维护等应用。我们的模式以及相关发现适用于考虑在汽车领域或其他专业领域进行命名实体识别的私人和公共实体。]]></description>
      <guid>https://arxiv.org/abs/2412.05655</guid>
      <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>