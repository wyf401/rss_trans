<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 15 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>研究文本摘要对主题建模的影响</title>
      <link>https://arxiv.org/abs/2410.09063</link>
      <description><![CDATA[arXiv:2410.09063v1 公告类型：新
摘要：主题模型用于识别和分组一组文档中的相似主题。基于深度学习的神经主题模型的最新进展引起了广泛的研究兴趣。本文提出了一种方法，该方法利用预先训练的大型语言模型 (LLM) 在将文档输入主题模型之前生成文档摘要，从而进一步提高主题建模性能。使用少量镜头提示来生成不同长度的摘要，以比较它们对主题建模的影响。这种方法对于较大的文档特别有效，因为它有助于捕获最重要的信息，同时减少可能掩盖整体主题的噪音和不相关的细节。此外，据观察，数据集表现出最佳摘要长度，从而提高了主题建模性能。与以前的模型相比，所提出的方法产生了更好的主题多样性和可比的连贯性值。]]></description>
      <guid>https://arxiv.org/abs/2410.09063</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Llettuce：一种开源自然语言处理工具，用于将医学术语翻译成统一的临床编码</title>
      <link>https://arxiv.org/abs/2410.09076</link>
      <description><![CDATA[arXiv:2410.09076v1 公告类型：新
摘要：本文介绍了 Llettuce，这是一种开源工具，旨在解决将医学术语转换为 OMOP 标准概念的复杂性。与 Athena 数据库搜索和 Usagi 等现有解决方案不同，这些解决方案难以处理语义细微差别并需要大量手动输入，而 Llettuce 利用先进的自然语言处理（包括大型语言模型和模糊匹配）来自动化和增强映射过程。Llettuce 以 GDPR 合规性为重点开发，可在本地部署，确保数据保护，同时在将非正式医学术语转换为标准化概念方面保持高性能。]]></description>
      <guid>https://arxiv.org/abs/2410.09076</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于大型语言模型的半结构化招标文件检索增强生成框架</title>
      <link>https://arxiv.org/abs/2410.09077</link>
      <description><![CDATA[arXiv:2410.09077v1 公告类型：新
摘要：采购领域的文件起草工作变得越来越复杂和多样化，这是由于需要满足法律要求、适应技术进步和满足利益相关者的需求。虽然大型语言模型 (LLM) 在文档生成方面显示出潜力，但大多数 LLM 缺乏采购方面的专业知识。为了弥补这一差距，我们使用检索增强技术来实现专业的文档生成，确保采购文档的准确性和相关性。]]></description>
      <guid>https://arxiv.org/abs/2410.09077</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>知识增强推理，以实现 EUAIA 合规性和 LLM 的对抗鲁棒性</title>
      <link>https://arxiv.org/abs/2410.09078</link>
      <description><![CDATA[arXiv:2410.09078v1 公告类型：新
摘要：欧盟人工智能法案 (EUAIA) 引入了对人工智能系统的要求，这些要求与建立对抗性鲁棒性所需的过程相交叉。然而，鉴于监管语言的模糊性和对抗性攻击的动态性，具有 LLM 等高度复杂模型的系统的开发人员可能会发现他们的努力是重复的，而无法保证实现合规性或鲁棒性。本文介绍了一种功能架构，该架构侧重于弥合这两个属性，通过引入明确引用其来源的组件。采用文献推荐的检测层和法律要求的报告层，我们旨在通过基于知识增强（规则、保证案例、上下文映射）的推理层为开发人员和审计员提供支持。我们的研究结果为确保部署在欧盟的 LLM 既合规又具有对抗性鲁棒性提供了一个新方向，这为可信度奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2410.09078</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BIPEFT：预算引导迭代搜索，用于大型预训练语言模型的参数高效微调</title>
      <link>https://arxiv.org/abs/2410.09079</link>
      <description><![CDATA[arXiv:2410.09079v1 公告类型：新
摘要：参数高效微调 (PEFT) 为下游任务的大型预训练语言模型的微调提供了一种有效的解决方案。然而，大多数 PEFT 策略都是手动设计的，通常导致性能不佳。最近的自动 PEFT 方法旨在解决这一问题，但面临着搜索空间纠缠、效率低下以及参数预算和搜索过程之间缺乏整合等挑战。为了克服这些问题，我们引入了一种新颖的预算引导迭代搜索策略，用于自动 PEFT (BIPEFT)，显着提高了搜索效率。BIPEFT 采用一种新的迭代搜索策略来解开二元模块和秩维度搜索空间。此外，我们根据参数预算设计早期选择策略，通过逐步删除不重要的模块和固定秩维度来加速学习过程。在公共基准上进行的大量实验证明了 BIPEFT 在以低参数预算实现下游任务的高效 PEFT 方面的卓越性能。]]></description>
      <guid>https://arxiv.org/abs/2410.09079</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型诊断机器人系统问题</title>
      <link>https://arxiv.org/abs/2410.09084</link>
      <description><![CDATA[arXiv:2410.09084v1 公告类型：新
摘要：快速解决工业应用中报告的问题对于最大限度地减少经济影响至关重要。然而，所需的数据分析使得诊断根本原因成为一项具有挑战性且耗时的任务，即使对于专家来说也是如此。相比之下，大型语言模型 (LLM) 擅长分析大量数据。事实上，AI-Ops 中的先前工作证明了它们在分析 IT 系统方面的有效性。在这里，我们将这项工作扩展到具有挑战性且尚未开发的机器人系统领域。为此，我们创建了 SYSDIAGBENCH，这是一个专有的机器人系统诊断基准，包含 2500 多个报告的问题。我们利用 SYSDIAGBENCH 来研究 LLM 在根本原因分析方面的性能，考虑了一系列模型大小和自适应技术。我们的结果表明，QLoRA 微调足以让 7B 参数模型在诊断准确性方面胜过 GPT-4，同时显著提高成本效益。我们通过人类专家的研究验证了我们的 LLM 作为评判的结果，发现我们的最佳模型获得了与我们的参考标签相似的支持率。]]></description>
      <guid>https://arxiv.org/abs/2410.09084</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 红队演练的最新进展：技术、防御和道德考量</title>
      <link>https://arxiv.org/abs/2410.09097</link>
      <description><![CDATA[arXiv:2410.09097v1 公告类型：新
摘要：大型语言模型 (LLM) 在自然语言处理任务中表现出色，但它们易受越狱攻击，带来重大安全风险。这篇调查论文全面分析了大型语言模型 (LLM) 红队攻击策略和防御机制的最新进展。我们分析了各种攻击方法，包括基于梯度的优化、强化学习和快速工程方法。我们讨论了这些攻击对 LLM 安全的影响以及改进防御机制的必要性。这项工作旨在彻底了解当前对 LLM 的红队攻击和防御状况，从而开发出更安全、更可靠的语言模型。]]></description>
      <guid>https://arxiv.org/abs/2410.09097</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ACER：通过检索实现自动语言模型上下文扩展</title>
      <link>https://arxiv.org/abs/2410.09141</link>
      <description><![CDATA[arXiv:2410.09141v1 公告类型：新
摘要：长上下文建模是语言 AI ​​用于消化和推理复杂信息片段的关键功能之一。在实践中，长上下文功能通常通过精心设计的上下文扩展阶段内置到预训练语言模型 (LM) 中，目的是产生通用的长上下文功能。然而，在我们的初步实验中，我们发现当前的开放权重通用长上下文模型在实际的长上下文处理任务中仍然缺乏。虽然这意味着完美有效的长上下文建模需要特定于任务的数据，但成本可能过高。在本文中，我们从人类如何处理大量信息中汲取灵感：有损 \textbf{检索} 阶段对大量文档进行排名，而读者最终只会深入阅读排名靠前的候选者。我们构建了一个 \textbf{自动} 数据合成管道，使用短上下文 LM 模拟此过程。短上下文 LM 使用这些自生成数据进一步调整，以获得特定于任务的长上下文能力。与预训练从不完美数据中学习的方式类似，我们假设并进一步证明，短上下文模型可以在合成数据上进行引导，不仅优于长上下文通用模型，而且优于用于在现实世界任务（例如长上下文检索增强生成）中合成训练数据的检索和读取管道。]]></description>
      <guid>https://arxiv.org/abs/2410.09141</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM 的混合训练方法：利用真实数据和合成数据来增强特定领域应用中的模型性能</title>
      <link>https://arxiv.org/abs/2410.09168</link>
      <description><![CDATA[arXiv:2410.09168v1 公告类型：新
摘要：本研究探索了一种通过整合真实数据和合成数据来微调大型语言模型 (LLM) 的混合方法，以提高模型性能，特别是在生成准确且与上下文相关的响应方面。通过利用将转录的真实交互与高质量的合成会话相结合的数据集，我们旨在克服稀缺、嘈杂和特定领域的真实数据的局限性。采用合成角色和场景来增强训练多样性。该研究评估了三个模型：基本基础模型、使用真实数据微调的模型和混合微调模型。实验结果表明，混合模型在特定的垂直应用中始终优于其他模型，在所有指标中均获得最高分。进一步的测试证实了混合模型在不同场景中的卓越适应性和上下文理解能力。这些发现表明，结合真实数据和合成数据可以显着提高 LLM 的稳健性和上下文敏感性，特别是在特定领域和垂直用例中。]]></description>
      <guid>https://arxiv.org/abs/2410.09168</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用小样本学习进行上下文感知的 SQL 错误更正——一种基于 NLQ、错误和 SQL 相似性的新方法</title>
      <link>https://arxiv.org/abs/2410.09174</link>
      <description><![CDATA[arXiv:2410.09174v1 公告类型：新
摘要：近年来，由于各种应用程序对高效数据查询的需求，对自动 SQL 生成的需求显着增加。然而，由于自然语言输入的复杂性和多变性，生成准确的 SQL 查询仍然是一个挑战。本文介绍了一种基于少样本学习的新型 SQL 生成错误纠正方法，通过为给定的自然语言问题 (NLQ) 选择最合适的少样本错误纠正示例来提高生成查询的准确性。在我们对开源 Gretel 数据集的实验中，所提出的模型与没有错误纠正的基线方法相比，修复错误率提高了 39.2%，与简单的错误纠正方法相比，修复错误率提高了 10%。所提出的技术利用基于嵌入的相似性度量从少样本存储库中识别最接近的匹配。每个示例都包含一个不正确的 SQL 查询、结果错误、正确的 SQL 查询以及将不正确查询转换为正确查询的详细步骤。通过采用此方法，系统可以有效地指导对新生成的 SQL 查询中的错误的更正。我们的方法通过提供有助于错误识别和更正的上下文相关示例，显著提高了 SQL 生成的准确性。实验结果突出了基于嵌入的选择在增强小样本学习过程方面的有效性，从而可以生成更精确、更可靠的 SQL 查询。这项研究通过提供一个强大的错误更正框架，为自动 SQL 生成领域做出了贡献，为更先进、更用户友好的数据库交互工具铺平了道路。]]></description>
      <guid>https://arxiv.org/abs/2410.09174</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>L3Cube-MahaSum：用于马拉地语抽象文本摘要的综合数据集和 BART 模型</title>
      <link>https://arxiv.org/abs/2410.09184</link>
      <description><![CDATA[arXiv:2410.09184v1 公告类型：新
摘要：我们介绍了 MahaSUM 数据集，这是马拉地语中各种新闻文章的大规模集合，旨在促进对印度语抽象摘要任务模型的训练和评估。该数据集包含 25k 个样本，是通过从各种在线新闻来源中抓取文章并手动验证摘要而创建的。此外，我们使用 MahaSUM 数据集训练了一个 IndicBART 模型，这是针对印度语量身定制的 BART 模型的变体。我们评估了我们训练的模型在抽象摘要任务上的表现，并证明了它们在用马拉地语生成高质量摘要方面的有效性。我们的工作促进了印度语自然语言处理研究的进步，并为未来使用最先进模型进行该领域的研究提供了宝贵的资源。数据集和模型在 https://github.com/l3cube-pune/MarathiNLP 上公开共享]]></description>
      <guid>https://arxiv.org/abs/2410.09184</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>马拉地语文档的长距离命名实体识别</title>
      <link>https://arxiv.org/abs/2410.09192</link>
      <description><![CDATA[arXiv:2410.09192v1 公告类型：新
摘要：由于马拉地语数字内容的指数级增长，对复杂的自然语言处理 (NLP) 方法（尤其是命名实体识别 (NER)）的需求不断增加。特别是，NER 对于识别远距离实体以及排列和理解非结构化马拉地语文本数据至关重要。本文重点介绍管理远程实体，全面分析了当前为马拉地语文档设计的 NER 技术。它深入研究了当前的做法，并研究了 BERT Transformer 模型对远程马拉地语 NER 的潜力。除了分析早期方法的有效性外，该报告还对英语文献中的 NER 进行了比较，并提出了马拉地语文献的适应策略。本文讨论了马拉地语特殊的语言特征和语境细微差别所带来的困难，同时承认 NER 在 NLP 中的关键作用。总而言之，该项目是改进马拉地语 NER 技术的重要一步，具有在一系列 NLP 任务和领域中更广泛的应用潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.09192</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>M3Hop-CoT：通过多模态多跳思维链识别厌女模因</title>
      <link>https://arxiv.org/abs/2410.09220</link>
      <description><![CDATA[arXiv:2410.09220v1 公告类型：新
摘要：近年来，社交媒体平台上针对女性的仇恨现象显著增加，尤其是通过使用厌女模因。这些模因通常以微妙和模糊的线索针对女性，这使得对自动化系统的检测成为一项具有挑战性的任务。最近，大型语言模型 (LLM) 在使用思维链 (CoT) 提示生成中间推理链作为促进多模态任务的理由进行推理方面显示出有希望的结果，但往往忽视了文化多样性和情感和背景知识等关键方面隐藏在视觉模态中。为了解决这一差距，我们引入了一个用于厌女模因识别的多模态多跳 CoT (M3Hop-CoT) 框架，将基于 CLIP 的分类器和多模态 CoT 模块与实体-对象-关系集成相结合。 M3Hop-CoT 采用三步多模态提示原则来诱导情绪、目标意识和背景知识以进行模因分析。我们的实证评估（包括定性和定量分析）验证了 M3Hop-CoT 框架在 SemEval-2022 任务 5（MAMI 任务）数据集上的有效性，突出了其在宏 F1 分数中的出色表现。此外，我们通过在各种基准模因数据集上对模型进行评估来评估模型的通用性，从而深入了解我们的方法在不同数据集中的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.09220</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>相同但不同：多语言建模的结构相似性和差异性</title>
      <link>https://arxiv.org/abs/2410.09223</link>
      <description><![CDATA[arXiv:2410.09223v1 公告类型：新
摘要：我们使用机械可解释性的新工具来询问大型语言模型 (LLM) 的内部结构是否与它们所训练的语言所依据的语言结构相对应。具体来说，我们问 (1) 当两种语言使用相同的形态句法过程时，LLM 是否使用共享的内部电路来处理它们？ (2) 当两种语言需要不同的形态句法过程时，LLM 是否使用不同的内部电路来处理它们？使用英语和中文多语言和单语模型，我们分析了两个任务中涉及的内部电路。我们发现证据表明，模型使用相同的电路来处理相同的句法过程，而不管它出现在哪种语言中，即使是完全独立训练的单语模型也是如此。此外，我们还表明，多语言模型在需要处理仅存在于某些语言中的语言过程（例如形态标记）时会使用特定于语言的组件（注意头和前馈网络）。总之，我们的结果为 LLM 在同时对多种语言进行建模时如何在利用共同结构和保留语言差异之间进行权衡提供了新的见解。]]></description>
      <guid>https://arxiv.org/abs/2410.09223</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过脑调节提高语音语言模型中的语义理解</title>
      <link>https://arxiv.org/abs/2410.09230</link>
      <description><![CDATA[arXiv:2410.09230v2 公告类型：新
摘要：语音语言模型与人类大脑对自然语言的反应在很大程度上一致。然而，目前的模型严重依赖低级语音特征，这表明它们缺乏与大脑相关的语义，这限制了它们作为大脑语义处理模型生物的效用。在这项工作中，我们通过对人们听自然故事的 fMRI 记录进行微调，将与大脑相关的偏差直接引入模型来解决这一限制，我们将这一过程称为大脑调整。在对 3 个不同的预训练模型系列进行测试后，我们发现大脑调整不仅可以改善与语义语言区域的新大脑记录的整体一致性，还可以减少对这种一致性对低级语音特征的依赖。令人兴奋的是，我们进一步表明，大脑调整可以 1) 持续提高一系列下游任务的性能，以及 2) 增加语义偏好的表征空间。我们的研究结果首次提供了一致的证据，表明将脑信号纳入语言模型的训练中可以提高模型的语义理解。]]></description>
      <guid>https://arxiv.org/abs/2410.09230</guid>
      <pubDate>Tue, 15 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>