<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Mon, 17 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>正确：上下文和参考提示的推理，并提示事实检查</title>
      <link>https://arxiv.org/abs/2502.09635</link>
      <description><![CDATA[ARXIV：2502.09635V1公告类型：新 
摘要：事实检查索赔的真实性通常需要对多个证据句子进行推理。通常，证据句子可能并不总是独立的，可能需要其他地方的其他上下文和参考，以了解核心表达式，首字母缩写和报告的发现的范围。例如，学术论文的证据句子可能需要在论文中的上下文句子和引用论文中的描述，以确定研究发现的范围。但是，大多数事实检查模型主要集中在证据句子中的推理上，而忽略了辅助上下文和参考。为了解决这个问题，我们提出了一种新颖的方法，上下文和引用的推理和提示。对于证据推理，我们构建了一个三层证据图，其中有证据，上下文和参考层。我们设计内部和跨层的推理，将三个图层整合到统一的证据嵌入中。为了预测，我们设计了有证据的及时编码器，该编码器为每种索赔产生独特的及时嵌入。这些有证据的及时嵌入和主张是统一的，以进行事实检查。实验验证了我们模型的强度。]]></description>
      <guid>https://arxiv.org/abs/2502.09635</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在两行之间阅读：LLM可以识别跨文化沟通差距吗？</title>
      <link>https://arxiv.org/abs/2502.09636</link>
      <description><![CDATA[ARXIV：2502.09636V1公告类型：新 
摘要：在一个迅速的全球化和数字世界中，来自不同文化的人们创建的书籍和产品评论等内容被来自世界各个角落的其他人所读和消费。在本文中，我们研究了由于具有特定于文化的项目和元素而与其他文化陌生的文化特定物品和元素，因此书面评论可理解的差距的程度和模式。我们对Goodreads的57本书评论的用户研究表明，有83％的评论至少有一个特定于文化的难以理解的元素。鉴于读者的文化背景，我们还评估了GPT-4O在识别此类项目方面的功效；结果是混合的，这意味着改进的显着范围。我们的数据集可在此处找到：https：//github.com/sougata-ub/reading_between_lines]]></description>
      <guid>https://arxiv.org/abs/2502.09636</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>越狱</title>
      <link>https://arxiv.org/abs/2502.09638</link>
      <description><![CDATA[ARXIV：2502.09638V1公告类型：新 
摘要：拒绝大语模型（LLMS）的拒绝培训可以防止有害产出，但这种防御仍然容易受到自动和人力制作的越狱的影响。我们提出了一种新颖的LLM-AS-RED团队方法，其中人类越狱拒绝训练LLM，以使其愿意越狱本身或其他LLM。我们将越狱的LLMS称为$ J_2 $攻击者，该攻击者可以使用各种红色小组策略系统地评估目标模型，并通过从以前的失败中学习通过内在学习来提高其性能。我们的实验表明，SONNET 3.5和GEMINI 1.5 Pro的表现优于其他LLMS $ J_2 $，在HarmBench上分别针对GPT-4O（在其他有能力的LLM的LLMS）中分别获得93.0％和91.0％的攻击成功率（ASRS）（ASRS）。我们的工作不仅引入了一种可扩展的战略红色团队的方法，还从人类红色的团队中汲取了灵感，而且还强调了越狱到命运的突破，这是保障措施的被忽视的失败模式。具体来说，LLM可以通过雇用愿意帮助进一步越狱的越狱版来绕开自己的保障措施。为了防止使用$ J_2 $的任何直接滥用，在进行AI安全研究的同时，我们公开分享我们的方法，同时将特定的提示详细信息保密。]]></description>
      <guid>https://arxiv.org/abs/2502.09638</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>西班牙社交媒体文本中的在线社会支持检测</title>
      <link>https://arxiv.org/abs/2502.09640</link>
      <description><![CDATA[ARXIV：2502.09640V1公告类型：新 
摘要：社交媒体的出现改变了沟通，使个人能够分享自己的经验，寻求支持并参与多样化的讨论。尽管广泛的研究集中在确定诸如仇恨言论之类的有害内容上，但对积极和支持性互动的认识和促进仍然在很大程度上没有探索。这项研究提出了一种创新的方法，可以在西班牙语社交媒体文本中检测在线社会支持。我们介绍了专门为此任务创建的第一个注释数据集，其中包含3,189个YouTube注释，分类为支持性或不支持。为了解决数据不平衡，我们使用GPT-4O来生成释义评论并创建平衡的数据集。然后，我们使用传统的机器学习模型，深度学习体系结构和基于变压器的模型（包括GPT-4O）评估了社会支持分类，但仅在不平衡的数据集中。随后，我们利用变压器模型比较平衡数据集和不平衡数据集之间的性能。我们的发现表明，平衡的数据集为任务2（个人和组）和任务3（国家，其他，LGBTQ，黑人社区，妇女，宗教）产生了改进的结果，而GPT-4O最适合任务1（社会支持和非社会支持和非-支持）。这项研究强调了促进支持性在线环境的重要性，并为自动化社会支持检测的未来研究奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2502.09640</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Krutrim LLM：超过十亿人的多语言基础模型</title>
      <link>https://arxiv.org/abs/2502.09642</link>
      <description><![CDATA[ARXIV：2502.09642V1公告类型：新 
摘要：印度是一个多元化的社会，在开发AI系统方面面临独特的挑战，包括语言多样性，口头传统，数据可访问性和可扩展性。现有的基础模型主要接受英语培训，从而限制了印度人口的有效性。尽管印度占全球人口的18％，但只占普通爬网语言的1％，导致语言偏见。由于稀疏的培训数据，成千上万的区域语言，方言和代码混合造成了其他表示挑战。
  我们介绍了Krutrim LLM，这是一个为印度语言景观设计的200万亿代币多语言模型。它结合了最大的已知IND数据集，减轻数据稀缺性并确保跨方言的平衡性能。 Krutrim的表现优于指示基准的最先进模型，同时保持竞争激烈的英语表现。尽管在训练拖失板中较小，但Krutrim LLM匹配或超过了16个任务中的10个模型，诸如Llama-2之类的模型，平均得分为0.57对0.55。这证明了克鲁特里姆在各种语言环境中的灵活多语言流利度。
  Krutrim与实时搜索集成在一起，以提高对话AI应用程序的事实准确性。这可以增强全球超过10亿用户的可访问性。通过解决数据失衡的故意设计选择，Krutrim LLM表示有意义的构建道德，全球代表性的AI模型的进展。]]></description>
      <guid>https://arxiv.org/abs/2502.09642</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从论证到审议：透视化的立场向量，用于细粒度（DIS）协议分析</title>
      <link>https://arxiv.org/abs/2502.09644</link>
      <description><![CDATA[ARXIV：2502.09644V1公告类型：新 
摘要：就冲突问题进行辩论是解决冲突的必要第一步。但是，有说服力的论证技巧很难克服争论者的内在观点。从辩论到审议过程，我们可以在其中确定可行的解决方案的选择，需要对论点和他们所扎根的观点进行更深入的分析 - 因为只有从那里才能得出相互同意的解决步骤。在这项工作中，我们开发了一个框架，以对计算论证设置中的论证进行审议分析。我们对在给定问题的不同论点或利益相关者的论点中表达的观点立场进行了精细的分析，不仅旨在确定他们的对立观点，而且旨在确定其态度，价值观或需求。我们以透视的立场向量形式化了这种分析，这些媒介是所有论点在给定问题上的个人观点的表现。我们通过确定特定于问题和参数的概念来构建这些向量，并预测争论者相对于它们的立场。向量使我们能够衡量由观点结构的论证者之间的调制（DIS）协议，这使我们能够确定解决冲突的可行点，这是审议的第一步。]]></description>
      <guid>https://arxiv.org/abs/2502.09644</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从不知道：分类法，挑战和机会在多模式基础模型中进行否定理解</title>
      <link>https://arxiv.org/abs/2502.09645</link>
      <description><![CDATA[ARXIV：2502.09645V1公告类型：新 
摘要：否定，一种传达缺失，否认或矛盾的语言结构，对多语言多模式基础模型构成了重大挑战。这些模型在机器翻译，文本引导的生成，图像字幕，音频交互和视频处理等任务中表现出色，但通常很难准确解释跨不同语言和文化背景的否定。从这个角度来看，我们提出了否定结构的全面分类法，说明结构，语义和文化因素如何影响多模式基础模型。我们提出了开放的研究问题，并强调了关键挑战，强调解决这些问题以实现强大的否定处理的重要性。最后，我们倡导专门的基准，特定于语言的令牌化，细粒度的注意机制和高级多模式体系结构。这些策略可以促进更适应性和语义上精确的多模式基础模型，可以更好地浏览和准确地解释多语言多模式环境中的否定复杂性。]]></description>
      <guid>https://arxiv.org/abs/2502.09645</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言转移还是维护？沙特阿拉伯藏族社区的代际研究</title>
      <link>https://arxiv.org/abs/2502.09646</link>
      <description><![CDATA[ARXIV：2502.09646V1公告类型：新 
摘要：本研究提供了有关语言从藏语到阿拉伯语的第一份报告，这些藏族的后代大约在70年前从西藏地区迁移到沙特阿拉伯。这项研究的目的是确定三个年龄组在维持藏族或转移到希贾兹阿拉伯语方面是否采取了不同的做法。为此，藏族社区的96名男性和女性成员回答了一份问卷，其中询问了他们在不同领域（家中，邻里，朋友和亲戚，表达情感和表演宗教仪式）中的代码选择。数据显示，社区成员在转向阿拉伯语的程度方面存在显着的代际差异，而藏族很少使用年轻成员和年长的成员使用它，而只能更多地使用它。在.001的p值下，三个年龄组之间的差异很大。]]></description>
      <guid>https://arxiv.org/abs/2502.09646</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>揭示关注的简单性：自适应长篇小写头标识</title>
      <link>https://arxiv.org/abs/2502.09647</link>
      <description><![CDATA[ARXIV：2502.09647V1公告类型：新 
摘要：处理长上下文的能力对于许多自然语言处理任务至关重要，但这仍然是一个重大挑战。尽管在提高注意力机制的效率方面已经取得了重大进展，但了解注意力头在长篇下说设置中的功能仍然存在差距。在本文中，我们观察到，虽然某些头部仅始终如一地参与本地信息，但其他人则根据查询的不同，在参与本地和长篇小说信息之间进行摇摆。这就提出了一个问题：我们可以确定哪些头部需要长篇文化信息才能准确预测下一个令牌？我们证明，有可能仅使用本地密钥来预测哪些头部对于长篇文化处理至关重要。这里的核心思想是通过第二次近似值来利用长篇文章得分的简单模型。这些发现在长序列的背景下揭示了注意力的简单特性，并为效率带来了潜在的显着提高的大门。]]></description>
      <guid>https://arxiv.org/abs/2502.09647</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>UKTA：统一的韩国文本分析仪</title>
      <link>https://arxiv.org/abs/2502.09648</link>
      <description><![CDATA[ARXIV：2502.09648V1公告类型：新 
摘要：评估写作质量是复杂的，耗时的时间通常会延迟向学习者的反馈。尽管自动写作评估工具对英语有效，但韩国自动化写作评估工具由于无法解决多视图分析，错误传播和评估解释性而面临挑战。为了克服这些挑战，我们介绍了韩国综合文本分析和写作评估系统的UKTA（统一韩国文本分析仪）。 UKTA提供准确的低级词素分析，中级解释性的关键词汇特征以及透明的高级标题写作分数。我们的方法提高了现有基线的准确性和二次加权Kappa，将UKTA定位为韩国文本分析和写作评估的领先多人工具。]]></description>
      <guid>https://arxiv.org/abs/2502.09648</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对齐的原则数据选择：困难示例的隐藏风险</title>
      <link>https://arxiv.org/abs/2502.09650</link>
      <description><![CDATA[ARXIV：2502.09650V1公告类型：新 
摘要：大语言模型（LLM）的对齐方式通常假设使用更多干净的数据会产生更好的结果，从而忽略模型容量和示例难度之间的匹配。挑战这一点，我们提出了一个新的原则：偏好数据在困难方面有所不同，并且过于困难的例子通过超出模型的能力来阻碍一致性。通过系统的实验，我们通过三个关键的发现来验证这一原理：（1）偏好示例在难度上有所不同，这是通过整个对齐运行的一致学习顺序证明的； （2）在四个LLM和两个数据集中大大降低了示例过于困难的示例； （3）模型的能力决定了其处理困难示例的阈值，强调了数据选择和模型容量之间的关键关系。以此原则为基础，我们介绍了选择性DPO，该DPO过滤了过于困难的例子。与DPO基线相比，这种简单的调整使Alpacaeval 2基准的赢率提高了对齐性能的胜利率9-16％，从而抑制了一系列具有不同算法调整的DPO变体。这些结果共同阐明了将数据难度与模型容量保持一致的重要性，从而提供了改善LLM中对齐策略的变革性观点。代码可在https://github.com/glorgao/selectivedpo上找到。]]></description>
      <guid>https://arxiv.org/abs/2502.09650</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>AI-VERDE：一个平等主义访问大型语言模型资源的门户的门户</title>
      <link>https://arxiv.org/abs/2502.09651</link>
      <description><![CDATA[ARXIV：2502.09651V1公告类型：新 
摘要：我们提出了AI-Verde，这是一种统一的LLM-AS-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-AS-A-A-A-AS-A-AS-A-AS-A-AS-A-AS-A-AS-A-AS-A-AS-A-AS-A-Verde服务，旨在促进在学术环境中无缝整合商业，云托管和本地开放式LLM。 AI-VERDE通过提供诸如强大的访问控制，隐私保护机制，本地检索效果生成（RAG）支持，第三方LLM服务的预算管理以及对话性Web界面等功能来简化教学和研究小组的访问管理。和API访问。在一所大型公立大学的试点部署中，AI-Verde在各种教育和研究小组中表现出了大量参与，这使活动通常需要具有有限用户和团队管理能力的商业LLM服务预算大量预算。据我们所知，AI-Verde是第一个解决高等教育机构框架内LLM的学术和研究需求的平台。]]></description>
      <guid>https://arxiv.org/abs/2502.09651</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>神经概念性人工智能：将OPM与深度学习整合在一起，以增强问题答案质量</title>
      <link>https://arxiv.org/abs/2502.09658</link>
      <description><![CDATA[ARXIV：2502.09658V1公告类型：新 
摘要：知识表示和推理是人工智能（AI）的关键挑战，尤其是在整合神经和象征性方法以实现可解释和透明的AI系统时。传统知识表示方法通常无法捕获复杂的过程和状态变化。我们介绍了神经概念人工智能（NCAI），这是神经符号AI方法的专业化，该方法使用对象过程方法（OPM）ISO 19450：2024整合概念建模，并深入学习，以增强问题的交流（QA）质量。通过使用信封学习将自然语言文本转换为OPM模型，NCAI利用OPM的表达能力来表示复杂的OPM元素程序，对象和状态 -  beyond-beyond基于传统三胞胎的知识图可以轻松捕获什么。这种丰富的结构化知识表示可以提高推理透明度并回答OPM-QA系统中的准确性。我们进一步提出透明度评估指标，以定量衡量预测推理与基于OPM的概念逻辑的忠实忠诚度。我们的实验表明，NCAI通过提供丰富的知识表示，可衡量的透明度和改善的推理来强调其推进神经符号AI的潜力。]]></description>
      <guid>https://arxiv.org/abs/2502.09658</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大语言模型从生物医学文献中识别癌症疫苗辅助名称</title>
      <link>https://arxiv.org/abs/2502.09659</link>
      <description><![CDATA[ARXIV：2502.09659V1公告类型：新 
摘要：动机：佐剂是一种化学物质，掺入疫苗中，通过改善免疫反应来增强其疗效。从癌症疫苗研究中鉴定辅助名称对于进一步研究和增强免疫疗法至关重要。但是，不断扩展的生物医学文献的手动策划提出了重大挑战。这项研究探讨了使用大语言模型（LLMS），特别是生成预验证的变压器（GPT）和大语言模型Meta AI（Llama）对疫苗辅助名称的自动识别。方法：我们利用了两个数据集：97个来自SwissuvaredB的临床试验记录，并用疫苗辅助汇编（VAC）注释的290个摘要。 GPT-4O和LLAMA 3.2在零射中使用，每提示最多四个示例。提示明确针对的辅助名称，测试上下文信息（例如物质或干预措施）的影响。输出经过自动化和手动验证，以获得准确性和一致性。结果：GPT-4O在所有情况下均达到100％的精度，同时在召回和F1得分方面表现出显着的改善，尤其是在纳入干预措施中。在VAC数据集上，GPT-4O在干预措施下达到了最高77.32％的F1得分，超过Llama-3.2-3b约2％。在SwixuvaredB数据集上，GPT-4O的F1得分达到了81.67％的三杆提示，并通过干预措施超过了Llama-3.2-3 B的最高F1次数为65.62％。结论：我们的发现表明，LLM在识别辅助名称方面表现出色，包括命名表示的罕见变化。这项研究强调了LLM通过有效提取见解来增强癌症疫苗发展的能力。未来的工作旨在扩大框架，以涵盖各种生物医学文献，并增强各种疫苗和佐剂的概括性。]]></description>
      <guid>https://arxiv.org/abs/2502.09659</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>k-llmmeans：总结为可解释和可扩展LLM的文本群集的质心</title>
      <link>https://arxiv.org/abs/2502.09667</link>
      <description><![CDATA[ARXIV：2502.09667V1公告类型：新 
摘要：我们介绍了K-llmmeans，这是对K-均值聚类算法的一种新颖的修改，该算法利用LLMS将文本摘要作为群集质心生成，从而捕获上下文和语义上的细微差别，通常依赖于纯粹的数值文档嵌入数字手段。这种修改保留了K-均值的属性，同时提供了更大的解释性：群集质心由LLM生成的摘要表示，其嵌入指南群集分配。我们还提出了一个迷你批次变体，可实现有效的在线聚类，用于流式文本数据并提供不断发展的群集质心的实时可解释性。通过大量的模拟，我们表明我们的方法的表现优于多个指标的香草k-均值，而仅产生不随数据集大小扩展的适度LLM使用情况。最后，我们提出了一项案例研究，展示了顺序文本流中不断发展的集群质心的解释性。作为评估的一部分，我们从Stackexchange编译了一个新数据集，为文本流集群提供了基准。]]></description>
      <guid>https://arxiv.org/abs/2502.09667</guid>
      <pubDate>Mon, 17 Feb 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>