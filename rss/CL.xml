<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 16 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>知识编辑视角下的大语言模型偏差缓解</title>
      <link>https://arxiv.org/abs/2405.09341</link>
      <description><![CDATA[arXiv:2405.09341v1 公告类型：新
摘要：现有的去偏见方法不可避免地会做出不合理或不受欢迎的预测，因为它们被指定和评估以实现不同社会群体之间的平等，但忽略了个体事实，导致现有知识被修改。在本文中，我们首先利用现有和额外构建的数据集建立了一个新的偏差缓解基准 BiasKE，该数据集通过公平性、特异性和泛化性的补充指标系统地评估去偏差性能。同时，我们提出了一种新颖的去偏见方法——公平邮票（FAST），它通过对个体偏见知识的细粒度校准来实现可编辑的公平性。综合实验表明，FAST 凭借出色的去偏性能超越了最先进的基线，同时不妨碍知识保存的整体模型能力，凸显了细粒度去偏策略在法学硕士中实现可编辑公平性的前景。]]></description>
      <guid>https://arxiv.org/abs/2405.09341</guid>
      <pubDate>Thu, 16 May 2024 06:15:37 GMT</pubDate>
    </item>
    <item>
      <title>PolygloToxicityPrompts：大型语言模型中神经毒性退化的多语言评估</title>
      <link>https://arxiv.org/abs/2405.09373</link>
      <description><![CDATA[arXiv:2405.09373v1 公告类型：新
摘要：大语言模型（LLM）的最新进展导致其在全球范围内广泛部署，并确保其安全性需要进行全面的多语言毒性评估。然而，现有的毒性基准绝大多数集中在英语上，这给以其他语言部署法学硕士带来了严重风险。我们通过引入 PolygloToxicityPrompts (PTP) 来解决这个问题，这是第一个大规模多语言毒性评估基准，涵盖 17 种语言的 425K 自然出现的提示。我们克服了网络文本中自然产生的毒性的稀缺性，并通过自动抓取超过 1 亿个网络文本文档来确保覆盖不同资源的语言。使用 PTP，我们通过对 60 多个法学硕士进行基准测试，调查研究问题，以研究模型大小、提示语言以及指令和偏好调整方法对毒性的影响。值得注意的是，我们发现随着语言资源的减少或模型大小的增加，毒性会增加。尽管指令和偏好调整可以降低毒性，但偏好调整方法的选择不会产生任何显着影响。我们的研究结果揭示了法学硕士保护的关键缺陷，并突出了未来研究的领域。]]></description>
      <guid>https://arxiv.org/abs/2405.09373</guid>
      <pubDate>Thu, 16 May 2024 06:15:37 GMT</pubDate>
    </item>
    <item>
      <title>基于提示的少样本问答合成数据生成</title>
      <link>https://arxiv.org/abs/2405.09335</link>
      <description><![CDATA[arXiv:2405.09335v1 公告类型：新
摘要：尽管语言模型（LM）提高了问答的性能，但它们仍然需要大量数据。相比之下，数据注释是一个耗时的过程。这尤其适用于问答，其中可能必须解析大型文档并用问题及其相应的答案进行注释。此外，问答模型通常只适用于它们所训练的领域。由于注释成本高昂，我们认为来自 LM 的领域不可知知识（例如语言理解）足以创建精心策划的数据集。出于这种动机，我们表明，与最先进的方法相比，使用大型语言模型可以提高少量镜头设置中各种数据集的问答性能。为此，我们利用提示框架执行数据生成，表明语言模型包含有价值的与任务无关的知识，可以在常见的预训练/微调方案之外使用。因此，我们在小样本问答方面始终优于以前的方法。]]></description>
      <guid>https://arxiv.org/abs/2405.09335</guid>
      <pubDate>Thu, 16 May 2024 06:15:36 GMT</pubDate>
    </item>
    <item>
      <title>语言模型能否捕捉隐含的话语含义？韩语形态学的穷尽性研究</title>
      <link>https://arxiv.org/abs/2405.09293</link>
      <description><![CDATA[arXiv:2405.09293v1 公告类型：新
摘要：自然语言中的标记性通常与话语中的非字面意义相关。韩语中的差异对象标记（DOM）是这种现象的一个例子，其中后置标记是根据名词短语的语义特征和与语义特征正交的话语特征来选择的。先前的工作表明，语言的分布式模型恢复了单词的某些语义特征——这些模型是否也捕获了隐含的话语层面的含义？我们评估一组大型语言模型是否能够将韩语中的话语含义与不同的对象标记相关联。结果表明，语法标记的话语含义比话语标记的话语含义更难编码。]]></description>
      <guid>https://arxiv.org/abs/2405.09293</guid>
      <pubDate>Thu, 16 May 2024 06:15:35 GMT</pubDate>
    </item>
    <item>
      <title>比较 GPT-4 和 Chat-GPT 在心理保健中的功效：心理支持大语言模型的盲评估</title>
      <link>https://arxiv.org/abs/2405.09300</link>
      <description><![CDATA[arXiv:2405.09300v1 公告类型：新
摘要：背景：自然语言处理的快速进步导致了大型语言模型的发展，有可能彻底改变心理健康保健。这些模型在协助临床医生和为经历各种心理挑战的个人提供支持方面表现出了希望。
  目的：本研究旨在比较两种大型语言模型 GPT-4 和 Chat-GPT 在响应一组 18 种心理提示时的表现，以评估它们在心理健康护理环境中的潜在适用性。
  方法：采用盲法，由临床心理学家在不了解模型来源的情况下评估模型的反应。这些提示涵盖了各种心理健康主题，包括抑郁、焦虑和创伤，以确保进行全面的评估。
  结果：结果表明两个模型之间的性能存在显着差异 (p &gt; 0.05)。 GPT-4 的平均评分为 8.29（满分 10），而 Chat-GPT 的平均评分为 6.52。临床心理学家的评估表明，GPT-4 在产生临床相关和同理心反应方面更有效，从而为潜在用户提供更好的支持和指导。
  结论：这项研究为越来越多的关于大语言模型在精神卫生保健环境中的适用性的文献做出了贡献。研究结果强调了该领域持续研究和开发以优化这些模型以供临床使用的重要性。有必要进行进一步的调查，以了解两种模型之间表现差异背后的具体因素，并探索它们在不同人群和心理健康状况下的普遍性。]]></description>
      <guid>https://arxiv.org/abs/2405.09300</guid>
      <pubDate>Thu, 16 May 2024 06:15:35 GMT</pubDate>
    </item>
    <item>
      <title>用于塞尔维亚语言建模的新文本语料库</title>
      <link>https://arxiv.org/abs/2405.09250</link>
      <description><![CDATA[arXiv:2405.09250v1 公告类型：新
摘要：本文将介绍塞尔维亚语（和塞尔维亚-克罗地亚语）文本语料库，可用于大型语言模型的训练，并可在几个著名的在线存储库之一公开获取。每个语料库将使用多种方法进行分类，并详细说明其特征。此外，本文还将引入三个新的语料库：一个新的塞尔维亚-克罗地亚语伞式网络语料库、一个基于存储在塞尔维亚所有大学国家博士论文存储库中的博士论文的新的高质量语料库，以及一个平行的摘要语料库。翻译自同一来源。新旧语料库的独特性将通过基于频率的文体测量方法来获取，并将简要讨论结果。]]></description>
      <guid>https://arxiv.org/abs/2405.09250</guid>
      <pubDate>Thu, 16 May 2024 06:15:34 GMT</pubDate>
    </item>
    <item>
      <title>时代的标志：评估大型语言模型在惯用语检测中的使用</title>
      <link>https://arxiv.org/abs/2405.09279</link>
      <description><![CDATA[arXiv:2405.09279v1 公告类型：新
摘要：尽管大型语言模型最近无处不在，并且它们的高零样本提高了各种任务的性能，但仍然不知道它们在需要处理潜在惯用语言的任务上的表现如何。特别是，与专门针对惯用性任务进行微调的仅编码器模型相比，此类模型的表现如何？在这项工作中，我们试图通过观察一系列法学硕士（本地模型和软件即服务模型）在三个惯用数据集上的表现来回答这个问题：SemEval 2022 Task 2a、FLUTE 和 MAGPIE。总的来说，我们发现虽然这些模型确实提供了有竞争力的性能，但它们与微调的特定任务模型的结果不符，即使是在最大规模上（例如 GPT-4）。尽管如此，我们确实看到了跨模型规模的一致性能改进。此外，我们还研究了提高绩效的激励方法，并讨论了使用法学硕士来完成这些任务的实用性。]]></description>
      <guid>https://arxiv.org/abs/2405.09279</guid>
      <pubDate>Thu, 16 May 2024 06:15:34 GMT</pubDate>
    </item>
    <item>
      <title>弥合在线仇恨言论检测的差距：BERT 与 X/Twitter 上恐同内容识别传统模型的比较分析</title>
      <link>https://arxiv.org/abs/2405.09221</link>
      <description><![CDATA[arXiv:2405.09221v1 公告类型：新
摘要：我们的研究通过关注同性恋恐惧症（情感分析研究中经常被忽视的一个领域）来解决在线仇恨言论检测研究中的重大差距。利用先进的情感分析模型（特别是 BERT）和传统的机器学习方法，我们开发了一种细致入微的方法来识别 X/Twitter 上的恐同内容。由于检测模型中恐同症的代表性持续不足，这项研究至关重要。我们的研究结果表明，虽然 BERT 的性能优于传统方法，但验证技术的选择会影响模型性能。这强调了语境理解在检测细致入微的仇恨言论方面的重要性。通过发布我们所知的最大的用于同性恋恐惧症检测的开源标记英语数据集、对各种模型性能的分析以及我们最强大的基于 BERT 的模型，我们的目标是增强在线安全性和包容性。未来的工作将扩展到更广泛的 LGBTQIA+ 仇恨言论检测，解决获取多样化数据集的挑战。通过这一努力，我们为打击网络仇恨做出了更大的努力，倡导更具包容性的数字环境。我们的研究不仅通过改进以前的研究结果，为有效检测同性恋内容提供了见解，而且还为仇恨言论分析的未来进步奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2405.09221</guid>
      <pubDate>Thu, 16 May 2024 06:15:33 GMT</pubDate>
    </item>
    <item>
      <title>单词对齐作为机器翻译的偏好</title>
      <link>https://arxiv.org/abs/2405.09223</link>
      <description><![CDATA[arXiv:2405.09223v1 公告类型：新
摘要： 幻觉和遗漏问题是机器翻译（MT）中长期存在的问题，当大语言模型（LLM）用于MT时，这种现象更加明显，因为LLM本身很容易受到这些现象的影响。在这项工作中，我们通过引导基于 LLM 的 MT 模型更好地进行单词对齐来缓解该模型中的问题。我们首先研究机器翻译中的词对齐与幻觉和遗漏现象之间的相关性。然后我们建议优先利用词对齐来优化基于 LLM 的 MT 模型。偏好数据是通过从多个 MT 工具中选择选定和拒绝的翻译来构建的。随后，使用直接偏好优化来针对偏好信号优化基于 LLM 的模型。鉴于缺乏专门针对 MT 中的幻觉和遗漏而设计的评估器，我们进一步建议选择硬实例并利用 GPT-4 来直接评估模型在缓解这些问题方面的性能。我们通过实验验证了这些设计的评估方法的合理性，随后的大量结果证明了基于单词对齐的偏好优化对减少幻觉和遗漏的有效性。]]></description>
      <guid>https://arxiv.org/abs/2405.09223</guid>
      <pubDate>Thu, 16 May 2024 06:15:33 GMT</pubDate>
    </item>
    <item>
      <title>使抽象意义表示解析适应临床叙述——SPRING THYME 解析器</title>
      <link>https://arxiv.org/abs/2405.09153</link>
      <description><![CDATA[arXiv:2405.09153v1 公告类型：新
摘要：本文致力于第一个为临床笔记量身定制的 AMR 解析器的设计和评估。我们的目标是促进临床记录精确转换为结构化 AMR 表达式，从而大规模增强临床文本数据的可解释性和可用性。利用来自您的医疗事件时间史 (THYME) 语料库的结肠癌数据集，我们采用持续训练的最先进的 AMR 解析器。我们的方法结合了数据增强技术来提高 AMR 结构预测的准确性。值得注意的是，通过这种学习策略，我们的解析器在 THYME 语料库的结肠癌数据集上取得了令人印象深刻的 88% 的 F1 分数。此外，我们的研究深入研究了临床记录领域内域适应所需数据的功效，提出了 AMR 解析的域适应数据要求。这一探索不仅强调了解析器的强大性能，还强调了其通过结构化语义表示促进对临床叙述的更深入理解的潜力。]]></description>
      <guid>https://arxiv.org/abs/2405.09153</guid>
      <pubDate>Thu, 16 May 2024 06:15:32 GMT</pubDate>
    </item>
    <item>
      <title>HumanRankEval：自动评估 LM 作为会话助理的能力</title>
      <link>https://arxiv.org/abs/2405.09186</link>
      <description><![CDATA[arXiv:2405.09186v1 公告类型：新
摘要：语言模型（LM）作为会话助手最近成为帮助人们完成各种任务的流行工具。这些通常是通过进一步的指令调整和可能的偏好优化方法来调整在通用域文本序列上预训练的 LM 的结果。理想情况下，此类语言模型的评估应使用人类判断来进行，然而，这是不可扩展的。另一方面，以辅助语言模型作为法官和/或基于知识的任务的自动评估是可扩展的，但在评估对话能力和对指令的遵守方面遇到了困难。为了帮助加速 LM 作为对话助理的发展，我们提出了一种新颖的自动评估任务：HumanRankEval (HRE)。它由一组大规模、多样化和高质量的问题组成，每个问题都有几个由人类编写和评分的答案。为了进行评估，HRE 根据 LM 分布下的对数似然对这些答案进行排名，然后计算它们与相应的人类排名的相关性。我们通过研究 HRE 分离不同大小的预训练和指令调整 LM 的效率来支持 HRE 的功效。我们表明，HRE 与人类判断有很好的相关性，并且对指令调整后的模型变化特别敏感。]]></description>
      <guid>https://arxiv.org/abs/2405.09186</guid>
      <pubDate>Thu, 16 May 2024 06:15:32 GMT</pubDate>
    </item>
    <item>
      <title>利用众包进行网络挖掘的日汉平行语料库</title>
      <link>https://arxiv.org/abs/2405.09017</link>
      <description><![CDATA[arXiv:2405.09017v1 公告类型：新
摘要：通过众包，我们收集了超过 10,000 个包含平行文档的双语网站 URL 对（平行首页对），并从这些网站创建了包含 460 万个句子对的日汉平行语料库。我们使用包含 16 万个单词对的日汉双语词典来进行文档和句子对齐。然后，我们使用高质量的 120 万个日汉句子对来训练基于统计语言模型和单词翻译概率的并行语料库过滤器。我们将在这 460 万个句子对上训练的模型的翻译准确性与在来自 CCMatrix（12.4M）（来自全球网络挖掘的平行语料库）的日文-中文句子对上训练的模型的翻译准确性进行了比较。尽管我们的语料库只有 CCMatrix 的三分之一，但我们发现两个模型的准确性相当，并证实使用众包进行并行数据的 Web 挖掘是可行的。]]></description>
      <guid>https://arxiv.org/abs/2405.09017</guid>
      <pubDate>Thu, 16 May 2024 06:15:31 GMT</pubDate>
    </item>
    <item>
      <title>通过面向子空间的模型融合的大型语言模型的安全重新调整框架</title>
      <link>https://arxiv.org/abs/2405.09055</link>
      <description><![CDATA[arXiv:2405.09055v1 公告类型：新
摘要：当前大型语言模型（LLM）的保护机制确实容易受到越狱攻击，使其本质上很脆弱。即使是对下游任务看似良性的数据进行微调的过程也可能会危及安全。一种可能的解决方案是在下游微调之后进行安全微调。然而，在安全微调过程中存在灾难性遗忘的风险，法学硕士可能会重新获得安全措施，但会丢失在下游微调过程中获得的特定于任务的知识。在本文中，我们通过面向子空间的模型融合（SOMF）引入了一种安全重新调整框架，旨在将初始调整模型和当前微调模型的保障能力结合到重新调整的模型中。我们的方法首先将所有任务向量与每个微调模型的权重分开。然后，我们通过子空间掩蔽技术识别这些向量中的安全相关区域。最后，我们基于已识别的安全子空间探索初始安全对齐的 LLM 与所有任务向量的融合。我们验证我们的安全调整框架满足单个微调模型以及多个模型融合过程中的安全要求。我们的研究结果证实，SOMF 在不显着影响下游任务性能的情况下保持了安全性，包括遵循中文、英语和印地语的指令，以及解决代码和数学问题的能力。]]></description>
      <guid>https://arxiv.org/abs/2405.09055</guid>
      <pubDate>Thu, 16 May 2024 06:15:31 GMT</pubDate>
    </item>
    <item>
      <title>通过自然语言进行人机协作粒子加速器调整的大型语言模型</title>
      <link>https://arxiv.org/abs/2405.08888</link>
      <description><![CDATA[arXiv:2405.08888v1 公告类型：新
摘要：粒子加速器的自主调谐是一个活跃且具有挑战性的研究领域，其目标是使新型加速器技术能够应用于物理发现、癌症研究和材料科学等前沿的高影响力应用。自主加速器调整的一个关键挑战仍然是，最强大的算法需要优化、机器学习或类似领域的专家来为每个新的调整任务实施算法。在这项工作中，我们建议使用大型语言模型（LLM）来调整粒子加速器。我们在原理验证示例中展示了法学硕士仅基于操作员的自然语言提示即可成功自主调整粒子加速器子系统的能力，并将我们基于法学硕士的解决方案的性能与现状进行比较-最先进的优化算法，例如贝叶斯优化（BO）和强化学习训练优化（RLO）。在此过程中，我们还展示了法学硕士如何对高度非线性的现实世界目标函数进行数值优化。最终，这项工作代表了法学硕士能够解决的另一项复杂任务，并有望帮助加速​​将自主调整算法部署到粒子加速器的日常操作中。]]></description>
      <guid>https://arxiv.org/abs/2405.08888</guid>
      <pubDate>Thu, 16 May 2024 06:15:30 GMT</pubDate>
    </item>
    <item>
      <title>针对低/无资源语言的法学硕士辅助基于规则的机器翻译</title>
      <link>https://arxiv.org/abs/2405.08997</link>
      <description><![CDATA[arXiv:2405.08997v1 公告类型：新
摘要：我们提出了一种新的机器翻译范例，对于无资源语言（没有任何公开可用的双语或单语语料库的语言）特别有用：\acronym（法学硕士辅助规则机器翻译）。使用\首字母缩略词范式，我们为欧文斯谷派尤特语（OVP）设计了第一个面向语言教育/振兴的机器翻译器，这是一种极度濒危的美洲土著语言，几乎没有公开可用的数据。我们对翻译器组件进行了详细评估：基于规则的句子构建器、OVP 到英语翻译器和英语到 OVP 翻译器。我们还讨论了该范式的潜力、其局限性以及它为未来研究开辟的许多途径。]]></description>
      <guid>https://arxiv.org/abs/2405.08997</guid>
      <pubDate>Thu, 16 May 2024 06:15:30 GMT</pubDate>
    </item>
    </channel>
</rss>