<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 06 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>CLUE：大型语言模型的概念级不确定性估计</title>
      <link>https://arxiv.org/abs/2409.03021</link>
      <description><![CDATA[arXiv:2409.03021v1 公告类型：新
摘要：大型语言模型 (LLM) 在各种自然语言生成 (NLG) 任务中表现出色。先前的研究表明，LLM 的生成过程涉及不确定性。然而，现有的不确定性估计方法主要关注序列级不确定性，忽略了序列中的单个信息。这些方法无法分别评估序列中每个组件的不确定性。为此，我们提出了一种用于 LLM 的概念级不确定性估计 (CLUE) 的新框架。我们利用 LLM 将输出序列转换为概念级表示，将序列分解为单个概念并分别测量每个概念的不确定性。我们进行实验以证明与句子级不确定性相比，CLUE 可以提供更可解释的不确定性估计结果，并且可以成为幻觉检测和故事生成等各种任务的有用工具。]]></description>
      <guid>https://arxiv.org/abs/2409.03021</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>奇异性：使用语言模型进行通用异常检测</title>
      <link>https://arxiv.org/abs/2409.03046</link>
      <description><![CDATA[arXiv:2409.03046v1 公告类型：新
摘要：我们提出了一种新方法，使用语言模型以完全无监督的方式检测文本中的异常（一般来说：任何数据序列中的异常）。该方法考虑语言模型生成的概率（可能性），但不是关注低可能性标记，而是考虑本文引入的新指标：奇异性。奇异性根据语言模型衡量给定标记的“奇怪”程度。我们在语法错误检测任务（文本异常检测的一个特定情况）中证明，如果假设完全无监督的设置，奇异性比仅考虑低可能性事件更好。]]></description>
      <guid>https://arxiv.org/abs/2409.03046</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>量化人工和 ASR 生成的非裔美国英语文本中的风格差异</title>
      <link>https://arxiv.org/abs/2409.03059</link>
      <description><![CDATA[arXiv:2409.03059v1 公告类型：新
摘要：用于评估自动语音识别 (ASR) 系统以及人工转录员性能的常见准确度指标会混淆多种错误来源。当训练数据集和测试数据集之间存在差异时，风格差异（例如逐字与非逐字）可以在 ASR 性能评估中发挥重要作用。对于代表性不足的变体的语音，问题更加复杂，因为语音到正字法的映射并不那么标准化。我们对 10 小时非裔美国英语 (AAE) 语音的 6 个转录版本（4 个人工转录和 2 个 ASR 转录）之间的风格差异进行了分类。我们重点关注逐字特征和 AAE 形态句法特征，研究这些类别与通过词错误率 (WER) 比较转录效果之间的相互作用。结果和整体分析有助于阐明 ASR 输出如何取决于训练数据的人工转录员所做出的决策。]]></description>
      <guid>https://arxiv.org/abs/2409.03059</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索自监督语音模型中的自注意力机制以发现跨语言差异</title>
      <link>https://arxiv.org/abs/2409.03115</link>
      <description><![CDATA[arXiv:2409.03115v1 公告类型：新
摘要：语音模型因新型 Transformer 架构的准确性提高而受到关注。虽然在自动语音识别 (ASR) 基准测试中性能的显著提升值得注意，但关于注意力机制在语音相关任务中的应用仍有许多未知之处。例如，虽然假设这些模型正在学习与语言无关的（即通用的）语音表示，但尚未深入探索模型与语言无关意味着什么。在本文中，我们在一个小型自监督语音 Transformer 模型 (TERA) 的自注意力机制领域内探讨了这个问题。我们发现，即使是小型模型，无论训练语言如何，所学习的注意力头也是多种多样的，从几乎完全对角线到几乎完全全局。我们强调了土耳其语和英语之间注意力模式的一些显着差异，并证明模型在预训练期间确实学习了重要的语音信息。我们还提出了一项头部消融研究，该研究表明跨语言的模型主要依靠对角头来对音素进行分类。]]></description>
      <guid>https://arxiv.org/abs/2409.03115</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>图论之争：大型语言模型的灵活可靠的推理框架</title>
      <link>https://arxiv.org/abs/2409.03155</link>
      <description><![CDATA[arXiv:2409.03155v1 公告类型：新
摘要：大型语言模型 (LLM) 可能会因缺乏相关知识而在实际应用中出现幻觉。相比之下，知识图谱包含广泛的多关系结构，可存储大量符号事实。因此，人们广泛探索了 LLM 与知识图谱的集成，其中知识图谱问答 (KGQA) 是集成的关键试金石。此任务要求 LLM 通过从知识图谱中检索相关三元组来回答自然语言问题。然而，现有的方法面临两个重大挑战：\textit{过长的推理路径分散了答案生成的注意力}，以及 \textit{假阳性关系阻碍了路径细化}。在本文中，我们提出了一个迭代交互式 KGQA 框架，该框架利用 LLM 的交互式学习功能来执行图谱推理和辩论 (DoG)。具体而言，DoG 采用子图聚焦机制，允许 LLM 在每个推理步骤后进行答案尝试，从而减轻冗长的推理路径的影响。另一方面，DoG 利用多角色辩论团队逐步简化复杂问题，减少假阳性关系的影响。这种辩论机制确保了推理过程的可靠性。在五个公共数据集上的实验结果证明了我们架构的有效性和优越性。值得注意的是，在 WebQuestions 和 GrailQA 上的准确率分别比最先进的方法 ToG 高出 23.7% 和 9.1%。此外，在上述数据集上与各种 LLM 的集成实验凸显了 DoG 的灵活性。代码可在 \url{https://github.com/reml-group/DoG} 获得。]]></description>
      <guid>https://arxiv.org/abs/2409.03155</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MaterialBENCH：评估大型语言模型的大学级材料科学问题解决能力</title>
      <link>https://arxiv.org/abs/2409.03161</link>
      <description><![CDATA[arXiv:2409.03161v1 公告类型：新
摘要：构建了材料科学领域大型语言模型 (LLM) 的大学级基准数据集 MaterialBENCH。该数据集由基于大学教科书的问题-答案对组成。问题有两种类型：一种是自由回答类型，另一种是多项选择类型。多项选择题的构造方法是将三个错误答案作为选项添加到正确答案中，以便 LLM 可以从四个答案中选择一个作为答案。除了答案的格式外，大多数自由回答和多项选择题类型的问题都是重叠的。我们还使用 MaterialBENCH 在 LLM 上进行了实验，包括 ChatGPT-3.5、ChatGPT-4、Bard（实验时）以及使用 OpenAI API 的 GPT-3.5 和 GPT-4。分析和讨论了 MaterialBENCH 测量的 LLM 性能的差异和相似之处。我们还研究了同一模型中自由回答类型和多项选择类型之间的性能差异以及使用系统反馈对多项选择问题的影响。我们预计 MaterialBENCH 将鼓励 LLM 进一步发展推理能力，以解决更复杂的问题，并最终为材料研究和发现做出贡献。]]></description>
      <guid>https://arxiv.org/abs/2409.03161</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MARAGS：用于多任务检索增强生成问答的多适配器系统</title>
      <link>https://arxiv.org/abs/2409.03171</link>
      <description><![CDATA[arXiv:2409.03171v1 公告类型：新
摘要：在本文中，我们为 KDD CUP 2024 的 Meta 综合 RAG (CRAG) 竞赛介绍了一种多适配器检索增强生成系统 (MARAGS)。CRAG 是一个问答数据集，包含 3 个不同的子任务，旨在完成与 RAG 相关的真实问答任务，具有多样化的问题主题、问题类型、时间动态答案和具有不同受欢迎程度实体的问题。
我们的系统遵循基于 Web 的 RAG 的标准设置，它使用处理过的网页为 LLM 提供生成生成的上下文，同时还查询 API 端点以获取更多信息。MARAGS 还利用多个不同的适配器来解决这些任务的各种要求，并使用标准交叉编码器模型对与回答问题相关的候选段落进行排名。我们的系统在任务 1 中获得了第二名，在任务 2 中获得了第三名。]]></description>
      <guid>https://arxiv.org/abs/2409.03171</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>绕过 DARCY 防御：难以区分的通用对抗触发器</title>
      <link>https://arxiv.org/abs/2409.03183</link>
      <description><![CDATA[arXiv:2409.03183v1 公告类型：新
摘要：用于自然语言处理 (NLP) 的神经网络 (NN) 分类模型容易受到通用对抗触发器 (UAT) 攻击，该攻击会触发模型对任何输入产生特定预测。DARCY 借用了“蜜罐”概念来诱饵多个陷门，有效地检测由 UAT 生成的对抗性示例。不幸的是，我们发现了一种新的 UAT 生成方法，称为 IndisUAT，它生成触发器（即标记）并使用它们来制作对抗性示例，其特征分布与 DARCY 检测层中随机选择类别中的良性示例的特征分布没有区别。产生的对抗性示例在受 DARCY 保护的模型中导致预测结果的最大损失。同时，产生的触发器在文本生成、文本推理和阅读理解的黑盒模型中是有效的。最后，在 NLP 任务的 NN 模型下的评估结果表明，IndisUAT 方法可以有效绕过 DARCY 并穿透其他防御。例如，IndisUAT 可以使 DARCY 检测的真正阳性率至少降低 40.8% 和 90.6%，并使 RNN 和 CNN 模型中的准确率至少降低 33.3% 和 51.6%。IndisUAT 使 BERT 对抗防御模型的准确率降低至少 34.0%，并使 GPT-2 语言模型即使在非种族背景下也会产生种族主义输出。]]></description>
      <guid>https://arxiv.org/abs/2409.03183</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>低资源情绪分类中扩散语言模型数据增强的有效部署</title>
      <link>https://arxiv.org/abs/2409.03203</link>
      <description><![CDATA[arXiv:2409.03203v1 公告类型：新
摘要：情感分类 (SC) 通常面临资源匮乏的挑战，例如领域特定上下文、标签分布不平衡和少样本场景。扩散语言模型 (LM) 在文本数据增强 (DA) 方面的潜力仍未得到探索，此外，文本 DA 方法难以平衡新样本的多样性和一致性。大多数 DA 方法要么执行逻辑修改，要么使用语言模型重新表述原始序列中不太重要的标记。在 SC 的背景下，强烈的情感标记可能会对整个序列的情感产生关键影响。因此，与重新表述不太重要的上下文相反，我们提出 DiffusionCLS 利用扩散 LM 来捕获领域内知识并通过重建强标签相关标记来生成伪样本。这种方法确保了一致性和多样性之间的平衡，避免了引入噪音并增强了数据集的关键特征。 DiffusionCLS 还包含一个抗噪声训练目标，以帮助模型进行泛化。实验证明了我们的方法在各种低资源场景中的有效性，包括特定领域和领域通用问题。消融研究证实了我们框架模块的有效性，可视化研究强调了最佳部署条件，从而强化了我们的结论。]]></description>
      <guid>https://arxiv.org/abs/2409.03203</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>xLAM：为 AI 代理系统赋能的大型动作模型系列</title>
      <link>https://arxiv.org/abs/2409.03215</link>
      <description><![CDATA[arXiv:2409.03215v1 公告类型：新
摘要：由大型语言模型 (LLM) 驱动的自主代理引起了广泛的研究兴趣。然而，开源社区在开发用于代理任务的专用模型方面面临许多挑战，这是由于高质量代理数据集的稀缺以及该领域缺乏标准协议所致。我们推出并公开发布了 xLAM，这是一系列专为 AI 代理任务设计的大型动作模型。xLAM 系列包括五种具有密集和混合专家架构的模型，参数范围从 1B 到 8x22B，使用可扩展、灵活的管道进行训练，该管道统一、增强和合成不同的数据集，以增强 AI 代理在不同环境中的通用性和性能。我们的实验结果表明，xLAM 在多个代理能力基准测试中始终提供出色的性能，尤其是在伯克利函数调用排行榜上名列第一，在工具使用方面优于 GPT-4、Claude-3 和许多其他模型。通过发布 xLAM 系列，我们旨在提高自主 AI 代理的开源 LLM 的性能，从而加速进展并实现代理任务高性能模型的民主化访问。模型可在 https://huggingface.co/collections/Salesforce/xlam-models-65f00e2a0a63bbcd1c2dade4 上找到]]></description>
      <guid>https://arxiv.org/abs/2409.03215</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过重新校准非典型表现来增强医疗保健法学硕士的信任</title>
      <link>https://arxiv.org/abs/2409.03225</link>
      <description><![CDATA[arXiv:2409.03225v1 公告类型：新
摘要：黑盒大型语言模型 (LLM) 越来越多地部署在各种环境中，因此这些模型必须有效地传达其信心和不确定性，尤其是在高风险环境中。然而，这些模型往往表现出过度自信，导致潜在的风险和误判。现有的引出和校准 LLM 信心的技术主要集中在一般推理数据集上，只产生了适度的改进。准确的校准对于明智的决策和防止不良后果至关重要，但由于这些模型执行的任务的复杂性和多变性，仍然具有挑战性。在这项工作中，我们调查了医疗保健环境中黑盒 LLM 的错误校准行为。我们提出了一种新方法 \textit{非典型演示重新校准}，它利用非典型演示来调整模型的置信度估计。我们的方法显著改善了校准，在三个医学问答数据集上将校准误差减少了约 60%，并且优于现有方法，例如 vanilla 言语置信度、CoT 言语置信度等。此外，我们还对非典型性在重新校准框架中的作用进行了深入分析。]]></description>
      <guid>https://arxiv.org/abs/2409.03225</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>保留 BERT 中的经验概率以实现小样本临床实体识别</title>
      <link>https://arxiv.org/abs/2409.03238</link>
      <description><![CDATA[arXiv:2409.03238v1 公告类型：新
摘要：命名实体识别 (NER) 面临标签不平衡的挑战，即某些实体类型在现实世界数据集中被过度代表，而其他实体类型则被低估。这种不平衡可能导致模型在少数实体类上表现不佳，从而阻碍准确和公平的实体识别。本文探讨了基于 BERT 的预训练模型的实体标签不平衡的影响。我们分析了随机数据集上 token 分类任务的不同损失计算和损失传播机制。然后，我们提出了改进高度不平衡的临床实体识别任务的 token 分类的方法。]]></description>
      <guid>https://arxiv.org/abs/2409.03238</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>E2CL：基于探索的具身代理纠错学习</title>
      <link>https://arxiv.org/abs/2409.03256</link>
      <description><![CDATA[arXiv:2409.03256v1 公告类型：新
摘要：语言模型在知识利用和推理方面表现出越来越强的能力。然而，当在具身环境中用作代理时，它们通常会遭受其内在知识与环境知识不一致的问题，从而导致不可行行动。传统的环境协调方法，例如专家轨迹上的监督学习和强化学习，在覆盖环境知识和实现有效收敛方面都面临限制。受人类学习的启发，我们提出了基于探索的纠错学习 (E2CL)，这是一种新颖的框架，它利用探索引起的错误和环境反馈来增强基于 LM 的代理的环境协调。E2CL 结合了教师指导和无教师探索来收集环境反馈并纠正错误行为。代理学习提供反馈和自我纠正，从而增强其对目标环境的适应性。在 Virtualhome 环境中的评估表明，E2CL 训练的代理优于通过基线方法训练的代理，并表现出卓越的自我纠正能力。]]></description>
      <guid>https://arxiv.org/abs/2409.03256</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过纵向研究了解法学硕士的发展：从 Open Ko-LLM 排行榜中获取的见解</title>
      <link>https://arxiv.org/abs/2409.03257</link>
      <description><![CDATA[arXiv:2409.03257v1 公告类型：新
摘要：本文进行了为期 11 个月的纵向研究，以解决先前对 Open Ko-LLM 排行榜的研究的局限性，这些研究依赖于仅 5 个月的观察期的实证研究。通过延长分析时间，我们旨在更全面地了解开发韩语大型语言模型 (LLM) 的进展。我们的研究由三个主要研究问题指导：(1) 随着时间的推移，提高 Open Ko-LLM 排行榜上不同任务的 LLM 性能面临哪些具体挑战？(2) 模型大小如何影响不同基准之间的任务性能相关性？(3) Open Ko-LLM 排行榜上的排行榜排名模式如何随时间变化？通过分析这段时间内的 1,769 个模型，我们的研究全面考察了 LLM 的持续进步和评估框架的演变性质。]]></description>
      <guid>https://arxiv.org/abs/2409.03257</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GraphInsight：解锁大型语言模型中的洞察，实现图形结构理解</title>
      <link>https://arxiv.org/abs/2409.03258</link>
      <description><![CDATA[arXiv:2409.03258v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 已显示出处理图形的潜力，但它们在通过图形描述序列的提示理解图形结构信息方面却举步维艰，尤其是随着图形大小的增加。我们将这一挑战归因于 LLM 在图形描述序列中不同位置的记忆性能不均匀，称为“位置偏差”。为了解决这个问题，我们提出了 GraphInsight，这是一个旨在提高 LLM 对宏观和微观图形信息的理解的新框架。GraphInsight 基于两个关键策略：1) 将关键图形信息放在 LLM 表现出更强记忆性能的位置，2) 受检索增强生成 (RAG) 的启发，为记忆性能较弱的区域研究轻量级外部知识库。此外，GraphInsight 探索将这两种策略集成到需要多步推理的复合图形任务的 LLM 代理流程中。对一系列评估任务的基准进行的大量实证研究表明，GraphInsight 在理解不同大小的图结构方面明显优于所有其他图描述方法（例如，提示技术和重新排序策略）。]]></description>
      <guid>https://arxiv.org/abs/2409.03258</guid>
      <pubDate>Fri, 06 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>