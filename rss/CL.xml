<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 13 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>LatentQA：教 LLM 将激活解码为自然语言</title>
      <link>https://arxiv.org/abs/2412.08686</link>
      <description><![CDATA[arXiv:2412.08686v1 公告类型：新
摘要：可解释性方法旨在理解语言模型表示，但大多数此类方法的输出（电路、向量、标量）都不是人类可立即解释的。为此，我们引入了 LatentQA，即用自然语言回答有关模型激活的开放式问题。为了解决 LatentQA，我们提出了潜在解释调整 (LIT)，它在激活数据集和相关的问答对上对解码器 LLM 进行微调，类似于视觉指令调整对与图像相关的问答对进行训练的方式。我们将解码器用于各种阅读应用，例如从表示中提取关系知识或揭示控制模型行为的系统提示。我们的解码器还指定了可微分损失，我们用它来控制模型，例如消除刻板句子上的模型偏差并控制世代的情绪。最后，我们扩展 LatentQA 以揭示有害的模型功能，例如生成生物武器的配方和黑客代码。]]></description>
      <guid>https://arxiv.org/abs/2412.08686</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用拓扑信息进行上下文学习以完成知识图谱</title>
      <link>https://arxiv.org/abs/2412.08742</link>
      <description><![CDATA[arXiv:2412.08742v1 公告类型：新
摘要：知识图谱 (KG) 对于表示和推理结构化信息至关重要，支持信息检索、问答和决策等广泛应用。然而，它们的有效性往往受到不完整性的阻碍，限制了它们对现实世界的影响潜力。虽然知识图谱完成 (KGC) 已在文献中得到广泛研究，但生成式 AI 模型（尤其是大型语言模型 (LLM)）的最新进展为创新带来了新的机会。上下文学习最近成为一种有前途的方法，可在一系列自然语言处理任务中利用 LLM 的预训练知识，并已在学术界和工业界广泛采用。然而，如何利用上下文学习进行有效的 KGC 仍然相对未被充分探索。我们开发了一种新方法，通过上下文学习结合拓扑信息来提高 KGC 性能。通过将本体知识和图结构集成到 LLM 上下文中，我们的方法在传导设置中实现了出色的性能，即测试图数据集中的节点存在于训练图数据集中。此外，我们将我们的方法应用于更具挑战性的归纳设置中的 KGC，即训练图数据集和测试图数据集中的节点是不相交的，利用本体推断有关缺失节点的有用信息，这些信息在推理过程中充当 LLM 的上下文线索。与 ILPC-small 和 ILPC-large 数据集上的基线相比，我们的方法表现出卓越的性能。]]></description>
      <guid>https://arxiv.org/abs/2412.08742</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BDA：孟加拉语文本数据增强框架</title>
      <link>https://arxiv.org/abs/2412.08753</link>
      <description><![CDATA[arXiv:2412.08753v1 公告类型：新
摘要：数据增强涉及生成与给定数据集中的样本相似的合成样本。在资源有限的领域，高质量数据稀缺，增强在增加训练数据量方面起着至关重要的作用。本文介绍了一种孟加拉语文本数据增强 (BDA) 框架，该框架使用预训练模型和基于规则的方法来创建文本的新变体。其中包括一个过滤过程，以确保新文本保持与原始文本相同的含义，同时增加所用单词的多样性。我们对该框架在孟加拉语文本分类任务中的有效性进行了全面评估。我们的框架在五个不同的数据集中实现了 F1 分数的显着提高，提供的性能相当于在仅使用 50% 的训练数据集的情况下对 100% 数据进行训练的模型。此外，我们通过逐步减少训练数据并通过 BDA 增强它来探索数据稀缺的影响，从而显着提高 F1 分数。该研究对 BDA 的性能进行了全面的检查，确定了实现最佳结果的关键因素，并通过详细的分析解决了其局限性。]]></description>
      <guid>https://arxiv.org/abs/2412.08753</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于覆盖率的多文档摘要公平性</title>
      <link>https://arxiv.org/abs/2412.08795</link>
      <description><![CDATA[arXiv:2412.08795v1 公告类型：新
摘要：多文档摘要 (MDS) 中的公平性衡量系统是否可以公平地生成摘要，以代表具有不同社会属性值的文档的信息。MDS 中的公平性至关重要，因为公平的摘要可以为读者提供全面的视角。以前的研究侧重于使用比例代表制来量化摘要级别的公平性，这是一种基于统计奇偶性的公平性度量。然而，比例代表制不考虑输入文档中的冗余，并且忽略了语料库级别的不公平性。在这项工作中，我们提出了一种新的摘要级公平性度量，即平等覆盖率，它基于具有不同社会属性值的文档的覆盖率，并考虑了文档内的冗余。为了检测语料库级别的不公平性，我们提出了一种新的语料库级别的度量，即覆盖奇偶性。我们的人工评估表明，我们的措施更符合我们对公平性的定义。使用我们的措施，我们评估了十三个不同 LLM 的公平性。我们发现，在所有评估的法学硕士中，Claude3-sonnet 是最公平的。我们还发现，几乎所有法学硕士都过度代表了不同的社会属性值。]]></description>
      <guid>https://arxiv.org/abs/2412.08795</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>jina-clip-v2：文本和图像的多语言多模式嵌入</title>
      <link>https://arxiv.org/abs/2412.08802</link>
      <description><![CDATA[arXiv:2412.08802v1 公告类型：新
摘要：对比语言-图像预训练 (CLIP) 是一种在共享嵌入空间中对齐图像和文本的高效方法。这些模型广泛用于跨模态信息检索和多模态理解等任务。然而，CLIP 模型在纯文本任务中往往表现不佳，与专门的文本模型相比表现不佳。这种性能差异迫使检索系统依赖于单独的模型来完成纯文本和多模态任务。在这项工作中，我们在之前的模型 jina-clip-v1 的基础上，引入了一个精炼的框架，该框架利用跨多种语言的多任务、多阶段对比学习，并结合改进的训练方法以增强纯文本检索。由此产生的模型 jina-clip-v2 在纯文本和多模态任务上的表现优于其前身，同时增加了多语言支持，更好地理解复杂的视觉文档，并借助 Matryoshka 表示学习和向量截断提高了效率。该模型在多语言-多模态和多语言文本检索基准测试中的表现与最先进的模型相当，解决了统一纯文本和多模态检索系统的挑战。]]></description>
      <guid>https://arxiv.org/abs/2412.08802</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型概念模型：句子表示空间中的语言建模</title>
      <link>https://arxiv.org/abs/2412.08821</link>
      <description><![CDATA[arXiv:2412.08821v1 公告类型：新
摘要：LLM 彻底改变了人工智能领域，并已成为许多任务的实际工具。LLM 的现有技术是在 token 级别处理输入并生成输出。这与人类形成了鲜明对比，人类在多个抽象层次上进行操作，远远超出单个单词，以分析信息并生成创造性内容。在本文中，我们提出了一种架构的尝试，该架构在显式高级语义表示上运行，我们将其称为概念。概念与语言和模态无关，代表流程中更高级别的想法或动作。因此，我们建立了一个“大概念模型”。在本研究中，作为可行性的证明，我们假设一个概念对应于一个句子，并使用现有的句子嵌入空间 SONAR，它在文本和语音模态中支持多达 200 种语言。
大概念模型经过训练可在嵌入空间中执行自回归句子预测。我们探索了多种方法，即 MSE 回归、基于扩散的生成变体以及在量化 SONAR 空间中运行的模型。这些探索是使用 1.6B 参数模型和 1.3T 标记量级的训练数据进行的。然后，我们将一个架构扩展到 7B 参数的模型大小和约 2.7T 标记的训练数据。我们对几个生成任务进行了实验评估，即摘要和新的摘要扩展任务。最后，我们表明我们的模型对许多语言表现出令人印象深刻的零样本泛化性能，优于现有同等规模的 LLM。我们模型的训练代码是免费提供的。]]></description>
      <guid>https://arxiv.org/abs/2412.08821</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索跨文化价值观的大型语言模型与训练方法</title>
      <link>https://arxiv.org/abs/2412.08846</link>
      <description><![CDATA[arXiv:2412.08846v1 公告类型：新
摘要：大型语言模型（LLM）与人类密切相关，因此需要对人类社会的文化价值观有深入的了解。在本文中，我们探讨了开源LLM如何对不同国家的不同文化价值观类别做出判断，以及它与模型大小、训练语料库、对齐等训练方法的关系。我们的分析表明，LLM可以判断与人类相似的社会文化规范，但对社会制度和进步的判断则较差。此外，LLM倾向于判断偏向西方文化的文化价值观，这可以通过对多语言语料库进行训练来改进。我们还发现，增加模型大小有助于更好地理解社会价值观，但较小的模型可以通过使用合成数据来增强。我们的分析揭示了与LLM对文化价值观的理解相关的设计方法的宝贵见解。]]></description>
      <guid>https://arxiv.org/abs/2412.08846</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于扩展高质量推理指令的基于图的合成数据管道</title>
      <link>https://arxiv.org/abs/2412.08864</link>
      <description><![CDATA[arXiv:2412.08864v1 公告类型：新 
摘要：合成高质量推理数据进行持续训练已被证明可有效提高大型语言模型 (LLM) 的性能。然而，以前的合成方法难以轻松扩展数据，并且在追求高质量时会产生高昂成本。在本文中，我们提出了基于图的合成数据管道 (GSDP)，这是一种经济且可扩展的高质量推理数据合成框架。受知识图谱的启发，我们从种子数据中提取知识点并构建知识点关系图以探索它们之间的互连。通过探索知识之间的隐式关系，我们的方法实现了 $\times$255 数据扩展。此外，由开源模型引领的 GSDP 实现了与 GPT-4-0613 相当的合成质量，同时保持了 $\times$100 更低的成本。为了解决最具挑战性的数学推理任务，我们提供了包含超过 191 万对数学问题和答案的 GSDP-MATH 数据集。在对 GSDP-MATH 进行微调后，基于 Mistral-7B 的 GSDP-7B 在 MATH 上的准确率达到 37.7%，在 GSM8K 上的准确率达到 78.4%，证明了我们方法的有效性。本文训练的数据集和模型将可用。]]></description>
      <guid>https://arxiv.org/abs/2412.08864</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能辅助生物医学文献知识发现，为精准肿瘤学决策提供支持</title>
      <link>https://arxiv.org/abs/2412.08900</link>
      <description><![CDATA[arXiv:2412.08900v1 公告类型：新
摘要：为癌症患者提供适当的靶向治疗需要在现有知识和生物医学文献和其他几个来源中描述的最新发现的背景下对肿瘤的分子分析和患者的临床特征进行全面分析。我们评估了特定自然语言处理解决方案对支持从生物医学文献中发现知识的潜在贡献。对 Transformers (BERT) 系列中的两个双向编码器表示模型、两个大型语言模型和 PubTator 3.0 进行了测试，以了解它们支持命名实体识别 (NER) 和关系提取 (RE) 任务的能力。 PubTator 3.0 和 BioBERT 模型在 NER 任务中表现最佳（最佳 F1 分数分别等于 0.93 和 0.89），而 BioBERT 在 RE 任务中优于所有其他解决方案（最佳 F1 分数 0.79）并且它通过识别几乎所有实体提及和大多数关系而应用于特定用例。]]></description>
      <guid>https://arxiv.org/abs/2412.08900</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Phi-4 技术报告</title>
      <link>https://arxiv.org/abs/2412.08905</link>
      <description><![CDATA[arXiv:2412.08905v1 公告类型：新
摘要：我们提出了 phi-4，这是一个拥有 140 亿个参数的语言模型，其开发方法主要关注数据质量。与大多数语言模型不同，这些语言模型的预训练主要基于网络内容或代码等有机数据源，而 phi-4 在整个训练过程中战略性地整合了合成数据。虽然 Phi 系列中的先前模型在很大程度上提炼了教师模型（特别是 GPT-4）的功能，但 phi-4 在以 STEM 为中心的 QA 功能方面大大超越了教师模型，这证明我们的数据生成和后训练技术超越了提炼。尽管对 phi-3 架构的改动很小，但由于数据、培训课程的改进和后训练方案的创新，phi-4 相对于其规模实现了强劲的性能——尤其是在以推理为重点的基准上。]]></description>
      <guid>https://arxiv.org/abs/2412.08905</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从文本到轨迹：探索安全强化学习中的复杂约束表示和分解</title>
      <link>https://arxiv.org/abs/2412.08920</link>
      <description><![CDATA[arXiv:2412.08920v1 公告类型：新
摘要：安全强化学习（RL）要求代理在遵守特定约束的同时完成给定的任务。以自然语言形式给出约束由于其灵活的迁移能力和可访问性而在实际场景中具有巨大的潜力。以前具有自然语言约束的安全 RL 方法通常需要为每个约束手动设计成本函数，这需要领域专业知识并且缺乏灵活性。在本文中，我们利用文本在此任务中的双重作用，不仅将其用作提供约束，还将其用作训练信号。我们引入了轨迹级文本约束转换器（TTCT）来取代手动设计的成本函数。我们的实证结果表明，TTCT 有效地理解了文本约束和轨迹，并且 TTCT 训练的策略可以实现比标准成本函数更低的违规率。进行了额外的研究表明 TTCT 具有零样本迁移能力，可以适应约束转移环境。]]></description>
      <guid>https://arxiv.org/abs/2412.08920</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对齐、生成、学习：跨语言情境学习的新型闭环框架</title>
      <link>https://arxiv.org/abs/2412.08955</link>
      <description><![CDATA[arXiv:2412.08955v1 公告类型：新
摘要：跨语言上下文学习 (XICL) 已成为一种利用大型语言模型 (LLM) 解决多语言任务的变革范式，尤其是对于资源匮乏的语言。然而，现有的方法通常依赖于外部检索器或特定于任务的微调，从而限制了它们的可扩展性和通用性。在本文中，我们提出了一种新颖的自监督框架，该框架利用 LLM 的生成能力在内部选择和利用与任务相关的示例。我们的方法引入了两个关键目标：检索生成对齐损失以优化所选示例的质量，语义连贯性损失以确保跨语言一致性。通过对多语言基准的大量实验，我们的方法实现了最先进的性能，大大优于现有基线。进一步的分析强调了它在各种语言家族中的稳健性以及它推广到看不见的任务的能力。人工评估证实了我们的方法生成的输出具有出色的流畅性、相关性和语义正确性。这项工作为跨语言上下文学习提供了一种可扩展、有效且可推广的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2412.08955</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推理感知的多表数据查询重点汇总</title>
      <link>https://arxiv.org/abs/2412.08970</link>
      <description><![CDATA[arXiv:2412.08970v1 公告类型：新
摘要：针对多表数据的查询重点摘要是一项具有挑战性但关键的任务，用于从结构化数据中提取精确且相关的信息。现有方法通常依赖于复杂的预处理步骤，并且难以跨域推广或处理多表查询所需的逻辑推理。在本文中，我们提出了 QueryTableSummarizer++，这​​是一个端到端的生成框架，利用大型语言模型 (LLM)，并通过表感知预训练、查询对齐微调和带反馈的强化学习进行了增强。我们的方法消除了中间序列化步骤的需要，并直接生成与查询相关的摘要。在基准数据集上的实验表明，QueryTableSummarizer++ 在 BLEU、ROUGE 和 F1 分数方面明显优于最先进的基线。其他分析强调了它的可扩展性、跨域泛化以及对复杂查询的稳健处理。人工评估进一步验证了所生成摘要的卓越品质和实际适用性，从而确立了 QueryTableSummarizer++ 成为多表摘要任务的高效解决方案。]]></description>
      <guid>https://arxiv.org/abs/2412.08970</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RuleArena：现实场景中法学硕士规则引导推理的基准</title>
      <link>https://arxiv.org/abs/2412.08972</link>
      <description><![CDATA[arXiv:2412.08972v1 公告类型：新
摘要：本文介绍了 RuleArena，这是一种新颖且具有挑战性的基准，旨在评估大型语言模型 (LLM) 在推理中遵循复杂的现实世界规则的能力。RuleArena 涵盖三个实际领域——航空行李费、NBA 交易和税收法规——评估 LLM 处理需要长上下文理解、逻辑推理和精确数学计算的复杂自然语言指令的能力。两个关键属性将 RuleArena 与传统的基于规则的推理基准区分开来：(1) 它超越了标准的一阶逻辑表示，(2) 它以真实的实际场景为基础，为 LLM 在实际应用中的适用性和可靠性提供了见解。我们的研究结果揭示了 LLM 的几个显著局限性：(1) 它们很难识别和应用适当的规则，经常被相似但不同的规则所混淆；(2) 它们无法始终如一地执行准确的数学计算，即使它们正确识别了相关规则；(3) 总体而言，它们在基准测试中表现不佳。这些结果凸显了在实际应用中提高 LLM 规则引导推理能力的重大挑战。]]></description>
      <guid>https://arxiv.org/abs/2412.08972</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估检索增强生成系统在存在知识差异的 K-12 教育问答中的稳健性</title>
      <link>https://arxiv.org/abs/2412.08985</link>
      <description><![CDATA[arXiv:2412.08985v1 公告类型：新
摘要：检索增强生成 (RAG) 系统已显示出作为 K-12 教育领域问答系统的巨大潜力，在该领域，知识通常在权威教科书的有限范围内查询。然而，教科书与大型语言模型 (LLM) 中的参数知识之间的差异可能会削弱 RAG 系统的有效性。为了系统地研究 RAG 系统在这种知识差异下的稳健性，我们提出了 EduKDQA，这是一个问答数据集，通过在答案和源文档中应用假设的知识更新来模拟实际应用中的知识差异。EduKDQA 包括 3,005 个问题，涵盖五个主题，从上下文利用和知识整合的角度进行了全面的问题类型学。我们对检索和问答性能进行了广泛的实验。我们发现大多数 RAG 系统在回答具有知识差异的问题时性能会大幅下降，而需要整合背景知识和参数知识的问题对 LLM 提出了挑战。]]></description>
      <guid>https://arxiv.org/abs/2412.08985</guid>
      <pubDate>Fri, 13 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>