<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 28 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>我们能够教语言模型来阐释濒危语言吗？</title>
      <link>https://arxiv.org/abs/2406.18895</link>
      <description><![CDATA[arXiv:2406.18895v1 公告类型：新
摘要：行间注释文本 (IGT) 是语言文档项目中的一种流行格式，其中每个词素都标有描述性注释。自动创建行间注释文本可以减少注释者的工作量并保持注释语料库的一致性。先前的研究已经探索了许多用于自动生成 IGT 的统计和神经方法。
由于大型语言模型 (LLM) 在多语言任务中显示出良好的结果，即使对于稀有、濒危语言也是如此，因此人们自然会想知道它们是否可以用于生成 IGT 的任务。我们探索 LLM 是否可以通过上下文学习有效地完成行间注释任务，而无需任何传统训练。我们提出了选择示例以提供上下文的新方法，并观察到有针对性的选择可以显着提高性能。我们发现基于 LLM 的方法优于标准 Transformer 基线，尽管根本不需要训练。这些方法在执行该任务时的表现仍然不及最先进的监督系统，但对于 NLP 社区以外的研究人员来说非常实用，并且只需很少的努力即可使用。]]></description>
      <guid>https://arxiv.org/abs/2406.18895</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:21 GMT</pubDate>
    </item>
    <item>
      <title>语言模型自我博弈在非零和博弈中的有效性</title>
      <link>https://arxiv.org/abs/2406.18872</link>
      <description><![CDATA[arXiv:2406.18872v1 公告类型：新
摘要：像 AlphaGo 这样的游戏智能体通过自我对弈实现了超人的表现，这在理论上保证了在竞争性游戏中产生最佳策略。然而，大多数语言任务都是部分或完全合作的，因此自我对弈等技术是否可以有效地用于改进语言模型仍是一个悬而未决的问题。我们在一种称为 Deal or No Deal (DoND) 的谈判游戏环境中对这个问题进行了实证研究。至关重要的是，DoND 中的目标可以修改为产生完全合作的游戏、严格竞争的游戏或介于两者之间的任何游戏。我们针对每个目标在 DoND 中通过多轮过滤行为克隆对自我对弈中的语言模型进行微调。与预期相反，我们发现语言模型自我对弈在与人类的合作和竞争中都带来了显着的性能提升，这表明尽管缺乏理论保证，但自我对弈和相关技术仍然很有前景。]]></description>
      <guid>https://arxiv.org/abs/2406.18872</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:20 GMT</pubDate>
    </item>
    <item>
      <title>SSP：使用大型语言模型进行低资源语言跨语言迁移的自监督提示</title>
      <link>https://arxiv.org/abs/2406.18880</link>
      <description><![CDATA[arXiv:2406.18880v1 公告类型：新
摘要：最近，仅使用上下文学习 (ICL)，超大型语言模型 (LLM) 就已在多个英语 NLP 任务中表现出色，但它们在其他语言中的实用性仍未得到充分探索。我们研究了它们在低资源语言 (LRL) 中的 NLP 任务的有效性，特别是在零标记跨语言迁移 (0-CLT) 的设置中，其中没有可用的目标语言的标记训练数据——但是，使用来自一种或多种相关中等资源语言 (MRL) 的训练数据，以及可用的目标语言未标记测试数据。我们引入了自监督提示 (SSP)，这是一种针对 0-CLT 设置量身定制的新型 ICL 方法。
SSP 基于关键观察，即如果上下文样本来自目标语言（即使它们的标签略有噪声），LLM 会输出更准确的标签。为了实现这一点，由于 0-CLT 中没有目标语言训练数据，SSP 分为两个阶段运行。在阶段 I 中，使用源 MRL 训练数据，对目标语言的测试数据进行噪声标记。在阶段 II 中，这些噪声测试数据点被用作 ICL 中的样本，以进一步改进标记。此外，我们的 SSP 实现使用了一种新颖的基于整数线性规划 (ILP) 的样本选择，该样本选择平衡了相似性、预测置信度（可用时）和标签覆盖率。对三项任务和十一项 LRL（来自三个区域）的实验表明，在 0-CLT 设置中，SSP 的表现远远优于现有的 SOTA 微调和基于提示的基线。]]></description>
      <guid>https://arxiv.org/abs/2406.18880</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:20 GMT</pubDate>
    </item>
    <item>
      <title>FFN：细粒度中英金融领域平行语料库</title>
      <link>https://arxiv.org/abs/2406.18856</link>
      <description><![CDATA[arXiv:2406.18856v1 公告类型：新
摘要：大型语言模型 (LLM) 极大地推动了机器翻译领域的发展，尽管它们在金融领域的有效性仍未得到充分探索。为了探究这个问题，我们构建了一个细粒度的中英金融新闻平行语料库 FFN。我们从 CNN、FOX 和中国日报等主流媒体网站获取了 2014 年 1 月 1 日至 2023 年 12 月 31 日之间的金融新闻文章。数据集包括 1,013 个正文和 809 个标题，所有这些都经过了手动更正。我们测量了两个 LLM——ChatGPT 和 ERNIE-bot 的翻译质量，使用 BLEU、TER 和 chrF 分数作为评估指标。为了进行比较，我们还基于我们的数据集训练了一个 OpenNMT 模型。我们详细介绍了 LLM 的问题并提供了深入的分析，旨在激发对这个未知领域的进一步研究和解决方案。我们的研究强调需要优化金融翻译特定领域的法学硕士学位，以确保准确性和质量。]]></description>
      <guid>https://arxiv.org/abs/2406.18856</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:19 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 自我校正在放射学报告简化中的双管齐下人工评估</title>
      <link>https://arxiv.org/abs/2406.18859</link>
      <description><![CDATA[arXiv:2406.18859v1 公告类型：新
摘要：放射学报告是高度技术性的文档，主要用于医生之间的交流。人们越来越有兴趣与患者分享这些报告，因此有必要为他们提供原始报告的患者友好型简化版本。本研究探讨了大型语言模型在自动生成这些简化版本方面的适用性。我们研究了思路链和自我纠正提示机制在这一领域的实用性。我们还提出了一种新的评估方案，该方案采用放射科医生和外行人员，其中放射科医生验证简化版本的事实正确性，外行人员评估简单性和理解性。我们的实验结果证明了自我纠正提示在产生高质量简化版本方面的有效性。我们的研究结果阐明了放射科医生和外行人员对文本简化的偏好，为未来关于该主题的研究提供了参考。]]></description>
      <guid>https://arxiv.org/abs/2406.18859</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:19 GMT</pubDate>
    </item>
    <item>
      <title>OutlierTune：适用于大型语言模型的高效通道量化</title>
      <link>https://arxiv.org/abs/2406.18832</link>
      <description><![CDATA[arXiv:2406.18832v1 公告类型：新 
摘要：由于存在结构化异常值，量化大型语言模型 (LLM) 的激活一直是一项重大挑战。大多数现有方法侧重于激活的每个标记或每个张量的量化，因此难以同时实现准确性和硬件效率。为了解决这个问题，我们提出了 OutlierTune，一种用于 LLM 激活的高效每通道训练后量化 (PTQ) 方法。OutlierTune 包含两个部分：去量化的预执行和对称化。去量化的预执行通过激活缩放因子更新模型权重，避免了每通道激活量化带来的内部缩放和昂贵的额外计算开销。对称化通过确保不同激活通道之间的平衡数值范围进一步减少了由权重更新引起的量化差异。 OutlierTune 易于实现且硬件效率高，在推理过程中几乎不会引入额外的计算开销。大量实验表明，所提出的框架在多个不同任务中的表现优于现有方法。该框架表现出更好的泛化能力，将指令调整 LLM（例如 OPT-IML）的 Int6 量化提高到与半精度（FP16）相同的水平。此外，我们已经证明，所提出的框架比 FP16 实现快 1.48 倍，同时将内存使用量减少了约 2 倍。]]></description>
      <guid>https://arxiv.org/abs/2406.18832</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:18 GMT</pubDate>
    </item>
    <item>
      <title>学习检索增强以实现个性化对话生成</title>
      <link>https://arxiv.org/abs/2406.18847</link>
      <description><![CDATA[arXiv:2406.18847v1 公告类型：新
摘要：个性化对话生成专注于通过利用人物档案和对话背景生成高度定制的响应，在对话式 AI 应用中引起了广泛关注。然而，人物档案是当前个性化对话数据集中普遍存在的设置，通常仅由四到五句话组成，可能无法提供有关代理的人物角色的全面描述，这对生成真正个性化的对话构成了挑战。为了解决这个问题，我们提出了 $\textbf{L}$earning Retrieval $\textbf{A}$ugmentation for $\textbf{P}$personalized $\textbf{D}$ial$\textbf{O}$gue $\textbf{G}$eneration ($\textbf{LAPDOG}$)，研究利用外部知识生成人物对话的潜力。具体来说，提出的 LAPDOG 模型由一个故事检索器和一个对话生成器组成。故事检索器使用给定的人物画像作为查询，从故事文档中检索相关信息，这些信息作为补充背景来增强人物画像。对话生成器利用对话历史和增强的人物画像来生成个性化响应。为了进行优化，我们采用了一个联合训练框架，该框架协同学习故事检索器和对话生成器，其中故事检索器针对所需的最终指标（例如 BLEU）进行优化，以检索对话生成器的内容以生成个性化响应。使用 ROCStory 作为补充数据源在 CONVAI2 数据集上进行的实验表明，所提出的 LAPDOG 方法大大优于基线，表明所提出方法的有效性。LAPDOG 模型代码已公开，可供进一步探索。https://github.com/hqsiswiliam/LAPDOG]]></description>
      <guid>https://arxiv.org/abs/2406.18847</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:18 GMT</pubDate>
    </item>
    <item>
      <title>尼日利亚皮钦语的隐性话语关系分类</title>
      <link>https://arxiv.org/abs/2406.18776</link>
      <description><![CDATA[arXiv:2406.18776v1 公告类型：新
摘要：尽管人们试图使大型语言模型支持多种语言，但世界上许多语言仍然严重缺乏资源。这扩大了针对资金充足的语言和针对资源较少语言的 NLP 和 AI 应用程序之间的性能差距。在本文中，我们重点关注尼日利亚皮钦语 (NP)，这种语言有近 1 亿人使用，但 NLP 资源和语料库相对较少。我们解决了隐式话语关系分类 (IDRC) 的任务，并系统地比较了将 NP 数据翻译成英语然后使用资源丰富的 IDRC 工具并反向投影标签的方法与为 NP 创建合成话语语料库的方法，其中我们翻译 PDTB 并投影 PDTB 标签，然后训练 NP IDR 分类器。后一种学习“本机” NP 分类器的方法在 4 路和 11 路分类的 f$_{1}$ 分数上分别比我们的基线高出 13.27% 和 33.98%。]]></description>
      <guid>https://arxiv.org/abs/2406.18776</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:17 GMT</pubDate>
    </item>
    <item>
      <title>网络安全中的心理分析：法学硕士和心理语言学特征概述</title>
      <link>https://arxiv.org/abs/2406.18783</link>
      <description><![CDATA[arXiv:2406.18783v1 公告类型：新
摘要：网络威胁日益复杂，需要创新的网络安全方法。在本文中，我们探讨了心理分析技术的潜力，特别关注大型语言模型 (LLM) 和心理语言学特征的利用。我们研究心理学与网络安全的交集，讨论如何使用 LLM 分析文本数据以识别威胁行为者的心理特征。我们探索将心理语言学特征（例如语言模式和情感线索）纳入网络安全框架。\iffalse 通过案例研究和实验，我们讨论了这些方法在增强威胁检测和缓解策略方面的有效性。\fi 我们的研究强调了将心理学观点融入网络安全实践以加强防御机制以应对不断发展的威胁的重要性。]]></description>
      <guid>https://arxiv.org/abs/2406.18783</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:17 GMT</pubDate>
    </item>
    <item>
      <title>逐步进行重新排序：研究使用大型语言模型进行重新排序的预过滤</title>
      <link>https://arxiv.org/abs/2406.18740</link>
      <description><![CDATA[arXiv:2406.18740v1 公告类型：新
摘要：大型语言模型 (LLM) 凭借其多样化的零样本能力彻底改变了无数自然语言处理任务。事实上，现有的工作已经表明，LLM 可以有效地用于许多任务，例如信息检索 (IR) 和段落排名。然而，目前最先进的结果在很大程度上依赖于所使用的 LLM 的能力。目前，专有和非常大的 LLM（例如 GPT-4）是性能最高的段落重新排序器。因此，没有资源利用顶级 LLM 或闭源 LLM 的用户处于劣势。在本文中，我们研究了在 IR 中段落重新排序之前使用预过滤步骤的情况。我们的实验表明，通过使用少量人工生成的相关性分数，再加上 LLM 相关性评分，可以在重新排名之前有效地过滤掉不相关的段落。我们的实验还表明，这种预过滤可以让 LLM 在重新排序任务中表现得更好。事实上，我们的结果表明，较小的模型（如 Mixtral）可以与更大的专有模型（例如 ChatGPT 和 GPT-4）相媲美。]]></description>
      <guid>https://arxiv.org/abs/2406.18740</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:16 GMT</pubDate>
    </item>
    <item>
      <title>重新审视范畴三段论：对法学硕士分析范畴三段论的逻辑推理能力的回顾</title>
      <link>https://arxiv.org/abs/2406.18762</link>
      <description><![CDATA[arXiv:2406.18762v1 公告类型：新
摘要：已经提出了大量基准来评估大型语言模型 (LLM) 在逻辑推理任务中的表现。然而，如何正确评估这种能力仍然是一个悬而未决的问题。在本文中，我们系统地概述了先前关于 LLM 用于分析分类三段论的逻辑推理能力的研究。我们首先从纯逻辑的角度研究分类三段论的所有可能变体，然后检查现有数据集测试的底层配置（即情绪和图形）。我们的结果表明，与基于模板的合成数据集相比，众包方法通常会牺牲分类三段论配置（即情绪和图形）的覆盖范围来获得更多的语言变化，从而给在不同情况下全面测试 LLM 带来挑战。然后，我们继续总结 LLM 性能的发现和观察结果，以从当前文献中推断三段论的有效性。错误率细分分析表明，量词的解释似乎是限制 LLM 性能的当前瓶颈，因此值得更多关注。最后，我们讨论了研究人员在计划未来发布分类三段论数据集时可能值得考虑的几点。我们希望我们的工作不仅能及时回顾当前关于分类三段论的文献，还能激发社区之间，特别是计算语言学家和逻辑学家之间的更多跨学科研究。]]></description>
      <guid>https://arxiv.org/abs/2406.18762</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:16 GMT</pubDate>
    </item>
    <item>
      <title>多语言协调棱镜：协调全球和本地偏好以减少伤害</title>
      <link>https://arxiv.org/abs/2406.18682</link>
      <description><![CDATA[arXiv:2406.18682v1 公告类型：新
摘要：“对齐”概念的一个关键问题是隐含的“对齐什么？”问题。人工智能系统在世界范围内的使用越来越多，但安全对齐通常集中在同质的单语设置上。此外，偏好训练和安全措施通常会过度拟合西方中心数据集中常见的危害。在这里，我们探讨了在平衡双重目标时不同对齐方法的可行性：解决和优化一组非同质的语言和文化偏好，同时最大限度地减少全球和本地危害。我们收集了第一组不同语言的人工注释红队提示，区分了全球和本地危害，这些提示可作为实验室，用于了解对齐技术在面对跨地域和语言的非平稳偏好分布时的可靠性。虽然迄今为止的文献很少涉及这种设置，主要集中在英语危害缓解上，但它捕捉了世界各地与人工智能系统的真实互动。我们开创了一项先例，在 6 种语言中实现了最先进的对齐技术，同时将总体性能的下降降到最低。我们的工作为跨语言迁移和新颖的优化方法提供了重要见解，以保护旨在服务全球人口的 AI 系统。]]></description>
      <guid>https://arxiv.org/abs/2406.18682</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:15 GMT</pubDate>
    </item>
    <item>
      <title>用于在线辩论分析的序列图网络</title>
      <link>https://arxiv.org/abs/2406.18696</link>
      <description><![CDATA[arXiv:2406.18696v1 公告类型：新
摘要：在线辩论涉及随时间动态交换思想，参与者需要积极考虑对手的论点，提出反驳，强化自己的观点，并在讨论展开时提出更有说服力的论点。对如此复杂的过程进行建模并非易事，因为它需要结合顺序特征和有效捕捉交互的能力。为了应对这一挑战，我们采用了序列图方法。将对话构建为图形使我们能够通过有向边有效地模拟参与者之间的交互。同时，以顺序方式沿这些边缘传播信息使我们能够捕获更全面的上下文表示。我们还引入了序列图注意层来说明所提出的信息更新方案。实验结果表明，序列图网络在在线辩论中取得了优于现有方法的效果。]]></description>
      <guid>https://arxiv.org/abs/2406.18696</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:15 GMT</pubDate>
    </item>
    <item>
      <title>评估语言模型的版权删除方法</title>
      <link>https://arxiv.org/abs/2406.18664</link>
      <description><![CDATA[arXiv:2406.18664v1 公告类型：新 
摘要：语言模型 (LM) 的能力源自对各种数据（包括可能受版权保护的材料）的广泛训练。这些模型可以记忆并生成与其训练数据类似的内容，这带来了潜在的担忧。因此，模型创建者有动力开发缓解方法来防止生成受保护的内容。我们将此过程称为 LM 的版权删除，并指出其概念上与 DMCA 删除相似（但在法律上有所区别）。本文首次介绍了对 LM 版权删除的可行性和副作用的评估。我们提出了 CoTaEval，这是一个评估框架，用于评估版权删除方法的有效性、对模型从被禁止朗诵的训练数据中保留不受版权保护的事实知识的能力的影响，以及模型如何保持其一般实用性和效率。我们研究了几种策略，包括添加系统提示、解码时间过滤干预和反学习方法。我们的研究结果表明，没有任何经过测试的方法在所有指标上都表现出色，这表明在这个独特的问题环境中还有很大的研究空间，也表明实时政策提案存在潜在的未解决的挑战。]]></description>
      <guid>https://arxiv.org/abs/2406.18664</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:14 GMT</pubDate>
    </item>
    <item>
      <title>了解 LLM 的需求：检索增强生成的双重偏好对齐</title>
      <link>https://arxiv.org/abs/2406.18676</link>
      <description><![CDATA[arXiv:2406.18676v1 公告类型：新
摘要：检索增强生成 (RAG) 已被证明可有效缓解大型语言模型 (LLM) 的幻觉问题。然而，将检索器与不同的 LLM 知识偏好进行对齐的难度不可避免地对开发可靠的 RAG 系统构成了不可避免的挑战。为了解决这个问题，我们提出了 DPA-RAG，这是一个通用框架，旨在在 RAG 系统内对齐不同的知识偏好。具体来说，我们首先引入了一个偏好知识构建管道，并结合了五种新颖的查询增强策略来缓解偏好数据稀缺问题。基于偏好数据，DPA-RAG 实现了外部和内部偏好对齐：1) 它将成对、逐点和对比偏好对齐能力联合集成到重新排序器中，实现 RAG 组件之间的外部偏好对齐。 2) 它进一步在 vanilla Supervised Fine-tuning (SFT) 之前引入了一个预对齐阶段，使 LLM 能够隐式捕获与其推理偏好一致的知识，从而实现 LLM 的内部对齐。在四个知识密集型 QA 数据集上的实验结果表明，DPA-RAG 优于所有基线，并无缝集成了黑盒和开源 LLM 读取器。进一步的定性分析和讨论也为实现可靠的 RAG 系统提供了实证指导。我们的代码可在 https://github.com/dongguanting/DPA-RAG 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2406.18676</guid>
      <pubDate>Fri, 28 Jun 2024 06:19:14 GMT</pubDate>
    </item>
    </channel>
</rss>