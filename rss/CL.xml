<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 19 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>上下文学习蒸馏，实现高效的小样本微调</title>
      <link>https://arxiv.org/abs/2412.13243</link>
      <description><![CDATA[arXiv:2412.13243v1 公告类型：新
摘要：我们在自然语言推理任务的 OPT-1.3B 模型上应用了少样本上下文学习，并使用知识蒸馏来内化上下文信息，将模型参数从 1.3B 减少到 125M，并将大小从 2.5GB 减少到 0.25GB。与在类似大小的模型上单独使用上下文学习相比，这种上下文蒸馏方法实现了域外准确率的近 50% 的提高，展示了优于基于提示的方法的知识迁移能力。此外，与传统的基于模式的微调相比，这种方法将内存消耗降低了 60%，同时将域外准确率提高了 20%。]]></description>
      <guid>https://arxiv.org/abs/2412.13243</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>增强对话系统中的人物角色分类：图神经网络方法</title>
      <link>https://arxiv.org/abs/2412.13283</link>
      <description><![CDATA[arXiv:2412.13283v1 公告类型：新
摘要：近年来，大型语言模型 (LLM) 因其在虚拟助手和聊天机器人中增强个性化体验的潜力而备受关注。一个关键的兴趣领域是将角色集成到 LLM 中以提高对话的自然度和用户参与度。本研究通过提出一个将文本嵌入与图神经网络 (GNN) 相结合的框架来实现有效的角色分类，解决了角色分类（对话理解的重要组成部分）的挑战。鉴于缺乏专门的角色分类数据集，我们创建了一个手动注释的数据集以促进模型训练和评估。我们的方法包括使用文本嵌入从角色陈述中提取语义特征并构建一个图，其中节点代表角色，边捕获它们的相似性。GNN 组件使用此图结构传播相关信息，从而提高分类性能。实验结果表明，我们的方法，特别是 GNN 的集成，显着提高了分类性能，尤其是在数据有限的情况下。我们的贡献包括开发角色分类框架和创建数据集。]]></description>
      <guid>https://arxiv.org/abs/2412.13283</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>提示边缘化可提高大型语言模型的推理能力</title>
      <link>https://arxiv.org/abs/2412.13292</link>
      <description><![CDATA[arXiv:2412.13292v1 公告类型：新
摘要：大型语言模型 (LLM) 表现出了执行推理任务的令人印象深刻的能力，特别是如果鼓励它们生成一系列中间步骤。通过适当组合多个 LLM 响应（在单个查询中并行生成，或在整个推理过程中通过与 LLM 的顺序交互生成），可以提高推理性能。现有的组合策略（例如自洽和渐进提示提示）使 LLM 响应的使用效率低下。我们提出了提示边缘化，这是一种新颖且有原则的算法框架，可增强 LLM 的推理能力。我们的方法可以看作是一种迭代采样策略，用于形成答案底层分布的蒙特卡罗近似，目的是确定最有可能的答案模式。对几个算术推理基准数据集的实证评估证明了所提出方法的优越性。]]></description>
      <guid>https://arxiv.org/abs/2412.13292</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>扩展跨度：在混合状态空间模型中结合衰减记忆和检索</title>
      <link>https://arxiv.org/abs/2412.13328</link>
      <description><![CDATA[arXiv:2412.13328v1 公告类型：新
摘要：状态空间模型 (SSM) 的“状态”代表其记忆，记忆会在无限的跨度内呈指数级消退。相比之下，基于注意力的模型在有限跨度（上下文大小）内具有“图像记忆”（即逐字或照相）记忆。混合架构将状态空间层与注意力相结合，但仍然无法回忆遥远的过去，并且只能图像记忆地访问最近的标记。与当前结合 SSM 和注意力层的方法不同，我们允许根据相关性而不是新近性来分配状态。通过这种方式，对于每一组新的查询标记，我们的模型都可以“图像记忆地”访问当前混合 SSM 的注意力跨度之外的标记，而无需额外的硬件资源。我们描述了一种扩展混合状态记忆跨度的方法，即通过“保留”部分注意力上下文来检索从过去任意远的标记，从而扩展整体状态的记忆跨度。我们将这个保留的标记部分称为“扩展跨度”，检索和聚合它的机制称为“跨度扩展注意力”（SE-Attn）。为了使混合模型适应使用 SE-Attn，我们提出了一种新颖的微调方法，将 LoRA 扩展到混合模型（HyLoRA），并允许对长跨度的标记进行有效调整。我们表明，SE-Attn 使我们能够有效地将预训练的混合模型适应比预训练所用序列长 8 倍的标记序列。我们表明，当将带有 SE-Attn 的 HyLoRA 应用于具有长距离依赖关系的自然语言基准测试（例如 PG-19、RULER 和其他常见的自然语言下游任务）上的混合模型时，与 LongLoRA 等替代方案相比，它更便宜、性能更高。]]></description>
      <guid>https://arxiv.org/abs/2412.13328</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从头开始训练 1.7B 参数 LLaMa 模型的经验</title>
      <link>https://arxiv.org/abs/2412.13335</link>
      <description><![CDATA[arXiv:2412.13335v1 公告类型：新
摘要：对大型语言模型进行预训练是一项复杂的工作，受多种因素影响，包括模型架构、数据质量、训练连续性和硬件限制。在本文中，我们分享了在大约 200 亿个精心策划的数据上训练 DMaS-LLaMa-Lite（一个完全开源的、17 亿个参数的基于 LLaMa 的模型）的经验所获得的见解。我们记录了完整的训练轨迹，记录了不断变化的验证损失水平和下游基准如何反映从不连贯的文本到流畅的、基于上下文的输出的转变。除了标准的定量指标之外，我们还强调了一些实际考虑因素，例如从检查点恢复时恢复优化器状态的重要性，以及硬件变化对训练稳定性和吞吐量的影响。虽然定性评估提供了对模型改进的直观理解，但我们的分析扩展到各种性能基准，展示了高质量数据和深思熟虑的扩展如何以更少的训练令牌实现具有竞争力的结果。通过详细介绍这些经验并提供训练日志、检查点和示例输出，我们旨在指导未来的研究人员和从业者完善他们的预训练策略。训练脚本可在 Github 上找到，网址为 https://github.com/McGill-DMaS/DMaS-LLaMa-Lite-Training-Code。模型检查点可在 Huggingface 上找到，网址为 https://huggingface.co/collections/McGill-DMaS/dmas-llama-lite-6761d97ba903f82341954ceb。]]></description>
      <guid>https://arxiv.org/abs/2412.13335</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>将法学硕士课程扩展到新语言：骆驼语和波斯语改编案例研究</title>
      <link>https://arxiv.org/abs/2412.13375</link>
      <description><![CDATA[arXiv:2412.13375v1 公告类型：新
摘要：大型语言模型 (LLM) 在分类和文本生成任务方面取得了巨大进展。然而，它们主要在英语数据上进行训练，并且经常难以处理资源匮乏的语言。在这项研究中，我们探索使用参数高效的微调将一种新语言（即波斯语）添加到 Llama（一种对波斯语理解有限的模型）中。我们采用多阶段方法，包括在单语波斯语数据上进行预训练、通过双语预训练和指令数据集对齐表示以及使用特定于任务的数据集进行指令调整。我们评估模型在生成和分类任务中每个阶段的性能。我们的研究结果表明，通过双语数据对齐加入波斯语可以提高波斯语任务的分类准确性，而不会对英语任务产生不利影响，有时甚至会有所改善。此外，结果还强调，在处理有限的训练数据时，模型的初始强度是一个关键因素，跨语言对齐对资源匮乏的语言的益处微乎其微。从英语到波斯语的知识转移效果不大，主要有利于简单的分类任务。]]></description>
      <guid>https://arxiv.org/abs/2412.13375</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DateLogicQA：对大型语言模型中的时间偏差进行基准测试</title>
      <link>https://arxiv.org/abs/2412.13377</link>
      <description><![CDATA[arXiv:2412.13377v1 公告类型：新
摘要：本文介绍了 DateLogicQA，这是一个包含 190 个问题的基准，涵盖各种日期格式、时间背景和推理类型。我们提出了语义完整性度量来评估标记化质量并分析两种偏差：影响嵌入的表示级偏差和影响推理输出的逻辑级偏差。我们的研究结果对 LLM 在时间推理方面的能力和局限性进行了全面评估，突出了准确处理时间数据的关键挑战。我们工作的 GitHub 存储库位于 https://github.com/gagan3012/EAIS-Temporal-Bias]]></description>
      <guid>https://arxiv.org/abs/2412.13377</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SummExecEdit：可执行编辑摘要中的事实一致性基准</title>
      <link>https://arxiv.org/abs/2412.13378</link>
      <description><![CDATA[arXiv:2412.13378v1 公告类型：新
摘要：检测摘要中的事实不一致至关重要，但现有的基准测试缺乏进行稳健评估所需的挑战性和可解释性。在本文中，我们介绍了 SummExecEdit，这是一种利用可执行编辑来评估模型检测事实错误和提供准确解释的能力的新型基准测试。在我们的基准测试中，表现最佳的模型 Claude3-Opus 的联合检测和解释得分仅为 0.49，检测得分为 0.67，解释得分为 0.73。此外，我们确定了四种主要类型的解释错误，其中 45.4% 的错误集中在摘要中完全不相关的部分。]]></description>
      <guid>https://arxiv.org/abs/2412.13378</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于法学硕士 (LLM) 的自动化可解释教育评估系统</title>
      <link>https://arxiv.org/abs/2412.13381</link>
      <description><![CDATA[arXiv:2412.13381v1 公告类型：新
摘要：在此演示中，我们展示了 AERA Chat，这是一种自动化且可解释的教育评估系统，旨在对学生的回答进行交互式和视觉评估。该系统利用大型语言模型 (LLM) 生成自动标记和理由解释，解决了自动教育评估中可解释性有限的挑战以及与注释相关的高成本。我们的系统允许用户输入问题和学生答案，为教育工作者和研究人员提供有关评估准确性和 LLM 评估理由质量的见解。此外，它还提供高级可视化和强大的评估工具，增强了教育评估的可用性并促进了有效的理由验证。我们的演示视频可以在 https://youtu.be/qUSjz-sxlBc 找到。]]></description>
      <guid>https://arxiv.org/abs/2412.13381</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过课堂教学话语加强数学教学中的话语动作分析</title>
      <link>https://arxiv.org/abs/2412.13395</link>
      <description><![CDATA[arXiv:2412.13395v1 公告类型：新
摘要：人类辅导干预在支持学生学习、提高学业成绩和促进个人成长方面发挥着至关重要的作用。本文重点使用谈话动作分析数学辅导话语 - 一个以负责任谈话理论为基础的对话行为框架。然而，扩大广泛辅导对话的收集、注释和分析以开发机器学习模型是一项具有挑战性且资源密集型的任务。为了解决这个问题，我们提出了一个紧凑的数据集 SAGA22，并探索了各种建模策略，包括对话上下文、说话者信息、预训练数据集和进一步微调。通过利用现有的为课堂教学设计的数据集和模型，我们的结果表明，对课堂数据进行补充预训练可以提高模型在辅导环境中的性能，特别是在结合更长的上下文和说话者信息时。此外，我们进行了广泛的消融研究，以强调谈话动作建模中的挑战。]]></description>
      <guid>https://arxiv.org/abs/2412.13395</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用精简语言模型进行轻量级安全分类</title>
      <link>https://arxiv.org/abs/2412.13435</link>
      <description><![CDATA[arXiv:2412.13435v1 公告类型：新 
摘要：在本文中，我们介绍了一种用于大型语言模型的内容安全和即时注入分类的新技术。我们的技术，层增强分类 (LEC)，在 LLM 最佳中间 Transformer 层的隐藏状态下训练惩罚逻辑回归 (PLR) 分类器。通过将精简的 PLR 分类器的计算效率与 LLM 的复杂语言理解相结合，我们的方法提供了超越 GPT-4o 和针对每个任务进行微调的专用模型的卓越性能。我们发现小型通用模型（Qwen 2.5 大小 0.5B、1.5B 和 3B）和其他基于 Transformer 的架构（如 DeBERTa v3）是强大的特征提取器，允许在少于 100 个高质量示例上有效地训练简单的分类器。重要的是，这些模型的中间 Transformer 层通常在两个分类任务中都优于最后一层。我们的结果表明，单个通用 LLM 可用于对内容安全性进行分类、检测即时注入并同时生成输出标记。或者，这些相对较小的 LLM 可以修剪到最佳中间层并专门用作稳健的特征提取器。由于我们的结果在不同的 Transformer 架构上是一致的，因此我们推断，稳健的特征提取是大多数（如果不是全部）LLM 的固有功能。]]></description>
      <guid>https://arxiv.org/abs/2412.13435</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从统计和多角度重新审视大型语言模型中的成员推理攻击</title>
      <link>https://arxiv.org/abs/2412.13475</link>
      <description><![CDATA[arXiv:2412.13475v1 公告类型：新
摘要：大型语言模型 (LLM) 缺乏数据透明度，凸显了成员推理攻击 (MIA) 的重要性，它可以区分经过训练的（成员）和未经训练的（非成员）数据。尽管它在之前的研究中显示出成功，但最近的研究报告在不同设置下的表现接近随机，突出了显著的性能不一致。我们假设单一设置不能代表庞大语料库的分布，导致具有不同分布的成员和非成员被采样并导致不一致。在本研究中，我们不是单一设置，而是从统计上重新审视来自各种设置的 MIA 方法，对每种 MIA 方法进行数千次实验，同时研究成员和非成员的文本特征、嵌入、阈值决策和解码动态。我们发现：（1）MIA 性能随着模型大小的提高而提高，并且因领域而异，而大多数方法在统计上并不优于基线；（2）虽然 MIA 性能通常较低，但存在大量可区分的成员和非成员异常值，并且因 MIA 方法而异；（3）确定分离成员和非成员的阈值是一个被忽视的挑战；（4）文本差异和长文本有利于 MIA 性能；（5）是否可区分反映在 LLM 嵌入中；（6）成员和非成员表现出不同的解码动态。]]></description>
      <guid>https://arxiv.org/abs/2412.13475</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用噪声数据进行跨语言数据到文本生成的课程学习</title>
      <link>https://arxiv.org/abs/2412.13484</link>
      <description><![CDATA[arXiv:2412.13484v1 公告类型：新
摘要：课程学习已用于通过按照各种任务中的特定时间表对训练样本进行排序来提高文本生成系统的质量。在数据到文本生成 (DTG) 的背景下，先前的研究使用各种难度标准来对单语 DTG 的训练样本进行排序。然而，这些标准并不适用于问题的跨语言变体，也不考虑噪声数据。我们探索了多种标准，这些标准可用于使用两个课程表来提高具有噪声数据的跨语言 DTG 系统的性能。使用对齐分数标准对样本进行排序并使用退火计划来训练模型，我们发现 BLEU 分数提高了 4 分，并且在 2 个独立数据集中 11 种印度语言和英语的代际忠实度和覆盖率平均提高了 5-15%。我们公开提供代码和数据]]></description>
      <guid>https://arxiv.org/abs/2412.13484</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>完善语言模型的显著性感知稀疏微调策略</title>
      <link>https://arxiv.org/abs/2412.13488</link>
      <description><![CDATA[arXiv:2412.13488v1 公告类型：新
摘要：参数高效微调 (PEFT) 通过 LoRA 等低秩自适应方法而备受关注。在本文中，我们重点介绍基于稀疏性的 PEFT (SPEFT)，它为模型中的权重矩阵引入了可训练的稀疏自适应，与低秩方法相比，在选择微调参数方面提供了更大的灵活性。受零成本 NAS 代理的启发，我们对 SPEFT 的显着性指标进行了首次系统评估，并确定简单的基于梯度的指标是可靠的，结果与最佳替代方案相当，既提供计算效率又提供稳健的性能。此外，我们比较了静态和动态掩码策略，发现静态掩码（在训练前预先确定非零条目）可以在不牺牲性能的情况下提供效率，而动态掩码没有带来实质性的好处。在 NLP 任务中，简单的基于梯度的静态 SPEFT 始终优于其他 LLM 微调方法，为 SPEFT 提供了简单而有效的基线。我们的工作挑战了复杂性是有效 PEFT 的必要条件这一观念。我们的工作是开源的，可在 [https://github.com/0-ml/speft] 上供社区使用。]]></description>
      <guid>https://arxiv.org/abs/2412.13488</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VaeDiff-DocRE：用于文档级关系提取的端到端数据增强框架</title>
      <link>https://arxiv.org/abs/2412.13503</link>
      <description><![CDATA[arXiv:2412.13503v1 公告类型：新
摘要：文档级关系提取 (DocRE) 旨在识别文档内实体对之间的关​​系。然而，大多数现有方法都假设标签分布均匀，导致在现实世界中不平衡的数据集上性能不佳。为了应对这一挑战，我们提出了一种新颖的数据增强方法，使用生成模型来增强来自嵌入空间的数据。我们的方法利用变分自动编码器 (VAE) 架构来捕获由实体对表示形成的所有关系分布，并为代表性不足的关系增强数据。为了更好地捕捉 DocRE 的多标签特性，我们使用扩散模型参数化 VAE 的潜在空间。此外，我们引入了一个分层训练框架，将提出的基于 VAE 的增强模块集成到 DocRE 系统中。在两个基准数据集上的实验表明，我们的方法优于最先进的模型，有效地解决了 DocRE 中的长尾分布问题。]]></description>
      <guid>https://arxiv.org/abs/2412.13503</guid>
      <pubDate>Thu, 19 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>