<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 18 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>检索增强生成 (RAG) 的全面概述：演变、现状和未来方向</title>
      <link>https://arxiv.org/abs/2410.12837</link>
      <description><![CDATA[arXiv:2410.12837v1 公告类型：新
摘要：本文对检索增强生成 (RAG) 进行了全面研究，追溯了其从基础概念到当前最先进的发展历程。RAG 将检索机制与生成语言模型相结合，以提高输出的准确性，解决 LLM 的主要局限性。该研究探讨了 RAG 的基本架构，重点研究了如何集成检索和生成来处理知识密集型任务。本文详细回顾了 RAG 的重大技术进步，包括检索增强语言模型的关键创新以及在问答、总结和基于知识的任务等各个领域的应用。本文讨论了最近的研究突破，重点介绍了提高检索效率的新方法。此外，本文还研究了部署中的可扩展性、偏见和道德问题等持续存在的挑战。提出了未来的研究方向，重点是提高 RAG 模型的稳健性、扩大 RAG 模型的应用范围以及解决社会影响。本调查旨在为研究人员和从业者提供基础资源，帮助他们了解 RAG 的潜力及其在自然语言处理中的发展轨迹。]]></description>
      <guid>https://arxiv.org/abs/2410.12837</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>捕捉法学硕士中的偏见多样性</title>
      <link>https://arxiv.org/abs/2410.12839</link>
      <description><![CDATA[arXiv:2410.12839v1 公告类型：新
摘要：本文介绍了通过增加其生成输出的多样性来增强大型语言模型 (LLM) 的研究。我们的研究引入了多个 LLM 的配置，展示了单个 LLM 能够实现的多样性。通过开发 GPT 模型的多个定制实例，每个实例都反映了特定人口统计特征（包括性别、年龄和种族）的偏见，我们提出、开发和评估了一个更细致入微、更具代表性的 AI 对话框架，我们称之为 BiasGPT。定制的 GPT 模型最终将进行协作，将他们对某个主题的不同观点融合成一个综合的响应，以捕捉广泛的人类经验和观点。在本文中，通过实验，我们展示了 GPT 模型嵌入不同偏见的能力，这些偏见结合起来，可以开启更具包容性的 AI 技术的可能性。]]></description>
      <guid>https://arxiv.org/abs/2410.12839</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分阶段回答问题：合同 QA 的提示链</title>
      <link>https://arxiv.org/abs/2410.12840</link>
      <description><![CDATA[arXiv:2410.12840v1 公告类型：新
摘要：寻找有关合同条款的法律问题的答案是许多法律工作流程（例如，了解市场趋势、尽职调查、风险缓解）中的重要分析形式，但更重要的是能够大规模地做到这一点。先前的研究表明，可以使用带有简单零样本提示的大型语言模型来生成问题的结构化答案，这些答案稍后可以纳入法律工作流程。这种提示虽然对简单明了的条款有效，但当条款很长且包含与问题无关的信息时，就会失效。在本文中，我们提出了两阶段提示链来为多项选择题和多项选择题提供结构化的答案，并表明它们比简单提示在更细致入微的法律文本上更有效。我们分析了这种技术效果良好的情况以及需要进一步改进的领域，尤其是当底层语言变化超过仅通过指定可能的答案就可以捕捉到的程度时。最后，我们讨论了未来的研究，旨在通过改善第一阶段的结果使其更针对问题来完善这项工作。]]></description>
      <guid>https://arxiv.org/abs/2410.12840</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>UniAutoML：以人为本的大型语言模型统一判别和生成 AutoML 框架</title>
      <link>https://arxiv.org/abs/2410.12841</link>
      <description><![CDATA[arXiv:2410.12841v1 公告类型：新
摘要：自动机器学习 (AutoML) 简化了复杂的 ML 流程，例如数据预处理、模型选择和超参数搜索。然而，传统的 AutoML 框架仅专注于判别性任务，在处理生成模型的 AutoML 时往往力不从心。此外，这些框架在训练过程中缺乏可解释性和用户参与度，这主要是由于缺乏以人为本的设计。这导致最终决策缺乏透明度和用户控制有限，从而可能降低对 AutoML 方法的信任和采用。为了解决这些限制，我们引入了 UniAutoML，这是一个以人为本的 AutoML 框架，它利用大型语言模型 (LLM) 将 AutoML 统一用于判别性（例如，用于分类或回归任务的 Transformers 和 CNN）和生成性任务（例如，微调扩散模型或 LLM）。 UniAutoML 以人为本的设计创新地采用了对话式用户界面 (CUI)，促进了自然语言交互，为用户提供实时指导、反馈和进度更新，以提高可解释性。这种设计增强了整个 AutoML 训练过程的透明度和用户控制，使用户可以无缝分解或修改正在训练的模型。为了减轻与 LLM 生成内容相关的潜在风险，UniAutoML 采用了一条安全防护线，可以过滤输入并审查输出。我们通过对八个不同数据集的实验和涉及 25 名参与者的用户研究评估了 UniAutoML 的性能和可用性，结果表明 UniAutoML 不仅提高了性能，还提高了用户控制和信任度。我们以人为本的设计弥合了 AutoML 功能与用户理解之间的差距，使 ML 更容易被更广泛的受众所接受。]]></description>
      <guid>https://arxiv.org/abs/2410.12841</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>幽默风格识别的双模型方法</title>
      <link>https://arxiv.org/abs/2410.12842</link>
      <description><![CDATA[arXiv:2410.12842v1 公告类型：新
摘要：幽默是人类交流的一个基本方面，它以各种风格表现出来，对社交互动和心理健康有重大影响。由于缺乏成熟的数据集和机器学习 (ML) 模型，识别不同的幽默风格具有挑战性。为了解决这一差距，我们提出了一个新的幽默风格识别文本数据集，包含四种风格（自我提升、自我贬低、亲和性和攻击性）和非幽默文本的 1463 个实例，长度从 4 到 229 个字不等。我们的研究采用了各种计算方法，包括经典机器学习分类器、文本嵌入模型和 DistilBERT，以建立基线性能。此外，我们提出了一种双模型方法来增强幽默风格识别，特别是在区分亲和性和攻击性风格方面。我们的方法显示，关联性幽默分类的 f1 分数提高了 11.61%，并且在测试的 14 个模型中都得到了持续改进。我们的发现有助于对文本中的幽默进行计算分析，为研究文学、社交媒体和其他文本来源中的幽默提供了新工具。]]></description>
      <guid>https://arxiv.org/abs/2410.12842</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索快速工程：基于 SWOT 分析的系统评价</title>
      <link>https://arxiv.org/abs/2410.12843</link>
      <description><![CDATA[arXiv:2410.12843v1 公告类型：新
摘要：在本文中，我们对大型语言模型 (LLM) 领域的提示工程技术进行了全面的 SWOT 分析。我们强调语言学原理，研究各种技术以确定它们的优势、劣势、机会和威胁。我们的研究结果为增强人工智能交互和提高语言模型对人类提示的理解提供了见解。分析涵盖了包括基于模板的方法和微调在内的技术，解决了与每种方法相关的问题和挑战。结论提供了未来的研究方向，旨在提高提示工程在优化人机通信方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2410.12843</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>TextLap：定制用于文本到布局规划的语言模型</title>
      <link>https://arxiv.org/abs/2410.12844</link>
      <description><![CDATA[arXiv:2410.12844v1 公告类型：新
摘要：图形布局的自动生成对于许多实际应用至关重要，包括设计海报、传单、广告和图形用户界面。鉴于大型语言模型 (LLM) 在自然语言理解和生成方面的惊人能力，我们相信我们可以定制一个 LLM，以帮助人们从用户的文本指令开始创建引人注目的图形布局。我们将我们的方法称为 TextLap（基于文本的布局规划）。它使用精选的基于指令的布局规划数据集 (InsLap) 来定制 LLM 作为图形设计师。我们证明了 TextLap 的有效性，并表明它在图像生成和图形设计基准方面优于强大的基线，包括基于 GPT-4 的方法。]]></description>
      <guid>https://arxiv.org/abs/2410.12844</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用中期医院数据自动生成进度记录，减轻临床医生负担</title>
      <link>https://arxiv.org/abs/2410.12845</link>
      <description><![CDATA[arXiv:2410.12845v1 公告类型：新
摘要：定期记录进度记录是增加临床医生负担的主要原因之一。医疗记录中大量的结构化图表信息进一步加剧了负担，然而，它也为自动生成进度记录提供了机会。在本文中，我们提出了一项任务，使用电子健康记录中存在的结构化或表格信息自动生成进度记录。为此，我们为该任务提出了一个新颖的框架和一个大型数据集 ChartPNG，其中包含 1616 名患者的 7089 个注释实例（每个实例都有一对进度记录和临时结构化图表数据）。我们使用来自一般和生物医学领域的大型语言模型在数据集上建立基线。我们执行自动（其中表现最佳的 Biomistral 模型实现了 BERTScore F1 为 $80.53$ 和 MEDCON 得分为 $19.61$）和手动（我们发现该模型能够利用相关结构化数据，准确率为 $76.9\%$）分析，以确定所提议任务的挑战和未来研究的机会。]]></description>
      <guid>https://arxiv.org/abs/2410.12845</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于表格问答的准确且具有遗憾意识的数值问题求解器</title>
      <link>https://arxiv.org/abs/2410.12846</link>
      <description><![CDATA[arXiv:2410.12846v1 公告类型：新 
摘要：由于表格结构灵活、模式复杂，自由格式表格（又名 TableQA）的问答是一项具有挑战性的任务。最近的研究使用大型语言模型 (LLM) 来完成这项任务，利用它们理解问题和表格数据的能力，这些问题和表格数据通常以自然语言给出，并分别包含许多文本字段。虽然这种方法已经显示出有希望的结果，但它忽略了表格数据中常见的数值带来的挑战，而众所周知，LLM 很难处理这样的值。我们的目标是解决这个问题并回答数字问题。我们提出了一个名为 TabLaP 的模型，它使用 LLM 作为规划器而不是答案生成器，利用 LLM 在多步推理中的能力，同时将实际的数值计算留给 Python 解释器进行精确计算。认识到 LLM 的不准确性，我们进一步首次尝试量化 TabLaP 生成的答案的可信度，以便用户可以以后悔的方式使用 TabLaP。在两个基准数据集上的实验结果表明，TabLaP 的准确度明显高于最先进的模型，在两个数据集上分别将答案准确率提高了 5.7% 和 5.8%。]]></description>
      <guid>https://arxiv.org/abs/2410.12846</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>接受：用于复合高效快速调整的自适应码本</title>
      <link>https://arxiv.org/abs/2410.12847</link>
      <description><![CDATA[arXiv:2410.12847v1 公告类型：新 
摘要：提示调整是一种流行的参数高效微调方法，这归功于它在各种大规模预训练语言模型 (PLM) 上只需很少的更新参数就能获得出色的性能。传统上，每个提示都被认为是不可分割的并独立更新，导致参数随着提示长度的增加而按比例增加。为了解决这个问题，我们提出了用于复合高效提示调整的自适应码本 (ACCEPT)。在我们的方法中，我们参考了乘积量化 (PQ) 的概念，允许所有软提示在每个子空间中共享一组可学习的码本向量，每个提示由一组自适应权重区分。我们仅通过调整 PLM 的 0.3% 参数，就在 17 种不同的自然语言任务（包括自然语言理解 (NLU) 和问答 (QA) 任务）上实现了卓越的性能。我们的方法在小样本和大型模型设置中也表现出色，凸显了其巨大的潜力。]]></description>
      <guid>https://arxiv.org/abs/2410.12847</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>及时设计精神分裂症聊天机器人：利用多智能体方法增强及时指令的遵守能力</title>
      <link>https://arxiv.org/abs/2410.12848</link>
      <description><![CDATA[arXiv:2410.12848v1 公告类型：新
摘要：患有精神分裂症的患者通常表现出认知障碍，这可能会妨碍他们了解自己病情的能力。这些人可以从利用 GPT-4 等大型语言模型 (LLM) 的适应性的教育平台中受益匪浅。虽然 LLM 有可能使主题心理健康信息更易于访问和吸引人，但它们的黑箱性质引发了对道德和安全的担忧。提示提供了一种生成半脚本聊天机器人的方法，其响应以指令和经过验证的信息为基础，但提示设计的聊天机器人可能会随着对话的进行而偏离其预期的身份。我们提出了一个关键分析过滤器，以更好地控制聊天机器人的行为。在这个系统中，一组提示的 LLM 代理经过提示设计，以批判性地分析和改进聊天机器人的响应并向聊天机器人提供实时反馈。为了测试这种方法，我们开发了一个信息性精神分裂症聊天机器人并与其交谈（过滤器停用），直到它超出其范围。一旦观察到偏差，就会使用 AI 代理自动生成示例对话，其中聊天机器人被诱导谈论超出范围的话题。我们手动为每个响应分配一个合规分数，以量化聊天机器人对其指令的遵守情况；特别是关于准确传达来源和透明限制的规则。激活批判性分析过滤器后，67.0% 的响应获得了可接受的合规分数（&gt;=2），而过滤器停用时只有 8.7%。这些结果表明，自我反思层可以使 LLM 有效安全地用于心理健康平台，保持适应性，同时可靠地将其范围限制在适当的用例中。]]></description>
      <guid>https://arxiv.org/abs/2410.12848</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RecurFormer：并非所有 Transformer 头都需要自我注意力</title>
      <link>https://arxiv.org/abs/2410.12850</link>
      <description><![CDATA[arXiv:2410.12850v1 公告类型：新
摘要：基于 Transformer 的大型语言模型 (LLM) 在建模复杂语言模式方面表现出色，但在推理过程中面临着巨大的计算成本，尤其是在输入较长的情况下，这是由于注意力机制的内存开销造成的。我们观察到某些注意力头表现出一种分布，其中注意力权重集中在查询标记附近的标记上，称为新近度感知，它关注局部和短距离依赖关系。利用这一见解，我们提出了 RecurFormer，这是一种新颖的架构，它用线性循环神经网络 (RNN)（特别是 Mamba 架构）取代这些注意力头。这种替换可以在不驱逐标记的情况下减少缓存大小，从而保持生成质量。RecurFormer 保留了通过剩余的注意力头建模长距离依赖关系的能力，并允许通过持续训练重用预先训练的基于 Transformer 的 LLM 权重。实验表明，RecurFormer 与原始模型的性能相匹配，同时显着提高了推理效率。我们的方法为基于 Transformer 的 LLM 推理的计算挑战提供了实用的解决方案，使其对于涉及长输入的任务具有很强的吸引力。]]></description>
      <guid>https://arxiv.org/abs/2410.12850</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>VibeCheck：发现并量化大型语言模型中的定性差异</title>
      <link>https://arxiv.org/abs/2410.12851</link>
      <description><![CDATA[arXiv:2410.12851v1 公告类型：新
摘要：大型语言模型 (LLM) 的输出通常会表现出微妙而独特的特征，用户可以直观地识别这些特征，但很难量化。这些“氛围”——例如语气、格式或写作风格——会影响用户偏好，但传统的评估主要关注正确性的单一轴。我们引入了 VibeCheck，这是一个通过发现模型的识别特征（“氛围”）来自动比较一对 LLM 的系统，这些特征定义明确、有区别且与用户一致。VibeCheck 会迭代地从模型输出中发现氛围，然后利用一组 LLM 评委来定量衡量每种氛围的效用。我们验证 VibeCheck 生成的氛围与人类发现中发现的氛围一致，并使用 llama-3-70b VS GPT-4 对来自真实用户对话的成对偏好数据运行 VibeCheck。 VibeCheck 发现 Llama 给人一种友好、有趣且有些争议的感觉。这些感觉预测模型身份的准确率为 80%，预测人类偏好的准确率为 61%。最后，我们对各种模型和任务（包括总结、数学和字幕）运行 VibeCheck，以深入了解模型行为的差异。我们发现的一些感觉是，与 TNGL 相比，Command X 在总结时更喜欢添加具体的介绍和结论；与 GPT-4o 相比，Llama-405b 经常过度解释其在数学问题上的思维过程；与 Gemini-1.5-Flash 相比，GPT-4 在字幕时更喜欢关注场景的情绪和情感。]]></description>
      <guid>https://arxiv.org/abs/2410.12851</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型 GreekLegalRoBERTa</title>
      <link>https://arxiv.org/abs/2410.12852</link>
      <description><![CDATA[arXiv:2410.12852v1 公告类型：新
摘要：我们开发了四个版本的 GreekLegalRoBERTa，它们是四个针对希腊法律和非法律文本进行训练的大型语言模型。我们表明，我们的模型在涉及希腊法律文件的两项任务中的表现超过了 GreekLegalBERT、Greek-LegalBERT-v2 和 GreekBERT：命名实体识别和多类法律主题分类。我们认为我们的工作是对使用现代 NLP 技术和方法研究希腊语等低资源语言领域特定 NLP 任务的贡献。]]></description>
      <guid>https://arxiv.org/abs/2410.12852</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>思想多样性在多智能体辩论框架中激发更强的推理能力</title>
      <link>https://arxiv.org/abs/2410.12853</link>
      <description><![CDATA[arXiv:2410.12853v1 公告类型：新 
摘要：大型语言模型 (LLM) 在自然语言生成方面表现出色，但经常会自信地产生错误的反应，尤其是在数学推理等任务中。思路提示、自我验证和多智能体辩论是提出的提高 LLM 推理和事实准确性的策略之一。基于 Du 等人的多智能体辩论框架，我们发现多智能体辩论在任何模型规模上都有帮助，并且思维的多样性会在辩论 LLM 中引发更强的推理。在各种模型大小中，当使用多样化的训练模型时，数学推理任务的性能受益最大。值得注意的是，经过 4 轮辩论后，一组多样化的中等容量模型（Gemini-Pro、Mixtral 7BX8 和 PaLM 2-M）在 GSM-8K 基准上的表现优于 GPT-4，准确率达到 91%。相比之下，当使用 3 个 Gemini-Pro 实例时，性能仅达到 82%。最后，这组多样化的中等容量模型在 ASDiv 基准上创下了新的最先进性能（94%）。这些结果强调了这样一种观点，即人工智能的未来是代理性的，各种合作的代理产生的新兴能力甚至超越了最强大的单个模型。]]></description>
      <guid>https://arxiv.org/abs/2410.12853</guid>
      <pubDate>Fri, 18 Oct 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>