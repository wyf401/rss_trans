<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 10 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>利用大型语言模型解决罕见的 MIP 挑战</title>
      <link>https://arxiv.org/abs/2409.04464</link>
      <description><![CDATA[arXiv:2409.04464v1 公告类型：新 
摘要：混合整数规划 (MIP) 已广泛应用于需要数学求解器在严格时间限制内解决复杂实例的领域。然而，随着问题规模的增加，模型制定和寻找可行解决方案的复杂性显著增加。相比之下，端到端模型（例如大型语言模型 (LLM)）的模型构建成本由于其模式识别能力而基本不受问题规模的影响。虽然像 GPT-4 这样的 LLM（无需微调）可以处理一些传统的中等规模 MIP 问题，但它们在处理不常见或高度专业化的 MIP 场景时会遇到困难。微调 LLM 可以为中等规模的 MIP 实例提供一些可行的解决方案，但这些模型在受到低温和恒定温度的限制时通常无法探索多种解决方案，从而限制了它们的性能。在本文中，我们提出并评估了一种结合思路链方法的递归动态温度方法。我们的研究结果表明，与其他动态温度策略相比，从高温开始逐渐降低温度可以得到更好的可行解决方案。此外，通过将 LLM 生成的结果与 Gurobi 生成的结果进行比较，我们证明了 LLM 可以通过加速修剪过程和提高整体效率来生成与传统求解器互补的解决方案。]]></description>
      <guid>https://arxiv.org/abs/2409.04464</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>翻译链提示 (CoTR)：一种针对低资源语言的新型提示技术</title>
      <link>https://arxiv.org/abs/2409.04512</link>
      <description><![CDATA[arXiv:2409.04512v1 公告类型：新
摘要：本文介绍了翻译提示链 (CoTR)，这是一种旨在提高低资源语言中语言模型性能的新策略。CoTR 重新构建提示，首先将输入上下文从低资源语言翻译成高资源语言，例如英语。然后对翻译后的文本执行指定的任务，如生成、分类或任何其他 NLP 功能，并可选择在需要时将输出翻译回原始语言。所有这些步骤都在一个提示中指定。我们通过对低资源印度语马拉地语的案例研究证明了该方法的有效性。CoTR 策略应用于各种任务，包括情绪分析、仇恨言论分类、主题分类和文本生成，并通过将其与常规提示方法进行比较来展示其有效性。我们的结果强调了基于翻译的提示策略在低资源语言中显着提高多语言 LLM 性能的潜力，为未来的研究和应用提供了宝贵的见解。我们特别看到了仇恨言论检测任务的最高准确率提升。该技术还有望提高使用 LLM 为代表性不足的语言生成合成数据的质量。]]></description>
      <guid>https://arxiv.org/abs/2409.04512</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>代码预训练如何影响语言模型任务性能？</title>
      <link>https://arxiv.org/abs/2409.04556</link>
      <description><![CDATA[arXiv:2409.04556v1 公告类型：新 
摘要：大型语言模型越来越多地在包含自然语言和非语言数据（如源代码）的语料库上进行训练。除了帮助完成与编程相关的任务外，有轶事证据表明，在预训练语料库中包含代码可能会提高其他不相关任务的性能，但迄今为止，还没有任何工作能够通过控制语言和代码数据来建立因果关系。我们在这里就是这么做的。我们在两种不同设置中交错自然语言和代码的数据集上对语言模型进行预训练：加法，其中预训练期间看到的总数据量保持不变；竞争，其中语言数据量保持不变。我们研究预训练混合物如何影响 (a) BigBench 基准中包含的各种任务集合的性能，以及 (b) 组合性，通过语义解析和句法转换的泛化准确性来衡量。我们发现，对更高比例的代码进行预训练可以提高涉及结构化输出（如语义解析）和数学的组合任务的性能。相反，增加代码混合可能会损害其他任务的性能，包括需要对语法或形态等语言结构敏感的任务，以及衡量现实世界知识的任务。]]></description>
      <guid>https://arxiv.org/abs/2409.04556</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用参数高效微调定制大型语言模型生成风格</title>
      <link>https://arxiv.org/abs/2409.04574</link>
      <description><![CDATA[arXiv:2409.04574v1 公告类型：新
摘要：一刀切的大型语言模型 (LLM) 越来越多地被用于帮助人们写作。然而，这些模型训练的写作风格可能并不适合所有用户或用例。如果 LLM 的个人语言可以根据每个用户进行定制，那么它们作为写作助手会更有用。在本文中，我们探讨了具有低秩自适应的参数高效微调 (PEFT) 是否可以有效指导 LLM 生成的风格。我们使用此方法将 LLaMA-2 定制为十位不同的作者，并表明生成的文本在词汇、句法和表面方面与目标作者一致，但在内容记忆方面存在困难。我们的研究结果凸显了 PEFT 支持 LLM 高效、用户级定制的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.04574</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Paper Copilot：一个自我进化且高效的 LLM 个性化学术辅助系统</title>
      <link>https://arxiv.org/abs/2409.04593</link>
      <description><![CDATA[arXiv:2409.04593v1 公告类型：新
摘要：随着科学研究的蓬勃发展，研究人员面临着浏览和阅读大量文献的艰巨任务。现有的解决方案（例如文档 QA）无法有效地提供个性化和最新的信息。我们提出了 Paper Copilot，这是一个自我进化的高效 LLM 系统，旨在基于思想检索、用户配置文件和高性能优化来协助研究人员。具体来说，Paper Copilot 可以提供个性化的研究服务，维护实时更新的数据库。定量评估表明，Paper Copilot 在高效部署后节省了 69.92% 的时间。本文详细介绍了 Paper Copilot 的设计和实施，强调了其对个性化学术支持的贡献以及简化研究流程的潜力。]]></description>
      <guid>https://arxiv.org/abs/2409.04593</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BPE 变得挑剔：Tokenizer 训练期间的高效词汇细化</title>
      <link>https://arxiv.org/abs/2409.04599</link>
      <description><![CDATA[arXiv:2409.04599v1 公告类型：新
摘要：语言模型可以从高效的标记化中受益匪浅。然而，它们仍然主要使用经典的 BPE 算法，这是一种简单可靠的方法。事实证明，这会导致诸如训练不足的标记和次优压缩等问题，从而影响下游性能。我们引入了 Picky BPE，这是一种改进的 BPE 算法，可在标记器训练期间执行词汇细化。我们的方法提高了词汇效率，消除了训练不足的标记，并且不会影响文本压缩。我们的实验表明，我们的方法不会降低下游性能，并且在某些情况下会提高它。]]></description>
      <guid>https://arxiv.org/abs/2409.04599</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>稀疏奖励可以自我训练对话代理</title>
      <link>https://arxiv.org/abs/2409.04617</link>
      <description><![CDATA[arXiv:2409.04617v1 公告类型：新
摘要：最新 (SOTA) 大型语言模型 (LLM) 代理的最新进展，尤其是在多轮对话任务中，主要由监督微调和高质量人工反馈驱动。然而，随着基础 LLM 模型的不断改进，获取有意义的人工反馈变得越来越具有挑战性和成本高昂。在某些领域，基础 LLM 代理最终可能会超越人类的能力，使传统的反馈驱动方法变得不切实际。在本文中，我们介绍了一种新颖的自我改进范式，使 LLM 代理能够在没有外部人工反馈的情况下自主提高其性能。我们的方法，并列模拟收获结果 (JOSH)，是一种自对齐算法，它利用稀疏奖励模拟环境来提取理想行为并进一步在其自身输出上训练 LLM。我们提出了 ToolWOZ，这是一个源自 MultiWOZ 的稀疏奖励工具调用模拟环境。我们证明，使用 JOSH 训练的模型（无论是小型模型还是前沿模型）都显著改善了基于工具的交互，同时保留了跨各种基准的通用模型功能。我们的代码和数据在 GitHub 上公开提供。]]></description>
      <guid>https://arxiv.org/abs/2409.04617</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>后期分块：使用长上下文嵌入模型的上下文块嵌入</title>
      <link>https://arxiv.org/abs/2409.04701</link>
      <description><![CDATA[arXiv:2409.04701v1 公告类型：新
摘要：许多用例需要检索较小的文本部分，而基于密集向量的检索系统通常在较短的文本段中表现更好，因为语义在嵌入中“过度压缩”的可能性较小。因此，从业者经常将文本文档分成较小的块并分别对其进行编码。但是，以这种方式创建的块嵌入可能会丢失周围块的上下文信息，从而导致表示不理想。在本文中，我们介绍了一种称为“后期分块”的新方法，该方法利用长上下文嵌入模型首先嵌入长文本的所有标记，在转换器模型之后和均值池之前应用分块。生成的块嵌入捕获完整的上下文信息，无需额外训练即可在各种检索任务中获得出色的结果。此外，我们的方法足够通用，可以应用于任何长上下文嵌入模型。]]></description>
      <guid>https://arxiv.org/abs/2409.04701</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>解开结：语言模型中长上下文预训练的有效数据增强策略</title>
      <link>https://arxiv.org/abs/2409.04774</link>
      <description><![CDATA[arXiv:2409.04774v1 公告类型：新
摘要：大型语言模型 (LLM) 优先扩展上下文窗口，以便模型可以整合更多信息。然而，训练模型来处理长上下文提出了重大挑战。这些挑战包括高质量自然长上下文数据的稀缺、短上下文任务的性能下降的可能性以及与注意力机制相关的训练效率降低。在本文中，我们介绍了 Untie the Knots (\textbf{UtK})，这是一种在持续预训练阶段采用的新型数据增强策略，旨在有效地使 LLM 获得长上下文能力，而无需修改现有的数据混合。具体来说，我们对文档进行分块，对块进行打乱，并创建一个复杂而打结的长文本结构；然后训练 LLM 解开这些结并在看似混乱的标记序列中识别相关段。这种方法通过准确地关注长上下文中的相关信息，大大提高了模型的性能，训练效率也大大提高。我们对具有 7B 和 72B 参数的模型进行了广泛的实验，并在 200 亿个标记上进行了训练，结果表明 UtK 在 128K 上下文长度的 RULER 上实现了 75\% 和 84.5\% 的准确率，明显优于其他长上下文策略。经过训练的模型将开源以供进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2409.04774</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LoCa：知识蒸馏的 Logit 校准</title>
      <link>https://arxiv.org/abs/2409.04778</link>
      <description><![CDATA[arXiv:2409.04778v1 公告类型：新
摘要：知识蒸馏（KD）旨在通过模仿教师模型来训练更好的学生模型，在模型压缩中起着重要作用。一种典型的方法是对齐输出逻辑。然而，我们发现一个常见的问题，即错误指导，即当基于教师逻辑的预测不符合标签时，学生会被误导。同时，逻辑中还有其他有用的暗知识，例如类别可辨别性，这对于蒸馏至关重要。在本文中，我们提出了一种简单而有效的逻辑校准（LoCa）方法，该方法基于真实标签校准来自教师模型的逻辑。关键见解是纠正预测（以解决错误指导问题）并同时保持有用的暗知识。我们提出的 LoCa 不需要任何额外的参数。图像分类和文本生成任务的实证结果表明，LoCa 可以有效提高基线的性能。]]></description>
      <guid>https://arxiv.org/abs/2409.04778</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>选择性自我排练：一种提高大型语言模型泛化能力的微调方法</title>
      <link>https://arxiv.org/abs/2409.04787</link>
      <description><![CDATA[arXiv:2409.04787v1 公告类型：新
摘要：在特定数据集上微调大型语言模型 (LLM) 是提高目标任务性能的常见做法。然而，这种性能提升往往会导致过度拟合，即模型在任务或训练数据的特征上变得过于专业化，从而导致泛化能力下降。本文介绍了选择性自我排练 (SSR)，这是一种微调方法，可在提高泛化能力的同时实现与标准监督微调 (SFT) 相当的性能。SSR 利用查询可以有多个有效响应这一事实。通过利用模型的正确响应，SSR 在微调阶段减少了模型专业化。SSR 首先通过部署适当的 LLM 作为评判者从训练集中识别正确的模型响应。然后，它使用正确的模型响应和剩余样本的黄金响应对模型进行微调。通过在各种数据集中识别无法回答的查询的任务上进行实验，证明了 SSR 的有效性。结果表明，标准 SFT 可能导致多个基准测试（例如 MMLU 和 TruthfulQA）上的平均性能下降高达 $16.7\%$。相比之下，SSR 平均导致性能下降接近 $2\%$，表明与标准 SFT 相比具有更好的泛化能力。]]></description>
      <guid>https://arxiv.org/abs/2409.04787</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>短语级对抗训练可减轻基于神经网络的自动作文评分中的偏见</title>
      <link>https://arxiv.org/abs/2409.04795</link>
      <description><![CDATA[arXiv:2409.04795v1 公告类型：新
摘要：自动论文评分（AES）被广泛用于评估教育目的的候选人。然而，由于缺乏代表性数据，大多数现有的 AES 系统并不稳健，并且它们的评分预测偏向最具代表性的数据样本。在本研究中，我们提出了一种与模型无关的短语级方法来生成对抗性论文集，以解决 AES 模型的偏差和稳健性。具体而言，我们使用我们提出的方法构建了一个攻击测试集，该测试集包含来自原始测试集的样本和对抗生成的样本。为了评估攻击策略和数据增强的有效性，我们利用各种神经网络评分模型进行了全面分析。实验结果表明，所提出的方法在存在对抗性示例和没有此类攻击的场景下显着提高了 AES 模型的性能。]]></description>
      <guid>https://arxiv.org/abs/2409.04795</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索简单易懂的红队对话</title>
      <link>https://arxiv.org/abs/2409.04822</link>
      <description><![CDATA[arXiv:2409.04822v1 公告类型：新
摘要：大型语言模型 (LLM) 在商业对话系统中的应用越来越广泛，但它们也带来了安全和道德风险。多轮对话（其中上下文会影响模型的行为）可能会被利用来产生不受欢迎的响应。在本文中，我们研究了在直接的红队攻击方法中使用现成的 LLM 的有效性，其中攻击者 LLM 旨在从目标 LLM 中引出不受欢迎的输出，并比较了单轮和对话式红队攻击策略。我们的实验提供了对各种使用策略的见解，这些策略会显着影响他们作为红队成员的表现。他们表明，现成的模型可以充当有效的红队成员，甚至可以根据过去的尝试调整他们的攻击策略，尽管它们的有效性会随着一致性的提高而降低。]]></description>
      <guid>https://arxiv.org/abs/2409.04822</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>实现大型语言模型的最佳性能：系统评价</title>
      <link>https://arxiv.org/abs/2409.04833</link>
      <description><![CDATA[arXiv:2409.04833v1 公告类型：新
摘要：近年来，大型语言模型 (LLM) 在自然语言处理 (NLP) 中取得了显著的成功。LLM 需要大量参数才能获得高性能。随着模型增长到万亿参数范围，计算和内存成本显着增加。这使得许多研究人员难以获得训练或应用这些模型所需的资源。优化 LLM 性能涉及两种主要方法：针对特定任务对预训练模型进行微调以实现最先进的性能，以及在保持相似性能的同时降低成本或缩短训练时间。本文按照系统评价和荟萃分析的首选报告项目 (PRISMA) 声明进行了系统文献综述 (SLR)。我们审查了 2017 年至 2023 年 12 月从 5 个数据库中检索到的 983 篇出版物中的 65 篇。本研究提出了优化和加速 LLM 的方法，同时在不牺牲准确性的情况下实现尖端结果。我们首先概述语言建模的发展，然后详细解释常用的框架和库，并基于三个类别（LLM 训练、LLM 推理和系统服务）对改进和加速 LLM 进行分类。然后，我们深入研究最近的优化和加速策略，例如训练优化、硬件优化、可扩展性和可靠性，并对这些策略进行分类和分类。最后，我们对每个类别和策略进行了深入比较，并提供了两个关于优化模型训练和提高推理效率的案例研究。这些案例研究展示了在保持性能的同时解决 LLM 资源限制的实用方法。]]></description>
      <guid>https://arxiv.org/abs/2409.04833</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>仅需 ASR + LLM？语音大型语言模型识别和理解口语对话中说话者的能力研究</title>
      <link>https://arxiv.org/abs/2409.04927</link>
      <description><![CDATA[arXiv:2409.04927v1 公告类型：新
摘要：近年来，我们观察到语音语言模型 (SpeechLLM) 的快速发展，赶上了人类的听力和推理能力。值得注意的是，SpeechLLM 在高考等基准测试中表现出令人印象深刻的口语对话问答 (SQA) 性能，高考是中国大学入学考试的英语听力测试，这似乎需要理解对话中说话者的口语内容和语音特征。然而，在仔细研究高考问题后，我们发现许多问题的正确答案可以仅从对话上下文中推断出来，而无需识别问题中询问的说话者。我们对高考和我们提出的“你喜欢什么？”数据集中最先进的模型 Qwen-Audio 和 WavLLM 的评估表明，这些基于上下文的问题的准确率明显高于身份关键问题，而身份关键问题只有通过正确的说话者识别才能正确回答。我们的研究结果和分析表明，在解决 SQA 问题时，当前的 SpeechLLM 对音频中的说话者意识有限，其行为类似于 LLM 从无声对话转录中进行推理。我们认为，我们对基于上下文和身份关键问题的定义和自动分类可以为 SQA 任务中的 SpeechLLM 提供更准确的评估框架。]]></description>
      <guid>https://arxiv.org/abs/2409.04927</guid>
      <pubDate>Tue, 10 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>