<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Thu, 20 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>命令R7B阿拉伯语：一种小型，企业的专注，多语言和文化意识的阿拉伯语LLM</title>
      <link>https://arxiv.org/abs/2503.14603</link>
      <description><![CDATA[ARXIV：2503.14603V1公告类型：新 
摘要：由于数字化的阿拉伯数据的可用性有限，为企业阿拉伯应用程序建立高质量的大语言模型（LLM）仍然具有挑战性。在这项工作中，我们提出了一个数据综合和完善策略，即通过利用合成数据生成和人类在循环注释来扩大我们的阿拉伯语培训语料库来帮助解决此问题。我们进一步介绍了我们的迭代后培训配方，这对于在将模型与人类偏好保持一致，这是企业用例的关键方面。这项工作的高潮是释放一个小的7B开放权重模型，该模型在面对面的比较和以阿拉伯语为中心的基准上优于大小的同龄人，涵盖文化知识，抹布，抹布和上下文忠诚。]]></description>
      <guid>https://arxiv.org/abs/2503.14603</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>检索启动模拟：最新和知识自适应模拟的生成代理</title>
      <link>https://arxiv.org/abs/2503.14620</link>
      <description><![CDATA[ARXIV：2503.14620V1公告类型：新 
摘要：在2023年的有关信息和通信的白皮书中，据估计，到2022年，日本的社交网络服务人口将超过1亿，而日本社交网络服务的影响正在增长。此外，正在积极地进行使用SNS的营销以及有关情绪和信息传播的传播的研究，从而需要系统来预测SNS相互作用趋势的系统。我们已经创建了一个系统，该系统通过构建虚拟SNS环境来模拟SNS上各个社区的行为，在该环境中，代理商在代理商使用LLMS创建的聊天社区中互相发布并互相回复。在本文中，我们评估了搜索扩展生成机制的影响，用于在虚拟SNS环境中使用仿真系统在生成帖子和答复的能力上创建帖子和答复。作为评估的结果，我们证实了拟议的搜索扩展生成机制，该机制模仿人类搜索行为，产生了最自然的交换。]]></description>
      <guid>https://arxiv.org/abs/2503.14620</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过关键问题回答识别错误信息的可解释框架</title>
      <link>https://arxiv.org/abs/2503.14626</link>
      <description><![CDATA[ARXIV：2503.14626V1公告类型：新 
摘要：迄今为止，自然语言错误信息检测方法在很大程度上取决于序列分类方法，生成不透明的系统，其中分类为错误信息的原因尚不清楚。尽管在自动事实检查领域已经做出了努力，以提出有关该问题的可解释方法，但自动核对系统检查系统并非如此。在本文中，我们提出了一个新的可解释框架，用于基于论证方案和关键问题理论的事实和理性错误信息检测。为此，我们创建并发布了NLAS-CQ，这是将3,566个类似教科书的自然语言论点实例和4,687个与这些参数相关的关键问题相应的答案的第一个语料库。在此语料库的基础上，我们实施和验证了我们的新框架，该框架结合了分类与问题回答以分析参数以寻求错误信息，并向人类用户提供了关键问题的形式说明。]]></description>
      <guid>https://arxiv.org/abs/2503.14626</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>征服：基于概念的测验生成的框架</title>
      <link>https://arxiv.org/abs/2503.14662</link>
      <description><![CDATA[ARXIV：2503.14662V1公告类型：新 
摘要：测验通过增强学生对关键概念的理解和鼓励自我指导的探索，在教育中起着至关重要的作用。但是，编译高质量的测验可能具有挑战性，需要深入的专业知识和深入了解特定主题。尽管LLM大大提高了测验的效率，但仍然关注这些AI生成的测验及其对学生的教育影响。为了解决这些问题，我们介绍了征服，这是一个基于概念的测验生成框架，利用外部知识来源。我们使用全面的评估维度来评估生成的测验的质量，并使用LLM作为法官。我们的实验结果表明，在对基线测验集的成对比较中，评估得分提高了4.8％，胜率为77.52％。消融研究进一步强调了每个组件在我们的框架中的有效性。代码可在https://github.com/sofyc/conquer上找到。]]></description>
      <guid>https://arxiv.org/abs/2503.14662</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用LLMS生成医学信息的解释以检测抑郁症</title>
      <link>https://arxiv.org/abs/2503.14671</link>
      <description><![CDATA[ARXIV：2503.14671V1公告类型：新 
摘要：从社交媒体数据中对抑郁症的早期发现为及时干预提供了宝贵的机会。但是，这项任务构成了重大挑战，需要专业的医学知识和准确和可解释的模型的发展。在本文中，我们提出了LLM-MTD（用于多任务抑郁症检测的大语言模型），这是一种新型方法，它利用预先训练的大型语言模型同时将社交媒体帖子分类为抑郁症，并在医学诊断标准中产生基于医疗诊断标准的文本解释。我们使用多任务学习框架训练模型，并具有组合的损失功能，可优化分类精度和解释质量。我们在基准REDDIT自我报告的抑郁数据集（RSDD）上评估了LLM-MTD，并将其性能与几种竞争性基线方法（包括传统的机器学习和微调BERT）进行比较。我们的实验结果表明，LLM-MTD在抑郁症检测中实现最先进的表现，显示AUPRC和其他关键指标的显着改善。此外，对生成的解释的人类评估揭示了它们的相关性，完整性和医疗准确性，从而强调了我们方法的增强性。这项工作为抑郁症检测提供了一种新颖的方法，将大语言模型的力量与解释性的关键方面相结合。]]></description>
      <guid>https://arxiv.org/abs/2503.14671</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Haplovl：单转化基线，用于多模式理解</title>
      <link>https://arxiv.org/abs/2503.14694</link>
      <description><![CDATA[ARXIV：2503.14694V1公告类型：新 
摘要：大语言模型（LLMS）的最新进展显着推动了大型多模式模型（LMM）的发展，突出了一般和智能助手的潜力。但是，大多数LMMS分别模型的视觉和文本模式分别模型，导致最近使用单个变压器开发天然LMM的努力。尽管有希望，这些本地模型是资源密集的，与其组成相比，这些模型经常表现出性能差距。为了减轻此问题，我们提出了一种简单而有效的方法，以在单个变压器中为天然和端到端大型多模式构建基线。首先，我们提出了一种新的早期融合LMM，该LMM可以在早期阶段融合多模式输入，并以自动回归方式响应视觉说明。其次，我们为提出的模型设计了有效的培训配方，该模型利用了预培训模型的先验知识，可以解决绩效限制和资源消费的挑战。提出的模型与其他LMM相比使用了一个变压器，表现出了卓越的性能，并用组成LMM显着缩小了性能差距。]]></description>
      <guid>https://arxiv.org/abs/2503.14694</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>第二语言韩国通用依赖性树库v1.2：专注于数据增强和注释方案改进</title>
      <link>https://arxiv.org/abs/2503.14718</link>
      <description><![CDATA[ARXIV：2503.14718V1公告类型：新 
摘要：我们将第二语言（L2）韩国通用依赖关系（UD）Treebank和5,454个手动注释的句子扩展。还对注释指南进行了修订，以更好地与UD框架保持一致。使用这种增强的树库，我们调整了三种韩国语言模型，并评估了它们在内域和外域L2-Korean数据集上的性能。结果表明，微调显着提高了各种指标的性能，从而突出了使用良好的L2数据集用于微调第一语言的通用语言模型的重要性，以对L2数据进行形态词法分析。]]></description>
      <guid>https://arxiv.org/abs/2503.14718</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>记忆编码中的战略资源分配：效率原理塑造语言处理</title>
      <link>https://arxiv.org/abs/2503.14728</link>
      <description><![CDATA[ARXIV：2503.14728V1公告类型：新 
摘要：如何有限地使用有限的工作记忆能力来支持人的语言行为？在本文中，我们研究了战略资源分配，作为在句子处理中编码内存的效率原则。这个想法是，工作记忆资源是动态和战略性分配的，以优先考虑新颖和意外的信息，从而增强其表示形式，以使其不易记忆衰减和干扰。从理论上讲，从资源理性的角度来看，我们认为这种效率原则自然源自关于工作记忆的两个功能假设，即其有限的能力和嘈杂的代表。从经验上，通过自然主义语料库数据，我们发现了从生产和理解方面的依赖性区域中的战略资源分配的融合证据，在这种情况下，非本地依赖性具有较低的前述依赖性，与降低了局部效应。但是，我们的结果还揭示了相当大的跨语言变异性，强调了对战略资源分配方式（作为普遍效率原则）如何与语言特定的短语结构相互作用的需求。]]></description>
      <guid>https://arxiv.org/abs/2503.14728</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>不确定性蒸馏：教学语言模型以表达语义信心</title>
      <link>https://arxiv.org/abs/2503.14749</link>
      <description><![CDATA[ARXIV：2503.14749V1公告类型：新 
摘要：由于大型语言模型（LLM）越来越多地用于事实提问，因此对于LLM而言，有能力传达其答案是正确的可能性。为了使这些不确定性的口头表达有意义，它们应在表达的置信度水平上反映错误率。但是，当提示表达信心时，当前LLM的错误率与他们传达的信心不一致，这突出了对不确定性量化方法的需求。许多先前的方法计算词汇不确定性，估计模型对其生成的特定字符串的信心。但是，在某些情况下，估计语义不确定性或模型对答案的信心可能更有用，无论其口头如何。我们提出了一个简单的程序，不确定性蒸馏，以教授LLM语言校准的语义信心。使用固定数据将初始不确定性估算映射到有意义的概率上，我们创建了带有口头化概率的示例以进行监督微调。我们证明我们的方法产生了口头上的信心，这些信心与观察到的错误率与小型微调语言模型以及较大的指导调整模型相关，并发现我们的语义不确定性与短答案的词汇不确定性息息相关。]]></description>
      <guid>https://arxiv.org/abs/2503.14749</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>语言独立命名实体识别通过单词向量的正交转换</title>
      <link>https://arxiv.org/abs/2503.14755</link>
      <description><![CDATA[ARXIV：2503.14755V1公告类型：新 
摘要：单词嵌入是NLP的关键构建块，其中模型在许多不同的任务中都严重依赖单词嵌入。在本文中，提出了一个模型，该模型是基于使用双向LSTM/CRF和Word Embeddings来执行任何语言命名实体识别的。这是通过使用正交线性转换矩阵来训练源语言（英语）的模型（英语）和将单词嵌入到源语言的单词嵌入中来完成的。该模型的评估表明，通过在英语数据集中训练模型，模型能够在阿拉伯数据集中检测到命名实体，而无需培训或微调阿拉伯语语言数据集的模型。]]></description>
      <guid>https://arxiv.org/abs/2503.14755</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>事实和证据：用于机器生成的文本的透明细粒度事实验证的交互式工具</title>
      <link>https://arxiv.org/abs/2503.14797</link>
      <description><![CDATA[ARXIV：2503.14797V1公告类型：新 
摘要：随着AI生成的内容的广泛消费，人们对开发自动化工具的重点越来越重，以验证此类内容的事实准确性。但是，为事实验证而开发的先前研究和工具将其视为二进制分类或线性回归问题。尽管这是系统中自动护栏的一部分，但我们认为，这种工具在来源证据的预测推理和多样性方面缺乏透明度，无法提供可信赖的用户体验。我们开发事实＆amp;证据 - 用于用户驱动的复杂文本验证的交互式和透明的工具。该工具促进了事实验证所涉及的复杂决策，向用户介绍了复杂的输入文本的细分，以可视化单个主张的信誉以及模型决策的解释以及对多种不同证据来源的解释。事实＆amp;证据旨在赋予机器生成的文本的消费者权力，并使他们可以理解，验证，有选择地信任和使用此类文本。]]></description>
      <guid>https://arxiv.org/abs/2503.14797</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MMDT：解码多模式基础模型的可信度和安全性</title>
      <link>https://arxiv.org/abs/2503.14827</link>
      <description><![CDATA[ARXIV：2503.14827V1公告类型：新 
摘要：多模式基础模型（MMFMS）在各种应用中起着至关重要的作用，包括自主驾驶，医疗保健和虚拟助手。但是，一些研究揭示了这些模型中的漏洞，例如通过文本对图像模型生成不安全的内容。多模型模型的现有基准主要评估这些模型的有益性，或者仅关注有限的观点，例如公平和隐私。在本文中，我们介绍了第一个统一平台MMDT（多模式解码器），旨在为MMFM提供全面的安全性和可信度评估。我们的平台从多个角度评估了模型，包括安全，幻觉，公平/偏见，隐私，对抗性鲁棒性和分布外（OOD）概括。我们已经在不同的任务下设计了各种评估方案和红色团队算法，以生成具有挑战性的数据，从而形成高质量的基准。我们使用MMDT评估了一系列多模型模型，我们的发现揭示了一系列脆弱性和在这些角度进行改进的领域。这项工作介绍了MMFMS的第一个全面，独特的安全和可信度评估平台，为开发更安全，更可靠的MMFM和系统铺平了道路。我们的平台和基准可在https://mmmdecodingtrust.github.io/上获得。]]></description>
      <guid>https://arxiv.org/abs/2503.14827</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CLEF-2025 CHECKTHAT！实验室：主观性，事实检查，要求归一化和检索</title>
      <link>https://arxiv.org/abs/2503.14828</link>
      <description><![CDATA[ARXIV：2503.14828V1公告类型：新 
摘要：checkthat！ LAB旨在推进旨在识别和抵消各种语言和平台的在线虚假信息和操纵工作的创新技术的开发。前五个版本的重点是信息验证管道中的关键任务，包括值得检查，证据检索和配对以及验证。自2023年版以来，该实验室扩大了其范围，以解决支持验证研究和决策的辅助任务。在2025年版中，该实验室重新审视了核心验证任务，同时还考虑了辅助挑战。任务1的重点是识别主观性（CheckThat！2024的后续），任务2解决了要求归一化的主张，任务3针对事实检查数值主张，任务4探索了科学的Web话语处理。这些任务在文档和跨度级别（包括多语言设置）上都表现出具有挑战性的分类和检索问题。]]></description>
      <guid>https://arxiv.org/abs/2503.14828</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MetalAdder：通过类似问题推理转移的升数学解决方案质量</title>
      <link>https://arxiv.org/abs/2503.14891</link>
      <description><![CDATA[ARXIV：2503.14891V1公告类型：新 
摘要：大型语言模型（LLMS）证明了在解决数学推理任务，利用思想链（COT）数据作为指导答案生成的重要组成部分。当前的范例通常会产生COT并直接解决给定问题，从某种程度上与人类解决问题的策略有所不同。人类经常通过召回类似案件并利用其解决方案来解决当前任务来解决问题。受这个认知过程的启发，我们提出了\ textbf {MetalAdder}，这是一个新颖的框架，明确提示LLMS回忆和反思元问题，这些问题在结构或语义上类似的问题以及在解决目标问题之前与COT解决方案一起。此外，我们引入了一种问题纠正的机制，以通过再生原始问题来增强模型对目标问题的理解，从而进一步提高了推理准确性。因此，该模型可以从类似问题中实现推理转移，模仿人类的“从例子学习”和概括能力。关于数学基准测试的广泛实验表明，我们的MetalAdder显着提高了LLMS解决问题的准确性，在很大程度上优于基于标准的COT方法（\ TextBf {10.3 \％}的精度增益）和其他方法。我们的代码和数据已在https://github.com/lhl3341/metaladder上发布。]]></description>
      <guid>https://arxiv.org/abs/2503.14891</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>对语言模型的深层对比性学习</title>
      <link>https://arxiv.org/abs/2503.14900</link>
      <description><![CDATA[ARXIV：2503.14900V1公告类型：新 
摘要：过去几年见证了大语言模型的巨大成功，展示了在理解文本数据和产生类似人类语言的功能方面的强大能力。大型语言模型通过接受大量文本数据的培训，包括具有版权内容和用户生成的知识的在线资源来实现成功。但是，这是有代价的：暴露用户隐私和侵犯版权保护的潜在风险。因此，为了维护个人的“被遗忘的权利”，对机器学习的兴趣越来越高 - 从模型中删除特定培训样本的信息的过程，同时并没有恶化其预测性质量。由于语言模型的黑框性质，这是一项具有挑战性的任务。大多数现有研究的重点是减轻这些忘记样本对模型输出的影响，并且没有明确考虑模型潜在空间中样品的几何分布。为了解决这个问题，我们提出了一个机器学习框架，该框架被称为“深度对比”，以进行微调（DEEPCUT）语言模型。我们提出的模型通过直接优化模型的潜在空间来实现机器的学习。对现实世界数据集的综合实验证明了深度曲线的有效性和效率，并且对基线方法一致且显着改善。]]></description>
      <guid>https://arxiv.org/abs/2503.14900</guid>
      <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>