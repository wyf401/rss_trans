<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Thu, 11 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>DiffusionDialog：具有潜在空间的多样化对话生成的扩散模型</title>
      <link>https://arxiv.org/abs/2404.06760</link>
      <description><![CDATA[arXiv:2404.06760v1 公告类型：新
摘要： 现实生活中的对话内容多种多样，存在需要多样化生成的一对多问题。先前的研究试图引入离散或基于高斯的连续潜变量来解决一对多问题，但多样性有限。最近，扩散模型在计算机视觉方面取得了突破，在自然语言处理方面也做出了一些尝试。在本文中，我们提出了 DiffusionDialog，这是一种借助扩散模型来增强对话生成多样性的新方法。在我们的方法中，我们将连续潜在变量引入扩散模型。在对话任务中使用潜在变量的问题是如何构建潜在空间的有效先验和推理过程以获得给定上下文的正确潜在变量。通过结合编码器和基于潜在的扩散模型，我们将响应的潜在表示在连续空间中编码为先验，而不是固定的高斯分布或简单的离散分布。然后，我们通过扩散模型逐步去噪来推断潜在的。实验结果表明，我们的模型极大地增强了对话响应的多样性，同时保持了连贯性。此外，在进一步分析中，我们发现我们的扩散模型实现了很高的推理效率，这是在自然语言处理中应用扩散模型的主要挑战。]]></description>
      <guid>https://arxiv.org/abs/2404.06760</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>对话式智能辅导系统的个性感知学生模拟</title>
      <link>https://arxiv.org/abs/2404.06762</link>
      <description><![CDATA[arXiv:2404.06762v1 公告类型：新
摘要：智能辅导系统（ITS）可以提供个性化和自定进度的学习体验。大语言模型（LLM）的出现进一步实现了更好的人机交互，并促进了数学和语言学习等各个学科中会话式ITS的发展。在对话教学中，认识并适应个体特征可以显着提高学生的参与度和学习效率。然而，在训练和评估会话式智能交通系统中，表征和模拟学生的性格仍然具有挑战性。在这项工作中，我们提出了一个框架，通过完善和整合认知和非认知方面来构建不同学生群体的概况，并利用法学硕士在语言学习场景中进行人格意识的学生模拟。我们通过多方面验证进一步增强了框架，并从教师和学生的角度进行了广泛的分析。我们的实验结果表明，最先进的法学硕士可以根据给定的语言能力和个性特征产生不同的学生反应，并触发教师的适应性脚手架策略。]]></description>
      <guid>https://arxiv.org/abs/2404.06762</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:45 GMT</pubDate>
    </item>
    <item>
      <title>Llama-VITS：通过语义意识增强 TTS 合成</title>
      <link>https://arxiv.org/abs/2404.06714</link>
      <description><![CDATA[arXiv:2404.06714v1 公告类型：新
摘要：自然语言处理 (NLP) 的最新进展表明，大规模语言模型 (LLM) 擅长为各种目的生成高质量文本。值得注意的是，在文本转语音 (TTS) 系统中，将 BERT 集成到语义标记生成中强调了语义内容在生成连贯语音输出中的重要性。尽管如此，法学硕士在增强 TTS 合成方面的具体效用仍然相当有限。本研究引入了一种创新方法 Llama-VITS，该方法通过使用 LLM 丰富文本的语义内容来增强 TTS 合成。 Llama-VITS 将 Llama2 的语义嵌入与领先的端到端 TTS 框架 VITS 模型集成。通过利用 Llama2 进行主要语音合成过程，我们的实验证明 Llama-VITS 与原始 VITS (ORI-VITS) 的自然度相匹配，并且在 LJSpeech 数据集上融入了 BERT (BERT-VITS)，LJSpeech 数据集是中性、清晰的言语。此外，我们的方法显着增强了 EmoV_DB_bea_sem 数据集的情感表达能力，该数据集是从 EmoV_DB 数据集中精心挑选的情感一致的语音，突出了其生成情感语音的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.06714</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>通过探针训练和离线一致性检查进行可转移且高效的非事实内容检测</title>
      <link>https://arxiv.org/abs/2404.06742</link>
      <description><![CDATA[arXiv:2404.06742v1 公告类型：新
摘要：检测非事实内容是提高大型语言模型（LLM）生成的可信度的长期目标。当前的事实性探针是使用人工注释标签进行训练的，对未发布内容的可转移性有限，而在线自我一致性检查由于需要生成多个输出而造成了大量的计算负担。本文提出了PINOSE，它在离线自一致性检查结果上训练探测模型，从而避免了对人工注释数据的需求，并实现了跨不同数据分布的可转移性。由于一致性检查过程是离线的，PINOSE通过在线一致性验证减少了生成多个响应的计算负担。此外，它还在响应解码之前检查内部状态的各个方面，有助于更有效地检测事实不准确之处。事实性检测和问答基准的实验结果表明，PINOSE 取得了优于现有事实性检测方法的结果。我们的代码和数据集在这个匿名存储库中公开可用。]]></description>
      <guid>https://arxiv.org/abs/2404.06742</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>Onco-Retriever：用于检索肿瘤学 EHR 记录的生成分类器</title>
      <link>https://arxiv.org/abs/2404.06680</link>
      <description><![CDATA[arXiv:2404.06680v1 公告类型：新
摘要：从 EHR 系统检索信息对于回答有关患者旅程的具体问题和改善临床护理的提供至关重要。尽管如此，大多数 EHR 系统仍然依赖基于关键字的搜索。随着生成式大语言模型 (LLM) 的出现，检索信息可以带来更好的搜索和摘要能力。此类检索器还可以提供检索增强生成（RAG）管道来回答任何查询。然而，由于创建查询文档支持对的困难，从 EHR 系统中包含的 EHR 现实世界临床数据中检索信息以解决多个下游用例的任务具有挑战性。我们提供了使用大型语言模型以经济实惠的方式创建此类数据集的蓝图。对于肿瘤学数据元素，我们的方法生成的检索器比 Ada 和 Mistral 等专有检索器好 30-50 F-1 点。我们进一步将我们的模型（称为 Onco-Retriever）与微调的 PubMedBERT 模型进行比较。我们对现实世界的 EHR 数据进行广泛的手动评估，并对不同模型进行延迟分析，并为医疗保健组织构建特定领域的检索器提供了一条前进的道路。]]></description>
      <guid>https://arxiv.org/abs/2404.06680</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>CQIL：准独立层并发计算的推理延迟优化</title>
      <link>https://arxiv.org/abs/2404.06709</link>
      <description><![CDATA[arXiv:2404.06709v1 公告类型：新
摘要：快速增长的大规模语言模型在几乎所有自然语言处理任务上都提供了前所未有的性能。然而，大型语言模型的有效性依赖于呈指数增长的参数数量。巨大的计算复杂性会导致较高的推理延迟，从而对用户体验产生负面影响。现有的提高推理效率的方法，例如张量并行和量化，目标是减少每层计算延迟，但却忽略了由于层数而导致的累积延迟。然而，最近通过层删除来减少累积延迟的工作导致性能显着下降。受相邻层之间输入相似性的启发，我们建议识别准独立层，这些层可以同时计算以显着减少推理延迟。我们还引入了一种旁路技术来减轻信息丢失的影响。所提出的方法在 LLaMA 模型上的实证实验证实，准独立层并发计算 (CQIL) 可以在 LLaMA-33B 模型上减少高达 48.3% 的延迟，同时保持接近的性能水平。]]></description>
      <guid>https://arxiv.org/abs/2404.06709</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>MathVC：用于数学教育的法学硕士模拟多角色虚拟教室</title>
      <link>https://arxiv.org/abs/2404.06711</link>
      <description><![CDATA[arXiv:2404.06711v1 公告类型：新
摘要：数学建模（MM）被认为是 STEM 学科学生的一项基本技能。当学生能够参与小组讨论和协作解决问题时，练习 MM 技能通常是最有效的。然而，由于监督此类团体活动所需的教师和教育资源分布不均，学生并不总是能获得平等的机会进行这种实践。令人兴奋的是，大型语言模型（LLM）最近在数学问题建模和模拟具有不同特征和属性的角色方面表现出了强大的能力。从法学硕士的进步中汲取灵感，在这项工作中，我们推出了 MATHVC，这是第一个由法学硕士支持的虚拟教室，其中包含多个法学硕士模拟的学生角色，人类学生可以与他们一起练习他们的 MM 技能。为了鼓励每个 LLM 角色的行为与其指定的数学相关属性保持一致（称为“特征对齐”），并使整体对话过程接近真实的学生 MM 讨论（称为“对话程序对齐”），我们提出了三项创新：将 MM 领域知识集成到模拟中，定义符号模式作为角色模拟的基础，并在平台级别设计元规划器来驱动对话过程。通过实验和消融研究，我们证实了模拟方法的有效性，并表明 MATHVC 有望在未来使现实生活中的学生受益。]]></description>
      <guid>https://arxiv.org/abs/2404.06711</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:43 GMT</pubDate>
    </item>
    <item>
      <title>文化团队：人工智能辅助的交互式红队，挑战法学硕士（缺乏）多元文化知识</title>
      <link>https://arxiv.org/abs/2404.06664</link>
      <description><![CDATA[arXiv:2404.06664v1 公告类型：新
摘要：前沿大语言模型（LLM）是由具有不同文化背景的研究人员和从业者在具有不同来源的数据集上开发的。然而，法学硕士（缺乏）多元文化知识无法通过当前制定基准的方法进行有效评估。现有的多元文化评估主要依赖于昂贵且受限的人工注释或可能过时的互联网资源。因此，他们努力捕捉文化规范的复杂性、动态性和多样性。 LLM 生成的基准很有前途，但也存在传播其旨在衡量的相同偏差的风险。为了协同人类注释者的创造力和专业文化知识以及基于法学硕士的自动化的可扩展性和标准化，我们引入了CulturalTeaming，这是一个交互式红队系统，利用人类与人工智能的协作来构建真正具有挑战性的评估数据集，用于评估法学硕士，同时提高注释者的能力和经验。我们的研究表明，CulturalTeaming 的各种人工智能辅助模式支持注释者以游戏化的方式提出现代法学硕士无法解决的文化问题。重要的是，人工智能辅助水平的提高（例如，法学硕士生成的修订提示）使用户能够通过增强的自身感知创造力来创建更困难的问题，从而揭示了在现代评估数据集创建程序中涉及更重的人工智能辅助的承诺。通过一系列时长一小时的研讨会，我们收集了 CULTURALBENCH-V0.1，这是一个紧凑但高质量的评估数据集，其中包含用户的红队尝试，现代法学硕士的不同系列的准确率在 37.7% 到 72.2% 之间，揭示了法学硕士多元文化能力的显着差距。]]></description>
      <guid>https://arxiv.org/abs/2404.06664</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>我的变成你的：定义、注释和检测新闻采访对话中上下文相关的释义</title>
      <link>https://arxiv.org/abs/2404.06670</link>
      <description><![CDATA[arXiv:2404.06670v1 公告类型：新
摘要：高冲突对话（例如咨询或客户支持）的最佳实践几乎总是包括解释前一位发言者的建议。尽管释义分类在 NLP 中受到了广泛关注，但释义通常被认为独立于上下文，并且常见的模型和数据集不适用于对话设置。在这项工作中，我们研究对话中的释义（例如，演讲者 1：“那本书是我的。”变成演讲者 2：“那本书是你的。”）。我们提供依赖于上下文的释义的操作化，并为众包工作者开发培训以对对话中的释义进行分类。我们引入了一个数据集，其中包含来自 NPR 和 CNN 新闻采访的话语对，并注释了上下文相关的释义。为了能够对标签变化进行分析，数据集包含 600 个话语对的 5,581 个注释。我们通过上下文学习和用于对话中自动释义检测的标记分类模型展示了有希望的结果。]]></description>
      <guid>https://arxiv.org/abs/2404.06670</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>RULER：您的长上下文语言模型的真实上下文大小是多少？</title>
      <link>https://arxiv.org/abs/2404.06654</link>
      <description><![CDATA[arXiv:2404.06654v1 公告类型：新
摘要：大海捞针（NIAH）测试检查从长干扰文本（“大海捞针”）中检索一条信息（“针”）的能力，已被广泛采用来评估长期干扰文本。上下文语言模型（LM）。然而，这种简单的基于检索的测试仅表明长上下文理解的表面形式。为了对长上下文 LM 提供更全面的评估，我们创建了一个新的综合基准标尺，该标尺具有灵活的配置，可定制序列长度和任务复杂性。 RULER 对普通 NIAH 测试进行了扩展，涵盖了不同类型和数量的针的变化。此外，RULER 引入了新的任务类别多跳跟踪和聚合来测试从上下文搜索之外的行为。我们在 RULER 中评估了 10 个长上下文 LM，其中包含 13 个代表性任务。尽管在普通 NIAH 测试中实现了近乎完美的准确性，但随着上下文长度的增加，所有模型都表现出大幅性能下降。虽然这些模型都声称上下文大小为 32K 令牌或更大，但只有四种模型（GPT-4、Command-R、Yi-34B 和 Mixtral）可以在 32K 长度下保持令人满意的性能。我们对支持 200K 上下文长度的 Yi-34B 的分析表明，随着输入长度和任务复杂性的增加，还有很大的改进空间。我们开源 RULER 来促进长上下文 LM 的综合评估。]]></description>
      <guid>https://arxiv.org/abs/2404.06654</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:41 GMT</pubDate>
    </item>
    <item>
      <title>利用有趣的事实通过对话界面增强用户参与度</title>
      <link>https://arxiv.org/abs/2404.06659</link>
      <description><![CDATA[arXiv:2404.06659v1 公告类型：新
摘要：会话任务助手（CTA）指导用户执行多种活动，例如制作食谱。然而，确保交互对于 CTA 用户来说仍然具有吸引力、有趣和愉快并不是一件小事，尤其是对于耗时或具有挑战性的任务。基于人类兴趣的心理学理论，我们建议在与多模式 CTA 交互时让用户了解上下文和有趣的陈述或事实，以减少任务完成前的疲劳和任务放弃。为了实现这个想法，我们训练了一个高性能分类器（F1 分数为 82%）来自动识别用户相关且有趣的事实。我们用它来创建烹饪领域特定任务的有趣事实的带注释数据集。最后，我们设计并验证对话策略，将识别出的相关且有趣的事实纳入对话中，以提高用户参与度和任务完成度。对领先的多模态语音助手的实时测试表明，66% 的所呈现事实得到了积极反馈，用户满意度提高了 40%，对话长度增加了 37%。这些发现强调，战略性地将有趣的事实融入到 CTA 体验中可以促进现实世界的用户参与引导任务交互。]]></description>
      <guid>https://arxiv.org/abs/2404.06659</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:41 GMT</pubDate>
    </item>
    <item>
      <title>FairPair：通过配对扰动对语言模型中的偏差进行稳健评估</title>
      <link>https://arxiv.org/abs/2404.06619</link>
      <description><![CDATA[arXiv:2404.06619v1 公告类型：新
摘要：准确评估语言模型中针对特定群体的差异化处理对于确保积极且安全的用户体验至关重要。理想的评估应该具有鲁棒性、可扩展到新的组或属性，并且能够捕获典型用法中出现的偏差（而不仅仅是极端、罕见的情况）。与此相关的是，偏见评估不仅应该揭露严重的偏见，还应该揭露那些微妙和普遍的偏见，例如谈论女性外表的可能性。我们提出 FairPair，一个评估框架，用于评估日常使用过程中发生的差别待遇。 FairPair 通过反事实对进行操作，但最重要的是，配对的延续基于相同的人口统计群体，这确保了等效比较。此外，与之前的工作不同，我们的方法通过测量采样变异性来考虑生成过程本身的固有变异性。我们对几种常用的生成模型进行了评估，并进行了定性分析，表明女性更倾向于讨论家庭和爱好。]]></description>
      <guid>https://arxiv.org/abs/2404.06619</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:40 GMT</pubDate>
    </item>
    <item>
      <title>你最喜欢的性别是什么，传销？多语言屏蔽语言模型中的性别偏见评估</title>
      <link>https://arxiv.org/abs/2404.06621</link>
      <description><![CDATA[arXiv:2404.06621v1 公告类型：新
【摘要】：偏见是一种偏向某一方而不是另一方的不成比例的偏见。由于基于 Transformer 的屏蔽语言模型 (MLM) 的成功及其对许多 NLP 任务的影响，比以往任何时候都更需要对这些模型中的偏差进行系统评估。虽然许多研究评估了英语传销中的性别偏见，但只有少数研究用其他语言进行过这项任务。本文提出了一种多语言方法来估计 5 种语言的传销中的性别偏见：中文、英语、德语、葡萄牙语和西班牙语。与之前的工作不同，我们的方法不依赖于平行语料库和英语来使用多语言词典检测其他语言中的性别偏见。此外，与传统的基于词典的方法相比，提出了一种基于模型的新颖方法来生成句子对，以便对性别偏见进行更稳健的分析。对于每种语言，基于词典和基于模型的方法分别用于创建两个数据集，这些数据集用于使用一个现有的和 3 个新的评分指标来评估专门针对该语言训练的 MLM 中的性别偏见。我们的结果表明，以前的方法是数据敏感的并且不稳定，因为它没有消除与性别无关的上下文依赖性。事实上，当在同一数据集上使用不同的评分指标时，结果经常会发生翻转，这表明应使用多个评估指标在大型数据集上研究性别偏见，以实现最佳实践。]]></description>
      <guid>https://arxiv.org/abs/2404.06621</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:40 GMT</pubDate>
    </item>
    <item>
      <title>Khayyam 挑战 (PersianMMLU)：您的法学硕士真的精通波斯语吗？</title>
      <link>https://arxiv.org/abs/2404.06644</link>
      <description><![CDATA[arXiv:2404.06644v1 公告类型：新
摘要：由于大型语言模型 (LLM) 的生成性质，评估大型语言模型 (LLM) 具有挑战性，需要精确的评估方法。此外，非英语LLM的评估落后于英语，导致许多语言的LLM缺乏或薄弱。为了满足这一需求，我们推出了 Khayyam Challenge（也称为 PersianMMLU），这是一个精心策划的题库，包含 20,192 道四选题，这些题目来自波斯语考试中提取的 38 项不同任务，涵盖广泛的主题、复杂性和年龄。海亚姆挑战赛的主要目标是促进对支持波斯语的法学硕士的严格评估。 Khayyam挑战赛的显着特点是（i）全面覆盖各种主题，包括文学理解、数学、科学、逻辑、智力测试等，旨在评估法学硕士的语言理解、推理和信息检索等不同方面涵盖从小学到高中的各个教育阶段 (ii) 包含丰富的元数据，例如人类响应率、难度级别和描述性答案 (iii) 利用新数据来避免现有框架中普遍存在的数据污染问题(iv) 使用为波斯语使用者量身定制的原始非翻译数据，确保该框架不存在翻译挑战和错误，同时涵盖文化细微差别 (v) 其固有的可扩展性，可用于未来的数据更新和评估，无需特殊的人力。以前的工作缺乏将所有这些功能组合成一个综合基准的评估框架。此外，我们还评估了各种支持波斯语的现有法学硕士，并对它们的输出进行了统计分析和解释。]]></description>
      <guid>https://arxiv.org/abs/2404.06644</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:40 GMT</pubDate>
    </item>
    <item>
      <title>少即是多，提高事实一致性的自动评估</title>
      <link>https://arxiv.org/abs/2404.06579</link>
      <description><![CDATA[arXiv:2404.06579v1 公告类型：新
摘要：评估自动生成的文本相对于源上下文的事实一致性对于开发可靠的自然语言生成应用程序至关重要。最近的文献提出了 AlignScore，它使用统一的对齐模型来评估事实一致性，并且在许多基准任务中大大优于以前的方法。在本文中，我们仔细研究了 AlignScore 中使用的数据集，并发现了一个意外的发现：利用较少数量的数据点实际上可以提高性能。我们处理原始 AlignScore 训练数据集以消除噪声，使用鲁棒性增强的样本进行扩充，并利用包含 10% 数据的子集来训练改进的事实一致性评估模型，我们称之为 LIM-RA（Less Is More for Robust AlignScore） ）。 LIM-RA 在四个基准测试中表现出卓越的性能，始终优于 AlignScore 和 ChatGPT 等其他强大基准（两个基准测试使用传统的自然语言生成数据集，两个基准测试专注于大型语言模型输出）。我们的实验表明，LIM-RA 在 33 个测试数据集中的 24 个上取得了最高分，同时在其余数据集上保持竞争力，建立了新的最先进基准。]]></description>
      <guid>https://arxiv.org/abs/2404.06579</guid>
      <pubDate>Thu, 11 Apr 2024 06:16:39 GMT</pubDate>
    </item>
    </channel>
</rss>