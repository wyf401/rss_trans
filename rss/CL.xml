<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 13 Jan 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>LLM-MedQA：通过大型语言模型中的案例研究增强医学问答能力</title>
      <link>https://arxiv.org/abs/2501.05464</link>
      <description><![CDATA[arXiv:2501.05464v1 公告类型：新
摘要：准确高效的问答系统对于在医疗领域提供高质量的患者护理至关重要。虽然大型语言模型 (LLM) 在各个领域取得了显著进步，但它们在医学问答方面仍然面临重大挑战，特别是在理解领域特定术语和执行复杂推理方面。这些限制削弱了它们在关键医疗应用中的有效性。为了解决这些问题，我们提出了一种新颖的方法，将类似案例生成纳入多智能体医学问答 (MedQA) 系统中。具体来说，我们在多智能体架构中利用最先进的 LLM Llama3.1:70B 模型，使用零样本学习来提高 MedQA 数据集的性能。我们的方法利用模型固有的医学知识和推理能力，无需额外的训练数据。实验结果表明，与现有基准模型相比，该模型的性能有显著提升，在各种医学问答任务中，准确率和 F1 分数均提高了 7%。此外，我们还测试了该模型在解决复杂医学问题时的可解释性和可靠性。这项研究不仅为医学问答提供了强大的解决方案，还为 LLM 在医学领域的更广泛应用奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2501.05464</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>小型语言模型 (SLM) 仍能发挥作用：一项调查</title>
      <link>https://arxiv.org/abs/2501.05465</link>
      <description><![CDATA[arXiv:2501.05465v1 公告类型：新
摘要：随着基础 AI 模型的规模不断扩大，一个重要的问题出现了——大规模是唯一的前进道路吗？这项对约 160 篇论文的调查介绍了一系列参数范围在 1 到 80 亿的小型语言模型 (SLM)，这些模型表明较小的模型可以表现得同样好，甚至优于大型模型。我们探索与任务无关的通用 SLM、特定于任务的 SLM 和创建 SLM 的技术，这些 SLM 可以指导社区构建模型，同时平衡性能、效率、可扩展性和成本。此外，我们定义和描述了 SLM 的有效尺寸，代表了相对于 LLM 的增强能力。]]></description>
      <guid>https://arxiv.org/abs/2501.05465</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LatteReview：使用大型语言模型进行系统评价自动化的多智能体框架</title>
      <link>https://arxiv.org/abs/2501.05468</link>
      <description><![CDATA[arXiv:2501.05468v1 公告类型：新
摘要：系统文献综述和荟萃分析对于综合研究见解至关重要，但由于筛选、评估和数据提取的迭代过程，它们仍然耗时且耗力。本文介绍并评估了 LatteReview，这是一个基于 Python 的框架，利用大型语言模型 (LLM) 和多代理系统来自动化系统审查过程的关键要素。LatteReview 旨在简化工作流程同时保持严谨性，它利用模块化代理执行标题和摘要筛选、相关性评分和结构化数据提取等任务。这些代理在精心策划的工作流程中运行，支持顺序和并行审查轮次、动态决策以及基于用户反馈的迭代改进。LatteReview 的架构集成了 LLM 提供程序，从而能够兼容基于云和本地托管的模型。该框架支持多种功能，例如用于整合外部上下文的检索增强生成 (RAG)、多模态评论、基于 Pydantic 的结构化输入和输出验证以及用于处理大规模数据集的异步编程。该框架可在 GitHub 存储库中找到，并附带详细文档和可安装包。]]></description>
      <guid>https://arxiv.org/abs/2501.05468</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于缺失多模态情绪分析的模态不变双向时间表征蒸馏网络</title>
      <link>https://arxiv.org/abs/2501.05474</link>
      <description><![CDATA[arXiv:2501.05474v1 公告类型：新
摘要：多模态情绪分析（MSA）整合了多种模态（文本、音频和视频），以全面分析和理解个人的情绪状态。然而，现实世界中不完整数据的普遍存在对 MSA 提出了重大挑战，主要是由于模态缺失的随机性。此外，多模态数据中的异质性问题尚未得到有效解决。为了应对这些挑战，我们引入了模态不变双向时间表示蒸馏网络（MITR-DNet）用于缺失多模态情绪分析。MITR-DNet 采用蒸馏方法，其中完整的模态教师模型指导缺失的模态学生模型，确保在模态缺失的情况下的稳健性。同时，我们开发了模态不变双向时间表示学习模块（MIB-TRL）来缓解异质性。]]></description>
      <guid>https://arxiv.org/abs/2501.05474</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士 (LLM) 中通过证据追溯实现检索增强生成</title>
      <link>https://arxiv.org/abs/2501.05475</link>
      <description><![CDATA[arXiv:2501.05475v1 公告类型：新
摘要：检索增强生成因其能够整合相关的外部知识、提高 LLM 响应的准确性和可靠性而受到广泛关注。大多数现有方法都采用动态的多重检索生成过程，通过将多跳复杂问题分解为子问题来解决这些问题。然而，这些方法依赖于单向正向推理范式，其中推理步骤不足或当前检索系统固有缺陷导致的错误是不可逆的，可能会破坏整个推理链。这项工作首次引入了追溯检索增强生成 (RetroRAG)，这是一种构建追溯推理范式的新颖框架。RetroRAG 修改和更新证据，将推理链重定向到正确的方向。RetroRAG 构建了一个证据整理发现框架来搜索、生成和提炼可信证据。它从现有的源知识中综合与问题中的关键实体相关的推理证据，并制定搜索查询以发现更多信息。随着新证据的发现，RetroRAG 不断更新和组织这些信息，增强其查找进一步必要证据的能力。与 Answerer 配对以生成和评估输出，RetroRAG 能够迭代地改进其推理过程，直到获得可靠的答案。实证评估表明，RetroRAG 的表现明显优于现有方法。]]></description>
      <guid>https://arxiv.org/abs/2501.05475</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>IntegrityAI 在 GenAI 检测任务 2 中的应用：使用 ELECTRA 和文体学检测机器生成的英语和阿拉伯语学术论文</title>
      <link>https://arxiv.org/abs/2501.05476</link>
      <description><![CDATA[arXiv:2501.05476v1 公告类型：新
摘要：最近的研究调查了用于学术目的的机器生成论文检测问题。为了应对这一挑战，本研究利用预先训练的基于 Transformer 的模型，该模型针对具有文体特征的阿拉伯语和英语学术论文进行了微调。使用基准数据集训练和评估了基于英语 ELECTRA 和阿拉伯语 AraELECTRA 的自定义模型。提出的模型取得了优异的成绩，F1 得分为 99.7%，在英语子任务的 26 个团队中排名第二，98.4%，在阿拉伯语子任务的 23 个团队中排名第一。]]></description>
      <guid>https://arxiv.org/abs/2501.05476</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器人导航中的语言和规划：对最先进模型的多语言评估</title>
      <link>https://arxiv.org/abs/2501.05478</link>
      <description><![CDATA[arXiv:2501.05478v1 公告类型：新 
摘要：大型语言模型 (LLM)（例如 GPT-4）在大量跨多个领域的数据集上进行训练，在各种任务中表现出显著的推理、理解和规划能力。这项研究首次介绍了机器人视觉和语言导航 (VLN) 领域中阿拉伯语集成的研究，这一领域在现有研究中尚未得到充分探索。我们对最先进的多语言小型语言模型 (SLM) 进行了全面评估，包括 GPT-4o mini、Llama 3 8B 和 Phi-3 medium 14B，以及以阿拉伯语为中心的 LLM Jais。我们的方法利用 NavGPT 框架（一个纯基于 LLM 的指令跟踪导航代理），通过使用 R2R 数据集的零样本顺序动作预测来评估语言对导航推理的影响。通过全面的实验，我们证明了我们的框架在提供英语和阿拉伯语指令时能够对导航任务进行高级规划。然而，由于其能力的固有限制、次优性能和解析问题，某些模型在阿拉伯语推理和规划方面遇到了困难。这些发现凸显了增强语言模型的规划和推理能力对于有效导航的重要性，强调这是进一步发展的关键领域，同时也释放了阿拉伯语模型在有影响力的现实世界应用中的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.05478</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>外科手术计费和编码生成式人工智能应用的实用设计和基准测试</title>
      <link>https://arxiv.org/abs/2501.05479</link>
      <description><![CDATA[arXiv:2501.05479v1 公告类型：新
摘要：背景：医疗保健有许多手动流程，这些流程可以从生成人工智能 (AI) 的自动化和增强中受益，即医疗计费和编码流程。然而，当前的基础大型语言模型 (LLM) 在生成准确的国际疾病分类第 10 版、临床修改 (ICD-10-CM) 和现行程序术语 (CPT) 代码时表现不佳。此外，在将生成式 AI 应用于医疗保健方面还面临许多安全和财务挑战。我们提出了一种在医疗保健领域开发生成式 AI 工具的策略，特别是针对医疗计费和编码，以平衡准确性、可访问性和患者隐私。
方法：我们使用机构数据对 PHI-3 Mini 和 PHI-3 Medium LLM 进行微调，并将结果与​​ PHI-3 基础模型、PHI-3 RAG 应用程序和 GPT-4o 进行比较。我们使用术后手术报告作为输入，并以患者账单索赔相关的 ICD-10、CPT 和修改器代码作为目标结果。性能通过代码生成的准确性、无效代码的比例和账单索赔格式的保真度来衡量。
结果：两种微调模型的表现都比 GPT-4o 更好或一样好。Phi-3 Medium 微调模型表现出最佳性能（ICD-10 召回率和准确率：72%、72%；CPT 召回率和准确率：77%、79%；修改器召回率和准确率：63%、64%）。Phi-3 Medium 微调模型仅伪造了 1% 的 ICD-10 代码和 0.6% 的 CPT 代码。
结论：我们的研究表明，使用一组简单的开源工具和最低的技术和资金要求针对特定任务对特定领域数据进行微调的小型模型的表现与更大的当代消费者模型一样好。]]></description>
      <guid>https://arxiv.org/abs/2501.05479</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>\textit{水与土地问题}：计算机作者验证研究</title>
      <link>https://arxiv.org/abs/2501.05480</link>
      <description><![CDATA[arXiv:2501.05480v1 公告类型：新
摘要：《水与地问题》是一本传统上归于但丁·阿利吉耶里的宇宙论论文。然而，由于与但丁既定作品存在差异，且缺乏当代参考文献，该文本的真实性存在争议。本研究通过计算作者验证 (AV) 调查《水与地问题》的真实性，这是一类结合监督机器学习和文体学的技术。我们建立了一个 AV 系统系列，并汇编了一个包含 330 篇 13 世纪和 14 世纪拉丁文本的语料库，我们通过留一交叉验证使用这些语料库对 AV 系统进行比较评估。尽管语料库在文本类型方面存在异质性，但我们表现最佳的系统仍实现了高验证准确率 (F1=0.970)。该系统准确性的关键贡献来自分布式随机过采样 (DRO)，这是一项专门针对文本分类而量身定制的技术，首次用于 AV。
AV 系统对 Questio 的应用对其真实性做出了高度自信的预测。这些发现有助于对 Questio 作者身份的争论，并凸显了 DRO 在将 AV 应用于文化遗产方面的潜力。]]></description>
      <guid>https://arxiv.org/abs/2501.05480</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HP-BERT：通过法学硕士纵向研究社交媒体上印度恐惧症的框架</title>
      <link>https://arxiv.org/abs/2501.05482</link>
      <description><![CDATA[arXiv:2501.05482v1 公告类型：新 
摘要：在 COVID-19 大流行期间，社区紧张局势加剧，助长了印度教恐惧症情绪，并加剧了印度及世界各地对印度教后裔的歧视。大型语言模型 (LLM) 在自然语言处理 (NLP) 任务和社交媒体分析中变得突出，使得对 X（以前称为 Twitter）等平台进行 COVID-19 期间特定问题的纵向研究成为可能。我们提出了一个滥用检测和情绪分析框架，该框架对 COVID-19 大流行期间和之后 X（Twitter）上的印度教恐惧症进行了纵向分析。该框架评估了印度教恐惧症话语的普遍性和强度，通过对预先训练和微调的 LLM 进行情绪分析和滥用检测，捕捉到贬义笑话和种族主义言论等元素。此外，我们整理并发布了“印度恐惧症 COVID-19 X（推特）数据集”，其中包含 8,000 条注释为检测印度恐惧症辱骂的推文，用于微调 BERT 模型，从而开发出印度恐惧症 BERT（HP-BERT）模型。然后，我们使用 SenWave 数据集进一步微调 HP-BERT，以进行多标签情绪分析。我们的研究涵盖了来自澳大利亚、巴西、印度、印度尼西亚、日本和英国等六个国家的约 2740 万条推文。我们的研究结果显示，COVID-19 病例激增与印度恐惧症言论激增之间存在很强的相关性，突显了政治叙事、错误信息和有针对性的笑话如何加剧了社区两极分化。这些见解为制定缓解未来本地和全球危机中社区紧张局势的战略提供了宝贵的指导。我们主张在社交媒体上实施自动监控和删除此类内容，以遏制分裂言论。]]></description>
      <guid>https://arxiv.org/abs/2501.05482</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>S2 分块：通过综合空间和语义分析进行文档分割的混合框架</title>
      <link>https://arxiv.org/abs/2501.05485</link>
      <description><![CDATA[arXiv:2501.05485v1 公告类型：新
摘要：文档分块是自然语言处理 (NLP) 中的一项关键任务，涉及将文档划分为有意义的片段。传统方法通常仅依赖于语义分析，而忽略了元素的空间布局，这对于理解复杂文档中的关系至关重要。本文介绍了一种新颖的混合方法，该方法结合了布局结构、语义分析和空间关系，以增强文档块的凝聚力和准确性。通过利用边界框信息 (bbox) 和文本嵌入，我们的方法构建了文档元素的加权图形表示，然后使用谱聚类对其进行聚类。实验结果表明，这种方法优于传统方法，特别是在具有多种布局的文档（例如报告、文章和多列设计）中。所提出的方法还确保没有块超过指定的标记长度，使其适用于标记限制至关重要的用例（例如，具有输入大小限制的语言模型）]]></description>
      <guid>https://arxiv.org/abs/2501.05485</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的未来：探索大型概念模型的潜力</title>
      <link>https://arxiv.org/abs/2501.05487</link>
      <description><![CDATA[arXiv:2501.05487v1 公告类型：新
摘要：人工智能 (AI) 领域继续推动变革性创新，对话界面、自动驾驶汽车和智能内容创建方面取得了重大进展。自 2022 年底 ChatGPT 推出以来，生成式人工智能的兴起标志着一个关键时代的到来，术语“大型语言模型 (LLM)”已成为日常生活中无处不在的一部分。LLM 在文本摘要、代码生成和创意写作等任务中表现出色。然而，这些模型本质上受到其 token 级处理的限制，这限制了它们执行抽象推理、概念理解和有效生成长篇内容的能力。为了解决这些限制，Meta 引入了大型概念模型 (LCM)，代表了与传统基于 token 的框架的重大转变。LCM 使用概念作为理解的基础单元，从而实现更复杂的语义推理和上下文感知决策。鉴于对这项新兴技术的学术研究有限，我们的研究旨在通过收集、分析和综合现有的灰色文献来弥补知识差距，以全面了解 LCM。具体来说，我们 (i) 识别和描述 LCM 与 LLM 的区别特征，(ii) 探索 LCM 在多个领域的潜在应用，以及 (iii) 提出未来的研究方向和实用策略，以推动 LCM 的开发和采用。]]></description>
      <guid>https://arxiv.org/abs/2501.05487</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于文档布局生成和分类的小型语言模型中的空间信息集成</title>
      <link>https://arxiv.org/abs/2501.05497</link>
      <description><![CDATA[arXiv:2501.05497v1 公告类型：新
摘要：文档布局理解是一个研究领域，它分析文档中信息的空间排列，希望了解其结构和布局。诸如 LayoutLM（及其后续迭代）之类的模型可以理解具有 SotA 结果的半结构化文档；然而，缺乏开放的半结构化数据本身就是一个限制。虽然半结构化数据在日常生活中很常见（资产负债表、采购订单、收据），但缺乏用于训练此类文档的机器学习模型的公共数据集。在本次调查中，我们提出了一种生成新的、合成的布局信息的方法，可以帮助克服这种数据短缺。根据我们的结果，所提出的方法比另一种流行的布局生成方法 LayoutTransformer 表现更好。我们还表明，在某些情况下，当有边界框信息支持时，文本分类可以得到改善。]]></description>
      <guid>https://arxiv.org/abs/2501.05497</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>多元人格越多越好——微调层空间几何的简要介绍</title>
      <link>https://arxiv.org/abs/2501.05503</link>
      <description><![CDATA[arXiv:2501.05503v1 公告类型：新
摘要：深度学习模型的解释是一个快速发展的领域，尤其对语言模型感兴趣。这项任务有多种方法，包括训练更简单的模型来复制神经网络预测和分析模型的潜在空间。后一种方法使我们不仅可以识别模型决策过程中的模式，还可以了解其内部结构的特征。在本文中，我们分析了在使用额外的语法模块和包含新语法结构（多重人格）的数据训练 BERT 模型时其内部表示的变化。我们发现，添加单个语法层会导致模型在其内部分离新旧语法系统，从而提高困惑度指标的整体性能。]]></description>
      <guid>https://arxiv.org/abs/2501.05503</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>意义随时间变化的动态：大型语言模型的评估</title>
      <link>https://arxiv.org/abs/2501.05552</link>
      <description><![CDATA[arXiv:2501.05552v1 公告类型：新 
摘要：了解大型语言模型 (LLM) 如何掌握概念的历史背景及其语义演变对于推动人工智能和语言学研究至关重要。本研究旨在评估各种 LLM 捕捉意义时间动态的能力，特别是它们如何解释不同时间段的术语。我们分析了来自多个领域的各种术语，使用定制的提示并通过客观指标（例如困惑度和字数）和主观人类专家评估来衡量响应。我们的比较分析包括 ChatGPT、GPT-4、Claude、Bard、Gemini 和 Llama 等著名模型。研究结果揭示了每个模型在处理历史背景和语义变化方面存在明显差异，突出了时间语义理解的优势和局限性。这些见解为改进 LLM 以更好地解决语言的演变性质提供了基础，对历史文本分析、人工智能设计和数字人文应用具有重要意义。]]></description>
      <guid>https://arxiv.org/abs/2501.05552</guid>
      <pubDate>Mon, 13 Jan 2025 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>