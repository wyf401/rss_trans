<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Tue, 30 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>乌克兰语毒性分类</title>
      <link>https://arxiv.org/abs/2404.17841</link>
      <description><![CDATA[arXiv:2404.17841v1 公告类型：新
摘要：毒性检测任务仍然是一项相关任务，特别是在安全和公平的 LM 开发背景下。然而，并非所有语言都有标记的二元毒性分类语料库，考虑到注释过程的资源密集型性质，这是可以理解的。尤其是乌克兰语，是缺乏此类资源的语言之一。据我们所知，乌克兰语中没有现有的毒性分类语料库。在本研究中，我们旨在通过研究跨语言知识转移技术并通过以下方式创建标记语料库来填补这一空白：(i)~从英语语料库翻译，(ii)~使用关键字过滤有毒样本，以及 (iii)~使用众包进行注释。我们比较了 LLM 提示和其他跨语言转移方法，包括微调和不微调，从而深入了解最稳健和最有效的基线。]]></description>
      <guid>https://arxiv.org/abs/2404.17841</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:26 GMT</pubDate>
    </item>
    <item>
      <title>回忆、检索和推理：迈向更好的上下文关系提取</title>
      <link>https://arxiv.org/abs/2404.17809</link>
      <description><![CDATA[arXiv:2404.17809v1 公告类型：新
摘要：关系提取（RE）旨在识别文本中提到的实体之间的关系。尽管大型语言模型（LLM）在各种任务中表现出了令人印象深刻的上下文学习（ICL）能力，但与大多数有监督的微调 RE 方法相比，它们仍然表现不佳。将 ICL 用于法学硕士的 RE 会遇到两个挑战：(1) 从训练示例中检索良好的演示，以及 (2) 使法学硕士能够在 RE 中表现出强大的 ICL 能力。一方面，在RE中检索好的示范是一个不平凡的过程，这很容易导致实体和关系的相关性较低。另一方面，带有LLM的ICL在RE中的表现较差，而RE本质上与语言建模不同，或者LLM不够大。在这项工作中，我们提出了一种新颖的召回-检索-推理 RE 框架，该框架将法学硕士与检索语料库（训练示例）相结合，以实现相关检索和可靠的上下文推理。具体来说，我们从训练数据集中提取一致的本体知识，让法学硕士生成以检索语料库为基础的相关实体对作为有效查询。然后使用这些实体对从检索语料库中检索相关的训练示例，作为法学硕士通过指令调整进行更好的 ICL 的演示。对不同 LLM 和 RE 数据集的大量实验表明，我们的方法生成相关且有效的实体对，并增强了 LLM 的 ICL 能力，与之前的监督微调方法相比，在句子级 RE 上实现了有竞争力或新的最先进性能以及基于 ICL 的方法。]]></description>
      <guid>https://arxiv.org/abs/2404.17809</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>波兰语分类任务的少样本学习评估</title>
      <link>https://arxiv.org/abs/2404.17832</link>
      <description><![CDATA[arXiv:2404.17832v1 公告类型：新
摘要：我们引入了一个由 7 个不同的波兰语分类任务组成的基准测试。我们使用各种预先训练的商业和开源模型，对微调、线性探测、SetFit 和上下文学习 (ICL) 之间的 0 和 16 个镜头进行了实证比较。我们的研究结果表明，ICL 实现了最佳性能，其中 GPT-3.5 和 GPT-4 等商业模型获得了最佳性能。然而，我们的最佳几次学习得分与 HerBERT-large 在整个训练数据集上进行微调的性能之间仍然存在 14 个百分点的显着差距。在这些技术中，SetFit 成为第二好的方法，紧随其后的是线性探测。我们观察到非线性磁头微调的最差和最不稳定的性能。 ICL 的结果表明，在波兰语料库上对 Mistral-7b 或 Llama-2-13b 等模型进行持续预训练是有益的。 Bielik-7b 和 Trurl-13b 的性能改进分别证实了这一点。为了进一步支持波兰语的少样本学习实验，我们正在发布手工制作的 ICL 模板。]]></description>
      <guid>https://arxiv.org/abs/2404.17832</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>VANER：利用大型语言模型实现多功能和自适应生物医学命名实体识别</title>
      <link>https://arxiv.org/abs/2404.17835</link>
      <description><![CDATA[arXiv:2404.17835v1 公告类型：新
摘要：BioNER 的普遍解决方案涉及使用表示学习技术和序列标记。然而，此类方法本质上是特定于任务的，普遍性较差，并且通常需要针对每个数据集的专用模型。为了利用最近引人注目的大型语言模型（LLM）的多功能功能，一些努力已经探索了实体提取的生成方法。然而，这些方法往往达不到以前序列标记方法的有效性。在本文中，我们利用开源的LLM LLaMA2作为主干模型，并设计特定的指令来区分不同类型的实体和数据集。通过将法学硕士对指令的理解与序列标记技术相结合，我们使用混合数据集来训练能够提取各种类型实体的模型。鉴于骨干法学硕士缺乏专业的医学知识，我们还集成外部实体知识库并采用指令调整来迫使模型密集识别精心策划的实体。我们的模型 VANER 使用小部分参数进行训练，显着优于以前基于 LLM 的模型，并且作为基于 LLM 的模型，首次超越了大多数传统的最先进的 BioNER 系统，实现了三个数据集的最高 F1 分数。]]></description>
      <guid>https://arxiv.org/abs/2404.17835</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:25 GMT</pubDate>
    </item>
    <item>
      <title>元上下文学习使大型语言模型更好的零和少样本关系提取器</title>
      <link>https://arxiv.org/abs/2404.17807</link>
      <description><![CDATA[arXiv:2404.17807v1 公告类型：新
摘要：关系提取（RE）是一项重要任务，旨在识别文本中实体之间的关系。虽然大型语言模型 (LLM) 在一般的零和少样本学习中展现了卓越的上下文学习 (ICL) 能力，但最近的研究表明，当前的 LLM 仍然在零和少样本 RE 方面苦苦挣扎。之前的研究主要致力于设计提示格式并选择好的例子来改进基于 ICL 的 RE。尽管这两个因素对于 ICL 都至关重要，但如果能够从根本上提高 RE 中 LLM 的 ICL 能力，那么通过 ICL 实现的零和少样本 RE 性能将得到显着提高。为此，我们引入了 \textsc{Micre} (\textbf{M}eta \textbf{I}n-\textbf{C}ontext Learning of LLMs for \textbf{R}elation \textbf{E}xtraction)，针对零次和少次 RE 的新元训练框架，其中 LLM 被调整为在不同的 RE 数据集集合上进行 ICL（即学习在 RE 的上下文中学习）。通过元训练，模型可以通过在推理时以一些没有参数更新或特定于任务的模板的训练示例为条件，更有效地在上下文中学习新的 RE 任务，从而实现更好的零和少样本任务泛化。我们在具有不同模型规模和 12 个公共 RE 数据集的各种 LLM 上实验 \textsc{Micre}，然后在零和少样本设置下在未见过的 RE 基准上对其进行评估。与一系列基线（包括监督微调和典型的上下文学习方法）相比，\textsc{Micre} 提供了相当或更好的性能。我们发现，对于较大的模型规模，收益尤其显着，并且使用不同的元训练 RE 数据集是改进的关键。根据经验，我们表明 \textsc{Micre} 可以在目标 RE 数据集的推理过程中通过关系标签名称传递关系语义知识。]]></description>
      <guid>https://arxiv.org/abs/2404.17807</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>Scaffold-BPE：通过简单有效的 Scaffold 令牌删除增强字节对编码</title>
      <link>https://arxiv.org/abs/2404.17808</link>
      <description><![CDATA[arXiv:2404.17808v1 公告类型：新
摘要：字节对编码（BPE）是自然语言处理（NLP）领域中文本标记化的基础方法。尽管被广泛采用，原始的 BPE 算法存在一个固有的缺陷：它无意中引入了文本语料库中标记的频率不平衡。由于 BPE 迭代地合并文本语料库中最常见的标记对，同时保留词汇表中已合并的所有标记，因此它不可避免地保留主要代表完整单词的子词且在文本语料库中很少出现的标记。我们将此类代币称为支架代币。由于脚手架令牌很少出现在文本语料库中，因此给语言模型带来了学习不平衡问题。为了解决这个问题，我们提出了 Scaffold-BPE，它通过对原始 BPE 进行无参数、轻计算且易于实现的修改，结合了动态脚手架令牌删除机制。这种新颖的方法确保从给定文本的标记表示中排除低频支架标记，从而减轻频率不平衡问题并促进模型训练。在跨语言建模任务和机器翻译任务的大量实验中，Scaffold-BPE 始终优于原始 BPE，充分证明了其有效性和优越性。]]></description>
      <guid>https://arxiv.org/abs/2404.17808</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的时间缩放定律</title>
      <link>https://arxiv.org/abs/2404.17785</link>
      <description><![CDATA[arXiv:2404.17785v1 公告类型：新
摘要：最近，大型语言模型（LLM）在各种任务中被广泛采用，导致人们越来越关注扩展 LLM 如何影响其性能的研究。称为“缩放定律”的现有研究发现，法学硕士的损失随着模型大小、计算预算和数据集大小的幂律而变化。然而，法学硕士在整个培训过程中的表现保持不变。在本文中，我们提出了时间尺度法则的新概念，并从时间维度研究了法学硕士的损失。我们首先调查每个代币位置的损失不平衡，并制定跨模型规模和训练阶段的倒数定律。然后，我们通过研究倒数律参数的时间模式来推导时间标度律。分布内（IID）数据和分布外（OOD）数据的结果表明，我们的时间缩放定律准确地预测了 LLM 在未来训练阶段的表现。此外，时间缩放定律表明，尽管损失不平衡，法学硕士在不同的代币位置上学习是一致的。各种规模的预训练LLM的实验表明，这种现象验证了生成语言模型的默认训练范式，即在训练过程中不附加重新加权策略。总体而言，时间缩放定律提供了对 LLM 预训练的更深入的了解。]]></description>
      <guid>https://arxiv.org/abs/2404.17785</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>跨语言LLM适应的持续预训练：增强日语能力</title>
      <link>https://arxiv.org/abs/2404.17790</link>
      <description><![CDATA[arXiv:2404.17790v1 公告类型：新
摘要：对最初在英语语料库上训练的大型语言模型 (LLM) 进行跨语言持续预训练，使我们能够利用大量英语语言资源并降低预训练成本。在本研究中，我们通过扩展 Llama 2 的词汇表以包含日语字符并在大型日语网络语料库上进行持续预训练，构建了具有增强日语能力的 LLM Swallow。实验结果证实，通过持续预训练，日语任务的性能得到了显着提高，并且随着训练数据量增加到 100B 个 token，性能单调增加。因此，与其他从头开始用英语和日语训练的 LLM 相比，Swallow 取得了卓越的表现。对持续预训练效果的分析表明，它对日语问答任务特别有效。此外，为了阐明从英语到日语的跨语言持续预训练的有效方法，我们研究了词汇量扩展的影响以及结合平行语料库的有效性。结果表明，通过词汇量扩展获得的效率对表现没有负面影响，除了总结任务，而结合使用平行语料库可以提高翻译能力。]]></description>
      <guid>https://arxiv.org/abs/2404.17790</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型对话关系抽取实证分析</title>
      <link>https://arxiv.org/abs/2404.17802</link>
      <description><![CDATA[arXiv:2404.17802v1 公告类型：新
摘要：对话关系提取（DRE）旨在提取对话中两个论点之间的关系，由于对话中人称代词频率较高且信息密度较低，这比标准 RE 更具挑战性。然而，现有的DRE方法仍然存在两个严重的问题：（1）难以捕获长且稀疏的多轮信息，（2）难以基于部分对话提取黄金关系，这促使我们发现更有效的方法缓解以上问题。我们注意到，大型语言模型（LLM）的兴起引发了人们对评估其在不同任务中的表现的极大兴趣。为此，我们首先研究了不同法学硕士在 DRE 中的能力，同时考虑了专有模型和开源模型。有趣的是，我们发现法学硕士显着缓解了现有 DRE 方法中的两个问题。总的来说，我们有以下发现：（1）扩大模型大小可以显着提高整体 DRE 性能并取得优异的结果，解决了捕获长且稀疏的多轮信息的困难； （2）与现有方法相比，LLM从整个对话设置到部分对话设置的性能下降要小得多； (3) 与当前最先进的技术相比，法学硕士在全镜头和少镜头设置下都能提供具有竞争力或优越的性能； (4) 法学硕士在逆关系上表现一般，但在一般关系上有更强的改进，并且它们可以处理各种长度的对话，特别是对于较长的序列。]]></description>
      <guid>https://arxiv.org/abs/2404.17802</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>MRScore：使用基于法学硕士的奖励系统评估放射学报告的生成</title>
      <link>https://arxiv.org/abs/2404.17778</link>
      <description><![CDATA[arXiv:2404.17778v1 公告类型：新
摘要：近年来，自动化放射学报告生成经历了显着增长。本文介绍了 MRScore，这是一种利用大型语言模型 (LLM) 为放射学报告生成量身定制的自动评估指标。正如我们在本文中的观察所系统地证明的那样，BLEU 等传统的 NLG（自然语言生成）指标不足以准确评估生成的放射学报告。为了应对这一挑战，我们与放射科医生合作开发了一个框架，指导法学硕士进行放射学报告评估，确保与人类分析保持一致。我们的框架包括两个关键组成部分：i）利用 GPT 生成大量训练数据，即具有不同质量的报告；ii）将 GPT 生成的报告配对为接受和拒绝的样本，并训练 LLM 生成 MRScore 作为模型奖励。我们的实验证明，与传统指标相比，MRScore 与人类判断具有更高的相关性，并且在模型选择方面具有卓越的性能。我们的代码和数据集将在 GitHub 上提供。]]></description>
      <guid>https://arxiv.org/abs/2404.17778</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>大脑异常的医学视觉语言预训练</title>
      <link>https://arxiv.org/abs/2404.17779</link>
      <description><![CDATA[arXiv:2404.17779v1 公告类型：新
摘要：视觉语言模型对于需要理解视觉和语言元素的任务变得越来越强大，弥合了这些模式之间的差距。在多模式临床人工智能的背景下，对拥有特定领域知识的模型的需求不断增长，因为现有模型往往缺乏医疗应用所需的专业知识。在本文中，我们以大脑异常为例，演示如何从 PubMed 等公共资源自动收集医学图文对齐数据进行预训练。特别是，我们提出了一个简化预训练过程的管道，首先从病例报告和已发表的期刊中收集大型大脑图像文本数据集，然后构建针对特定医疗任务的高性能视觉语言模型。我们还研究了医学领域中将子图映射到子标题的独特挑战。我们通过定量和定性的内在评估来评估最终的模型。生成的数据集和我们的代码可以在这里找到 https://github.com/masoud-monajati/MedVL_pretraining_pipeline]]></description>
      <guid>https://arxiv.org/abs/2404.17779</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:22 GMT</pubDate>
    </item>
    <item>
      <title>PLAYER*：增强基于 LLM 的谋杀悬疑游戏中的多智能体沟通与互动</title>
      <link>https://arxiv.org/abs/2404.17662</link>
      <description><![CDATA[arXiv:2404.17662v1 公告类型：新
摘要：大型语言模型（LLM）的最新进展提高了代理沟通和社交互动的效率。尽管取得了这些进步，但由于基于图的知情搜索方法的局限性，构建用于在涉及竞争和协作的动态环境中进行推理的基于 LLM 的代理仍然具有挑战性。我们提出了 PLAYER*，这是一种基于随时采样的规划器的新颖框架，它利用传感器和修剪器为复杂的推理任务提供纯粹的问题驱动的搜索框架。我们还引入了一种使用多项选择题的量化评估方法，并构建了包含 1,482 个 QA 对的 WellPlay 数据集。实验证明，与复杂、动态环境中的现有方法相比，PLAYER* 的效率和性能有所提高，并具有可量化的结果。]]></description>
      <guid>https://arxiv.org/abs/2404.17662</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>CoMM：协作多代理、多推理路径提示解决复杂问题</title>
      <link>https://arxiv.org/abs/2404.17729</link>
      <description><![CDATA[arXiv:2404.17729v1 公告类型：新
摘要：大型语言模型（LLM）在通过适当的提示技术解决传统自然语言任务和基本推理任务方面表现出了强大的能力。然而，他们解决复杂科学问题的能力仍然有限。在这项工作中，我们的目标是通过提出一种协作多智能体、多推理路径（CoMM）提示框架来推动法学硕士推理能力的上限。具体来说，我们促使法学硕士在问题解决团队中扮演不同的角色，并鼓励不同的角色扮演代理协作解决目标任务。特别是，我们发现针对不同角色应用不同的推理路径是在多智能体场景中实现少样本提示方法的有效策略。实证结果证明了所提出的方法在竞争基线上对两个大学水平的科学问题的有效性。我们的进一步分析表明，有必要促使法学硕士独立扮演不同的角色或专家。我们在以下位置发布代码：https://github.com/amazon-science/comm-prompt]]></description>
      <guid>https://arxiv.org/abs/2404.17729</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>为大型语言模型构建大型日语网络语料库</title>
      <link>https://arxiv.org/abs/2404.17733</link>
      <description><![CDATA[arXiv:2404.17733v1 公告类型：新
摘要：开放式日语大语言模型 (LLM) 已在语料库的日语部分（例如 CC-100、mC4 和 OSCAR）上进行了训练。然而，这些语料库并不是为了日语文本的质量而创建的。这项研究通过从 Common Crawl 档案（2020 年至 2023 年间抓取的约 634 亿个页面的 21 个快照）中提取和精炼文本，构建了一个大型日语网络语料库。该语料库包含约 3121 亿个字符（约 1.73 亿页），是日本 LLM 可用的所有培训语料库中最大的，超过了 CC-100（约 258 亿个字符）、mC4（约 2397 亿个字符）和 OSCAR 23.10（约 740 亿个字符）。为了确认语料库的质量，我们对 Llama 2 7B、13B、70B、Mistral 7B v0.1 和 Mixtral 8x7B Instruct 作为基础 LLM 进行了持续的预训练，并在日本基准数据集上获得了一致的改进（6.6-8.1 分） 。我们还证明，所提供的语料库对 Llama 2 13B 的改进是其他现有语料库中最大的。]]></description>
      <guid>https://arxiv.org/abs/2404.17733</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:21 GMT</pubDate>
    </item>
    <item>
      <title>为文本数据增强提供大型语言模型</title>
      <link>https://arxiv.org/abs/2404.17642</link>
      <description><![CDATA[arXiv:2404.17642v1 公告类型：新
摘要：凭借理解和执行自然​​语言指令的能力，大型语言模型（LLM）有可能成为文本数据增强的强大工具。然而，增强数据的质量在很大程度上取决于所提供的增强指令，并且其有效性可能会因不同的下游任务而波动。虽然手动制作和选择指令可以提供一些改进，但由于下游任务的多样性，这种方法在实践中面临可扩展性和一致性问题。在这项工作中，我们通过提出一种新的解决方案来解决这些限制，该解决方案可以自动生成大量增强指令并选择最合适的任务通知指令，从而使法学硕士能够为不同的下游任务创建高质量的增强数据。根据经验，与非 LLM 和基于 LLM 的数据增强方法相比，所提出的方法始终能够生成质量更好的增强数据，从而在来自广泛应用领域的 26 个小样本学习任务上获得最佳性能。]]></description>
      <guid>https://arxiv.org/abs/2404.17642</guid>
      <pubDate>Tue, 30 Apr 2024 06:17:20 GMT</pubDate>
    </item>
    </channel>
</rss>