<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Tue, 26 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>开源 LLM 能否增强毒性检测的数据增强？：一项实验研究</title>
      <link>https://arxiv.org/abs/2411.15175</link>
      <description><![CDATA[arXiv:2411.15175v1 公告类型：新
摘要：高质量、多样化的有害数据对于解决内容审核中的实时应用至关重要。当前使用 GPT 系列模型进行有毒内容检测的最先进方法成本高昂且缺乏可解释性。本文研究了在开源 LLM 上使用快速工程和微调技术来增强有害数据增强，特别是针对有毒内容检测。我们进行了一项两阶段的实证研究，第一阶段仅使用快速工程评估跨多个数据集的六个开源 LLM，第二阶段侧重于微调。我们的研究结果表明，Mistral 可以在生成有害数据方面表现出色，同时将幻觉降到最低。虽然对这些模型进行微调可以提高数据质量和多样性，但数据重复和过度拟合等挑战仍然存在。我们的实验结果强调了可扩展、经济高效的增强有毒内容检测系统的策略。这些发现不仅展示了开源 LLM 在创建强大的内容审核工具方面的潜力。该方法在实际工业场景中的应用进一步证明了经过微调的开源 LLM 用于数据增强的可行性和效率。我们希望我们的研究将有助于了解当前模型在有毒成分检测方面的能力和局限性，并推动该领域的进一步发展。]]></description>
      <guid>https://arxiv.org/abs/2411.15175</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于图神经网络的复杂知识图谱实体提取与关系推理</title>
      <link>https://arxiv.org/abs/2411.15195</link>
      <description><![CDATA[arXiv:2411.15195v1 Announce Type: new 
摘要：本研究提出了一种基于图神经网络的知识图谱实体抽取与关系推理算法，利用图卷积网络和图注意力网络对知识图谱中的复杂结构进行建模，通过构建端到端的联合模型，实现实体与关系的高效识别与推理。在实验中，本文将该模型与多种深度学习算法进行了对比，并通过AUC、召回率、准确率、F1值等指标验证了其优越性。实验结果表明，本文提出的模型在各项指标上均表现良好，尤其在复杂知识图谱中具有更强的泛化能力和稳定性。这为知识图谱的进一步研究提供了强有力的支持，也展示了图神经网络在实体抽取与关系推理中的应用潜力。]]></description>
      <guid>https://arxiv.org/abs/2411.15195</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>BanglaEmbed：使用跨语言提炼技术为低资源语言提供高效的句子嵌入模型</title>
      <link>https://arxiv.org/abs/2411.15270</link>
      <description><![CDATA[arXiv:2411.15270v1 公告类型：新
摘要：句子级嵌入对于需要理解自然语言的各种任务至关重要。许多研究已经探索了英语等高资源语言的此类嵌入。然而，像孟加拉语（一种近两亿三千万人使用的语言）这样的低资源语言仍未得到充分探索。这项工作为孟加拉语引入了两个轻量级句子转换器，利用了一种新颖的跨语言知识提炼方法。该方法从预先训练的高性能英语句子转换器中提取知识。提出的模型在多个下游任务中进行评估，包括释义检测、语义文本相似性 (STS) 和孟加拉仇恨言论检测。新方法的表现始终优于现有的孟加拉句子转换器。此外，轻量级架构和更短的推理时间使模型非常适合在资源受限的环境中部署，使其对低资源语言中的实际 NLP 应用很有价值。]]></description>
      <guid>https://arxiv.org/abs/2411.15270</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型中的谄媚行为：原因及缓解措施</title>
      <link>https://arxiv.org/abs/2411.15287</link>
      <description><![CDATA[arXiv:2411.15287v1 公告类型：新
摘要：大型语言模型 (LLM) 在广泛的自然语言处理任务中表现出了卓越的能力。然而，它们倾向于表现出谄媚行为——过度同意或奉承用户——这对它们的可靠性和道德部署构成了重大风险。本文对 LLM 中的谄媚行为进行了技术调查，分析了其原因、影响和潜在的缓解策略。我们回顾了最近关于测量和量化谄媚倾向的研究，研究了谄媚与幻觉和偏见等其他挑战之间的关系，并评估了在保持模型性能的同时减少谄媚的有希望的技术。探索的主要方法包括改进的训练数据、新颖的微调方法、部署后控制机制和解码策略。我们还讨论了谄媚对人工智能对齐的更广泛影响，并提出了未来研究的方向。我们的分析表明，减轻谄媚对于开发更为稳健、可靠和符合道德的语言模型至关重要。]]></description>
      <guid>https://arxiv.org/abs/2411.15287</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PPLqa：用于比较生成大型语言模型的无监督信息论质量度量</title>
      <link>https://arxiv.org/abs/2411.15320</link>
      <description><![CDATA[arXiv:2411.15320v1 公告类型：新
摘要：我们提出了 PPLqa，这是一种易于计算、独立于语言的信息理论度量，用于以无监督的方式测量生成大型语言模型 (LLM) 的响应质量，而无需基本事实注释或人工监督。该方法和度量使用户能够对生成语言模型的响应质量进行排名，从而为给定任务选择最佳模型。我们的单一指标评估 LLM 的方法包含但不明确基于查询的连贯性和流畅性（写作质量）以及相关性和一致性（响应的适当性）。PPLqa 的表现与其他相关指标一样好，并且更适用于长格式问答。因此，PPLqa 可以绕过基本事实评估所需的冗长的注释过程，并且它也与人工和 LLM 排名有很好的相关性。]]></description>
      <guid>https://arxiv.org/abs/2411.15320</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Babylon 改造 NLU：用于自动免下车订购的实时、边缘高效、多意图翻译系统的开发案例研究</title>
      <link>https://arxiv.org/abs/2411.15372</link>
      <description><![CDATA[arXiv:2411.15372v1 公告类型：新
摘要：实时对话式 AI 代理在自动驾车系统等动态户外环境中执行自然语言理解 (NLU) 时面临挑战。这些设置要求 NLU 模型在边缘设备的严格延迟和内存限制下运行时处理背景噪音、不同的口音和多意图查询。此外，对上游自动语音识别 (ASR) 错误的鲁棒性至关重要，因为这些环境中的 ASR 输出通常很嘈杂。我们介绍了 Babylon，这是一种基于转换器的架构，它将 NLU 作为意图翻译任务来处理，将自然语言输入转换为常规语言单元序列（“转码”），这些序列同时编码意图和时隙信息。这种公式允许 Babylon 在一次对话中管理多意图场景。此外，Babylon 结合了基于 LSTM 的令牌池机制来预处理音素序列，从而缩短了输入长度并针对低延迟、低内存边缘部署进行了优化。这也有助于缓解 ASR 输出中的不准确性，从而增强系统的稳健性。虽然这项工作主要针对免下车点餐，但 Babylon 的设计也扩展到了类似的易受噪音影响的场景，例如售票亭。我们的实验表明，与通常使用的 NMT 模型（如 Flan-T5 和 BART）相比，Babylon 在准确度-延迟-内存占用方面的权衡明显更好，证明了其在边缘部署设置中对实时 NLU 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.15372</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>论微调对思路链推理的影响</title>
      <link>https://arxiv.org/abs/2411.15382</link>
      <description><![CDATA[arXiv:2411.15382v1 公告类型：新
摘要：大型语言模型已成为通用智能的强大工具，展示了可应用于不同领域的高级自然语言处理能力。尽管它们的表现令人印象深刻，但最近的研究强调了通过微调策略（如带人类反馈的强化学习 (RLHF)、监督微调 (SFT) 和量化低秩适配器 (Q-LoRA) 方法）显着提高 LLM 任务特定性能的潜力。然而，以前的研究表明，虽然微调可以显着提高性能，但它也带来了灾难性遗忘以及隐私和安全风险等挑战。为此，在 \textit{了解微调对 LLM 推理能力的影响} 方面几乎没有开展任何工作。我们的研究调查了微调对法学硕士推理能力的影响，解决了关于任务特定微调对整体推理能力的影响、微调对思维链 (CoT) 推理性能的影响以及对 CoT 推理忠实度的影响等关键问题。通过探索这些维度，我们的研究显示了微调对法学硕士推理能力的影响，其中四个数据集中 CoT 推理的忠实度平均下降，突显了微调过程可能导致法学硕士内部机制发生转变。]]></description>
      <guid>https://arxiv.org/abs/2411.15382</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从万事通到精通一门：专门为 LLM 自动评分器打造测试集</title>
      <link>https://arxiv.org/abs/2411.15387</link>
      <description><![CDATA[arXiv:2411.15387v1 公告类型：新
摘要：随着 LLM 变得越来越强大和多功能，人工评估在规模上很快变得难以处理，对自动指标的依赖已成为常态。最近，有研究表明 LLM 本身就是许多任务的最先进的评估器。这些自动评分器通常设计为可以推广到新系统和测试集。然而，在实践中，评估是在一小组固定的、规范的测试集上进行的，这些测试集经过精心策划，可以测量某些感兴趣的功能，并且不会经常更改。在这项工作中，我们设计了一种方法，通过利用测试集上的历史评分来构建上下文学习 (ICL) 示例，将提示的自动评分器专门用于给定的测试集。我们在细粒度机器翻译评估任务上评估了我们的专家方法，结果表明它在 WMT&#39;23 和 WMT&#39;24 测试集上的表现分别比最先进的 XCOMET 指标高出 54% 和 119%。我们进行了广泛的分析，以了解我们的专家指标所学习到的表征，以及评估者行为的变化如何影响他们的表现。我们还验证了我们的专家方法在不同数量的 ICL 示例、LLM 主干、要评估的系统和评估任务中设计自动指标的通用性和稳健性。]]></description>
      <guid>https://arxiv.org/abs/2411.15387</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>ML-SPEAK：一种用于研究和预测对话话轮模式的理论指导机器学习方法</title>
      <link>https://arxiv.org/abs/2411.15405</link>
      <description><![CDATA[arXiv:2411.15405v1 公告类型：新
摘要：根据人格特质预测团队动态仍然是心理科学和团队组织面临的基本挑战。了解团队组成如何产生团队流程可以显著推动团队研究，并为团队人员配备和培训提供实用指南。虽然输入-过程-输出 (IPO) 模型对于研究这些联系很有用，但团队成员互动的复杂性要求采用更动态的方法。我们开发了一个自组织团队中对话轮换的计算模型，可以深入了解团队成员人格特质与团队沟通动态之间的关系。我们专注于团队成员之间的轮换模式，与内容无关，它可以显著影响团队的突发状态和结果，同时具有客观可衡量和量化的特点。由于我们的模型是根据给定特征组成的团队的对话数据进行训练的，因此它可以学习个人特征与说话行为之间的关系，并仅根据团队特征组成来预测整个群体的沟通模式。我们首先使用模拟数据评估模型的性能，然后将其应用于从自组织的学生团队收集的真实数据。与基线相比，我们的模型在预测发言顺序方面更准确，并且可以揭示团队成员特征与其沟通模式之间的新关系。我们的方法提供了对团队流程的更数据驱动和动态的理解。通过弥合个人性格特征和团队沟通模式之间的差距，我们的模型有可能为团队流程理论提供信息，并为优化团队人员配置和培训提供有力的见解。]]></description>
      <guid>https://arxiv.org/abs/2411.15405</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>探索多模态情绪分析的大型语言模型：挑战、基准和未来方向</title>
      <link>https://arxiv.org/abs/2411.15408</link>
      <description><![CDATA[arXiv:2411.15408v1 公告类型：新
摘要：基于多模态方面的情绪分析 (MABSA) 旨在从多模态信息（包括文本和图像）中提取方面术语及其相应的情绪极性。虽然传统的监督学习方法已显示出在这项任务中的有效性，但大型语言模型 (LLM) 对 MABSA 的适应性仍不确定。LLM 的最新进展，例如 Llama2、LLaVA 和 ChatGPT，在一般任务中表现出强大的能力，但它们在 MABSA 等复杂和细粒度场景中的表现尚未得到充分探索。在本研究中，我们对 LLM 对 MABSA 的适用性进行了全面调查。为此，我们构建了一个基准来评估 LLM 在 MABSA 任务上的表现，并将它们与最先进的监督学习方法进行比较。我们的实验表明，虽然 LLM 在多模态理解方面表现出潜力，但它们在实现 MABSA 的令人满意的结果方面面临重大挑战，特别是在准确性和推理时间方面。基于这些发现，我们讨论了当前 LLM 的局限性，并概述了未来研究的方向，以增强其在多模态情绪分析方面的能力。]]></description>
      <guid>https://arxiv.org/abs/2411.15408</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>具有低秩混合专家的视觉语言模型的终身知识编辑</title>
      <link>https://arxiv.org/abs/2411.15432</link>
      <description><![CDATA[arXiv:2411.15432v1 公告类型：新
摘要：模型编辑旨在纠正不准确的知识，更新过时的信息，并将新数据合并到大型语言模型 (LLM) 中，而无需重新训练。这项任务在终身场景中提出了挑战，在这些场景中，必须不断将编辑应用于实际应用。虽然一些编辑器在纯 LLM 中表现出对终身编辑的强大鲁棒性，但包含额外视觉模态的视觉 LLM (VLLM) 不能直接适应现有的 LLM 编辑器。在本文中，我们提出了 LiveEdit，一种终身视觉语言模型，以弥合终身 LLM 编辑和 VLLM 之间的差距。我们首先训练一个编辑专家生成器，为每个编辑实例独立生成低秩专家，目的是纠正 VLLM 的相关响应。开发了一种硬过滤机制来利用视觉语义知识，从而在后编辑模型的推理阶段粗略地消除输入查询中视觉上不相关的专家。最后，为了整合视觉相关专家，我们引入了基于文本语义相关性的软路由机制来实现多专家融合。为了进行评估，我们建立了终身 VLLM 编辑的基准。大量实验表明 LiveEdit 在终身 VLLM 编辑场景中具有显著优势。进一步的实验验证了 LiveEdit 中各个模块设计的合理性和有效性。]]></description>
      <guid>https://arxiv.org/abs/2411.15432</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>高效三元权重嵌入模型：兼顾可扩展性和性能</title>
      <link>https://arxiv.org/abs/2411.15438</link>
      <description><![CDATA[arXiv:2411.15438v1 公告类型：新
摘要：嵌入模型已成为自然语言处理和计算机视觉中必不可少的工具，可实现高效的语义搜索、推荐、聚类等。然而，全精度嵌入的高内存和计算需求对资源受限环境（如实时推荐系统）中的部署提出了挑战。在这项工作中，我们提出了一种新颖的三元权重嵌入模型微调框架，可在保持高性能的同时减少内存和计算开销。为了将三元化应用于预训练的嵌入模型，我们引入了自学知识蒸馏来确定线性层的三元权重。通过在公共文本和视觉数据集上进行大量实验，我们证明了在不牺牲有效性的情况下，三元化模型消耗的内存很少，推理阶段的延迟很低，效率很高。在实际实现中，嵌入模型通常与近似最近邻 (ANN) 搜索集成。我们将三元嵌入与 ANN 搜索相结合的实验在准确性和计算效率方面都取得了显著的提升。存储库可在此处获取。]]></description>
      <guid>https://arxiv.org/abs/2411.15438</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HateDay：来自 Twitter 上一天的全球仇恨言论数据集的见解</title>
      <link>https://arxiv.org/abs/2411.15462</link>
      <description><![CDATA[arXiv:2411.15462v1 公告类型：新
摘要：为了应对网络仇恨言论的全球挑战，大量研究开发了检测模型来标记海量网络内容中的仇恨言论。然而，由于评估数据集中的系统性偏差，现实世界环境中的检测性能仍然不清楚，更不用说跨地域了。为了解决这个问题，我们引入了 HateDay，这是第一个代表社交媒体环境的全球仇恨言论数据集，它是从 2022 年 9 月 21 日发布的所有推文中随机抽样的，涵盖八种语言和四个英语国家。使用 HateDay，我们展示了仇恨言论的流行程度和构成在不同语言和国家之间的差异。我们还发现，对学术仇恨言论数据集的评估高估了现实世界的检测性能，我们发现这种性能非常低，尤其是对于非欧洲语言。我们确定了导致性能不佳的几个因素，包括模型无法区分仇恨言论和冒犯性言论，以及学术目标焦点与现实世界目标流行程度之间的不一致。我们最后指出，如此低的性能使得使用公共检测模型进行仇恨言论审核变得不可行，即使在成本高昂的人机交互环境中也是如此。总的来说，我们强调需要在现实世界环境中评估来自学术界和平台的未来检测模型，以应对这一全球挑战。]]></description>
      <guid>https://arxiv.org/abs/2411.15462</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>通过数据转换实现对法学硕士 (LLM) 中的反学习的稳健评估</title>
      <link>https://arxiv.org/abs/2411.15477</link>
      <description><![CDATA[arXiv:2411.15477v1 公告类型：新
摘要：大型语言模型 (LLM) 已在从常规 NLP 用例到 AI 代理的广泛应用中取得了巨大成功。LLM 已在来自各种来源的大量文本语料库上进行训练；尽管在训练 LLM 时在数据预处理阶段尽了最大努力，但它们可能会挑选一些不良信息，例如个人身份信息 (PII)。因此，近年来，机器学习 (MUL) 领域的研究变得活跃起来，主要思想是迫使 LLM 忘记（忘记）某些信息（例如 PII），而不会在常规任务上遭受性能损失。在这项工作中，我们检查了现有 MUL 技术的稳健性，以确定它们是否能够在 LLM 中实现防泄漏遗忘。具体来说，我们研究了数据转换对遗忘的影响，即如果输入格式发生变化，未学习的 LLM 是否能够回忆起遗忘的信息？我们在 TOFU 数据集上的发现强调了使用多种数据格式来更可靠地量化 LLM 中的遗忘的必要性。]]></description>
      <guid>https://arxiv.org/abs/2411.15477</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于指令调整法学硕士 (LLM) 的无种子合成数据生成框架：泰语案例研究</title>
      <link>https://arxiv.org/abs/2411.15484</link>
      <description><![CDATA[arXiv:2411.15484v1 公告类型：新
摘要：我们提出了一种合成数据方法，用于以数据高效的方式对低资源语言的大型语言模型 (LLM) 进行指令调整，特别关注泰语。我们确定了有助于提高指令调整数据集有效性的三个关键属性：流畅性、多样性和文化背景。我们提出了一个无种子​​数据框架，用于生成包含这些基本属性的合成指令调整数据。我们的框架使用 LLM 来生成不同的主题，从维基百科检索相关上下文，并为各种任务（例如问答、总结和对话）创建指令。实验结果表明，与使用数十万条指令训练的最先进的泰语 LLM 相比，我们表现最佳的合成数据集结合了所有三个关键属性，仅使用 5,000 条指令就实现了具有竞争力的性能。我们的代码和数据集可在 https://github.com/parinzee/seed-free-synthetic-instruct 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2411.15484</guid>
      <pubDate>Tue, 26 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>