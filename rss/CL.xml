<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上进行更新。</description>
    <lastBuildDate>Mon, 15 Apr 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>FastSpell：LangId 魔法咒语</title>
      <link>https://arxiv.org/abs/2404.08345</link>
      <description><![CDATA[arXiv:2404.08345v1 公告类型：新
摘要：语言识别是语言资源自动化生产的重要组成部分，特别是在多语言和大数据环境中。然而，常用的语言标识符很难区分相似或密切相关的语言。本文介绍了 FastSpell，这是一种语言标识符，它结合了 fastText（一种预先训练的语言标识符工具）和 Hunspell（一种拼写检查器），目的是在决定应将哪种语言分配给文本之前获得精炼的第二意见。我们提供了 FastSpell 算法的描述以及如何使用和配置它的说明。为此，我们激发了对此类工具的需求，并提出了一个基准，其中包括在 FastSpell 开发过程中评估的一些流行语言标识符。我们展示了 FastSpell 如何有用，不仅可以提高对相似语言的识别，还可以识别被其他工具忽略的新语言。]]></description>
      <guid>https://arxiv.org/abs/2404.08345</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>通过具有挑战性的基准更深入地了解神经语义解析</title>
      <link>https://arxiv.org/abs/2404.08354</link>
      <description><![CDATA[arXiv:2404.08354v1 公告类型：新
摘要：并行意义库（PMB）作为语义处理的语料库，重点关注语义解析和文本生成。目前，我们见证了 PMB 上神经解析器和生成器的出色性能。这可能表明此类语义处理任务已基本上得到解决。我们认为事实并非如此，过去在 PMB 上的性能分数因非最佳数据分割和过于简单的测试集而被夸大。作为回应，我们引入了几项更改。首先，我们提出了一种更系统的分割方法，而不是之前的随机分割，以提高标准测试数据的可靠性。其次，除了标准测试集之外，我们还提出了两种挑战集：一种具有较长的文本，包括篇章结构，另一种则解决构图概括。我们评估了五种用于语义解析和意义到文本生成的神经模型。我们的结果表明，模型性能在挑战集上下降（在某些情况下急剧下降），揭示了神经模型在面对此类挑战时的局限性。]]></description>
      <guid>https://arxiv.org/abs/2404.08354</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:12 GMT</pubDate>
    </item>
    <item>
      <title>知识图谱实体类型中语义和结构知识的集成</title>
      <link>https://arxiv.org/abs/2404.08313</link>
      <description><![CDATA[arXiv:2404.08313v1 公告类型：新
摘要：知识图实体类型（KGET）任务旨在预测知识图中实体缺失的类型注释。最近的工作仅在实体的局部邻域中利用 \textit{\textbf{结构知识}}，而忽略对类型也至关重要的实体、关系和类型的文本表示中的 \textit{\textbf{语义知识}}推理。此外，我们观察到语义和结构知识之间的相互作用可以用来解决假阴性问题。在本文中，我们提出了一种新颖的 \textbf{\underline{S}} 语义和 \textbf{\underline{S}} 结构感知 KG \textbf{\underline{E}}ntity \textbf{\underline{T} }yping~{(SSET)}框架，由三个模块组成。首先，\textit{语义知识编码}模块使用屏蔽实体类型任务对知识图谱中的事实知识进行编码。然后，\textit{结构知识聚合}模块聚合来自实体的多跳邻域的知识以推断缺失的类型。最后，\textit{无监督类型重排序}模块利用上述两个模型的推理结果来生成对假阴性样本具有鲁棒性的类型预测。大量实验表明，SSET 显着优于现有的最先进方法。]]></description>
      <guid>https://arxiv.org/abs/2404.08313</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>迈向法学硕士的代币化理论</title>
      <link>https://arxiv.org/abs/2404.08335</link>
      <description><![CDATA[arXiv:2404.08335v1 公告类型：新
摘要：虽然有大量研究试图规避语言建模的标记化（Clark 等人，2022；Xue 等人，2022），但目前的共识是，这是设计状态的必要的初始步骤。 -最先进的高性能语言模型。在本文中，我们通过研究变压器在简单数据生成过程中的行为，从理论角度研究了标记化。当对从某些简单的 $k^{\text{th}}$ 阶马尔可夫过程中提取的数据进行训练（$k &gt; 1$）时，变压器表现出令人惊讶的现象 - 在没有标记化的情况下，它们根据经验无法学习正确的分布并根据一元模型预测字符（Makkuva 等人，2024）。然而，通过添加标记化，我们凭经验观察到变压器突破了这一障碍，并且能够对从源中提取的序列的概率进行近乎最优的建模，从而实现较小的交叉熵损失。以此观察为起点，我们研究了有和没有标记化的变压器实现的端到端交叉熵损失。通过适当的标记化，我们表明，即使是 Transformer 学习的最简单的一元模型（通过标记）也能够对从 $k^{\text{th}}$ 阶马尔可夫源抽取的序列的概率进行近乎最佳的建模。我们的分析通过研究马尔可夫数据上变压器的行为，为在实践中使用标记化提供了理由。]]></description>
      <guid>https://arxiv.org/abs/2404.08335</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>预训练和更新特定于语言和领域的大语言模型：日语商业领域的案例研究</title>
      <link>https://arxiv.org/abs/2404.08262</link>
      <description><![CDATA[arXiv:2404.08262v1 公告类型：新
摘要：之前的几项研究已将特定语言和特定领域的大语言模型（LLM）视为单独的主题。本研究探索非英语语言与高需求行业领域的结合，重点关注日本特定商业法学硕士。这种类型的模型需要业务领域的专业知识、强大的语言技能以及定期更新知识。我们使用新的商业文本和专利数据集从头开始训练了一个包含 130 亿参数的法学硕士，并不断使用最新的商业文档对其进行预训练。此外，我们提出了日本商业领域问答（QA）的新基准，并据此评估我们的模型。结果表明，我们的预训练模型在不丢失一般知识的情况下提高了 QA 准确性，并且持续的预训练增强了对新信息的适应。我们的预训练模型和业务领域基准是公开的。]]></description>
      <guid>https://arxiv.org/abs/2404.08262</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>用于社交事件检测的基于关系提示的预训练语言模型</title>
      <link>https://arxiv.org/abs/2404.08263</link>
      <description><![CDATA[arXiv:2404.08263v1 公告类型：新
摘要：社交事件检测（SED）旨在识别社交流中的重大事件，在舆情分析和风险管理等领域有着广泛的应用。近年来，基于图神经网络（GNN）的解决方案已经取得了最先进的性能。然而，基于 GNN 的方法经常会遇到消息之间的噪声和边缘缺失问题，从而影响学习消息嵌入的质量。此外，这些方法在训练之前静态初始化节点嵌入，这反过来又限制了同时从消息文本和关系中学习的能力。在本文中，我们从基于预训练语言模型（PLM）的新角度来处理社交事件检测，并提出了 RPLM_SED（用于社交事件检测的基于关系提示的预训练语言模型）。我们首先提出了一种新的成对消息建模策略，将社交消息构建为具有多关系序列的消息对。其次，提出了一种新的基于多关系提示的成对消息学习机制，以使用 PLM 从具有多关系提示的消息对中学习更全面的消息表示。第三，我们设计了一种新的聚类约束，通过增强簇内紧凑性和簇间分散性来优化编码过程，使消息表示更具可区分性。我们在三个真实数据集上评估 RPLM_SED，证明 RPLM_SED 模型在社交事件检测任务的离线、在线、低资源和长尾分发场景中实现了最先进的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.08263</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:10 GMT</pubDate>
    </item>
    <item>
      <title>对话式 AI 模型的多模态上下文对话故障检测</title>
      <link>https://arxiv.org/abs/2404.08156</link>
      <description><![CDATA[arXiv:2404.08156v1 公告类型：新
摘要：实时检测对话故障对于对话式人工智能系统至关重要，因为它可以采取纠正措施来成功完成任务。在语音对话系统中，这种故障可能是由各种意外情况引起的，包括高水平的背景噪声，导致 STT 转录错误或意外的用户流。特别是医疗保健等行业环境，需要高精度和高灵活性，以便根据对话历史记录和对话状态进行不同的导航。这使得准确检测对话故障变得更具挑战性和更加关键。为了准确检测故障，我们发现需要实时处理音频输入以及下游 NLP 模型对转录文本的推断。在本文中，我们介绍了多模态上下文对话分解（MultConDB）模型。该模型的 F1 达到 69.27，明显优于其他已知的最佳模型。]]></description>
      <guid>https://arxiv.org/abs/2404.08156</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>以字节为单位测量跨语言传输</title>
      <link>https://arxiv.org/abs/2404.08191</link>
      <description><![CDATA[arXiv:2404.08191v1 公告类型：新
摘要：多语言预训练已成功解决语言资源缺乏带来的挑战。这些模型可以将知识转移到目标语言，只需很少的示例或无需示例。最近的研究表明，单语模型也具有类似的能力，但这种迁移背后的机制仍不清楚。一些研究探讨了语言污染和句法相似性等因素。一项新兴的研究表明，语言模型学习的表示包含两个组成部分：特定于语言的组成部分和与语言无关的组成部分。后者负责传递更普遍的知识。然而，缺乏对不同目标语言的这些属性的全面探索。为了研究这个假设，我们进行了一项实验，其灵感来自于转移缩放定律的工作。我们测量了从源语言传输到目标语言的数据量，发现从不同语言初始化的模型在跨语言设置中的表现与目标语言类似。这令人惊讶，因为传输到 10 种不同目标语言（例如西班牙语、韩语和芬兰语）的数据量非常相似。我们还发现证据表明这种转移与语言污染或语言接近无关，这强化了该模型也依赖于与语言无关的知识的假设。我们的实验为测量有多少数据代表预训练期间学到的与语言无关的表示开辟了新的可能性。]]></description>
      <guid>https://arxiv.org/abs/2404.08191</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>研究低资源语言的神经机器翻译：以巴伐利亚语为例</title>
      <link>https://arxiv.org/abs/2404.08259</link>
      <description><![CDATA[arXiv:2404.08259v1 公告类型：新
摘要：近年来，机器翻译取得了令人瞩目的进展，在许多语言上提供了接近人类水平的性能，但研究主要集中在具有广泛在线存在和资源的高资源语言上。在不断增长的大型语言模型的帮助下，越来越多的低资源语言通过其他语言的存在取得了更好的结果。然而，研究表明，并非所有资源匮乏的语言都能从多语言系统中受益，尤其是那些训练和评估数据不足的语言。在本文中，我们重新审视最先进的神经机器翻译技术，以开发德语和巴伐利亚语之间的自动翻译系统。我们研究低资源语言的条件，例如数据稀缺和参数敏感性，并专注于解决低资源困难的精细解决方案和利用语言相似性等创造性解决方案。我们的实验需要应用反向翻译和迁移学习来自动生成更多训练数据并实现更高的翻译性能。我们展示了数据中的噪声，并介绍了我们广泛进行文本预处理的方法。使用组合指标进行评估：BLEU、chrF 和 TER。 Bonferroni 校正的统计显着性结果显示出令人惊讶的高基线系统，并且反向翻译带来了显着的改进。此外，我们还对翻译错误和系统限制进行了定性分析。]]></description>
      <guid>https://arxiv.org/abs/2404.08259</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:09 GMT</pubDate>
    </item>
    <item>
      <title>通过解释解决方案从法学硕士中提炼算法推理</title>
      <link>https://arxiv.org/abs/2404.08148</link>
      <description><![CDATA[arXiv:2404.08148v1 公告类型：新
摘要：提炼显式的思想链推理路径已成为提高大型语言模型（LLM）跨各种任务的推理能力的有效方法。然而，在处理对最先进模型构成重大挑战的复杂任务时，这种技术通常很难产生有效的思维链来得出正确的答案。在这项工作中，我们提出了一种新方法，通过利用法学硕士解释解决方案的能力来提炼他们的推理能力。我们应用我们的方法来解决竞争级别的编程挑战。更具体地说，我们采用 LLM 来生成一组对的解释，然后使用对来微调较小的语言模型（我们将其称为 Reasoner），以学习可以生成“如何解决”的算法推理未见问题的提示。我们的实验表明，从解释中学习使 Reasoner 能够更有效地指导编码员执行程序，从而在竞争级别的编程问题上比强大的思想链基线获得更高的解决率。它的性能也优于直接从结对学习的模型。我们以 CodeContests 格式策划了一个额外的测试集，其中包括模型知识截止后发布的 246 个最新问题。]]></description>
      <guid>https://arxiv.org/abs/2404.08148</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>用于复杂电话呼叫中下一步行动预测的图形集成语言转换器</title>
      <link>https://arxiv.org/abs/2404.08155</link>
      <description><![CDATA[arXiv:2404.08155v1 公告类型：新
摘要：当前的对话式人工智能系统采用不同的机器学习管道以及外部知识源和业务逻辑来预测下一步行动。维护对话管理器管道中的各种组件会增加扩展和更新的复杂性，增加处理时间，并导致管道中的附加噪声，从而导致错误的下一步动作预测。本文研究了将图形集成到语言转换器中，以提高对人类话语、先前和下一步动作之间关系的理解，而不依赖于外部源或组件。对真实通话的实验分析表明，与其他生产级会话人工智能系统相比，所提出的图集成语言转换器模型在现实环境中与人类用户进行交互式通话方面可以实现更高的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.08155</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:08 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士基于数据增强的方言适应</title>
      <link>https://arxiv.org/abs/2404.08092</link>
      <description><![CDATA[arXiv:2404.08092v1 公告类型：新
摘要：本报告介绍了 GMUNLP 参与 VarDial 2024 方言-Copa 共享任务的情况，该任务重点评估大语言模型 (LLM) 对南斯拉夫微方言的常识推理能力。该任务旨在评估法学硕士处理非标准方言品种的能力，因为他们在标准语言上的表现已经很成熟。我们提出了一种方法，结合了不同类型语言模型的优势，并利用数据增强技术来提高三种南斯拉夫方言的任务性能：Chakavian、Cherkano 和 Torlak。我们使用以语言家族为中心的基于编码器的模型 (BERTi\&#39;c) 和与领域无关的多语言模型 (AYA-101) 进行实验。我们的结果表明，所提出的数据增强技术可以在开源模型类别中的所有三个测试数据集上带来显着的性能提升。这项工作强调了数据增强的实际效用以及法学硕士在处理非标准方言变体方面的潜力，有助于实现在资源匮乏和方言环境中促进自然语言理解的更广泛目标。代码：https://github.com/ffaisal93/dialect_copa]]></description>
      <guid>https://arxiv.org/abs/2404.08092</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>HLTCOE 出席 TREC 2023 NeuCLIR Track</title>
      <link>https://arxiv.org/abs/2404.08118</link>
      <description><![CDATA[arXiv:2404.08118v1 公告类型：新
摘要：HLTCOE 团队将 PLAID、mT5 重排序器和文档翻译应用到 TREC 2023 NeuCLIR 赛道。对于 PLAID，我们包含了多种模型和训练技术——随 ColBERT v2 发布的英文模型、translate-train~(TT)、Translate Distill~(TD) 和多语言 translate-train~(MTT)。 TT 使用自动翻译成 MS-MARCO v1 集合中的文档语言的英语查询和段落来训练 ColBERT 模型。这会产生该曲目的三个跨语言模型，每种语言一个。 MTT 通过将所有三种语言的 MS-MARCO 段落的翻译组合成混合语言批次，为所有三种文档语言创建单一模型。因此，该模型可以学习同时将所有语言的查询与段落进行匹配。 Distillation 使用 mT5 模型对非英语翻译文档对的分数来学习如何对查询文档对进行评分。该团队提交了所有 NeuCLIR 任务的运行：CLIR 和 MLIR 新闻任务以及技术文档任务。]]></description>
      <guid>https://arxiv.org/abs/2404.08118</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>MSciNLI：科学自然语言推理的多样化基准</title>
      <link>https://arxiv.org/abs/2404.08066</link>
      <description><![CDATA[arXiv:2404.08066v1 公告类型：新
摘要：科学自然语言推理（NLI）的任务涉及预测从研究文章中提取的两个句子之间的语义关系。这项任务最近与一个名为 SciNLI 的新数据集一起提出，该数据集源自计算语言学领域发表的论文。在本文中，我们旨在引入科学 NLI 任务的多样性，并提出 MSciNLI，这是一个包含从五个新科学领域提取的 132,320 个句子对的数据集。多个域的可用性使得研究科学 NLI 的域转移成为可能。我们通过微调预训练语言模型 (PLM) 和促进大型语言模型 (LLM) 为 MSciNLI 建立强大的基线。 PLM 和 LLM 基线的最高 Macro F1 分数分别为 77.21% 和 51.77%，这说明 MSciNLI 对两种类型的模型都具有挑战性。此外，我们发现领域转移会降低科学 NLI 模型的性能，这表明我们数据集中不同领域的不同特征。最后，我们在中间任务迁移学习环境中使用这两个科学 NLI 数据集，并表明它们可以提高科学领域下游任务的性能。我们在 Github 上提供我们的数据集和代码。]]></description>
      <guid>https://arxiv.org/abs/2404.08066</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:06 GMT</pubDate>
    </item>
    <item>
      <title>SQBC：使用法学硕士生成的综合数据进行主动学习，用于在线政治讨论中的立场检测</title>
      <link>https://arxiv.org/abs/2404.08078</link>
      <description><![CDATA[arXiv:2404.08078v1 公告类型：新
摘要：立场检测对于许多分析或支持在线政治讨论的应用程序来说是一项重要任务。常见的方法包括微调基于变压器的模型。然而，这些模型需要大量的标记数据，而这些数据可能无法获得。在这项工作中，我们提出了两种不同的方法来利用 LLM 生成的合成数据来训练和改进在线政治讨论的立场检测代理：首先，我们证明用合成数据增强小型微调数据集可以提高立场的性能检测模型。其次，我们提出了一种基于“委员会查询”方法的新主动学习方法，称为 SQBC。关键思想是使用法学硕士生成的合成数据作为预言机来识别信息最丰富的未标记样本，并选择这些样本进行手动标记。综合实验表明，这两种想法都可以提高姿态检测性能。奇怪的是，我们观察到对主动选择的样本进行微调可以超过使用完整数据集的性能。]]></description>
      <guid>https://arxiv.org/abs/2404.08078</guid>
      <pubDate>Mon, 15 Apr 2024 06:17:06 GMT</pubDate>
    </item>
    </channel>
</rss>