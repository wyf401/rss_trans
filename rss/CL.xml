<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Mon, 24 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过从大型语言模型中学习实现事实对话总结</title>
      <link>https://arxiv.org/abs/2406.14709</link>
      <description><![CDATA[arXiv:2406.14709v1 公告类型：新
摘要：事实一致性是对话摘要中的一个重要品质。与较小的预训练语言模型相比，基于大型语言模型 (LLM) 的自动文本摘要模型可以生成更多事实一致的摘要，但由于隐私或资源限制，它们在实际应用中面临部署挑战。在本文中，我们研究了使用符号知识蒸馏来提高对话摘要的较小预训练模型的事实一致性。我们使用零样本学习从 LLM 中提取符号知识，生成事实一致（正面）和不一致（负面）的摘要。然后，我们对这些摘要应用两个对比学习目标来增强较小的摘要模型。对 BART、PEGASUS 和 Flan-T5 的实验表明，我们的方法超越了依赖复杂数据增强策略的强基线。我们的方法实现了更好的事实一致性，同时保持了连贯性、流畅性和相关性，这已得到各种自动评估指标的证实。我们还提供数据和代码访问权限，以促进未来的研究。]]></description>
      <guid>https://arxiv.org/abs/2406.14709</guid>
      <pubDate>Mon, 24 Jun 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>多智能体协作攻击：通过辩论调查大型语言模型协作中的对抗性攻击</title>
      <link>https://arxiv.org/abs/2406.14711</link>
      <description><![CDATA[arXiv:2406.14711v1 公告类型：新
摘要：大型语言模型 (LLM) 在单独工作时在当前基准上表现出色。其功能的进步以及参数大小和推理时间的减少促进了这些模型作为代理的使用，使多个模型之间的交互能够执行复杂的任务。这种协作提供了几个优点，包括使用专门的模型（例如编码）、通过多次计算提高信心以及增强发散思维，从而产生更多样化的输出。因此，语言模型的协作使用预计在未来几年将显着增长。在这项工作中，我们评估了在对手的影响下通过辩论进行协作的模型网络的行为。我们引入了相关指标来评估对手的有效性，重点关注系统准确性和模型一致性。我们的研究结果强调了模型的说服能力在影响他人方面的重要性。此外，我们探索推理时间方法来生成更令人信服的论据，并评估基于提示的缓解作为防御策略的潜力。]]></description>
      <guid>https://arxiv.org/abs/2406.14711</guid>
      <pubDate>Mon, 24 Jun 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>1+1>2：大型语言模型可以充当跨语言知识聚合器吗？</title>
      <link>https://arxiv.org/abs/2406.14721</link>
      <description><![CDATA[arXiv:2406.14721v1 公告类型：新
摘要：大型语言模型 (LLM) 因其处理跨多种语言信息的出色能力而备受关注。尽管它们具有强大的功能，但它们在处理不同语言的相同查询时表现出不一致，这对进一步发展提出了挑战。本文介绍了一种通过聚合来自不同语言的知识来增强 LLM 多语言性能的方法。该方法结合了特定于语言的低资源知识检测器、语言选择过程以及答案替换和集成机制。我们的实验表明性能显着提高，特别是在减少语言性能差异方面。一项消融研究证实，我们方法的每个组成部分都对这些增强做出了重大贡献。这项研究强调了 LLM 协调多语言能力的内在潜力，并为进一步探索提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2406.14721</guid>
      <pubDate>Mon, 24 Jun 2024 06:20:02 GMT</pubDate>
    </item>
    <item>
      <title>深度 $F_1$：通过测量语义泛化能力来改进跨领域文本分类的评估</title>
      <link>https://arxiv.org/abs/2406.14695</link>
      <description><![CDATA[arXiv:2406.14695v1 公告类型：新 
摘要：最近对跨域文本分类模型的评估旨在衡量模型在给定源域中的标记样本的情况下在目标域中获得域不变性能的能力。此评估的主要策略依赖于基准数据集中源域样本和目标域样本之间的假设差异。这种评估策略未能考虑源域和目标域之间的相似性，并且可能会掩盖模型无法将学习迁移到与源域高度不同的特定目标样本的情况。我们引入了深度 $F_1$，一种新颖的跨域文本分类性能指标。深度 $F_1$ 旨在补充现有的分类指​​标（例如 $F_1$），它衡量模型在与源域不同的目标样本上的表现。我们使用标准跨域文本分类数据集来激发该指标，并对几个最近的跨域文本分类模型进行基准测试，目的是能够深入评估跨域文本分类模型的语义通用性。]]></description>
      <guid>https://arxiv.org/abs/2406.14695</guid>
      <pubDate>Mon, 24 Jun 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士是否具有独特而一致的个性？ TRAIT：专为法学硕士设计的心理测量个性测试集</title>
      <link>https://arxiv.org/abs/2406.14703</link>
      <description><![CDATA[arXiv:2406.14703v1 公告类型：新
摘要：描述心理学中的人格概念传统上是通过可观察的行为来定义的，现在已经扩展到大型语言模型 (LLM)，以更好地理解它们的行为。这就提出了一个问题：LLM 是否表现出与人类相似的独特而一致的人格特质？现有的自我评估人格测试虽然适用，但缺乏精确人格测量所需的有效性和可靠性。为了解决这个问题，我们推出了 TRAIT，这是一种由 8K 多项选择题组成的新工具，旨在以有效性和可靠性评估 LLM 的人格。TRAIT 建立在经过心理测量验证的人类问卷、大五人格量表 (BFI) 和短暗三角 (SD-3) 的基础上，并通过 ATOMIC10X 知识图谱进行了增强，可在各种真实场景中测试人格。 TRAIT 克服了使用自我评估测量 LLM 人格时存在的信度和效度问题，在三个指标中得分最高：拒绝率、提示敏感度和选项顺序敏感度。它揭示了 LLM 人格的显著见解：1) LLM 表现出独特而一致的人格，这在很大程度上受到其训练数据（即用于对齐调整的数据）的影响；2) 当前的提示技术在引出某些特征（例如高度精神病或低尽责性）方面效果有限，这表明需要在这方面进一步研究。]]></description>
      <guid>https://arxiv.org/abs/2406.14703</guid>
      <pubDate>Mon, 24 Jun 2024 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>（西班牙语）上下文中歧义词的双向 Transformer 表示：新的词汇资源和实证分析</title>
      <link>https://arxiv.org/abs/2406.14678</link>
      <description><![CDATA[arXiv:2406.14678v1 公告类型：新
摘要：词汇歧义（即单个词形具有不同的、依赖于上下文的含义）是一种有用的工具，可用于比较不同大型语言模型 (LLM) 形成相同刺激的不同、语境化表示的能力。很少有研究系统地比较过英语以外语言的 LLM 语境化词嵌入。在这里，我们评估了多个双向转换器 (BERT) 在上下文中对西班牙语歧义名词的语义表示。我们开发了一个新颖的最小对句子数据集，这些句子对目标歧义名词具有相同或不同的意义。在一项预先注册的研究中，我们收集了每个句子对的语境化人类相关性判断。我们发现各种基于 BERT 的 LLM 的语境化语义表示捕捉到了人类判断的一些差异，但达不到人类基准，而且对于西班牙语——与英语不同——模型规模与性能无关。我们还确定了目标名词消歧的刻板轨迹，将其作为遍历给定 LLM 系列架构的一部分，我们在英语中部分复制了这些轨迹。我们贡献了 (1) 一个受控的西班牙语句子刺激数据集，其中包含人类相关性规范，以及 (2) 我们对 LLM 规范（架构、训练协议）对语境化嵌入的影响的不断发展的理解。]]></description>
      <guid>https://arxiv.org/abs/2406.14678</guid>
      <pubDate>Mon, 24 Jun 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>从普遍依赖性视角看达罗毗荼语系</title>
      <link>https://arxiv.org/abs/2406.14680</link>
      <description><![CDATA[arXiv:2406.14680v1 公告类型：新
摘要：通用依赖项 (UD) 项目旨在为多种语言创建跨语言一致的依赖项注释，以促进多语言 NLP。它目前支持 114 种语言。全球有超过 2 亿人使用达罗毗荼语，但 UD 中只有两种来自该语系的语言。本文研究了达罗毗荼语的一些形态和句法特征，并探讨了如何在 UD 框架中对它们进行注释。]]></description>
      <guid>https://arxiv.org/abs/2406.14680</guid>
      <pubDate>Mon, 24 Jun 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>一种减轻语音模型偏差的对比学习方法</title>
      <link>https://arxiv.org/abs/2406.14686</link>
      <description><![CDATA[arXiv:2406.14686v1 公告类型：新
摘要：语音模型可能会受到不同人群子群体表现不平衡的影响，这引发了人们对这些群体之间公平待遇的担忧。先前减轻不公平现象的尝试要么侧重于用户定义的子群体，可能会忽略其他受影响的子群体，要么没有明确改善子群体级别的内部表示。本文首次提出采用对比学习来减轻表现不佳的子群体中的语音模型偏差。我们采用三级学习技术，指导模型关注对比损失的不同范围，即任务、子组和子组内的错误。在两个口语理解数据集和两种语言上的实验表明，我们的方法改进了内部子群表示，从而减少了模型偏差并提高了性能。]]></description>
      <guid>https://arxiv.org/abs/2406.14686</guid>
      <pubDate>Mon, 24 Jun 2024 06:20:00 GMT</pubDate>
    </item>
    <item>
      <title>探索构建特定语言的 LLM 的设计选择</title>
      <link>https://arxiv.org/abs/2406.14670</link>
      <description><![CDATA[arXiv:2406.14670v1 公告类型：新
摘要：尽管大型语言模型 (LLM) 取得了快速进展，但它们在绝大多数语言上的表现仍然不令人满意。在本文中，我们研究通过调整单语和多语 LLM 来构建特定于语言的 LLM。我们对设计选择（基础模型选择、词汇扩展和持续微调）如何影响调整后的 LLM 进行了系统的实验，包括效率（编码相同数量的信息需要多少个标记）和最终任务性能。我们发现 (1) 调整前的初始性能并不总是代表最终性能。 (2) 在我们研究的大多数 LLM 中，通过简单的词汇扩展和持续微调可以轻松提高效率，(3) 最佳适应方法高度依赖于语言，最简单的方法在各种实验环境中都很有效。调整以英语为中心的模型可以比调整多语言模型产生更好的结果，尽管它们在低资源语言上的初始性能较差。总之，我们的工作通过调整现有的 LLM 为高效构建特定语言的 LLM 奠定了基础。]]></description>
      <guid>https://arxiv.org/abs/2406.14670</guid>
      <pubDate>Mon, 24 Jun 2024 06:19:59 GMT</pubDate>
    </item>
    <item>
      <title>洞察 LLM 长上下文失败：当 Transformers 知道但不告诉别人时</title>
      <link>https://arxiv.org/abs/2406.14673</link>
      <description><![CDATA[arXiv:2406.14673v1 公告类型：新
摘要：大型语言模型 (LLM) 表现出位置偏差，难以利用长上下文中间或末尾的信息。我们的研究通过探测其隐藏的表示来探索 LLM 的长上下文推理。我们发现，虽然 LLM 编码了目标信息的位置，但它们往往无法利用这一点来生成准确的响应。这揭示了信息检索和利用之间的脱节，这是一种“知而不言”的现象。我们进一步分析了提取时间与最终准确度之间的关系，为 Transformer 模型的底层机制提供了见解。]]></description>
      <guid>https://arxiv.org/abs/2406.14673</guid>
      <pubDate>Mon, 24 Jun 2024 06:19:59 GMT</pubDate>
    </item>
    <item>
      <title>主实体识别：共指解析的通用替代方案</title>
      <link>https://arxiv.org/abs/2406.14654</link>
      <description><![CDATA[arXiv:2406.14654v1 公告类型：新
摘要：共指解析 (CR) 模型的泛化能力有限一直是该任务广泛应用的主要瓶颈。先前的研究已将注释差异（尤其是提及检测）确定为泛化差距的主要原因之一，并提出使用额外的带注释的目标域数据。我们不依赖于这种额外的注释，而是提出了 CR 任务的另一种表述，即主要实体识别 (MEI)，其中我们：(a) 假设目标实体在输入中指定，(b) 将任务限制为仅频繁实体。通过大量实验，我们证明 MEI 模型在具有监督模型和基于 LLM 的少量提示的多个数据集上跨域很好地泛化。此外，MEI 任务适合分类框架，这使得可以使用比当前 CR 指标更稳健的基于分类的指标。最后，MEI 还具有实际用途，因为它允许用户搜索特定实体或一组感兴趣的实体的所有提及。]]></description>
      <guid>https://arxiv.org/abs/2406.14654</guid>
      <pubDate>Mon, 24 Jun 2024 06:19:58 GMT</pubDate>
    </item>
    <item>
      <title>OpenDebateEvidence：大规模论证挖掘和总结数据集</title>
      <link>https://arxiv.org/abs/2406.14657</link>
      <description><![CDATA[arXiv:2406.14657v1 公告类型：新
摘要：我们介绍了 OpenDebateEvidence，这是一个来自美国竞争性辩论社区的用于论证挖掘和总结的综合数据集。该数据集包含超过 350 万份具有丰富元数据的文档，使其成为最广泛的辩论证据集合之一。OpenDebateEvidence 捕捉了高中和大学辩论中论证的复杂性，为培训和评估提供了宝贵的资源。我们进行了广泛的实验，证明了在各种方法、模型和数据集中微调最先进的大型语言模型进行论证抽象总结的有效性。通过提供这种全面的资源，我们旨在推进计算论证并为辩论者、教育工作者和研究人员提供实际应用。OpenDebateEvidence 是公开的，以支持计算论证的进一步研究和创新。在此处访问：https://huggingface.co/datasets/Yusuf5/OpenCaselist]]></description>
      <guid>https://arxiv.org/abs/2406.14657</guid>
      <pubDate>Mon, 24 Jun 2024 06:19:58 GMT</pubDate>
    </item>
    <item>
      <title>低资源科学自然语言推理的联合训练</title>
      <link>https://arxiv.org/abs/2406.14666</link>
      <description><![CDATA[arXiv:2406.14666v1 公告类型：新
摘要：科学自然语言推理 (NLI) 是预测从研究文章中提取的一对句子之间的语义关系的任务。基于远程监督的自动注释方法针对 SciNLI (Sadat and Caragea, 2022b) 训练集，这是此任务的第一个也是最受欢迎的数据集，会导致标签噪声，这不可避免地会降低分类器的性能。在本文中，我们提出了一种新颖的共同训练方法，该方法根据分类器的训练动态为远程监督标签分配权重，以反映它们在后续训练阶段的使用方式。也就是说，与现有的半监督学习 (SSL) 方法不同，我们考虑分类器的历史行为来评估自动注释标签的质量。此外，通过分配重要性权重，而不是根据预测置信度的任意阈值过滤掉示例，我们可以最大限度地利用自动标记的数据，同时确保噪声标签对模型训练的影响最小。与远程监督基线相比，所提出的方法在 Macro F1 中获得了 1.5% 的改进，并且与其他几个强大的 SSL 基线相比也有了显着的改进。我们在 Github 上提供了我们的代码和数据。]]></description>
      <guid>https://arxiv.org/abs/2406.14666</guid>
      <pubDate>Mon, 24 Jun 2024 06:19:58 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士能否通过教学来学习？一项初步研究</title>
      <link>https://arxiv.org/abs/2406.14629</link>
      <description><![CDATA[arXiv:2406.14629v1 公告类型：新
摘要：通过教学改进学生模型（例如知识提炼）是法学硕士 (LLM) 中广泛研究的方法。然而，对于人类来说，教学不仅可以提高学生的水平，还可以提高教师的水平。我们要问：法学硕士 (LLM) 也可以通过教学 (LbT) 来学习吗？如果是，我们就可以潜在地解锁持续改进模型的可能性，而不仅仅依赖于人工生成的数据或更强大的模型。在本文中，我们对这一雄心勃勃的议程进行了初步探索。我们表明，LbT 思想可以融入现有的法学硕士 (LLM) 训练/提示管道中，并提供显着的改进。具体来说，我们设计了三种方法，每种方法都模仿人类 LbT 的三个级别之一：观察学生的反馈、从反馈中学习和迭代学习，目标是在无需训练的情况下提高答案准确性，并通过微调提高模型的固有能力。研究结果令人鼓舞。例如，与人类的 LbT 类似，我们发现：(1) LbT 可以引发从弱到强的泛化：强模型可以通过教其他弱模型来提高自身；(2) 学生的多样性可能有所帮助：教多个学生可能比教一个学生或教老师更好。我们希望这一早期成果可以启发未来对 LbT 的研究，并更广泛地采用先进的教育技术来改进 LLM。代码可在 https://github.com/imagination-research/lbt 上找到。]]></description>
      <guid>https://arxiv.org/abs/2406.14629</guid>
      <pubDate>Mon, 24 Jun 2024 06:19:57 GMT</pubDate>
    </item>
    <item>
      <title>揭示语言模型中数据污染的频谱：从检测到补救的调查</title>
      <link>https://arxiv.org/abs/2406.14644</link>
      <description><![CDATA[arXiv:2406.14644v1 公告类型：新
摘要：由于依赖大量来自互联网的训练语料库，数据污染在大型语言模型 (LLM) 时代引起了越来越多的关注。训练语料库与评估基准重叠的问题（称为污染）一直是近期重要研究的焦点。这项工作旨在识别污染，了解其影响，并从不同角度探索缓解策略。然而，在这个新兴领域，缺乏提供从基础概念到高级见解的清晰途径的综合研究。因此，我们对数据污染领域进行了全面调查，列出了迄今为止的关键问题、方法和发现，并强调了需要进一步研究和开发的领域。特别是，我们首先研究数据污染在不同阶段和形式中的影响。然后，我们对当前的污染检测方法进行了详细分析，对它们进行了分类，以突出它们的重点、假设、优势和局限性。我们还讨论了缓解策略，为未来的研究提供了明确的指导。本调查简明扼要地概述了数据污染研究的最新进展，为未来的研究工作提供了直接的指导。]]></description>
      <guid>https://arxiv.org/abs/2406.14644</guid>
      <pubDate>Mon, 24 Jun 2024 06:19:57 GMT</pubDate>
    </item>
    </channel>
</rss>