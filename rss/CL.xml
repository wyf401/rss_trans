<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 07 Jun 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过建模潜在词内结构实现字符级中文依存句法分析</title>
      <link>https://arxiv.org/abs/2406.03772</link>
      <description><![CDATA[arXiv:2406.03772v1 公告类型：新
摘要：由于缺乏明确的词边界，揭示中文句子的句法结构对词级解析器提出了重大挑战。为了促进从词级到字符级的中文依存关系解析的过渡，本文提出对词内的潜在内部结构进行建模。这样，每个词级依存关系树都被解释为一个字符级树的森林。实施了受约束的 Eisner 算法来确保字符级树的兼容性，保证词内结构的单根并在这些根之间建立词间依存关系。在中文树库上的实验证明了我们的方法优于管道框架和以前的联合模型。详细分析表明，由粗到细的解析策略使模型能够预测更符合语言学的词内结构。]]></description>
      <guid>https://arxiv.org/abs/2406.03772</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:13 GMT</pubDate>
    </item>
    <item>
      <title>通过 KG-LLM 衔接实现有效的知识融合</title>
      <link>https://arxiv.org/abs/2406.03746</link>
      <description><![CDATA[arXiv:2406.03746v1 公告类型：新
摘要：为了解决大型语言模型 (LLM) 中领域特定知识稀缺的问题，知识图谱检索增强方法已被证明是一种有效且高效的知识注入技术。然而，现有的方法面临两个主要挑战：公共可用知识图谱与当前任务的特定领域之间的知识不匹配，以及 LLM 与知识图谱的信息一致性较差。在本文中，我们利用一小组标记样本和大规模语料库通过 LLM 有效地构建领域特定知识图谱，解决知识不匹配的问题。此外，我们提出了一种三阶段 KG-LLM 对齐策略来增强 LLM 利用知识图谱信息的能力。我们在两个生物医学问答数据集上进行了有限样本设置的实验，结果表明我们的方法优于现有的基线。]]></description>
      <guid>https://arxiv.org/abs/2406.03746</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:12 GMT</pubDate>
    </item>
    <item>
      <title>NAP^2：通过学习人类的自然性和隐私保护文本重写的基准</title>
      <link>https://arxiv.org/abs/2406.03749</link>
      <description><![CDATA[arXiv:2406.03749v1 公告类型：新
摘要：在使用第三方提供商的 NLP 模型处理敏感文本时，学术界和工业界对隐私泄露问题的担忧日益增加。为了在将敏感数据发送到这些模型之前保护隐私，我们建议使用人类使用的两种常见策略对敏感文本进行清理：i) 删除敏感表达，ii) 通过抽象来模糊敏感细节。为了探索这些问题并开发文本重写的工具，我们通过众包和使用大型语言模型 (LLM) 策划了第一个语料库 NAP^2。与之前基于差异隐私的研究相比，这导致信息效用和不自然文本的急剧下降，而人类启发的方法可以实现更自然的重写，并在隐私保护和数据效用之间提供更好的平衡，这一点已通过我们的大量实验得到证明。]]></description>
      <guid>https://arxiv.org/abs/2406.03749</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:12 GMT</pubDate>
    </item>
    <item>
      <title>医学大型语言模型综述：技术、应用、可信度及未来方向</title>
      <link>https://arxiv.org/abs/2406.03712</link>
      <description><![CDATA[arXiv:2406.03712v1 公告类型：新
摘要：大型语言模型（LLM），例如 GPT 系列模型，因其生成和理解人类语言的出色能力而受到广泛关注。最近，LLM 已成为医学领域的创新而强大的辅助手段，改变了传统做法并预示着增强医疗服务的新时代。本调查全面概述了医学大型语言模型 (Med-LLM)，概述了它们从通用到医学特定领域的演变（即技术和应用），以及它们对医疗保健的变革性影响（例如可信度和安全性）。具体来说，从 LLM 的基本历史和技术开始，我们首先深入研究通用 LLM 模型在医学领域的逐步适应和改进，特别强调了提高 LLM 在处理复杂医疗环境中的性能的高级算法，包括临床推理、知识图谱、检索增强生成、人体对齐和多模态学习。其次，我们探讨了 Med-LLM 在临床决策支持、报告生成和医学教育等领域的广泛应用，说明了它们在简化医疗服务和改善患者治疗效果方面的潜力。最后，我们认识到创新的必要性和负责任性，并讨论了在 Med-LLM 应用中确保公平性、问责制、隐私性和稳健性的挑战。最后，我们进行了简要的讨论，以预测 Med-LLM 未来的可能发展轨迹，确定 Med-LLM 审慎扩展的途径。通过整合上述见解，本评论旨在全面调查 Med-LLM 对专业人士和研究人员的潜在优势和局限性，确保医疗保健环境中负责任的格局。]]></description>
      <guid>https://arxiv.org/abs/2406.03712</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:11 GMT</pubDate>
    </item>
    <item>
      <title>LLMEmbed：重新思考轻量级 LLM 在文本分类中的真正作用</title>
      <link>https://arxiv.org/abs/2406.03725</link>
      <description><![CDATA[arXiv:2406.03725v1 公告类型：新
摘要：随着大型语言模型（LLM）的蓬勃发展，提示学习已成为主要在各个研究领域进行研究的一种有前途的方法。最近，已经进行了许多基于提示学习的尝试来提高文本分类的性能。然而，这些方法大多基于启发式的思路链（CoT），往往更复杂但效率更低。在本文中，我们重新思考基于LLM的文本分类方法，提出一种简单有效的迁移学习策略，即LLMEmbed，以解决这一经典但具有挑战性的任务。为了说明，我们首先研究如何通过不同网络深度的各种轻量级LLM正确提取和融合文本嵌入，以提高其鲁棒性和区分度，然后调整这些嵌入来训练分类器。我们对公开数据集进行了广泛的实验，结果表明，与基于较大 LLM（例如 GPT-3）和复杂提示策略的最新方法相比，LLMEmbed 使用轻量级 LLM 主干实现了强大的性能，同时训练开销较低。我们的 LLMEmbed 在公开基准上实现了足够的准确度，无需任何微调，而与其他同类产品相比，仅使用 4% 的模型参数、1.8% 的电力消耗和 1.5% 的运行时间。代码可在以下位置获得：https://github.com/ChunLiu-cs/LLMEmbed-ACL2024。]]></description>
      <guid>https://arxiv.org/abs/2406.03725</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:11 GMT</pubDate>
    </item>
    <item>
      <title>M-QALM：通过问答评估大型语言模型中的临床阅读理解和知识回忆的基准</title>
      <link>https://arxiv.org/abs/2406.03699</link>
      <description><![CDATA[arXiv:2406.03699v1 公告类型：新
摘要：关于如何将大型语言模型 (LLM) 应用于医疗保健等高风险领域的各种任务，已有大量研究成果。尽管 LLM 非常受欢迎，但人们对于 LLM 回忆相关知识并将其与临床和生物医学领域呈现的信息相结合的程度和影响因素缺乏了解：这是成功完成下游任务的基本先决条件。为了解决这一差距，我们使用多项选择题和抽象问答对三个通才和三个专才生物医学子领域的 22 个数据集进行了大规模实证研究。我们对 15 个 LLM 的性能进行了多方面的分析，并进一步按子域、知识来源和模型架构进行了细分，揭示了导致回忆和理解能力提高的成功因素，例如指令调整。我们进一步表明，虽然最近提出的领域适应模型可能缺乏足够的知识，但直接对我们收集的医学知识数据集进行微调显示出令人鼓舞的结果，甚至可以推广到看不见的专业子领域。我们用技能导向的手动错误分析补充了定量结果，这表明模型在简单回忆必要知识和将其与呈现的上下文相结合的能力之间存在显著差距。为了促进该领域的研究和合作，我们与研究界分享 M-QALM、我们的资源、标准化方法和评估结果，以促进语言模型中临床知识表示学习的进一步发展。]]></description>
      <guid>https://arxiv.org/abs/2406.03699</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:10 GMT</pubDate>
    </item>
    <item>
      <title>使用自动响应分割从未标记的文档中合成对话</title>
      <link>https://arxiv.org/abs/2406.03703</link>
      <description><![CDATA[arXiv:2406.03703v1 公告类型：新
摘要：在本研究中，我们解决了训练数据不足和成本高昂的挑战，这一挑战阻碍了对话式问答 (ConvQA) 系统的发展。企业拥有大量不同的内部文档。与依赖搜索引擎相比，让人们理解这些文档的更引人注目的方法是创建一个对话系统。在本文中，我们提出了一种强大的对话合成方法。我们学习对话任务的数据分割，而不是在句子边界处进行分割。通过机器和人工评估，我们提出的方法生成的合成数据集与 WikiDialog 相比具有更高的质量。通过将我们的修复数据用于 ConvQA 检索系统预训练，我们观察到 OR-QuAC 基准测试中性能显着提高。]]></description>
      <guid>https://arxiv.org/abs/2406.03703</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:10 GMT</pubDate>
    </item>
    <item>
      <title>语言条件下的语义文本相似性</title>
      <link>https://arxiv.org/abs/2406.03673</link>
      <description><![CDATA[arXiv:2406.03673v1 公告类型：新
摘要：语义文本相似度 (STS) 是一项基本的 NLP 任务，用于测量一对句子之间的语义相似度。为了减少句子固有的歧义性，最近提出了一项称为条件 STS (C-STS) 的工作，用于测量基于某个方面的句子相似度。尽管 C-STS 很受欢迎，但我们发现当前的 C-STS 数据集存在各种问题，可能会妨碍对该任务进行正确的评估。在本文中，我们重新注释了 C-STS 验证集，并观察到 ​​55% 的实例存在注释者差异，这是由于原始标签中的注释错误、条件定义不明确以及任务定义不明确造成的。经过彻底的数据集分析，我们利用模型在 QA 任务设置下理解条件的能力来改进 C-STS 任务。利用生成的答案，我们提出了一个自动错误识别管道，该管道能够识别 C-STS 数据中的注释错误，F1 得分超过 80%。我们还提出了一种新方法，通过使用答案训练模型，大大提高了 C-STS 数据上基线的性能。最后，我们讨论了基于实体类型的类型特征结构 (TFS) 的条件性注释。我们在示例中展示了 TFS 能够为构建具有新条件的 C-STS 数据提供语言基础。]]></description>
      <guid>https://arxiv.org/abs/2406.03673</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:09 GMT</pubDate>
    </item>
    <item>
      <title>评估生成模型中隐含的世界模型</title>
      <link>https://arxiv.org/abs/2406.03689</link>
      <description><![CDATA[arXiv:2406.03689v1 公告类型：新摘要：最近的研究表明，大型语言模型可能会隐式学习世界模型。我们应该如何评估这种可能性？我们将这个问题形式化为底层现实由确定性有限自动机控制的情况。这包括简单的逻辑推理、地理导航、游戏和化学等各种问题。我们提出了受语言理论中经典的 Myhill-Nerode 定理启发的世界模型恢复新评估指标。我们在三个领域说明了它们的效用：游戏、逻辑谜题和导航。在所有领域中，我们考虑的生成模型在现有的评估世界模型的诊断上表现良好，但我们的评估指标显示它们的世界模型远没有看起来那么连贯。这种不连贯性造成了脆弱性：使用生成模型来解决相关但略有不同的任务可能会导致它严重失败。构建能够有意义地捕捉它们建模领域的底层逻辑的生成模型将非常有价值；我们的研究结果提出了评估给定模型与该目标的接近程度的新方法。]]></description>
      <guid>https://arxiv.org/abs/2406.03689</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:09 GMT</pubDate>
    </item>
    <item>
      <title>什么使得语言模型足够好？</title>
      <link>https://arxiv.org/abs/2406.03666</link>
      <description><![CDATA[arXiv:2406.03666v1 公告类型：新
摘要：心理语言学研究表明，人类可以构建一种“足够好”的语言输入表征来完成手头的任务。本研究探讨了哪些架构特征使语言模型能够学习类似人类的足够好的语言处理。我们关注 Transformers 中的层数和自注意力头。我们创建了一个足够好的语言处理 (GELP) 评估数据集（7,680 个示例），旨在测试两种可信度类型、八种构造类型和三种内存成本对语言处理的影响。为了注释 GELP，我们首先进行众包实验，其设计遵循先前的心理语言学研究。我们对带注释的 GELP 的模型评估表明，完整模型以及具有较少层和/或自注意力头的模型都表现出足够好的性能。这个结果表明，深度较浅、头部较少的模型可以学习足够好的语言处理。]]></description>
      <guid>https://arxiv.org/abs/2406.03666</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:08 GMT</pubDate>
    </item>
    <item>
      <title>TACT：利用信息提取工具推进复杂的聚合推理</title>
      <link>https://arxiv.org/abs/2406.03618</link>
      <description><![CDATA[arXiv:2406.03618v1 公告类型：新
摘要：大型语言模型 (LLM) 通常在需要跨文本聚合信息的查询上表现不佳。为了更好地评估这种设置并促进建模工作，我们引入了 TACT - 通过表格进行文本和计算，这是一个使用复杂指令评估 LLM 推理和计算能力的数据集。TACT 包含具有挑战性的指令，要求拼接分散在一个或多个文本中的信息，并对这些信息执行复杂的集成以生成答案。我们通过利用现有的文本数据集及其相关表格来构建此数据集。对于每个这样的表，我们制定新的查询并收集它们各自的答案。我们证明所有当代 LLM 在该数据集上的表现都很差，准确率低于 38%。为了找出困难并彻底剖析问题，我们分析了三个组件的模型性能：表生成、Pandas 命令生成和执行。出乎意料的是，我们发现每个组件都给当前的 LLM 带来了巨大的挑战。这些见解促使我们提出了一个专注的建模框架，我们将其称为 IE 工具。具体来说，我们建议为上述每个步骤添加“工具”，并通过少样本提示来实现每个这样的工具。这种方法比现有的提示技术有所改进，为增强这些任务中的模型能力提供了一个有希望的方向。]]></description>
      <guid>https://arxiv.org/abs/2406.03618</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:07 GMT</pubDate>
    </item>
    <item>
      <title>可以实现自由自调心吗？</title>
      <link>https://arxiv.org/abs/2406.03642</link>
      <description><![CDATA[arXiv:2406.03642v1 公告类型：新
摘要：对齐预训练语言模型 (LM) 是一个复杂且资源密集的过程，通常需要访问大量真实偏好数据和大量计算。这些成本是必要的吗？也就是说，是否可以使用固有模型知识进行对齐而无需额外训练？我们使用 AlignEZ 应对这一挑战，这是一种新颖的方法，它使用 (1) 自生成的偏好数据和 (2) 表示编辑来提供几乎免费的对齐。在推理过程中，AlignEZ 修改 LM 表示以减少不良组件并提升所需组件，使用通过自生成的偏好对识别的子空间。我们的实验表明，这种几乎免费的程序显着缩小了基础预训练模型和调整模型之间的差距，平均缩小了 31.6%，这是在六个数据集和三个模型架构中观察到的。此外，我们探索了使用 AlignEZ 作为加快更昂贵的对齐程序的手段的潜力。我们的实验表明，AlignEZ 可以改进仅使用一小部分真实偏好数据进行调整的 DPO 模型。最后，我们研究了使用 AlignEZ 进行改进的可行性条件，从而为其有效性提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2406.03642</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:07 GMT</pubDate>
    </item>
    <item>
      <title>测量问答系统中的检索复杂性</title>
      <link>https://arxiv.org/abs/2406.03592</link>
      <description><![CDATA[arXiv:2406.03592v1 公告类型：新
摘要：在本文中，我们研究了哪些问题对于基于检索的问答 (QA) 具有挑战性。我们 (i) 提出了检索复杂度 (RC)，这是一种以检索文档的完整性为条件的新指标，用于衡量回答问题的难度，以及 (ii) 提出了一种无监督的管道来测量给定任意检索系统的 RC。我们提出的管道在六个具有挑战性的 QA 基准上比其他估计器（包括 LLM）更准确地测量了 RC。进一步的调查显示，在六个研究基准中的五个中，RC 分数与 QA 性能和专家判断都密切相关，表明 RC 是衡量问题难度的有效指标。随后对高 RC 问题的分类表明，它们涵盖了广泛的问题形状，包括多跳、组合和时间 QA，这表明 RC 分数可以对一组新的复杂问题进行分类。我们的系统还可以通过帮助识别现有数据集中更具挑战性的问题，对基于检索的系统产生重大影响。]]></description>
      <guid>https://arxiv.org/abs/2406.03592</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:06 GMT</pubDate>
    </item>
    <item>
      <title>知识注入的法律智慧：通过诊断和正向无标记强化学习指导法学硕士咨询</title>
      <link>https://arxiv.org/abs/2406.03600</link>
      <description><![CDATA[arXiv:2406.03600v1 公告类型：新
摘要：生成式大型语言模型 (LLM) 因其广泛和多功能的特性而加速了其与法律领域等各种应用的集成。然而，在面对法律案件时，没有法律背景的用户往往难以提出专业查询，并且在向 LLM 呈现案件叙述时可能会无意中忽略关键的法律因素。为了解决这个问题，我们提出了诊断性法律大型语言模型 (D3LM)，该模型利用自适应律师式诊断问题来收集额外的案例信息，然后提供高质量的反馈。D3LM 采用了创新的基于图的正向无标记强化学习 (PURL) 算法，可以生成关键问题并增强用户与 LLM 的交互。此外，集成的基于 LLM 的停止标准有助于精确生成法院观点 (CVG)。我们的研究还引入了一个基于美国判例法数据库的新英语 CVG 数据集，为 LLM 研究和部署领域提供了重要的维度。 D3LM 在法律领域提供出色的性能和卓越的用户体验，超越了传统的 LLM。]]></description>
      <guid>https://arxiv.org/abs/2406.03600</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:06 GMT</pubDate>
    </item>
    <item>
      <title>对话搜索引擎的排名操纵</title>
      <link>https://arxiv.org/abs/2406.03589</link>
      <description><![CDATA[arXiv:2406.03589v1 公告类型：新
摘要：主要搜索引擎提供商正在迅速整合大型语言模型 (LLM) 生成的内容以响应用户查询。这些对话式搜索引擎通过将检索到的网站文本加载到 LLM 上下文中进行总结和解释来运行。最近的研究表明，LLM 极易受到越狱和提示注入攻击，这会破坏使用对抗性字符串的 LLM 的安全性和质量目标。这项工作调查了提示注入对对话式搜索引擎引用的来源排名顺序的影响。为此，我们引入了一个现实世界消费品网站的重点数据集，并将对话式搜索排名形式化为对抗性问题。通过实验，我们在没有对抗性注入的情况下分析了对话式搜索排名，并表明不同的 LLM 在优先考虑产品名称、文档内容和上下文位置方面存在显着差异。然后，我们提出了一种基于攻击树的越狱技术，可以可靠地推广排名较低的产品。重要的是，这些攻击可以有效地转移到最先进的对话式搜索引擎，例如 perplexity.ai。考虑到网站所有者提高搜索排名的强大经济动机，我们认为我们的问题表述对于未来的稳健性工作至关重要。]]></description>
      <guid>https://arxiv.org/abs/2406.03589</guid>
      <pubDate>Fri, 07 Jun 2024 06:20:05 GMT</pubDate>
    </item>
    </channel>
</rss>