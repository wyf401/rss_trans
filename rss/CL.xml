<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Fri, 22 Nov 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>AddrLLM：通过大型语言模型对全国物流数据进行地址重写</title>
      <link>https://arxiv.org/abs/2411.13584</link>
      <description><![CDATA[arXiv:2411.13584v1 公告类型：新
摘要：物理位置的文本描述，通常称为地址，在基于位置的服务 (LBS)（例如按需交付和导航）中起着重要作用。然而，异常地址的普遍存在，这些地址包含无法精确定位的不准确信息，导致了巨大的成本。地址重写已成为纠正这些异常地址的解决方案。尽管迫切需要，但现有的地址重写方法有限，通常针对纠正特定错误类型进行量身定制，或者经常需要重新训练才能有效处理新地址数据。在本研究中，我们介绍了 AddrLLM，这是一个基于检索增强大型语言模型构建的地址重写创新框架。AddrLLM 通过精心设计的监督微调模块、以地址为中心的检索增强生成模块和无偏差客观对齐模块克服了上述限制。据我们所知，本研究开创性地应用基于 LLM 的地址重写方法来解决异常地址问题。通过全国范围内使用真实数据进行的全面离线测试以及随后的在线部署，AddrLLM 在与现有物流系统的集成方面表现出色。它显著降低了包裹改道率约 43%，凸显了其在实际应用中的卓越功效。]]></description>
      <guid>https://arxiv.org/abs/2411.13584</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Hymba：一种用于小型语言模型的混合头架构</title>
      <link>https://arxiv.org/abs/2411.13676</link>
      <description><![CDATA[arXiv:2411.13676v1 公告类型：新
摘要：我们提出了 Hymba，这是一系列小型语言模型，具有混合头并行架构，将变压器注意机制与状态空间模型 (SSM) 集成在一起以提高效率。注意头提供高分辨率回忆，而 SSM 头实现高效的上下文摘要。此外，我们引入了可学习的元标记，这些标记被添加到提示前面，存储关键信息并减轻与注意机制相关的“强制注意”负担。通过结合跨层键值 (KV) 共享和部分滑动窗口注意，该模型得到进一步优化，从而实现了紧凑的缓存大小。在开发过程中，我们进行了一项对照研究，在相同的设置下比较了各种架构，并观察到我们提出的架构的显着优势。值得注意的是，Hymba 在小型 LM 中取得了最先进的结果：我们的 Hymba-1.5B-Base 模型在性能上超越了所有 2B 以下的公共模型，甚至优于 Llama-3.2-3B，平均准确率高出 1.32%，缓存大小减少了 11.67 倍，吞吐量提高了 3.49 倍。]]></description>
      <guid>https://arxiv.org/abs/2411.13676</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>分层文本分类 (HTC) 与 eXtreme 多标签分类 (XML)：同一枚奖牌的两面</title>
      <link>https://arxiv.org/abs/2411.13687</link>
      <description><![CDATA[arXiv:2411.13687v1 公告类型：新
摘要：将固定标签池中的标签子集分配给给定的输入文本是文本分类问题，具有许多实际应用，例如在推荐系统中。两个独立的研究流解决了这个问题。分层文本分类 (HTC) 专注于具有数百个条目的较小标签池的数据集，并伴有语义标签层次结构。相比之下，eXtreme 多标签文本分类 (XML) 考虑具有多达数百万个条目的非常大的标签池，其中的标签没有以任何特定方式排列。然而，在 XML 中，一种常见的方法是在训练过程之前或期间构建一个没有任何语义信息的人工层次结构。在这里，我们研究一个领域的最先进模型在另一个领域的数据集上进行训练和测试时的表现。 HTC 域中的 HBGL 和 HGLCR 模型在 XML 域中的数据集 Wiki10-31K、AmazonCat-13K 和 Amazon-670K 上进行训练和测试。另一方面，XML 模型 CascadeXML 和 XR-Transformer 在 HTC 域中的数据集 Web of Science、纽约时报注释语料库和 RCV1-V2 上进行训练和测试。另一方面，HTC 模型无法处理 XML 数据集的大小，并且传输结果较差。可以从 https://github.com/FloHauss/XMC_HTC 获取重现我们的结果所需的代码和大量文件]]></description>
      <guid>https://arxiv.org/abs/2411.13687</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>评估法学硕士中的性别偏见：将法学硕士成果与人类认知和官方统计数据进行比较</title>
      <link>https://arxiv.org/abs/2411.13738</link>
      <description><![CDATA[arXiv:2411.13738v1 公告类型：新
摘要：本研究通过将大型语言模型 (LLM) 的性别感知与人类受访者、美国劳工统计局数据和 50% 无偏见基准进行比较，调查了大型语言模型 (LLM) 中的性别偏见。我们使用职业数据和特定于角色的句子创建了一个新的评估集。与 LLM 训练数据中包含的常见基准不同，我们的数据集是新开发的，可防止数据泄露和测试集污染。测试了五个 LLM，使用单词答案预测每个角色的性别。我们使用 Kullback-Leibler (KL) 散度将模型输出与人类感知、统计数据和 50% 中立基准进行比较。所有 LLM 都显示出与性别中立的显著偏差，并且与统计数据更加一致，仍然反映了固有的偏见。]]></description>
      <guid>https://arxiv.org/abs/2411.13738</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4 与人工翻译的对比：跨语言、领域和专业水平的全面评估</title>
      <link>https://arxiv.org/abs/2411.13775</link>
      <description><![CDATA[arXiv:2411.13775v1 公告类型：新 
摘要：本研究对 GPT-4 的翻译能力与不同专业水平的人工翻译进行了全面评估。通过使用 MQM 模式进行系统的人工评估，我们评估了三种语言对（中文$\longleftrightarrow$英语、俄语$\longleftrightarrow$英语和中文$\longleftrightarrow$印地语）和三个领域（新闻、技术和生物医学）的翻译。我们的研究结果表明，GPT-4 在总错误方面的表现与初级翻译相当，但仍落后于高级翻译。与传统的神经机器翻译系统在资源匮乏的语言方向上表现出显着的性能下降不同，GPT-4 在所有评估的语言对中保持一致的翻译质量。通过定性分析，我们发现了翻译方法中的独特模式：GPT-4 倾向于过度直译并表现出词汇不一致，而人类翻译有时会过度解释上下文并引入幻觉。这项研究首次对不同熟练程度的 LLM 和人类翻译进行了系统比较，为了解基于 LLM 的翻译系统的当前能力和局限性提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2411.13775</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>新闻采访：通过信息采访评估法学硕士 (LLM) 基础差距的数据集和平台</title>
      <link>https://arxiv.org/abs/2411.13779</link>
      <description><![CDATA[arXiv:2411.13779v1 公告类型：新
摘要：大型语言模型 (LLM) 在生成连贯文本方面表现出令人印象深刻的能力，但往往在基础语言和战略对话方面存在困难。为了解决这一差距，我们专注于新闻采访，这是一个基础交流丰富且数据丰富的领域。我们从 NPR 和 CNN 整理了 40,000 个双人信息采访的数据集，并发现 LLM 使用致谢和转向更高级别问题的可能性明显低于人类采访者。意识到多轮规划和战略思维存在根本缺陷，我们开发了一个逼真的模拟环境，结合源角色和说服元素，以促进具有长期回报的代理的发展。我们的实验表明，虽然源 LLM 模仿人类在信息共享中的行为，但采访者 LLM 难以识别问题何时得到回答并具有说服力，导致模型大小和能力的信息提取不理想。这些发现强调了提高法学硕士战略对话能力的必要性。]]></description>
      <guid>https://arxiv.org/abs/2411.13779</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用机器行为分析解释 GPT-4 的抑郁症图式</title>
      <link>https://arxiv.org/abs/2411.13800</link>
      <description><![CDATA[arXiv:2411.13800v1 公告类型：新 
摘要：ChatGPT（GPT-4）等大型语言模型在心理健康支持中的使用迅速增长，成为评估和帮助抑郁症等情绪障碍患者的有前途的途径。然而，我们对 GPT-4 的精神障碍模式的理解有限，即它如何在内部关联和解释症状。在这项工作中，我们利用当代测量理论来解码 GPT-4 如何将抑郁症症状相互关联，以提供临床效用和理论理解。我们发现 GPT-4 对抑郁症的评估：（a）具有较高的整体收敛效度（955 个样本的自我报告 r = .71，209 个样本的专家判断 r = .81）；（b）具有中等高的内部一致性（症状相互关联 r = .23 至 .78），与文献和自我报告基本一致；但 GPT-4 (c) 低估了自杀倾向——而过分强调了心理运动——与其他症状的关系，并且 (d) 具有表明细微假设的症状推断模式（例如，睡眠和疲劳受大多数其他症状的影响，而无价值感/内疚感主要受抑郁情绪的影响）。]]></description>
      <guid>https://arxiv.org/abs/2411.13800</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>SemiKong：策划、训练和评估半导体行业特定的大型语言模型</title>
      <link>https://arxiv.org/abs/2411.13802</link>
      <description><![CDATA[arXiv:2411.13802v1 公告类型：新
摘要：大型语言模型 (LLM) 已显示出解决半导体行业某些问题的潜力。然而，它们通常是通用模型，缺乏应对该行业独特挑战所需的专业知识，例如半导体器件和工艺的复杂物理和化学。SemiKong 是第一个针对半导体领域的行业特定 LLM，它提供了可用于开发定制专有模型的基础。借助 SemiKong 1.0，我们旨在开发一个能够在专家级别理解蚀刻问题的基础模型。我们的主要贡献包括 (a) 整理全面的半导体相关文本语料库，(b) 创建具有深入半导体知识的基础模型，以及 (c) 引入集成专家知识的框架，从而推进特定领域 AI 模型的评估过程。通过使用我们精选的数据集对预训练的 LLM 进行微调，我们已证明 SemiKong 在各种半导体制造和设计任务中的表现优于更大的通用 LLM。我们进行了广泛的实验，强调了开发领域特定的 LLM 作为公司或工具特定专有模型的基础的重要性，为半导体领域的进一步研究和应用铺平了道路。代码和数据集将在 https://github.com/aitomatic/semikong 上提供]]></description>
      <guid>https://arxiv.org/abs/2411.13802</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>InstCache：用于 LLM 服务的预测缓存</title>
      <link>https://arxiv.org/abs/2411.13820</link>
      <description><![CDATA[arXiv:2411.13820v1 公告类型：新
摘要：大型语言模型正在彻底改变人类生活的方方面面。然而，这种前所未有的能力是以巨大的计算强度为代价的，这意味着较长的延迟和较大的能源占用。键值缓存和语义缓存已被提出作为上述问题的解决方案，但由于每个标记或指令嵌入的内存成本很高，因此两者都存在有限的可扩展性。受大多数指令短、重复且可被 LLM 预测的观察结果的启发，我们建议通过指令对齐的 LLM 预测用户指令并将其存储在预测缓存中，即所谓的 InstCache。我们引入了一种基于指令负对数似然的指令预填充算法，根据命中率确定缓存大小。所提出的 InstCache 被有效地实现为哈希表，部署时查找延迟最小。实验结果表明，InstCache 在 LMSys 数据集上可以实现高达 51.34% 的命中率，相当于加速 2 倍，而内存成本仅为 4.5GB。]]></description>
      <guid>https://arxiv.org/abs/2411.13820</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行交互式、富有表现力的代码增强规划</title>
      <link>https://arxiv.org/abs/2411.13826</link>
      <description><![CDATA[arXiv:2411.13826v1 公告类型：新
摘要：大型语言模型 (LLM) 在常识推理和交互式决策方面表现出强大的能力，但通常在处理复杂的长期规划任务时会遇到困难。最近的技术试图使用控制流和其他代码相邻技术来构造 LLM 输出，以提高规划性能。这些技术包括使用变量（跟踪重要信息）和函数（将复杂任务划分为较小的可重复使用的子任务）。然而，纯粹基于代码的方法容易出错，并且不足以处理模糊或非结构化数据。为了应对这些挑战，我们提出了 REPL-Plan，这是一种完全代码表达的 LLM 规划方法（它可以利用代码的所有好处），同时也是动态的（它可以灵活地适应错误并在模糊情况下使用 LLM）。在 REPL-Plan 中，LLM 通过与读取-求值-打印循环 (REPL) 交互来解决任务，REPL 以迭代方式执行和评估代码，类似于语言 shell 或交互式代码笔记本，从而使模型能够灵活地纠正错误并动态处理任务。我们证明，与以前的方法相比，REPL-Plan 在各种规划领域都取得了出色的成果。]]></description>
      <guid>https://arxiv.org/abs/2411.13826</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>PIORS：基于大型语言模型和多智能体医疗场景模拟的个性化智能门诊接待</title>
      <link>https://arxiv.org/abs/2411.13902</link>
      <description><![CDATA[arXiv:2411.13902v1 公告类型：新
摘要：在中国，门诊护士面临着繁重的工作量，限制了他们对每个患者的时间和注意力，最终降低了服务质量。在本文中，我们提出了个性化智能门诊接待系统（PIORS）。该系统将基于LLM的接待护士以及LLM与医院信息系统（HIS）的协作整合到真实的门诊接待环境中，旨在提供个性化、高质量和高效的接待服务。此外，为了提高LLM在现实医疗场景中的表现，我们提出了一种名为服务流感知医疗场景模拟（SFMSS）的医疗对话数据生成框架，旨在使LLM适应现实环境和PIORS设置。我们通过涉及15名用户和15名临床专家的自动和人工评估来评估PIORS和SFMSS的有效性。结果表明，PIORS-Nurse 的表现优于所有基线，包括当前最先进的模型 GPT-4o，并且符合人类偏好和临床需求。更多详细信息和演示可在 https://github.com/FudanDISC/PIORS 找到]]></description>
      <guid>https://arxiv.org/abs/2411.13902</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向全面授权：设计旅行规划的理想代理行为</title>
      <link>https://arxiv.org/abs/2411.13904</link>
      <description><![CDATA[arXiv:2411.13904v1 公告类型：新
摘要：基于 LLM 的代理在未来将如何使用？虽然现有的许多代理工作都集中在提高特定客观和具有挑战性的任务系列的性能，但在这项工作中，我们采取了不同的视角，考虑完全授权：代理接管人类的日常决策过程，并受到人类的信任，以找到适合人们个性化需求并适应不断变化的环境的解决方案。为了实现这一目标，代理的行为，即代理行为，不仅应根据其成就（即结果评估）进行评估，还应根据其实现方式（即程序评估）进行评估。为此，我们提出了 APEC 代理宪法，这是代理应遵循的良好代理行为标准列表，包括准确性、主动性、效率和可信度。为了验证 APEC 是否符合人类偏好，我们开发了 APEC-Travel，这是一个旅行规划代理，它通过与旅行者进行多轮对话主动提取隐藏的个性化需求。APEC-Travel 完全由 Llama3.1-405B-Instruct 生成的合成数据构建，具有一组多样化的旅行者角色，以模拟丰富的对话分布。APEC-Travel 经过迭代微调以遵循 APEC Agent Constitution，在基于规则的指标上超出基线 20.7%，在宪法轴上的 LLM-as-a-Judge 得分上超出基线 9.1%。]]></description>
      <guid>https://arxiv.org/abs/2411.13904</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>预测未来国际事件：基于文本的事件建模的可靠数据集</title>
      <link>https://arxiv.org/abs/2411.14042</link>
      <description><![CDATA[arXiv:2411.14042v1 公告类型：新
摘要：根据新闻文章等文本信息预测未来国际事件在全球政策、战略决策和地缘政治中具有巨大的应用潜力。然而，现有的可用于此任务的数据集通常质量有限，阻碍了相关研究的进展。在本文中，我们介绍了 WORLDREP（世界关系和事件预测），这是一个新颖的数据集，旨在通过利用大型语言模型 (LLM) 的高级推理能力来解决这些限制。我们的数据集具有通过高级提示建模生成的高质量评分标签，并经过政治科学领域专家的严格验证。我们展示了 WORLDREP 在现实世界事件预测任务中的质量和实用性，并通过大量实验和分析证明了其有效性。此外，我们公开发布了我们的数据集以及用于数据收集、标记和基准测试的完整自动化源代码，旨在支持和推进基于文本的事件预测研究。]]></description>
      <guid>https://arxiv.org/abs/2411.14042</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>FunctionChat-Bench：韩语工具使用对话中语言模型生成能力的综合评估</title>
      <link>https://arxiv.org/abs/2411.14054</link>
      <description><![CDATA[arXiv:2411.14054v1 公告类型：新
摘要：本研究调查了语言模型在工具使用对话框中的生成能力。我们将工具使用对话框中的模型输出分为四种不同的类型：工具调用、答案完成、槽位问题和相关性检测，这些类型作为评估的方面。我们引入了 FunctionChat-Bench，它包含 700 个评估项目和自动评估程序。使用此基准，我们评估了几种支持函数调用的语言模型。我们的研究结果表明，虽然语言模型在单轮工具调用场景中可能表现出高精度，但这并不一定意味着在多轮环境中具有出色的生成性能。我们认为函数调用所需的能力不仅限于生成工具调用消息；它们还必须有效地生成吸引用户的对话消息。]]></description>
      <guid>https://arxiv.org/abs/2411.14054</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>DRPruning：通过分布式鲁棒优化实现高效的大型语言模型修剪</title>
      <link>https://arxiv.org/abs/2411.14055</link>
      <description><![CDATA[arXiv:2411.14055v1 公告类型：新
摘要：大型语言模型 (LLM) 提供了令人印象深刻的结果，但面临着模型大小和计算成本增加的挑战。结构化修剪可以减小模型大小并加快推理速度，但通常会导致跨域不均匀的退化，从而导致性能偏差。为了解决这个问题，我们提出了 DRPruning，它结合了分布式稳健优化来恢复跨域的平衡性能，并进行了进一步的改进以增强稳健性。在单语和多语环境中的实验表明，我们的方法在修剪和持续预训练方面优于类似大小的模型，包括困惑度、下游任务和指令调整。我们进一步提供了分析，证明了我们的方法对各种领域和分布变化的稳健性。此外，我们的方法会自动确定最佳参考损失和数据比率，这表明它具有更广泛的应用潜力。我们的代码可在 https://github.com/hexuandeng/DRPruning 上找到。]]></description>
      <guid>https://arxiv.org/abs/2411.14055</guid>
      <pubDate>Fri, 22 Nov 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>