<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arXiv.org 上的 cs.CL 更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 在 arXiv.org 电子打印档案上更新。</description>
    <lastBuildDate>Mon, 20 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>语言模型可以利用跨任务上下文学习来完成数据稀缺的新任务</title>
      <link>https://arxiv.org/abs/2405.10548</link>
      <description><![CDATA[arXiv:2405.10548v1 公告类型：新
摘要：大型语言模型（LLM）以其卓越的上下文学习（ICL）能力改变了 NLP。基于法学硕士的自动化助理越来越受欢迎；然而，让它们适应新任务仍然具有挑战性。虽然巨大的模型在零样本性能方面表现出色，但它们的计算需求限制了广泛使用，而较小的语言模型在没有上下文的情况下举步维艰。本文研究了法学硕士是否可以从预定义任务的标记示例推广到新任务。从生物神经元和 Transformer 架构的机械解释中汲取灵感，我们探索了跨任务信息共享的潜力。我们用三个法学硕士设计了一个跨任务提示设置，并表明尽管上下文中没有目标任务的示例，法学硕士仍实现了显着的性能改进。与零样本提示相比，跨任务提示使 LLaMA-2 7B 的性能显着提高了 107%，LLaMA-2 13B 的性能提高了 18.6%，GPT 3.5 的性能提高了 3.2%，并且性能与标准上下文学习相当。证明了为任务内示例生成伪标签的有效性，并且我们的分析揭示了跨任务示例的效果与源和目标输入标记中的模型激活相似性之间存在很强的相关性。本文对法学硕士根据不同任务示例的上下文信号解决新任务的能力进行了首次探索。]]></description>
      <guid>https://arxiv.org/abs/2405.10548</guid>
      <pubDate>Mon, 20 May 2024 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>难题：使用会话大型语言模型进行习语检测</title>
      <link>https://arxiv.org/abs/2405.10579</link>
      <description><![CDATA[arXiv:2405.10579v1 公告类型：新
摘要：在这项工作中，我们利用大型语言模型（LLM）探索惯用语言处理。我们推出了惯用语言测试套件 IdioTS，这是一个新的困难示例数据集，由语言专家专门设计，用于评估法学硕士在句子级别处理比喻语言的能力。我们提出了一种基于习语检测任务的综合评估方法，其中提示法学硕士检测给定英语句子中的惯用表达。我们对结果进行彻底的自动和手动评估，并进行广泛的错误分析。]]></description>
      <guid>https://arxiv.org/abs/2405.10579</guid>
      <pubDate>Mon, 20 May 2024 06:18:30 GMT</pubDate>
    </item>
    <item>
      <title>智能专家系统：作为文本分类器的大型语言模型</title>
      <link>https://arxiv.org/abs/2405.10523</link>
      <description><![CDATA[arXiv:2405.10523v1 公告类型：新
摘要：文本分类是自然语言处理（NLP）中的一项基本任务，大型​​语言模型（LLM）的出现彻底改变了该领域。本文介绍了智能专家系统，这是一种利用法学硕士作为文本分类器的新颖方法。该系统简化了传统的文本分类工作流程，无需大量预处理和领域专业知识。多个法学硕士、机器学习 (ML) 算法和基于神经网络 (NN) 的结构的性能在四个数据集上进行了评估。结果表明，某些法学硕士在情感分析、垃圾短信检测和多标签分类方面超越了传统方法。此外，研究表明，系统的性能可以通过少量或微调策略进一步增强，从而使微调后的模型在所有数据集中表现最佳。源代码和数据集可在此 GitHub 存储库中获取：https://github.com/yeyimilk/llm-zero-shot-classifiers。]]></description>
      <guid>https://arxiv.org/abs/2405.10523</guid>
      <pubDate>Mon, 20 May 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>在 CFLUE 上对大型语言模型进行基准测试——中国金融语言理解评估数据集</title>
      <link>https://arxiv.org/abs/2405.10542</link>
      <description><![CDATA[arXiv:2405.10542v1 公告类型：新
摘要：鉴于最近大型语言模型（LLM）的突破彻底改变了自然语言处理（NLP），迫切需要新的基准来跟上 LLM 的快速发展。在本文中，我们提出了CFLUE，即中文金融语言理解评估基准，旨在评估法学硕士在各个维度的能力。具体来说，CFLUE 提供了为知识评估和应用评估量身定制的数据集。在知识评估中，它由 38K+ 多项选择题和相关解决方案说明组成。这些问题有双重目的：答案预测和问题推理。在应用评估中，CFLUE 在不同的 NLP 任务组中提供了 16K 多个测试实例，例如文本分类、机器翻译、关系提取、阅读理解和文本生成。在 CFLUE 上，我们对代表性的法学硕士进行了彻底的评估。结果表明，只有 GPT-4 和 GPT-4-turbo 在知识评估的答案预测中达到了超过 60% 的准确率，这表明当前的 LLM 仍有很大的改进空间。在申请评估中，虽然 GPT-4 和 GPT-4-turbo 是表现最好的两个，但它们相对于轻量级 LLM 的巨大优势明显减弱。与 CFLUE 相关的数据集和脚本可在 https://github.com/aliyun/cflue 上公开访问。]]></description>
      <guid>https://arxiv.org/abs/2405.10542</guid>
      <pubDate>Mon, 20 May 2024 06:18:29 GMT</pubDate>
    </item>
    <item>
      <title>语言模型可以通过概率差异来自我评估</title>
      <link>https://arxiv.org/abs/2405.10516</link>
      <description><![CDATA[arXiv:2405.10516v1 公告类型：新
摘要：在本文中，我们通过演示大型语言模型（LLM）在负责响应查询时如何在其更熟练的情况下在其答案中显示出更均匀的概率分布来开始我们的讨论，而不是技能较差的同行。扩展这一基本见解，我们提出了一种新的自我评估方法 ProbDiff，用于评估各种法学硕士的有效性。这种方法消除了额外评估模型的必要性，也消除了对 GPT-4 等外部专有模型进行判断的依赖。它独特地利用正在测试的法学硕士来计算初始响应与其修订版本之间的概率差异。两个法学硕士之间给定查询的差异越大，表明能力相对较弱。我们的研究结果表明，ProbDiff 取得的结果与基于 GPT-4 的评估获得的结果相当，涵盖了一系列场景，包括自然语言生成 (NLG) 任务，如翻译、摘要和我们提出的小红书博客写作任务以及基准测试用于 LLM 评估，例如 AlignBench、MT-Bench 和 AlpacaEval，涵盖不同程度的 LLM。]]></description>
      <guid>https://arxiv.org/abs/2405.10516</guid>
      <pubDate>Mon, 20 May 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>在基于 QA 的事件提取中实现更好的问题生成</title>
      <link>https://arxiv.org/abs/2405.10517</link>
      <description><![CDATA[arXiv:2405.10517v1 公告类型：新
摘要：事件提取（EE）是一项重要的信息提取任务，旨在从非结构化文本中提取与事件相关的信息。这项任务的范式已经从传统的基于分类的方法转变为更现代的基于问答 (QA) 的方法。然而，在基于 QA 的 EE 中，问题的质量极大地影响了提取的准确性，如何为基于 QA 的 EE 生成高质量的问题仍然是一个挑战。在这项工作中，为了应对这一挑战，我们提出了四个标准来评估问题的质量，并提出了一种基于 QA 的 EE 的强化学习方法，该方法可以生成流畅的、可概括的和上下文相关的问题，并为 QA 模型提供明确的指导。在 ACE 和 RAMS 数据集上进行的大量实验有力地验证了我们方法的有效性，这也证明了其在训练数据有限的场景中的鲁棒性。]]></description>
      <guid>https://arxiv.org/abs/2405.10517</guid>
      <pubDate>Mon, 20 May 2024 06:18:28 GMT</pubDate>
    </item>
    <item>
      <title>重新思考 ChatGPT 的成功：自回归 LLM 提示带来的可用性和认知行为</title>
      <link>https://arxiv.org/abs/2405.10474</link>
      <description><![CDATA[arXiv:2405.10474v1 公告类型：新
摘要：在过去的十年中，出现了各种针对大型语言模型（LLM）的培训和部署策略。其中，自回归法学硕士（AR-LLM）的推动范式催化了人工智能（AI）的显着增长。本文旨在强调利用自由形式模态（输入和输出的形式）和言语自由形式上下文作为下游部署的用户导向渠道（转换模态的方法）的重要性。具体来说，我们分析了部署期间两种类型的法学硕士和六个特定于任务的渠道内的模式结构。从用户的角度来看，我们的分析引入并应用了任务可定制性、透明度和复杂性的分析指标来衡量其可用性，突出了 AR-LLM 提示范式的优越性。此外，我们通过采用自由格式的文本和言语环境，反映了此类行为的人类语言表达，研究了法学硕士中不同认知行为的刺激。然后，我们详细介绍了四种常见的认知行为，以强调 AR-LLM 的提示如何使用这种自由形式的模式和渠道成功模仿类人行为。最后，通过认知行为概念和原则确定了改进 LLM 部署（无论是作为自主代理还是在多代理系统内）的潜力。]]></description>
      <guid>https://arxiv.org/abs/2405.10474</guid>
      <pubDate>Mon, 20 May 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>CNER：命名实体关系的工具分类器</title>
      <link>https://arxiv.org/abs/2405.10485</link>
      <description><![CDATA[arXiv:2405.10485v1 公告类型：新
摘要：我们介绍了 CNER，这是一个用于提取西班牙语命名实体之间语义关系的强大工具集。 CNER建立在基于容器的架构之上，将不同的命名实体识别和关系提取工具与用户友好的界面集成在一起，允许用户轻松输入自由文本或文件，从而促进简化分析。 CNER 是为山谷大学自然语言处理 (NLP) 小组开发的原型版本，可作为实用的教育资源，说明机器学习技术如何有效地处理西班牙语的各种 NLP 任务。我们的初步结果揭示了 CNER 在促进 NLP 工具的理解和开发方面的巨大潜力，特别是在西班牙语环境中。]]></description>
      <guid>https://arxiv.org/abs/2405.10485</guid>
      <pubDate>Mon, 20 May 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>基于语言处理的新闻自动生成与事实核查系统</title>
      <link>https://arxiv.org/abs/2405.10492</link>
      <description><![CDATA[arXiv:2405.10492v1 Announce Type: new 
摘要：本文探讨一种基于语言处理的新闻自动生成与事实核查系统，旨在提高新闻生产的效率和质量，同时保证新闻内容的真实性和可靠性。随着自然语言处理（NLP）和深度学习技术的快速发展，新闻自动生成系统能够从海量数据中提取关键信息，生成结构良好、流畅的新闻文章。同时，通过整合事实核查技术，该系统可以有效防止虚假新闻的传播，提高新闻的准确性和可信度。本研究详细介绍了新闻自动生成与事实核查所涉及的关键技术，包括文本生成、信息提取和知识图谱的应用，并通过实验验证了这些技术的有效性。此外，本文还讨论了新闻自动生成与事实核查系统未来的发展方向，强调了进一步融合和创新技术的重要性。结果表明，随着技术不断优化和实际应用，这些系统将在未来的新闻行业中发挥越来越重要的作用，提供更加高效、可靠的新闻服务。]]></description>
      <guid>https://arxiv.org/abs/2405.10492</guid>
      <pubDate>Mon, 20 May 2024 06:18:27 GMT</pubDate>
    </item>
    <item>
      <title>通过主题建模和超参数优化引导循环经济中的公众情绪</title>
      <link>https://arxiv.org/abs/2405.10452</link>
      <description><![CDATA[arXiv:2405.10452v1 公告类型：新
摘要：为了推动循环经济 (CE)，了解公众情绪的演变、大众对循环产品和数字技术的认知路径，并认识到主要关注点至关重要。为此，我们从 Twitter、Reddit 和卫报等各种平台收集了与 CE 相关的数据。这一全面的数据收集涵盖了公众的三个不同阶层：普通公众、专业人士和官方来源。随后，我们在收集的数据上使用三个主题模型。主题建模代表一种数据驱动和机器学习的文本挖掘方法，能够自动将大量文档分类为不同的语义组。同时，这些组由主题描述，这些主题可以帮助从高层次理解文档的语义内容。然而，主题建模的性能可能会因不同的超参数值而有所不同。因此，在本研究中，我们提出了一个针对 CE 的主题建模和超参数优化框架，并进行了一系列系统性实验，以确保主题模型设置了适当的超参数，并基于完善的模型深入了解 CE 与公众舆论之间的相关性。本研究的结果表明，对可持续性和经济影响的担忧在所有三个数据集中都持续存在。官方消息来源对 CE 的应用和监管表现出更高的参与度。据我们所知，这项研究开创性地通过主题建模和超参数优化探索调查了有关 CE 的不同层次的公众舆论。]]></description>
      <guid>https://arxiv.org/abs/2405.10452</guid>
      <pubDate>Mon, 20 May 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>分词前置的名词比分词后附加的名词具有更低的熵</title>
      <link>https://arxiv.org/abs/2405.10457</link>
      <description><![CDATA[arXiv:2405.10457v1 公告类型：新
摘要：英语允许复合词（例如，London-made）和短语释义（例如，made in London）。虽然这些结构具有大致相同的真值条件含义，但我们假设该复合词在表达分词和前分词名词之间语义关系的本质方面的自由度较低。因此，我们预测前分词槽比短语结构中的等效位置受到更多限制。我们通过测量相应名义槽的熵（以所使用的分词为条件）在大型语料库中测试此预测。也就是说，对于给定的情况，我们将 $\alpha$-[V]ed 等复合结构槽中 $\alpha$ 的熵与 $\alpha$ 的 [V]ed 等短语结构中 $\alpha$ 的熵进行比较动词 V。正如预测的那样，复合结构中的熵明显低于短语结构中的熵。我们考虑这些预测如何从更一般的语法属性和处理因素中得出。]]></description>
      <guid>https://arxiv.org/abs/2405.10457</guid>
      <pubDate>Mon, 20 May 2024 06:18:26 GMT</pubDate>
    </item>
    <item>
      <title>检索和提炼：用于罕见疾病识别的大型语言模型混合框架</title>
      <link>https://arxiv.org/abs/2405.10440</link>
      <description><![CDATA[arXiv:2405.10440v1 公告类型：新
摘要：罕见疾病临床表现的不频繁性和异质性常常导致诊断不足以及被排除在结构化数据集中。这就需要利用非结构化文本数据进行综合分析。然而，从临床报告中进行手动识别是一项艰巨且本质上主观的任务。这项研究提出了一种新颖的混合方法，将传统的基于字典的自然语言处理（NLP）工具与大语言模型（LLM）的强大功能相结合，以增强从非结构化临床记录中识别罕见疾病的能力。我们全面评估了不同规模和领域（普通和医学）的六种大型语言模型（LLM）的各种提示策略。该评估涵盖零样本、少样本和检索增强生成 (RAG) 技术，以增强法学硕士推理和理解患者报告中的上下文信息的能力。结果证明了罕见病识别的有效性，凸显了从临床记录中识别诊断不足的患者的潜力。]]></description>
      <guid>https://arxiv.org/abs/2405.10440</guid>
      <pubDate>Mon, 20 May 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>同时屏蔽，不提示优化：同步翻译法学硕士微调的范式转变</title>
      <link>https://arxiv.org/abs/2405.10443</link>
      <description><![CDATA[arXiv:2405.10443v1 公告类型：新
摘要：大型语言模型（LLM）在各种语言处理任务中取得了最先进的性能，推动了它们在同声翻译中的采用。当前使法学硕士适应同声翻译的微调方法侧重于使用数据增强或提示结构修改来提示优化策略。然而，这些方法存在几个问题，例如不必要地扩展训练集、转储 KV 缓存导致的计算效率低下、提示大小增加或对单个决策策略的限制。为了消除这些问题，我们提出了一种新的范例，用于微调同步翻译法学硕士，称为 SimulMask。它利用一种新颖的注意力屏蔽技术，通过在所需的决策策略下屏蔽注意力连接，在微调过程中对同步翻译进行建模。将所提出的 SimulMask 应用到 IWSLT 2017 数据集的 Falcon LLM 上，我们观察到，与三种语言对上最先进的提示优化策略相比，当在四种不同的延迟情况下进行平均时，翻译质量有了显着的提高，同时降低了计算成本。]]></description>
      <guid>https://arxiv.org/abs/2405.10443</guid>
      <pubDate>Mon, 20 May 2024 06:18:25 GMT</pubDate>
    </item>
    <item>
      <title>AmazUtah_NLP 在 SemEval-2024 任务 9：用于违背常识推理的多选问答系统</title>
      <link>https://arxiv.org/abs/2405.10385</link>
      <description><![CDATA[arXiv:2405.10385v1 公告类型：新
摘要：SemEval 2024 BRAINTEASER 任务代表了自然语言处理 (NLP) 领域的一项开创性尝试，它专注于横向思维，这是传统语言分析中经常被忽视的认知推理维度。该挑战包括句子谜题和单词谜题子任务，旨在测试语言模型的发散思维能力。
  在本文中，我们介绍了 BRAINTEASER 任务的方法。我们通过在多项选择架构中利用尖端的预训练模型来采用整体策略，并通过句子和单词谜题数据集使训练数据多样化。为了获得进一步的改进，我们使用合成幽默/笑话数据集和 RiddleSense 数据集对模型进行了微调，这有助于增强模型的横向思维能力。实证结果表明，我们的方法在句子谜题子任务中达到了 92.5% 的准确率，在单词谜题子任务中达到了 80.2% 的准确率。]]></description>
      <guid>https://arxiv.org/abs/2405.10385</guid>
      <pubDate>Mon, 20 May 2024 06:18:24 GMT</pubDate>
    </item>
    <item>
      <title>公平而缓慢的思考：论结构化提示对消除语言模型偏差的功效</title>
      <link>https://arxiv.org/abs/2405.10431</link>
      <description><![CDATA[arXiv:2405.10431v1 公告类型：新
摘要：现有的去偏技术通常基于训练，或者需要访问模型的内部结构和输出分布，因此对于希望根据特定需求调整 LLM 输出的最终用户来说，它们无法访问。在本研究中，我们研究了结构化提示技术是否可以提供公平文本生成的机会。我们评估了一个全面的以最终用户为中心的去偏迭代框架，该框架将系统 2 思维过程应用于提示，以诱导逻辑、反思和批判性文本生成，具有单步、多步、指令和基于角色的变体。通过系统地评估许多数据集和不同提示策略中的许多 LLM，我们表明，更复杂的基于系统 2 的隐含提示比其他技术有显著的改进，输出中的平均偏差更低，下游任务中的表现具有竞争力。我们的工作为 LLM 使用的以最终用户为中心的评估框架的设计和潜力提供了研究方向。]]></description>
      <guid>https://arxiv.org/abs/2405.10431</guid>
      <pubDate>Mon, 20 May 2024 06:18:24 GMT</pubDate>
    </item>
    </channel>
</rss>