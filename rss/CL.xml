<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>arxiv.org上的cs.cl更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.cl在arxiv.org e-print档案中更新。</description>
    <lastBuildDate>Mon, 24 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>语言模型训练后的令牌级别的不确定性感知目标</title>
      <link>https://arxiv.org/abs/2503.16511</link>
      <description><![CDATA[ARXIV：2503.16511V1公告类型：新 
摘要：在当前工作中，我们将因果语言建模中的令牌级别的不确定性连接到两种类型的培训目标：1）掩盖最大可能性（MLE），2）自我抗议。我们表明，蒙面的MLE有效地降低了认知不确定性，并充当有效的令牌自动课程学习技术。但是，蒙面的MLE容易过度拟合，需要自我验证正规化以改善或维持分布式任务的绩效。我们通过提出的训练目标（跨多个体系结构（Gemma，Llama，Phi）和数据集（Alpaca，ShareGPT，GSM8K）跨越了跨性能的训练目标 - 结合掩盖的MLE和自我鉴定，表明了显着的性能增长，从而在培训期间保持适应能力，从而缓解过度拟合。我们的发现表明，不确定性感知培训为增强语言模型培训提供了有效的机制。]]></description>
      <guid>https://arxiv.org/abs/2503.16511</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Medifact在Peranssumm 2025：利用轻巧模型，以特定于临床问答论坛的特定透视图</title>
      <link>https://arxiv.org/abs/2503.16513</link>
      <description><![CDATA[ARXIV：2503.16513V1公告类型：新 
摘要：Peranssumm 2025挑战重点关注视角 - 意识到的医疗答案摘要（Agarwal等，2025）。这项工作建议使用浮潜-BART-SVM管道进行几次学习框架，以分类和总结开放式医疗保健社区的问题避开（CQA）。 SVM模型通过浮潜训练较弱的监督，从而增强了零拍的学习。提取性分类标识了与透视相关的句子，然后使用预验证的Bart-CNN模型进行汇总。该方法在共享任务中获得了100个团队中的第12位，证明了计算效率和上下文准确性。通过利用预处理的摘要模型，这项工作将进步医学CQA研究，并为临床决策支持系统做出了贡献。]]></description>
      <guid>https://arxiv.org/abs/2503.16513</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM文献综述的跨学科系统科学综述中强调案例研究</title>
      <link>https://arxiv.org/abs/2503.16515</link>
      <description><![CDATA[ARXIV：2503.16515V1公告类型：新 
摘要：大型语言模型（LLM）用于协助四个联邦科学和工业研究组织（CSIRO）研究人员进行系统文献评论（SLR）。在这些案例研究中，我们评估了SLR任务的LLMS的性能。在每个中，我们探讨了改变参数对LLM响应准确性的影响。 LLM的任务是从选定的学术论文中提取证据，以回答具体的研究问题。我们评估了模型在忠实地再现文献报价中的表现，并要求专家评估回答研究问题时的模型绩效。我们开发了一种语义文本突出显示工具，以促进对LLM响应的专家审查。
  我们发现，最新的LLM的状态能够从准确性超过95％的文本中复制报价，并以约83％的精度回答研究问题。我们使用两种方法来确定LLM响应的正确性。专家评论和LLM的变压器嵌入和专家答案的余弦相似性。这些方法之间的相关性范围为0.48至0.77，提供了证据表明后者是测量语义相似性的有效指标。]]></description>
      <guid>https://arxiv.org/abs/2503.16515</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用LLM进行自动隐私政策分析：及时工程，微调和解释性</title>
      <link>https://arxiv.org/abs/2503.16516</link>
      <description><![CDATA[ARXIV：2503.16516V1公告类型：新 
摘要：隐私政策被数字服务广泛使用，通常是为了法律目的。已经开发出许多基于机器的基于机器的分类器来自动检测给定的隐私政策中不同概念，这可以帮助促进其他自动化任务，例如产生更友好的摘要和检测法律合规性问题。尽管大型语言模型（LLMS）成功地应用于各个领域的许多NLP任务，但研究LLM用于自动隐私政策分析的工作很少，因此，IF和LLMS可以帮助自动化隐私政策分析的方法仍然不足。为了填补这一研究差距，我们对基于LLM的隐私政策概念分类器进行了全面评估，同时采用了迅速的工程和LORA（低级别适应）微调，对四个最先进的（SOTA）隐私政策公司和分类法。我们的实验结果表明，将及时的工程和微调结合起来可以使基于LLM的分类器优于其他SOTA方法，即\ emph {显着}和\ emph {始终如一的emph {一致}跨隐私政策语料库/分类法/分类法和概念。此外，我们使用三个指标评估了基于LLM的分类器的解释性：完整性，逻辑性和可理解性。对于所有三个指标，在我们的评估中都观察到超过91.1 \％的分数，表明LLM不仅有用可改善分类性能，而且还可以增强检测结果的解释性。]]></description>
      <guid>https://arxiv.org/abs/2503.16516</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>并非所有的角色都值得：文化反射性角色数据增强</title>
      <link>https://arxiv.org/abs/2503.16520</link>
      <description><![CDATA[ARXIV：2503.16520V1公告类型：新 
摘要：将角色纳入会话AI模型对于实现真实和引人入胜的相互作用至关重要。但是，现有角色数据集的文化多样性和适应性经常被忽略，从而降低了它们在构建文化意识的AI系统方面的功效。为了解决这个问题，我们提出了一条两步的管道，用于产生特定文化的角色并介绍Kopersona，这是一个包含200,000个角色的数据集，旨在捕捉韩国文化价值观，行为和社会细微差别。通过各种指标进行的全面评估验证了Kopersona的质量及其与韩国文化的相关性。这项工作不仅有助于基于角色的研究，而且还建立了一种可扩展的方法来创建适应各种语言和文化背景的文化相关角色。]]></description>
      <guid>https://arxiv.org/abs/2503.16520</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Mind2：通过双向认知话语分析的心态情感支持系统</title>
      <link>https://arxiv.org/abs/2503.16523</link>
      <description><![CDATA[ARXIV：2503.16523V1公告类型：新 
摘要：情感支持（ES）系统通过基于不同用户情况产生战略支持对话来减轻用户的心理困扰。但是，ES系统的生成有效对话的能力有限，包括及时的上下文和解释性，阻碍了他们获得公众信任。在认知模型的驱动下，我们提出了思想与脑海（Mind2），这是一个ES框架，从话语分析的角度来看，使用ES对话生成任务的可解释的ES上下文建模。具体来说，我们根据我们的动态话语上下文传播窗口对ES对话进行认知话语分析，该窗口随着ES系统与用户之间的对话而适应不断发展的上下文。为了增强可解释性，Mind2优先考虑将每个说话者对另一个说话者的信念的细节，以双向性，整合心理理论，生理期望效用和认知合理性，以从ES对话中提取认知知识。实验结果支持Mind2可以实现竞争性能与最先进的ES系统，而仅接受10 \％的可用培训数据培训。]]></description>
      <guid>https://arxiv.org/abs/2503.16523</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>KVShare：有效的大语言模型推理的语义意识键值缓存共享</title>
      <link>https://arxiv.org/abs/2503.16525</link>
      <description><![CDATA[ARXIV：2503.16525V1公告类型：新 
摘要：本文介绍了基于语义相似性的多用户键值（KV）缓存共享技术的KVShare，旨在提高大语言模型（LLMS）和多模式大语模型（MLLMS）的推理效率。 KVShare解决了现有前缀缓存（严格的文本前缀匹配）和语义缓存（响应多样性的丧失）的局限性，通过语义对齐算法和差分编辑操作，KVShare实现了细粒度的KV缓存重复使用。现实世界中用户对话数据集的实验表明，KVShare将KV Cache HIT率提高了60％以上，同时保持与完整计算相当的输出质量（BLEU和ROUGE-L METICS无显着降解）。这种方法有效地减少了GPU的资源消耗，并且适用于具有重复性查询的场景，例如医疗保健和教育。]]></description>
      <guid>https://arxiv.org/abs/2503.16525</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>LLM生成的角色是一个陷阱的承诺</title>
      <link>https://arxiv.org/abs/2503.16527</link>
      <description><![CDATA[ARXIV：2503.16527V1公告类型：新 
摘要：使用大语言模型（LLM）模拟人类行为已引起了人们的重大关注，尤其是通过近似个体特征的角色。基于角色的模拟有望改变依赖人口水平反馈的学科，包括社会科学，经济分析，市场研究和业务运营。收集现实角色数据的传统方法面临重大挑战。由于隐私的限制，它们非常昂贵且具有逻辑上的挑战，并且通常无法捕获多维属性，尤其是主观质量。因此，LLMS的合成角色生成提供了可扩展的，具有成本效益的替代方案。但是，当前的方法依赖于临时和启发式生成技术，这些技术不能保证方法论严格或模拟精度，从而导致下游任务的系统偏见。通过广泛的大规模实验，包括总统选举预测和对美国人口的一般意见调查，我们透露，这些偏见可能导致与现实成果的巨大偏差。我们的发现强调了开发严格的角色生成科学的必要性，并概述了方法论创新，组织和机构支持以及增强LLM驱动角色模拟的可靠性和可扩展性所需的经验基础。为了支持该领域的进一步研究和发展，我们已经开源了大约一百万个生成的角色，可在https://huggingface.co/datasets/tianyi-lab/personas上进行公共访问和分析。]]></description>
      <guid>https://arxiv.org/abs/2503.16527</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>HDLCORE：用于减轻LLM生成HDL幻觉的无培训框架</title>
      <link>https://arxiv.org/abs/2503.16528</link>
      <description><![CDATA[ARXIV：2503.16528V1公告类型：新 
摘要：大语言模型（LLMS）的最新进展已在代码生成任务中表现出显着的功能。但是，当应用于硬件说明语言（HDL）时，由于数据稀缺性，这些模型会出现重大限制，从而导致幻觉和代码生成不正确。为了应对这些挑战，我们提出了HDLCore，这是一个无培训的框架，通过迅速的工程技术和检索功能增强的生成（RAG）来增强LLMS的HDL生成能力。我们的方法由两个主要组成部分组成：（1）一种用自我验证提示技术提示技术的HDL感知链（COT），这些技术通过复杂性和类型对任务进行了分类，结合了域特异性知识，并通过逐步的逐步自我模拟来指导LLMS以进行错误纠正； （2）一个两阶段的异质抹布系统，通过关键组件提取来解决格式的不一致，并通过顺序滤波和重新排列有效地检索相关的HDL示例。 HDLCORE消除了对模型进行微调的需求，同时实质上提高了LLMS的HDL生成功能。实验结果表明，我们的框架在RTLLM2.0基准上实现了卓越的性能，大大降低了幻觉并提高了句法和功能正确性。]]></description>
      <guid>https://arxiv.org/abs/2503.16528</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在中文环境下的安全评估和增强DeepSeek模型</title>
      <link>https://arxiv.org/abs/2503.16529</link>
      <description><![CDATA[ARXIV：2503.16529V1公告类型：新 
摘要：DeepSeek-R1以其出色的推理能力和开源战略而闻名，它极大地影响了全球人工智能领域。但是，它表现出显着的安全缺点。 Cisco的子公司与宾夕法尼亚大学合作进行的Robust Intelligence进行的最新研究表明，DeepSeek-R1在处理有害提示时达到了100 \％的攻击成功率。此外，多个安全公司和研究机构已经确定了模型中的关键安全漏洞。尽管中国Unicom在中国环境中发现了R1的安全漏洞，但尚未对R1系列中其余蒸馏模型的安全能力进行全面评估。为了解决这一差距，这项研究利用了全面的中国安全基准Chisafetybench对DeepSeek-R1系列蒸馏模型进行了深入的安全评估。目的是在蒸馏之前和之后评估这些模型的安全能力，并进一步阐明蒸馏对模型安全的不利影响。在这些发现的基础上，我们为六种蒸馏型实施了针对性的安全性增强。评估结果表明，增强模型在没有明显降解的情况下保持推理能力的同时，可以取得显着改善。我们在https://github.com/unicomai/deepseek-r1-distill-safe/tree/main上开放安全增强模型，以作为未来研究和优化DeepSeek模型的宝贵资源。]]></description>
      <guid>https://arxiv.org/abs/2503.16529</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用知识超图来增强LLM的生成循证医学</title>
      <link>https://arxiv.org/abs/2503.16530</link>
      <description><![CDATA[ARXIV：2503.16530V1公告类型：新 
摘要：基于证据的医学（EBM）在医疗保健中大型语言模型（LLM）的应用中起着至关重要的作用，因为它为医疗决策过程提供了可靠的支持。尽管它受益于当前的检索型发电〜（RAG）技术，但它仍然面临两个重大挑战：分散证据的收集和有效的该证据的组织来支持EBM所需的复杂查询。为了解决这些问题，我们建议使用LLM从多个来源收集分散的证据，并提出基于知识的证据管理模型，以在捕获复杂的关系的同时整合这些证据。此外，为了更好地支持复杂的查询，我们开发了一种重要性驱动的证据优先级（IDEP）算法，该算法利用LLM来生成多个证据特征，每个算法都具有相关的重要性评分，然后将其用于对证据进行排名并产生最终检索结果。六个数据集的实验结果表明，我们的方法在EBM感兴趣的应用领域（例如医疗测验，幻觉检测和决策支持）优于现有的破布技术。可以通过\ href {https://drive.google.com/file/d/1wj9qtokkk3mdkjemwufqxwufqxwh96j_byawj_/view？usp = drive_link} {]]></description>
      <guid>https://arxiv.org/abs/2503.16530</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>EEG-CLIP：从自然语言描述中学习脑电图表示</title>
      <link>https://arxiv.org/abs/2503.16531</link>
      <description><![CDATA[Arxiv：2503.16531V1公告类型：新 
摘要：脑电图（EEG）解码的深网通常经常受过训练，以解决诸如病理或性别解码之类的特定任务。利用临床脑电图记录的医学报告的一种更通用的方法是学习医疗报告和脑电图记录之间的映射。这种方法在计算机视觉域匹配的图像及其文本字幕中率先开创，随后允许使用文本类提示进行成功进行零射击解码。在这项工作中，我们遵循这种方法，并开发了一个对比度学习框架eeg-clip，该框架将eeg时间序列及其相应的临床文本描述保持在共享的嵌入空间中。我们研究了其多功能脑电图解码的潜力，评估了一系列少数和零弹性设置的性能。总体而言，结果表明，EEG-CLIP管理非对齐文本和EEG表示。我们的工作提出了一种有前途的方法来学习一般脑电图表示，这可以通过零射击解码或培训特定于任务的模型从更少的培训示例来更轻松地分析各种解码问题。复制我们结果的代码可在https://github.com/tidiane-camaret/eegclip上获得。]]></description>
      <guid>https://arxiv.org/abs/2503.16531</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从患者咨询到图表：利用LLM的患者旅程知识图构建</title>
      <link>https://arxiv.org/abs/2503.16533</link>
      <description><![CDATA[ARXIV：2503.16533V1公告类型：新 
摘要：向以患者为中心的医疗保健的过渡需要对患者旅行有全面的了解，这涵盖了整个护理领域的所有医疗体验和互动。现有的医疗保健数据系统通常是分散的，缺乏对患者轨迹的整体表示，从而为协调的护理和个性化干预措施构成了挑战。患者旅程知识图（PJKGS）代表了一种新的方法，可以通过将各种患者信息整合到统一的结构化表示形式中来解决零散的医疗保健数据的挑战。本文提出了一种使用大语言模型（LLM）来构建PJKG的方法，以处理和构建正式的临床文档和非结构化的患者支持者对话。这些图形封装了临床相遇，诊断，治疗和结果之间的时间和因果关系，从而实现了高级的时间推理和个性化的护理见解。该研究以产生准确和计算有效的知识图的能力评估了四种不同的LLM，例如Claude 3.5，Mistral，Llama 3.1和Chatgpt4o。结果表明，尽管所有模型均达到完美的结构合规性，但它们在医疗实体处理和计算效率方面表现出差异。本文通过确定关键挑战和未来的研究方向结束。这项工作有助于通过发展全面，可行的知识图来推进以患者为中心的医疗保健，从而支持改善护理协调和结果预测。]]></description>
      <guid>https://arxiv.org/abs/2503.16533</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>大语言模型中的性别和内容偏见：Google Gemini 2.0 Flash实验的案例研究</title>
      <link>https://arxiv.org/abs/2503.16534</link>
      <description><![CDATA[ARXIV：2503.16534V1公告类型：新 
摘要：这项研究评估了Gemini 2.0 Flash实验中的偏见，这是Google开发的最先进的大语言模型（LLM），重点是内容审核和性别差异。通过将其性能与作者先前的作品进行了研究，分析强调了道德节制实践的某些差异。 Gemini 2.0表现出性别偏见的减少，特别是与Chatgpt-4O获得的结果相比，女性特异性提示的接受率大幅上升。它对性内容采取了更宽松的立场，并在包括特定性别的案件在内的暴力提示中保持了相对较高的接受率。尽管有这些变化，但它们是否构成改进是有争议的。尽管性别偏见已经减少，但这种减少的代价是允许对男性和女性的更多暴力内容，可能使暴力正常而不是减轻伤害。男性特异性提示通常仍然比女性特定的提示更高。这些发现强调了使AI系统与道德标准保持一致的复杂性，从而强调了减少某些偏见的进步，同时提出了对模型允许性更广泛含义的担忧。持续的改进对于实现适度实践至关重要，以确保透明度，公平性和包容性而不会放大有害内容。]]></description>
      <guid>https://arxiv.org/abs/2503.16534</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Word2minecraft：通过大语言模型生成3D游戏水平</title>
      <link>https://arxiv.org/abs/2503.16536</link>
      <description><![CDATA[ARXIV：2503.16536V1公告类型：新 
摘要：我们提出Word2Minecraft，该系统利用大型语言模型根据结构化的故事在Minecraft中生成可玩的游戏水平。该系统会改变叙事元素，例如主角目标，对手挑战和环境环境，以及具有空间和游戏限制的into游戏水平。我们引入了一个灵活的框架，该框架允许自定义故事复杂性，从而使动态级别的生成。该系统采用缩放算法来保持空间一致性，同时调整关键游戏元素。我们使用基于度量的和基于人类的方法评估Word2minecraft。我们的结果表明，GPT-4-Turbo在大多数领域的表现都优于GPT-4O-Mini，包括故事连贯性和客观享受，而后者在美学吸引力方面表现出色。我们还展示了该系统具有高地图享受的产生水平的能力，这在故事和游戏设计的交集中为前进提供了有希望的一步。我们在https://github.com/jmz-kk/word2minecraft/tree/word2mc_v0上打开代码]]></description>
      <guid>https://arxiv.org/abs/2503.16536</guid>
      <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>