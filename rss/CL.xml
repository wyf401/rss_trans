<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 07 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>深度循环语言模型中的论元结构构造分析</title>
      <link>https://arxiv.org/abs/2408.03062</link>
      <description><![CDATA[arXiv:2408.03062v1 公告类型：新
摘要：了解大脑如何处理语言和语言结构是认知计算神经科学的一个基本问题。在本研究中，我们探索了循环神经语言模型中论元结构构造 (ASC) 的表示和处理。我们在一个由 2000 个句子组成的定制数据集上训练了一个长短期记忆 (LSTM) 网络，这些句子使用 GPT-4 生成，代表了四种不同的 ASC：及物动词、双及物动词、引起运动和结果结构。
我们使用多维缩放 (MDS) 和 t 分布随机邻域嵌入 (t-SNE) 分析了 LSTM 模型隐藏层的内部激活，以可视化句子表示。计算了广义判别值 (GDV) 以量化这些表示内的聚类程度。我们的结果表明，句子表征在所有隐藏层中形成与四个 ASC 相对应的不同聚类，其中最明显的聚类出现在输出层之前的最后一个隐藏层中。这表明即使是相对简单的、受大脑约束的循环神经网络也能有效区分各种构造类型。
这些发现与之前的研究一致，这些研究证明了在下一个单词预测任务上训练的循环语言模型中出现了词类和语法规则表征。在未来的工作中，我们旨在使用更大的语言模型来验证这些结果，并将它们与连续语音感知期间获得的神经成像数据进行比较。这项研究强调了循环神经语言模型在反映人类大脑语言处理方面的潜力，为语言理解背后的计算和神经机制提供了宝贵的见解。]]></description>
      <guid>https://arxiv.org/abs/2408.03062</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:28 GMT</pubDate>
    </item>
    <item>
      <title>事实发现者——通过整合知识图谱来增强大型语言模型的领域专业知识</title>
      <link>https://arxiv.org/abs/2408.03010</link>
      <description><![CDATA[arXiv:2408.03010v1 公告类型：新
摘要：大型语言模型 (LLM) 的最新进展展示了它们在回答自然语言查询方面的能力。然而，它们的有效性受到有限的领域特定知识的阻碍，引发了人们对其响应可靠性的担忧。我们引入了一个混合系统，该系统使用领域特定知识图 (KG) 增强 LLM，从而旨在使用基于 KG 的检索方法提高事实正确性。我们专注于医学 KG 来展示我们的方法，其中包括 (1) 预处理、(2) Cypher 查询生成、(3) Cypher 查询处理、(4) KG 检索和 (5) LLM 增强响应生成。我们在 69 个样本的精选数据集上评估了我们的系统，在检索正确的 KG 节点方面实现了 78\% 的精度。我们的研究结果表明，混合系统在准确性和完整性方面超越了独立的 LLM，这一点已通过 LLM-as-a-Judge 评估方法进行了验证。这使得该系统成为一种有前途的工具，适用于需要事实正确性和完整性的应用，例如目标识别——这是确定生物实体以进行疾病治疗或作物改良的关键过程。此外，其直观的搜索界面和在几秒钟内提供准确响应的能力使其非常适合时间敏感、注重精度的研究环境。我们将源代码与使用的数据集和提示模板一起发布。]]></description>
      <guid>https://arxiv.org/abs/2408.03010</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:27 GMT</pubDate>
    </item>
    <item>
      <title>L3iTC 参加 FinLLM 挑战任务：金融文本分类和摘要的量化</title>
      <link>https://arxiv.org/abs/2408.03033</link>
      <description><![CDATA[arXiv:2408.03033v1 公告类型：新
摘要：本文详细介绍了我们（L3iTC）参加 FinLLM 挑战赛 2024 的情况，重点关注两个关键领域：任务 1，金融文本分类，任务 2，金融文本摘要。为了应对这些挑战，我们对几个大型语言模型 (LLM) 进行了微调，以优化每个任务的性能。具体来说，我们使用 4 位量化和 LoRA 来确定哪些 LLM 层应该以较低的精度进行训练。这种方法不仅加速了组织者提供的训练数据的微调过程，还使我们能够在低 GPU 内存上运行模型。我们的微调模型在官方测试数据集上的金融分类任务中以 F1 分数 0.7543 获得了第三名，并在金融摘要任务中获得了第六名。]]></description>
      <guid>https://arxiv.org/abs/2408.03033</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:27 GMT</pubDate>
    </item>
    <item>
      <title>EC-Guide：指令调整和量化的综合电子商务指南</title>
      <link>https://arxiv.org/abs/2408.02970</link>
      <description><![CDATA[arXiv:2408.02970v1 公告类型：新
摘要：大型语言模型 (LLM) 因其对各种挑战的经济高效解决方案而受到各个领域的广泛关注，尤其是随着指令调整和量化方面的进步。电子商务具有复杂的任务和广泛的产品-用户交互，为 LLM 提供了一个有前途的应用领域。然而，电子商务固有的领域特定概念和知识对适应一般 LLM 构成了重大挑战。为了解决这个问题，我们开发了 EC-Guide \href{https://github.com/fzp0424/EC-Guide-KDDUP-2024}，这是一份全面的电子商务指南，用于 LLM 的指令调整和量化。我们还在推理过程中启发式地集成了思想链 (CoT) 以提高算术性能。我们的方法在 Amazon KDD Cup&#39;24 中获得了 Track 2 的第二名和 Track 5 的第五名 \href{https://www.aicrowd.com/challenges/amazon-kdd-cup-2024-multi-task-online-shopping-challenge-for-llms}。此外，我们的解决方案与模型无关，可在更大的系统中实现有效的可扩展性。]]></description>
      <guid>https://arxiv.org/abs/2408.02970</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:26 GMT</pubDate>
    </item>
    <item>
      <title>通过强化学习实现同理心水平协调，从而产生同理心反应</title>
      <link>https://arxiv.org/abs/2408.02976</link>
      <description><![CDATA[arXiv:2408.02976v1 公告类型：新
摘要：共情响应生成旨在理解用户的处境和感受并做出共情响应，这对于构建类似人类的对话系统至关重要。以前的方法主要侧重于使用最大似然估计作为训练响应生成模型的优化目标，而没有考虑生成的响应和目标响应之间的共情水平一致性。为此，我们提出了一种使用强化学习 (EmpRL) 框架的共情响应生成。该框架设计了有效的共情奖励函数，并通过强化学习最大化预期奖励来生成共情响应。鉴于预训练语言模型强大的文本生成能力，EmpRL 利用预训练的 T5 模型作为生成器并进行进一步训练以初始化策略。为了使生成的响应和上下文中的目标响应之间的共情水平保持一致，使用预先设计和预先训练的共情标识符构建了一个共情奖励函数，其中包含三种共情沟通机制，即情绪反应、解释和探索。最后，使用近端策略优化算法进一步训练策略以产生共情响应。自动和手动评估都表明，所提出的 EmpRL 框架可以提高生成的响应的质量，增强生成的响应和目标响应之间的共情水平相似性，并产生涵盖情感和认知方面的共情响应。]]></description>
      <guid>https://arxiv.org/abs/2408.02976</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:26 GMT</pubDate>
    </item>
    <item>
      <title>女木匠像蓝香蕉吗？职业性别典型性的语料库调查</title>
      <link>https://arxiv.org/abs/2408.02948</link>
      <description><![CDATA[arXiv:2408.02948v1 公告类型：新
摘要：人们倾向于使用语言来提及事件的令人惊讶的特性：例如，当香蕉是蓝色时，我们更有可能提及颜色，而不是黄色。这一事实表明，黄色在某种程度上是香蕉的典型特征，而蓝色则是例外。与黄色是香蕉的典型特征类似，职业也可能存在性别。在这项工作中，我们使用信息理论技术结合语料库统计分析来探索这个问题。在两个不同的大型语料库中，我们没有发现强有力的证据表明职业和性别表现出与香蕉和颜色相同的提及模式。相反，我们发现性别提及与职业的女性化有关，这或许表明，女性主导的职业在某种程度上被视为比男性主导的职业“更具性别特征”，因此它们总体上鼓励更多地提及性别。]]></description>
      <guid>https://arxiv.org/abs/2408.02948</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:25 GMT</pubDate>
    </item>
    <item>
      <title>注册营养师考试中法学硕士的准确性和一致性：快速工程和知识检索的影响</title>
      <link>https://arxiv.org/abs/2408.02964</link>
      <description><![CDATA[arXiv:2408.02964v1 公告类型：新
摘要：大型语言模型 (LLM) 正在从根本上改变健康和福祉领域的面向人类的应用程序：提高患者参与度、加快临床决策并促进医学教育。尽管最先进的 LLM 在多个对话应用程序中表现出色，但在营养和饮食应用程序中的评估仍然不足。在本文中，我们建议采用注册营养师 (RD) 考试对最先进的 LLM、GPT-4o、Claude 3.5 Sonnet 和 Gemini 1.5 Pro 进行标准和全面的评估，评估营养查询的准确性和一致性。我们的评估包括 1050 道 RD 考试问题，涵盖多个营养主题和熟练程度。此外，我们首次研究了零样本 (ZS)、思维链 (CoT)、具有自我一致性的思维链 (CoT-SC) 和检索增强提示 (RAP) 对回答准确性和一致性的影响。我们的研究结果表明，虽然这些 LLM 获得了可接受的整体性能，但它们的结果因提示和问题领域的不同而存在很大差异。采用 CoT-SC 提示的 GPT-4o 优于其他方法，而采用 ZS 的 Gemini 1.5 Pro 记录了最高的一致性。对于 GPT-4o 和 Claude 3.5，CoT 提高了准确性，而 CoT-SC 提高了准确性和一致性。RAP 对 GPT-4o 回答专家级问题特别有效。因此，选择适合熟练程度和特定领域的适当 LLM 和提示技术可以减少饮食和营养聊天机器人中的错误和潜在风险。]]></description>
      <guid>https://arxiv.org/abs/2408.02964</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:25 GMT</pubDate>
    </item>
    <item>
      <title>中级直接偏好优化</title>
      <link>https://arxiv.org/abs/2408.02923</link>
      <description><![CDATA[arXiv:2408.02923v1 公告类型：新 
摘要：我们提出了中间直接偏好优化 (DPO) 方法来计算选定中间层的 DPO 损失，作为微调大型语言模型 (LLM) 的辅助损失。传统的 DPO 方法通过使用来自最后一层的 logit 计算 DPO 损失来微调监督微调 (SFT) 模型。在我们的中间 DPO 方法中，使用来自 K 个选定中间层的 logit 计算 DPO 损失并取平均值以获得中间 DPO 损失。对于训练中间 DPO 模型，最终损失是通过计算 DPO 和中间 DPO 损失的加权和来获得的。在推理过程中，中间 DPO 模型使用最后一层 logit 进行解码，类似于传统 DPO 模型。在使用超反馈数据集的实验中，使用 GPT-4 评估了中间 DPO 模型的性能。结果显示，使用 32 层 SFT 模型第 22 层计算的中间 DPO 损失训练的中间 DPO 模型分别相对于传统 DPO 和 SFT 模型取得了 52.5% 和 67.5% 的胜率，证明了所提方法的有效性。此外，我们报告了所选中间层的位置、层数和性能之间的关系。]]></description>
      <guid>https://arxiv.org/abs/2408.02923</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:24 GMT</pubDate>
    </item>
    <item>
      <title>多通道神经传感器的自监督学习</title>
      <link>https://arxiv.org/abs/2408.02945</link>
      <description><![CDATA[arXiv:2408.02945v1 公告类型：新
摘要：自监督学习，例如使用 wav2vec 2.0 框架，可显著提高端到端自动语音识别 (ASR) 的准确性。Wav2vec 2.0 已应用于单通道端到端 ASR 模型。在这项工作中，我们探索了一种基于 wav2vec 2.0 框架的多通道端到端 ASR 模型的自监督学习方法。作为多通道端到端 ASR 模型，我们专注于多通道神经传感器。在预训练中，我们比较了三种不同的特征量化方法来训练多通道顺应者音频编码器：联合量化、特征量化和通道量化。在微调中，我们训练了多通道顺应者换能器。所有实验均使用远场内部和 CHiME-4 数据集进行。实验结果表明，特征量化是最有效的方法。与未经任何预训练的模型相比，我们观察到远场内部数据集的字符错误率相对降低了 66%。]]></description>
      <guid>https://arxiv.org/abs/2408.02945</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:24 GMT</pubDate>
    </item>
    <item>
      <title>利用块间交互来增强基于大型语言模型的问答中的检索</title>
      <link>https://arxiv.org/abs/2408.02907</link>
      <description><![CDATA[arXiv:2408.02907v1 公告类型：新
摘要：检索外部知识并用相关信息提示大型语言模型是提高问答任务性能的有效范例。以前的研究通常孤立地处理来自外部文档的段落，导致缺乏上下文和模糊引用，特别是在多文档和复杂任务中。为了克服这些挑战，我们提出了一个新的检索框架 IIER，它利用块间交互来增强检索。该框架通过考虑三种类型的交互来捕获文档块之间的内部连接：结构、关键字和语义。然后，我们构建一个统一的块交互图来全面表示所有外部文档。此外，我们设计了一个基于图的证据链检索器，它利用先前的路径和块交互来指导检索过程。它根据目标问题识别多个种子节点，并迭代搜索相关块以收集支持证据。此检索过程可细化上下文和推理链，帮助大型语言模型进行推理和生成答案。大量实验表明，IIER 在四个数据集上的表现优于强基线，凸显了其在提高检索和推理能力方面的有效性。]]></description>
      <guid>https://arxiv.org/abs/2408.02907</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:23 GMT</pubDate>
    </item>
    <item>
      <title>数据清单：关于具有可用信息的单元测试数据集</title>
      <link>https://arxiv.org/abs/2408.02919</link>
      <description><![CDATA[arXiv:2408.02919v1 公告类型：新
摘要：模型检查表（Ribeiro 等人，2020 年）已成为理解 LLM 行为的有用工具，类似于软件工程中的单元测试。然而，尽管数据集是模型行为的关键决定因素，但评估数据集（例如，是否存在注释工件）主要是在下游发现模型行为问题后临时进行的。在这项工作中，我们通过提出基于 V 信息文献的分类法，采取了一种更原则性的数据集单元测试方法。我们将此类单元测试的集合称为数据检查表。使用检查表，我们不仅能够恢复众所周知的数据集（例如 SNLI）中的已知工件，而且还能发现 LLM 对齐偏好数据集中以前未知的工件。数据检查表进一步实现了一种新的数据过滤，我们使用它来提高偏好对齐的有效性和数据效率。]]></description>
      <guid>https://arxiv.org/abs/2408.02919</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:23 GMT</pubDate>
    </item>
    <item>
      <title>使用异构反馈微调 LLM 的框架</title>
      <link>https://arxiv.org/abs/2408.02861</link>
      <description><![CDATA[arXiv:2408.02861v1 公告类型：新
摘要：大型语言模型 (LLM) 已应用于广泛的任务，包括文本摘要、网页导航和聊天机器人。它们受益于监督微调 (SFT) 和在无监督预训练之后从人工反馈中强化学习 (RLHF)。这些数据集可能难以收集、范围有限且样本质量各不相同。此外，数据集的监督格式可能存在很大差异，从数值到二进制以及具有许多不同值的多维。我们提出了一个使用异构反馈微调 LLM 的框架，该框架有两个主要组成部分。首先，我们将异构反馈数据组合成单一的监督格式，与 SFT 和 RLHF 等方法兼容。接下来，给定这个统一的反馈数据集，我们提取一个高质量且多样化的子集，以获得可能超过完整数据集的性能提升。我们进行了大量实验，以了解这些技术整合异构反馈的有效性，并展示了使用高质量和多样化数据子集所带来的改进。我们发现我们的框架能够同时在多个领域改进模型，例如在指令遵循和偏差减少方面。]]></description>
      <guid>https://arxiv.org/abs/2408.02861</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:22 GMT</pubDate>
    </item>
    <item>
      <title>SETN：利用文本和网络信息增强的股票嵌入</title>
      <link>https://arxiv.org/abs/2408.02899</link>
      <description><![CDATA[arXiv:2408.02899v1 公告类型：新
摘要：股票嵌入是一种用于股票向量表示的方法。财富管理领域对股票向量表示（即股票嵌入）的需求日益增长，该方法已应用于股票价格预测、投资组合优化和类似的基金识别等各种任务。股票嵌入的优点是能够量化股票之间的相对关系，并且可以从文本和网络数据等非结构化数据中提取有用信息。在本研究中，我们提出了增强文本和网络信息的股票嵌入（SETN），使用领域自适应的预训练的基于 Transformer 的模型来嵌入文本信息，使用图神经网络模型来掌握网络信息。我们评估了我们提出的模型在相关公司信息提取任务上的性能。我们还证明，从所提出的模型获得的股票嵌入在创建主题基金方面的表现优于从基线方法获得的股票嵌入，为财富管理行业的各种应用提供了有希望的途径。]]></description>
      <guid>https://arxiv.org/abs/2408.02899</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:22 GMT</pubDate>
    </item>
    <item>
      <title>LLM 经济人？通过效用理论绘制 LLM 的行为偏差</title>
      <link>https://arxiv.org/abs/2408.02784</link>
      <description><![CDATA[arXiv:2408.02784v1 公告类型：新
摘要：人类不是经济人（即理性的经济人）。作为人类，我们表现出系统性的行为偏见，例如损失厌恶、锚定、框架等，这导致我们做出次优的经济决策。如果这些偏见可能嵌入在训练大型语言模型 (LLM) 的文本数据中，那么 LLM 在多大程度上容易出现相同的行为偏见？了解 LLM 中的这些偏见对于部署 LLM 来支持人类决策至关重要。我们提出了效用理论——现代经济理论核心的范式——作为评估 LLM 经济偏见的方法。效用理论能够量化和比较经济行为与基准（例如完全理性或人类行为）。为了展示我们的方法，我们量化和比较了各种开源和闭源 LLM 的经济行为。我们发现，当前法学硕士的经济行为既不完全像人类，也不完全像经济人。我们还发现，大多数当前法学硕士都难以在不同环境下保持一致的经济行为。最后，我们说明了我们的方法如何衡量诸如提示之类的干预措施对经济偏见的影响。]]></description>
      <guid>https://arxiv.org/abs/2408.02784</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:21 GMT</pubDate>
    </item>
    <item>
      <title>通过面部表情和礼貌审视维基百科上的性别和权力</title>
      <link>https://arxiv.org/abs/2408.02798</link>
      <description><![CDATA[arXiv:2408.02798v1 公告类型：新
摘要：我们提出了一个分析话语的框架，结合了社会语言学理论中的两个相互依赖的概念：面子行为和礼貌。虽然礼貌有强大的现有工具和数据，但面子行为的资源较少。我们引入了一个通过用面子行为注释维基百科讨论页面创建的新语料库，并使用它来训练面子行为标记器。然后，我们使用我们的框架来研究面子和礼貌如何与维基百科编辑之间的讨论中的性别和权力相互作用。除其他发现外，我们观察到女性维基百科人不仅更有礼貌，这与之前的研究一致，而且这种差异与更多针对自己面子方面的语言相对应。有趣的是，一旦限制在具有管理权力的编辑身上，这种区别几乎就消失了。]]></description>
      <guid>https://arxiv.org/abs/2408.02798</guid>
      <pubDate>Wed, 07 Aug 2024 06:20:21 GMT</pubDate>
    </item>
    </channel>
</rss>