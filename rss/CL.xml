<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Thu, 05 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>优化土耳其语大型语言模型：语料库选择和训练的新方法</title>
      <link>https://arxiv.org/abs/2412.02775</link>
      <description><![CDATA[arXiv:2412.02775v1 公告类型：新
摘要：在本研究中，我们开发并评估了新的语料库选择和训练方法，以提高土耳其语模型的有效性。具体来说，我们调整了大型语言模型生成的数据集，并将英语数据集翻译成土耳其语，将这些资源整合到训练过程中。这种方法大大提高了小样本和零样本学习场景的模型准确性。此外，我们发现，合并这些调整后的模型可以显著提高其性能。包括特定任务的绩效评估在内的人工评估指标进一步表明，这些调整后的模型更善于理解土耳其语和解决基于逻辑的查询。这项研究强调了改进语料库选择策略以优化多语言模型性能的重要性，尤其是对于土耳其语等资源不足的语言。]]></description>
      <guid>https://arxiv.org/abs/2412.02775</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Hybrid-SQuAD：混合学术问答数据集</title>
      <link>https://arxiv.org/abs/2412.02788</link>
      <description><![CDATA[arXiv:2412.02788v1 公告类型：新
摘要：现有的学术问答 (QA) 方法通常针对同质数据源，仅依赖于文本或知识图谱 (KG)。然而，学术信息通常跨越异构来源，因此需要开发能够整合来自多个异构数据源的信息的 QA 系统。为了应对这一挑战，我们引入了 Hybrid-SQuAD（混合学术问答数据集），这是一种新颖的大规模 QA 数据集，旨在帮助回答结合文本和 KG 事实的问题。该数据集由大型语言模型生成的 10.5K 个问答对组成，利用 KG - DBLP 和 SemOpenAlex 以及来自维基百科的相应文本。此外，我们提出了一种基于 RAG 的基线混合 QA 模型，在 Hybrid-SQuAD 测试集上实现了 69.65 的精确匹配分数。]]></description>
      <guid>https://arxiv.org/abs/2412.02788</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用于缓解幻觉的进化大型语言模型</title>
      <link>https://arxiv.org/abs/2412.02790</link>
      <description><![CDATA[arXiv:2412.02790v1 公告类型：新
摘要：ChatGPT 和 Gemini 等 LLM 的出现标志着人工智能应用的现代时代的到来，其特点是高影响力的应用生成文本、图像和视频。然而，这些模型通常伴随着一个关键的挑战，即幻觉：自信地呈现不准确或捏造的信息。当这些模型应用于医疗保健和法律等专业领域时，这个问题引起了严重的担忧，因为这些领域的信息的准确性和精确性是绝对条件。在本文中，我们提出了 EvoLLMs，这是一个受进化计算启发的创新框架，它可以自动生成高质量的问答 (QA) 数据集，同时最大限度地减少幻觉。EvoLLMs 采用遗传算法，模仿选择、变异和突变等进化过程，以指导 LLM 生成准确、上下文相关的问答对。比较分析表明，EvoLLM 在深度、相关性和覆盖率等关键指标上始终优于人类生成的数据集，同时在缓解幻觉方面的表现几乎与人类相当。这些结果表明，EvoLLM 是一种强大而高效的 QA 数据集生成解决方案，可显著减少手动整理所需的时间和资源。]]></description>
      <guid>https://arxiv.org/abs/2412.02790</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CNNSum：利用大型语言模型探索中国小说的长上下文摘要</title>
      <link>https://arxiv.org/abs/2412.02819</link>
      <description><![CDATA[arXiv:2412.02819v1 公告类型：新
摘要：大型语言模型（LLM）在许多长上下文任务中得到了很好的研究。然而，由于标注成本高，用于训练或评估的高质量长上下文摘要数据集很少，限制了进一步的研究。在这项工作中，我们引入了一个新的多尺度中文长上下文小说摘要基准CNNSum，包括四个子集，长度覆盖16k\textasciitilde128k，共695个样本，标注由人为驱动。我们在CNNSum上评估了商业和开源模型并进行了详细分析。基于观察，我们进一步使用短上下文摘要数据进行微调探索。在我们的研究中：（1）GPT-4o表现不佳，原因是主观评论过多。（2）目前，长上下文摘要主要依赖于记忆能力，具有稳定的较长上下文长度的小型LLM最具成本效益。使用由短上下文摘要连接而成的长数据可以带来显著的改进。（3）提示模板可能会导致很大的性能差距，但可以通过微调来缓解。（4）微调后的聊天或指令版本可能会损害基础模型，进一步的微调无法弥补性能差距。（5）虽然具有 RoPE 基础缩放的模型表现出很强的外推潜力，但与其他插值方法结合使用时，它们的性能可能会有很大差异，需要仔细选择。（6）与其他基准相比，CNNSum 提供了更可靠、更有见地的评估结果。我们发布 CNNSum 以推动该领域的研究。]]></description>
      <guid>https://arxiv.org/abs/2412.02819</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>上下文概念学习中布尔复杂度的最小化</title>
      <link>https://arxiv.org/abs/2412.02823</link>
      <description><![CDATA[arXiv:2412.02823v1 公告类型：新
摘要：哪些因素导致了大型语言模型 (LLM) 的情境学习的相对成功和相应的困难？借鉴人类概念学习文献中的见解，我们在精心设计的概念学习任务上测试了 LLM，并表明任务表现与概念的布尔复杂性高度相关。这表明情境学习表现出与人类类似的学习倾向。]]></description>
      <guid>https://arxiv.org/abs/2412.02823</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>RARE：大型语言模型的检索增强推理增强</title>
      <link>https://arxiv.org/abs/2412.02830</link>
      <description><![CDATA[arXiv:2412.02830v1 公告类型：新
摘要：这项工作引入了 RARE（检索增强推理增强），这是相互推理框架（rStar）的多功能扩展，旨在提高大型语言模型（LLM）的推理准确性和事实完整性，以应对常识和医学推理等复杂、知识密集型任务。RARE 在蒙特卡洛树搜索（MCTS）框架内结合了两项创新操作：A6，它根据初始问题陈述生成搜索查询，使用这些查询执行信息检索，并使用检索到的数据增强推理以形成最终答案；A7，它专门针对生成的子问题利用信息检索，并使用相关的上下文信息重新回答这些子问题。此外，提出了一种检索增强事实性评分器来取代原始鉴别器，优先考虑符合高事实性标准的推理路径。使用 LLaMA 3.1 的实验结果表明，RARE 可使开源 LLM 实现与 GPT-4 和 GPT-4o 等顶级开源模型相媲美的性能。这项研究确立了 RARE 是一种可扩展的解决方案，可用于在逻辑连贯性和事实完整性至关重要的领域改进 LLM。]]></description>
      <guid>https://arxiv.org/abs/2412.02830</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>CAISSON：自组织神经网络的概念增强推理套件</title>
      <link>https://arxiv.org/abs/2412.02835</link>
      <description><![CDATA[arXiv:2412.02835v1 公告类型：新
摘要：我们提出了 CAISSON，一种新颖的检索增强生成 (RAG) 分层方法，它将传统的单向量搜索转变为多视图聚类框架。CAISSON 的核心是利用双自组织映射 (SOM) 创建文档空间的互补组织视图，其中每个视图通过专门的嵌入捕获文档关系的不同方面。第一个视图处理组合的文本和元数据嵌入，而第二个视图对富含概念嵌入的元数据进行操作，从而实现全面的多视图分析，既能捕获细粒度的语义关系，又能捕获高级概念模式。这种双视图方法通过结合来自不同组织视角的证据，实现了更细致入微的文档发现。为了评估 CAISSON，我们开发了 SynFAQA，这是一个用于生成合成金融分析师笔记和问答对的框架，可以系统地测试信息检索能力的不同方面。 SynFAQA 借鉴 HotPotQA 构建多步推理问题的方法，生成受控测试用例，其中每个问题都与包含其基本答案的一组注释配对，从简单的单实体查询发展到涉及多个实体和概念的复杂多跳检索任务。我们的实验结果表明，与基本和增强型 RAG 实现相比，都有显著改进，特别是对于复杂的多实体查询，同时保持了适合交互式应用程序的实际响应时间。]]></description>
      <guid>https://arxiv.org/abs/2412.02835</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>从神经网络解释中消除虚假相关性</title>
      <link>https://arxiv.org/abs/2412.02893</link>
      <description><![CDATA[arXiv:2412.02893v1 公告类型：新
摘要：现有的识别导致不良和有害行为的神经元的算法没有考虑混杂因素（例如谈话主题）的影响。在这项工作中，我们表明混杂因素可以产生虚假相关性，并提出了一种控制主题影响的新因果中介方法。在对两个大型语言模型的实验中，我们研究了局部化假设，并表明调整谈话主题的影响后，毒性的局部性会降低。]]></description>
      <guid>https://arxiv.org/abs/2412.02893</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>MLD-EA：通过引入情感和动作来检查并完成叙事连贯性</title>
      <link>https://arxiv.org/abs/2412.02897</link>
      <description><![CDATA[arXiv:2412.02897v1 公告类型：新
摘要：叙事理解和故事生成是自然语言处理 (NLP) 中的关键挑战，现有的大部分研究都集中在总结和问答任务上。虽然以前的研究已经探索了预测情节结局和生成扩展叙事，但它们往往忽视了故事中的逻辑连贯性，导致该领域存在重大空白。为了解决这个问题，我们引入了情感和动作缺失逻辑检测器 (MLD-EA) 模型，该模型利用大型语言模型 (LLM) 来识别叙事空白并生成与故事的情感和逻辑流程无缝集成的连贯句子。实验结果表明，MLD-EA 模型增强了叙事理解和故事生成，突出了 LLM 作为具有逻辑连贯性和情感一致性的故事写作中有效逻辑检查器的潜力。这项工作填补了 NLP 研究的空白，并推进了创建更复杂、更可靠的故事生成系统的边界目标。]]></description>
      <guid>https://arxiv.org/abs/2412.02897</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用不确定性感知微调增强对大型语言模型的信任</title>
      <link>https://arxiv.org/abs/2412.02904</link>
      <description><![CDATA[arXiv:2412.02904v1 公告类型：新
摘要：大型语言模型 (LLM) 以其令人印象深刻的推理和问答能力彻底改变了自然语言处理领域。然而，这些模型有时容易产生听起来可信但不正确的信息，这种现象称为 LLM 幻觉。LLM 中可靠的不确定性估计对于培养对其生成的响应的信任至关重要，并且是检测和预防错误或幻觉输出的关键工具。为了在开放式和自由形式的自然语言生成中实现可靠且经过良好校准的不确定性量化，我们提出了一种不确定性感知的 LLM 微调方法。这种方法增强了模型在不影响准确性的情况下提供可靠不确定性估计的能力，从而指导它们产生更值得信赖的响应。我们引入了一种新颖的不确定性感知因果语言建模损失函数，该函数以决策理论原理为基础。通过对多个自由形式问答数据集和模型进行严格评估，我们证明了我们的不确定性感知微调方法在自然语言生成任务中比使用标准因果语言建模损失进行微调能产生更好的校准不确定性估计。此外，实验结果表明，所提出的方法显著提高了模型检测幻觉和识别域外提示的能力。]]></description>
      <guid>https://arxiv.org/abs/2412.02904</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>单细胞组学领域：使用单细胞数据进行细胞类型注释的大型语言模型基准研究</title>
      <link>https://arxiv.org/abs/2412.02915</link>
      <description><![CDATA[arXiv:2412.02915v1 公告类型：新
摘要：在过去十年中，单细胞测序的革命使得人们能够同时对数千个单个细胞的各种模式进行分子分析，从而使科学家能够研究复杂组织的多种功能并揭示潜在的疾病机制。在所有分析步骤中，将单个细胞分配到特定类型对于理解细胞异质性至关重要。然而，这个过程通常是劳动密集型的，需要大量的专业知识。大型语言模型 (LLM) 的最新进展已经证明了它们能够有效地处理和合成大量文本，以自动提取必要的生物学知识，例如标记基因，从而有可能促进更高效和自动化的细胞类型注释。为了彻底评估现代指令调整的 LLM 在自动化细胞类型识别过程中的能力，我们引入了 SOAR，这是一项针对单细胞基因组学中细胞类型注释任务的 LLM 的全面基准研究。具体来说，我们评估了 8 个指令调整的 LLM 在 11 个数据集上的性能，这些数据集涵盖多种细胞类型和物种。我们的研究探索了 LLM 在单细胞 RNA 测序 (scRNA-seq) 数据中准确分类和注释细胞类型的潜力，同时通过跨模态翻译将其应用扩展到多组学数据。此外，我们评估了思路链 (CoT) 提示技术在注释过程中生成详细生物学见解的有效性。结果表明，LLM 可以提供对单细胞数据的稳健解释，而无需额外的微调，从而推进基因组学研究中细胞类型注释的自动化。]]></description>
      <guid>https://arxiv.org/abs/2412.02915</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>动态图神经常微分方程网络用于对话中的多模态情感识别</title>
      <link>https://arxiv.org/abs/2412.02935</link>
      <description><![CDATA[arXiv:2412.02935v1 公告类型：新
摘要：对话中的多模态情绪识别（MERC）是指通过组合来自多种不同模态（例如音频、图像、文本、视频等）的数据来识别和分类人类的情绪状态。大多数现有的多模态情绪识别方法使用GCN来提高性能，但现有的GCN方法容易过拟合，无法捕捉说话者情绪的时间依赖性。为了解决上述问题，我们提出了一种用于MERC的动态图神经常微分方程网络（DGODE），结合情绪的动态变化来捕捉说话者情绪的时间依赖性，有效地缓解了GCN的过拟合问题。从技术上讲，DGODE的关键思想是利用自适应mixhop机制来提高GCN的泛化能力，并使用图ODE演化网络来表征节点表示随时间的连续动态并捕获时间依赖性。在两个公开的多模态情绪识别数据集上进行的大量实验表明，所提出的 DGODE 模型与各种基线相比具有优异的性能。此外，所提出的 DGODE 还可以缓解过度平滑问题，从而实现深度 GCN 网络的构建。]]></description>
      <guid>https://arxiv.org/abs/2412.02935</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于法学硕士的隐喻检测的课程式数据增强</title>
      <link>https://arxiv.org/abs/2412.02956</link>
      <description><![CDATA[arXiv:2412.02956v1 公告类型：新
摘要：最近，利用大型语言模型 (LLM) 进行隐喻检测取得了令人鼓舞的成果。然而，这些方法严重依赖于闭源 LLM 的功能，而闭源 LLM 的推理成本和延迟相对较高。为了解决这个问题，我们提出了一种通过微调开源 LLM 进行隐喻检测的方法，通过单个推理步骤有效降低推理成本和延迟。此外，隐喻检测存在严重的数据稀缺问题，阻碍了 LLM 的有效微调。为了解决这个问题，我们引入了课程式数据增强 (CDA)。具体来说，在微调之前，我们评估训练数据以识别正确预测的实例进行微调，而错误预测的实例则用作数据增强的种子数据。这种方法使模型能够快速学习更简单的知识并逐步获取更复杂的知识，从而逐步提高性能。实验结果表明，我们的方法在所有基线上都达到了最佳性能。此外，我们还提供了详细的消融研究来验证 CDA 的有效性。]]></description>
      <guid>https://arxiv.org/abs/2412.02956</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>推进对话心理治疗：将隐私、双记忆和领域专业知识与大型语言模型相结合</title>
      <link>https://arxiv.org/abs/2412.02987</link>
      <description><![CDATA[arXiv:2412.02987v1 公告类型：新
摘要：心理健康日益成为一个全球性问题，这揭示了传统对话心理治疗的局限性，受到地点、时间、费用和隐私问题的限制。为了应对这些挑战，我们推出了 SoulSpeak，这是一款支持大型语言模型 (LLM) 的聊天机器人，旨在使心理治疗的访问变得民主化。SoulSpeak 通过结合一种新颖的双记忆组件改进了标准 LLM 聊天机器人的功能，该组件通过检索增强生成 (RAG) 结合短期和长期上下文来提供个性化响应，同时通过专用隐私模块确保保护用户隐私和亲密关系。此外，它利用治疗师与客户互动的咨询聊天数据集和各种提示技术来使生成的响应与心理治疗方法保持一致。我们引入了两个经过微调的 BERT 模型来评估该系统与现有 LLM 和人类治疗师的比较：对话心理治疗偏好模型 (CPPM) 用于模拟人类对响应的偏好，另一个用于评估响应与用户输入的相关性。CPPM 可用于训练和评估独立于 SoulSpeak 的以心理治疗为中心的语言模型，有助于解决可用于心理治疗的有限资源。此外，还检查了双记忆组件的有效性和隐私模块的稳健性。我们的研究结果强调了通过提供一种将传统疗法的专业知识与 LLM 的优势相结合的替代方案来增强心理健康护理的潜力和挑战，为解决当前心理健康服务中的可及性和个性化差距提供了一种有希望的方法。]]></description>
      <guid>https://arxiv.org/abs/2412.02987</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    <item>
      <title>人类差异与机器一致性：对人类和大型语言模型生成的文本的语言分析</title>
      <link>https://arxiv.org/abs/2412.03025</link>
      <description><![CDATA[arXiv:2412.03025v1 公告类型：新
摘要：大型语言模型 (LLM) 的快速发展显著提高了它们生成自然语言的能力，使得 LLM 生成的文本与人类书写的文本越来越难以区分。最近的研究主要集中在使用 LLM 将文本分类为人写或机器生成的。在我们的研究中，我们采用了一种不同的方法，根据 250 种不同的语言特征对跨四个领域的文本进行分析。我们从 SemEval 2024 任务 8 的子任务 B 中选择了 M4 数据集。我们使用 LFTK 工具自动计算各种语言特征，并另外测量每个文档的平均句法深度、语义相似性和情感内容。然后，我们对所有计算出的特征应用二维 PCA 约简。我们的分析揭示了人类书写的文本与 LLM 生成的文本之间存在显著差异，尤其是在这些特征的可变性方面，我们发现人类书写的文本的可变性要高得多。这种差异在语言风格约束不太严格的文本类型中尤其明显。我们的研究结果表明，与 LLM 生成的文本相比，人类书写的文本对认知的要求较低，语义内容更丰富，情感内容更丰富。这些见解强调了需要结合有意义的语言特征来增强对 LLM 文本输出的理解。]]></description>
      <guid>https://arxiv.org/abs/2412.03025</guid>
      <pubDate>Thu, 05 Dec 2024 05:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>