<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>cs.CL 在 arXiv.org 上更新</title>
    <link>http://rss.arxiv.org/rss/cs.CL</link>
    <description>cs.CL 更新 arXiv.org 电子印刷档案。</description>
    <lastBuildDate>Wed, 04 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过法学硕士 (LLM) 自动从科学文献中发现知识：一种具有渐进式本体提示的双代理方法</title>
      <link>https://arxiv.org/abs/2409.00054</link>
      <description><![CDATA[arXiv:2409.00054v1 公告类型：新
摘要：为了应对从大量文献中自动发现知识的挑战，本文介绍了一种基于大型语言模型 (LLM) 的新框架，该框架将渐进式本体提示 (POP) 算法与双代理系统相结合，称为 LLM-Duo，旨在增强从科学文章中提取知识的自动化。POP 算法利用跨预定义本体的优先广度优先搜索 (BFS) 来生成结构化的提示模板和操作顺序，从而引导 LLM 以自动方式发现知识。此外，我们的 LLM-Duo 采用了两个专门的 LLM 代理：一个探索器和一个评估器。这两个代理协同和对抗性地工作，以提高发现和注释过程的可靠性。实验表明，我们的方法优于高级基线，可以实现更准确和完整的注释。为了验证我们的方法在现实场景中的有效性，我们在言语干预发现案例研究中采用了我们的方法。我们的方法从言语治疗领域的 64,177 篇研究文章中确定了 2,421 种干预措施。我们将这些发现整理成一个可公开访问的干预知识库，该知识库具有巨大的潜力，可以造福言语治疗界。]]></description>
      <guid>https://arxiv.org/abs/2409.00054</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士课程理解文学文本：以中国古诗词为例</title>
      <link>https://arxiv.org/abs/2409.00060</link>
      <description><![CDATA[arXiv:2409.00060v1 Announce Type: new 
摘要：大型语言模型（LLM）的诞生和快速发展在文学领域引起了不小的轰动，曾经被认为遥不可及的人工智能在文学创作中的作用正日益成为现实。在诗歌、笑话、短篇小说等体裁中，出现了许多人工智能工具，提供了令人耳目一新的新视角。然而，这些作品的质量很难进一步提高。这主要是因为理解和欣赏一部好的文学作品需要相当的门槛，比如文学理论知识、审美能力、跨学科知识等。因此，这方面的权威数据相当缺乏。此外，对文学作品的评价往往很复杂，很难完全量化，这直接阻碍了人工智能创作的进一步发展。
针对这一问题，本文尝试从LLM的角度探索文学文本的奥秘，以中国古诗词为例进行实验。首先，我们收集了各种不同来源的古诗，并请专家对其中一小部分进行注释。然后，我们设计了一系列基于 LLM 的理解指标来评估这些诗歌。最后，我们分析了不同诗集之间的相关性和差异性，以识别文学模式。通过实验，我们观察到了一系列有启发性的现象，为未来基于 LLM 的高水平文学创作提供了技术支持。]]></description>
      <guid>https://arxiv.org/abs/2409.00060</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>利用知识图谱增强自然语言推理性能，实现印尼语 COVID-19 自动事实核查</title>
      <link>https://arxiv.org/abs/2409.00061</link>
      <description><![CDATA[arXiv:2409.00061v1 公告类型：新 
摘要：自动事实核查是克服互联网上 COVID-19 错误信息传播的关键策略。这些系统通常通过自然语言推理 (NLI) 利用深度学习方法来根据支持证据验证信息的真实性。然而，深度学习中出现的一个挑战是由于训练期间缺乏知识而导致性能停滞。本研究建议使用知识图谱 (KG) 作为外部知识来增强 NLI 性能，以自动对印尼语中的 COVID-19 事实进行核查。所提出的模型架构包括三个模块：事实模块、NLI 模块和分类器模块。事实模块处理来自 KG 的信息，而 NLI 模块处理给定前提和假设之间的语义关系。两个模块的表示向量被连接起来并输入到分类器模块中以产生最终结果。该模型使用生成的印度尼西亚 COVID-19 事实核查数据集和 COVID-19 KG Bahasa Indonesia 进行训练。我们的研究表明，加入 KG 可以显著提高 NLI 在事实核查中的表现，达到 0.8616 的最佳准确率。这表明 KG 是增强 NLI 在自动事实核查中的表现的宝贵组成部分。]]></description>
      <guid>https://arxiv.org/abs/2409.00061</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 进行城市交通评估</title>
      <link>https://arxiv.org/abs/2409.00063</link>
      <description><![CDATA[arXiv:2409.00063v1 公告类型：新
摘要：了解城市流动模式并分析人们在城市中的流动方式有助于提高整体生活质量，并支持更宜居、更高效和更可持续的城市地区的发展。这项工作的一个挑战是通过用户跟踪或旅行调查收集流动性数据，因为涉及到隐私问题、不合规和高成本。这项工作提出了一种基于人工智能的创新方法，通过提示大型语言模型 (LLM) 来合成旅行调查，旨在利用其大量相关背景知识和文本生成能力。我们的研究通过将结果与不同粒度级别的现有调查数据进行比较，评估了这种方法在美国各个大都市地区的有效性。这些级别包括 (i) 模式级别，比较聚合指标，如平均旅行地点数量和旅行时间，(ii) 行程级别，重点是使用转移概率将旅行作为整体单位进行比较，以及 (iii) 活动链级别，检查个人访问的地点顺序。我们的工作涵盖了几个专有和开源的 LLM，揭示了像 Llama-2 这样的开源基础模型，即使在有限量的实际数据上进行微调时，也可以生成与实际旅行调查数据非常接近的合成数据，从而为在流动性研究中使用此类数据提供了论据。]]></description>
      <guid>https://arxiv.org/abs/2409.00063</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>用户体验措辞：通过计算语言学和创造性分析增强信息参与度</title>
      <link>https://arxiv.org/abs/2409.00064</link>
      <description><![CDATA[arXiv:2409.00064v1 公告类型：新
摘要：本研究探讨了数字平台上文本特征与信息参与度 (IE) 之间的关系。它强调了计算语言学和分析对用户交互的影响。引入 READ 模型来量化关键预测因素，如代表性、易用性、影响力和分布，以预测参与度。该模型的有效性通过 AB 测试和随机试验得到验证，在参与度（准确度：0.94）、感知（准确度：0.85）、毅力（准确度：0.81）和整体 IE（准确度：0.97）方面表现出强大的预测性能。
虽然参与度指标很强，但感知和毅力显示出略低的回忆率和 F1 分数，表明存在一些挑战。研究表明，根据 READ 模型的见解修改文本会带来显着的改进。例如，提高代表性和积极影响可使选择率提高 11%，将评估平均值从 3.98 提高到 4.46，并将保留率提高 11%。这些发现凸显了语言因素在 IE 中的重要性，为增强数字文本参与度提供了框架。该研究提供了适用于教育、健康和媒体等领域的实用策略。]]></description>
      <guid>https://arxiv.org/abs/2409.00064</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>翻译中注意力集中功能的另一种表述</title>
      <link>https://arxiv.org/abs/2409.00068</link>
      <description><![CDATA[arXiv:2409.00068v1 公告类型：新
摘要：本文旨在提出翻译任务中注意力评分函数的另一种表述。一般来说，语言具有深厚的结构，这反映在注意力评分矩阵中。我们利用这一特性来定义注意力池函数，并考虑到这一方面。在第一章中，我们用数学术语介绍了注意力机制，并解释了它的局限性和替代表述。接下来，我们重点介绍导致替代表述的实验环节。本质上，我们引导查询和键以特定方式进行交互，编码注意力头的不同角色，并将值引导到寻找上下文的位置。用数学术语来说，我们可以将这个公式视为将注意力得分矩阵（比如 $H$）投影到具有固定带宽的带矩阵空间上。这个凸子空间显然是有限维的，因此是封闭的。因此，在这个空间上的投影是适定的和唯一的。然而，以失去投影的唯一性（即 $H$ 的最佳近似值）为代价，我们定义了一个由带矩阵加上误差稀疏矩阵组成的新空间。我们证明这是一个紧凑的子空间，保证存在一个最接近 $H$ 的矩阵。我们通过验证新公式来总结论文，即计算注意力得分的新公式与原始公式的近似程度。此外，我们探讨了不同参数的影响，例如 w（上下文窗口）和 num-pos（句子中相关单词的数量）。这些分析提供了对语言处理和翻译方式的更深入的见解，揭示了上下文和单词相关性作用的细微差别。]]></description>
      <guid>https://arxiv.org/abs/2409.00068</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>学习语言建模的长期规划</title>
      <link>https://arxiv.org/abs/2409.00070</link>
      <description><![CDATA[arXiv:2409.00070v1 公告类型：新
摘要：现代语言模型通过注意力等强大功能考虑过去的文本来预测序列中的下一个标记。然而，语言模型没有明确的机制允许它们花费计算时间来规划长距离的未来文本，导致标记预测不理想。在本文中，我们提出了一个规划器，它可以预测未来许多句子的潜在计划。通过一次采样多个计划，我们根据文本连续分布的准确近似来调整语言模型，从而提高下一个标记预测的准确性。实际上，这允许用计算时间来换取预测准确性。]]></description>
      <guid>https://arxiv.org/abs/2409.00070</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>机器翻译中用于低资源语言数据增强的生成对抗网络</title>
      <link>https://arxiv.org/abs/2409.00071</link>
      <description><![CDATA[arXiv:2409.00071v1 公告类型：新
摘要：神经机器翻译 (NMT) 系统在翻译低资源语言时会遇到困难，因为这些语言缺乏用于训练模型的大规模数据语料库。由于手动数据管理既昂贵又耗时，我们建议利用生成对抗网络 (GAN) 来增强低资源语言数据。在模拟的低资源环境中对极少量的语言数据（少于 20,000 个句子）进行训练时，我们的模型显示出数据增强的潜力，可以生成单语语言数据，例如“问我我正在做的健康午餐”和“我祖父比你祖父以前更努力工作”。我们新颖的数据增强方法迈出了研究 GAN 在低资源 NMT 中的能力的第一步，我们的结果表明，未来将 GAN 扩展到低资源 NMT 是有希望的。]]></description>
      <guid>https://arxiv.org/abs/2409.00071</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 LLM 的方法是否足以检测不公平的服务条款？</title>
      <link>https://arxiv.org/abs/2409.00077</link>
      <description><![CDATA[arXiv:2409.00077v1 公告类型：新
摘要：世界各地的用户每天都会在与各种应用程序和网站交互时签署无数的服务条款 (ToS)。通常情况下，这些长达两位数页的在线合同都是由只想立即访问所需服务的用户盲目签署的。通常需要咨询法律团队的事情现在变成了一项平凡的活动，用户只需点击几下鼠标，就可能将自己的权利（例如数据隐私方面的权利）转让给无数的在线实体/公司。大型语言模型 (LLM) 擅长解析长文本文档，并且可以用于帮助用户处理 ToS 及其底层隐私政策中的可疑条款。为了研究现有模型对这项任务的实用性，我们首先构建了一个数据集，其中包含 12 个问题，这些问题分别应用于从热门网站抓取的一组隐私政策。随后，针对每个问题，一系列开源和商业聊天机器人（如 ChatGPT）都会被询问，并将答案与给定的基本事实进行比较。我们的结果表明，一些开源模型能够提供比一些商业模型更高的准确率。然而，最好的表现来自一个商业聊天机器人（ChatGPT4）。总的来说，所有模型在这项任务上的表现都只比随机模型略好一点。因此，在它们被广泛采用之前，它们的性能需要得到显著提高。]]></description>
      <guid>https://arxiv.org/abs/2409.00077</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>迈向人类层面对复杂过程工程图的理解：一个用于开放域问答的教学型、内省型多智能体框架</title>
      <link>https://arxiv.org/abs/2409.00082</link>
      <description><![CDATA[arXiv:2409.00082v1 公告类型：新 
摘要：在化学和过程工业中，工艺流程图 (PFD) 和管道与仪表图 (P&amp;ID) 对于设计、施工和维护至关重要。生成式人工智能的最新进展，例如 GPT4 (Omni) 等大型多模态模型 (LMM)，在理解和解释视觉问答 (VQA) 的流程图方面显示出良好的前景。然而，专有模型会带来数据隐私风险，而且它们的计算复杂性阻碍了在消费硬件上进行领域特定定制的知识编辑。为了克服这些挑战，我们提出了一种安全的本地企业解决方案，使用分层、多代理检索增强生成 (RAG) 框架来完成开放域问答 (ODQA) 任务，从而提供增强的数据隐私、可解释性和成本效益。我们新颖的多智能体框架采用内省和专门的子智能体，使用开源、小型多模态模型，并采用 ReAct（原因+行为）提示技术进行 PFD 和 P&amp;ID 分析，整合多个信息源以提供准确且与上下文相关的答案。我们的方法由迭代自我修正支持，旨在在 ODQA 任务中提供卓越的性能。我们进行了严格的实验研究，实证结果验证了所提出方法的有效性。]]></description>
      <guid>https://arxiv.org/abs/2409.00082</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>视觉语言和大型语言模型在胃肠病学中的表现：GPT、Claude、Llama、Phi、Mistral、Gemma 和量化模型</title>
      <link>https://arxiv.org/abs/2409.00084</link>
      <description><![CDATA[arXiv:2409.00084v1 公告类型：新
摘要：背景和目的：本研究评估大型语言模型 (LLM) 和视觉语言模型 (VLM) 在胃肠病学中的医学推理性能。
方法：我们使用了 300 道胃肠病学委员会考试风格的多项选择题，其中 138 道包含图像，以系统地评估模型配置和参数的影响，并利用 GPT-3.5 提示工程策略。接下来，我们评估了专有和开源 LLM（版本）的性能，包括 GPT（3.5、4、4{\deg}、4omini）、Claude（3、3.5）、Gemini（1.0）、Mistral、Llama（2、3、3.1）、Mixtral 和 Phi（3），跨越不同的界面（Web 和 API）、计算环境（云和本地）和模型精度（有和没有量化）。最后，我们使用半自动化管道评估了准确性。
结果：在专有模型中，GPT-4o（73.7%）和 Claude3.5-Sonnet（74.0%）的准确率最高，而 Llama3-70b（54.7%）和 Mixtral8x7b（54.3%）是准确率最高的开源模型。在量化的开源模型中，6 位量化的 Phi3-14b（48.7%）表现最佳。量化模型的得分与全精度模型 Llama2--7b、Llama2--13b 和 Gemma2--9b 的得分相当。值得注意的是，当提供图像时，VLM 对包含图像的问题的表现并没有改善，而当提供 LLM 生成的字幕时，VLM 的表现会变差。相比之下，当图像附带一句话的人工图像描述时，准确率提高了 10%。
结论：总而言之，虽然 LLM 在医学推理中表现出稳健的零样本性能，但视觉数据的整合仍然是 VLM 面临的挑战。有效的部署需要仔细确定最佳模型配置，鼓励用户考虑专有模型的高性能或开源模型的灵活适应性。]]></description>
      <guid>https://arxiv.org/abs/2409.00084</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>减轻生成性红外幻觉的遗传方法</title>
      <link>https://arxiv.org/abs/2409.00085</link>
      <description><![CDATA[arXiv:2409.00085v1 公告类型：新
摘要：生成语言模型会产生幻觉。也就是说，它们有时会生成有事实缺陷的响应。这些不准确性尤其隐蔽，因为响应流畅且表达清晰。我们专注于接地答案生成（生成 IR 的一部分）的任务，该任务旨在根据从搜索引擎检索到的结果直接回答用户的问题。我们通过采用新的“平衡适应度函数”来调整现有的遗传生成方法来解决幻觉问题，该函数由用于相关性的交叉编码器模型和用于促进接地的 n-gram 重叠度量组成。我们的平衡适应度函数方法将接地答案生成准确率提高了四倍，同时保持了高相关性。]]></description>
      <guid>https://arxiv.org/abs/2409.00085</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>设备上的语言模型：全面回顾</title>
      <link>https://arxiv.org/abs/2409.00088</link>
      <description><![CDATA[arXiv:2409.00088v1 公告类型：新
摘要：大型语言模型 (LLM) 的出现彻底改变了自然语言处理应用程序，在边缘设备上运行 LLM 变得越来越有吸引力，原因包括减少延迟、数据本地化和个性化用户体验。这篇全面的评论探讨了在资源受限的设备上部署计算成本高昂的 LLM 所面临的挑战，并探索了跨多个领域的创新解决方案。本文研究了设备上语言模型的开发、它们的高效架构（包括参数共享和模块化设计）以及量化、修剪和知识提炼等最先进的压缩技术。分析了硬件加速策略和协作边缘云部署方法，强调了性能和资源利用率之间复杂的平衡。来自主要移动制造商的设备语言模型案例研究展示了现实世界的应用和潜在好处。该评论还讨论了自适应学习、多模式功能和个性化等关键方面。通过确定关键研究方向和开放挑战，本文为设备语言模型的未来发展提供了路线图，强调需要跨学科努力，以充分发挥无处不在的智能计算的潜力，同时确保负责任和合乎道德的部署。如需全面了解设备上大型语言模型 (LLM) 的研究工作和教育资源，请访问 https://github.com/NexaAI/Awesome-LLMs-on-device。如需下载和运行设备上的 LLM，请访问 https://www.nexaai.com/models。]]></description>
      <guid>https://arxiv.org/abs/2409.00088</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在核领域特定数据上评估 ChatGPT</title>
      <link>https://arxiv.org/abs/2409.00090</link>
      <description><![CDATA[arXiv:2409.00090v1 公告类型：新
摘要：本文研究了大型语言模型 (LLM) ChatGPT 在高度专业化的核数据领域中用于问答 (Q&amp;A) 任务的应用。主要重点是评估 ChatGPT 在精选测试数据集上的性能，将独立 LLM 的结果与通过检索增强生成 (RAG) 方法生成的结果进行比较。尽管 LLM 最近取得了进展，但很容易生成不正确或“幻觉”的信息，这在需要高精度和高可靠性的应用中是一个重大限制。本研究探讨了在 LLM 中使用 RAG 的潜力，这是一种集成外部知识库和复杂检索技术来提高生成输出的准确性和相关性的方法。在此背景下，本文评估了 ChatGPT 回答特定领域问题的能力，采用了两种方法：A) 来自 LLM 的直接响应，以及 B) 来自 RAG 框架内的 LLM 的响应。这些方法的有效性通过人工和 LLM 评估的双重机制进行评估，对响应的正确性和其他指标进行评分。研究结果强调了在 LLM 中整合 RAG 管道时性能的提高，特别是在为核领域特定查询生成更准确、更符合上下文的响应方面。此外，本文还强调了进一步完善和提高此类专业领域答案质量的替代方法。]]></description>
      <guid>https://arxiv.org/abs/2409.00090</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型对核电站安全事件进行分类</title>
      <link>https://arxiv.org/abs/2409.00091</link>
      <description><![CDATA[arXiv:2409.00091v1 公告类型：新
摘要：本文提出开发一种基于大型语言模型 (LLM) 的机器学习分类器，旨在将核电站的站场状况记录 (SCR) 分为安全相关和非安全相关类别。主要目标是通过提高核电站安全分类过程的效率和准确性来增强现有的人工审查流程。本文讨论了对标记的 SCR 数据集进行分类的实验，并评估了分类器的性能。它探讨了几种提示变化的构建及其对 LLM 决策过程的观察影响。此外，它还引入了一种数值评分机制，可以为 SCR 安全分类提供更细致入微、更灵活的方法。该方法代表了核安全管理的一个创新步骤，为识别安全事件提供了一种可扩展的工具。]]></description>
      <guid>https://arxiv.org/abs/2409.00091</guid>
      <pubDate>Wed, 04 Sep 2024 04:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>